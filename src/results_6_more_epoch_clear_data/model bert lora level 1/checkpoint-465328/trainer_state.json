{
  "best_metric": 0.029151981696486473,
  "best_model_checkpoint": "results_6_more_epoch_clear_data/model bert lora level 1/checkpoint-465328",
  "epoch": 16.0,
  "eval_steps": 500,
  "global_step": 465328,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003438434824467902,
      "grad_norm": 0.9073464274406433,
      "learning_rate": 4.9990329194228464e-05,
      "loss": 0.6405,
      "step": 100
    },
    {
      "epoch": 0.006876869648935804,
      "grad_norm": 0.5731483101844788,
      "learning_rate": 4.9979583854482316e-05,
      "loss": 0.143,
      "step": 200
    },
    {
      "epoch": 0.010315304473403706,
      "grad_norm": 0.33769702911376953,
      "learning_rate": 4.996883851473616e-05,
      "loss": 0.1397,
      "step": 300
    },
    {
      "epoch": 0.013753739297871609,
      "grad_norm": 0.3372642993927002,
      "learning_rate": 4.995809317499001e-05,
      "loss": 0.135,
      "step": 400
    },
    {
      "epoch": 0.01719217412233951,
      "grad_norm": 0.2987305223941803,
      "learning_rate": 4.994734783524386e-05,
      "loss": 0.1353,
      "step": 500
    },
    {
      "epoch": 0.020630608946807412,
      "grad_norm": 0.24360592663288116,
      "learning_rate": 4.9936602495497704e-05,
      "loss": 0.1243,
      "step": 600
    },
    {
      "epoch": 0.024069043771275316,
      "grad_norm": 0.2048596292734146,
      "learning_rate": 4.9925857155751556e-05,
      "loss": 0.1352,
      "step": 700
    },
    {
      "epoch": 0.027507478595743217,
      "grad_norm": 0.39124399423599243,
      "learning_rate": 4.99151118160054e-05,
      "loss": 0.1243,
      "step": 800
    },
    {
      "epoch": 0.03094591342021112,
      "grad_norm": 0.39772889018058777,
      "learning_rate": 4.990436647625925e-05,
      "loss": 0.1341,
      "step": 900
    },
    {
      "epoch": 0.03438434824467902,
      "grad_norm": 0.41367650032043457,
      "learning_rate": 4.98936211365131e-05,
      "loss": 0.1331,
      "step": 1000
    },
    {
      "epoch": 0.03782278306914692,
      "grad_norm": 0.3266945779323578,
      "learning_rate": 4.9882875796766944e-05,
      "loss": 0.1293,
      "step": 1100
    },
    {
      "epoch": 0.041261217893614824,
      "grad_norm": 0.30541667342185974,
      "learning_rate": 4.9872130457020796e-05,
      "loss": 0.1359,
      "step": 1200
    },
    {
      "epoch": 0.04469965271808273,
      "grad_norm": 0.2651641368865967,
      "learning_rate": 4.986138511727464e-05,
      "loss": 0.1363,
      "step": 1300
    },
    {
      "epoch": 0.04813808754255063,
      "grad_norm": 0.25016847252845764,
      "learning_rate": 4.985063977752849e-05,
      "loss": 0.1304,
      "step": 1400
    },
    {
      "epoch": 0.05157652236701853,
      "grad_norm": 0.4408978521823883,
      "learning_rate": 4.983989443778234e-05,
      "loss": 0.129,
      "step": 1500
    },
    {
      "epoch": 0.055014957191486434,
      "grad_norm": 0.3379097878932953,
      "learning_rate": 4.9829149098036184e-05,
      "loss": 0.124,
      "step": 1600
    },
    {
      "epoch": 0.058453392015954335,
      "grad_norm": 0.22901250422000885,
      "learning_rate": 4.9818403758290036e-05,
      "loss": 0.1326,
      "step": 1700
    },
    {
      "epoch": 0.06189182684042224,
      "grad_norm": 0.3077338933944702,
      "learning_rate": 4.980765841854388e-05,
      "loss": 0.1367,
      "step": 1800
    },
    {
      "epoch": 0.06533026166489014,
      "grad_norm": 0.3771415650844574,
      "learning_rate": 4.979691307879773e-05,
      "loss": 0.1221,
      "step": 1900
    },
    {
      "epoch": 0.06876869648935804,
      "grad_norm": 0.429300457239151,
      "learning_rate": 4.978616773905158e-05,
      "loss": 0.1385,
      "step": 2000
    },
    {
      "epoch": 0.07220713131382595,
      "grad_norm": 0.5831432938575745,
      "learning_rate": 4.9775422399305424e-05,
      "loss": 0.1225,
      "step": 2100
    },
    {
      "epoch": 0.07564556613829385,
      "grad_norm": 0.2676733136177063,
      "learning_rate": 4.976467705955927e-05,
      "loss": 0.1354,
      "step": 2200
    },
    {
      "epoch": 0.07908400096276175,
      "grad_norm": 0.32648032903671265,
      "learning_rate": 4.975393171981312e-05,
      "loss": 0.129,
      "step": 2300
    },
    {
      "epoch": 0.08252243578722965,
      "grad_norm": 0.32802242040634155,
      "learning_rate": 4.974318638006697e-05,
      "loss": 0.1251,
      "step": 2400
    },
    {
      "epoch": 0.08596087061169755,
      "grad_norm": 0.5151005387306213,
      "learning_rate": 4.9732548493718276e-05,
      "loss": 0.1308,
      "step": 2500
    },
    {
      "epoch": 0.08939930543616546,
      "grad_norm": 0.21697783470153809,
      "learning_rate": 4.972180315397212e-05,
      "loss": 0.127,
      "step": 2600
    },
    {
      "epoch": 0.09283774026063336,
      "grad_norm": 0.3428710401058197,
      "learning_rate": 4.9711057814225974e-05,
      "loss": 0.1245,
      "step": 2700
    },
    {
      "epoch": 0.09627617508510126,
      "grad_norm": 0.34526684880256653,
      "learning_rate": 4.970031247447982e-05,
      "loss": 0.1227,
      "step": 2800
    },
    {
      "epoch": 0.09971460990956917,
      "grad_norm": 0.21916380524635315,
      "learning_rate": 4.9689567134733664e-05,
      "loss": 0.1206,
      "step": 2900
    },
    {
      "epoch": 0.10315304473403707,
      "grad_norm": 0.4151705503463745,
      "learning_rate": 4.9678821794987516e-05,
      "loss": 0.1309,
      "step": 3000
    },
    {
      "epoch": 0.10659147955850497,
      "grad_norm": 0.30002349615097046,
      "learning_rate": 4.966807645524136e-05,
      "loss": 0.1247,
      "step": 3100
    },
    {
      "epoch": 0.11002991438297287,
      "grad_norm": 0.27380669116973877,
      "learning_rate": 4.9657331115495214e-05,
      "loss": 0.1276,
      "step": 3200
    },
    {
      "epoch": 0.11346834920744077,
      "grad_norm": 0.22428062558174133,
      "learning_rate": 4.964658577574906e-05,
      "loss": 0.1226,
      "step": 3300
    },
    {
      "epoch": 0.11690678403190867,
      "grad_norm": 0.3892894983291626,
      "learning_rate": 4.9635840436002904e-05,
      "loss": 0.1206,
      "step": 3400
    },
    {
      "epoch": 0.12034521885637657,
      "grad_norm": 0.33560529351234436,
      "learning_rate": 4.9625095096256756e-05,
      "loss": 0.1216,
      "step": 3500
    },
    {
      "epoch": 0.12378365368084449,
      "grad_norm": 0.19835305213928223,
      "learning_rate": 4.96143497565106e-05,
      "loss": 0.133,
      "step": 3600
    },
    {
      "epoch": 0.1272220885053124,
      "grad_norm": 0.2938903868198395,
      "learning_rate": 4.9603604416764454e-05,
      "loss": 0.1294,
      "step": 3700
    },
    {
      "epoch": 0.1306605233297803,
      "grad_norm": 0.29273346066474915,
      "learning_rate": 4.95928590770183e-05,
      "loss": 0.1197,
      "step": 3800
    },
    {
      "epoch": 0.1340989581542482,
      "grad_norm": 0.47031670808792114,
      "learning_rate": 4.9582113737272144e-05,
      "loss": 0.1258,
      "step": 3900
    },
    {
      "epoch": 0.1375373929787161,
      "grad_norm": 0.2278866320848465,
      "learning_rate": 4.9571368397525996e-05,
      "loss": 0.1262,
      "step": 4000
    },
    {
      "epoch": 0.140975827803184,
      "grad_norm": 0.22192639112472534,
      "learning_rate": 4.956062305777984e-05,
      "loss": 0.1186,
      "step": 4100
    },
    {
      "epoch": 0.1444142626276519,
      "grad_norm": 0.24341076612472534,
      "learning_rate": 4.9549877718033694e-05,
      "loss": 0.1203,
      "step": 4200
    },
    {
      "epoch": 0.1478526974521198,
      "grad_norm": 0.20527778565883636,
      "learning_rate": 4.953913237828754e-05,
      "loss": 0.1149,
      "step": 4300
    },
    {
      "epoch": 0.1512911322765877,
      "grad_norm": 0.2350742667913437,
      "learning_rate": 4.9528387038541384e-05,
      "loss": 0.1244,
      "step": 4400
    },
    {
      "epoch": 0.1547295671010556,
      "grad_norm": 0.2822144329547882,
      "learning_rate": 4.9517641698795236e-05,
      "loss": 0.1204,
      "step": 4500
    },
    {
      "epoch": 0.1581680019255235,
      "grad_norm": 0.2554875612258911,
      "learning_rate": 4.9507003812446546e-05,
      "loss": 0.119,
      "step": 4600
    },
    {
      "epoch": 0.1616064367499914,
      "grad_norm": 0.21153509616851807,
      "learning_rate": 4.949625847270039e-05,
      "loss": 0.1285,
      "step": 4700
    },
    {
      "epoch": 0.1650448715744593,
      "grad_norm": 0.2904265522956848,
      "learning_rate": 4.948551313295424e-05,
      "loss": 0.1244,
      "step": 4800
    },
    {
      "epoch": 0.1684833063989272,
      "grad_norm": 0.18141816556453705,
      "learning_rate": 4.947476779320809e-05,
      "loss": 0.1256,
      "step": 4900
    },
    {
      "epoch": 0.1719217412233951,
      "grad_norm": 0.1961376667022705,
      "learning_rate": 4.9464022453461934e-05,
      "loss": 0.1243,
      "step": 5000
    },
    {
      "epoch": 0.17536017604786303,
      "grad_norm": 0.3938993215560913,
      "learning_rate": 4.9453277113715786e-05,
      "loss": 0.1168,
      "step": 5100
    },
    {
      "epoch": 0.17879861087233093,
      "grad_norm": 0.2695522904396057,
      "learning_rate": 4.944253177396963e-05,
      "loss": 0.113,
      "step": 5200
    },
    {
      "epoch": 0.18223704569679883,
      "grad_norm": 0.3212375044822693,
      "learning_rate": 4.943178643422348e-05,
      "loss": 0.1179,
      "step": 5300
    },
    {
      "epoch": 0.18567548052126673,
      "grad_norm": 0.21177126467227936,
      "learning_rate": 4.942104109447733e-05,
      "loss": 0.1212,
      "step": 5400
    },
    {
      "epoch": 0.18911391534573463,
      "grad_norm": 0.2890593409538269,
      "learning_rate": 4.9410295754731174e-05,
      "loss": 0.1246,
      "step": 5500
    },
    {
      "epoch": 0.19255235017020253,
      "grad_norm": 0.1538163423538208,
      "learning_rate": 4.9399550414985026e-05,
      "loss": 0.121,
      "step": 5600
    },
    {
      "epoch": 0.19599078499467043,
      "grad_norm": 0.2392071783542633,
      "learning_rate": 4.938880507523887e-05,
      "loss": 0.1112,
      "step": 5700
    },
    {
      "epoch": 0.19942921981913833,
      "grad_norm": 0.33588358759880066,
      "learning_rate": 4.9378059735492723e-05,
      "loss": 0.1186,
      "step": 5800
    },
    {
      "epoch": 0.20286765464360623,
      "grad_norm": 0.2536092698574066,
      "learning_rate": 4.936731439574657e-05,
      "loss": 0.1217,
      "step": 5900
    },
    {
      "epoch": 0.20630608946807413,
      "grad_norm": 0.15711748600006104,
      "learning_rate": 4.9356569056000414e-05,
      "loss": 0.1255,
      "step": 6000
    },
    {
      "epoch": 0.20974452429254203,
      "grad_norm": 0.17721474170684814,
      "learning_rate": 4.9345823716254266e-05,
      "loss": 0.1163,
      "step": 6100
    },
    {
      "epoch": 0.21318295911700993,
      "grad_norm": 0.4311469495296478,
      "learning_rate": 4.933507837650811e-05,
      "loss": 0.114,
      "step": 6200
    },
    {
      "epoch": 0.21662139394147784,
      "grad_norm": 0.2842305898666382,
      "learning_rate": 4.9324333036761963e-05,
      "loss": 0.1088,
      "step": 6300
    },
    {
      "epoch": 0.22005982876594574,
      "grad_norm": 0.24867123365402222,
      "learning_rate": 4.931358769701581e-05,
      "loss": 0.1161,
      "step": 6400
    },
    {
      "epoch": 0.22349826359041364,
      "grad_norm": 0.2353530079126358,
      "learning_rate": 4.9302842357269654e-05,
      "loss": 0.1162,
      "step": 6500
    },
    {
      "epoch": 0.22693669841488154,
      "grad_norm": 0.22464290261268616,
      "learning_rate": 4.9292097017523506e-05,
      "loss": 0.1142,
      "step": 6600
    },
    {
      "epoch": 0.23037513323934944,
      "grad_norm": 0.1422571986913681,
      "learning_rate": 4.928135167777735e-05,
      "loss": 0.1128,
      "step": 6700
    },
    {
      "epoch": 0.23381356806381734,
      "grad_norm": 0.2001102864742279,
      "learning_rate": 4.92706063380312e-05,
      "loss": 0.1098,
      "step": 6800
    },
    {
      "epoch": 0.23725200288828524,
      "grad_norm": 0.17032569646835327,
      "learning_rate": 4.925986099828505e-05,
      "loss": 0.1126,
      "step": 6900
    },
    {
      "epoch": 0.24069043771275314,
      "grad_norm": 0.3193188011646271,
      "learning_rate": 4.9249115658538894e-05,
      "loss": 0.1142,
      "step": 7000
    },
    {
      "epoch": 0.24412887253722107,
      "grad_norm": 0.22914376854896545,
      "learning_rate": 4.923837031879274e-05,
      "loss": 0.1105,
      "step": 7100
    },
    {
      "epoch": 0.24756730736168897,
      "grad_norm": 0.3292933702468872,
      "learning_rate": 4.922762497904659e-05,
      "loss": 0.1126,
      "step": 7200
    },
    {
      "epoch": 0.25100574218615684,
      "grad_norm": 0.18599554896354675,
      "learning_rate": 4.921687963930044e-05,
      "loss": 0.1158,
      "step": 7300
    },
    {
      "epoch": 0.2544441770106248,
      "grad_norm": 0.26610133051872253,
      "learning_rate": 4.920613429955428e-05,
      "loss": 0.1107,
      "step": 7400
    },
    {
      "epoch": 0.25788261183509265,
      "grad_norm": 0.2842605710029602,
      "learning_rate": 4.9195388959808134e-05,
      "loss": 0.1111,
      "step": 7500
    },
    {
      "epoch": 0.2613210466595606,
      "grad_norm": 0.165016770362854,
      "learning_rate": 4.918464362006198e-05,
      "loss": 0.1099,
      "step": 7600
    },
    {
      "epoch": 0.26475948148402845,
      "grad_norm": 0.14235369861125946,
      "learning_rate": 4.9173898280315825e-05,
      "loss": 0.1075,
      "step": 7700
    },
    {
      "epoch": 0.2681979163084964,
      "grad_norm": 0.39767107367515564,
      "learning_rate": 4.916315294056968e-05,
      "loss": 0.1075,
      "step": 7800
    },
    {
      "epoch": 0.27163635113296425,
      "grad_norm": 0.21212495863437653,
      "learning_rate": 4.915240760082352e-05,
      "loss": 0.1107,
      "step": 7900
    },
    {
      "epoch": 0.2750747859574322,
      "grad_norm": 0.23310346901416779,
      "learning_rate": 4.9141662261077374e-05,
      "loss": 0.1151,
      "step": 8000
    },
    {
      "epoch": 0.2785132207819001,
      "grad_norm": 0.2199891209602356,
      "learning_rate": 4.913091692133122e-05,
      "loss": 0.1017,
      "step": 8100
    },
    {
      "epoch": 0.281951655606368,
      "grad_norm": 0.1783996820449829,
      "learning_rate": 4.9120171581585065e-05,
      "loss": 0.1071,
      "step": 8200
    },
    {
      "epoch": 0.2853900904308359,
      "grad_norm": 0.15566657483577728,
      "learning_rate": 4.910942624183892e-05,
      "loss": 0.104,
      "step": 8300
    },
    {
      "epoch": 0.2888285252553038,
      "grad_norm": 0.24159586429595947,
      "learning_rate": 4.909868090209276e-05,
      "loss": 0.1015,
      "step": 8400
    },
    {
      "epoch": 0.2922669600797717,
      "grad_norm": 0.2499234676361084,
      "learning_rate": 4.9087935562346614e-05,
      "loss": 0.0986,
      "step": 8500
    },
    {
      "epoch": 0.2957053949042396,
      "grad_norm": 0.20207281410694122,
      "learning_rate": 4.907719022260046e-05,
      "loss": 0.1038,
      "step": 8600
    },
    {
      "epoch": 0.2991438297287075,
      "grad_norm": 0.16666832566261292,
      "learning_rate": 4.9066444882854305e-05,
      "loss": 0.1089,
      "step": 8700
    },
    {
      "epoch": 0.3025822645531754,
      "grad_norm": 0.16458630561828613,
      "learning_rate": 4.905569954310816e-05,
      "loss": 0.104,
      "step": 8800
    },
    {
      "epoch": 0.3060206993776433,
      "grad_norm": 0.27578556537628174,
      "learning_rate": 4.9044954203362e-05,
      "loss": 0.1025,
      "step": 8900
    },
    {
      "epoch": 0.3094591342021112,
      "grad_norm": 0.16494378447532654,
      "learning_rate": 4.903431631701331e-05,
      "loss": 0.0978,
      "step": 9000
    },
    {
      "epoch": 0.3128975690265791,
      "grad_norm": 0.11669504642486572,
      "learning_rate": 4.9023570977267164e-05,
      "loss": 0.0943,
      "step": 9100
    },
    {
      "epoch": 0.316336003851047,
      "grad_norm": 0.1445360779762268,
      "learning_rate": 4.901282563752101e-05,
      "loss": 0.105,
      "step": 9200
    },
    {
      "epoch": 0.3197744386755149,
      "grad_norm": 0.1097131073474884,
      "learning_rate": 4.9002080297774854e-05,
      "loss": 0.1011,
      "step": 9300
    },
    {
      "epoch": 0.3232128734999828,
      "grad_norm": 0.15553201735019684,
      "learning_rate": 4.8991334958028706e-05,
      "loss": 0.1018,
      "step": 9400
    },
    {
      "epoch": 0.3266513083244507,
      "grad_norm": 0.19508346915245056,
      "learning_rate": 4.898058961828255e-05,
      "loss": 0.0947,
      "step": 9500
    },
    {
      "epoch": 0.3300897431489186,
      "grad_norm": 0.19470715522766113,
      "learning_rate": 4.8969844278536404e-05,
      "loss": 0.0976,
      "step": 9600
    },
    {
      "epoch": 0.3335281779733865,
      "grad_norm": 0.23140735924243927,
      "learning_rate": 4.895909893879025e-05,
      "loss": 0.1044,
      "step": 9700
    },
    {
      "epoch": 0.3369666127978544,
      "grad_norm": 0.19821801781654358,
      "learning_rate": 4.8948353599044094e-05,
      "loss": 0.0989,
      "step": 9800
    },
    {
      "epoch": 0.3404050476223223,
      "grad_norm": 0.1474676877260208,
      "learning_rate": 4.8937608259297946e-05,
      "loss": 0.1026,
      "step": 9900
    },
    {
      "epoch": 0.3438434824467902,
      "grad_norm": 0.22299911081790924,
      "learning_rate": 4.892686291955179e-05,
      "loss": 0.0979,
      "step": 10000
    },
    {
      "epoch": 0.3472819172712581,
      "grad_norm": 0.1497635841369629,
      "learning_rate": 4.8916117579805644e-05,
      "loss": 0.1003,
      "step": 10100
    },
    {
      "epoch": 0.35072035209572605,
      "grad_norm": 0.1713329404592514,
      "learning_rate": 4.890537224005949e-05,
      "loss": 0.095,
      "step": 10200
    },
    {
      "epoch": 0.3541587869201939,
      "grad_norm": 0.29561731219291687,
      "learning_rate": 4.8894626900313334e-05,
      "loss": 0.0912,
      "step": 10300
    },
    {
      "epoch": 0.35759722174466185,
      "grad_norm": 0.11726946383714676,
      "learning_rate": 4.8883881560567186e-05,
      "loss": 0.0913,
      "step": 10400
    },
    {
      "epoch": 0.3610356565691297,
      "grad_norm": 0.17286720871925354,
      "learning_rate": 4.887313622082103e-05,
      "loss": 0.1012,
      "step": 10500
    },
    {
      "epoch": 0.36447409139359765,
      "grad_norm": 0.1463281214237213,
      "learning_rate": 4.8862390881074884e-05,
      "loss": 0.0936,
      "step": 10600
    },
    {
      "epoch": 0.3679125262180655,
      "grad_norm": 0.21481545269489288,
      "learning_rate": 4.885164554132873e-05,
      "loss": 0.0893,
      "step": 10700
    },
    {
      "epoch": 0.37135096104253346,
      "grad_norm": 0.13143648207187653,
      "learning_rate": 4.8840900201582574e-05,
      "loss": 0.0889,
      "step": 10800
    },
    {
      "epoch": 0.37478939586700133,
      "grad_norm": 0.17603865265846252,
      "learning_rate": 4.8830154861836427e-05,
      "loss": 0.0917,
      "step": 10900
    },
    {
      "epoch": 0.37822783069146926,
      "grad_norm": 0.22317172586917877,
      "learning_rate": 4.881940952209027e-05,
      "loss": 0.091,
      "step": 11000
    },
    {
      "epoch": 0.38166626551593713,
      "grad_norm": 0.2634740173816681,
      "learning_rate": 4.8808664182344124e-05,
      "loss": 0.0897,
      "step": 11100
    },
    {
      "epoch": 0.38510470034040506,
      "grad_norm": 0.15853019058704376,
      "learning_rate": 4.879791884259797e-05,
      "loss": 0.0956,
      "step": 11200
    },
    {
      "epoch": 0.38854313516487293,
      "grad_norm": 0.22476105391979218,
      "learning_rate": 4.8787173502851814e-05,
      "loss": 0.0932,
      "step": 11300
    },
    {
      "epoch": 0.39198156998934086,
      "grad_norm": 0.14824950695037842,
      "learning_rate": 4.8776428163105667e-05,
      "loss": 0.0883,
      "step": 11400
    },
    {
      "epoch": 0.39542000481380873,
      "grad_norm": 0.23125526309013367,
      "learning_rate": 4.876568282335951e-05,
      "loss": 0.0912,
      "step": 11500
    },
    {
      "epoch": 0.39885843963827666,
      "grad_norm": 0.22130881249904633,
      "learning_rate": 4.8754937483613364e-05,
      "loss": 0.0921,
      "step": 11600
    },
    {
      "epoch": 0.40229687446274454,
      "grad_norm": 0.2070164978504181,
      "learning_rate": 4.874419214386721e-05,
      "loss": 0.0922,
      "step": 11700
    },
    {
      "epoch": 0.40573530928721246,
      "grad_norm": 0.12816168367862701,
      "learning_rate": 4.8733446804121054e-05,
      "loss": 0.0866,
      "step": 11800
    },
    {
      "epoch": 0.40917374411168034,
      "grad_norm": 0.2323610484600067,
      "learning_rate": 4.8722701464374907e-05,
      "loss": 0.0853,
      "step": 11900
    },
    {
      "epoch": 0.41261217893614827,
      "grad_norm": 0.22220109403133392,
      "learning_rate": 4.871195612462875e-05,
      "loss": 0.0892,
      "step": 12000
    },
    {
      "epoch": 0.4160506137606162,
      "grad_norm": 0.1358814686536789,
      "learning_rate": 4.87012107848826e-05,
      "loss": 0.085,
      "step": 12100
    },
    {
      "epoch": 0.41948904858508407,
      "grad_norm": 0.21693067252635956,
      "learning_rate": 4.869046544513645e-05,
      "loss": 0.0815,
      "step": 12200
    },
    {
      "epoch": 0.422927483409552,
      "grad_norm": 0.23607929050922394,
      "learning_rate": 4.8679720105390295e-05,
      "loss": 0.0869,
      "step": 12300
    },
    {
      "epoch": 0.42636591823401987,
      "grad_norm": 0.2467462718486786,
      "learning_rate": 4.866897476564414e-05,
      "loss": 0.0872,
      "step": 12400
    },
    {
      "epoch": 0.4298043530584878,
      "grad_norm": 0.20269182324409485,
      "learning_rate": 4.865822942589799e-05,
      "loss": 0.0829,
      "step": 12500
    },
    {
      "epoch": 0.43324278788295567,
      "grad_norm": 0.17614759504795074,
      "learning_rate": 4.864748408615184e-05,
      "loss": 0.0872,
      "step": 12600
    },
    {
      "epoch": 0.4366812227074236,
      "grad_norm": 0.3547607660293579,
      "learning_rate": 4.863673874640568e-05,
      "loss": 0.0833,
      "step": 12700
    },
    {
      "epoch": 0.4401196575318915,
      "grad_norm": 0.36258789896965027,
      "learning_rate": 4.8625993406659535e-05,
      "loss": 0.0839,
      "step": 12800
    },
    {
      "epoch": 0.4435580923563594,
      "grad_norm": 0.22686003148555756,
      "learning_rate": 4.8615355520310844e-05,
      "loss": 0.0835,
      "step": 12900
    },
    {
      "epoch": 0.4469965271808273,
      "grad_norm": 0.13427217304706573,
      "learning_rate": 4.860461018056469e-05,
      "loss": 0.0875,
      "step": 13000
    },
    {
      "epoch": 0.4504349620052952,
      "grad_norm": 0.15369290113449097,
      "learning_rate": 4.8593864840818535e-05,
      "loss": 0.0827,
      "step": 13100
    },
    {
      "epoch": 0.4538733968297631,
      "grad_norm": 0.16302791237831116,
      "learning_rate": 4.858311950107239e-05,
      "loss": 0.077,
      "step": 13200
    },
    {
      "epoch": 0.457311831654231,
      "grad_norm": 0.20439061522483826,
      "learning_rate": 4.857237416132623e-05,
      "loss": 0.0844,
      "step": 13300
    },
    {
      "epoch": 0.4607502664786989,
      "grad_norm": 0.140630841255188,
      "learning_rate": 4.8561628821580084e-05,
      "loss": 0.0823,
      "step": 13400
    },
    {
      "epoch": 0.4641887013031668,
      "grad_norm": 0.22534365952014923,
      "learning_rate": 4.855088348183393e-05,
      "loss": 0.08,
      "step": 13500
    },
    {
      "epoch": 0.4676271361276347,
      "grad_norm": 0.1841152310371399,
      "learning_rate": 4.8540138142087775e-05,
      "loss": 0.083,
      "step": 13600
    },
    {
      "epoch": 0.4710655709521026,
      "grad_norm": 0.23866263031959534,
      "learning_rate": 4.852939280234163e-05,
      "loss": 0.0832,
      "step": 13700
    },
    {
      "epoch": 0.4745040057765705,
      "grad_norm": 0.12955544888973236,
      "learning_rate": 4.851864746259547e-05,
      "loss": 0.0781,
      "step": 13800
    },
    {
      "epoch": 0.4779424406010384,
      "grad_norm": 0.23007643222808838,
      "learning_rate": 4.8507902122849324e-05,
      "loss": 0.0748,
      "step": 13900
    },
    {
      "epoch": 0.4813808754255063,
      "grad_norm": 0.416856050491333,
      "learning_rate": 4.849715678310317e-05,
      "loss": 0.0899,
      "step": 14000
    },
    {
      "epoch": 0.4848193102499742,
      "grad_norm": 0.2540677487850189,
      "learning_rate": 4.8486411443357015e-05,
      "loss": 0.0811,
      "step": 14100
    },
    {
      "epoch": 0.48825774507444214,
      "grad_norm": 0.1914619654417038,
      "learning_rate": 4.847566610361087e-05,
      "loss": 0.0809,
      "step": 14200
    },
    {
      "epoch": 0.49169617989891,
      "grad_norm": 0.1450183242559433,
      "learning_rate": 4.846492076386471e-05,
      "loss": 0.076,
      "step": 14300
    },
    {
      "epoch": 0.49513461472337794,
      "grad_norm": 0.2708604633808136,
      "learning_rate": 4.8454175424118564e-05,
      "loss": 0.0796,
      "step": 14400
    },
    {
      "epoch": 0.4985730495478458,
      "grad_norm": 0.2287832498550415,
      "learning_rate": 4.844343008437241e-05,
      "loss": 0.0862,
      "step": 14500
    },
    {
      "epoch": 0.5020114843723137,
      "grad_norm": 0.27567124366760254,
      "learning_rate": 4.8432684744626255e-05,
      "loss": 0.0782,
      "step": 14600
    },
    {
      "epoch": 0.5054499191967816,
      "grad_norm": 0.1584228277206421,
      "learning_rate": 4.842193940488011e-05,
      "loss": 0.0791,
      "step": 14700
    },
    {
      "epoch": 0.5088883540212495,
      "grad_norm": 0.23261289298534393,
      "learning_rate": 4.841119406513395e-05,
      "loss": 0.0813,
      "step": 14800
    },
    {
      "epoch": 0.5123267888457175,
      "grad_norm": 0.22723770141601562,
      "learning_rate": 4.8400448725387804e-05,
      "loss": 0.0832,
      "step": 14900
    },
    {
      "epoch": 0.5157652236701853,
      "grad_norm": 0.24394044280052185,
      "learning_rate": 4.838970338564165e-05,
      "loss": 0.0802,
      "step": 15000
    },
    {
      "epoch": 0.5192036584946532,
      "grad_norm": 0.1576448529958725,
      "learning_rate": 4.8378958045895495e-05,
      "loss": 0.0832,
      "step": 15100
    },
    {
      "epoch": 0.5226420933191211,
      "grad_norm": 0.16833075881004333,
      "learning_rate": 4.836821270614935e-05,
      "loss": 0.0772,
      "step": 15200
    },
    {
      "epoch": 0.5260805281435891,
      "grad_norm": 0.26464512944221497,
      "learning_rate": 4.835746736640319e-05,
      "loss": 0.0788,
      "step": 15300
    },
    {
      "epoch": 0.5295189629680569,
      "grad_norm": 0.35930198431015015,
      "learning_rate": 4.8346722026657044e-05,
      "loss": 0.0812,
      "step": 15400
    },
    {
      "epoch": 0.5329573977925248,
      "grad_norm": 0.18654689192771912,
      "learning_rate": 4.833597668691089e-05,
      "loss": 0.078,
      "step": 15500
    },
    {
      "epoch": 0.5363958326169928,
      "grad_norm": 0.1907995641231537,
      "learning_rate": 4.8325231347164735e-05,
      "loss": 0.0815,
      "step": 15600
    },
    {
      "epoch": 0.5398342674414607,
      "grad_norm": 0.17796720564365387,
      "learning_rate": 4.831448600741859e-05,
      "loss": 0.0739,
      "step": 15700
    },
    {
      "epoch": 0.5432727022659285,
      "grad_norm": 0.24779829382896423,
      "learning_rate": 4.830374066767243e-05,
      "loss": 0.0754,
      "step": 15800
    },
    {
      "epoch": 0.5467111370903964,
      "grad_norm": 0.17324504256248474,
      "learning_rate": 4.8292995327926284e-05,
      "loss": 0.072,
      "step": 15900
    },
    {
      "epoch": 0.5501495719148644,
      "grad_norm": 0.20739074051380157,
      "learning_rate": 4.828224998818013e-05,
      "loss": 0.075,
      "step": 16000
    },
    {
      "epoch": 0.5535880067393323,
      "grad_norm": 0.2953018546104431,
      "learning_rate": 4.8271504648433975e-05,
      "loss": 0.071,
      "step": 16100
    },
    {
      "epoch": 0.5570264415638002,
      "grad_norm": 0.16331183910369873,
      "learning_rate": 4.826075930868783e-05,
      "loss": 0.075,
      "step": 16200
    },
    {
      "epoch": 0.560464876388268,
      "grad_norm": 0.21171122789382935,
      "learning_rate": 4.825001396894167e-05,
      "loss": 0.0751,
      "step": 16300
    },
    {
      "epoch": 0.563903311212736,
      "grad_norm": 0.25699496269226074,
      "learning_rate": 4.8239268629195524e-05,
      "loss": 0.074,
      "step": 16400
    },
    {
      "epoch": 0.5673417460372039,
      "grad_norm": 0.2688630223274231,
      "learning_rate": 4.822852328944937e-05,
      "loss": 0.0746,
      "step": 16500
    },
    {
      "epoch": 0.5707801808616718,
      "grad_norm": 0.1296052634716034,
      "learning_rate": 4.8217777949703215e-05,
      "loss": 0.0696,
      "step": 16600
    },
    {
      "epoch": 0.5742186156861396,
      "grad_norm": 0.22121062874794006,
      "learning_rate": 4.820703260995707e-05,
      "loss": 0.0758,
      "step": 16700
    },
    {
      "epoch": 0.5776570505106076,
      "grad_norm": 0.18489059805870056,
      "learning_rate": 4.819628727021091e-05,
      "loss": 0.0765,
      "step": 16800
    },
    {
      "epoch": 0.5810954853350755,
      "grad_norm": 0.1858852654695511,
      "learning_rate": 4.8185541930464764e-05,
      "loss": 0.0779,
      "step": 16900
    },
    {
      "epoch": 0.5845339201595434,
      "grad_norm": 0.23487132787704468,
      "learning_rate": 4.817479659071861e-05,
      "loss": 0.0712,
      "step": 17000
    },
    {
      "epoch": 0.5879723549840112,
      "grad_norm": 0.1761070042848587,
      "learning_rate": 4.8164051250972455e-05,
      "loss": 0.0746,
      "step": 17100
    },
    {
      "epoch": 0.5914107898084792,
      "grad_norm": 0.17208726704120636,
      "learning_rate": 4.815330591122631e-05,
      "loss": 0.07,
      "step": 17200
    },
    {
      "epoch": 0.5948492246329471,
      "grad_norm": 0.27508828043937683,
      "learning_rate": 4.814256057148015e-05,
      "loss": 0.0738,
      "step": 17300
    },
    {
      "epoch": 0.598287659457415,
      "grad_norm": 0.206131249666214,
      "learning_rate": 4.8131815231734e-05,
      "loss": 0.0718,
      "step": 17400
    },
    {
      "epoch": 0.6017260942818828,
      "grad_norm": 0.2514951825141907,
      "learning_rate": 4.812106989198785e-05,
      "loss": 0.071,
      "step": 17500
    },
    {
      "epoch": 0.6051645291063508,
      "grad_norm": 0.2276366502046585,
      "learning_rate": 4.8110324552241695e-05,
      "loss": 0.0754,
      "step": 17600
    },
    {
      "epoch": 0.6086029639308187,
      "grad_norm": 0.2286929339170456,
      "learning_rate": 4.809957921249554e-05,
      "loss": 0.0708,
      "step": 17700
    },
    {
      "epoch": 0.6120413987552866,
      "grad_norm": 0.2411756068468094,
      "learning_rate": 4.808883387274939e-05,
      "loss": 0.072,
      "step": 17800
    },
    {
      "epoch": 0.6154798335797544,
      "grad_norm": 0.2297852784395218,
      "learning_rate": 4.807808853300324e-05,
      "loss": 0.0684,
      "step": 17900
    },
    {
      "epoch": 0.6189182684042224,
      "grad_norm": 0.14161714911460876,
      "learning_rate": 4.806734319325708e-05,
      "loss": 0.0687,
      "step": 18000
    },
    {
      "epoch": 0.6223567032286903,
      "grad_norm": 0.23610830307006836,
      "learning_rate": 4.8056597853510935e-05,
      "loss": 0.0747,
      "step": 18100
    },
    {
      "epoch": 0.6257951380531582,
      "grad_norm": 0.14664264023303986,
      "learning_rate": 4.804585251376478e-05,
      "loss": 0.0705,
      "step": 18200
    },
    {
      "epoch": 0.6292335728776262,
      "grad_norm": 0.24682223796844482,
      "learning_rate": 4.8035107174018626e-05,
      "loss": 0.0635,
      "step": 18300
    },
    {
      "epoch": 0.632672007702094,
      "grad_norm": 0.17202061414718628,
      "learning_rate": 4.802436183427248e-05,
      "loss": 0.0705,
      "step": 18400
    },
    {
      "epoch": 0.6361104425265619,
      "grad_norm": 0.16014616191387177,
      "learning_rate": 4.801361649452632e-05,
      "loss": 0.0687,
      "step": 18500
    },
    {
      "epoch": 0.6395488773510298,
      "grad_norm": 0.141210675239563,
      "learning_rate": 4.8002871154780175e-05,
      "loss": 0.0728,
      "step": 18600
    },
    {
      "epoch": 0.6429873121754978,
      "grad_norm": 0.16993312537670135,
      "learning_rate": 4.799212581503402e-05,
      "loss": 0.0705,
      "step": 18700
    },
    {
      "epoch": 0.6464257469999656,
      "grad_norm": 0.19793905317783356,
      "learning_rate": 4.7981380475287866e-05,
      "loss": 0.0685,
      "step": 18800
    },
    {
      "epoch": 0.6498641818244335,
      "grad_norm": 0.2891254425048828,
      "learning_rate": 4.797063513554172e-05,
      "loss": 0.0671,
      "step": 18900
    },
    {
      "epoch": 0.6533026166489014,
      "grad_norm": 0.16773129999637604,
      "learning_rate": 4.795988979579556e-05,
      "loss": 0.0679,
      "step": 19000
    },
    {
      "epoch": 0.6567410514733694,
      "grad_norm": 0.16730839014053345,
      "learning_rate": 4.7949144456049415e-05,
      "loss": 0.0714,
      "step": 19100
    },
    {
      "epoch": 0.6601794862978372,
      "grad_norm": 0.29931172728538513,
      "learning_rate": 4.7938506569700725e-05,
      "loss": 0.0664,
      "step": 19200
    },
    {
      "epoch": 0.6636179211223051,
      "grad_norm": 0.23325489461421967,
      "learning_rate": 4.792776122995457e-05,
      "loss": 0.0634,
      "step": 19300
    },
    {
      "epoch": 0.667056355946773,
      "grad_norm": 0.25407013297080994,
      "learning_rate": 4.7917015890208415e-05,
      "loss": 0.0656,
      "step": 19400
    },
    {
      "epoch": 0.670494790771241,
      "grad_norm": 0.2555665671825409,
      "learning_rate": 4.790627055046227e-05,
      "loss": 0.0687,
      "step": 19500
    },
    {
      "epoch": 0.6739332255957088,
      "grad_norm": 0.32665207982063293,
      "learning_rate": 4.789552521071611e-05,
      "loss": 0.0684,
      "step": 19600
    },
    {
      "epoch": 0.6773716604201767,
      "grad_norm": 0.15637679398059845,
      "learning_rate": 4.7884779870969965e-05,
      "loss": 0.0643,
      "step": 19700
    },
    {
      "epoch": 0.6808100952446446,
      "grad_norm": 0.27307626605033875,
      "learning_rate": 4.787403453122381e-05,
      "loss": 0.0662,
      "step": 19800
    },
    {
      "epoch": 0.6842485300691126,
      "grad_norm": 0.15421618521213531,
      "learning_rate": 4.7863289191477655e-05,
      "loss": 0.0648,
      "step": 19900
    },
    {
      "epoch": 0.6876869648935804,
      "grad_norm": 0.19695115089416504,
      "learning_rate": 4.785254385173151e-05,
      "loss": 0.0638,
      "step": 20000
    },
    {
      "epoch": 0.6911253997180483,
      "grad_norm": 0.32887929677963257,
      "learning_rate": 4.784179851198535e-05,
      "loss": 0.0645,
      "step": 20100
    },
    {
      "epoch": 0.6945638345425162,
      "grad_norm": 0.3122800886631012,
      "learning_rate": 4.7831053172239205e-05,
      "loss": 0.0689,
      "step": 20200
    },
    {
      "epoch": 0.6980022693669842,
      "grad_norm": 0.14795030653476715,
      "learning_rate": 4.782030783249305e-05,
      "loss": 0.0635,
      "step": 20300
    },
    {
      "epoch": 0.7014407041914521,
      "grad_norm": 0.16588394343852997,
      "learning_rate": 4.7809562492746895e-05,
      "loss": 0.0636,
      "step": 20400
    },
    {
      "epoch": 0.7048791390159199,
      "grad_norm": 0.14780686795711517,
      "learning_rate": 4.779892460639821e-05,
      "loss": 0.0651,
      "step": 20500
    },
    {
      "epoch": 0.7083175738403878,
      "grad_norm": 0.46069368720054626,
      "learning_rate": 4.778817926665206e-05,
      "loss": 0.0646,
      "step": 20600
    },
    {
      "epoch": 0.7117560086648558,
      "grad_norm": 0.1553313434123993,
      "learning_rate": 4.77774339269059e-05,
      "loss": 0.0644,
      "step": 20700
    },
    {
      "epoch": 0.7151944434893237,
      "grad_norm": 0.22603720426559448,
      "learning_rate": 4.7766688587159754e-05,
      "loss": 0.0695,
      "step": 20800
    },
    {
      "epoch": 0.7186328783137915,
      "grad_norm": 0.3219057023525238,
      "learning_rate": 4.77559432474136e-05,
      "loss": 0.0669,
      "step": 20900
    },
    {
      "epoch": 0.7220713131382595,
      "grad_norm": 0.29452136158943176,
      "learning_rate": 4.774519790766745e-05,
      "loss": 0.0716,
      "step": 21000
    },
    {
      "epoch": 0.7255097479627274,
      "grad_norm": 0.20887188613414764,
      "learning_rate": 4.77344525679213e-05,
      "loss": 0.0642,
      "step": 21100
    },
    {
      "epoch": 0.7289481827871953,
      "grad_norm": 0.320991188287735,
      "learning_rate": 4.772370722817514e-05,
      "loss": 0.0681,
      "step": 21200
    },
    {
      "epoch": 0.7323866176116631,
      "grad_norm": 0.2401220202445984,
      "learning_rate": 4.7712961888428994e-05,
      "loss": 0.0659,
      "step": 21300
    },
    {
      "epoch": 0.735825052436131,
      "grad_norm": 0.33573096990585327,
      "learning_rate": 4.770221654868284e-05,
      "loss": 0.0627,
      "step": 21400
    },
    {
      "epoch": 0.739263487260599,
      "grad_norm": 0.16627298295497894,
      "learning_rate": 4.769147120893669e-05,
      "loss": 0.0659,
      "step": 21500
    },
    {
      "epoch": 0.7427019220850669,
      "grad_norm": 0.3284315764904022,
      "learning_rate": 4.768072586919054e-05,
      "loss": 0.0691,
      "step": 21600
    },
    {
      "epoch": 0.7461403569095347,
      "grad_norm": 0.18314336240291595,
      "learning_rate": 4.766998052944438e-05,
      "loss": 0.0697,
      "step": 21700
    },
    {
      "epoch": 0.7495787917340027,
      "grad_norm": 0.12282110750675201,
      "learning_rate": 4.7659235189698234e-05,
      "loss": 0.0696,
      "step": 21800
    },
    {
      "epoch": 0.7530172265584706,
      "grad_norm": 0.3623780608177185,
      "learning_rate": 4.764848984995208e-05,
      "loss": 0.0651,
      "step": 21900
    },
    {
      "epoch": 0.7564556613829385,
      "grad_norm": 0.1949496865272522,
      "learning_rate": 4.7637744510205925e-05,
      "loss": 0.0642,
      "step": 22000
    },
    {
      "epoch": 0.7598940962074063,
      "grad_norm": 0.23606783151626587,
      "learning_rate": 4.762699917045978e-05,
      "loss": 0.0611,
      "step": 22100
    },
    {
      "epoch": 0.7633325310318743,
      "grad_norm": 0.33453109860420227,
      "learning_rate": 4.761625383071362e-05,
      "loss": 0.0642,
      "step": 22200
    },
    {
      "epoch": 0.7667709658563422,
      "grad_norm": 0.1585954874753952,
      "learning_rate": 4.760550849096747e-05,
      "loss": 0.0744,
      "step": 22300
    },
    {
      "epoch": 0.7702094006808101,
      "grad_norm": 0.29316791892051697,
      "learning_rate": 4.759476315122132e-05,
      "loss": 0.0672,
      "step": 22400
    },
    {
      "epoch": 0.773647835505278,
      "grad_norm": 0.19350995123386383,
      "learning_rate": 4.7584017811475165e-05,
      "loss": 0.067,
      "step": 22500
    },
    {
      "epoch": 0.7770862703297459,
      "grad_norm": 0.17858365178108215,
      "learning_rate": 4.757327247172901e-05,
      "loss": 0.0621,
      "step": 22600
    },
    {
      "epoch": 0.7805247051542138,
      "grad_norm": 0.17870667576789856,
      "learning_rate": 4.756252713198286e-05,
      "loss": 0.0671,
      "step": 22700
    },
    {
      "epoch": 0.7839631399786817,
      "grad_norm": 0.24368035793304443,
      "learning_rate": 4.755178179223671e-05,
      "loss": 0.0628,
      "step": 22800
    },
    {
      "epoch": 0.7874015748031497,
      "grad_norm": 0.15582022070884705,
      "learning_rate": 4.754103645249055e-05,
      "loss": 0.0674,
      "step": 22900
    },
    {
      "epoch": 0.7908400096276175,
      "grad_norm": 0.14808553457260132,
      "learning_rate": 4.7530291112744405e-05,
      "loss": 0.0626,
      "step": 23000
    },
    {
      "epoch": 0.7942784444520854,
      "grad_norm": 0.10384104400873184,
      "learning_rate": 4.751954577299825e-05,
      "loss": 0.0657,
      "step": 23100
    },
    {
      "epoch": 0.7977168792765533,
      "grad_norm": 0.19911819696426392,
      "learning_rate": 4.7508800433252096e-05,
      "loss": 0.0673,
      "step": 23200
    },
    {
      "epoch": 0.8011553141010213,
      "grad_norm": 0.16959117352962494,
      "learning_rate": 4.749805509350595e-05,
      "loss": 0.0589,
      "step": 23300
    },
    {
      "epoch": 0.8045937489254891,
      "grad_norm": 0.15563000738620758,
      "learning_rate": 4.748730975375979e-05,
      "loss": 0.0624,
      "step": 23400
    },
    {
      "epoch": 0.808032183749957,
      "grad_norm": 0.21471631526947021,
      "learning_rate": 4.7476564414013645e-05,
      "loss": 0.0628,
      "step": 23500
    },
    {
      "epoch": 0.8114706185744249,
      "grad_norm": 0.21758948266506195,
      "learning_rate": 4.746581907426749e-05,
      "loss": 0.0666,
      "step": 23600
    },
    {
      "epoch": 0.8149090533988929,
      "grad_norm": 0.20641787350177765,
      "learning_rate": 4.7455073734521336e-05,
      "loss": 0.0651,
      "step": 23700
    },
    {
      "epoch": 0.8183474882233607,
      "grad_norm": 0.21043488383293152,
      "learning_rate": 4.744432839477519e-05,
      "loss": 0.0578,
      "step": 23800
    },
    {
      "epoch": 0.8217859230478286,
      "grad_norm": 0.24480517208576202,
      "learning_rate": 4.743358305502903e-05,
      "loss": 0.0615,
      "step": 23900
    },
    {
      "epoch": 0.8252243578722965,
      "grad_norm": 0.1659219115972519,
      "learning_rate": 4.7422837715282885e-05,
      "loss": 0.0645,
      "step": 24000
    },
    {
      "epoch": 0.8286627926967645,
      "grad_norm": 0.18170292675495148,
      "learning_rate": 4.741209237553673e-05,
      "loss": 0.0674,
      "step": 24100
    },
    {
      "epoch": 0.8321012275212324,
      "grad_norm": 0.14760561287403107,
      "learning_rate": 4.7401347035790576e-05,
      "loss": 0.0595,
      "step": 24200
    },
    {
      "epoch": 0.8355396623457002,
      "grad_norm": 0.1597808450460434,
      "learning_rate": 4.739060169604443e-05,
      "loss": 0.0628,
      "step": 24300
    },
    {
      "epoch": 0.8389780971701681,
      "grad_norm": 0.24956652522087097,
      "learning_rate": 4.737985635629827e-05,
      "loss": 0.0641,
      "step": 24400
    },
    {
      "epoch": 0.8424165319946361,
      "grad_norm": 0.11472072452306747,
      "learning_rate": 4.7369111016552125e-05,
      "loss": 0.0614,
      "step": 24500
    },
    {
      "epoch": 0.845854966819104,
      "grad_norm": 0.33493682742118835,
      "learning_rate": 4.735836567680597e-05,
      "loss": 0.0655,
      "step": 24600
    },
    {
      "epoch": 0.8492934016435718,
      "grad_norm": 0.27123400568962097,
      "learning_rate": 4.734772779045728e-05,
      "loss": 0.062,
      "step": 24700
    },
    {
      "epoch": 0.8527318364680397,
      "grad_norm": 0.21056990325450897,
      "learning_rate": 4.733698245071113e-05,
      "loss": 0.0629,
      "step": 24800
    },
    {
      "epoch": 0.8561702712925077,
      "grad_norm": 0.18931232392787933,
      "learning_rate": 4.732623711096498e-05,
      "loss": 0.0645,
      "step": 24900
    },
    {
      "epoch": 0.8596087061169756,
      "grad_norm": 0.15434318780899048,
      "learning_rate": 4.731559922461629e-05,
      "loss": 0.0653,
      "step": 25000
    },
    {
      "epoch": 0.8630471409414434,
      "grad_norm": 0.28880786895751953,
      "learning_rate": 4.730485388487013e-05,
      "loss": 0.0593,
      "step": 25100
    },
    {
      "epoch": 0.8664855757659113,
      "grad_norm": 0.15589356422424316,
      "learning_rate": 4.7294108545123984e-05,
      "loss": 0.0629,
      "step": 25200
    },
    {
      "epoch": 0.8699240105903793,
      "grad_norm": 0.13363885879516602,
      "learning_rate": 4.728336320537783e-05,
      "loss": 0.0609,
      "step": 25300
    },
    {
      "epoch": 0.8733624454148472,
      "grad_norm": 0.23500439524650574,
      "learning_rate": 4.727272531902914e-05,
      "loss": 0.0615,
      "step": 25400
    },
    {
      "epoch": 0.876800880239315,
      "grad_norm": 0.13693253695964813,
      "learning_rate": 4.726197997928299e-05,
      "loss": 0.0611,
      "step": 25500
    },
    {
      "epoch": 0.880239315063783,
      "grad_norm": 0.3414493203163147,
      "learning_rate": 4.725123463953684e-05,
      "loss": 0.0634,
      "step": 25600
    },
    {
      "epoch": 0.8836777498882509,
      "grad_norm": 0.287826269865036,
      "learning_rate": 4.724048929979069e-05,
      "loss": 0.0599,
      "step": 25700
    },
    {
      "epoch": 0.8871161847127188,
      "grad_norm": 0.15364423394203186,
      "learning_rate": 4.7229743960044534e-05,
      "loss": 0.0598,
      "step": 25800
    },
    {
      "epoch": 0.8905546195371866,
      "grad_norm": 0.1335248053073883,
      "learning_rate": 4.721899862029838e-05,
      "loss": 0.0628,
      "step": 25900
    },
    {
      "epoch": 0.8939930543616545,
      "grad_norm": 0.22588704526424408,
      "learning_rate": 4.720825328055223e-05,
      "loss": 0.064,
      "step": 26000
    },
    {
      "epoch": 0.8974314891861225,
      "grad_norm": 0.15868446230888367,
      "learning_rate": 4.719750794080608e-05,
      "loss": 0.0606,
      "step": 26100
    },
    {
      "epoch": 0.9008699240105904,
      "grad_norm": 0.19593842327594757,
      "learning_rate": 4.718676260105992e-05,
      "loss": 0.0607,
      "step": 26200
    },
    {
      "epoch": 0.9043083588350583,
      "grad_norm": 0.2569267153739929,
      "learning_rate": 4.717601726131377e-05,
      "loss": 0.0639,
      "step": 26300
    },
    {
      "epoch": 0.9077467936595262,
      "grad_norm": 0.2757514417171478,
      "learning_rate": 4.716527192156762e-05,
      "loss": 0.0638,
      "step": 26400
    },
    {
      "epoch": 0.9111852284839941,
      "grad_norm": 0.24029168486595154,
      "learning_rate": 4.7154526581821465e-05,
      "loss": 0.0619,
      "step": 26500
    },
    {
      "epoch": 0.914623663308462,
      "grad_norm": 0.15742553770542145,
      "learning_rate": 4.714378124207531e-05,
      "loss": 0.0565,
      "step": 26600
    },
    {
      "epoch": 0.9180620981329299,
      "grad_norm": 0.5576928853988647,
      "learning_rate": 4.713303590232916e-05,
      "loss": 0.0646,
      "step": 26700
    },
    {
      "epoch": 0.9215005329573978,
      "grad_norm": 0.5927403569221497,
      "learning_rate": 4.712229056258301e-05,
      "loss": 0.0615,
      "step": 26800
    },
    {
      "epoch": 0.9249389677818657,
      "grad_norm": 0.30506202578544617,
      "learning_rate": 4.711154522283685e-05,
      "loss": 0.0604,
      "step": 26900
    },
    {
      "epoch": 0.9283774026063336,
      "grad_norm": 0.18198156356811523,
      "learning_rate": 4.7100799883090705e-05,
      "loss": 0.061,
      "step": 27000
    },
    {
      "epoch": 0.9318158374308015,
      "grad_norm": 0.15620318055152893,
      "learning_rate": 4.709005454334455e-05,
      "loss": 0.0622,
      "step": 27100
    },
    {
      "epoch": 0.9352542722552694,
      "grad_norm": 0.0998847708106041,
      "learning_rate": 4.70793092035984e-05,
      "loss": 0.0589,
      "step": 27200
    },
    {
      "epoch": 0.9386927070797373,
      "grad_norm": 0.23567573726177216,
      "learning_rate": 4.706856386385225e-05,
      "loss": 0.064,
      "step": 27300
    },
    {
      "epoch": 0.9421311419042052,
      "grad_norm": 0.3228026330471039,
      "learning_rate": 4.705781852410609e-05,
      "loss": 0.0602,
      "step": 27400
    },
    {
      "epoch": 0.9455695767286731,
      "grad_norm": 0.12983429431915283,
      "learning_rate": 4.7047073184359945e-05,
      "loss": 0.0625,
      "step": 27500
    },
    {
      "epoch": 0.949008011553141,
      "grad_norm": 0.2968798279762268,
      "learning_rate": 4.703632784461379e-05,
      "loss": 0.0607,
      "step": 27600
    },
    {
      "epoch": 0.9524464463776089,
      "grad_norm": 0.17175062000751495,
      "learning_rate": 4.702558250486764e-05,
      "loss": 0.0626,
      "step": 27700
    },
    {
      "epoch": 0.9558848812020768,
      "grad_norm": 0.11086032539606094,
      "learning_rate": 4.701483716512149e-05,
      "loss": 0.0631,
      "step": 27800
    },
    {
      "epoch": 0.9593233160265447,
      "grad_norm": 0.15422362089157104,
      "learning_rate": 4.700409182537533e-05,
      "loss": 0.0572,
      "step": 27900
    },
    {
      "epoch": 0.9627617508510126,
      "grad_norm": 0.1481456160545349,
      "learning_rate": 4.6993346485629185e-05,
      "loss": 0.062,
      "step": 28000
    },
    {
      "epoch": 0.9662001856754805,
      "grad_norm": 0.26382145285606384,
      "learning_rate": 4.698260114588303e-05,
      "loss": 0.0548,
      "step": 28100
    },
    {
      "epoch": 0.9696386204999484,
      "grad_norm": 0.1281788945198059,
      "learning_rate": 4.697185580613688e-05,
      "loss": 0.0547,
      "step": 28200
    },
    {
      "epoch": 0.9730770553244164,
      "grad_norm": 0.24034029245376587,
      "learning_rate": 4.696111046639073e-05,
      "loss": 0.0647,
      "step": 28300
    },
    {
      "epoch": 0.9765154901488843,
      "grad_norm": 0.2899155616760254,
      "learning_rate": 4.695036512664457e-05,
      "loss": 0.0579,
      "step": 28400
    },
    {
      "epoch": 0.9799539249733521,
      "grad_norm": 0.19558899104595184,
      "learning_rate": 4.6939619786898425e-05,
      "loss": 0.0612,
      "step": 28500
    },
    {
      "epoch": 0.98339235979782,
      "grad_norm": 0.2511119544506073,
      "learning_rate": 4.692887444715227e-05,
      "loss": 0.0593,
      "step": 28600
    },
    {
      "epoch": 0.986830794622288,
      "grad_norm": 0.16166651248931885,
      "learning_rate": 4.691812910740612e-05,
      "loss": 0.0577,
      "step": 28700
    },
    {
      "epoch": 0.9902692294467559,
      "grad_norm": 0.11629333347082138,
      "learning_rate": 4.690738376765997e-05,
      "loss": 0.0549,
      "step": 28800
    },
    {
      "epoch": 0.9937076642712237,
      "grad_norm": 0.18720020353794098,
      "learning_rate": 4.689663842791381e-05,
      "loss": 0.0587,
      "step": 28900
    },
    {
      "epoch": 0.9971460990956916,
      "grad_norm": 0.30421608686447144,
      "learning_rate": 4.6885893088167665e-05,
      "loss": 0.0605,
      "step": 29000
    },
    {
      "epoch": 1.0,
      "eval_accuracy_macro_0.5": 0.9766168594360352,
      "eval_accuracy_micro_0.5": 0.9766169190406799,
      "eval_accuracy_weighted_0.5": 0.9623836278915405,
      "eval_aucroc_macro": 0.8319724202156067,
      "eval_aucroc_micro": 0.856098473072052,
      "eval_aucroc_weighted": 0.8504243493080139,
      "eval_f1_macro_0.5": 0.5191218852996826,
      "eval_f1_macro_0.6": 0.44914674758911133,
      "eval_f1_macro_0.7": 0.3660026788711548,
      "eval_f1_macro_0.8": 0.10012910515069962,
      "eval_f1_micro_0.5": 0.6071780920028687,
      "eval_f1_micro_0.6": 0.5511518120765686,
      "eval_f1_micro_0.7": 0.4730420708656311,
      "eval_f1_micro_0.8": 0.34461987018585205,
      "eval_f1_micro_0.9": 0.15587696433067322,
      "eval_f1_weighted_0.5": 0.5617457628250122,
      "eval_f1_weighted_0.6": 0.49087029695510864,
      "eval_f1_weighted_0.7": 0.41234663128852844,
      "eval_f1_weighted_0.8": 0.13582614064216614,
      "eval_loss": 0.05529993027448654,
      "eval_runtime": 3245.852,
      "eval_samples_per_second": 17.91,
      "eval_steps_per_second": 2.239,
      "step": 29083
    },
    {
      "epoch": 1.0005845339201596,
      "grad_norm": 0.22607988119125366,
      "learning_rate": 4.687514774842151e-05,
      "loss": 0.0596,
      "step": 29100
    },
    {
      "epoch": 1.0040229687446274,
      "grad_norm": 0.18772664666175842,
      "learning_rate": 4.686440240867536e-05,
      "loss": 0.0595,
      "step": 29200
    },
    {
      "epoch": 1.0074614035690954,
      "grad_norm": 0.13546910881996155,
      "learning_rate": 4.685365706892921e-05,
      "loss": 0.0574,
      "step": 29300
    },
    {
      "epoch": 1.0108998383935632,
      "grad_norm": 0.09138514846563339,
      "learning_rate": 4.684291172918305e-05,
      "loss": 0.059,
      "step": 29400
    },
    {
      "epoch": 1.014338273218031,
      "grad_norm": 0.3375832736492157,
      "learning_rate": 4.6832166389436905e-05,
      "loss": 0.0616,
      "step": 29500
    },
    {
      "epoch": 1.017776708042499,
      "grad_norm": 0.1813536286354065,
      "learning_rate": 4.682142104969075e-05,
      "loss": 0.0617,
      "step": 29600
    },
    {
      "epoch": 1.021215142866967,
      "grad_norm": 0.09384224563837051,
      "learning_rate": 4.68106757099446e-05,
      "loss": 0.0583,
      "step": 29700
    },
    {
      "epoch": 1.024653577691435,
      "grad_norm": 0.30529454350471497,
      "learning_rate": 4.679993037019845e-05,
      "loss": 0.0615,
      "step": 29800
    },
    {
      "epoch": 1.0280920125159028,
      "grad_norm": 0.15244530141353607,
      "learning_rate": 4.678918503045229e-05,
      "loss": 0.0576,
      "step": 29900
    },
    {
      "epoch": 1.0315304473403706,
      "grad_norm": 0.14858466386795044,
      "learning_rate": 4.6778439690706145e-05,
      "loss": 0.0589,
      "step": 30000
    },
    {
      "epoch": 1.0349688821648386,
      "grad_norm": 0.10743581503629684,
      "learning_rate": 4.676769435095999e-05,
      "loss": 0.0579,
      "step": 30100
    },
    {
      "epoch": 1.0384073169893064,
      "grad_norm": 0.16125862300395966,
      "learning_rate": 4.675694901121384e-05,
      "loss": 0.0578,
      "step": 30200
    },
    {
      "epoch": 1.0418457518137743,
      "grad_norm": 0.1769934445619583,
      "learning_rate": 4.674620367146769e-05,
      "loss": 0.0615,
      "step": 30300
    },
    {
      "epoch": 1.0452841866382423,
      "grad_norm": 0.16073445975780487,
      "learning_rate": 4.673545833172153e-05,
      "loss": 0.0593,
      "step": 30400
    },
    {
      "epoch": 1.0487226214627101,
      "grad_norm": 0.2574889063835144,
      "learning_rate": 4.6724712991975385e-05,
      "loss": 0.0592,
      "step": 30500
    },
    {
      "epoch": 1.0521610562871782,
      "grad_norm": 0.13823018968105316,
      "learning_rate": 4.671396765222923e-05,
      "loss": 0.0571,
      "step": 30600
    },
    {
      "epoch": 1.055599491111646,
      "grad_norm": 0.17609399557113647,
      "learning_rate": 4.670322231248308e-05,
      "loss": 0.0626,
      "step": 30700
    },
    {
      "epoch": 1.0590379259361138,
      "grad_norm": 0.229111447930336,
      "learning_rate": 4.669247697273693e-05,
      "loss": 0.0569,
      "step": 30800
    },
    {
      "epoch": 1.0624763607605818,
      "grad_norm": 0.277151495218277,
      "learning_rate": 4.668173163299077e-05,
      "loss": 0.0615,
      "step": 30900
    },
    {
      "epoch": 1.0659147955850496,
      "grad_norm": 0.1164795458316803,
      "learning_rate": 4.6670986293244625e-05,
      "loss": 0.0573,
      "step": 31000
    },
    {
      "epoch": 1.0693532304095177,
      "grad_norm": 0.31073760986328125,
      "learning_rate": 4.666024095349847e-05,
      "loss": 0.058,
      "step": 31100
    },
    {
      "epoch": 1.0727916652339855,
      "grad_norm": 0.1426888406276703,
      "learning_rate": 4.664949561375232e-05,
      "loss": 0.0587,
      "step": 31200
    },
    {
      "epoch": 1.0762301000584533,
      "grad_norm": 0.19154156744480133,
      "learning_rate": 4.663875027400617e-05,
      "loss": 0.0542,
      "step": 31300
    },
    {
      "epoch": 1.0796685348829214,
      "grad_norm": 0.2277858406305313,
      "learning_rate": 4.662800493426001e-05,
      "loss": 0.0584,
      "step": 31400
    },
    {
      "epoch": 1.0831069697073892,
      "grad_norm": 0.23240838944911957,
      "learning_rate": 4.6617259594513865e-05,
      "loss": 0.0582,
      "step": 31500
    },
    {
      "epoch": 1.086545404531857,
      "grad_norm": 0.07808056473731995,
      "learning_rate": 4.660651425476771e-05,
      "loss": 0.059,
      "step": 31600
    },
    {
      "epoch": 1.089983839356325,
      "grad_norm": 0.2428131401538849,
      "learning_rate": 4.659576891502156e-05,
      "loss": 0.057,
      "step": 31700
    },
    {
      "epoch": 1.0934222741807929,
      "grad_norm": 0.16472193598747253,
      "learning_rate": 4.658502357527541e-05,
      "loss": 0.0608,
      "step": 31800
    },
    {
      "epoch": 1.096860709005261,
      "grad_norm": 0.18763647973537445,
      "learning_rate": 4.657427823552925e-05,
      "loss": 0.0547,
      "step": 31900
    },
    {
      "epoch": 1.1002991438297287,
      "grad_norm": 0.14470703899860382,
      "learning_rate": 4.6563532895783105e-05,
      "loss": 0.0585,
      "step": 32000
    },
    {
      "epoch": 1.1037375786541965,
      "grad_norm": 0.11536841094493866,
      "learning_rate": 4.655289500943441e-05,
      "loss": 0.0613,
      "step": 32100
    },
    {
      "epoch": 1.1071760134786646,
      "grad_norm": 0.18425296247005463,
      "learning_rate": 4.654214966968825e-05,
      "loss": 0.0536,
      "step": 32200
    },
    {
      "epoch": 1.1106144483031324,
      "grad_norm": 0.3241647183895111,
      "learning_rate": 4.6531404329942105e-05,
      "loss": 0.0554,
      "step": 32300
    },
    {
      "epoch": 1.1140528831276004,
      "grad_norm": 0.2737562656402588,
      "learning_rate": 4.652065899019595e-05,
      "loss": 0.0569,
      "step": 32400
    },
    {
      "epoch": 1.1174913179520682,
      "grad_norm": 0.2145937979221344,
      "learning_rate": 4.65099136504498e-05,
      "loss": 0.0587,
      "step": 32500
    },
    {
      "epoch": 1.120929752776536,
      "grad_norm": 0.16928674280643463,
      "learning_rate": 4.649916831070365e-05,
      "loss": 0.0565,
      "step": 32600
    },
    {
      "epoch": 1.124368187601004,
      "grad_norm": 0.17462939023971558,
      "learning_rate": 4.648842297095749e-05,
      "loss": 0.0562,
      "step": 32700
    },
    {
      "epoch": 1.127806622425472,
      "grad_norm": 0.21488410234451294,
      "learning_rate": 4.6477677631211345e-05,
      "loss": 0.0525,
      "step": 32800
    },
    {
      "epoch": 1.1312450572499397,
      "grad_norm": 0.4212440848350525,
      "learning_rate": 4.646693229146519e-05,
      "loss": 0.059,
      "step": 32900
    },
    {
      "epoch": 1.1346834920744078,
      "grad_norm": 0.2535529136657715,
      "learning_rate": 4.645618695171904e-05,
      "loss": 0.0573,
      "step": 33000
    },
    {
      "epoch": 1.1381219268988756,
      "grad_norm": 0.21789418160915375,
      "learning_rate": 4.644544161197289e-05,
      "loss": 0.063,
      "step": 33100
    },
    {
      "epoch": 1.1415603617233436,
      "grad_norm": 0.28363239765167236,
      "learning_rate": 4.643469627222673e-05,
      "loss": 0.0563,
      "step": 33200
    },
    {
      "epoch": 1.1449987965478114,
      "grad_norm": 0.12136217206716537,
      "learning_rate": 4.6423950932480585e-05,
      "loss": 0.0617,
      "step": 33300
    },
    {
      "epoch": 1.1484372313722793,
      "grad_norm": 0.2605043053627014,
      "learning_rate": 4.641320559273443e-05,
      "loss": 0.0582,
      "step": 33400
    },
    {
      "epoch": 1.1518756661967473,
      "grad_norm": 0.19924041628837585,
      "learning_rate": 4.640246025298828e-05,
      "loss": 0.0532,
      "step": 33500
    },
    {
      "epoch": 1.1553141010212151,
      "grad_norm": 0.0862584114074707,
      "learning_rate": 4.639171491324213e-05,
      "loss": 0.0578,
      "step": 33600
    },
    {
      "epoch": 1.1587525358456832,
      "grad_norm": 0.13847632706165314,
      "learning_rate": 4.638096957349597e-05,
      "loss": 0.053,
      "step": 33700
    },
    {
      "epoch": 1.162190970670151,
      "grad_norm": 0.11203864216804504,
      "learning_rate": 4.6370224233749825e-05,
      "loss": 0.0584,
      "step": 33800
    },
    {
      "epoch": 1.1656294054946188,
      "grad_norm": 0.2986195385456085,
      "learning_rate": 4.635947889400367e-05,
      "loss": 0.0533,
      "step": 33900
    },
    {
      "epoch": 1.1690678403190868,
      "grad_norm": 0.1442376971244812,
      "learning_rate": 4.634873355425752e-05,
      "loss": 0.0553,
      "step": 34000
    },
    {
      "epoch": 1.1725062751435547,
      "grad_norm": 0.257183313369751,
      "learning_rate": 4.633798821451137e-05,
      "loss": 0.0558,
      "step": 34100
    },
    {
      "epoch": 1.1759447099680225,
      "grad_norm": 0.15556827187538147,
      "learning_rate": 4.632724287476521e-05,
      "loss": 0.0559,
      "step": 34200
    },
    {
      "epoch": 1.1793831447924905,
      "grad_norm": 0.16163718700408936,
      "learning_rate": 4.6316497535019065e-05,
      "loss": 0.0557,
      "step": 34300
    },
    {
      "epoch": 1.1828215796169583,
      "grad_norm": 0.13958421349525452,
      "learning_rate": 4.630575219527291e-05,
      "loss": 0.0576,
      "step": 34400
    },
    {
      "epoch": 1.1862600144414261,
      "grad_norm": 0.38104599714279175,
      "learning_rate": 4.629500685552676e-05,
      "loss": 0.059,
      "step": 34500
    },
    {
      "epoch": 1.1896984492658942,
      "grad_norm": 0.44431811571121216,
      "learning_rate": 4.628426151578061e-05,
      "loss": 0.0542,
      "step": 34600
    },
    {
      "epoch": 1.193136884090362,
      "grad_norm": 0.2515470087528229,
      "learning_rate": 4.627351617603445e-05,
      "loss": 0.0582,
      "step": 34700
    },
    {
      "epoch": 1.19657531891483,
      "grad_norm": 0.14731287956237793,
      "learning_rate": 4.6262770836288305e-05,
      "loss": 0.0545,
      "step": 34800
    },
    {
      "epoch": 1.2000137537392979,
      "grad_norm": 0.18882232904434204,
      "learning_rate": 4.6252132949939615e-05,
      "loss": 0.0538,
      "step": 34900
    },
    {
      "epoch": 1.2034521885637657,
      "grad_norm": 0.2998765707015991,
      "learning_rate": 4.624138761019346e-05,
      "loss": 0.0572,
      "step": 35000
    },
    {
      "epoch": 1.2068906233882337,
      "grad_norm": 0.1138722151517868,
      "learning_rate": 4.623064227044731e-05,
      "loss": 0.0545,
      "step": 35100
    },
    {
      "epoch": 1.2103290582127015,
      "grad_norm": 0.12653613090515137,
      "learning_rate": 4.621989693070116e-05,
      "loss": 0.0596,
      "step": 35200
    },
    {
      "epoch": 1.2137674930371696,
      "grad_norm": 0.18737776577472687,
      "learning_rate": 4.620915159095501e-05,
      "loss": 0.0565,
      "step": 35300
    },
    {
      "epoch": 1.2172059278616374,
      "grad_norm": 0.2875010371208191,
      "learning_rate": 4.6198406251208855e-05,
      "loss": 0.0597,
      "step": 35400
    },
    {
      "epoch": 1.2206443626861052,
      "grad_norm": 0.25182676315307617,
      "learning_rate": 4.61876609114627e-05,
      "loss": 0.0564,
      "step": 35500
    },
    {
      "epoch": 1.2240827975105733,
      "grad_norm": 0.3847463130950928,
      "learning_rate": 4.617691557171655e-05,
      "loss": 0.0551,
      "step": 35600
    },
    {
      "epoch": 1.227521232335041,
      "grad_norm": 0.2504464387893677,
      "learning_rate": 4.61661702319704e-05,
      "loss": 0.0587,
      "step": 35700
    },
    {
      "epoch": 1.2309596671595089,
      "grad_norm": 0.09678267687559128,
      "learning_rate": 4.615542489222425e-05,
      "loss": 0.0554,
      "step": 35800
    },
    {
      "epoch": 1.234398101983977,
      "grad_norm": 0.16834598779678345,
      "learning_rate": 4.6144679552478095e-05,
      "loss": 0.0546,
      "step": 35900
    },
    {
      "epoch": 1.2378365368084447,
      "grad_norm": 0.17764179408550262,
      "learning_rate": 4.613393421273194e-05,
      "loss": 0.0581,
      "step": 36000
    },
    {
      "epoch": 1.2412749716329128,
      "grad_norm": 0.20469212532043457,
      "learning_rate": 4.612318887298579e-05,
      "loss": 0.0553,
      "step": 36100
    },
    {
      "epoch": 1.2447134064573806,
      "grad_norm": 0.1675846129655838,
      "learning_rate": 4.611244353323964e-05,
      "loss": 0.0559,
      "step": 36200
    },
    {
      "epoch": 1.2481518412818484,
      "grad_norm": 0.10594408214092255,
      "learning_rate": 4.610169819349349e-05,
      "loss": 0.057,
      "step": 36300
    },
    {
      "epoch": 1.2515902761063165,
      "grad_norm": 0.07030506432056427,
      "learning_rate": 4.6090952853747335e-05,
      "loss": 0.0555,
      "step": 36400
    },
    {
      "epoch": 1.2550287109307843,
      "grad_norm": 0.11532942950725555,
      "learning_rate": 4.608020751400118e-05,
      "loss": 0.0536,
      "step": 36500
    },
    {
      "epoch": 1.2584671457552523,
      "grad_norm": 0.42065978050231934,
      "learning_rate": 4.606946217425503e-05,
      "loss": 0.0523,
      "step": 36600
    },
    {
      "epoch": 1.2619055805797201,
      "grad_norm": 0.23085474967956543,
      "learning_rate": 4.605871683450888e-05,
      "loss": 0.057,
      "step": 36700
    },
    {
      "epoch": 1.265344015404188,
      "grad_norm": 0.3324525058269501,
      "learning_rate": 4.604797149476272e-05,
      "loss": 0.0584,
      "step": 36800
    },
    {
      "epoch": 1.268782450228656,
      "grad_norm": 0.09106617420911789,
      "learning_rate": 4.6037226155016575e-05,
      "loss": 0.0511,
      "step": 36900
    },
    {
      "epoch": 1.2722208850531238,
      "grad_norm": 0.1342764049768448,
      "learning_rate": 4.602648081527042e-05,
      "loss": 0.0568,
      "step": 37000
    },
    {
      "epoch": 1.2756593198775916,
      "grad_norm": 0.1839590221643448,
      "learning_rate": 4.601584292892172e-05,
      "loss": 0.0546,
      "step": 37100
    },
    {
      "epoch": 1.2790977547020597,
      "grad_norm": 0.1938760131597519,
      "learning_rate": 4.600520504257304e-05,
      "loss": 0.053,
      "step": 37200
    },
    {
      "epoch": 1.2825361895265275,
      "grad_norm": 0.12598451972007751,
      "learning_rate": 4.5994459702826885e-05,
      "loss": 0.0542,
      "step": 37300
    },
    {
      "epoch": 1.2859746243509953,
      "grad_norm": 0.34441623091697693,
      "learning_rate": 4.598371436308073e-05,
      "loss": 0.054,
      "step": 37400
    },
    {
      "epoch": 1.2894130591754633,
      "grad_norm": 0.2900671660900116,
      "learning_rate": 4.597296902333458e-05,
      "loss": 0.0515,
      "step": 37500
    },
    {
      "epoch": 1.2928514939999312,
      "grad_norm": 0.4469219446182251,
      "learning_rate": 4.596222368358843e-05,
      "loss": 0.0578,
      "step": 37600
    },
    {
      "epoch": 1.2962899288243992,
      "grad_norm": 0.1639603078365326,
      "learning_rate": 4.595147834384228e-05,
      "loss": 0.0549,
      "step": 37700
    },
    {
      "epoch": 1.299728363648867,
      "grad_norm": 0.14724482595920563,
      "learning_rate": 4.5940733004096125e-05,
      "loss": 0.0558,
      "step": 37800
    },
    {
      "epoch": 1.303166798473335,
      "grad_norm": 0.32480621337890625,
      "learning_rate": 4.592998766434997e-05,
      "loss": 0.0567,
      "step": 37900
    },
    {
      "epoch": 1.3066052332978029,
      "grad_norm": 0.20632410049438477,
      "learning_rate": 4.591924232460382e-05,
      "loss": 0.0548,
      "step": 38000
    },
    {
      "epoch": 1.3100436681222707,
      "grad_norm": 0.2185560166835785,
      "learning_rate": 4.590849698485767e-05,
      "loss": 0.0591,
      "step": 38100
    },
    {
      "epoch": 1.3134821029467387,
      "grad_norm": 0.28997185826301575,
      "learning_rate": 4.589775164511152e-05,
      "loss": 0.0555,
      "step": 38200
    },
    {
      "epoch": 1.3169205377712065,
      "grad_norm": 0.21470661461353302,
      "learning_rate": 4.5887006305365365e-05,
      "loss": 0.0553,
      "step": 38300
    },
    {
      "epoch": 1.3203589725956744,
      "grad_norm": 0.12970615923404694,
      "learning_rate": 4.587626096561921e-05,
      "loss": 0.0544,
      "step": 38400
    },
    {
      "epoch": 1.3237974074201424,
      "grad_norm": 0.16148771345615387,
      "learning_rate": 4.586551562587306e-05,
      "loss": 0.053,
      "step": 38500
    },
    {
      "epoch": 1.3272358422446102,
      "grad_norm": 0.17396925389766693,
      "learning_rate": 4.585477028612691e-05,
      "loss": 0.053,
      "step": 38600
    },
    {
      "epoch": 1.330674277069078,
      "grad_norm": 0.15690171718597412,
      "learning_rate": 4.584402494638076e-05,
      "loss": 0.0518,
      "step": 38700
    },
    {
      "epoch": 1.334112711893546,
      "grad_norm": 0.21254682540893555,
      "learning_rate": 4.583338706003207e-05,
      "loss": 0.0504,
      "step": 38800
    },
    {
      "epoch": 1.337551146718014,
      "grad_norm": 0.11484777182340622,
      "learning_rate": 4.5822641720285915e-05,
      "loss": 0.0547,
      "step": 38900
    },
    {
      "epoch": 1.340989581542482,
      "grad_norm": 0.5283973217010498,
      "learning_rate": 4.581189638053976e-05,
      "loss": 0.0536,
      "step": 39000
    },
    {
      "epoch": 1.3444280163669498,
      "grad_norm": 0.45880326628685,
      "learning_rate": 4.580115104079361e-05,
      "loss": 0.0539,
      "step": 39100
    },
    {
      "epoch": 1.3478664511914178,
      "grad_norm": 0.551971435546875,
      "learning_rate": 4.579040570104746e-05,
      "loss": 0.0525,
      "step": 39200
    },
    {
      "epoch": 1.3513048860158856,
      "grad_norm": 0.0762157142162323,
      "learning_rate": 4.577966036130131e-05,
      "loss": 0.0544,
      "step": 39300
    },
    {
      "epoch": 1.3547433208403534,
      "grad_norm": 0.1138208881020546,
      "learning_rate": 4.5768915021555155e-05,
      "loss": 0.0559,
      "step": 39400
    },
    {
      "epoch": 1.3581817556648215,
      "grad_norm": 0.19803903996944427,
      "learning_rate": 4.5758169681809e-05,
      "loss": 0.0547,
      "step": 39500
    },
    {
      "epoch": 1.3616201904892893,
      "grad_norm": 0.1688784509897232,
      "learning_rate": 4.574742434206285e-05,
      "loss": 0.0518,
      "step": 39600
    },
    {
      "epoch": 1.365058625313757,
      "grad_norm": 0.25816845893859863,
      "learning_rate": 4.57366790023167e-05,
      "loss": 0.0563,
      "step": 39700
    },
    {
      "epoch": 1.3684970601382251,
      "grad_norm": 0.19008250534534454,
      "learning_rate": 4.572593366257055e-05,
      "loss": 0.06,
      "step": 39800
    },
    {
      "epoch": 1.371935494962693,
      "grad_norm": 0.13826942443847656,
      "learning_rate": 4.5715188322824395e-05,
      "loss": 0.0551,
      "step": 39900
    },
    {
      "epoch": 1.3753739297871608,
      "grad_norm": 0.24240435659885406,
      "learning_rate": 4.570444298307825e-05,
      "loss": 0.0543,
      "step": 40000
    },
    {
      "epoch": 1.3788123646116288,
      "grad_norm": 0.09359491616487503,
      "learning_rate": 4.569369764333209e-05,
      "loss": 0.0547,
      "step": 40100
    },
    {
      "epoch": 1.3822507994360966,
      "grad_norm": 0.1914350390434265,
      "learning_rate": 4.568295230358594e-05,
      "loss": 0.0553,
      "step": 40200
    },
    {
      "epoch": 1.3856892342605647,
      "grad_norm": 0.1084386482834816,
      "learning_rate": 4.567220696383979e-05,
      "loss": 0.055,
      "step": 40300
    },
    {
      "epoch": 1.3891276690850325,
      "grad_norm": 0.09390226006507874,
      "learning_rate": 4.5661461624093635e-05,
      "loss": 0.0562,
      "step": 40400
    },
    {
      "epoch": 1.3925661039095005,
      "grad_norm": 0.08428965508937836,
      "learning_rate": 4.565071628434748e-05,
      "loss": 0.0591,
      "step": 40500
    },
    {
      "epoch": 1.3960045387339683,
      "grad_norm": 0.14882203936576843,
      "learning_rate": 4.563997094460133e-05,
      "loss": 0.0538,
      "step": 40600
    },
    {
      "epoch": 1.3994429735584362,
      "grad_norm": 0.12760011851787567,
      "learning_rate": 4.562922560485518e-05,
      "loss": 0.0475,
      "step": 40700
    },
    {
      "epoch": 1.4028814083829042,
      "grad_norm": 0.13508161902427673,
      "learning_rate": 4.561848026510902e-05,
      "loss": 0.0554,
      "step": 40800
    },
    {
      "epoch": 1.406319843207372,
      "grad_norm": 0.08745329082012177,
      "learning_rate": 4.5607734925362875e-05,
      "loss": 0.0505,
      "step": 40900
    },
    {
      "epoch": 1.4097582780318398,
      "grad_norm": 0.31890419125556946,
      "learning_rate": 4.559698958561672e-05,
      "loss": 0.0553,
      "step": 41000
    },
    {
      "epoch": 1.4131967128563079,
      "grad_norm": 0.2146415114402771,
      "learning_rate": 4.5586244245870565e-05,
      "loss": 0.0556,
      "step": 41100
    },
    {
      "epoch": 1.4166351476807757,
      "grad_norm": 0.2835005819797516,
      "learning_rate": 4.557549890612442e-05,
      "loss": 0.0535,
      "step": 41200
    },
    {
      "epoch": 1.4200735825052435,
      "grad_norm": 0.11285675317049026,
      "learning_rate": 4.556475356637826e-05,
      "loss": 0.0575,
      "step": 41300
    },
    {
      "epoch": 1.4235120173297116,
      "grad_norm": 0.15316060185432434,
      "learning_rate": 4.555400822663211e-05,
      "loss": 0.0578,
      "step": 41400
    },
    {
      "epoch": 1.4269504521541794,
      "grad_norm": 0.11437429487705231,
      "learning_rate": 4.554326288688596e-05,
      "loss": 0.0518,
      "step": 41500
    },
    {
      "epoch": 1.4303888869786472,
      "grad_norm": 0.08531537652015686,
      "learning_rate": 4.5532517547139805e-05,
      "loss": 0.0533,
      "step": 41600
    },
    {
      "epoch": 1.4338273218031152,
      "grad_norm": 0.19409410655498505,
      "learning_rate": 4.552177220739365e-05,
      "loss": 0.0521,
      "step": 41700
    },
    {
      "epoch": 1.437265756627583,
      "grad_norm": 0.12232618778944016,
      "learning_rate": 4.55110268676475e-05,
      "loss": 0.0525,
      "step": 41800
    },
    {
      "epoch": 1.440704191452051,
      "grad_norm": 0.17836716771125793,
      "learning_rate": 4.550028152790135e-05,
      "loss": 0.0533,
      "step": 41900
    },
    {
      "epoch": 1.444142626276519,
      "grad_norm": 0.5337342619895935,
      "learning_rate": 4.54895361881552e-05,
      "loss": 0.0535,
      "step": 42000
    },
    {
      "epoch": 1.447581061100987,
      "grad_norm": 0.1421932727098465,
      "learning_rate": 4.5478790848409045e-05,
      "loss": 0.0533,
      "step": 42100
    },
    {
      "epoch": 1.4510194959254548,
      "grad_norm": 0.1426364630460739,
      "learning_rate": 4.546804550866289e-05,
      "loss": 0.0495,
      "step": 42200
    },
    {
      "epoch": 1.4544579307499226,
      "grad_norm": 0.1722976118326187,
      "learning_rate": 4.545730016891674e-05,
      "loss": 0.0515,
      "step": 42300
    },
    {
      "epoch": 1.4578963655743906,
      "grad_norm": 0.12281984835863113,
      "learning_rate": 4.544655482917059e-05,
      "loss": 0.0533,
      "step": 42400
    },
    {
      "epoch": 1.4613348003988584,
      "grad_norm": 0.09596214443445206,
      "learning_rate": 4.543580948942444e-05,
      "loss": 0.0546,
      "step": 42500
    },
    {
      "epoch": 1.4647732352233263,
      "grad_norm": 0.17179003357887268,
      "learning_rate": 4.5425064149678285e-05,
      "loss": 0.0525,
      "step": 42600
    },
    {
      "epoch": 1.4682116700477943,
      "grad_norm": 0.1288982778787613,
      "learning_rate": 4.541431880993213e-05,
      "loss": 0.0543,
      "step": 42700
    },
    {
      "epoch": 1.471650104872262,
      "grad_norm": 0.1899571716785431,
      "learning_rate": 4.540357347018598e-05,
      "loss": 0.0509,
      "step": 42800
    },
    {
      "epoch": 1.47508853969673,
      "grad_norm": 0.08382153511047363,
      "learning_rate": 4.539282813043983e-05,
      "loss": 0.0526,
      "step": 42900
    },
    {
      "epoch": 1.478526974521198,
      "grad_norm": 0.05137893930077553,
      "learning_rate": 4.538208279069368e-05,
      "loss": 0.0524,
      "step": 43000
    },
    {
      "epoch": 1.4819654093456658,
      "grad_norm": 0.1783352792263031,
      "learning_rate": 4.5371337450947525e-05,
      "loss": 0.0581,
      "step": 43100
    },
    {
      "epoch": 1.4854038441701338,
      "grad_norm": 0.08917257934808731,
      "learning_rate": 4.536059211120137e-05,
      "loss": 0.0521,
      "step": 43200
    },
    {
      "epoch": 1.4888422789946016,
      "grad_norm": 0.08957384526729584,
      "learning_rate": 4.534984677145522e-05,
      "loss": 0.0512,
      "step": 43300
    },
    {
      "epoch": 1.4922807138190697,
      "grad_norm": 0.1759868562221527,
      "learning_rate": 4.533910143170907e-05,
      "loss": 0.0498,
      "step": 43400
    },
    {
      "epoch": 1.4957191486435375,
      "grad_norm": 0.14423952996730804,
      "learning_rate": 4.532835609196292e-05,
      "loss": 0.0497,
      "step": 43500
    },
    {
      "epoch": 1.4991575834680053,
      "grad_norm": 0.07661028951406479,
      "learning_rate": 4.5317610752216766e-05,
      "loss": 0.0505,
      "step": 43600
    },
    {
      "epoch": 1.5025960182924734,
      "grad_norm": 0.10468999296426773,
      "learning_rate": 4.5306972865868075e-05,
      "loss": 0.0579,
      "step": 43700
    },
    {
      "epoch": 1.5060344531169412,
      "grad_norm": 0.10256296396255493,
      "learning_rate": 4.529622752612192e-05,
      "loss": 0.0547,
      "step": 43800
    },
    {
      "epoch": 1.509472887941409,
      "grad_norm": 0.2035222053527832,
      "learning_rate": 4.528548218637577e-05,
      "loss": 0.0509,
      "step": 43900
    },
    {
      "epoch": 1.512911322765877,
      "grad_norm": 0.10512731224298477,
      "learning_rate": 4.527473684662962e-05,
      "loss": 0.0475,
      "step": 44000
    },
    {
      "epoch": 1.5163497575903448,
      "grad_norm": 0.35400205850601196,
      "learning_rate": 4.526409896028093e-05,
      "loss": 0.0529,
      "step": 44100
    },
    {
      "epoch": 1.5197881924148127,
      "grad_norm": 0.1828010231256485,
      "learning_rate": 4.525335362053478e-05,
      "loss": 0.0511,
      "step": 44200
    },
    {
      "epoch": 1.5232266272392807,
      "grad_norm": 0.16694441437721252,
      "learning_rate": 4.5242608280788625e-05,
      "loss": 0.0501,
      "step": 44300
    },
    {
      "epoch": 1.5266650620637487,
      "grad_norm": 0.28153833746910095,
      "learning_rate": 4.523186294104248e-05,
      "loss": 0.0511,
      "step": 44400
    },
    {
      "epoch": 1.5301034968882163,
      "grad_norm": 0.08652609586715698,
      "learning_rate": 4.522111760129632e-05,
      "loss": 0.0518,
      "step": 44500
    },
    {
      "epoch": 1.5335419317126844,
      "grad_norm": 0.1494307965040207,
      "learning_rate": 4.521037226155017e-05,
      "loss": 0.0533,
      "step": 44600
    },
    {
      "epoch": 1.5369803665371524,
      "grad_norm": 0.26682597398757935,
      "learning_rate": 4.519962692180402e-05,
      "loss": 0.0532,
      "step": 44700
    },
    {
      "epoch": 1.5404188013616202,
      "grad_norm": 0.22967462241649628,
      "learning_rate": 4.5188881582057865e-05,
      "loss": 0.0525,
      "step": 44800
    },
    {
      "epoch": 1.543857236186088,
      "grad_norm": 0.256336510181427,
      "learning_rate": 4.517813624231172e-05,
      "loss": 0.0535,
      "step": 44900
    },
    {
      "epoch": 1.547295671010556,
      "grad_norm": 0.07457835227251053,
      "learning_rate": 4.516739090256556e-05,
      "loss": 0.0516,
      "step": 45000
    },
    {
      "epoch": 1.550734105835024,
      "grad_norm": 0.2619694173336029,
      "learning_rate": 4.515664556281941e-05,
      "loss": 0.051,
      "step": 45100
    },
    {
      "epoch": 1.5541725406594917,
      "grad_norm": 0.23036237061023712,
      "learning_rate": 4.514590022307326e-05,
      "loss": 0.0527,
      "step": 45200
    },
    {
      "epoch": 1.5576109754839598,
      "grad_norm": 0.1481781154870987,
      "learning_rate": 4.5135154883327105e-05,
      "loss": 0.0492,
      "step": 45300
    },
    {
      "epoch": 1.5610494103084276,
      "grad_norm": 0.19496922194957733,
      "learning_rate": 4.512440954358095e-05,
      "loss": 0.0543,
      "step": 45400
    },
    {
      "epoch": 1.5644878451328954,
      "grad_norm": 0.2858981490135193,
      "learning_rate": 4.51136642038348e-05,
      "loss": 0.0509,
      "step": 45500
    },
    {
      "epoch": 1.5679262799573634,
      "grad_norm": 0.19216611981391907,
      "learning_rate": 4.510291886408865e-05,
      "loss": 0.0499,
      "step": 45600
    },
    {
      "epoch": 1.5713647147818313,
      "grad_norm": 0.19589312374591827,
      "learning_rate": 4.509217352434249e-05,
      "loss": 0.0515,
      "step": 45700
    },
    {
      "epoch": 1.574803149606299,
      "grad_norm": 0.12707370519638062,
      "learning_rate": 4.5081428184596345e-05,
      "loss": 0.0508,
      "step": 45800
    },
    {
      "epoch": 1.5782415844307671,
      "grad_norm": 0.15732865035533905,
      "learning_rate": 4.507068284485019e-05,
      "loss": 0.0507,
      "step": 45900
    },
    {
      "epoch": 1.5816800192552352,
      "grad_norm": 0.2526780366897583,
      "learning_rate": 4.5059937505104035e-05,
      "loss": 0.052,
      "step": 46000
    },
    {
      "epoch": 1.5851184540797028,
      "grad_norm": 0.1359701156616211,
      "learning_rate": 4.504919216535788e-05,
      "loss": 0.0491,
      "step": 46100
    },
    {
      "epoch": 1.5885568889041708,
      "grad_norm": 0.26853808760643005,
      "learning_rate": 4.503844682561173e-05,
      "loss": 0.052,
      "step": 46200
    },
    {
      "epoch": 1.5919953237286388,
      "grad_norm": 0.19781732559204102,
      "learning_rate": 4.502770148586558e-05,
      "loss": 0.0517,
      "step": 46300
    },
    {
      "epoch": 1.5954337585531067,
      "grad_norm": 0.0906292274594307,
      "learning_rate": 4.501695614611943e-05,
      "loss": 0.0512,
      "step": 46400
    },
    {
      "epoch": 1.5988721933775745,
      "grad_norm": 0.23867760598659515,
      "learning_rate": 4.5006210806373275e-05,
      "loss": 0.0528,
      "step": 46500
    },
    {
      "epoch": 1.6023106282020425,
      "grad_norm": 0.1283588856458664,
      "learning_rate": 4.499546546662712e-05,
      "loss": 0.0484,
      "step": 46600
    },
    {
      "epoch": 1.6057490630265103,
      "grad_norm": 0.31814655661582947,
      "learning_rate": 4.498472012688097e-05,
      "loss": 0.0525,
      "step": 46700
    },
    {
      "epoch": 1.6091874978509781,
      "grad_norm": 0.15237227082252502,
      "learning_rate": 4.497397478713482e-05,
      "loss": 0.0511,
      "step": 46800
    },
    {
      "epoch": 1.6126259326754462,
      "grad_norm": 0.1388968974351883,
      "learning_rate": 4.496322944738867e-05,
      "loss": 0.0513,
      "step": 46900
    },
    {
      "epoch": 1.616064367499914,
      "grad_norm": 0.12764795124530792,
      "learning_rate": 4.4952484107642516e-05,
      "loss": 0.0541,
      "step": 47000
    },
    {
      "epoch": 1.6195028023243818,
      "grad_norm": 0.33228573203086853,
      "learning_rate": 4.494173876789636e-05,
      "loss": 0.0504,
      "step": 47100
    },
    {
      "epoch": 1.6229412371488499,
      "grad_norm": 0.3884831368923187,
      "learning_rate": 4.493099342815021e-05,
      "loss": 0.0504,
      "step": 47200
    },
    {
      "epoch": 1.626379671973318,
      "grad_norm": 0.2750505805015564,
      "learning_rate": 4.492024808840406e-05,
      "loss": 0.0503,
      "step": 47300
    },
    {
      "epoch": 1.6298181067977855,
      "grad_norm": 0.0783415138721466,
      "learning_rate": 4.490950274865791e-05,
      "loss": 0.0537,
      "step": 47400
    },
    {
      "epoch": 1.6332565416222535,
      "grad_norm": 0.16110490262508392,
      "learning_rate": 4.4898757408911756e-05,
      "loss": 0.0541,
      "step": 47500
    },
    {
      "epoch": 1.6366949764467216,
      "grad_norm": 0.07647166401147842,
      "learning_rate": 4.48880120691656e-05,
      "loss": 0.0509,
      "step": 47600
    },
    {
      "epoch": 1.6401334112711894,
      "grad_norm": 0.14527611434459686,
      "learning_rate": 4.487726672941945e-05,
      "loss": 0.0504,
      "step": 47700
    },
    {
      "epoch": 1.6435718460956572,
      "grad_norm": 0.11155863851308823,
      "learning_rate": 4.48665213896733e-05,
      "loss": 0.0483,
      "step": 47800
    },
    {
      "epoch": 1.6470102809201252,
      "grad_norm": 0.31445664167404175,
      "learning_rate": 4.485577604992715e-05,
      "loss": 0.0481,
      "step": 47900
    },
    {
      "epoch": 1.650448715744593,
      "grad_norm": 0.21358536183834076,
      "learning_rate": 4.4845030710180996e-05,
      "loss": 0.0525,
      "step": 48000
    },
    {
      "epoch": 1.6538871505690609,
      "grad_norm": 0.301132470369339,
      "learning_rate": 4.483428537043484e-05,
      "loss": 0.0533,
      "step": 48100
    },
    {
      "epoch": 1.657325585393529,
      "grad_norm": 0.20816673338413239,
      "learning_rate": 4.482354003068869e-05,
      "loss": 0.049,
      "step": 48200
    },
    {
      "epoch": 1.6607640202179967,
      "grad_norm": 0.33717238903045654,
      "learning_rate": 4.481279469094254e-05,
      "loss": 0.0586,
      "step": 48300
    },
    {
      "epoch": 1.6642024550424646,
      "grad_norm": 0.13052304089069366,
      "learning_rate": 4.480204935119639e-05,
      "loss": 0.0507,
      "step": 48400
    },
    {
      "epoch": 1.6676408898669326,
      "grad_norm": 0.1949557512998581,
      "learning_rate": 4.47914114648477e-05,
      "loss": 0.0499,
      "step": 48500
    },
    {
      "epoch": 1.6710793246914006,
      "grad_norm": 0.1382618099451065,
      "learning_rate": 4.4780666125101545e-05,
      "loss": 0.0504,
      "step": 48600
    },
    {
      "epoch": 1.6745177595158682,
      "grad_norm": 0.21417580544948578,
      "learning_rate": 4.47699207853554e-05,
      "loss": 0.0455,
      "step": 48700
    },
    {
      "epoch": 1.6779561943403363,
      "grad_norm": 0.12298980355262756,
      "learning_rate": 4.475917544560924e-05,
      "loss": 0.0476,
      "step": 48800
    },
    {
      "epoch": 1.6813946291648043,
      "grad_norm": 0.11708198487758636,
      "learning_rate": 4.474843010586309e-05,
      "loss": 0.0506,
      "step": 48900
    },
    {
      "epoch": 1.6848330639892721,
      "grad_norm": 0.16896340250968933,
      "learning_rate": 4.473768476611694e-05,
      "loss": 0.054,
      "step": 49000
    },
    {
      "epoch": 1.68827149881374,
      "grad_norm": 0.4992751181125641,
      "learning_rate": 4.4726939426370785e-05,
      "loss": 0.0502,
      "step": 49100
    },
    {
      "epoch": 1.691709933638208,
      "grad_norm": 0.13935910165309906,
      "learning_rate": 4.471619408662464e-05,
      "loss": 0.0507,
      "step": 49200
    },
    {
      "epoch": 1.6951483684626758,
      "grad_norm": 0.15893776714801788,
      "learning_rate": 4.470555620027595e-05,
      "loss": 0.048,
      "step": 49300
    },
    {
      "epoch": 1.6985868032871436,
      "grad_norm": 0.18688319623470306,
      "learning_rate": 4.469481086052979e-05,
      "loss": 0.05,
      "step": 49400
    },
    {
      "epoch": 1.7020252381116117,
      "grad_norm": 0.12960882484912872,
      "learning_rate": 4.468406552078364e-05,
      "loss": 0.0559,
      "step": 49500
    },
    {
      "epoch": 1.7054636729360795,
      "grad_norm": 0.14542219042778015,
      "learning_rate": 4.467332018103749e-05,
      "loss": 0.0497,
      "step": 49600
    },
    {
      "epoch": 1.7089021077605473,
      "grad_norm": 0.14139176905155182,
      "learning_rate": 4.4662574841291335e-05,
      "loss": 0.0547,
      "step": 49700
    },
    {
      "epoch": 1.7123405425850153,
      "grad_norm": 0.15684820711612701,
      "learning_rate": 4.465182950154519e-05,
      "loss": 0.0466,
      "step": 49800
    },
    {
      "epoch": 1.7157789774094832,
      "grad_norm": 0.08847667276859283,
      "learning_rate": 4.464108416179903e-05,
      "loss": 0.0495,
      "step": 49900
    },
    {
      "epoch": 1.719217412233951,
      "grad_norm": 0.509400486946106,
      "learning_rate": 4.463033882205288e-05,
      "loss": 0.0509,
      "step": 50000
    },
    {
      "epoch": 1.722655847058419,
      "grad_norm": 0.15684324502944946,
      "learning_rate": 4.461959348230673e-05,
      "loss": 0.0507,
      "step": 50100
    },
    {
      "epoch": 1.726094281882887,
      "grad_norm": 0.09277015179395676,
      "learning_rate": 4.4608848142560575e-05,
      "loss": 0.0518,
      "step": 50200
    },
    {
      "epoch": 1.7295327167073549,
      "grad_norm": 0.05287408083677292,
      "learning_rate": 4.459810280281442e-05,
      "loss": 0.0551,
      "step": 50300
    },
    {
      "epoch": 1.7329711515318227,
      "grad_norm": 0.24304819107055664,
      "learning_rate": 4.4587357463068266e-05,
      "loss": 0.0507,
      "step": 50400
    },
    {
      "epoch": 1.7364095863562907,
      "grad_norm": 0.22860457003116608,
      "learning_rate": 4.457661212332212e-05,
      "loss": 0.048,
      "step": 50500
    },
    {
      "epoch": 1.7398480211807585,
      "grad_norm": 0.5774891972541809,
      "learning_rate": 4.456586678357596e-05,
      "loss": 0.0544,
      "step": 50600
    },
    {
      "epoch": 1.7432864560052264,
      "grad_norm": 0.139569491147995,
      "learning_rate": 4.455522889722727e-05,
      "loss": 0.0507,
      "step": 50700
    },
    {
      "epoch": 1.7467248908296944,
      "grad_norm": 0.19979597628116608,
      "learning_rate": 4.454448355748112e-05,
      "loss": 0.0468,
      "step": 50800
    },
    {
      "epoch": 1.7501633256541622,
      "grad_norm": 0.31315797567367554,
      "learning_rate": 4.453373821773497e-05,
      "loss": 0.0563,
      "step": 50900
    },
    {
      "epoch": 1.75360176047863,
      "grad_norm": 0.16586191952228546,
      "learning_rate": 4.4522992877988815e-05,
      "loss": 0.0511,
      "step": 51000
    },
    {
      "epoch": 1.757040195303098,
      "grad_norm": 0.16754747927188873,
      "learning_rate": 4.451224753824267e-05,
      "loss": 0.0507,
      "step": 51100
    },
    {
      "epoch": 1.760478630127566,
      "grad_norm": 0.13454490900039673,
      "learning_rate": 4.450150219849651e-05,
      "loss": 0.0518,
      "step": 51200
    },
    {
      "epoch": 1.7639170649520337,
      "grad_norm": 0.06620018184185028,
      "learning_rate": 4.449075685875036e-05,
      "loss": 0.0497,
      "step": 51300
    },
    {
      "epoch": 1.7673554997765017,
      "grad_norm": 0.25289642810821533,
      "learning_rate": 4.448001151900421e-05,
      "loss": 0.05,
      "step": 51400
    },
    {
      "epoch": 1.7707939346009698,
      "grad_norm": 0.2368691861629486,
      "learning_rate": 4.4469266179258055e-05,
      "loss": 0.0537,
      "step": 51500
    },
    {
      "epoch": 1.7742323694254374,
      "grad_norm": 0.2478773295879364,
      "learning_rate": 4.445852083951191e-05,
      "loss": 0.0494,
      "step": 51600
    },
    {
      "epoch": 1.7776708042499054,
      "grad_norm": 0.1503683477640152,
      "learning_rate": 4.444777549976575e-05,
      "loss": 0.0493,
      "step": 51700
    },
    {
      "epoch": 1.7811092390743735,
      "grad_norm": 0.3245108723640442,
      "learning_rate": 4.44370301600196e-05,
      "loss": 0.0492,
      "step": 51800
    },
    {
      "epoch": 1.7845476738988413,
      "grad_norm": 0.21303991973400116,
      "learning_rate": 4.442628482027345e-05,
      "loss": 0.0538,
      "step": 51900
    },
    {
      "epoch": 1.787986108723309,
      "grad_norm": 0.20800597965717316,
      "learning_rate": 4.4415539480527295e-05,
      "loss": 0.0519,
      "step": 52000
    },
    {
      "epoch": 1.7914245435477771,
      "grad_norm": 0.2222350537776947,
      "learning_rate": 4.440479414078115e-05,
      "loss": 0.0501,
      "step": 52100
    },
    {
      "epoch": 1.794862978372245,
      "grad_norm": 0.1247779056429863,
      "learning_rate": 4.439404880103499e-05,
      "loss": 0.0479,
      "step": 52200
    },
    {
      "epoch": 1.7983014131967128,
      "grad_norm": 0.19951710104942322,
      "learning_rate": 4.438330346128884e-05,
      "loss": 0.0517,
      "step": 52300
    },
    {
      "epoch": 1.8017398480211808,
      "grad_norm": 0.2512938976287842,
      "learning_rate": 4.437255812154269e-05,
      "loss": 0.0516,
      "step": 52400
    },
    {
      "epoch": 1.8051782828456486,
      "grad_norm": 0.19138909876346588,
      "learning_rate": 4.4361812781796535e-05,
      "loss": 0.0499,
      "step": 52500
    },
    {
      "epoch": 1.8086167176701164,
      "grad_norm": 0.09741238504648209,
      "learning_rate": 4.435106744205039e-05,
      "loss": 0.0544,
      "step": 52600
    },
    {
      "epoch": 1.8120551524945845,
      "grad_norm": 0.2588399350643158,
      "learning_rate": 4.434032210230423e-05,
      "loss": 0.051,
      "step": 52700
    },
    {
      "epoch": 1.8154935873190525,
      "grad_norm": 0.220539391040802,
      "learning_rate": 4.432957676255808e-05,
      "loss": 0.0479,
      "step": 52800
    },
    {
      "epoch": 1.8189320221435201,
      "grad_norm": 0.0728217363357544,
      "learning_rate": 4.431883142281193e-05,
      "loss": 0.0499,
      "step": 52900
    },
    {
      "epoch": 1.8223704569679882,
      "grad_norm": 0.12185671180486679,
      "learning_rate": 4.4308086083065775e-05,
      "loss": 0.0485,
      "step": 53000
    },
    {
      "epoch": 1.8258088917924562,
      "grad_norm": 0.19196726381778717,
      "learning_rate": 4.429734074331963e-05,
      "loss": 0.0464,
      "step": 53100
    },
    {
      "epoch": 1.829247326616924,
      "grad_norm": 0.37632906436920166,
      "learning_rate": 4.428659540357347e-05,
      "loss": 0.0533,
      "step": 53200
    },
    {
      "epoch": 1.8326857614413918,
      "grad_norm": 0.12253402173519135,
      "learning_rate": 4.427585006382732e-05,
      "loss": 0.0506,
      "step": 53300
    },
    {
      "epoch": 1.8361241962658599,
      "grad_norm": 0.16823603212833405,
      "learning_rate": 4.426510472408117e-05,
      "loss": 0.0508,
      "step": 53400
    },
    {
      "epoch": 1.8395626310903277,
      "grad_norm": 0.17435304820537567,
      "learning_rate": 4.4254359384335015e-05,
      "loss": 0.0461,
      "step": 53500
    },
    {
      "epoch": 1.8430010659147955,
      "grad_norm": 0.21789312362670898,
      "learning_rate": 4.424361404458887e-05,
      "loss": 0.0526,
      "step": 53600
    },
    {
      "epoch": 1.8464395007392636,
      "grad_norm": 0.1617061048746109,
      "learning_rate": 4.423286870484271e-05,
      "loss": 0.0467,
      "step": 53700
    },
    {
      "epoch": 1.8498779355637314,
      "grad_norm": 0.2767861485481262,
      "learning_rate": 4.422212336509656e-05,
      "loss": 0.0454,
      "step": 53800
    },
    {
      "epoch": 1.8533163703881992,
      "grad_norm": 0.12610264122486115,
      "learning_rate": 4.421137802535041e-05,
      "loss": 0.0497,
      "step": 53900
    },
    {
      "epoch": 1.8567548052126672,
      "grad_norm": 0.14004309475421906,
      "learning_rate": 4.4200632685604255e-05,
      "loss": 0.0508,
      "step": 54000
    },
    {
      "epoch": 1.860193240037135,
      "grad_norm": 0.20897096395492554,
      "learning_rate": 4.418988734585811e-05,
      "loss": 0.0535,
      "step": 54100
    },
    {
      "epoch": 1.8636316748616029,
      "grad_norm": 0.16421067714691162,
      "learning_rate": 4.417914200611195e-05,
      "loss": 0.0583,
      "step": 54200
    },
    {
      "epoch": 1.867070109686071,
      "grad_norm": 0.22377315163612366,
      "learning_rate": 4.41683966663658e-05,
      "loss": 0.0509,
      "step": 54300
    },
    {
      "epoch": 1.870508544510539,
      "grad_norm": 0.24752753973007202,
      "learning_rate": 4.415765132661965e-05,
      "loss": 0.0512,
      "step": 54400
    },
    {
      "epoch": 1.8739469793350068,
      "grad_norm": 0.18912123143672943,
      "learning_rate": 4.4146905986873495e-05,
      "loss": 0.0507,
      "step": 54500
    },
    {
      "epoch": 1.8773854141594746,
      "grad_norm": 0.189903125166893,
      "learning_rate": 4.413616064712735e-05,
      "loss": 0.0488,
      "step": 54600
    },
    {
      "epoch": 1.8808238489839426,
      "grad_norm": 0.11992229521274567,
      "learning_rate": 4.412541530738119e-05,
      "loss": 0.0508,
      "step": 54700
    },
    {
      "epoch": 1.8842622838084104,
      "grad_norm": 0.10318339616060257,
      "learning_rate": 4.411466996763504e-05,
      "loss": 0.0479,
      "step": 54800
    },
    {
      "epoch": 1.8877007186328782,
      "grad_norm": 0.2795236110687256,
      "learning_rate": 4.410392462788889e-05,
      "loss": 0.0505,
      "step": 54900
    },
    {
      "epoch": 1.8911391534573463,
      "grad_norm": 0.20414599776268005,
      "learning_rate": 4.4093179288142735e-05,
      "loss": 0.0491,
      "step": 55000
    },
    {
      "epoch": 1.894577588281814,
      "grad_norm": 0.20147578418254852,
      "learning_rate": 4.408243394839659e-05,
      "loss": 0.0498,
      "step": 55100
    },
    {
      "epoch": 1.898016023106282,
      "grad_norm": 0.4442271590232849,
      "learning_rate": 4.407168860865043e-05,
      "loss": 0.0508,
      "step": 55200
    },
    {
      "epoch": 1.90145445793075,
      "grad_norm": 0.07827098667621613,
      "learning_rate": 4.406094326890428e-05,
      "loss": 0.0513,
      "step": 55300
    },
    {
      "epoch": 1.9048928927552178,
      "grad_norm": 0.3725649416446686,
      "learning_rate": 4.405019792915813e-05,
      "loss": 0.0537,
      "step": 55400
    },
    {
      "epoch": 1.9083313275796856,
      "grad_norm": 0.08393838256597519,
      "learning_rate": 4.4039452589411975e-05,
      "loss": 0.0493,
      "step": 55500
    },
    {
      "epoch": 1.9117697624041536,
      "grad_norm": 0.5895624756813049,
      "learning_rate": 4.402870724966582e-05,
      "loss": 0.0464,
      "step": 55600
    },
    {
      "epoch": 1.9152081972286217,
      "grad_norm": 0.26137661933898926,
      "learning_rate": 4.4017961909919666e-05,
      "loss": 0.0505,
      "step": 55700
    },
    {
      "epoch": 1.9186466320530893,
      "grad_norm": 0.19928286969661713,
      "learning_rate": 4.400721657017352e-05,
      "loss": 0.05,
      "step": 55800
    },
    {
      "epoch": 1.9220850668775573,
      "grad_norm": 0.22938422858715057,
      "learning_rate": 4.399647123042736e-05,
      "loss": 0.0501,
      "step": 55900
    },
    {
      "epoch": 1.9255235017020254,
      "grad_norm": 0.1518542617559433,
      "learning_rate": 4.398572589068121e-05,
      "loss": 0.0475,
      "step": 56000
    },
    {
      "epoch": 1.9289619365264932,
      "grad_norm": 0.12381894886493683,
      "learning_rate": 4.397498055093506e-05,
      "loss": 0.049,
      "step": 56100
    },
    {
      "epoch": 1.932400371350961,
      "grad_norm": 0.23920337855815887,
      "learning_rate": 4.3964235211188906e-05,
      "loss": 0.0479,
      "step": 56200
    },
    {
      "epoch": 1.935838806175429,
      "grad_norm": 0.07786203920841217,
      "learning_rate": 4.395348987144276e-05,
      "loss": 0.0486,
      "step": 56300
    },
    {
      "epoch": 1.9392772409998968,
      "grad_norm": 0.12130565196275711,
      "learning_rate": 4.3942744531696603e-05,
      "loss": 0.0518,
      "step": 56400
    },
    {
      "epoch": 1.9427156758243647,
      "grad_norm": 0.24538516998291016,
      "learning_rate": 4.393199919195045e-05,
      "loss": 0.0461,
      "step": 56500
    },
    {
      "epoch": 1.9461541106488327,
      "grad_norm": 0.1399511843919754,
      "learning_rate": 4.39212538522043e-05,
      "loss": 0.0509,
      "step": 56600
    },
    {
      "epoch": 1.9495925454733005,
      "grad_norm": 0.5307855606079102,
      "learning_rate": 4.3910508512458146e-05,
      "loss": 0.0488,
      "step": 56700
    },
    {
      "epoch": 1.9530309802977683,
      "grad_norm": 0.07317222654819489,
      "learning_rate": 4.3899763172712e-05,
      "loss": 0.0463,
      "step": 56800
    },
    {
      "epoch": 1.9564694151222364,
      "grad_norm": 0.10659679770469666,
      "learning_rate": 4.3889017832965843e-05,
      "loss": 0.0505,
      "step": 56900
    },
    {
      "epoch": 1.9599078499467044,
      "grad_norm": 0.27213385701179504,
      "learning_rate": 4.387827249321969e-05,
      "loss": 0.0471,
      "step": 57000
    },
    {
      "epoch": 1.963346284771172,
      "grad_norm": 0.07413185387849808,
      "learning_rate": 4.386752715347354e-05,
      "loss": 0.0482,
      "step": 57100
    },
    {
      "epoch": 1.96678471959564,
      "grad_norm": 0.13966122269630432,
      "learning_rate": 4.385688926712485e-05,
      "loss": 0.0486,
      "step": 57200
    },
    {
      "epoch": 1.970223154420108,
      "grad_norm": 0.17690922319889069,
      "learning_rate": 4.3846143927378696e-05,
      "loss": 0.0501,
      "step": 57300
    },
    {
      "epoch": 1.973661589244576,
      "grad_norm": 0.17795374989509583,
      "learning_rate": 4.383539858763255e-05,
      "loss": 0.0457,
      "step": 57400
    },
    {
      "epoch": 1.9771000240690437,
      "grad_norm": 0.12059889733791351,
      "learning_rate": 4.382465324788639e-05,
      "loss": 0.0471,
      "step": 57500
    },
    {
      "epoch": 1.9805384588935118,
      "grad_norm": 0.12402757257223129,
      "learning_rate": 4.381390790814024e-05,
      "loss": 0.0536,
      "step": 57600
    },
    {
      "epoch": 1.9839768937179796,
      "grad_norm": 0.11475211381912231,
      "learning_rate": 4.380316256839409e-05,
      "loss": 0.0502,
      "step": 57700
    },
    {
      "epoch": 1.9874153285424474,
      "grad_norm": 0.12197063863277435,
      "learning_rate": 4.3792417228647936e-05,
      "loss": 0.049,
      "step": 57800
    },
    {
      "epoch": 1.9908537633669154,
      "grad_norm": 0.16953836381435394,
      "learning_rate": 4.378167188890179e-05,
      "loss": 0.049,
      "step": 57900
    },
    {
      "epoch": 1.9942921981913833,
      "grad_norm": 0.13335879147052765,
      "learning_rate": 4.377092654915563e-05,
      "loss": 0.05,
      "step": 58000
    },
    {
      "epoch": 1.997730633015851,
      "grad_norm": 0.17289231717586517,
      "learning_rate": 4.376018120940948e-05,
      "loss": 0.0493,
      "step": 58100
    },
    {
      "epoch": 2.0,
      "eval_accuracy_macro_0.5": 0.9800798296928406,
      "eval_accuracy_micro_0.5": 0.9800798296928406,
      "eval_accuracy_weighted_0.5": 0.9674797058105469,
      "eval_aucroc_macro": 0.867046594619751,
      "eval_aucroc_micro": 0.8814491033554077,
      "eval_aucroc_weighted": 0.8769199252128601,
      "eval_f1_macro_0.5": 0.6414310932159424,
      "eval_f1_macro_0.6": 0.5939019322395325,
      "eval_f1_macro_0.7": 0.526482343673706,
      "eval_f1_macro_0.8": 0.2828349173069,
      "eval_f1_micro_0.5": 0.6888630390167236,
      "eval_f1_micro_0.6": 0.6554504632949829,
      "eval_f1_micro_0.7": 0.6024655699729919,
      "eval_f1_micro_0.8": 0.5144906044006348,
      "eval_f1_micro_0.9": 0.35557323694229126,
      "eval_f1_weighted_0.5": 0.6662567853927612,
      "eval_f1_weighted_0.6": 0.6210130453109741,
      "eval_f1_weighted_0.7": 0.5555518269538879,
      "eval_f1_weighted_0.8": 0.30295804142951965,
      "eval_loss": 0.04528762400150299,
      "eval_runtime": 2053.8939,
      "eval_samples_per_second": 28.303,
      "eval_steps_per_second": 3.538,
      "step": 58166
    },
    {
      "epoch": 2.001169067840319,
      "grad_norm": 0.27143263816833496,
      "learning_rate": 4.374943586966333e-05,
      "loss": 0.0526,
      "step": 58200
    },
    {
      "epoch": 2.004607502664787,
      "grad_norm": 0.12614873051643372,
      "learning_rate": 4.3738690529917176e-05,
      "loss": 0.0504,
      "step": 58300
    },
    {
      "epoch": 2.0080459374892548,
      "grad_norm": 0.36144477128982544,
      "learning_rate": 4.372794519017103e-05,
      "loss": 0.0484,
      "step": 58400
    },
    {
      "epoch": 2.011484372313723,
      "grad_norm": 0.18416756391525269,
      "learning_rate": 4.371719985042487e-05,
      "loss": 0.0494,
      "step": 58500
    },
    {
      "epoch": 2.014922807138191,
      "grad_norm": 0.19804325699806213,
      "learning_rate": 4.370645451067872e-05,
      "loss": 0.046,
      "step": 58600
    },
    {
      "epoch": 2.0183612419626584,
      "grad_norm": 0.29304003715515137,
      "learning_rate": 4.369570917093257e-05,
      "loss": 0.0512,
      "step": 58700
    },
    {
      "epoch": 2.0217996767871265,
      "grad_norm": 0.5084890723228455,
      "learning_rate": 4.3684963831186416e-05,
      "loss": 0.0464,
      "step": 58800
    },
    {
      "epoch": 2.0252381116115945,
      "grad_norm": 0.16600896418094635,
      "learning_rate": 4.367421849144027e-05,
      "loss": 0.046,
      "step": 58900
    },
    {
      "epoch": 2.028676546436062,
      "grad_norm": 0.12349559366703033,
      "learning_rate": 4.366347315169411e-05,
      "loss": 0.0492,
      "step": 59000
    },
    {
      "epoch": 2.03211498126053,
      "grad_norm": 0.17750993371009827,
      "learning_rate": 4.365272781194796e-05,
      "loss": 0.048,
      "step": 59100
    },
    {
      "epoch": 2.035553416084998,
      "grad_norm": 0.1580389440059662,
      "learning_rate": 4.364198247220181e-05,
      "loss": 0.0519,
      "step": 59200
    },
    {
      "epoch": 2.038991850909466,
      "grad_norm": 0.11857717484235764,
      "learning_rate": 4.3631237132455656e-05,
      "loss": 0.0483,
      "step": 59300
    },
    {
      "epoch": 2.042430285733934,
      "grad_norm": 0.14896483719348907,
      "learning_rate": 4.362049179270951e-05,
      "loss": 0.0494,
      "step": 59400
    },
    {
      "epoch": 2.045868720558402,
      "grad_norm": 0.3360487222671509,
      "learning_rate": 4.360974645296335e-05,
      "loss": 0.0477,
      "step": 59500
    },
    {
      "epoch": 2.04930715538287,
      "grad_norm": 0.38407793641090393,
      "learning_rate": 4.35990011132172e-05,
      "loss": 0.051,
      "step": 59600
    },
    {
      "epoch": 2.0527455902073375,
      "grad_norm": 0.33343154191970825,
      "learning_rate": 4.358825577347105e-05,
      "loss": 0.047,
      "step": 59700
    },
    {
      "epoch": 2.0561840250318055,
      "grad_norm": 0.21452467143535614,
      "learning_rate": 4.3577510433724896e-05,
      "loss": 0.0466,
      "step": 59800
    },
    {
      "epoch": 2.0596224598562736,
      "grad_norm": 0.25608816742897034,
      "learning_rate": 4.3566872547376205e-05,
      "loss": 0.0516,
      "step": 59900
    },
    {
      "epoch": 2.063060894680741,
      "grad_norm": 0.30160272121429443,
      "learning_rate": 4.355612720763006e-05,
      "loss": 0.0489,
      "step": 60000
    },
    {
      "epoch": 2.066499329505209,
      "grad_norm": 0.1680818498134613,
      "learning_rate": 4.35453818678839e-05,
      "loss": 0.0474,
      "step": 60100
    },
    {
      "epoch": 2.0699377643296772,
      "grad_norm": 0.12393761426210403,
      "learning_rate": 4.353463652813775e-05,
      "loss": 0.0437,
      "step": 60200
    },
    {
      "epoch": 2.073376199154145,
      "grad_norm": 0.26194578409194946,
      "learning_rate": 4.3523891188391593e-05,
      "loss": 0.0498,
      "step": 60300
    },
    {
      "epoch": 2.076814633978613,
      "grad_norm": 0.16127625107765198,
      "learning_rate": 4.3513145848645446e-05,
      "loss": 0.0513,
      "step": 60400
    },
    {
      "epoch": 2.080253068803081,
      "grad_norm": 0.12725743651390076,
      "learning_rate": 4.350240050889929e-05,
      "loss": 0.0507,
      "step": 60500
    },
    {
      "epoch": 2.0836915036275485,
      "grad_norm": 0.12105388194322586,
      "learning_rate": 4.3491655169153136e-05,
      "loss": 0.0497,
      "step": 60600
    },
    {
      "epoch": 2.0871299384520166,
      "grad_norm": 0.23544926941394806,
      "learning_rate": 4.348090982940699e-05,
      "loss": 0.0476,
      "step": 60700
    },
    {
      "epoch": 2.0905683732764846,
      "grad_norm": 0.2548244297504425,
      "learning_rate": 4.3470164489660833e-05,
      "loss": 0.049,
      "step": 60800
    },
    {
      "epoch": 2.0940068081009526,
      "grad_norm": 0.17022058367729187,
      "learning_rate": 4.345941914991468e-05,
      "loss": 0.0421,
      "step": 60900
    },
    {
      "epoch": 2.0974452429254202,
      "grad_norm": 0.10828676074743271,
      "learning_rate": 4.344867381016853e-05,
      "loss": 0.0451,
      "step": 61000
    },
    {
      "epoch": 2.1008836777498883,
      "grad_norm": 0.11704062670469284,
      "learning_rate": 4.3437928470422376e-05,
      "loss": 0.0529,
      "step": 61100
    },
    {
      "epoch": 2.1043221125743563,
      "grad_norm": 0.10061486810445786,
      "learning_rate": 4.342718313067623e-05,
      "loss": 0.0498,
      "step": 61200
    },
    {
      "epoch": 2.107760547398824,
      "grad_norm": 0.2874567210674286,
      "learning_rate": 4.3416437790930073e-05,
      "loss": 0.047,
      "step": 61300
    },
    {
      "epoch": 2.111198982223292,
      "grad_norm": 0.08625586330890656,
      "learning_rate": 4.340569245118392e-05,
      "loss": 0.0475,
      "step": 61400
    },
    {
      "epoch": 2.11463741704776,
      "grad_norm": 0.16349387168884277,
      "learning_rate": 4.339494711143777e-05,
      "loss": 0.0482,
      "step": 61500
    },
    {
      "epoch": 2.1180758518722276,
      "grad_norm": 0.13612054288387299,
      "learning_rate": 4.3384201771691616e-05,
      "loss": 0.0486,
      "step": 61600
    },
    {
      "epoch": 2.1215142866966956,
      "grad_norm": 0.2978208363056183,
      "learning_rate": 4.337345643194547e-05,
      "loss": 0.0485,
      "step": 61700
    },
    {
      "epoch": 2.1249527215211637,
      "grad_norm": 0.07632958143949509,
      "learning_rate": 4.3362711092199314e-05,
      "loss": 0.046,
      "step": 61800
    },
    {
      "epoch": 2.1283911563456313,
      "grad_norm": 0.249819815158844,
      "learning_rate": 4.335196575245316e-05,
      "loss": 0.047,
      "step": 61900
    },
    {
      "epoch": 2.1318295911700993,
      "grad_norm": 0.1750968098640442,
      "learning_rate": 4.3341327866104475e-05,
      "loss": 0.0454,
      "step": 62000
    },
    {
      "epoch": 2.1352680259945673,
      "grad_norm": 0.187373548746109,
      "learning_rate": 4.333058252635832e-05,
      "loss": 0.0515,
      "step": 62100
    },
    {
      "epoch": 2.1387064608190354,
      "grad_norm": 0.12221811711788177,
      "learning_rate": 4.3319837186612166e-05,
      "loss": 0.0471,
      "step": 62200
    },
    {
      "epoch": 2.142144895643503,
      "grad_norm": 0.21971072256565094,
      "learning_rate": 4.330909184686602e-05,
      "loss": 0.0529,
      "step": 62300
    },
    {
      "epoch": 2.145583330467971,
      "grad_norm": 0.43494799733161926,
      "learning_rate": 4.329834650711986e-05,
      "loss": 0.0447,
      "step": 62400
    },
    {
      "epoch": 2.149021765292439,
      "grad_norm": 0.16332833468914032,
      "learning_rate": 4.3287601167373715e-05,
      "loss": 0.0507,
      "step": 62500
    },
    {
      "epoch": 2.1524602001169066,
      "grad_norm": 0.1220371425151825,
      "learning_rate": 4.327685582762756e-05,
      "loss": 0.0455,
      "step": 62600
    },
    {
      "epoch": 2.1558986349413747,
      "grad_norm": 0.2727951109409332,
      "learning_rate": 4.3266110487881406e-05,
      "loss": 0.046,
      "step": 62700
    },
    {
      "epoch": 2.1593370697658427,
      "grad_norm": 0.12693651020526886,
      "learning_rate": 4.325536514813526e-05,
      "loss": 0.0481,
      "step": 62800
    },
    {
      "epoch": 2.1627755045903103,
      "grad_norm": 0.16094034910202026,
      "learning_rate": 4.32446198083891e-05,
      "loss": 0.0502,
      "step": 62900
    },
    {
      "epoch": 2.1662139394147784,
      "grad_norm": 0.17074257135391235,
      "learning_rate": 4.3233874468642955e-05,
      "loss": 0.0502,
      "step": 63000
    },
    {
      "epoch": 2.1696523742392464,
      "grad_norm": 0.17575813829898834,
      "learning_rate": 4.32231291288968e-05,
      "loss": 0.049,
      "step": 63100
    },
    {
      "epoch": 2.173090809063714,
      "grad_norm": 0.10455961525440216,
      "learning_rate": 4.3212383789150646e-05,
      "loss": 0.047,
      "step": 63200
    },
    {
      "epoch": 2.176529243888182,
      "grad_norm": 0.0994258001446724,
      "learning_rate": 4.32016384494045e-05,
      "loss": 0.0462,
      "step": 63300
    },
    {
      "epoch": 2.17996767871265,
      "grad_norm": 0.1943177580833435,
      "learning_rate": 4.319089310965834e-05,
      "loss": 0.0425,
      "step": 63400
    },
    {
      "epoch": 2.183406113537118,
      "grad_norm": 0.33416926860809326,
      "learning_rate": 4.3180147769912195e-05,
      "loss": 0.0476,
      "step": 63500
    },
    {
      "epoch": 2.1868445483615857,
      "grad_norm": 0.33221834897994995,
      "learning_rate": 4.316940243016604e-05,
      "loss": 0.0515,
      "step": 63600
    },
    {
      "epoch": 2.1902829831860537,
      "grad_norm": 0.12500953674316406,
      "learning_rate": 4.3158657090419886e-05,
      "loss": 0.0489,
      "step": 63700
    },
    {
      "epoch": 2.193721418010522,
      "grad_norm": 0.16967837512493134,
      "learning_rate": 4.314791175067374e-05,
      "loss": 0.0483,
      "step": 63800
    },
    {
      "epoch": 2.1971598528349894,
      "grad_norm": 0.37761345505714417,
      "learning_rate": 4.313716641092758e-05,
      "loss": 0.0444,
      "step": 63900
    },
    {
      "epoch": 2.2005982876594574,
      "grad_norm": 0.3689574897289276,
      "learning_rate": 4.3126421071181435e-05,
      "loss": 0.0455,
      "step": 64000
    },
    {
      "epoch": 2.2040367224839255,
      "grad_norm": 0.31335705518722534,
      "learning_rate": 4.311567573143528e-05,
      "loss": 0.05,
      "step": 64100
    },
    {
      "epoch": 2.207475157308393,
      "grad_norm": 0.14324119687080383,
      "learning_rate": 4.3104930391689126e-05,
      "loss": 0.0505,
      "step": 64200
    },
    {
      "epoch": 2.210913592132861,
      "grad_norm": 0.2945038080215454,
      "learning_rate": 4.309418505194298e-05,
      "loss": 0.0496,
      "step": 64300
    },
    {
      "epoch": 2.214352026957329,
      "grad_norm": 0.1037667989730835,
      "learning_rate": 4.308343971219682e-05,
      "loss": 0.0489,
      "step": 64400
    },
    {
      "epoch": 2.2177904617817967,
      "grad_norm": 0.12705716490745544,
      "learning_rate": 4.3072694372450675e-05,
      "loss": 0.0479,
      "step": 64500
    },
    {
      "epoch": 2.2212288966062648,
      "grad_norm": 0.18027131259441376,
      "learning_rate": 4.306194903270452e-05,
      "loss": 0.0448,
      "step": 64600
    },
    {
      "epoch": 2.224667331430733,
      "grad_norm": 0.07027801126241684,
      "learning_rate": 4.3051203692958366e-05,
      "loss": 0.0452,
      "step": 64700
    },
    {
      "epoch": 2.228105766255201,
      "grad_norm": 0.13215160369873047,
      "learning_rate": 4.304045835321222e-05,
      "loss": 0.0452,
      "step": 64800
    },
    {
      "epoch": 2.2315442010796684,
      "grad_norm": 0.10353628545999527,
      "learning_rate": 4.302971301346606e-05,
      "loss": 0.0478,
      "step": 64900
    },
    {
      "epoch": 2.2349826359041365,
      "grad_norm": 0.16896694898605347,
      "learning_rate": 4.3018967673719915e-05,
      "loss": 0.0467,
      "step": 65000
    },
    {
      "epoch": 2.2384210707286045,
      "grad_norm": 0.1484900861978531,
      "learning_rate": 4.300822233397376e-05,
      "loss": 0.0488,
      "step": 65100
    },
    {
      "epoch": 2.241859505553072,
      "grad_norm": 0.27588093280792236,
      "learning_rate": 4.2997476994227606e-05,
      "loss": 0.0472,
      "step": 65200
    },
    {
      "epoch": 2.24529794037754,
      "grad_norm": 0.07350276410579681,
      "learning_rate": 4.298673165448146e-05,
      "loss": 0.0468,
      "step": 65300
    },
    {
      "epoch": 2.248736375202008,
      "grad_norm": 0.6340361833572388,
      "learning_rate": 4.29759863147353e-05,
      "loss": 0.0474,
      "step": 65400
    },
    {
      "epoch": 2.252174810026476,
      "grad_norm": 0.1798485368490219,
      "learning_rate": 4.2965348428386606e-05,
      "loss": 0.0481,
      "step": 65500
    },
    {
      "epoch": 2.255613244850944,
      "grad_norm": 0.2686115503311157,
      "learning_rate": 4.295460308864046e-05,
      "loss": 0.0488,
      "step": 65600
    },
    {
      "epoch": 2.259051679675412,
      "grad_norm": 0.400795578956604,
      "learning_rate": 4.2943857748894304e-05,
      "loss": 0.0504,
      "step": 65700
    },
    {
      "epoch": 2.2624901144998795,
      "grad_norm": 0.21147362887859344,
      "learning_rate": 4.293311240914815e-05,
      "loss": 0.0464,
      "step": 65800
    },
    {
      "epoch": 2.2659285493243475,
      "grad_norm": 0.5493516325950623,
      "learning_rate": 4.2922367069402e-05,
      "loss": 0.0448,
      "step": 65900
    },
    {
      "epoch": 2.2693669841488155,
      "grad_norm": 0.3553805351257324,
      "learning_rate": 4.2911621729655846e-05,
      "loss": 0.046,
      "step": 66000
    },
    {
      "epoch": 2.2728054189732836,
      "grad_norm": 0.4810235798358917,
      "learning_rate": 4.29008763899097e-05,
      "loss": 0.0491,
      "step": 66100
    },
    {
      "epoch": 2.276243853797751,
      "grad_norm": 0.16015487909317017,
      "learning_rate": 4.2890131050163544e-05,
      "loss": 0.0462,
      "step": 66200
    },
    {
      "epoch": 2.279682288622219,
      "grad_norm": 0.12278418242931366,
      "learning_rate": 4.287938571041739e-05,
      "loss": 0.0465,
      "step": 66300
    },
    {
      "epoch": 2.2831207234466873,
      "grad_norm": 0.20718976855278015,
      "learning_rate": 4.286864037067124e-05,
      "loss": 0.0469,
      "step": 66400
    },
    {
      "epoch": 2.286559158271155,
      "grad_norm": 0.1438944935798645,
      "learning_rate": 4.2857895030925086e-05,
      "loss": 0.0479,
      "step": 66500
    },
    {
      "epoch": 2.289997593095623,
      "grad_norm": 0.11132709681987762,
      "learning_rate": 4.284714969117894e-05,
      "loss": 0.0478,
      "step": 66600
    },
    {
      "epoch": 2.293436027920091,
      "grad_norm": 0.33388322591781616,
      "learning_rate": 4.2836404351432784e-05,
      "loss": 0.0422,
      "step": 66700
    },
    {
      "epoch": 2.2968744627445585,
      "grad_norm": 0.18439780175685883,
      "learning_rate": 4.2825659011686636e-05,
      "loss": 0.0492,
      "step": 66800
    },
    {
      "epoch": 2.3003128975690266,
      "grad_norm": 0.19041313230991364,
      "learning_rate": 4.281491367194048e-05,
      "loss": 0.0467,
      "step": 66900
    },
    {
      "epoch": 2.3037513323934946,
      "grad_norm": 0.22243580222129822,
      "learning_rate": 4.2804168332194326e-05,
      "loss": 0.0435,
      "step": 67000
    },
    {
      "epoch": 2.307189767217962,
      "grad_norm": 0.3689756393432617,
      "learning_rate": 4.279342299244818e-05,
      "loss": 0.0427,
      "step": 67100
    },
    {
      "epoch": 2.3106282020424302,
      "grad_norm": 0.23278401792049408,
      "learning_rate": 4.2782677652702024e-05,
      "loss": 0.0502,
      "step": 67200
    },
    {
      "epoch": 2.3140666368668983,
      "grad_norm": 0.28221264481544495,
      "learning_rate": 4.2771932312955876e-05,
      "loss": 0.048,
      "step": 67300
    },
    {
      "epoch": 2.3175050716913663,
      "grad_norm": 0.101369708776474,
      "learning_rate": 4.276118697320972e-05,
      "loss": 0.0489,
      "step": 67400
    },
    {
      "epoch": 2.320943506515834,
      "grad_norm": 0.1653650403022766,
      "learning_rate": 4.2750441633463566e-05,
      "loss": 0.0486,
      "step": 67500
    },
    {
      "epoch": 2.324381941340302,
      "grad_norm": 0.19597259163856506,
      "learning_rate": 4.273969629371742e-05,
      "loss": 0.0485,
      "step": 67600
    },
    {
      "epoch": 2.3278203761647696,
      "grad_norm": 0.5295432209968567,
      "learning_rate": 4.2728950953971264e-05,
      "loss": 0.0454,
      "step": 67700
    },
    {
      "epoch": 2.3312588109892376,
      "grad_norm": 0.15288607776165009,
      "learning_rate": 4.2718205614225116e-05,
      "loss": 0.042,
      "step": 67800
    },
    {
      "epoch": 2.3346972458137056,
      "grad_norm": 0.30714526772499084,
      "learning_rate": 4.270746027447896e-05,
      "loss": 0.046,
      "step": 67900
    },
    {
      "epoch": 2.3381356806381737,
      "grad_norm": 0.41826170682907104,
      "learning_rate": 4.2696714934732806e-05,
      "loss": 0.0508,
      "step": 68000
    },
    {
      "epoch": 2.3415741154626413,
      "grad_norm": 0.2154315710067749,
      "learning_rate": 4.268596959498666e-05,
      "loss": 0.0492,
      "step": 68100
    },
    {
      "epoch": 2.3450125502871093,
      "grad_norm": 0.3599412143230438,
      "learning_rate": 4.2675224255240504e-05,
      "loss": 0.0488,
      "step": 68200
    },
    {
      "epoch": 2.3484509851115773,
      "grad_norm": 0.10285454988479614,
      "learning_rate": 4.266458636889181e-05,
      "loss": 0.0463,
      "step": 68300
    },
    {
      "epoch": 2.351889419936045,
      "grad_norm": 0.17625710368156433,
      "learning_rate": 4.2653841029145665e-05,
      "loss": 0.0464,
      "step": 68400
    },
    {
      "epoch": 2.355327854760513,
      "grad_norm": 0.4639838635921478,
      "learning_rate": 4.264309568939951e-05,
      "loss": 0.0506,
      "step": 68500
    },
    {
      "epoch": 2.358766289584981,
      "grad_norm": 0.08248856663703918,
      "learning_rate": 4.2632350349653356e-05,
      "loss": 0.0427,
      "step": 68600
    },
    {
      "epoch": 2.362204724409449,
      "grad_norm": 0.14076527953147888,
      "learning_rate": 4.262160500990721e-05,
      "loss": 0.0475,
      "step": 68700
    },
    {
      "epoch": 2.3656431592339167,
      "grad_norm": 0.3055732548236847,
      "learning_rate": 4.261085967016105e-05,
      "loss": 0.0443,
      "step": 68800
    },
    {
      "epoch": 2.3690815940583847,
      "grad_norm": 0.18479642271995544,
      "learning_rate": 4.2600114330414905e-05,
      "loss": 0.0431,
      "step": 68900
    },
    {
      "epoch": 2.3725200288828523,
      "grad_norm": 0.2830513119697571,
      "learning_rate": 4.258936899066875e-05,
      "loss": 0.0481,
      "step": 69000
    },
    {
      "epoch": 2.3759584637073203,
      "grad_norm": 0.11947616934776306,
      "learning_rate": 4.2578623650922596e-05,
      "loss": 0.0439,
      "step": 69100
    },
    {
      "epoch": 2.3793968985317884,
      "grad_norm": 0.17743390798568726,
      "learning_rate": 4.256787831117645e-05,
      "loss": 0.0471,
      "step": 69200
    },
    {
      "epoch": 2.3828353333562564,
      "grad_norm": 0.33056139945983887,
      "learning_rate": 4.255713297143029e-05,
      "loss": 0.0433,
      "step": 69300
    },
    {
      "epoch": 2.386273768180724,
      "grad_norm": 0.11921201646327972,
      "learning_rate": 4.2546387631684145e-05,
      "loss": 0.0434,
      "step": 69400
    },
    {
      "epoch": 2.389712203005192,
      "grad_norm": 0.25764256715774536,
      "learning_rate": 4.253564229193799e-05,
      "loss": 0.0468,
      "step": 69500
    },
    {
      "epoch": 2.39315063782966,
      "grad_norm": 0.12066236883401871,
      "learning_rate": 4.2524896952191836e-05,
      "loss": 0.0462,
      "step": 69600
    },
    {
      "epoch": 2.3965890726541277,
      "grad_norm": 0.3172065019607544,
      "learning_rate": 4.251415161244569e-05,
      "loss": 0.0454,
      "step": 69700
    },
    {
      "epoch": 2.4000275074785957,
      "grad_norm": 0.19248726963996887,
      "learning_rate": 4.2503406272699533e-05,
      "loss": 0.0471,
      "step": 69800
    },
    {
      "epoch": 2.4034659423030638,
      "grad_norm": 0.104634128510952,
      "learning_rate": 4.249266093295338e-05,
      "loss": 0.0435,
      "step": 69900
    },
    {
      "epoch": 2.4069043771275314,
      "grad_norm": 0.16871823370456696,
      "learning_rate": 4.248191559320723e-05,
      "loss": 0.0458,
      "step": 70000
    },
    {
      "epoch": 2.4103428119519994,
      "grad_norm": 0.24562735855579376,
      "learning_rate": 4.2471170253461076e-05,
      "loss": 0.0472,
      "step": 70100
    },
    {
      "epoch": 2.4137812467764674,
      "grad_norm": 0.06297620385885239,
      "learning_rate": 4.246042491371492e-05,
      "loss": 0.0432,
      "step": 70200
    },
    {
      "epoch": 2.417219681600935,
      "grad_norm": 0.15484657883644104,
      "learning_rate": 4.2449679573968773e-05,
      "loss": 0.0429,
      "step": 70300
    },
    {
      "epoch": 2.420658116425403,
      "grad_norm": 0.2250639647245407,
      "learning_rate": 4.243893423422262e-05,
      "loss": 0.048,
      "step": 70400
    },
    {
      "epoch": 2.424096551249871,
      "grad_norm": 0.25725364685058594,
      "learning_rate": 4.2428188894476464e-05,
      "loss": 0.0508,
      "step": 70500
    },
    {
      "epoch": 2.427534986074339,
      "grad_norm": 0.2309344857931137,
      "learning_rate": 4.2417443554730316e-05,
      "loss": 0.0498,
      "step": 70600
    },
    {
      "epoch": 2.4309734208988067,
      "grad_norm": 0.66605144739151,
      "learning_rate": 4.240669821498416e-05,
      "loss": 0.0492,
      "step": 70700
    },
    {
      "epoch": 2.434411855723275,
      "grad_norm": 0.1718294620513916,
      "learning_rate": 4.239595287523801e-05,
      "loss": 0.0475,
      "step": 70800
    },
    {
      "epoch": 2.437850290547743,
      "grad_norm": 0.19956618547439575,
      "learning_rate": 4.238520753549186e-05,
      "loss": 0.0439,
      "step": 70900
    },
    {
      "epoch": 2.4412887253722104,
      "grad_norm": 0.25184866786003113,
      "learning_rate": 4.2374462195745704e-05,
      "loss": 0.0453,
      "step": 71000
    },
    {
      "epoch": 2.4447271601966785,
      "grad_norm": 0.14812977612018585,
      "learning_rate": 4.236371685599955e-05,
      "loss": 0.0517,
      "step": 71100
    },
    {
      "epoch": 2.4481655950211465,
      "grad_norm": 0.11825615167617798,
      "learning_rate": 4.23529715162534e-05,
      "loss": 0.0444,
      "step": 71200
    },
    {
      "epoch": 2.451604029845614,
      "grad_norm": 0.11951078474521637,
      "learning_rate": 4.234222617650725e-05,
      "loss": 0.046,
      "step": 71300
    },
    {
      "epoch": 2.455042464670082,
      "grad_norm": 0.3972504734992981,
      "learning_rate": 4.23314808367611e-05,
      "loss": 0.0487,
      "step": 71400
    },
    {
      "epoch": 2.45848089949455,
      "grad_norm": 0.1701744794845581,
      "learning_rate": 4.2320735497014944e-05,
      "loss": 0.0466,
      "step": 71500
    },
    {
      "epoch": 2.4619193343190178,
      "grad_norm": 0.3775598108768463,
      "learning_rate": 4.230999015726879e-05,
      "loss": 0.0452,
      "step": 71600
    },
    {
      "epoch": 2.465357769143486,
      "grad_norm": 0.17890702188014984,
      "learning_rate": 4.229924481752264e-05,
      "loss": 0.0445,
      "step": 71700
    },
    {
      "epoch": 2.468796203967954,
      "grad_norm": 0.5178388953208923,
      "learning_rate": 4.228849947777649e-05,
      "loss": 0.0488,
      "step": 71800
    },
    {
      "epoch": 2.472234638792422,
      "grad_norm": 0.41207242012023926,
      "learning_rate": 4.227775413803034e-05,
      "loss": 0.0436,
      "step": 71900
    },
    {
      "epoch": 2.4756730736168895,
      "grad_norm": 0.34360867738723755,
      "learning_rate": 4.2267008798284184e-05,
      "loss": 0.0461,
      "step": 72000
    },
    {
      "epoch": 2.4791115084413575,
      "grad_norm": 0.13029547035694122,
      "learning_rate": 4.2256263458538036e-05,
      "loss": 0.0461,
      "step": 72100
    },
    {
      "epoch": 2.4825499432658256,
      "grad_norm": 0.3046310842037201,
      "learning_rate": 4.224551811879188e-05,
      "loss": 0.0475,
      "step": 72200
    },
    {
      "epoch": 2.485988378090293,
      "grad_norm": 0.1892365962266922,
      "learning_rate": 4.223477277904573e-05,
      "loss": 0.0466,
      "step": 72300
    },
    {
      "epoch": 2.489426812914761,
      "grad_norm": 0.22267568111419678,
      "learning_rate": 4.222402743929958e-05,
      "loss": 0.0493,
      "step": 72400
    },
    {
      "epoch": 2.4928652477392292,
      "grad_norm": 0.14590749144554138,
      "learning_rate": 4.2213282099553424e-05,
      "loss": 0.0459,
      "step": 72500
    },
    {
      "epoch": 2.496303682563697,
      "grad_norm": 0.12136819958686829,
      "learning_rate": 4.2202536759807276e-05,
      "loss": 0.0423,
      "step": 72600
    },
    {
      "epoch": 2.499742117388165,
      "grad_norm": 0.07755757123231888,
      "learning_rate": 4.219179142006112e-05,
      "loss": 0.0453,
      "step": 72700
    },
    {
      "epoch": 2.503180552212633,
      "grad_norm": 0.10833197832107544,
      "learning_rate": 4.218104608031497e-05,
      "loss": 0.0471,
      "step": 72800
    },
    {
      "epoch": 2.5066189870371005,
      "grad_norm": 0.12422280013561249,
      "learning_rate": 4.2170408193966276e-05,
      "loss": 0.0453,
      "step": 72900
    },
    {
      "epoch": 2.5100574218615685,
      "grad_norm": 0.1093907579779625,
      "learning_rate": 4.215966285422013e-05,
      "loss": 0.0473,
      "step": 73000
    },
    {
      "epoch": 2.5134958566860366,
      "grad_norm": 0.2716098427772522,
      "learning_rate": 4.2148917514473974e-05,
      "loss": 0.0422,
      "step": 73100
    },
    {
      "epoch": 2.5169342915105046,
      "grad_norm": 0.3989171087741852,
      "learning_rate": 4.2138172174727826e-05,
      "loss": 0.0466,
      "step": 73200
    },
    {
      "epoch": 2.5203727263349722,
      "grad_norm": 0.2601211667060852,
      "learning_rate": 4.212742683498167e-05,
      "loss": 0.047,
      "step": 73300
    },
    {
      "epoch": 2.5238111611594403,
      "grad_norm": 0.19018696248531342,
      "learning_rate": 4.2116681495235516e-05,
      "loss": 0.0428,
      "step": 73400
    },
    {
      "epoch": 2.527249595983908,
      "grad_norm": 0.15477600693702698,
      "learning_rate": 4.210593615548937e-05,
      "loss": 0.0421,
      "step": 73500
    },
    {
      "epoch": 2.530688030808376,
      "grad_norm": 0.23306943476200104,
      "learning_rate": 4.2095190815743214e-05,
      "loss": 0.046,
      "step": 73600
    },
    {
      "epoch": 2.534126465632844,
      "grad_norm": 0.46066978573799133,
      "learning_rate": 4.2084445475997066e-05,
      "loss": 0.0478,
      "step": 73700
    },
    {
      "epoch": 2.537564900457312,
      "grad_norm": 0.1896735280752182,
      "learning_rate": 4.207370013625091e-05,
      "loss": 0.0482,
      "step": 73800
    },
    {
      "epoch": 2.5410033352817796,
      "grad_norm": 0.11297459155321121,
      "learning_rate": 4.2062954796504756e-05,
      "loss": 0.0435,
      "step": 73900
    },
    {
      "epoch": 2.5444417701062476,
      "grad_norm": 0.2923584580421448,
      "learning_rate": 4.205220945675861e-05,
      "loss": 0.0437,
      "step": 74000
    },
    {
      "epoch": 2.5478802049307157,
      "grad_norm": 0.09519033879041672,
      "learning_rate": 4.2041464117012454e-05,
      "loss": 0.0459,
      "step": 74100
    },
    {
      "epoch": 2.5513186397551832,
      "grad_norm": 0.2276836335659027,
      "learning_rate": 4.2030718777266306e-05,
      "loss": 0.0461,
      "step": 74200
    },
    {
      "epoch": 2.5547570745796513,
      "grad_norm": 0.15395359694957733,
      "learning_rate": 4.201997343752015e-05,
      "loss": 0.0475,
      "step": 74300
    },
    {
      "epoch": 2.5581955094041193,
      "grad_norm": 0.3193883001804352,
      "learning_rate": 4.2009228097773996e-05,
      "loss": 0.0524,
      "step": 74400
    },
    {
      "epoch": 2.5616339442285874,
      "grad_norm": 0.06668335199356079,
      "learning_rate": 4.199848275802785e-05,
      "loss": 0.0443,
      "step": 74500
    },
    {
      "epoch": 2.565072379053055,
      "grad_norm": 0.176713764667511,
      "learning_rate": 4.1987737418281694e-05,
      "loss": 0.0478,
      "step": 74600
    },
    {
      "epoch": 2.568510813877523,
      "grad_norm": 0.2001045048236847,
      "learning_rate": 4.1976992078535546e-05,
      "loss": 0.0486,
      "step": 74700
    },
    {
      "epoch": 2.5719492487019906,
      "grad_norm": 0.11740066111087799,
      "learning_rate": 4.196624673878939e-05,
      "loss": 0.0441,
      "step": 74800
    },
    {
      "epoch": 2.5753876835264586,
      "grad_norm": 0.1859062761068344,
      "learning_rate": 4.19556088524407e-05,
      "loss": 0.0464,
      "step": 74900
    },
    {
      "epoch": 2.5788261183509267,
      "grad_norm": 0.3097315728664398,
      "learning_rate": 4.1944863512694546e-05,
      "loss": 0.0455,
      "step": 75000
    },
    {
      "epoch": 2.5822645531753947,
      "grad_norm": 0.2280566543340683,
      "learning_rate": 4.193411817294839e-05,
      "loss": 0.0471,
      "step": 75100
    },
    {
      "epoch": 2.5857029879998623,
      "grad_norm": 0.27570390701293945,
      "learning_rate": 4.1923372833202244e-05,
      "loss": 0.0457,
      "step": 75200
    },
    {
      "epoch": 2.5891414228243304,
      "grad_norm": 0.22522011399269104,
      "learning_rate": 4.191262749345609e-05,
      "loss": 0.0436,
      "step": 75300
    },
    {
      "epoch": 2.5925798576487984,
      "grad_norm": 0.23098497092723846,
      "learning_rate": 4.1901882153709934e-05,
      "loss": 0.0457,
      "step": 75400
    },
    {
      "epoch": 2.596018292473266,
      "grad_norm": 0.16409341990947723,
      "learning_rate": 4.1891136813963786e-05,
      "loss": 0.0436,
      "step": 75500
    },
    {
      "epoch": 2.599456727297734,
      "grad_norm": 0.09154848009347916,
      "learning_rate": 4.188039147421763e-05,
      "loss": 0.0423,
      "step": 75600
    },
    {
      "epoch": 2.602895162122202,
      "grad_norm": 0.3384108543395996,
      "learning_rate": 4.186964613447148e-05,
      "loss": 0.0465,
      "step": 75700
    },
    {
      "epoch": 2.60633359694667,
      "grad_norm": 0.24234868586063385,
      "learning_rate": 4.185890079472533e-05,
      "loss": 0.0465,
      "step": 75800
    },
    {
      "epoch": 2.6097720317711377,
      "grad_norm": 0.25750941038131714,
      "learning_rate": 4.1848155454979174e-05,
      "loss": 0.046,
      "step": 75900
    },
    {
      "epoch": 2.6132104665956057,
      "grad_norm": 0.2585510313510895,
      "learning_rate": 4.1837410115233026e-05,
      "loss": 0.0471,
      "step": 76000
    },
    {
      "epoch": 2.6166489014200733,
      "grad_norm": 0.54887855052948,
      "learning_rate": 4.182666477548687e-05,
      "loss": 0.0479,
      "step": 76100
    },
    {
      "epoch": 2.6200873362445414,
      "grad_norm": 0.13243548572063446,
      "learning_rate": 4.181591943574072e-05,
      "loss": 0.044,
      "step": 76200
    },
    {
      "epoch": 2.6235257710690094,
      "grad_norm": 0.13291388750076294,
      "learning_rate": 4.180517409599457e-05,
      "loss": 0.0476,
      "step": 76300
    },
    {
      "epoch": 2.6269642058934775,
      "grad_norm": 0.12981534004211426,
      "learning_rate": 4.1794428756248414e-05,
      "loss": 0.0456,
      "step": 76400
    },
    {
      "epoch": 2.630402640717945,
      "grad_norm": 0.3410451114177704,
      "learning_rate": 4.1783683416502266e-05,
      "loss": 0.0471,
      "step": 76500
    },
    {
      "epoch": 2.633841075542413,
      "grad_norm": 0.16035319864749908,
      "learning_rate": 4.177293807675611e-05,
      "loss": 0.0459,
      "step": 76600
    },
    {
      "epoch": 2.637279510366881,
      "grad_norm": 0.2084415704011917,
      "learning_rate": 4.176219273700996e-05,
      "loss": 0.0434,
      "step": 76700
    },
    {
      "epoch": 2.6407179451913487,
      "grad_norm": 0.1241903156042099,
      "learning_rate": 4.175144739726381e-05,
      "loss": 0.0465,
      "step": 76800
    },
    {
      "epoch": 2.6441563800158168,
      "grad_norm": 0.09609448164701462,
      "learning_rate": 4.1740702057517654e-05,
      "loss": 0.0437,
      "step": 76900
    },
    {
      "epoch": 2.647594814840285,
      "grad_norm": 0.15863732993602753,
      "learning_rate": 4.1729956717771506e-05,
      "loss": 0.0469,
      "step": 77000
    },
    {
      "epoch": 2.651033249664753,
      "grad_norm": 0.1277483105659485,
      "learning_rate": 4.171921137802535e-05,
      "loss": 0.0465,
      "step": 77100
    },
    {
      "epoch": 2.6544716844892204,
      "grad_norm": 0.2114197015762329,
      "learning_rate": 4.17084660382792e-05,
      "loss": 0.0397,
      "step": 77200
    },
    {
      "epoch": 2.6579101193136885,
      "grad_norm": 0.264967143535614,
      "learning_rate": 4.169772069853305e-05,
      "loss": 0.0459,
      "step": 77300
    },
    {
      "epoch": 2.661348554138156,
      "grad_norm": 0.14655399322509766,
      "learning_rate": 4.1686975358786894e-05,
      "loss": 0.0464,
      "step": 77400
    },
    {
      "epoch": 2.664786988962624,
      "grad_norm": 0.3867028057575226,
      "learning_rate": 4.1676230019040746e-05,
      "loss": 0.0468,
      "step": 77500
    },
    {
      "epoch": 2.668225423787092,
      "grad_norm": 0.15819355845451355,
      "learning_rate": 4.166548467929459e-05,
      "loss": 0.0462,
      "step": 77600
    },
    {
      "epoch": 2.67166385861156,
      "grad_norm": 0.13555635511875153,
      "learning_rate": 4.165473933954844e-05,
      "loss": 0.0442,
      "step": 77700
    },
    {
      "epoch": 2.675102293436028,
      "grad_norm": 0.1478092521429062,
      "learning_rate": 4.164399399980229e-05,
      "loss": 0.0496,
      "step": 77800
    },
    {
      "epoch": 2.678540728260496,
      "grad_norm": 0.16446563601493835,
      "learning_rate": 4.1633248660056134e-05,
      "loss": 0.0472,
      "step": 77900
    },
    {
      "epoch": 2.681979163084964,
      "grad_norm": 0.19334134459495544,
      "learning_rate": 4.1622610773707444e-05,
      "loss": 0.0475,
      "step": 78000
    },
    {
      "epoch": 2.6854175979094315,
      "grad_norm": 0.10778214782476425,
      "learning_rate": 4.1611865433961296e-05,
      "loss": 0.046,
      "step": 78100
    },
    {
      "epoch": 2.6888560327338995,
      "grad_norm": 0.22268839180469513,
      "learning_rate": 4.160112009421514e-05,
      "loss": 0.0463,
      "step": 78200
    },
    {
      "epoch": 2.6922944675583675,
      "grad_norm": 0.21914413571357727,
      "learning_rate": 4.159037475446899e-05,
      "loss": 0.0457,
      "step": 78300
    },
    {
      "epoch": 2.6957329023828356,
      "grad_norm": 0.32695871591567993,
      "learning_rate": 4.157962941472284e-05,
      "loss": 0.0479,
      "step": 78400
    },
    {
      "epoch": 2.699171337207303,
      "grad_norm": 0.11028853803873062,
      "learning_rate": 4.1568884074976684e-05,
      "loss": 0.0427,
      "step": 78500
    },
    {
      "epoch": 2.702609772031771,
      "grad_norm": 0.1267632097005844,
      "learning_rate": 4.1558138735230536e-05,
      "loss": 0.0474,
      "step": 78600
    },
    {
      "epoch": 2.706048206856239,
      "grad_norm": 0.08412528038024902,
      "learning_rate": 4.154739339548438e-05,
      "loss": 0.0446,
      "step": 78700
    },
    {
      "epoch": 2.709486641680707,
      "grad_norm": 0.3419053256511688,
      "learning_rate": 4.153664805573823e-05,
      "loss": 0.0418,
      "step": 78800
    },
    {
      "epoch": 2.712925076505175,
      "grad_norm": 0.27206361293792725,
      "learning_rate": 4.152590271599208e-05,
      "loss": 0.0425,
      "step": 78900
    },
    {
      "epoch": 2.716363511329643,
      "grad_norm": 0.2350924015045166,
      "learning_rate": 4.1515157376245924e-05,
      "loss": 0.0471,
      "step": 79000
    },
    {
      "epoch": 2.7198019461541105,
      "grad_norm": 0.11348675936460495,
      "learning_rate": 4.1504412036499776e-05,
      "loss": 0.0463,
      "step": 79100
    },
    {
      "epoch": 2.7232403809785786,
      "grad_norm": 0.20216242969036102,
      "learning_rate": 4.149366669675362e-05,
      "loss": 0.0433,
      "step": 79200
    },
    {
      "epoch": 2.7266788158030466,
      "grad_norm": 0.2807627022266388,
      "learning_rate": 4.148292135700747e-05,
      "loss": 0.0466,
      "step": 79300
    },
    {
      "epoch": 2.730117250627514,
      "grad_norm": 0.27814361453056335,
      "learning_rate": 4.147217601726132e-05,
      "loss": 0.043,
      "step": 79400
    },
    {
      "epoch": 2.7335556854519822,
      "grad_norm": 0.11578359454870224,
      "learning_rate": 4.1461430677515164e-05,
      "loss": 0.0452,
      "step": 79500
    },
    {
      "epoch": 2.7369941202764503,
      "grad_norm": 0.13688339293003082,
      "learning_rate": 4.1450685337769016e-05,
      "loss": 0.0411,
      "step": 79600
    },
    {
      "epoch": 2.7404325551009183,
      "grad_norm": 0.15052494406700134,
      "learning_rate": 4.143993999802286e-05,
      "loss": 0.043,
      "step": 79700
    },
    {
      "epoch": 2.743870989925386,
      "grad_norm": 0.12253942340612411,
      "learning_rate": 4.1429194658276707e-05,
      "loss": 0.0468,
      "step": 79800
    },
    {
      "epoch": 2.747309424749854,
      "grad_norm": 0.22778190672397614,
      "learning_rate": 4.141844931853056e-05,
      "loss": 0.0486,
      "step": 79900
    },
    {
      "epoch": 2.7507478595743216,
      "grad_norm": 0.1099204570055008,
      "learning_rate": 4.140781143218186e-05,
      "loss": 0.0475,
      "step": 80000
    },
    {
      "epoch": 2.7541862943987896,
      "grad_norm": 0.11208617687225342,
      "learning_rate": 4.139706609243571e-05,
      "loss": 0.0456,
      "step": 80100
    },
    {
      "epoch": 2.7576247292232576,
      "grad_norm": 0.4726990759372711,
      "learning_rate": 4.138642820608702e-05,
      "loss": 0.0423,
      "step": 80200
    },
    {
      "epoch": 2.7610631640477257,
      "grad_norm": 0.4690116047859192,
      "learning_rate": 4.137568286634087e-05,
      "loss": 0.0454,
      "step": 80300
    },
    {
      "epoch": 2.7645015988721933,
      "grad_norm": 0.5668428540229797,
      "learning_rate": 4.1364937526594714e-05,
      "loss": 0.0468,
      "step": 80400
    },
    {
      "epoch": 2.7679400336966613,
      "grad_norm": 0.35473161935806274,
      "learning_rate": 4.1354192186848566e-05,
      "loss": 0.0438,
      "step": 80500
    },
    {
      "epoch": 2.7713784685211293,
      "grad_norm": 0.23563383519649506,
      "learning_rate": 4.134344684710241e-05,
      "loss": 0.0465,
      "step": 80600
    },
    {
      "epoch": 2.774816903345597,
      "grad_norm": 0.25024649500846863,
      "learning_rate": 4.133270150735626e-05,
      "loss": 0.0481,
      "step": 80700
    },
    {
      "epoch": 2.778255338170065,
      "grad_norm": 0.19487974047660828,
      "learning_rate": 4.132195616761011e-05,
      "loss": 0.0438,
      "step": 80800
    },
    {
      "epoch": 2.781693772994533,
      "grad_norm": 0.47024020552635193,
      "learning_rate": 4.1311210827863954e-05,
      "loss": 0.0458,
      "step": 80900
    },
    {
      "epoch": 2.785132207819001,
      "grad_norm": 0.13646157085895538,
      "learning_rate": 4.1300465488117806e-05,
      "loss": 0.0475,
      "step": 81000
    },
    {
      "epoch": 2.7885706426434687,
      "grad_norm": 0.19739869236946106,
      "learning_rate": 4.128972014837165e-05,
      "loss": 0.0465,
      "step": 81100
    },
    {
      "epoch": 2.7920090774679367,
      "grad_norm": 0.28312477469444275,
      "learning_rate": 4.12789748086255e-05,
      "loss": 0.0449,
      "step": 81200
    },
    {
      "epoch": 2.7954475122924043,
      "grad_norm": 0.6332489252090454,
      "learning_rate": 4.126822946887935e-05,
      "loss": 0.048,
      "step": 81300
    },
    {
      "epoch": 2.7988859471168723,
      "grad_norm": 0.11828584223985672,
      "learning_rate": 4.1257484129133194e-05,
      "loss": 0.0434,
      "step": 81400
    },
    {
      "epoch": 2.8023243819413404,
      "grad_norm": 0.12008213996887207,
      "learning_rate": 4.1246738789387046e-05,
      "loss": 0.0425,
      "step": 81500
    },
    {
      "epoch": 2.8057628167658084,
      "grad_norm": 0.4037693440914154,
      "learning_rate": 4.123599344964089e-05,
      "loss": 0.0434,
      "step": 81600
    },
    {
      "epoch": 2.809201251590276,
      "grad_norm": 0.29190516471862793,
      "learning_rate": 4.122524810989474e-05,
      "loss": 0.0426,
      "step": 81700
    },
    {
      "epoch": 2.812639686414744,
      "grad_norm": 0.12454953044652939,
      "learning_rate": 4.121450277014859e-05,
      "loss": 0.0438,
      "step": 81800
    },
    {
      "epoch": 2.8160781212392116,
      "grad_norm": 0.22307004034519196,
      "learning_rate": 4.1203757430402434e-05,
      "loss": 0.0505,
      "step": 81900
    },
    {
      "epoch": 2.8195165560636797,
      "grad_norm": 0.38303232192993164,
      "learning_rate": 4.1193012090656286e-05,
      "loss": 0.0477,
      "step": 82000
    },
    {
      "epoch": 2.8229549908881477,
      "grad_norm": 0.30164679884910583,
      "learning_rate": 4.118226675091013e-05,
      "loss": 0.0491,
      "step": 82100
    },
    {
      "epoch": 2.8263934257126158,
      "grad_norm": 0.13308990001678467,
      "learning_rate": 4.117152141116398e-05,
      "loss": 0.0471,
      "step": 82200
    },
    {
      "epoch": 2.8298318605370834,
      "grad_norm": 0.17748649418354034,
      "learning_rate": 4.116077607141783e-05,
      "loss": 0.0451,
      "step": 82300
    },
    {
      "epoch": 2.8332702953615514,
      "grad_norm": 0.09146453440189362,
      "learning_rate": 4.1150030731671674e-05,
      "loss": 0.0437,
      "step": 82400
    },
    {
      "epoch": 2.8367087301860194,
      "grad_norm": 0.1784454584121704,
      "learning_rate": 4.1139285391925526e-05,
      "loss": 0.0456,
      "step": 82500
    },
    {
      "epoch": 2.840147165010487,
      "grad_norm": 0.09165052324533463,
      "learning_rate": 4.112854005217937e-05,
      "loss": 0.0463,
      "step": 82600
    },
    {
      "epoch": 2.843585599834955,
      "grad_norm": 0.12705548107624054,
      "learning_rate": 4.111779471243322e-05,
      "loss": 0.044,
      "step": 82700
    },
    {
      "epoch": 2.847024034659423,
      "grad_norm": 0.444663941860199,
      "learning_rate": 4.110704937268707e-05,
      "loss": 0.0485,
      "step": 82800
    },
    {
      "epoch": 2.850462469483891,
      "grad_norm": 0.12961561977863312,
      "learning_rate": 4.1096304032940914e-05,
      "loss": 0.0458,
      "step": 82900
    },
    {
      "epoch": 2.8539009043083587,
      "grad_norm": 0.5310490131378174,
      "learning_rate": 4.1085558693194766e-05,
      "loss": 0.0411,
      "step": 83000
    },
    {
      "epoch": 2.857339339132827,
      "grad_norm": 0.08523353934288025,
      "learning_rate": 4.107481335344861e-05,
      "loss": 0.0469,
      "step": 83100
    },
    {
      "epoch": 2.8607777739572944,
      "grad_norm": 0.04488784819841385,
      "learning_rate": 4.106406801370246e-05,
      "loss": 0.0414,
      "step": 83200
    },
    {
      "epoch": 2.8642162087817624,
      "grad_norm": 0.12228317558765411,
      "learning_rate": 4.105332267395631e-05,
      "loss": 0.043,
      "step": 83300
    },
    {
      "epoch": 2.8676546436062305,
      "grad_norm": 0.27259430289268494,
      "learning_rate": 4.1042577334210154e-05,
      "loss": 0.0455,
      "step": 83400
    },
    {
      "epoch": 2.8710930784306985,
      "grad_norm": 0.0691288486123085,
      "learning_rate": 4.1031831994464006e-05,
      "loss": 0.0423,
      "step": 83500
    },
    {
      "epoch": 2.874531513255166,
      "grad_norm": 0.07203920185565948,
      "learning_rate": 4.102108665471785e-05,
      "loss": 0.0459,
      "step": 83600
    },
    {
      "epoch": 2.877969948079634,
      "grad_norm": 0.16081643104553223,
      "learning_rate": 4.1010341314971703e-05,
      "loss": 0.0411,
      "step": 83700
    },
    {
      "epoch": 2.881408382904102,
      "grad_norm": 0.13340361416339874,
      "learning_rate": 4.099959597522555e-05,
      "loss": 0.0432,
      "step": 83800
    },
    {
      "epoch": 2.8848468177285698,
      "grad_norm": 0.25539109110832214,
      "learning_rate": 4.0988850635479394e-05,
      "loss": 0.0436,
      "step": 83900
    },
    {
      "epoch": 2.888285252553038,
      "grad_norm": 0.18157845735549927,
      "learning_rate": 4.0978105295733246e-05,
      "loss": 0.0438,
      "step": 84000
    },
    {
      "epoch": 2.891723687377506,
      "grad_norm": 0.10060789436101913,
      "learning_rate": 4.096735995598709e-05,
      "loss": 0.0444,
      "step": 84100
    },
    {
      "epoch": 2.895162122201974,
      "grad_norm": 0.25303593277931213,
      "learning_rate": 4.0956614616240943e-05,
      "loss": 0.0439,
      "step": 84200
    },
    {
      "epoch": 2.8986005570264415,
      "grad_norm": 0.14923274517059326,
      "learning_rate": 4.094586927649479e-05,
      "loss": 0.0415,
      "step": 84300
    },
    {
      "epoch": 2.9020389918509095,
      "grad_norm": 0.15093597769737244,
      "learning_rate": 4.0935123936748634e-05,
      "loss": 0.0461,
      "step": 84400
    },
    {
      "epoch": 2.905477426675377,
      "grad_norm": 0.1421879380941391,
      "learning_rate": 4.0924378597002486e-05,
      "loss": 0.0442,
      "step": 84500
    },
    {
      "epoch": 2.908915861499845,
      "grad_norm": 0.17365477979183197,
      "learning_rate": 4.091363325725633e-05,
      "loss": 0.0421,
      "step": 84600
    },
    {
      "epoch": 2.912354296324313,
      "grad_norm": 0.3756207227706909,
      "learning_rate": 4.090288791751018e-05,
      "loss": 0.0466,
      "step": 84700
    },
    {
      "epoch": 2.9157927311487812,
      "grad_norm": 0.11720200628042221,
      "learning_rate": 4.089214257776403e-05,
      "loss": 0.044,
      "step": 84800
    },
    {
      "epoch": 2.919231165973249,
      "grad_norm": 0.3444092869758606,
      "learning_rate": 4.0881397238017874e-05,
      "loss": 0.0453,
      "step": 84900
    },
    {
      "epoch": 2.922669600797717,
      "grad_norm": 0.38455674052238464,
      "learning_rate": 4.087065189827172e-05,
      "loss": 0.0429,
      "step": 85000
    },
    {
      "epoch": 2.926108035622185,
      "grad_norm": 0.14897982776165009,
      "learning_rate": 4.085990655852557e-05,
      "loss": 0.0461,
      "step": 85100
    },
    {
      "epoch": 2.9295464704466525,
      "grad_norm": 0.14038975536823273,
      "learning_rate": 4.084916121877942e-05,
      "loss": 0.0454,
      "step": 85200
    },
    {
      "epoch": 2.9329849052711205,
      "grad_norm": 0.24832648038864136,
      "learning_rate": 4.083841587903326e-05,
      "loss": 0.0424,
      "step": 85300
    },
    {
      "epoch": 2.9364233400955886,
      "grad_norm": 0.11520673334598541,
      "learning_rate": 4.082767053928711e-05,
      "loss": 0.0434,
      "step": 85400
    },
    {
      "epoch": 2.9398617749200566,
      "grad_norm": 0.08134905248880386,
      "learning_rate": 4.081692519954096e-05,
      "loss": 0.0435,
      "step": 85500
    },
    {
      "epoch": 2.943300209744524,
      "grad_norm": 0.45706215500831604,
      "learning_rate": 4.0806179859794805e-05,
      "loss": 0.0471,
      "step": 85600
    },
    {
      "epoch": 2.9467386445689923,
      "grad_norm": 0.16264723241329193,
      "learning_rate": 4.079543452004866e-05,
      "loss": 0.0441,
      "step": 85700
    },
    {
      "epoch": 2.95017707939346,
      "grad_norm": 0.16863161325454712,
      "learning_rate": 4.07846891803025e-05,
      "loss": 0.0447,
      "step": 85800
    },
    {
      "epoch": 2.953615514217928,
      "grad_norm": 0.14122875034809113,
      "learning_rate": 4.077394384055635e-05,
      "loss": 0.0456,
      "step": 85900
    },
    {
      "epoch": 2.957053949042396,
      "grad_norm": 0.10104452818632126,
      "learning_rate": 4.07631985008102e-05,
      "loss": 0.0435,
      "step": 86000
    },
    {
      "epoch": 2.960492383866864,
      "grad_norm": 0.42386817932128906,
      "learning_rate": 4.0752453161064045e-05,
      "loss": 0.0436,
      "step": 86100
    },
    {
      "epoch": 2.9639308186913316,
      "grad_norm": 0.11388842761516571,
      "learning_rate": 4.07417078213179e-05,
      "loss": 0.045,
      "step": 86200
    },
    {
      "epoch": 2.9673692535157996,
      "grad_norm": 0.4396100342273712,
      "learning_rate": 4.0731069934969206e-05,
      "loss": 0.0493,
      "step": 86300
    },
    {
      "epoch": 2.9708076883402676,
      "grad_norm": 0.493432879447937,
      "learning_rate": 4.072032459522305e-05,
      "loss": 0.0465,
      "step": 86400
    },
    {
      "epoch": 2.9742461231647352,
      "grad_norm": 0.0966314822435379,
      "learning_rate": 4.0709579255476904e-05,
      "loss": 0.0435,
      "step": 86500
    },
    {
      "epoch": 2.9776845579892033,
      "grad_norm": 0.2838592827320099,
      "learning_rate": 4.069883391573075e-05,
      "loss": 0.046,
      "step": 86600
    },
    {
      "epoch": 2.9811229928136713,
      "grad_norm": 0.2992722988128662,
      "learning_rate": 4.0688088575984594e-05,
      "loss": 0.0483,
      "step": 86700
    },
    {
      "epoch": 2.9845614276381394,
      "grad_norm": 0.14500954747200012,
      "learning_rate": 4.0677343236238446e-05,
      "loss": 0.0463,
      "step": 86800
    },
    {
      "epoch": 2.987999862462607,
      "grad_norm": 0.11749602109193802,
      "learning_rate": 4.066659789649229e-05,
      "loss": 0.045,
      "step": 86900
    },
    {
      "epoch": 2.991438297287075,
      "grad_norm": 0.13996705412864685,
      "learning_rate": 4.0655852556746144e-05,
      "loss": 0.0451,
      "step": 87000
    },
    {
      "epoch": 2.9948767321115426,
      "grad_norm": 0.23005050420761108,
      "learning_rate": 4.064510721699999e-05,
      "loss": 0.0425,
      "step": 87100
    },
    {
      "epoch": 2.9983151669360106,
      "grad_norm": 0.07852217555046082,
      "learning_rate": 4.0634361877253834e-05,
      "loss": 0.0469,
      "step": 87200
    },
    {
      "epoch": 3.0,
      "eval_accuracy_macro_0.5": 0.9817173480987549,
      "eval_accuracy_micro_0.5": 0.9817173480987549,
      "eval_accuracy_weighted_0.5": 0.9700323939323425,
      "eval_aucroc_macro": 0.8867300748825073,
      "eval_aucroc_micro": 0.8961271047592163,
      "eval_aucroc_weighted": 0.892038881778717,
      "eval_f1_macro_0.5": 0.6902885437011719,
      "eval_f1_macro_0.6": 0.6560604572296143,
      "eval_f1_macro_0.7": 0.6055007576942444,
      "eval_f1_macro_0.8": 0.38602346181869507,
      "eval_f1_micro_0.5": 0.7222331166267395,
      "eval_f1_micro_0.6": 0.6967452764511108,
      "eval_f1_micro_0.7": 0.6535136699676514,
      "eval_f1_micro_0.8": 0.5781863927841187,
      "eval_f1_micro_0.9": 0.4197615087032318,
      "eval_f1_weighted_0.5": 0.709204912185669,
      "eval_f1_weighted_0.6": 0.6762757301330566,
      "eval_f1_weighted_0.7": 0.6242278814315796,
      "eval_f1_weighted_0.8": 0.37251025438308716,
      "eval_loss": 0.040428631007671356,
      "eval_runtime": 2060.2843,
      "eval_samples_per_second": 28.216,
      "eval_steps_per_second": 3.527,
      "step": 87249
    },
    {
      "epoch": 3.0017536017604787,
      "grad_norm": 0.11118602007627487,
      "learning_rate": 4.0623616537507686e-05,
      "loss": 0.0479,
      "step": 87300
    },
    {
      "epoch": 3.0051920365849467,
      "grad_norm": 0.10631394386291504,
      "learning_rate": 4.061287119776153e-05,
      "loss": 0.0434,
      "step": 87400
    },
    {
      "epoch": 3.0086304714094143,
      "grad_norm": 0.10128136724233627,
      "learning_rate": 4.060223331141284e-05,
      "loss": 0.0418,
      "step": 87500
    },
    {
      "epoch": 3.0120689062338823,
      "grad_norm": 0.1280774027109146,
      "learning_rate": 4.0591487971666693e-05,
      "loss": 0.0447,
      "step": 87600
    },
    {
      "epoch": 3.0155073410583504,
      "grad_norm": 0.17370979487895966,
      "learning_rate": 4.058074263192054e-05,
      "loss": 0.0451,
      "step": 87700
    },
    {
      "epoch": 3.018945775882818,
      "grad_norm": 0.0345519483089447,
      "learning_rate": 4.0569997292174384e-05,
      "loss": 0.0405,
      "step": 87800
    },
    {
      "epoch": 3.022384210707286,
      "grad_norm": 0.09408749639987946,
      "learning_rate": 4.0559251952428236e-05,
      "loss": 0.0401,
      "step": 87900
    },
    {
      "epoch": 3.025822645531754,
      "grad_norm": 0.22575436532497406,
      "learning_rate": 4.054850661268208e-05,
      "loss": 0.0466,
      "step": 88000
    },
    {
      "epoch": 3.0292610803562217,
      "grad_norm": 0.3232145607471466,
      "learning_rate": 4.0537761272935933e-05,
      "loss": 0.0449,
      "step": 88100
    },
    {
      "epoch": 3.0326995151806897,
      "grad_norm": 0.12891024351119995,
      "learning_rate": 4.052701593318978e-05,
      "loss": 0.0437,
      "step": 88200
    },
    {
      "epoch": 3.0361379500051577,
      "grad_norm": 0.12184416502714157,
      "learning_rate": 4.051627059344363e-05,
      "loss": 0.0413,
      "step": 88300
    },
    {
      "epoch": 3.0395763848296253,
      "grad_norm": 0.09481063485145569,
      "learning_rate": 4.0505525253697476e-05,
      "loss": 0.0413,
      "step": 88400
    },
    {
      "epoch": 3.0430148196540934,
      "grad_norm": 0.1492377519607544,
      "learning_rate": 4.049477991395132e-05,
      "loss": 0.0442,
      "step": 88500
    },
    {
      "epoch": 3.0464532544785614,
      "grad_norm": 0.4686430096626282,
      "learning_rate": 4.0484034574205173e-05,
      "loss": 0.0447,
      "step": 88600
    },
    {
      "epoch": 3.0498916893030295,
      "grad_norm": 0.12142924964427948,
      "learning_rate": 4.047328923445902e-05,
      "loss": 0.0422,
      "step": 88700
    },
    {
      "epoch": 3.053330124127497,
      "grad_norm": NaN,
      "learning_rate": 4.046265134811033e-05,
      "loss": 0.0438,
      "step": 88800
    },
    {
      "epoch": 3.056768558951965,
      "grad_norm": 0.08051660656929016,
      "learning_rate": 4.0451906008364174e-05,
      "loss": 0.045,
      "step": 88900
    },
    {
      "epoch": 3.060206993776433,
      "grad_norm": 0.16719265282154083,
      "learning_rate": 4.044116066861802e-05,
      "loss": 0.0381,
      "step": 89000
    },
    {
      "epoch": 3.0636454286009007,
      "grad_norm": 0.14983732998371124,
      "learning_rate": 4.043041532887187e-05,
      "loss": 0.0439,
      "step": 89100
    },
    {
      "epoch": 3.0670838634253688,
      "grad_norm": 0.22403714060783386,
      "learning_rate": 4.0419669989125716e-05,
      "loss": 0.046,
      "step": 89200
    },
    {
      "epoch": 3.070522298249837,
      "grad_norm": 0.46461448073387146,
      "learning_rate": 4.040892464937956e-05,
      "loss": 0.0443,
      "step": 89300
    },
    {
      "epoch": 3.0739607330743044,
      "grad_norm": 0.22049580514431,
      "learning_rate": 4.0398179309633414e-05,
      "loss": 0.0424,
      "step": 89400
    },
    {
      "epoch": 3.0773991678987724,
      "grad_norm": 0.19445888698101044,
      "learning_rate": 4.038743396988726e-05,
      "loss": 0.0447,
      "step": 89500
    },
    {
      "epoch": 3.0808376027232405,
      "grad_norm": 0.18413399159908295,
      "learning_rate": 4.0376688630141104e-05,
      "loss": 0.0434,
      "step": 89600
    },
    {
      "epoch": 3.084276037547708,
      "grad_norm": 0.34082096815109253,
      "learning_rate": 4.0365943290394956e-05,
      "loss": 0.0512,
      "step": 89700
    },
    {
      "epoch": 3.087714472372176,
      "grad_norm": 0.10472317039966583,
      "learning_rate": 4.03551979506488e-05,
      "loss": 0.0448,
      "step": 89800
    },
    {
      "epoch": 3.091152907196644,
      "grad_norm": 0.184773251414299,
      "learning_rate": 4.0344452610902654e-05,
      "loss": 0.0421,
      "step": 89900
    },
    {
      "epoch": 3.094591342021112,
      "grad_norm": 0.14018675684928894,
      "learning_rate": 4.03337072711565e-05,
      "loss": 0.0402,
      "step": 90000
    },
    {
      "epoch": 3.09802977684558,
      "grad_norm": 0.06847874075174332,
      "learning_rate": 4.0322961931410344e-05,
      "loss": 0.0409,
      "step": 90100
    },
    {
      "epoch": 3.101468211670048,
      "grad_norm": 0.12612862884998322,
      "learning_rate": 4.0312216591664196e-05,
      "loss": 0.0423,
      "step": 90200
    },
    {
      "epoch": 3.104906646494516,
      "grad_norm": 0.10089319199323654,
      "learning_rate": 4.030147125191804e-05,
      "loss": 0.0399,
      "step": 90300
    },
    {
      "epoch": 3.1083450813189835,
      "grad_norm": 0.04390933737158775,
      "learning_rate": 4.0290725912171894e-05,
      "loss": 0.0465,
      "step": 90400
    },
    {
      "epoch": 3.1117835161434515,
      "grad_norm": 0.03922780975699425,
      "learning_rate": 4.027998057242574e-05,
      "loss": 0.0421,
      "step": 90500
    },
    {
      "epoch": 3.1152219509679195,
      "grad_norm": 0.11344652622938156,
      "learning_rate": 4.0269235232679584e-05,
      "loss": 0.0436,
      "step": 90600
    },
    {
      "epoch": 3.118660385792387,
      "grad_norm": 0.051319919526576996,
      "learning_rate": 4.0258489892933436e-05,
      "loss": 0.0387,
      "step": 90700
    },
    {
      "epoch": 3.122098820616855,
      "grad_norm": 0.24905915558338165,
      "learning_rate": 4.024774455318728e-05,
      "loss": 0.0429,
      "step": 90800
    },
    {
      "epoch": 3.125537255441323,
      "grad_norm": 0.24118562042713165,
      "learning_rate": 4.0236999213441134e-05,
      "loss": 0.0469,
      "step": 90900
    },
    {
      "epoch": 3.128975690265791,
      "grad_norm": 0.09810077399015427,
      "learning_rate": 4.022625387369498e-05,
      "loss": 0.0431,
      "step": 91000
    },
    {
      "epoch": 3.132414125090259,
      "grad_norm": 0.11958913505077362,
      "learning_rate": 4.0215508533948824e-05,
      "loss": 0.0424,
      "step": 91100
    },
    {
      "epoch": 3.135852559914727,
      "grad_norm": 0.08686754107475281,
      "learning_rate": 4.0204763194202676e-05,
      "loss": 0.0461,
      "step": 91200
    },
    {
      "epoch": 3.139290994739195,
      "grad_norm": 0.23257169127464294,
      "learning_rate": 4.019401785445652e-05,
      "loss": 0.0387,
      "step": 91300
    },
    {
      "epoch": 3.1427294295636625,
      "grad_norm": 0.05422389134764671,
      "learning_rate": 4.0183272514710374e-05,
      "loss": 0.039,
      "step": 91400
    },
    {
      "epoch": 3.1461678643881306,
      "grad_norm": 0.177272230386734,
      "learning_rate": 4.017252717496422e-05,
      "loss": 0.0408,
      "step": 91500
    },
    {
      "epoch": 3.1496062992125986,
      "grad_norm": 0.06300906836986542,
      "learning_rate": 4.0161781835218064e-05,
      "loss": 0.0417,
      "step": 91600
    },
    {
      "epoch": 3.153044734037066,
      "grad_norm": 0.10263961553573608,
      "learning_rate": 4.0151036495471917e-05,
      "loss": 0.0431,
      "step": 91700
    },
    {
      "epoch": 3.1564831688615342,
      "grad_norm": 0.2981507480144501,
      "learning_rate": 4.014029115572576e-05,
      "loss": 0.0431,
      "step": 91800
    },
    {
      "epoch": 3.1599216036860023,
      "grad_norm": 0.8671268820762634,
      "learning_rate": 4.0129545815979614e-05,
      "loss": 0.0443,
      "step": 91900
    },
    {
      "epoch": 3.16336003851047,
      "grad_norm": 0.27105265855789185,
      "learning_rate": 4.011880047623346e-05,
      "loss": 0.0456,
      "step": 92000
    },
    {
      "epoch": 3.166798473334938,
      "grad_norm": 0.07897526025772095,
      "learning_rate": 4.0108055136487304e-05,
      "loss": 0.0491,
      "step": 92100
    },
    {
      "epoch": 3.170236908159406,
      "grad_norm": 0.5459581613540649,
      "learning_rate": 4.0097309796741157e-05,
      "loss": 0.0384,
      "step": 92200
    },
    {
      "epoch": 3.1736753429838735,
      "grad_norm": 0.15332597494125366,
      "learning_rate": 4.0086564456995e-05,
      "loss": 0.0437,
      "step": 92300
    },
    {
      "epoch": 3.1771137778083416,
      "grad_norm": 0.3905046880245209,
      "learning_rate": 4.0075819117248854e-05,
      "loss": 0.0437,
      "step": 92400
    },
    {
      "epoch": 3.1805522126328096,
      "grad_norm": 0.1730782836675644,
      "learning_rate": 4.00650737775027e-05,
      "loss": 0.0469,
      "step": 92500
    },
    {
      "epoch": 3.1839906474572777,
      "grad_norm": 0.28266289830207825,
      "learning_rate": 4.0054328437756544e-05,
      "loss": 0.0408,
      "step": 92600
    },
    {
      "epoch": 3.1874290822817453,
      "grad_norm": 0.26459914445877075,
      "learning_rate": 4.0043583098010397e-05,
      "loss": 0.0457,
      "step": 92700
    },
    {
      "epoch": 3.1908675171062133,
      "grad_norm": 0.30501627922058105,
      "learning_rate": 4.003283775826424e-05,
      "loss": 0.0445,
      "step": 92800
    },
    {
      "epoch": 3.1943059519306813,
      "grad_norm": 0.2329406440258026,
      "learning_rate": 4.002219987191555e-05,
      "loss": 0.0448,
      "step": 92900
    },
    {
      "epoch": 3.197744386755149,
      "grad_norm": 0.10633484274148941,
      "learning_rate": 4.0011454532169404e-05,
      "loss": 0.047,
      "step": 93000
    },
    {
      "epoch": 3.201182821579617,
      "grad_norm": 0.24332928657531738,
      "learning_rate": 4.000070919242325e-05,
      "loss": 0.0415,
      "step": 93100
    },
    {
      "epoch": 3.204621256404085,
      "grad_norm": 0.24613451957702637,
      "learning_rate": 3.99899638526771e-05,
      "loss": 0.0435,
      "step": 93200
    },
    {
      "epoch": 3.2080596912285526,
      "grad_norm": 0.16771915555000305,
      "learning_rate": 3.9979218512930946e-05,
      "loss": 0.046,
      "step": 93300
    },
    {
      "epoch": 3.2114981260530207,
      "grad_norm": 0.10093200951814651,
      "learning_rate": 3.996847317318479e-05,
      "loss": 0.0412,
      "step": 93400
    },
    {
      "epoch": 3.2149365608774887,
      "grad_norm": 0.18524503707885742,
      "learning_rate": 3.9957727833438644e-05,
      "loss": 0.0437,
      "step": 93500
    },
    {
      "epoch": 3.2183749957019563,
      "grad_norm": 0.18315701186656952,
      "learning_rate": 3.994698249369249e-05,
      "loss": 0.0421,
      "step": 93600
    },
    {
      "epoch": 3.2218134305264243,
      "grad_norm": 0.1984689086675644,
      "learning_rate": 3.993623715394634e-05,
      "loss": 0.0441,
      "step": 93700
    },
    {
      "epoch": 3.2252518653508924,
      "grad_norm": 0.14756257832050323,
      "learning_rate": 3.9925491814200186e-05,
      "loss": 0.0425,
      "step": 93800
    },
    {
      "epoch": 3.2286903001753604,
      "grad_norm": 0.2070898860692978,
      "learning_rate": 3.991474647445403e-05,
      "loss": 0.0418,
      "step": 93900
    },
    {
      "epoch": 3.232128734999828,
      "grad_norm": 0.21865692734718323,
      "learning_rate": 3.990400113470788e-05,
      "loss": 0.0433,
      "step": 94000
    },
    {
      "epoch": 3.235567169824296,
      "grad_norm": 0.07544039189815521,
      "learning_rate": 3.989325579496173e-05,
      "loss": 0.0444,
      "step": 94100
    },
    {
      "epoch": 3.239005604648764,
      "grad_norm": 0.21899375319480896,
      "learning_rate": 3.9882510455215574e-05,
      "loss": 0.0429,
      "step": 94200
    },
    {
      "epoch": 3.2424440394732317,
      "grad_norm": 0.1603986620903015,
      "learning_rate": 3.987176511546942e-05,
      "loss": 0.0408,
      "step": 94300
    },
    {
      "epoch": 3.2458824742976997,
      "grad_norm": 0.3218192160129547,
      "learning_rate": 3.986101977572327e-05,
      "loss": 0.046,
      "step": 94400
    },
    {
      "epoch": 3.2493209091221678,
      "grad_norm": 0.7140547633171082,
      "learning_rate": 3.985027443597712e-05,
      "loss": 0.0418,
      "step": 94500
    },
    {
      "epoch": 3.2527593439466354,
      "grad_norm": 0.17511330544948578,
      "learning_rate": 3.983952909623096e-05,
      "loss": 0.043,
      "step": 94600
    },
    {
      "epoch": 3.2561977787711034,
      "grad_norm": 0.2118271440267563,
      "learning_rate": 3.982889120988227e-05,
      "loss": 0.0438,
      "step": 94700
    },
    {
      "epoch": 3.2596362135955714,
      "grad_norm": 0.0993833988904953,
      "learning_rate": 3.9818145870136124e-05,
      "loss": 0.0404,
      "step": 94800
    },
    {
      "epoch": 3.263074648420039,
      "grad_norm": 0.15720023214817047,
      "learning_rate": 3.980740053038997e-05,
      "loss": 0.0413,
      "step": 94900
    },
    {
      "epoch": 3.266513083244507,
      "grad_norm": 0.0950627252459526,
      "learning_rate": 3.979665519064382e-05,
      "loss": 0.0428,
      "step": 95000
    },
    {
      "epoch": 3.269951518068975,
      "grad_norm": 0.12490681558847427,
      "learning_rate": 3.9785909850897667e-05,
      "loss": 0.0434,
      "step": 95100
    },
    {
      "epoch": 3.273389952893443,
      "grad_norm": 0.3658888339996338,
      "learning_rate": 3.977516451115151e-05,
      "loss": 0.0437,
      "step": 95200
    },
    {
      "epoch": 3.2768283877179107,
      "grad_norm": 0.1368446797132492,
      "learning_rate": 3.9764419171405364e-05,
      "loss": 0.0458,
      "step": 95300
    },
    {
      "epoch": 3.280266822542379,
      "grad_norm": 0.1572715938091278,
      "learning_rate": 3.975367383165921e-05,
      "loss": 0.0435,
      "step": 95400
    },
    {
      "epoch": 3.2837052573668464,
      "grad_norm": 0.054527923464775085,
      "learning_rate": 3.974292849191306e-05,
      "loss": 0.0397,
      "step": 95500
    },
    {
      "epoch": 3.2871436921913144,
      "grad_norm": 0.15840892493724823,
      "learning_rate": 3.9732183152166907e-05,
      "loss": 0.0433,
      "step": 95600
    },
    {
      "epoch": 3.2905821270157825,
      "grad_norm": 0.1904727816581726,
      "learning_rate": 3.972143781242075e-05,
      "loss": 0.0428,
      "step": 95700
    },
    {
      "epoch": 3.2940205618402505,
      "grad_norm": 0.12271834909915924,
      "learning_rate": 3.9710692472674604e-05,
      "loss": 0.0497,
      "step": 95800
    },
    {
      "epoch": 3.297458996664718,
      "grad_norm": 0.13886836171150208,
      "learning_rate": 3.969994713292845e-05,
      "loss": 0.0438,
      "step": 95900
    },
    {
      "epoch": 3.300897431489186,
      "grad_norm": 0.12337984144687653,
      "learning_rate": 3.96892017931823e-05,
      "loss": 0.0455,
      "step": 96000
    },
    {
      "epoch": 3.304335866313654,
      "grad_norm": 0.1486198455095291,
      "learning_rate": 3.9678456453436147e-05,
      "loss": 0.0426,
      "step": 96100
    },
    {
      "epoch": 3.3077743011381218,
      "grad_norm": 0.2500136196613312,
      "learning_rate": 3.966771111368999e-05,
      "loss": 0.04,
      "step": 96200
    },
    {
      "epoch": 3.31121273596259,
      "grad_norm": 0.13508713245391846,
      "learning_rate": 3.9656965773943844e-05,
      "loss": 0.0438,
      "step": 96300
    },
    {
      "epoch": 3.314651170787058,
      "grad_norm": 0.12173989415168762,
      "learning_rate": 3.964622043419769e-05,
      "loss": 0.0441,
      "step": 96400
    },
    {
      "epoch": 3.318089605611526,
      "grad_norm": 0.11073759943246841,
      "learning_rate": 3.963547509445154e-05,
      "loss": 0.0424,
      "step": 96500
    },
    {
      "epoch": 3.3215280404359935,
      "grad_norm": 0.19165094196796417,
      "learning_rate": 3.9624729754705387e-05,
      "loss": 0.0403,
      "step": 96600
    },
    {
      "epoch": 3.3249664752604615,
      "grad_norm": 0.37150847911834717,
      "learning_rate": 3.961398441495923e-05,
      "loss": 0.0422,
      "step": 96700
    },
    {
      "epoch": 3.328404910084929,
      "grad_norm": 0.18724234402179718,
      "learning_rate": 3.9603239075213084e-05,
      "loss": 0.0432,
      "step": 96800
    },
    {
      "epoch": 3.331843344909397,
      "grad_norm": 0.11274142563343048,
      "learning_rate": 3.959249373546693e-05,
      "loss": 0.0428,
      "step": 96900
    },
    {
      "epoch": 3.335281779733865,
      "grad_norm": 0.11625087261199951,
      "learning_rate": 3.958174839572078e-05,
      "loss": 0.0433,
      "step": 97000
    },
    {
      "epoch": 3.3387202145583332,
      "grad_norm": 0.047295548021793365,
      "learning_rate": 3.957100305597463e-05,
      "loss": 0.0438,
      "step": 97100
    },
    {
      "epoch": 3.342158649382801,
      "grad_norm": 0.06934230774641037,
      "learning_rate": 3.956025771622847e-05,
      "loss": 0.0454,
      "step": 97200
    },
    {
      "epoch": 3.345597084207269,
      "grad_norm": 0.056446947157382965,
      "learning_rate": 3.9549512376482324e-05,
      "loss": 0.0453,
      "step": 97300
    },
    {
      "epoch": 3.349035519031737,
      "grad_norm": 0.12760010361671448,
      "learning_rate": 3.953876703673617e-05,
      "loss": 0.0428,
      "step": 97400
    },
    {
      "epoch": 3.3524739538562045,
      "grad_norm": 0.21911795437335968,
      "learning_rate": 3.952802169699002e-05,
      "loss": 0.0411,
      "step": 97500
    },
    {
      "epoch": 3.3559123886806725,
      "grad_norm": 0.08737129718065262,
      "learning_rate": 3.951727635724387e-05,
      "loss": 0.0436,
      "step": 97600
    },
    {
      "epoch": 3.3593508235051406,
      "grad_norm": 0.4552108645439148,
      "learning_rate": 3.950653101749771e-05,
      "loss": 0.0413,
      "step": 97700
    },
    {
      "epoch": 3.362789258329608,
      "grad_norm": 0.10666390508413315,
      "learning_rate": 3.9495785677751564e-05,
      "loss": 0.0414,
      "step": 97800
    },
    {
      "epoch": 3.366227693154076,
      "grad_norm": 0.11898548156023026,
      "learning_rate": 3.948504033800541e-05,
      "loss": 0.0401,
      "step": 97900
    },
    {
      "epoch": 3.3696661279785443,
      "grad_norm": 0.11662934720516205,
      "learning_rate": 3.947429499825926e-05,
      "loss": 0.0438,
      "step": 98000
    },
    {
      "epoch": 3.373104562803012,
      "grad_norm": 0.25537368655204773,
      "learning_rate": 3.946354965851311e-05,
      "loss": 0.0441,
      "step": 98100
    },
    {
      "epoch": 3.37654299762748,
      "grad_norm": 0.18350103497505188,
      "learning_rate": 3.945280431876695e-05,
      "loss": 0.0428,
      "step": 98200
    },
    {
      "epoch": 3.379981432451948,
      "grad_norm": 0.27752885222435,
      "learning_rate": 3.9442058979020804e-05,
      "loss": 0.0415,
      "step": 98300
    },
    {
      "epoch": 3.383419867276416,
      "grad_norm": 0.3058205842971802,
      "learning_rate": 3.943131363927465e-05,
      "loss": 0.0435,
      "step": 98400
    },
    {
      "epoch": 3.3868583021008836,
      "grad_norm": 0.14222322404384613,
      "learning_rate": 3.94205682995285e-05,
      "loss": 0.0412,
      "step": 98500
    },
    {
      "epoch": 3.3902967369253516,
      "grad_norm": 0.09696386754512787,
      "learning_rate": 3.940982295978235e-05,
      "loss": 0.0416,
      "step": 98600
    },
    {
      "epoch": 3.3937351717498196,
      "grad_norm": 0.1049385815858841,
      "learning_rate": 3.939907762003619e-05,
      "loss": 0.046,
      "step": 98700
    },
    {
      "epoch": 3.3971736065742872,
      "grad_norm": 0.1645042449235916,
      "learning_rate": 3.9388332280290044e-05,
      "loss": 0.0426,
      "step": 98800
    },
    {
      "epoch": 3.4006120413987553,
      "grad_norm": 0.10262257605791092,
      "learning_rate": 3.937758694054389e-05,
      "loss": 0.0426,
      "step": 98900
    },
    {
      "epoch": 3.4040504762232233,
      "grad_norm": 0.12456602603197098,
      "learning_rate": 3.936684160079774e-05,
      "loss": 0.046,
      "step": 99000
    },
    {
      "epoch": 3.407488911047691,
      "grad_norm": 0.18467400968074799,
      "learning_rate": 3.935609626105159e-05,
      "loss": 0.0384,
      "step": 99100
    },
    {
      "epoch": 3.410927345872159,
      "grad_norm": 0.34334632754325867,
      "learning_rate": 3.934535092130543e-05,
      "loss": 0.043,
      "step": 99200
    },
    {
      "epoch": 3.414365780696627,
      "grad_norm": 0.1616184562444687,
      "learning_rate": 3.933460558155928e-05,
      "loss": 0.0444,
      "step": 99300
    },
    {
      "epoch": 3.4178042155210946,
      "grad_norm": 0.13680443167686462,
      "learning_rate": 3.932386024181313e-05,
      "loss": 0.04,
      "step": 99400
    },
    {
      "epoch": 3.4212426503455626,
      "grad_norm": 0.08732520043849945,
      "learning_rate": 3.9313114902066975e-05,
      "loss": 0.0446,
      "step": 99500
    },
    {
      "epoch": 3.4246810851700307,
      "grad_norm": 0.16412954032421112,
      "learning_rate": 3.930236956232082e-05,
      "loss": 0.0428,
      "step": 99600
    },
    {
      "epoch": 3.4281195199944987,
      "grad_norm": 0.1912776231765747,
      "learning_rate": 3.929162422257467e-05,
      "loss": 0.0399,
      "step": 99700
    },
    {
      "epoch": 3.4315579548189663,
      "grad_norm": 0.1008053719997406,
      "learning_rate": 3.928087888282852e-05,
      "loss": 0.0413,
      "step": 99800
    },
    {
      "epoch": 3.4349963896434343,
      "grad_norm": 0.10886271297931671,
      "learning_rate": 3.927013354308236e-05,
      "loss": 0.0388,
      "step": 99900
    },
    {
      "epoch": 3.4384348244679024,
      "grad_norm": 0.15878286957740784,
      "learning_rate": 3.9259388203336215e-05,
      "loss": 0.0422,
      "step": 100000
    },
    {
      "epoch": 3.44187325929237,
      "grad_norm": 0.16894090175628662,
      "learning_rate": 3.924864286359006e-05,
      "loss": 0.043,
      "step": 100100
    },
    {
      "epoch": 3.445311694116838,
      "grad_norm": 0.4944307208061218,
      "learning_rate": 3.9237897523843905e-05,
      "loss": 0.0414,
      "step": 100200
    },
    {
      "epoch": 3.448750128941306,
      "grad_norm": 0.10887064039707184,
      "learning_rate": 3.922725963749522e-05,
      "loss": 0.0434,
      "step": 100300
    },
    {
      "epoch": 3.4521885637657737,
      "grad_norm": 0.1770738810300827,
      "learning_rate": 3.921651429774907e-05,
      "loss": 0.0431,
      "step": 100400
    },
    {
      "epoch": 3.4556269985902417,
      "grad_norm": 0.14731214940547943,
      "learning_rate": 3.920576895800291e-05,
      "loss": 0.0427,
      "step": 100500
    },
    {
      "epoch": 3.4590654334147097,
      "grad_norm": 0.20505480468273163,
      "learning_rate": 3.9195023618256764e-05,
      "loss": 0.0436,
      "step": 100600
    },
    {
      "epoch": 3.4625038682391773,
      "grad_norm": 0.13693951070308685,
      "learning_rate": 3.918427827851061e-05,
      "loss": 0.0402,
      "step": 100700
    },
    {
      "epoch": 3.4659423030636454,
      "grad_norm": 0.11238101869821548,
      "learning_rate": 3.917353293876446e-05,
      "loss": 0.0427,
      "step": 100800
    },
    {
      "epoch": 3.4693807378881134,
      "grad_norm": 0.16637422144412994,
      "learning_rate": 3.916278759901831e-05,
      "loss": 0.043,
      "step": 100900
    },
    {
      "epoch": 3.4728191727125814,
      "grad_norm": 0.24759621918201447,
      "learning_rate": 3.915204225927215e-05,
      "loss": 0.0419,
      "step": 101000
    },
    {
      "epoch": 3.476257607537049,
      "grad_norm": 0.2033165842294693,
      "learning_rate": 3.9141296919526004e-05,
      "loss": 0.0401,
      "step": 101100
    },
    {
      "epoch": 3.479696042361517,
      "grad_norm": 0.15719012916088104,
      "learning_rate": 3.913055157977985e-05,
      "loss": 0.0415,
      "step": 101200
    },
    {
      "epoch": 3.483134477185985,
      "grad_norm": 0.13866019248962402,
      "learning_rate": 3.91198062400337e-05,
      "loss": 0.0422,
      "step": 101300
    },
    {
      "epoch": 3.4865729120104527,
      "grad_norm": 0.04028741270303726,
      "learning_rate": 3.910906090028755e-05,
      "loss": 0.0415,
      "step": 101400
    },
    {
      "epoch": 3.4900113468349208,
      "grad_norm": 0.14425736665725708,
      "learning_rate": 3.909831556054139e-05,
      "loss": 0.0423,
      "step": 101500
    },
    {
      "epoch": 3.493449781659389,
      "grad_norm": 0.1745479702949524,
      "learning_rate": 3.9087570220795244e-05,
      "loss": 0.0443,
      "step": 101600
    },
    {
      "epoch": 3.4968882164838564,
      "grad_norm": 0.17226065695285797,
      "learning_rate": 3.907682488104909e-05,
      "loss": 0.0434,
      "step": 101700
    },
    {
      "epoch": 3.5003266513083244,
      "grad_norm": 0.11904232203960419,
      "learning_rate": 3.906607954130294e-05,
      "loss": 0.0454,
      "step": 101800
    },
    {
      "epoch": 3.5037650861327925,
      "grad_norm": 0.2295418679714203,
      "learning_rate": 3.905533420155679e-05,
      "loss": 0.0417,
      "step": 101900
    },
    {
      "epoch": 3.50720352095726,
      "grad_norm": 0.20703424513339996,
      "learning_rate": 3.904458886181063e-05,
      "loss": 0.046,
      "step": 102000
    },
    {
      "epoch": 3.510641955781728,
      "grad_norm": 0.5758790373802185,
      "learning_rate": 3.9033843522064484e-05,
      "loss": 0.0415,
      "step": 102100
    },
    {
      "epoch": 3.514080390606196,
      "grad_norm": 0.15400093793869019,
      "learning_rate": 3.902309818231833e-05,
      "loss": 0.0395,
      "step": 102200
    },
    {
      "epoch": 3.517518825430664,
      "grad_norm": 0.09147961437702179,
      "learning_rate": 3.901235284257218e-05,
      "loss": 0.0423,
      "step": 102300
    },
    {
      "epoch": 3.520957260255132,
      "grad_norm": 0.10038585215806961,
      "learning_rate": 3.900160750282603e-05,
      "loss": 0.0439,
      "step": 102400
    },
    {
      "epoch": 3.5243956950796,
      "grad_norm": 0.1336938738822937,
      "learning_rate": 3.899086216307987e-05,
      "loss": 0.0416,
      "step": 102500
    },
    {
      "epoch": 3.5278341299040674,
      "grad_norm": 0.138637512922287,
      "learning_rate": 3.8980116823333724e-05,
      "loss": 0.0416,
      "step": 102600
    },
    {
      "epoch": 3.5312725647285355,
      "grad_norm": 0.3105789124965668,
      "learning_rate": 3.896937148358757e-05,
      "loss": 0.0375,
      "step": 102700
    },
    {
      "epoch": 3.5347109995530035,
      "grad_norm": 0.314955472946167,
      "learning_rate": 3.895862614384142e-05,
      "loss": 0.0437,
      "step": 102800
    },
    {
      "epoch": 3.5381494343774715,
      "grad_norm": 0.23111261427402496,
      "learning_rate": 3.894788080409527e-05,
      "loss": 0.0485,
      "step": 102900
    },
    {
      "epoch": 3.541587869201939,
      "grad_norm": 0.179277241230011,
      "learning_rate": 3.893724291774658e-05,
      "loss": 0.0424,
      "step": 103000
    },
    {
      "epoch": 3.545026304026407,
      "grad_norm": 0.07722112536430359,
      "learning_rate": 3.892649757800042e-05,
      "loss": 0.0436,
      "step": 103100
    },
    {
      "epoch": 3.548464738850875,
      "grad_norm": 0.08628726005554199,
      "learning_rate": 3.8915752238254274e-05,
      "loss": 0.0424,
      "step": 103200
    },
    {
      "epoch": 3.551903173675343,
      "grad_norm": 0.1929989904165268,
      "learning_rate": 3.890500689850812e-05,
      "loss": 0.0436,
      "step": 103300
    },
    {
      "epoch": 3.555341608499811,
      "grad_norm": 0.11004838347434998,
      "learning_rate": 3.889426155876197e-05,
      "loss": 0.0382,
      "step": 103400
    },
    {
      "epoch": 3.558780043324279,
      "grad_norm": 0.18058167397975922,
      "learning_rate": 3.888351621901582e-05,
      "loss": 0.0462,
      "step": 103500
    },
    {
      "epoch": 3.562218478148747,
      "grad_norm": 0.20088274776935577,
      "learning_rate": 3.887277087926966e-05,
      "loss": 0.0433,
      "step": 103600
    },
    {
      "epoch": 3.5656569129732145,
      "grad_norm": 0.13022296130657196,
      "learning_rate": 3.8862025539523514e-05,
      "loss": 0.0438,
      "step": 103700
    },
    {
      "epoch": 3.5690953477976826,
      "grad_norm": 0.24758413434028625,
      "learning_rate": 3.885128019977736e-05,
      "loss": 0.0433,
      "step": 103800
    },
    {
      "epoch": 3.57253378262215,
      "grad_norm": 0.22095175087451935,
      "learning_rate": 3.8840534860031205e-05,
      "loss": 0.0402,
      "step": 103900
    },
    {
      "epoch": 3.575972217446618,
      "grad_norm": 0.26249322295188904,
      "learning_rate": 3.882978952028506e-05,
      "loss": 0.0401,
      "step": 104000
    },
    {
      "epoch": 3.5794106522710862,
      "grad_norm": 0.2450215369462967,
      "learning_rate": 3.88190441805389e-05,
      "loss": 0.042,
      "step": 104100
    },
    {
      "epoch": 3.5828490870955543,
      "grad_norm": 0.09552702307701111,
      "learning_rate": 3.880829884079275e-05,
      "loss": 0.0411,
      "step": 104200
    },
    {
      "epoch": 3.586287521920022,
      "grad_norm": 0.16943511366844177,
      "learning_rate": 3.87975535010466e-05,
      "loss": 0.0423,
      "step": 104300
    },
    {
      "epoch": 3.58972595674449,
      "grad_norm": 0.2841964066028595,
      "learning_rate": 3.8786808161300445e-05,
      "loss": 0.0439,
      "step": 104400
    },
    {
      "epoch": 3.593164391568958,
      "grad_norm": 0.16418901085853577,
      "learning_rate": 3.877606282155429e-05,
      "loss": 0.0432,
      "step": 104500
    },
    {
      "epoch": 3.5966028263934255,
      "grad_norm": 0.16831955313682556,
      "learning_rate": 3.876531748180814e-05,
      "loss": 0.0417,
      "step": 104600
    },
    {
      "epoch": 3.6000412612178936,
      "grad_norm": 0.09537317603826523,
      "learning_rate": 3.875457214206199e-05,
      "loss": 0.0396,
      "step": 104700
    },
    {
      "epoch": 3.6034796960423616,
      "grad_norm": 0.04584725573658943,
      "learning_rate": 3.874382680231583e-05,
      "loss": 0.0359,
      "step": 104800
    },
    {
      "epoch": 3.6069181308668297,
      "grad_norm": 0.1960572749376297,
      "learning_rate": 3.8733081462569685e-05,
      "loss": 0.0394,
      "step": 104900
    },
    {
      "epoch": 3.6103565656912973,
      "grad_norm": 0.23527784645557404,
      "learning_rate": 3.872233612282353e-05,
      "loss": 0.0432,
      "step": 105000
    },
    {
      "epoch": 3.6137950005157653,
      "grad_norm": 0.16802896559238434,
      "learning_rate": 3.871159078307738e-05,
      "loss": 0.0446,
      "step": 105100
    },
    {
      "epoch": 3.617233435340233,
      "grad_norm": 0.1479083150625229,
      "learning_rate": 3.870084544333123e-05,
      "loss": 0.0421,
      "step": 105200
    },
    {
      "epoch": 3.620671870164701,
      "grad_norm": 0.13091647624969482,
      "learning_rate": 3.869010010358507e-05,
      "loss": 0.0391,
      "step": 105300
    },
    {
      "epoch": 3.624110304989169,
      "grad_norm": 0.18932263553142548,
      "learning_rate": 3.8679354763838925e-05,
      "loss": 0.041,
      "step": 105400
    },
    {
      "epoch": 3.627548739813637,
      "grad_norm": 0.0755046159029007,
      "learning_rate": 3.866860942409277e-05,
      "loss": 0.0398,
      "step": 105500
    },
    {
      "epoch": 3.6309871746381046,
      "grad_norm": 0.15802861750125885,
      "learning_rate": 3.865786408434662e-05,
      "loss": 0.042,
      "step": 105600
    },
    {
      "epoch": 3.6344256094625726,
      "grad_norm": 0.23919729888439178,
      "learning_rate": 3.864711874460047e-05,
      "loss": 0.0447,
      "step": 105700
    },
    {
      "epoch": 3.6378640442870407,
      "grad_norm": 0.18390481173992157,
      "learning_rate": 3.863637340485431e-05,
      "loss": 0.0441,
      "step": 105800
    },
    {
      "epoch": 3.6413024791115083,
      "grad_norm": 0.10571859776973724,
      "learning_rate": 3.8625628065108165e-05,
      "loss": 0.0411,
      "step": 105900
    },
    {
      "epoch": 3.6447409139359763,
      "grad_norm": 0.15031307935714722,
      "learning_rate": 3.861488272536201e-05,
      "loss": 0.0411,
      "step": 106000
    },
    {
      "epoch": 3.6481793487604444,
      "grad_norm": 0.19412574172019958,
      "learning_rate": 3.860413738561586e-05,
      "loss": 0.0416,
      "step": 106100
    },
    {
      "epoch": 3.6516177835849124,
      "grad_norm": 0.2976880371570587,
      "learning_rate": 3.859339204586971e-05,
      "loss": 0.0413,
      "step": 106200
    },
    {
      "epoch": 3.65505621840938,
      "grad_norm": 0.08831343799829483,
      "learning_rate": 3.858264670612355e-05,
      "loss": 0.0417,
      "step": 106300
    },
    {
      "epoch": 3.658494653233848,
      "grad_norm": 0.15398995578289032,
      "learning_rate": 3.8571901366377405e-05,
      "loss": 0.0409,
      "step": 106400
    },
    {
      "epoch": 3.6619330880583156,
      "grad_norm": 0.11671335250139236,
      "learning_rate": 3.856115602663125e-05,
      "loss": 0.0439,
      "step": 106500
    },
    {
      "epoch": 3.6653715228827837,
      "grad_norm": 0.11822739988565445,
      "learning_rate": 3.85504106868851e-05,
      "loss": 0.0387,
      "step": 106600
    },
    {
      "epoch": 3.6688099577072517,
      "grad_norm": 0.36681067943573,
      "learning_rate": 3.853977280053641e-05,
      "loss": 0.0415,
      "step": 106700
    },
    {
      "epoch": 3.6722483925317198,
      "grad_norm": 0.11744876205921173,
      "learning_rate": 3.852902746079026e-05,
      "loss": 0.0419,
      "step": 106800
    },
    {
      "epoch": 3.6756868273561873,
      "grad_norm": 0.16451117396354675,
      "learning_rate": 3.85182821210441e-05,
      "loss": 0.0432,
      "step": 106900
    },
    {
      "epoch": 3.6791252621806554,
      "grad_norm": 0.29372137784957886,
      "learning_rate": 3.8507536781297955e-05,
      "loss": 0.0429,
      "step": 107000
    },
    {
      "epoch": 3.6825636970051234,
      "grad_norm": 0.17804279923439026,
      "learning_rate": 3.84967914415518e-05,
      "loss": 0.0428,
      "step": 107100
    },
    {
      "epoch": 3.686002131829591,
      "grad_norm": 0.14884497225284576,
      "learning_rate": 3.848604610180565e-05,
      "loss": 0.0435,
      "step": 107200
    },
    {
      "epoch": 3.689440566654059,
      "grad_norm": 0.11316677927970886,
      "learning_rate": 3.84753007620595e-05,
      "loss": 0.0442,
      "step": 107300
    },
    {
      "epoch": 3.692879001478527,
      "grad_norm": 0.09092933684587479,
      "learning_rate": 3.846455542231334e-05,
      "loss": 0.0466,
      "step": 107400
    },
    {
      "epoch": 3.696317436302995,
      "grad_norm": 0.12985342741012573,
      "learning_rate": 3.8453810082567195e-05,
      "loss": 0.0434,
      "step": 107500
    },
    {
      "epoch": 3.6997558711274627,
      "grad_norm": 0.500065803527832,
      "learning_rate": 3.844306474282104e-05,
      "loss": 0.0394,
      "step": 107600
    },
    {
      "epoch": 3.7031943059519308,
      "grad_norm": 0.16591620445251465,
      "learning_rate": 3.843231940307489e-05,
      "loss": 0.037,
      "step": 107700
    },
    {
      "epoch": 3.7066327407763984,
      "grad_norm": 0.11305586248636246,
      "learning_rate": 3.842157406332874e-05,
      "loss": 0.0422,
      "step": 107800
    },
    {
      "epoch": 3.7100711756008664,
      "grad_norm": 0.07279361039400101,
      "learning_rate": 3.841082872358258e-05,
      "loss": 0.0424,
      "step": 107900
    },
    {
      "epoch": 3.7135096104253345,
      "grad_norm": 0.1377880722284317,
      "learning_rate": 3.8400083383836435e-05,
      "loss": 0.0425,
      "step": 108000
    },
    {
      "epoch": 3.7169480452498025,
      "grad_norm": 0.29251858592033386,
      "learning_rate": 3.838933804409028e-05,
      "loss": 0.0444,
      "step": 108100
    },
    {
      "epoch": 3.72038648007427,
      "grad_norm": 0.17188660800457,
      "learning_rate": 3.837859270434413e-05,
      "loss": 0.0402,
      "step": 108200
    },
    {
      "epoch": 3.723824914898738,
      "grad_norm": 0.5140308737754822,
      "learning_rate": 3.836784736459798e-05,
      "loss": 0.0403,
      "step": 108300
    },
    {
      "epoch": 3.7272633497232057,
      "grad_norm": 0.1416088193655014,
      "learning_rate": 3.835710202485182e-05,
      "loss": 0.0439,
      "step": 108400
    },
    {
      "epoch": 3.7307017845476738,
      "grad_norm": 0.19816555082798004,
      "learning_rate": 3.8346356685105675e-05,
      "loss": 0.0468,
      "step": 108500
    },
    {
      "epoch": 3.734140219372142,
      "grad_norm": 0.16030016541481018,
      "learning_rate": 3.833561134535952e-05,
      "loss": 0.0391,
      "step": 108600
    },
    {
      "epoch": 3.73757865419661,
      "grad_norm": 0.25456079840660095,
      "learning_rate": 3.832486600561337e-05,
      "loss": 0.0406,
      "step": 108700
    },
    {
      "epoch": 3.741017089021078,
      "grad_norm": 0.10544571280479431,
      "learning_rate": 3.831412066586722e-05,
      "loss": 0.041,
      "step": 108800
    },
    {
      "epoch": 3.7444555238455455,
      "grad_norm": 0.21103668212890625,
      "learning_rate": 3.830337532612106e-05,
      "loss": 0.0388,
      "step": 108900
    },
    {
      "epoch": 3.7478939586700135,
      "grad_norm": 0.12535424530506134,
      "learning_rate": 3.829273743977237e-05,
      "loss": 0.0436,
      "step": 109000
    },
    {
      "epoch": 3.751332393494481,
      "grad_norm": 0.09406321495771408,
      "learning_rate": 3.828199210002622e-05,
      "loss": 0.0407,
      "step": 109100
    },
    {
      "epoch": 3.754770828318949,
      "grad_norm": 0.10180144757032394,
      "learning_rate": 3.827124676028006e-05,
      "loss": 0.0398,
      "step": 109200
    },
    {
      "epoch": 3.758209263143417,
      "grad_norm": 0.26897522807121277,
      "learning_rate": 3.8260501420533915e-05,
      "loss": 0.0465,
      "step": 109300
    },
    {
      "epoch": 3.7616476979678852,
      "grad_norm": 0.23195159435272217,
      "learning_rate": 3.824975608078776e-05,
      "loss": 0.0381,
      "step": 109400
    },
    {
      "epoch": 3.765086132792353,
      "grad_norm": 0.4396868944168091,
      "learning_rate": 3.823901074104161e-05,
      "loss": 0.0412,
      "step": 109500
    },
    {
      "epoch": 3.768524567616821,
      "grad_norm": 0.30289426445961,
      "learning_rate": 3.822826540129546e-05,
      "loss": 0.0415,
      "step": 109600
    },
    {
      "epoch": 3.7719630024412885,
      "grad_norm": 0.0472751222550869,
      "learning_rate": 3.82175200615493e-05,
      "loss": 0.0397,
      "step": 109700
    },
    {
      "epoch": 3.7754014372657565,
      "grad_norm": 0.11575182527303696,
      "learning_rate": 3.8206774721803155e-05,
      "loss": 0.0441,
      "step": 109800
    },
    {
      "epoch": 3.7788398720902245,
      "grad_norm": 0.10011076182126999,
      "learning_rate": 3.8196029382057e-05,
      "loss": 0.04,
      "step": 109900
    },
    {
      "epoch": 3.7822783069146926,
      "grad_norm": 0.08128207921981812,
      "learning_rate": 3.818528404231085e-05,
      "loss": 0.0453,
      "step": 110000
    },
    {
      "epoch": 3.78571674173916,
      "grad_norm": 0.11729153990745544,
      "learning_rate": 3.81745387025647e-05,
      "loss": 0.0417,
      "step": 110100
    },
    {
      "epoch": 3.789155176563628,
      "grad_norm": 0.308329701423645,
      "learning_rate": 3.816379336281854e-05,
      "loss": 0.0433,
      "step": 110200
    },
    {
      "epoch": 3.7925936113880963,
      "grad_norm": 0.06840004771947861,
      "learning_rate": 3.8153048023072395e-05,
      "loss": 0.0459,
      "step": 110300
    },
    {
      "epoch": 3.796032046212564,
      "grad_norm": 0.08890525251626968,
      "learning_rate": 3.814230268332624e-05,
      "loss": 0.0418,
      "step": 110400
    },
    {
      "epoch": 3.799470481037032,
      "grad_norm": 0.08988366276025772,
      "learning_rate": 3.813155734358009e-05,
      "loss": 0.0454,
      "step": 110500
    },
    {
      "epoch": 3.8029089158615,
      "grad_norm": 0.18830916285514832,
      "learning_rate": 3.812081200383394e-05,
      "loss": 0.0417,
      "step": 110600
    },
    {
      "epoch": 3.806347350685968,
      "grad_norm": 0.11171754449605942,
      "learning_rate": 3.811006666408778e-05,
      "loss": 0.0431,
      "step": 110700
    },
    {
      "epoch": 3.8097857855104356,
      "grad_norm": 0.254664808511734,
      "learning_rate": 3.8099321324341635e-05,
      "loss": 0.0413,
      "step": 110800
    },
    {
      "epoch": 3.8132242203349036,
      "grad_norm": 0.23646533489227295,
      "learning_rate": 3.808857598459548e-05,
      "loss": 0.0418,
      "step": 110900
    },
    {
      "epoch": 3.816662655159371,
      "grad_norm": 0.23247642815113068,
      "learning_rate": 3.807783064484933e-05,
      "loss": 0.0379,
      "step": 111000
    },
    {
      "epoch": 3.8201010899838392,
      "grad_norm": 0.29720351099967957,
      "learning_rate": 3.806708530510318e-05,
      "loss": 0.0455,
      "step": 111100
    },
    {
      "epoch": 3.8235395248083073,
      "grad_norm": 0.11176358908414841,
      "learning_rate": 3.805633996535702e-05,
      "loss": 0.0417,
      "step": 111200
    },
    {
      "epoch": 3.8269779596327753,
      "grad_norm": 0.19182023406028748,
      "learning_rate": 3.8045594625610875e-05,
      "loss": 0.0459,
      "step": 111300
    },
    {
      "epoch": 3.830416394457243,
      "grad_norm": 0.10631216317415237,
      "learning_rate": 3.803484928586472e-05,
      "loss": 0.044,
      "step": 111400
    },
    {
      "epoch": 3.833854829281711,
      "grad_norm": 0.14558352530002594,
      "learning_rate": 3.802410394611857e-05,
      "loss": 0.0397,
      "step": 111500
    },
    {
      "epoch": 3.837293264106179,
      "grad_norm": 0.24085751175880432,
      "learning_rate": 3.801335860637242e-05,
      "loss": 0.0418,
      "step": 111600
    },
    {
      "epoch": 3.8407316989306466,
      "grad_norm": 0.13421645760536194,
      "learning_rate": 3.800261326662626e-05,
      "loss": 0.0414,
      "step": 111700
    },
    {
      "epoch": 3.8441701337551146,
      "grad_norm": 0.14127236604690552,
      "learning_rate": 3.7991867926880115e-05,
      "loss": 0.0409,
      "step": 111800
    },
    {
      "epoch": 3.8476085685795827,
      "grad_norm": 0.10274823009967804,
      "learning_rate": 3.798112258713396e-05,
      "loss": 0.0396,
      "step": 111900
    },
    {
      "epoch": 3.8510470034040507,
      "grad_norm": 0.13412725925445557,
      "learning_rate": 3.797037724738781e-05,
      "loss": 0.0379,
      "step": 112000
    },
    {
      "epoch": 3.8544854382285183,
      "grad_norm": 0.11398301273584366,
      "learning_rate": 3.795963190764166e-05,
      "loss": 0.0402,
      "step": 112100
    },
    {
      "epoch": 3.8579238730529863,
      "grad_norm": 0.12340451031923294,
      "learning_rate": 3.79488865678955e-05,
      "loss": 0.041,
      "step": 112200
    },
    {
      "epoch": 3.861362307877454,
      "grad_norm": 0.16017651557922363,
      "learning_rate": 3.7938141228149355e-05,
      "loss": 0.0413,
      "step": 112300
    },
    {
      "epoch": 3.864800742701922,
      "grad_norm": 0.15022222697734833,
      "learning_rate": 3.79273958884032e-05,
      "loss": 0.0413,
      "step": 112400
    },
    {
      "epoch": 3.86823917752639,
      "grad_norm": 0.3343394100666046,
      "learning_rate": 3.791665054865705e-05,
      "loss": 0.0406,
      "step": 112500
    },
    {
      "epoch": 3.871677612350858,
      "grad_norm": 0.13906553387641907,
      "learning_rate": 3.79059052089109e-05,
      "loss": 0.0409,
      "step": 112600
    },
    {
      "epoch": 3.8751160471753257,
      "grad_norm": 0.05231733247637749,
      "learning_rate": 3.789515986916474e-05,
      "loss": 0.041,
      "step": 112700
    },
    {
      "epoch": 3.8785544819997937,
      "grad_norm": 0.15664352476596832,
      "learning_rate": 3.7884414529418595e-05,
      "loss": 0.041,
      "step": 112800
    },
    {
      "epoch": 3.8819929168242617,
      "grad_norm": 0.19833612442016602,
      "learning_rate": 3.787366918967244e-05,
      "loss": 0.0405,
      "step": 112900
    },
    {
      "epoch": 3.8854313516487293,
      "grad_norm": 0.14664559066295624,
      "learning_rate": 3.786292384992629e-05,
      "loss": 0.0447,
      "step": 113000
    },
    {
      "epoch": 3.8888697864731974,
      "grad_norm": 0.1088060662150383,
      "learning_rate": 3.78522859635776e-05,
      "loss": 0.0388,
      "step": 113100
    },
    {
      "epoch": 3.8923082212976654,
      "grad_norm": 0.1528611183166504,
      "learning_rate": 3.784154062383145e-05,
      "loss": 0.0432,
      "step": 113200
    },
    {
      "epoch": 3.8957466561221334,
      "grad_norm": 0.36193910241127014,
      "learning_rate": 3.78307952840853e-05,
      "loss": 0.0467,
      "step": 113300
    },
    {
      "epoch": 3.899185090946601,
      "grad_norm": 0.16209296882152557,
      "learning_rate": 3.7820049944339145e-05,
      "loss": 0.0439,
      "step": 113400
    },
    {
      "epoch": 3.902623525771069,
      "grad_norm": 0.09019017964601517,
      "learning_rate": 3.780930460459299e-05,
      "loss": 0.0413,
      "step": 113500
    },
    {
      "epoch": 3.9060619605955367,
      "grad_norm": 0.17154961824417114,
      "learning_rate": 3.779855926484684e-05,
      "loss": 0.0385,
      "step": 113600
    },
    {
      "epoch": 3.9095003954200047,
      "grad_norm": 0.2353275716304779,
      "learning_rate": 3.778781392510069e-05,
      "loss": 0.0403,
      "step": 113700
    },
    {
      "epoch": 3.9129388302444728,
      "grad_norm": 0.34182798862457275,
      "learning_rate": 3.777706858535453e-05,
      "loss": 0.0389,
      "step": 113800
    },
    {
      "epoch": 3.916377265068941,
      "grad_norm": 0.36570456624031067,
      "learning_rate": 3.7766323245608385e-05,
      "loss": 0.0428,
      "step": 113900
    },
    {
      "epoch": 3.9198156998934084,
      "grad_norm": 0.108917735517025,
      "learning_rate": 3.775557790586223e-05,
      "loss": 0.0379,
      "step": 114000
    },
    {
      "epoch": 3.9232541347178764,
      "grad_norm": 0.17856205999851227,
      "learning_rate": 3.7744832566116075e-05,
      "loss": 0.0386,
      "step": 114100
    },
    {
      "epoch": 3.9266925695423445,
      "grad_norm": 0.12112843245267868,
      "learning_rate": 3.773408722636993e-05,
      "loss": 0.0439,
      "step": 114200
    },
    {
      "epoch": 3.930131004366812,
      "grad_norm": 0.14287877082824707,
      "learning_rate": 3.772334188662377e-05,
      "loss": 0.0402,
      "step": 114300
    },
    {
      "epoch": 3.93356943919128,
      "grad_norm": 0.0723111629486084,
      "learning_rate": 3.771259654687762e-05,
      "loss": 0.0399,
      "step": 114400
    },
    {
      "epoch": 3.937007874015748,
      "grad_norm": 0.25307929515838623,
      "learning_rate": 3.770185120713147e-05,
      "loss": 0.0412,
      "step": 114500
    },
    {
      "epoch": 3.940446308840216,
      "grad_norm": 0.08414503186941147,
      "learning_rate": 3.7691105867385315e-05,
      "loss": 0.0438,
      "step": 114600
    },
    {
      "epoch": 3.943884743664684,
      "grad_norm": 0.14886628091335297,
      "learning_rate": 3.768036052763916e-05,
      "loss": 0.0414,
      "step": 114700
    },
    {
      "epoch": 3.947323178489152,
      "grad_norm": 0.23518094420433044,
      "learning_rate": 3.766972264129047e-05,
      "loss": 0.0411,
      "step": 114800
    },
    {
      "epoch": 3.9507616133136194,
      "grad_norm": 0.348743736743927,
      "learning_rate": 3.765897730154432e-05,
      "loss": 0.0403,
      "step": 114900
    },
    {
      "epoch": 3.9542000481380875,
      "grad_norm": 0.058193087577819824,
      "learning_rate": 3.764823196179817e-05,
      "loss": 0.0427,
      "step": 115000
    },
    {
      "epoch": 3.9576384829625555,
      "grad_norm": 0.19745634496212006,
      "learning_rate": 3.763748662205202e-05,
      "loss": 0.0456,
      "step": 115100
    },
    {
      "epoch": 3.9610769177870235,
      "grad_norm": 0.30506575107574463,
      "learning_rate": 3.7626741282305865e-05,
      "loss": 0.0414,
      "step": 115200
    },
    {
      "epoch": 3.964515352611491,
      "grad_norm": 0.08414871990680695,
      "learning_rate": 3.761599594255971e-05,
      "loss": 0.0421,
      "step": 115300
    },
    {
      "epoch": 3.967953787435959,
      "grad_norm": 0.26172804832458496,
      "learning_rate": 3.760525060281356e-05,
      "loss": 0.0432,
      "step": 115400
    },
    {
      "epoch": 3.971392222260427,
      "grad_norm": 0.1093626618385315,
      "learning_rate": 3.759450526306741e-05,
      "loss": 0.0415,
      "step": 115500
    },
    {
      "epoch": 3.974830657084895,
      "grad_norm": 0.1453622430562973,
      "learning_rate": 3.758386737671872e-05,
      "loss": 0.0408,
      "step": 115600
    },
    {
      "epoch": 3.978269091909363,
      "grad_norm": 0.08487558364868164,
      "learning_rate": 3.757312203697257e-05,
      "loss": 0.039,
      "step": 115700
    },
    {
      "epoch": 3.981707526733831,
      "grad_norm": 0.13219594955444336,
      "learning_rate": 3.7562376697226415e-05,
      "loss": 0.0399,
      "step": 115800
    },
    {
      "epoch": 3.985145961558299,
      "grad_norm": 0.19947470724582672,
      "learning_rate": 3.755163135748026e-05,
      "loss": 0.0367,
      "step": 115900
    },
    {
      "epoch": 3.9885843963827665,
      "grad_norm": 0.10003221035003662,
      "learning_rate": 3.754088601773411e-05,
      "loss": 0.0401,
      "step": 116000
    },
    {
      "epoch": 3.9920228312072346,
      "grad_norm": 0.15218397974967957,
      "learning_rate": 3.753014067798796e-05,
      "loss": 0.0422,
      "step": 116100
    },
    {
      "epoch": 3.995461266031702,
      "grad_norm": 0.16474398970603943,
      "learning_rate": 3.751939533824181e-05,
      "loss": 0.0434,
      "step": 116200
    },
    {
      "epoch": 3.99889970085617,
      "grad_norm": 0.08344074338674545,
      "learning_rate": 3.7508649998495655e-05,
      "loss": 0.0398,
      "step": 116300
    },
    {
      "epoch": 4.0,
      "eval_accuracy_macro_0.5": 0.9828732013702393,
      "eval_accuracy_micro_0.5": 0.982873260974884,
      "eval_accuracy_weighted_0.5": 0.9716916084289551,
      "eval_aucroc_macro": 0.8980076909065247,
      "eval_aucroc_micro": 0.9062056541442871,
      "eval_aucroc_weighted": 0.9023030400276184,
      "eval_f1_macro_0.5": 0.7250716090202332,
      "eval_f1_macro_0.6": 0.6981790065765381,
      "eval_f1_macro_0.7": 0.6539167761802673,
      "eval_f1_macro_0.8": 0.46112748980522156,
      "eval_f1_micro_0.5": 0.7455812692642212,
      "eval_f1_micro_0.6": 0.7262109518051147,
      "eval_f1_micro_0.7": 0.689734697341919,
      "eval_f1_micro_0.8": 0.6247643232345581,
      "eval_f1_micro_0.9": 0.48798611760139465,
      "eval_f1_weighted_0.5": 0.736722469329834,
      "eval_f1_weighted_0.6": 0.7114654779434204,
      "eval_f1_weighted_0.7": 0.6669408679008484,
      "eval_f1_weighted_0.8": 0.4466066062450409,
      "eval_loss": 0.03768959268927574,
      "eval_runtime": 2070.1657,
      "eval_samples_per_second": 28.081,
      "eval_steps_per_second": 3.51,
      "step": 116332
    },
    {
      "epoch": 4.002338135680638,
      "grad_norm": 0.20116853713989258,
      "learning_rate": 3.74979046587495e-05,
      "loss": 0.0361,
      "step": 116400
    },
    {
      "epoch": 4.005776570505106,
      "grad_norm": 0.1528819501399994,
      "learning_rate": 3.748715931900335e-05,
      "loss": 0.0401,
      "step": 116500
    },
    {
      "epoch": 4.009215005329574,
      "grad_norm": 0.43272367119789124,
      "learning_rate": 3.74764139792572e-05,
      "loss": 0.0412,
      "step": 116600
    },
    {
      "epoch": 4.0126534401540415,
      "grad_norm": 0.30832356214523315,
      "learning_rate": 3.746566863951105e-05,
      "loss": 0.039,
      "step": 116700
    },
    {
      "epoch": 4.0160918749785095,
      "grad_norm": 0.1908552497625351,
      "learning_rate": 3.7454923299764895e-05,
      "loss": 0.0402,
      "step": 116800
    },
    {
      "epoch": 4.0195303098029775,
      "grad_norm": 0.20039281249046326,
      "learning_rate": 3.744417796001874e-05,
      "loss": 0.0448,
      "step": 116900
    },
    {
      "epoch": 4.022968744627446,
      "grad_norm": 0.13207019865512848,
      "learning_rate": 3.743343262027259e-05,
      "loss": 0.042,
      "step": 117000
    },
    {
      "epoch": 4.026407179451914,
      "grad_norm": 0.11233564466238022,
      "learning_rate": 3.742268728052644e-05,
      "loss": 0.0403,
      "step": 117100
    },
    {
      "epoch": 4.029845614276382,
      "grad_norm": 0.21168068051338196,
      "learning_rate": 3.741194194078029e-05,
      "loss": 0.0422,
      "step": 117200
    },
    {
      "epoch": 4.03328404910085,
      "grad_norm": 0.19758738577365875,
      "learning_rate": 3.7401196601034135e-05,
      "loss": 0.0395,
      "step": 117300
    },
    {
      "epoch": 4.036722483925317,
      "grad_norm": 0.256904274225235,
      "learning_rate": 3.739045126128798e-05,
      "loss": 0.0381,
      "step": 117400
    },
    {
      "epoch": 4.040160918749785,
      "grad_norm": 0.04919906333088875,
      "learning_rate": 3.737970592154183e-05,
      "loss": 0.0421,
      "step": 117500
    },
    {
      "epoch": 4.043599353574253,
      "grad_norm": 0.3395371735095978,
      "learning_rate": 3.736896058179568e-05,
      "loss": 0.0393,
      "step": 117600
    },
    {
      "epoch": 4.047037788398721,
      "grad_norm": 0.12279345840215683,
      "learning_rate": 3.735821524204953e-05,
      "loss": 0.0413,
      "step": 117700
    },
    {
      "epoch": 4.050476223223189,
      "grad_norm": 0.1469445377588272,
      "learning_rate": 3.7347469902303375e-05,
      "loss": 0.0441,
      "step": 117800
    },
    {
      "epoch": 4.053914658047657,
      "grad_norm": 0.37239816784858704,
      "learning_rate": 3.733672456255722e-05,
      "loss": 0.0386,
      "step": 117900
    },
    {
      "epoch": 4.057353092872124,
      "grad_norm": 0.12599430978298187,
      "learning_rate": 3.732597922281107e-05,
      "loss": 0.0359,
      "step": 118000
    },
    {
      "epoch": 4.060791527696592,
      "grad_norm": 0.15398487448692322,
      "learning_rate": 3.731523388306492e-05,
      "loss": 0.0399,
      "step": 118100
    },
    {
      "epoch": 4.06422996252106,
      "grad_norm": 0.22978395223617554,
      "learning_rate": 3.730448854331877e-05,
      "loss": 0.0389,
      "step": 118200
    },
    {
      "epoch": 4.067668397345528,
      "grad_norm": 0.15292853116989136,
      "learning_rate": 3.7293743203572615e-05,
      "loss": 0.0396,
      "step": 118300
    },
    {
      "epoch": 4.071106832169996,
      "grad_norm": 0.1328374743461609,
      "learning_rate": 3.728299786382646e-05,
      "loss": 0.0389,
      "step": 118400
    },
    {
      "epoch": 4.074545266994464,
      "grad_norm": 0.2559749484062195,
      "learning_rate": 3.727225252408031e-05,
      "loss": 0.0403,
      "step": 118500
    },
    {
      "epoch": 4.077983701818932,
      "grad_norm": 0.07280004024505615,
      "learning_rate": 3.726150718433416e-05,
      "loss": 0.0377,
      "step": 118600
    },
    {
      "epoch": 4.0814221366434,
      "grad_norm": 0.12731531262397766,
      "learning_rate": 3.7250761844588e-05,
      "loss": 0.0412,
      "step": 118700
    },
    {
      "epoch": 4.084860571467868,
      "grad_norm": 0.20255573093891144,
      "learning_rate": 3.7240016504841855e-05,
      "loss": 0.0405,
      "step": 118800
    },
    {
      "epoch": 4.088299006292336,
      "grad_norm": 0.16145241260528564,
      "learning_rate": 3.72292711650957e-05,
      "loss": 0.0407,
      "step": 118900
    },
    {
      "epoch": 4.091737441116804,
      "grad_norm": 0.07192032784223557,
      "learning_rate": 3.7218525825349545e-05,
      "loss": 0.0394,
      "step": 119000
    },
    {
      "epoch": 4.095175875941272,
      "grad_norm": 0.4121856689453125,
      "learning_rate": 3.720778048560339e-05,
      "loss": 0.0406,
      "step": 119100
    },
    {
      "epoch": 4.09861431076574,
      "grad_norm": 0.13815438747406006,
      "learning_rate": 3.719703514585724e-05,
      "loss": 0.0405,
      "step": 119200
    },
    {
      "epoch": 4.102052745590207,
      "grad_norm": 0.2996186912059784,
      "learning_rate": 3.718628980611109e-05,
      "loss": 0.0386,
      "step": 119300
    },
    {
      "epoch": 4.105491180414675,
      "grad_norm": 0.19330209493637085,
      "learning_rate": 3.717554446636493e-05,
      "loss": 0.043,
      "step": 119400
    },
    {
      "epoch": 4.108929615239143,
      "grad_norm": 0.12842945754528046,
      "learning_rate": 3.7164799126618785e-05,
      "loss": 0.0401,
      "step": 119500
    },
    {
      "epoch": 4.112368050063611,
      "grad_norm": 0.27342331409454346,
      "learning_rate": 3.715405378687263e-05,
      "loss": 0.0397,
      "step": 119600
    },
    {
      "epoch": 4.115806484888079,
      "grad_norm": 0.21672014892101288,
      "learning_rate": 3.714330844712648e-05,
      "loss": 0.0383,
      "step": 119700
    },
    {
      "epoch": 4.119244919712547,
      "grad_norm": 0.16420698165893555,
      "learning_rate": 3.713256310738033e-05,
      "loss": 0.037,
      "step": 119800
    },
    {
      "epoch": 4.122683354537015,
      "grad_norm": 0.20912349224090576,
      "learning_rate": 3.7121817767634173e-05,
      "loss": 0.0399,
      "step": 119900
    },
    {
      "epoch": 4.126121789361482,
      "grad_norm": 0.08291551470756531,
      "learning_rate": 3.7111072427888025e-05,
      "loss": 0.0422,
      "step": 120000
    },
    {
      "epoch": 4.12956022418595,
      "grad_norm": 0.08388017863035202,
      "learning_rate": 3.710032708814187e-05,
      "loss": 0.038,
      "step": 120100
    },
    {
      "epoch": 4.132998659010418,
      "grad_norm": 0.6285947561264038,
      "learning_rate": 3.708958174839572e-05,
      "loss": 0.0412,
      "step": 120200
    },
    {
      "epoch": 4.1364370938348864,
      "grad_norm": 0.12985195219516754,
      "learning_rate": 3.707883640864957e-05,
      "loss": 0.0357,
      "step": 120300
    },
    {
      "epoch": 4.1398755286593545,
      "grad_norm": 0.2591918408870697,
      "learning_rate": 3.706809106890342e-05,
      "loss": 0.0404,
      "step": 120400
    },
    {
      "epoch": 4.1433139634838225,
      "grad_norm": 0.26507583260536194,
      "learning_rate": 3.7057345729157265e-05,
      "loss": 0.0389,
      "step": 120500
    },
    {
      "epoch": 4.14675239830829,
      "grad_norm": 0.08039010316133499,
      "learning_rate": 3.7046707842808575e-05,
      "loss": 0.0379,
      "step": 120600
    },
    {
      "epoch": 4.150190833132758,
      "grad_norm": 0.2445317655801773,
      "learning_rate": 3.703596250306242e-05,
      "loss": 0.0407,
      "step": 120700
    },
    {
      "epoch": 4.153629267957226,
      "grad_norm": 0.1857737898826599,
      "learning_rate": 3.702521716331627e-05,
      "loss": 0.0391,
      "step": 120800
    },
    {
      "epoch": 4.157067702781694,
      "grad_norm": 0.10417928546667099,
      "learning_rate": 3.701447182357012e-05,
      "loss": 0.0393,
      "step": 120900
    },
    {
      "epoch": 4.160506137606162,
      "grad_norm": 0.17220041155815125,
      "learning_rate": 3.700372648382397e-05,
      "loss": 0.0385,
      "step": 121000
    },
    {
      "epoch": 4.16394457243063,
      "grad_norm": 0.1957331895828247,
      "learning_rate": 3.6992981144077815e-05,
      "loss": 0.0361,
      "step": 121100
    },
    {
      "epoch": 4.167383007255097,
      "grad_norm": 0.1266251504421234,
      "learning_rate": 3.698223580433166e-05,
      "loss": 0.0374,
      "step": 121200
    },
    {
      "epoch": 4.170821442079565,
      "grad_norm": 0.25358060002326965,
      "learning_rate": 3.697149046458551e-05,
      "loss": 0.0405,
      "step": 121300
    },
    {
      "epoch": 4.174259876904033,
      "grad_norm": 0.30977165699005127,
      "learning_rate": 3.696074512483936e-05,
      "loss": 0.0381,
      "step": 121400
    },
    {
      "epoch": 4.177698311728501,
      "grad_norm": 0.11794997751712799,
      "learning_rate": 3.694999978509321e-05,
      "loss": 0.0442,
      "step": 121500
    },
    {
      "epoch": 4.181136746552969,
      "grad_norm": 0.09391262382268906,
      "learning_rate": 3.6939254445347055e-05,
      "loss": 0.0408,
      "step": 121600
    },
    {
      "epoch": 4.184575181377437,
      "grad_norm": 0.1265684813261032,
      "learning_rate": 3.69285091056009e-05,
      "loss": 0.0378,
      "step": 121700
    },
    {
      "epoch": 4.188013616201905,
      "grad_norm": 0.3029537796974182,
      "learning_rate": 3.691776376585475e-05,
      "loss": 0.0413,
      "step": 121800
    },
    {
      "epoch": 4.191452051026372,
      "grad_norm": 0.0931638553738594,
      "learning_rate": 3.69070184261086e-05,
      "loss": 0.0388,
      "step": 121900
    },
    {
      "epoch": 4.1948904858508405,
      "grad_norm": 0.22347533702850342,
      "learning_rate": 3.689627308636245e-05,
      "loss": 0.0427,
      "step": 122000
    },
    {
      "epoch": 4.1983289206753085,
      "grad_norm": 0.17942681908607483,
      "learning_rate": 3.688563520001376e-05,
      "loss": 0.0422,
      "step": 122100
    },
    {
      "epoch": 4.2017673554997765,
      "grad_norm": 0.08241020143032074,
      "learning_rate": 3.6874889860267605e-05,
      "loss": 0.0396,
      "step": 122200
    },
    {
      "epoch": 4.205205790324245,
      "grad_norm": 0.13159674406051636,
      "learning_rate": 3.686414452052146e-05,
      "loss": 0.0417,
      "step": 122300
    },
    {
      "epoch": 4.208644225148713,
      "grad_norm": 0.16837134957313538,
      "learning_rate": 3.68533991807753e-05,
      "loss": 0.0411,
      "step": 122400
    },
    {
      "epoch": 4.212082659973181,
      "grad_norm": 0.10646423697471619,
      "learning_rate": 3.684265384102915e-05,
      "loss": 0.0386,
      "step": 122500
    },
    {
      "epoch": 4.215521094797648,
      "grad_norm": 0.3818374276161194,
      "learning_rate": 3.6831908501283e-05,
      "loss": 0.0421,
      "step": 122600
    },
    {
      "epoch": 4.218959529622116,
      "grad_norm": 0.07923916727304459,
      "learning_rate": 3.6821163161536845e-05,
      "loss": 0.0384,
      "step": 122700
    },
    {
      "epoch": 4.222397964446584,
      "grad_norm": 0.1492481380701065,
      "learning_rate": 3.68104178217907e-05,
      "loss": 0.0386,
      "step": 122800
    },
    {
      "epoch": 4.225836399271052,
      "grad_norm": 0.2074127197265625,
      "learning_rate": 3.679967248204454e-05,
      "loss": 0.0421,
      "step": 122900
    },
    {
      "epoch": 4.22927483409552,
      "grad_norm": 0.3369643986225128,
      "learning_rate": 3.678892714229839e-05,
      "loss": 0.0406,
      "step": 123000
    },
    {
      "epoch": 4.232713268919988,
      "grad_norm": 0.2271353006362915,
      "learning_rate": 3.677818180255224e-05,
      "loss": 0.0369,
      "step": 123100
    },
    {
      "epoch": 4.236151703744455,
      "grad_norm": 0.19816316664218903,
      "learning_rate": 3.6767436462806085e-05,
      "loss": 0.0413,
      "step": 123200
    },
    {
      "epoch": 4.239590138568923,
      "grad_norm": 0.08094300329685211,
      "learning_rate": 3.675669112305993e-05,
      "loss": 0.0368,
      "step": 123300
    },
    {
      "epoch": 4.243028573393391,
      "grad_norm": 0.22291335463523865,
      "learning_rate": 3.6745945783313775e-05,
      "loss": 0.04,
      "step": 123400
    },
    {
      "epoch": 4.246467008217859,
      "grad_norm": 0.172465518116951,
      "learning_rate": 3.673520044356763e-05,
      "loss": 0.0398,
      "step": 123500
    },
    {
      "epoch": 4.249905443042327,
      "grad_norm": 0.5670657157897949,
      "learning_rate": 3.672445510382147e-05,
      "loss": 0.0445,
      "step": 123600
    },
    {
      "epoch": 4.253343877866795,
      "grad_norm": 0.1514502465724945,
      "learning_rate": 3.671370976407532e-05,
      "loss": 0.0396,
      "step": 123700
    },
    {
      "epoch": 4.2567823126912625,
      "grad_norm": 0.39539775252342224,
      "learning_rate": 3.670296442432917e-05,
      "loss": 0.0432,
      "step": 123800
    },
    {
      "epoch": 4.2602207475157305,
      "grad_norm": 0.09587173163890839,
      "learning_rate": 3.6692219084583015e-05,
      "loss": 0.0381,
      "step": 123900
    },
    {
      "epoch": 4.263659182340199,
      "grad_norm": 0.15096253156661987,
      "learning_rate": 3.668147374483686e-05,
      "loss": 0.0404,
      "step": 124000
    },
    {
      "epoch": 4.267097617164667,
      "grad_norm": 0.5039681196212769,
      "learning_rate": 3.667072840509071e-05,
      "loss": 0.0415,
      "step": 124100
    },
    {
      "epoch": 4.270536051989135,
      "grad_norm": 0.22831694781780243,
      "learning_rate": 3.666009051874202e-05,
      "loss": 0.0381,
      "step": 124200
    },
    {
      "epoch": 4.273974486813603,
      "grad_norm": 0.251407265663147,
      "learning_rate": 3.664934517899587e-05,
      "loss": 0.0405,
      "step": 124300
    },
    {
      "epoch": 4.277412921638071,
      "grad_norm": 0.14480452239513397,
      "learning_rate": 3.663859983924972e-05,
      "loss": 0.0425,
      "step": 124400
    },
    {
      "epoch": 4.280851356462538,
      "grad_norm": 0.17141908407211304,
      "learning_rate": 3.6627854499503565e-05,
      "loss": 0.0397,
      "step": 124500
    },
    {
      "epoch": 4.284289791287006,
      "grad_norm": 0.13464970886707306,
      "learning_rate": 3.661710915975741e-05,
      "loss": 0.0432,
      "step": 124600
    },
    {
      "epoch": 4.287728226111474,
      "grad_norm": 0.17868328094482422,
      "learning_rate": 3.660636382001126e-05,
      "loss": 0.0427,
      "step": 124700
    },
    {
      "epoch": 4.291166660935942,
      "grad_norm": 0.08335258066654205,
      "learning_rate": 3.659561848026511e-05,
      "loss": 0.0398,
      "step": 124800
    },
    {
      "epoch": 4.29460509576041,
      "grad_norm": 0.23470550775527954,
      "learning_rate": 3.658487314051896e-05,
      "loss": 0.0385,
      "step": 124900
    },
    {
      "epoch": 4.298043530584878,
      "grad_norm": 0.11902379989624023,
      "learning_rate": 3.6574127800772805e-05,
      "loss": 0.0416,
      "step": 125000
    },
    {
      "epoch": 4.301481965409346,
      "grad_norm": 0.10045737028121948,
      "learning_rate": 3.656338246102665e-05,
      "loss": 0.0413,
      "step": 125100
    },
    {
      "epoch": 4.304920400233813,
      "grad_norm": 0.13744519650936127,
      "learning_rate": 3.65526371212805e-05,
      "loss": 0.0415,
      "step": 125200
    },
    {
      "epoch": 4.308358835058281,
      "grad_norm": 0.23039822280406952,
      "learning_rate": 3.654189178153435e-05,
      "loss": 0.0359,
      "step": 125300
    },
    {
      "epoch": 4.311797269882749,
      "grad_norm": 0.17191511392593384,
      "learning_rate": 3.65311464417882e-05,
      "loss": 0.0405,
      "step": 125400
    },
    {
      "epoch": 4.315235704707217,
      "grad_norm": 0.5462591052055359,
      "learning_rate": 3.6520401102042045e-05,
      "loss": 0.0385,
      "step": 125500
    },
    {
      "epoch": 4.318674139531685,
      "grad_norm": 0.23138190805912018,
      "learning_rate": 3.65096557622959e-05,
      "loss": 0.0386,
      "step": 125600
    },
    {
      "epoch": 4.3221125743561535,
      "grad_norm": 0.20311929285526276,
      "learning_rate": 3.649891042254974e-05,
      "loss": 0.0401,
      "step": 125700
    },
    {
      "epoch": 4.325551009180621,
      "grad_norm": 0.48664477467536926,
      "learning_rate": 3.648816508280359e-05,
      "loss": 0.043,
      "step": 125800
    },
    {
      "epoch": 4.328989444005089,
      "grad_norm": 0.056781575083732605,
      "learning_rate": 3.647741974305744e-05,
      "loss": 0.0411,
      "step": 125900
    },
    {
      "epoch": 4.332427878829557,
      "grad_norm": 0.13882935047149658,
      "learning_rate": 3.6466674403311285e-05,
      "loss": 0.0394,
      "step": 126000
    },
    {
      "epoch": 4.335866313654025,
      "grad_norm": 0.13675473630428314,
      "learning_rate": 3.645592906356514e-05,
      "loss": 0.0395,
      "step": 126100
    },
    {
      "epoch": 4.339304748478493,
      "grad_norm": 0.1457841843366623,
      "learning_rate": 3.644518372381898e-05,
      "loss": 0.0388,
      "step": 126200
    },
    {
      "epoch": 4.342743183302961,
      "grad_norm": 0.10520117729902267,
      "learning_rate": 3.643443838407283e-05,
      "loss": 0.0424,
      "step": 126300
    },
    {
      "epoch": 4.346181618127428,
      "grad_norm": 0.13194489479064941,
      "learning_rate": 3.642369304432668e-05,
      "loss": 0.0413,
      "step": 126400
    },
    {
      "epoch": 4.349620052951896,
      "grad_norm": 0.10496336966753006,
      "learning_rate": 3.6412947704580525e-05,
      "loss": 0.0401,
      "step": 126500
    },
    {
      "epoch": 4.353058487776364,
      "grad_norm": 0.18690301477909088,
      "learning_rate": 3.640220236483438e-05,
      "loss": 0.0399,
      "step": 126600
    },
    {
      "epoch": 4.356496922600832,
      "grad_norm": 0.2624734342098236,
      "learning_rate": 3.639145702508822e-05,
      "loss": 0.0358,
      "step": 126700
    },
    {
      "epoch": 4.3599353574253,
      "grad_norm": 0.40845632553100586,
      "learning_rate": 3.638071168534207e-05,
      "loss": 0.0433,
      "step": 126800
    },
    {
      "epoch": 4.363373792249768,
      "grad_norm": 0.27472975850105286,
      "learning_rate": 3.636996634559592e-05,
      "loss": 0.0377,
      "step": 126900
    },
    {
      "epoch": 4.366812227074236,
      "grad_norm": 0.15811040997505188,
      "learning_rate": 3.6359221005849765e-05,
      "loss": 0.0403,
      "step": 127000
    },
    {
      "epoch": 4.370250661898703,
      "grad_norm": 0.3903219699859619,
      "learning_rate": 3.634847566610362e-05,
      "loss": 0.0417,
      "step": 127100
    },
    {
      "epoch": 4.373689096723171,
      "grad_norm": 0.22879886627197266,
      "learning_rate": 3.633773032635746e-05,
      "loss": 0.0407,
      "step": 127200
    },
    {
      "epoch": 4.3771275315476394,
      "grad_norm": 0.14054463803768158,
      "learning_rate": 3.632698498661131e-05,
      "loss": 0.0386,
      "step": 127300
    },
    {
      "epoch": 4.3805659663721075,
      "grad_norm": 0.18859505653381348,
      "learning_rate": 3.631623964686516e-05,
      "loss": 0.04,
      "step": 127400
    },
    {
      "epoch": 4.3840044011965755,
      "grad_norm": 0.5043140053749084,
      "learning_rate": 3.6305494307119005e-05,
      "loss": 0.0438,
      "step": 127500
    },
    {
      "epoch": 4.387442836021044,
      "grad_norm": 0.29712942242622375,
      "learning_rate": 3.629474896737286e-05,
      "loss": 0.0373,
      "step": 127600
    },
    {
      "epoch": 4.390881270845511,
      "grad_norm": 0.2841683030128479,
      "learning_rate": 3.62840036276267e-05,
      "loss": 0.0409,
      "step": 127700
    },
    {
      "epoch": 4.394319705669979,
      "grad_norm": 0.19523979723453522,
      "learning_rate": 3.627325828788055e-05,
      "loss": 0.0394,
      "step": 127800
    },
    {
      "epoch": 4.397758140494447,
      "grad_norm": 0.07849930226802826,
      "learning_rate": 3.62625129481344e-05,
      "loss": 0.0391,
      "step": 127900
    },
    {
      "epoch": 4.401196575318915,
      "grad_norm": 0.07447298616170883,
      "learning_rate": 3.6251767608388245e-05,
      "loss": 0.0357,
      "step": 128000
    },
    {
      "epoch": 4.404635010143383,
      "grad_norm": 0.1069328710436821,
      "learning_rate": 3.62410222686421e-05,
      "loss": 0.0428,
      "step": 128100
    },
    {
      "epoch": 4.408073444967851,
      "grad_norm": 0.3019959628582001,
      "learning_rate": 3.623027692889594e-05,
      "loss": 0.0456,
      "step": 128200
    },
    {
      "epoch": 4.411511879792318,
      "grad_norm": 0.2502041161060333,
      "learning_rate": 3.6219639042547246e-05,
      "loss": 0.0406,
      "step": 128300
    },
    {
      "epoch": 4.414950314616786,
      "grad_norm": 0.12519751489162445,
      "learning_rate": 3.62088937028011e-05,
      "loss": 0.0422,
      "step": 128400
    },
    {
      "epoch": 4.418388749441254,
      "grad_norm": 0.29308652877807617,
      "learning_rate": 3.619814836305494e-05,
      "loss": 0.0399,
      "step": 128500
    },
    {
      "epoch": 4.421827184265722,
      "grad_norm": 0.1558796465396881,
      "learning_rate": 3.618740302330879e-05,
      "loss": 0.0373,
      "step": 128600
    },
    {
      "epoch": 4.42526561909019,
      "grad_norm": 0.1887921243906021,
      "learning_rate": 3.617665768356264e-05,
      "loss": 0.0349,
      "step": 128700
    },
    {
      "epoch": 4.428704053914658,
      "grad_norm": 0.2211243361234665,
      "learning_rate": 3.6165912343816486e-05,
      "loss": 0.0388,
      "step": 128800
    },
    {
      "epoch": 4.432142488739126,
      "grad_norm": 0.1731952428817749,
      "learning_rate": 3.615516700407033e-05,
      "loss": 0.0408,
      "step": 128900
    },
    {
      "epoch": 4.4355809235635935,
      "grad_norm": 0.22459326684474945,
      "learning_rate": 3.614442166432418e-05,
      "loss": 0.038,
      "step": 129000
    },
    {
      "epoch": 4.4390193583880615,
      "grad_norm": 0.12845729291439056,
      "learning_rate": 3.613367632457803e-05,
      "loss": 0.0436,
      "step": 129100
    },
    {
      "epoch": 4.4424577932125295,
      "grad_norm": 0.3957928717136383,
      "learning_rate": 3.612293098483188e-05,
      "loss": 0.0416,
      "step": 129200
    },
    {
      "epoch": 4.445896228036998,
      "grad_norm": 0.19268490374088287,
      "learning_rate": 3.6112185645085726e-05,
      "loss": 0.0379,
      "step": 129300
    },
    {
      "epoch": 4.449334662861466,
      "grad_norm": 0.40641167759895325,
      "learning_rate": 3.610144030533957e-05,
      "loss": 0.0412,
      "step": 129400
    },
    {
      "epoch": 4.452773097685934,
      "grad_norm": 0.037546392530202866,
      "learning_rate": 3.609069496559342e-05,
      "loss": 0.0358,
      "step": 129500
    },
    {
      "epoch": 4.456211532510402,
      "grad_norm": 0.1832023710012436,
      "learning_rate": 3.607994962584727e-05,
      "loss": 0.0402,
      "step": 129600
    },
    {
      "epoch": 4.459649967334869,
      "grad_norm": 0.18223319947719574,
      "learning_rate": 3.606920428610112e-05,
      "loss": 0.0415,
      "step": 129700
    },
    {
      "epoch": 4.463088402159337,
      "grad_norm": 0.20996493101119995,
      "learning_rate": 3.6058458946354966e-05,
      "loss": 0.0413,
      "step": 129800
    },
    {
      "epoch": 4.466526836983805,
      "grad_norm": 0.10478854179382324,
      "learning_rate": 3.604771360660881e-05,
      "loss": 0.0387,
      "step": 129900
    },
    {
      "epoch": 4.469965271808273,
      "grad_norm": 0.20771555602550507,
      "learning_rate": 3.603696826686266e-05,
      "loss": 0.0402,
      "step": 130000
    },
    {
      "epoch": 4.473403706632741,
      "grad_norm": 0.1174854263663292,
      "learning_rate": 3.602622292711651e-05,
      "loss": 0.0373,
      "step": 130100
    },
    {
      "epoch": 4.476842141457209,
      "grad_norm": 0.24108877778053284,
      "learning_rate": 3.601547758737036e-05,
      "loss": 0.0393,
      "step": 130200
    },
    {
      "epoch": 4.480280576281676,
      "grad_norm": 0.15413382649421692,
      "learning_rate": 3.6004732247624206e-05,
      "loss": 0.0411,
      "step": 130300
    },
    {
      "epoch": 4.483719011106144,
      "grad_norm": 0.23325751721858978,
      "learning_rate": 3.5994094361275515e-05,
      "loss": 0.0397,
      "step": 130400
    },
    {
      "epoch": 4.487157445930612,
      "grad_norm": 0.06751077622175217,
      "learning_rate": 3.598334902152937e-05,
      "loss": 0.0372,
      "step": 130500
    },
    {
      "epoch": 4.49059588075508,
      "grad_norm": 0.08760244399309158,
      "learning_rate": 3.597260368178321e-05,
      "loss": 0.0389,
      "step": 130600
    },
    {
      "epoch": 4.494034315579548,
      "grad_norm": 0.07225161790847778,
      "learning_rate": 3.596185834203706e-05,
      "loss": 0.0391,
      "step": 130700
    },
    {
      "epoch": 4.497472750404016,
      "grad_norm": 0.1407499611377716,
      "learning_rate": 3.595122045568837e-05,
      "loss": 0.0384,
      "step": 130800
    },
    {
      "epoch": 4.5009111852284835,
      "grad_norm": 0.0978786051273346,
      "learning_rate": 3.594047511594222e-05,
      "loss": 0.0397,
      "step": 130900
    },
    {
      "epoch": 4.504349620052952,
      "grad_norm": 0.12642210721969604,
      "learning_rate": 3.5929729776196065e-05,
      "loss": 0.0351,
      "step": 131000
    },
    {
      "epoch": 4.50778805487742,
      "grad_norm": 0.10385879874229431,
      "learning_rate": 3.591898443644992e-05,
      "loss": 0.042,
      "step": 131100
    },
    {
      "epoch": 4.511226489701888,
      "grad_norm": 0.17763212323188782,
      "learning_rate": 3.590823909670376e-05,
      "loss": 0.0414,
      "step": 131200
    },
    {
      "epoch": 4.514664924526356,
      "grad_norm": 0.5722852349281311,
      "learning_rate": 3.5897493756957614e-05,
      "loss": 0.0392,
      "step": 131300
    },
    {
      "epoch": 4.518103359350824,
      "grad_norm": 0.07025434076786041,
      "learning_rate": 3.588674841721146e-05,
      "loss": 0.0387,
      "step": 131400
    },
    {
      "epoch": 4.521541794175292,
      "grad_norm": 0.23734869062900543,
      "learning_rate": 3.5876003077465305e-05,
      "loss": 0.0452,
      "step": 131500
    },
    {
      "epoch": 4.524980228999759,
      "grad_norm": 0.12701746821403503,
      "learning_rate": 3.586525773771916e-05,
      "loss": 0.0428,
      "step": 131600
    },
    {
      "epoch": 4.528418663824227,
      "grad_norm": 0.3571348786354065,
      "learning_rate": 3.5854512397973e-05,
      "loss": 0.0365,
      "step": 131700
    },
    {
      "epoch": 4.531857098648695,
      "grad_norm": 0.10311142355203629,
      "learning_rate": 3.5843767058226854e-05,
      "loss": 0.0375,
      "step": 131800
    },
    {
      "epoch": 4.535295533473163,
      "grad_norm": 0.1182827278971672,
      "learning_rate": 3.58330217184807e-05,
      "loss": 0.0411,
      "step": 131900
    },
    {
      "epoch": 4.538733968297631,
      "grad_norm": 0.22645528614521027,
      "learning_rate": 3.5822276378734545e-05,
      "loss": 0.0386,
      "step": 132000
    },
    {
      "epoch": 4.542172403122099,
      "grad_norm": 0.10228581726551056,
      "learning_rate": 3.58115310389884e-05,
      "loss": 0.0376,
      "step": 132100
    },
    {
      "epoch": 4.545610837946567,
      "grad_norm": 0.09191513806581497,
      "learning_rate": 3.580078569924224e-05,
      "loss": 0.0351,
      "step": 132200
    },
    {
      "epoch": 4.549049272771034,
      "grad_norm": 0.11945264786481857,
      "learning_rate": 3.579004035949609e-05,
      "loss": 0.0434,
      "step": 132300
    },
    {
      "epoch": 4.552487707595502,
      "grad_norm": 0.22871297597885132,
      "learning_rate": 3.577929501974994e-05,
      "loss": 0.0408,
      "step": 132400
    },
    {
      "epoch": 4.55592614241997,
      "grad_norm": 0.13380710780620575,
      "learning_rate": 3.5768549680003785e-05,
      "loss": 0.0413,
      "step": 132500
    },
    {
      "epoch": 4.559364577244438,
      "grad_norm": 0.06590045243501663,
      "learning_rate": 3.575780434025763e-05,
      "loss": 0.0435,
      "step": 132600
    },
    {
      "epoch": 4.5628030120689065,
      "grad_norm": 0.11913962662220001,
      "learning_rate": 3.574705900051148e-05,
      "loss": 0.0375,
      "step": 132700
    },
    {
      "epoch": 4.5662414468933745,
      "grad_norm": 0.2327151745557785,
      "learning_rate": 3.573631366076533e-05,
      "loss": 0.0404,
      "step": 132800
    },
    {
      "epoch": 4.569679881717842,
      "grad_norm": 0.2957235276699066,
      "learning_rate": 3.572556832101917e-05,
      "loss": 0.0417,
      "step": 132900
    },
    {
      "epoch": 4.57311831654231,
      "grad_norm": 0.12763433158397675,
      "learning_rate": 3.5714822981273025e-05,
      "loss": 0.0357,
      "step": 133000
    },
    {
      "epoch": 4.576556751366778,
      "grad_norm": 0.22920015454292297,
      "learning_rate": 3.570407764152687e-05,
      "loss": 0.0413,
      "step": 133100
    },
    {
      "epoch": 4.579995186191246,
      "grad_norm": 0.11191361397504807,
      "learning_rate": 3.5693332301780716e-05,
      "loss": 0.0395,
      "step": 133200
    },
    {
      "epoch": 4.583433621015714,
      "grad_norm": 0.1046794205904007,
      "learning_rate": 3.568258696203457e-05,
      "loss": 0.0387,
      "step": 133300
    },
    {
      "epoch": 4.586872055840182,
      "grad_norm": 0.10769108682870865,
      "learning_rate": 3.567184162228841e-05,
      "loss": 0.0349,
      "step": 133400
    },
    {
      "epoch": 4.590310490664649,
      "grad_norm": 0.19858667254447937,
      "learning_rate": 3.566109628254226e-05,
      "loss": 0.041,
      "step": 133500
    },
    {
      "epoch": 4.593748925489117,
      "grad_norm": 0.16002340614795685,
      "learning_rate": 3.565035094279611e-05,
      "loss": 0.038,
      "step": 133600
    },
    {
      "epoch": 4.597187360313585,
      "grad_norm": 0.22696749866008759,
      "learning_rate": 3.5639605603049956e-05,
      "loss": 0.0391,
      "step": 133700
    },
    {
      "epoch": 4.600625795138053,
      "grad_norm": 0.14519920945167542,
      "learning_rate": 3.562886026330381e-05,
      "loss": 0.042,
      "step": 133800
    },
    {
      "epoch": 4.604064229962521,
      "grad_norm": 0.34393876791000366,
      "learning_rate": 3.561811492355765e-05,
      "loss": 0.0403,
      "step": 133900
    },
    {
      "epoch": 4.607502664786989,
      "grad_norm": 0.1967644840478897,
      "learning_rate": 3.56073695838115e-05,
      "loss": 0.0395,
      "step": 134000
    },
    {
      "epoch": 4.610941099611457,
      "grad_norm": 0.24683979153633118,
      "learning_rate": 3.559662424406535e-05,
      "loss": 0.0398,
      "step": 134100
    },
    {
      "epoch": 4.614379534435924,
      "grad_norm": 0.22635497152805328,
      "learning_rate": 3.5585878904319196e-05,
      "loss": 0.0394,
      "step": 134200
    },
    {
      "epoch": 4.6178179692603925,
      "grad_norm": 0.47158282995224,
      "learning_rate": 3.557513356457305e-05,
      "loss": 0.0418,
      "step": 134300
    },
    {
      "epoch": 4.6212564040848605,
      "grad_norm": 0.22430679202079773,
      "learning_rate": 3.556438822482689e-05,
      "loss": 0.0406,
      "step": 134400
    },
    {
      "epoch": 4.6246948389093285,
      "grad_norm": 0.17325221002101898,
      "learning_rate": 3.555364288508074e-05,
      "loss": 0.0407,
      "step": 134500
    },
    {
      "epoch": 4.628133273733797,
      "grad_norm": 0.0824640616774559,
      "learning_rate": 3.554289754533459e-05,
      "loss": 0.0348,
      "step": 134600
    },
    {
      "epoch": 4.631571708558265,
      "grad_norm": 0.126089408993721,
      "learning_rate": 3.5532152205588436e-05,
      "loss": 0.0399,
      "step": 134700
    },
    {
      "epoch": 4.635010143382733,
      "grad_norm": 0.08038220554590225,
      "learning_rate": 3.552140686584229e-05,
      "loss": 0.04,
      "step": 134800
    },
    {
      "epoch": 4.6384485782072,
      "grad_norm": 0.08040659874677658,
      "learning_rate": 3.551066152609613e-05,
      "loss": 0.0375,
      "step": 134900
    },
    {
      "epoch": 4.641887013031668,
      "grad_norm": 0.3659031391143799,
      "learning_rate": 3.549991618634998e-05,
      "loss": 0.0398,
      "step": 135000
    },
    {
      "epoch": 4.645325447856136,
      "grad_norm": 0.08682011812925339,
      "learning_rate": 3.548917084660383e-05,
      "loss": 0.0409,
      "step": 135100
    },
    {
      "epoch": 4.648763882680604,
      "grad_norm": 0.2563946843147278,
      "learning_rate": 3.5478425506857676e-05,
      "loss": 0.0415,
      "step": 135200
    },
    {
      "epoch": 4.652202317505072,
      "grad_norm": 0.2149129956960678,
      "learning_rate": 3.546768016711153e-05,
      "loss": 0.0406,
      "step": 135300
    },
    {
      "epoch": 4.655640752329539,
      "grad_norm": 0.06746026128530502,
      "learning_rate": 3.545693482736537e-05,
      "loss": 0.0404,
      "step": 135400
    },
    {
      "epoch": 4.659079187154007,
      "grad_norm": 0.13940422236919403,
      "learning_rate": 3.544618948761922e-05,
      "loss": 0.0398,
      "step": 135500
    },
    {
      "epoch": 4.662517621978475,
      "grad_norm": 0.08283684402704239,
      "learning_rate": 3.543544414787307e-05,
      "loss": 0.0386,
      "step": 135600
    },
    {
      "epoch": 4.665956056802943,
      "grad_norm": 0.38015034794807434,
      "learning_rate": 3.5424698808126916e-05,
      "loss": 0.0374,
      "step": 135700
    },
    {
      "epoch": 4.669394491627411,
      "grad_norm": 0.1684209704399109,
      "learning_rate": 3.541395346838077e-05,
      "loss": 0.0394,
      "step": 135800
    },
    {
      "epoch": 4.672832926451879,
      "grad_norm": 0.11482726782560349,
      "learning_rate": 3.540320812863461e-05,
      "loss": 0.0409,
      "step": 135900
    },
    {
      "epoch": 4.676271361276347,
      "grad_norm": 0.09213025867938995,
      "learning_rate": 3.539257024228592e-05,
      "loss": 0.0401,
      "step": 136000
    },
    {
      "epoch": 4.6797097961008145,
      "grad_norm": 0.0742994174361229,
      "learning_rate": 3.538182490253977e-05,
      "loss": 0.0379,
      "step": 136100
    },
    {
      "epoch": 4.6831482309252825,
      "grad_norm": 0.20994745194911957,
      "learning_rate": 3.537107956279362e-05,
      "loss": 0.0397,
      "step": 136200
    },
    {
      "epoch": 4.686586665749751,
      "grad_norm": 0.11103996634483337,
      "learning_rate": 3.5360334223047465e-05,
      "loss": 0.043,
      "step": 136300
    },
    {
      "epoch": 4.690025100574219,
      "grad_norm": 0.28305667638778687,
      "learning_rate": 3.534958888330132e-05,
      "loss": 0.0367,
      "step": 136400
    },
    {
      "epoch": 4.693463535398687,
      "grad_norm": 0.24680766463279724,
      "learning_rate": 3.533884354355516e-05,
      "loss": 0.0387,
      "step": 136500
    },
    {
      "epoch": 4.696901970223155,
      "grad_norm": 0.18139663338661194,
      "learning_rate": 3.5328098203809015e-05,
      "loss": 0.0403,
      "step": 136600
    },
    {
      "epoch": 4.700340405047623,
      "grad_norm": 0.36274561285972595,
      "learning_rate": 3.531735286406286e-05,
      "loss": 0.0382,
      "step": 136700
    },
    {
      "epoch": 4.70377883987209,
      "grad_norm": 0.22772961854934692,
      "learning_rate": 3.5306607524316705e-05,
      "loss": 0.0415,
      "step": 136800
    },
    {
      "epoch": 4.707217274696558,
      "grad_norm": 0.188018336892128,
      "learning_rate": 3.529586218457056e-05,
      "loss": 0.0382,
      "step": 136900
    },
    {
      "epoch": 4.710655709521026,
      "grad_norm": 0.0639265701174736,
      "learning_rate": 3.52851168448244e-05,
      "loss": 0.0366,
      "step": 137000
    },
    {
      "epoch": 4.714094144345494,
      "grad_norm": 0.08180639892816544,
      "learning_rate": 3.5274371505078255e-05,
      "loss": 0.0399,
      "step": 137100
    },
    {
      "epoch": 4.717532579169962,
      "grad_norm": 0.672985851764679,
      "learning_rate": 3.52636261653321e-05,
      "loss": 0.04,
      "step": 137200
    },
    {
      "epoch": 4.72097101399443,
      "grad_norm": 0.1708863377571106,
      "learning_rate": 3.5252880825585945e-05,
      "loss": 0.0386,
      "step": 137300
    },
    {
      "epoch": 4.724409448818898,
      "grad_norm": 0.07423026114702225,
      "learning_rate": 3.52421354858398e-05,
      "loss": 0.04,
      "step": 137400
    },
    {
      "epoch": 4.727847883643365,
      "grad_norm": 0.30071789026260376,
      "learning_rate": 3.523139014609364e-05,
      "loss": 0.041,
      "step": 137500
    },
    {
      "epoch": 4.731286318467833,
      "grad_norm": 0.22069205343723297,
      "learning_rate": 3.522064480634749e-05,
      "loss": 0.0396,
      "step": 137600
    },
    {
      "epoch": 4.734724753292301,
      "grad_norm": 0.07764959335327148,
      "learning_rate": 3.520989946660134e-05,
      "loss": 0.0385,
      "step": 137700
    },
    {
      "epoch": 4.738163188116769,
      "grad_norm": 0.27589181065559387,
      "learning_rate": 3.5199154126855186e-05,
      "loss": 0.0387,
      "step": 137800
    },
    {
      "epoch": 4.741601622941237,
      "grad_norm": 0.9364343285560608,
      "learning_rate": 3.518840878710903e-05,
      "loss": 0.0406,
      "step": 137900
    },
    {
      "epoch": 4.745040057765705,
      "grad_norm": 0.1458185464143753,
      "learning_rate": 3.517766344736288e-05,
      "loss": 0.0409,
      "step": 138000
    },
    {
      "epoch": 4.748478492590173,
      "grad_norm": 0.18158385157585144,
      "learning_rate": 3.516691810761673e-05,
      "loss": 0.0379,
      "step": 138100
    },
    {
      "epoch": 4.751916927414641,
      "grad_norm": 0.10298699885606766,
      "learning_rate": 3.5156172767870573e-05,
      "loss": 0.038,
      "step": 138200
    },
    {
      "epoch": 4.755355362239109,
      "grad_norm": 0.14633844792842865,
      "learning_rate": 3.5145427428124426e-05,
      "loss": 0.0391,
      "step": 138300
    },
    {
      "epoch": 4.758793797063577,
      "grad_norm": 0.3519946336746216,
      "learning_rate": 3.513468208837827e-05,
      "loss": 0.0375,
      "step": 138400
    },
    {
      "epoch": 4.762232231888045,
      "grad_norm": 0.09815406054258347,
      "learning_rate": 3.5123936748632116e-05,
      "loss": 0.0398,
      "step": 138500
    },
    {
      "epoch": 4.765670666712513,
      "grad_norm": 0.1144370511174202,
      "learning_rate": 3.511319140888597e-05,
      "loss": 0.0409,
      "step": 138600
    },
    {
      "epoch": 4.76910910153698,
      "grad_norm": 0.29416224360466003,
      "learning_rate": 3.510255352253728e-05,
      "loss": 0.0389,
      "step": 138700
    },
    {
      "epoch": 4.772547536361448,
      "grad_norm": 0.07426571846008301,
      "learning_rate": 3.509180818279112e-05,
      "loss": 0.0418,
      "step": 138800
    },
    {
      "epoch": 4.775985971185916,
      "grad_norm": 0.28716617822647095,
      "learning_rate": 3.508106284304497e-05,
      "loss": 0.0373,
      "step": 138900
    },
    {
      "epoch": 4.779424406010384,
      "grad_norm": 0.12822335958480835,
      "learning_rate": 3.507031750329882e-05,
      "loss": 0.0394,
      "step": 139000
    },
    {
      "epoch": 4.782862840834852,
      "grad_norm": 0.19589108228683472,
      "learning_rate": 3.5059572163552666e-05,
      "loss": 0.0417,
      "step": 139100
    },
    {
      "epoch": 4.78630127565932,
      "grad_norm": 0.10256090760231018,
      "learning_rate": 3.504882682380652e-05,
      "loss": 0.0408,
      "step": 139200
    },
    {
      "epoch": 4.789739710483788,
      "grad_norm": 0.18826942145824432,
      "learning_rate": 3.503808148406036e-05,
      "loss": 0.0368,
      "step": 139300
    },
    {
      "epoch": 4.793178145308255,
      "grad_norm": 0.20989327132701874,
      "learning_rate": 3.502733614431421e-05,
      "loss": 0.0382,
      "step": 139400
    },
    {
      "epoch": 4.796616580132723,
      "grad_norm": 0.2235211879014969,
      "learning_rate": 3.501659080456806e-05,
      "loss": 0.0403,
      "step": 139500
    },
    {
      "epoch": 4.8000550149571914,
      "grad_norm": 0.2129034847021103,
      "learning_rate": 3.5005845464821906e-05,
      "loss": 0.0386,
      "step": 139600
    },
    {
      "epoch": 4.8034934497816595,
      "grad_norm": 0.2557990849018097,
      "learning_rate": 3.499510012507576e-05,
      "loss": 0.0397,
      "step": 139700
    },
    {
      "epoch": 4.8069318846061275,
      "grad_norm": 0.11635047942399979,
      "learning_rate": 3.49843547853296e-05,
      "loss": 0.0388,
      "step": 139800
    },
    {
      "epoch": 4.810370319430596,
      "grad_norm": 0.25118881464004517,
      "learning_rate": 3.497360944558345e-05,
      "loss": 0.0386,
      "step": 139900
    },
    {
      "epoch": 4.813808754255063,
      "grad_norm": 0.05437340587377548,
      "learning_rate": 3.49628641058373e-05,
      "loss": 0.04,
      "step": 140000
    },
    {
      "epoch": 4.817247189079531,
      "grad_norm": 0.22966958582401276,
      "learning_rate": 3.4952118766091146e-05,
      "loss": 0.0372,
      "step": 140100
    },
    {
      "epoch": 4.820685623903999,
      "grad_norm": 0.1792401820421219,
      "learning_rate": 3.4941373426345e-05,
      "loss": 0.0385,
      "step": 140200
    },
    {
      "epoch": 4.824124058728467,
      "grad_norm": 0.5756007432937622,
      "learning_rate": 3.493062808659884e-05,
      "loss": 0.0411,
      "step": 140300
    },
    {
      "epoch": 4.827562493552935,
      "grad_norm": 0.13914896547794342,
      "learning_rate": 3.491988274685269e-05,
      "loss": 0.0416,
      "step": 140400
    },
    {
      "epoch": 4.831000928377403,
      "grad_norm": 0.19708344340324402,
      "learning_rate": 3.490913740710654e-05,
      "loss": 0.0438,
      "step": 140500
    },
    {
      "epoch": 4.83443936320187,
      "grad_norm": 0.4375096261501312,
      "learning_rate": 3.4898392067360386e-05,
      "loss": 0.0363,
      "step": 140600
    },
    {
      "epoch": 4.837877798026338,
      "grad_norm": 0.22964347898960114,
      "learning_rate": 3.488764672761424e-05,
      "loss": 0.0382,
      "step": 140700
    },
    {
      "epoch": 4.841316232850806,
      "grad_norm": 0.5308972597122192,
      "learning_rate": 3.487690138786808e-05,
      "loss": 0.0403,
      "step": 140800
    },
    {
      "epoch": 4.844754667675274,
      "grad_norm": 0.2173166275024414,
      "learning_rate": 3.486615604812193e-05,
      "loss": 0.0407,
      "step": 140900
    },
    {
      "epoch": 4.848193102499742,
      "grad_norm": 0.198796808719635,
      "learning_rate": 3.485541070837578e-05,
      "loss": 0.0359,
      "step": 141000
    },
    {
      "epoch": 4.85163153732421,
      "grad_norm": 0.3068957030773163,
      "learning_rate": 3.484477282202709e-05,
      "loss": 0.0402,
      "step": 141100
    },
    {
      "epoch": 4.855069972148678,
      "grad_norm": 0.16726243495941162,
      "learning_rate": 3.4834027482280936e-05,
      "loss": 0.0374,
      "step": 141200
    },
    {
      "epoch": 4.8585084069731455,
      "grad_norm": 0.07362949103116989,
      "learning_rate": 3.482328214253479e-05,
      "loss": 0.0391,
      "step": 141300
    },
    {
      "epoch": 4.8619468417976135,
      "grad_norm": 0.12650784850120544,
      "learning_rate": 3.481253680278863e-05,
      "loss": 0.042,
      "step": 141400
    },
    {
      "epoch": 4.8653852766220815,
      "grad_norm": 0.09726575016975403,
      "learning_rate": 3.4801791463042485e-05,
      "loss": 0.0377,
      "step": 141500
    },
    {
      "epoch": 4.86882371144655,
      "grad_norm": 0.1968434602022171,
      "learning_rate": 3.479104612329633e-05,
      "loss": 0.0403,
      "step": 141600
    },
    {
      "epoch": 4.872262146271018,
      "grad_norm": 0.17586122453212738,
      "learning_rate": 3.4780300783550176e-05,
      "loss": 0.043,
      "step": 141700
    },
    {
      "epoch": 4.875700581095486,
      "grad_norm": 0.14194190502166748,
      "learning_rate": 3.476955544380403e-05,
      "loss": 0.0389,
      "step": 141800
    },
    {
      "epoch": 4.879139015919954,
      "grad_norm": 0.2882722020149231,
      "learning_rate": 3.475881010405787e-05,
      "loss": 0.0383,
      "step": 141900
    },
    {
      "epoch": 4.882577450744421,
      "grad_norm": 0.26963573694229126,
      "learning_rate": 3.4748064764311725e-05,
      "loss": 0.0374,
      "step": 142000
    },
    {
      "epoch": 4.886015885568889,
      "grad_norm": 0.090837761759758,
      "learning_rate": 3.473731942456557e-05,
      "loss": 0.0375,
      "step": 142100
    },
    {
      "epoch": 4.889454320393357,
      "grad_norm": 0.18687711656093597,
      "learning_rate": 3.4726574084819416e-05,
      "loss": 0.036,
      "step": 142200
    },
    {
      "epoch": 4.892892755217825,
      "grad_norm": 0.24525420367717743,
      "learning_rate": 3.471582874507327e-05,
      "loss": 0.041,
      "step": 142300
    },
    {
      "epoch": 4.896331190042293,
      "grad_norm": 0.11668887734413147,
      "learning_rate": 3.470508340532711e-05,
      "loss": 0.0432,
      "step": 142400
    },
    {
      "epoch": 4.89976962486676,
      "grad_norm": 0.33117780089378357,
      "learning_rate": 3.469433806558096e-05,
      "loss": 0.0372,
      "step": 142500
    },
    {
      "epoch": 4.903208059691228,
      "grad_norm": 0.11400093138217926,
      "learning_rate": 3.468359272583481e-05,
      "loss": 0.039,
      "step": 142600
    },
    {
      "epoch": 4.906646494515696,
      "grad_norm": 0.3235645592212677,
      "learning_rate": 3.4672847386088656e-05,
      "loss": 0.0404,
      "step": 142700
    },
    {
      "epoch": 4.910084929340164,
      "grad_norm": 0.23295465111732483,
      "learning_rate": 3.46621020463425e-05,
      "loss": 0.0405,
      "step": 142800
    },
    {
      "epoch": 4.913523364164632,
      "grad_norm": 0.31264370679855347,
      "learning_rate": 3.465135670659635e-05,
      "loss": 0.042,
      "step": 142900
    },
    {
      "epoch": 4.9169617989891,
      "grad_norm": 0.29798582196235657,
      "learning_rate": 3.46406113668502e-05,
      "loss": 0.0359,
      "step": 143000
    },
    {
      "epoch": 4.920400233813568,
      "grad_norm": 0.08047717064619064,
      "learning_rate": 3.4629866027104044e-05,
      "loss": 0.0372,
      "step": 143100
    },
    {
      "epoch": 4.9238386686380355,
      "grad_norm": 0.48455655574798584,
      "learning_rate": 3.461912068735789e-05,
      "loss": 0.04,
      "step": 143200
    },
    {
      "epoch": 4.927277103462504,
      "grad_norm": 0.2549307942390442,
      "learning_rate": 3.460837534761174e-05,
      "loss": 0.0375,
      "step": 143300
    },
    {
      "epoch": 4.930715538286972,
      "grad_norm": 0.09720878303050995,
      "learning_rate": 3.4597630007865586e-05,
      "loss": 0.0349,
      "step": 143400
    },
    {
      "epoch": 4.93415397311144,
      "grad_norm": 0.14627063274383545,
      "learning_rate": 3.458688466811944e-05,
      "loss": 0.0367,
      "step": 143500
    },
    {
      "epoch": 4.937592407935908,
      "grad_norm": 0.08443408459424973,
      "learning_rate": 3.4576139328373284e-05,
      "loss": 0.0363,
      "step": 143600
    },
    {
      "epoch": 4.941030842760376,
      "grad_norm": 0.10786646604537964,
      "learning_rate": 3.456539398862713e-05,
      "loss": 0.0394,
      "step": 143700
    },
    {
      "epoch": 4.944469277584844,
      "grad_norm": 0.2696813941001892,
      "learning_rate": 3.4554756102278445e-05,
      "loss": 0.0421,
      "step": 143800
    },
    {
      "epoch": 4.947907712409311,
      "grad_norm": 0.13987569510936737,
      "learning_rate": 3.454401076253229e-05,
      "loss": 0.0384,
      "step": 143900
    },
    {
      "epoch": 4.951346147233779,
      "grad_norm": 0.10124902427196503,
      "learning_rate": 3.4533265422786136e-05,
      "loss": 0.0346,
      "step": 144000
    },
    {
      "epoch": 4.954784582058247,
      "grad_norm": 0.32331958413124084,
      "learning_rate": 3.452252008303999e-05,
      "loss": 0.0415,
      "step": 144100
    },
    {
      "epoch": 4.958223016882715,
      "grad_norm": 0.14077413082122803,
      "learning_rate": 3.451177474329383e-05,
      "loss": 0.0389,
      "step": 144200
    },
    {
      "epoch": 4.961661451707183,
      "grad_norm": 0.11710045486688614,
      "learning_rate": 3.4501029403547685e-05,
      "loss": 0.0406,
      "step": 144300
    },
    {
      "epoch": 4.965099886531651,
      "grad_norm": 0.18431420624256134,
      "learning_rate": 3.4490391517198995e-05,
      "loss": 0.0381,
      "step": 144400
    },
    {
      "epoch": 4.968538321356119,
      "grad_norm": 0.6461592316627502,
      "learning_rate": 3.447964617745284e-05,
      "loss": 0.0402,
      "step": 144500
    },
    {
      "epoch": 4.971976756180586,
      "grad_norm": 0.08285430073738098,
      "learning_rate": 3.4468900837706686e-05,
      "loss": 0.0375,
      "step": 144600
    },
    {
      "epoch": 4.975415191005054,
      "grad_norm": 0.5405073165893555,
      "learning_rate": 3.445815549796054e-05,
      "loss": 0.0402,
      "step": 144700
    },
    {
      "epoch": 4.978853625829522,
      "grad_norm": 0.35667651891708374,
      "learning_rate": 3.444741015821438e-05,
      "loss": 0.0417,
      "step": 144800
    },
    {
      "epoch": 4.98229206065399,
      "grad_norm": 0.09828335046768188,
      "learning_rate": 3.4436664818468235e-05,
      "loss": 0.0404,
      "step": 144900
    },
    {
      "epoch": 4.9857304954784585,
      "grad_norm": 0.12761768698692322,
      "learning_rate": 3.442591947872208e-05,
      "loss": 0.0378,
      "step": 145000
    },
    {
      "epoch": 4.989168930302926,
      "grad_norm": 0.19413605332374573,
      "learning_rate": 3.4415174138975926e-05,
      "loss": 0.0373,
      "step": 145100
    },
    {
      "epoch": 4.992607365127394,
      "grad_norm": 0.23495563864707947,
      "learning_rate": 3.440442879922978e-05,
      "loss": 0.0428,
      "step": 145200
    },
    {
      "epoch": 4.996045799951862,
      "grad_norm": 0.42725419998168945,
      "learning_rate": 3.439368345948362e-05,
      "loss": 0.039,
      "step": 145300
    },
    {
      "epoch": 4.99948423477633,
      "grad_norm": 0.12025557458400726,
      "learning_rate": 3.4382938119737475e-05,
      "loss": 0.0407,
      "step": 145400
    },
    {
      "epoch": 5.0,
      "eval_accuracy_macro_0.5": 0.9835006594657898,
      "eval_accuracy_micro_0.5": 0.9835006594657898,
      "eval_accuracy_weighted_0.5": 0.9729087352752686,
      "eval_aucroc_macro": 0.9119529724121094,
      "eval_aucroc_micro": 0.9135534763336182,
      "eval_aucroc_weighted": 0.9103424549102783,
      "eval_f1_macro_0.5": 0.7483717203140259,
      "eval_f1_macro_0.6": 0.7309954762458801,
      "eval_f1_macro_0.7": 0.6981548070907593,
      "eval_f1_macro_0.8": 0.5303426384925842,
      "eval_f1_micro_0.5": 0.7593579888343811,
      "eval_f1_micro_0.6": 0.7452898025512695,
      "eval_f1_micro_0.7": 0.718865156173706,
      "eval_f1_micro_0.8": 0.6701377034187317,
      "eval_f1_micro_0.9": 0.5605922341346741,
      "eval_f1_weighted_0.5": 0.7521272897720337,
      "eval_f1_weighted_0.6": 0.7325741052627563,
      "eval_f1_weighted_0.7": 0.698780357837677,
      "eval_f1_weighted_0.8": 0.5179413557052612,
      "eval_loss": 0.03646622598171234,
      "eval_runtime": 2019.0037,
      "eval_samples_per_second": 28.792,
      "eval_steps_per_second": 3.599,
      "step": 145415
    },
    {
      "epoch": 5.002922669600798,
      "grad_norm": 0.12672187387943268,
      "learning_rate": 3.437219277999132e-05,
      "loss": 0.0331,
      "step": 145500
    },
    {
      "epoch": 5.006361104425266,
      "grad_norm": 0.39112043380737305,
      "learning_rate": 3.4361447440245166e-05,
      "loss": 0.0366,
      "step": 145600
    },
    {
      "epoch": 5.009799539249734,
      "grad_norm": 0.19804887473583221,
      "learning_rate": 3.435070210049902e-05,
      "loss": 0.0415,
      "step": 145700
    },
    {
      "epoch": 5.013237974074201,
      "grad_norm": 0.17321880161762238,
      "learning_rate": 3.433995676075286e-05,
      "loss": 0.0387,
      "step": 145800
    },
    {
      "epoch": 5.016676408898669,
      "grad_norm": 0.23370885848999023,
      "learning_rate": 3.4329211421006715e-05,
      "loss": 0.0378,
      "step": 145900
    },
    {
      "epoch": 5.020114843723137,
      "grad_norm": 0.11752183735370636,
      "learning_rate": 3.431846608126056e-05,
      "loss": 0.0399,
      "step": 146000
    },
    {
      "epoch": 5.023553278547605,
      "grad_norm": 0.07812107354402542,
      "learning_rate": 3.4307720741514406e-05,
      "loss": 0.0368,
      "step": 146100
    },
    {
      "epoch": 5.026991713372073,
      "grad_norm": 0.39631038904190063,
      "learning_rate": 3.429697540176826e-05,
      "loss": 0.0393,
      "step": 146200
    },
    {
      "epoch": 5.030430148196541,
      "grad_norm": 0.12695375084877014,
      "learning_rate": 3.42862300620221e-05,
      "loss": 0.0358,
      "step": 146300
    },
    {
      "epoch": 5.033868583021009,
      "grad_norm": 0.08570073544979095,
      "learning_rate": 3.4275484722275955e-05,
      "loss": 0.0377,
      "step": 146400
    },
    {
      "epoch": 5.037307017845476,
      "grad_norm": 0.1813914179801941,
      "learning_rate": 3.42647393825298e-05,
      "loss": 0.0376,
      "step": 146500
    },
    {
      "epoch": 5.0407454526699444,
      "grad_norm": 0.1575014591217041,
      "learning_rate": 3.4253994042783646e-05,
      "loss": 0.0389,
      "step": 146600
    },
    {
      "epoch": 5.0441838874944125,
      "grad_norm": 0.08836916089057922,
      "learning_rate": 3.42432487030375e-05,
      "loss": 0.0423,
      "step": 146700
    },
    {
      "epoch": 5.0476223223188805,
      "grad_norm": 0.23958998918533325,
      "learning_rate": 3.423250336329134e-05,
      "loss": 0.0413,
      "step": 146800
    },
    {
      "epoch": 5.051060757143349,
      "grad_norm": 0.12169920653104782,
      "learning_rate": 3.4221758023545195e-05,
      "loss": 0.0356,
      "step": 146900
    },
    {
      "epoch": 5.054499191967817,
      "grad_norm": 0.15398305654525757,
      "learning_rate": 3.421101268379904e-05,
      "loss": 0.0394,
      "step": 147000
    },
    {
      "epoch": 5.057937626792284,
      "grad_norm": 0.3472692370414734,
      "learning_rate": 3.4200267344052886e-05,
      "loss": 0.0388,
      "step": 147100
    },
    {
      "epoch": 5.061376061616752,
      "grad_norm": 0.16056761145591736,
      "learning_rate": 3.418952200430674e-05,
      "loss": 0.0353,
      "step": 147200
    },
    {
      "epoch": 5.06481449644122,
      "grad_norm": 0.0859985426068306,
      "learning_rate": 3.417877666456058e-05,
      "loss": 0.0379,
      "step": 147300
    },
    {
      "epoch": 5.068252931265688,
      "grad_norm": 0.12646454572677612,
      "learning_rate": 3.416803132481443e-05,
      "loss": 0.0384,
      "step": 147400
    },
    {
      "epoch": 5.071691366090156,
      "grad_norm": 0.24621577560901642,
      "learning_rate": 3.4157285985068274e-05,
      "loss": 0.0368,
      "step": 147500
    },
    {
      "epoch": 5.075129800914624,
      "grad_norm": 0.13695111870765686,
      "learning_rate": 3.4146540645322126e-05,
      "loss": 0.0351,
      "step": 147600
    },
    {
      "epoch": 5.078568235739092,
      "grad_norm": 0.12619297206401825,
      "learning_rate": 3.413579530557597e-05,
      "loss": 0.0363,
      "step": 147700
    },
    {
      "epoch": 5.082006670563559,
      "grad_norm": 0.341189444065094,
      "learning_rate": 3.4125049965829816e-05,
      "loss": 0.037,
      "step": 147800
    },
    {
      "epoch": 5.085445105388027,
      "grad_norm": 0.16852344572544098,
      "learning_rate": 3.411430462608367e-05,
      "loss": 0.0388,
      "step": 147900
    },
    {
      "epoch": 5.088883540212495,
      "grad_norm": 0.10486570745706558,
      "learning_rate": 3.4103559286337514e-05,
      "loss": 0.0358,
      "step": 148000
    },
    {
      "epoch": 5.092321975036963,
      "grad_norm": 0.18323078751564026,
      "learning_rate": 3.4092813946591366e-05,
      "loss": 0.0352,
      "step": 148100
    },
    {
      "epoch": 5.095760409861431,
      "grad_norm": 0.1696014404296875,
      "learning_rate": 3.408206860684521e-05,
      "loss": 0.034,
      "step": 148200
    },
    {
      "epoch": 5.099198844685899,
      "grad_norm": 0.3612422049045563,
      "learning_rate": 3.4071323267099056e-05,
      "loss": 0.0379,
      "step": 148300
    },
    {
      "epoch": 5.1026372795103665,
      "grad_norm": 0.13597770035266876,
      "learning_rate": 3.406057792735291e-05,
      "loss": 0.0399,
      "step": 148400
    },
    {
      "epoch": 5.1060757143348345,
      "grad_norm": 0.16137783229351044,
      "learning_rate": 3.4049832587606754e-05,
      "loss": 0.0362,
      "step": 148500
    },
    {
      "epoch": 5.109514149159303,
      "grad_norm": 0.13954615592956543,
      "learning_rate": 3.4039087247860606e-05,
      "loss": 0.0421,
      "step": 148600
    },
    {
      "epoch": 5.112952583983771,
      "grad_norm": 0.10804873704910278,
      "learning_rate": 3.4028449361511915e-05,
      "loss": 0.0375,
      "step": 148700
    },
    {
      "epoch": 5.116391018808239,
      "grad_norm": 0.15991774201393127,
      "learning_rate": 3.401770402176576e-05,
      "loss": 0.0427,
      "step": 148800
    },
    {
      "epoch": 5.119829453632707,
      "grad_norm": 0.14413367211818695,
      "learning_rate": 3.4006958682019606e-05,
      "loss": 0.0411,
      "step": 148900
    },
    {
      "epoch": 5.123267888457175,
      "grad_norm": 0.25968775153160095,
      "learning_rate": 3.399621334227346e-05,
      "loss": 0.0362,
      "step": 149000
    },
    {
      "epoch": 5.126706323281642,
      "grad_norm": 0.32481637597084045,
      "learning_rate": 3.39854680025273e-05,
      "loss": 0.0378,
      "step": 149100
    },
    {
      "epoch": 5.13014475810611,
      "grad_norm": 0.10082178562879562,
      "learning_rate": 3.3974722662781155e-05,
      "loss": 0.035,
      "step": 149200
    },
    {
      "epoch": 5.133583192930578,
      "grad_norm": 0.2849690616130829,
      "learning_rate": 3.3963977323035e-05,
      "loss": 0.0395,
      "step": 149300
    },
    {
      "epoch": 5.137021627755046,
      "grad_norm": 0.11202307045459747,
      "learning_rate": 3.3953231983288846e-05,
      "loss": 0.0374,
      "step": 149400
    },
    {
      "epoch": 5.140460062579514,
      "grad_norm": 0.06861300021409988,
      "learning_rate": 3.39424866435427e-05,
      "loss": 0.0372,
      "step": 149500
    },
    {
      "epoch": 5.143898497403982,
      "grad_norm": 0.23858048021793365,
      "learning_rate": 3.393174130379654e-05,
      "loss": 0.035,
      "step": 149600
    },
    {
      "epoch": 5.147336932228449,
      "grad_norm": 0.17428156733512878,
      "learning_rate": 3.3920995964050395e-05,
      "loss": 0.0381,
      "step": 149700
    },
    {
      "epoch": 5.150775367052917,
      "grad_norm": 0.18927638232707977,
      "learning_rate": 3.391025062430424e-05,
      "loss": 0.0392,
      "step": 149800
    },
    {
      "epoch": 5.154213801877385,
      "grad_norm": 0.5532324314117432,
      "learning_rate": 3.3899505284558086e-05,
      "loss": 0.0384,
      "step": 149900
    },
    {
      "epoch": 5.157652236701853,
      "grad_norm": 0.09641098231077194,
      "learning_rate": 3.388875994481194e-05,
      "loss": 0.0401,
      "step": 150000
    },
    {
      "epoch": 5.161090671526321,
      "grad_norm": 0.17587034404277802,
      "learning_rate": 3.387801460506578e-05,
      "loss": 0.0387,
      "step": 150100
    },
    {
      "epoch": 5.164529106350789,
      "grad_norm": 0.15570709109306335,
      "learning_rate": 3.3867269265319635e-05,
      "loss": 0.0375,
      "step": 150200
    },
    {
      "epoch": 5.167967541175257,
      "grad_norm": 0.3990325331687927,
      "learning_rate": 3.385652392557348e-05,
      "loss": 0.0386,
      "step": 150300
    },
    {
      "epoch": 5.171405975999725,
      "grad_norm": 0.22510980069637299,
      "learning_rate": 3.3845778585827326e-05,
      "loss": 0.0363,
      "step": 150400
    },
    {
      "epoch": 5.174844410824193,
      "grad_norm": 0.3469006419181824,
      "learning_rate": 3.383503324608118e-05,
      "loss": 0.0377,
      "step": 150500
    },
    {
      "epoch": 5.178282845648661,
      "grad_norm": 0.28754517436027527,
      "learning_rate": 3.3824287906335023e-05,
      "loss": 0.039,
      "step": 150600
    },
    {
      "epoch": 5.181721280473129,
      "grad_norm": 0.06785380095243454,
      "learning_rate": 3.3813542566588875e-05,
      "loss": 0.0392,
      "step": 150700
    },
    {
      "epoch": 5.185159715297597,
      "grad_norm": 0.24296124279499054,
      "learning_rate": 3.380279722684272e-05,
      "loss": 0.0391,
      "step": 150800
    },
    {
      "epoch": 5.188598150122065,
      "grad_norm": 0.2122551053762436,
      "learning_rate": 3.3792051887096566e-05,
      "loss": 0.0369,
      "step": 150900
    },
    {
      "epoch": 5.192036584946532,
      "grad_norm": 0.1030765250325203,
      "learning_rate": 3.378130654735042e-05,
      "loss": 0.0371,
      "step": 151000
    },
    {
      "epoch": 5.195475019771,
      "grad_norm": 0.13735359907150269,
      "learning_rate": 3.3770561207604263e-05,
      "loss": 0.0389,
      "step": 151100
    },
    {
      "epoch": 5.198913454595468,
      "grad_norm": 0.1584194153547287,
      "learning_rate": 3.3759815867858115e-05,
      "loss": 0.0354,
      "step": 151200
    },
    {
      "epoch": 5.202351889419936,
      "grad_norm": 0.09338154643774033,
      "learning_rate": 3.374907052811196e-05,
      "loss": 0.0385,
      "step": 151300
    },
    {
      "epoch": 5.205790324244404,
      "grad_norm": 0.25331079959869385,
      "learning_rate": 3.3738325188365806e-05,
      "loss": 0.0383,
      "step": 151400
    },
    {
      "epoch": 5.209228759068872,
      "grad_norm": 0.4501940608024597,
      "learning_rate": 3.372757984861966e-05,
      "loss": 0.0349,
      "step": 151500
    },
    {
      "epoch": 5.212667193893339,
      "grad_norm": 0.08416292071342468,
      "learning_rate": 3.3716834508873503e-05,
      "loss": 0.0374,
      "step": 151600
    },
    {
      "epoch": 5.216105628717807,
      "grad_norm": 0.18154212832450867,
      "learning_rate": 3.3706089169127356e-05,
      "loss": 0.0377,
      "step": 151700
    },
    {
      "epoch": 5.219544063542275,
      "grad_norm": 0.5117009878158569,
      "learning_rate": 3.36953438293812e-05,
      "loss": 0.0382,
      "step": 151800
    },
    {
      "epoch": 5.222982498366743,
      "grad_norm": 0.15139074623584747,
      "learning_rate": 3.368470594303251e-05,
      "loss": 0.0407,
      "step": 151900
    },
    {
      "epoch": 5.2264209331912115,
      "grad_norm": 0.09113477915525436,
      "learning_rate": 3.3673960603286356e-05,
      "loss": 0.0374,
      "step": 152000
    },
    {
      "epoch": 5.2298593680156795,
      "grad_norm": 0.09306969493627548,
      "learning_rate": 3.36632152635402e-05,
      "loss": 0.0428,
      "step": 152100
    },
    {
      "epoch": 5.233297802840148,
      "grad_norm": 0.3653470575809479,
      "learning_rate": 3.365246992379405e-05,
      "loss": 0.0377,
      "step": 152200
    },
    {
      "epoch": 5.236736237664615,
      "grad_norm": 0.346781849861145,
      "learning_rate": 3.36417245840479e-05,
      "loss": 0.0371,
      "step": 152300
    },
    {
      "epoch": 5.240174672489083,
      "grad_norm": 0.28823158144950867,
      "learning_rate": 3.3630979244301744e-05,
      "loss": 0.0356,
      "step": 152400
    },
    {
      "epoch": 5.243613107313551,
      "grad_norm": 0.2515604794025421,
      "learning_rate": 3.3620233904555596e-05,
      "loss": 0.0397,
      "step": 152500
    },
    {
      "epoch": 5.247051542138019,
      "grad_norm": 0.24301955103874207,
      "learning_rate": 3.360948856480944e-05,
      "loss": 0.0392,
      "step": 152600
    },
    {
      "epoch": 5.250489976962487,
      "grad_norm": 0.10678425431251526,
      "learning_rate": 3.3598743225063286e-05,
      "loss": 0.0371,
      "step": 152700
    },
    {
      "epoch": 5.253928411786955,
      "grad_norm": 0.14962488412857056,
      "learning_rate": 3.358799788531714e-05,
      "loss": 0.036,
      "step": 152800
    },
    {
      "epoch": 5.257366846611422,
      "grad_norm": 0.4223570227622986,
      "learning_rate": 3.3577252545570984e-05,
      "loss": 0.036,
      "step": 152900
    },
    {
      "epoch": 5.26080528143589,
      "grad_norm": 0.2584286034107208,
      "learning_rate": 3.3566507205824836e-05,
      "loss": 0.0381,
      "step": 153000
    },
    {
      "epoch": 5.264243716260358,
      "grad_norm": 0.7155339121818542,
      "learning_rate": 3.355576186607868e-05,
      "loss": 0.0396,
      "step": 153100
    },
    {
      "epoch": 5.267682151084826,
      "grad_norm": 0.2181994616985321,
      "learning_rate": 3.3545016526332526e-05,
      "loss": 0.0349,
      "step": 153200
    },
    {
      "epoch": 5.271120585909294,
      "grad_norm": 0.22384516894817352,
      "learning_rate": 3.353427118658638e-05,
      "loss": 0.039,
      "step": 153300
    },
    {
      "epoch": 5.274559020733762,
      "grad_norm": 0.17452210187911987,
      "learning_rate": 3.3523525846840224e-05,
      "loss": 0.0408,
      "step": 153400
    },
    {
      "epoch": 5.27799745555823,
      "grad_norm": 0.1547478437423706,
      "learning_rate": 3.3512780507094076e-05,
      "loss": 0.0378,
      "step": 153500
    },
    {
      "epoch": 5.2814358903826975,
      "grad_norm": 0.12759557366371155,
      "learning_rate": 3.350203516734792e-05,
      "loss": 0.0366,
      "step": 153600
    },
    {
      "epoch": 5.2848743252071655,
      "grad_norm": 0.14563173055648804,
      "learning_rate": 3.3491289827601766e-05,
      "loss": 0.0361,
      "step": 153700
    },
    {
      "epoch": 5.2883127600316335,
      "grad_norm": 0.14085471630096436,
      "learning_rate": 3.348054448785562e-05,
      "loss": 0.0366,
      "step": 153800
    },
    {
      "epoch": 5.291751194856102,
      "grad_norm": 0.2002193182706833,
      "learning_rate": 3.3469799148109464e-05,
      "loss": 0.0391,
      "step": 153900
    },
    {
      "epoch": 5.29518962968057,
      "grad_norm": 0.06294013559818268,
      "learning_rate": 3.3459053808363316e-05,
      "loss": 0.0386,
      "step": 154000
    },
    {
      "epoch": 5.298628064505038,
      "grad_norm": 0.17435380816459656,
      "learning_rate": 3.344830846861716e-05,
      "loss": 0.038,
      "step": 154100
    },
    {
      "epoch": 5.302066499329505,
      "grad_norm": 0.24975194036960602,
      "learning_rate": 3.343767058226847e-05,
      "loss": 0.038,
      "step": 154200
    },
    {
      "epoch": 5.305504934153973,
      "grad_norm": 0.319499135017395,
      "learning_rate": 3.342692524252232e-05,
      "loss": 0.0385,
      "step": 154300
    },
    {
      "epoch": 5.308943368978441,
      "grad_norm": 0.57093346118927,
      "learning_rate": 3.341617990277617e-05,
      "loss": 0.0386,
      "step": 154400
    },
    {
      "epoch": 5.312381803802909,
      "grad_norm": 0.11147205531597137,
      "learning_rate": 3.3405434563030013e-05,
      "loss": 0.038,
      "step": 154500
    },
    {
      "epoch": 5.315820238627377,
      "grad_norm": 0.22060611844062805,
      "learning_rate": 3.3394689223283865e-05,
      "loss": 0.0379,
      "step": 154600
    },
    {
      "epoch": 5.319258673451845,
      "grad_norm": 0.14333395659923553,
      "learning_rate": 3.338394388353771e-05,
      "loss": 0.0376,
      "step": 154700
    },
    {
      "epoch": 5.322697108276313,
      "grad_norm": 0.14800740778446198,
      "learning_rate": 3.337319854379156e-05,
      "loss": 0.0397,
      "step": 154800
    },
    {
      "epoch": 5.32613554310078,
      "grad_norm": 0.14512702822685242,
      "learning_rate": 3.336245320404541e-05,
      "loss": 0.0333,
      "step": 154900
    },
    {
      "epoch": 5.329573977925248,
      "grad_norm": 0.338491290807724,
      "learning_rate": 3.3351707864299253e-05,
      "loss": 0.0403,
      "step": 155000
    },
    {
      "epoch": 5.333012412749716,
      "grad_norm": 0.10525170713663101,
      "learning_rate": 3.3340962524553106e-05,
      "loss": 0.0396,
      "step": 155100
    },
    {
      "epoch": 5.336450847574184,
      "grad_norm": 0.1490357220172882,
      "learning_rate": 3.333021718480695e-05,
      "loss": 0.0367,
      "step": 155200
    },
    {
      "epoch": 5.339889282398652,
      "grad_norm": 0.1901503950357437,
      "learning_rate": 3.33194718450608e-05,
      "loss": 0.0391,
      "step": 155300
    },
    {
      "epoch": 5.34332771722312,
      "grad_norm": 0.12670065462589264,
      "learning_rate": 3.330872650531465e-05,
      "loss": 0.0363,
      "step": 155400
    },
    {
      "epoch": 5.3467661520475875,
      "grad_norm": 0.19089514017105103,
      "learning_rate": 3.3297981165568493e-05,
      "loss": 0.0356,
      "step": 155500
    },
    {
      "epoch": 5.350204586872056,
      "grad_norm": 0.16646137833595276,
      "learning_rate": 3.3287235825822346e-05,
      "loss": 0.0383,
      "step": 155600
    },
    {
      "epoch": 5.353643021696524,
      "grad_norm": 0.26234281063079834,
      "learning_rate": 3.327649048607619e-05,
      "loss": 0.0379,
      "step": 155700
    },
    {
      "epoch": 5.357081456520992,
      "grad_norm": 0.1843755841255188,
      "learning_rate": 3.326574514633004e-05,
      "loss": 0.0364,
      "step": 155800
    },
    {
      "epoch": 5.36051989134546,
      "grad_norm": 0.4636417329311371,
      "learning_rate": 3.325499980658389e-05,
      "loss": 0.0379,
      "step": 155900
    },
    {
      "epoch": 5.363958326169928,
      "grad_norm": 0.9409213066101074,
      "learning_rate": 3.3244254466837734e-05,
      "loss": 0.0378,
      "step": 156000
    },
    {
      "epoch": 5.367396760994396,
      "grad_norm": 0.5734846591949463,
      "learning_rate": 3.3233509127091586e-05,
      "loss": 0.0351,
      "step": 156100
    },
    {
      "epoch": 5.370835195818863,
      "grad_norm": 0.3798789381980896,
      "learning_rate": 3.322276378734543e-05,
      "loss": 0.0356,
      "step": 156200
    },
    {
      "epoch": 5.374273630643331,
      "grad_norm": 0.1366649568080902,
      "learning_rate": 3.321201844759928e-05,
      "loss": 0.037,
      "step": 156300
    },
    {
      "epoch": 5.377712065467799,
      "grad_norm": 0.13109469413757324,
      "learning_rate": 3.3201380561250586e-05,
      "loss": 0.0362,
      "step": 156400
    },
    {
      "epoch": 5.381150500292267,
      "grad_norm": 0.1508646160364151,
      "learning_rate": 3.319063522150444e-05,
      "loss": 0.0399,
      "step": 156500
    },
    {
      "epoch": 5.384588935116735,
      "grad_norm": 0.0896749198436737,
      "learning_rate": 3.317988988175828e-05,
      "loss": 0.0367,
      "step": 156600
    },
    {
      "epoch": 5.388027369941203,
      "grad_norm": 0.4539749324321747,
      "learning_rate": 3.316914454201213e-05,
      "loss": 0.0415,
      "step": 156700
    },
    {
      "epoch": 5.39146580476567,
      "grad_norm": 0.23523491621017456,
      "learning_rate": 3.315839920226598e-05,
      "loss": 0.035,
      "step": 156800
    },
    {
      "epoch": 5.394904239590138,
      "grad_norm": 0.10096193850040436,
      "learning_rate": 3.3147653862519826e-05,
      "loss": 0.0371,
      "step": 156900
    },
    {
      "epoch": 5.398342674414606,
      "grad_norm": 0.13136625289916992,
      "learning_rate": 3.313690852277367e-05,
      "loss": 0.0424,
      "step": 157000
    },
    {
      "epoch": 5.401781109239074,
      "grad_norm": 0.23934412002563477,
      "learning_rate": 3.312616318302752e-05,
      "loss": 0.0378,
      "step": 157100
    },
    {
      "epoch": 5.405219544063542,
      "grad_norm": 0.15909244120121002,
      "learning_rate": 3.311541784328137e-05,
      "loss": 0.0367,
      "step": 157200
    },
    {
      "epoch": 5.4086579788880105,
      "grad_norm": 0.143707275390625,
      "learning_rate": 3.3104672503535214e-05,
      "loss": 0.0372,
      "step": 157300
    },
    {
      "epoch": 5.412096413712478,
      "grad_norm": 0.09494990110397339,
      "learning_rate": 3.3093927163789066e-05,
      "loss": 0.0378,
      "step": 157400
    },
    {
      "epoch": 5.415534848536946,
      "grad_norm": 0.12141802906990051,
      "learning_rate": 3.308318182404291e-05,
      "loss": 0.0392,
      "step": 157500
    },
    {
      "epoch": 5.418973283361414,
      "grad_norm": 0.1858670562505722,
      "learning_rate": 3.3072436484296756e-05,
      "loss": 0.0389,
      "step": 157600
    },
    {
      "epoch": 5.422411718185882,
      "grad_norm": 0.1874295175075531,
      "learning_rate": 3.306169114455061e-05,
      "loss": 0.0398,
      "step": 157700
    },
    {
      "epoch": 5.42585015301035,
      "grad_norm": 0.3580186069011688,
      "learning_rate": 3.3050945804804454e-05,
      "loss": 0.0361,
      "step": 157800
    },
    {
      "epoch": 5.429288587834818,
      "grad_norm": 0.16067399084568024,
      "learning_rate": 3.3040200465058306e-05,
      "loss": 0.0354,
      "step": 157900
    },
    {
      "epoch": 5.432727022659286,
      "grad_norm": 0.2643006145954132,
      "learning_rate": 3.302945512531215e-05,
      "loss": 0.0408,
      "step": 158000
    },
    {
      "epoch": 5.436165457483753,
      "grad_norm": 0.06960181891918182,
      "learning_rate": 3.3018709785566e-05,
      "loss": 0.0373,
      "step": 158100
    },
    {
      "epoch": 5.439603892308221,
      "grad_norm": 0.4322322607040405,
      "learning_rate": 3.300796444581985e-05,
      "loss": 0.0403,
      "step": 158200
    },
    {
      "epoch": 5.443042327132689,
      "grad_norm": 0.4305720627307892,
      "learning_rate": 3.2997219106073694e-05,
      "loss": 0.0414,
      "step": 158300
    },
    {
      "epoch": 5.446480761957157,
      "grad_norm": 0.3181597590446472,
      "learning_rate": 3.2986473766327546e-05,
      "loss": 0.0345,
      "step": 158400
    },
    {
      "epoch": 5.449919196781625,
      "grad_norm": 0.1711954027414322,
      "learning_rate": 3.297572842658139e-05,
      "loss": 0.038,
      "step": 158500
    },
    {
      "epoch": 5.453357631606093,
      "grad_norm": Infinity,
      "learning_rate": 3.29650905402327e-05,
      "loss": 0.0389,
      "step": 158600
    },
    {
      "epoch": 5.456796066430561,
      "grad_norm": 0.14816394448280334,
      "learning_rate": 3.295434520048655e-05,
      "loss": 0.0429,
      "step": 158700
    },
    {
      "epoch": 5.460234501255028,
      "grad_norm": 0.2171892523765564,
      "learning_rate": 3.29435998607404e-05,
      "loss": 0.0412,
      "step": 158800
    },
    {
      "epoch": 5.4636729360794964,
      "grad_norm": 0.18790656328201294,
      "learning_rate": 3.2932854520994243e-05,
      "loss": 0.0353,
      "step": 158900
    },
    {
      "epoch": 5.4671113709039645,
      "grad_norm": 0.21000422537326813,
      "learning_rate": 3.2922109181248096e-05,
      "loss": 0.0369,
      "step": 159000
    },
    {
      "epoch": 5.4705498057284325,
      "grad_norm": 0.21348026394844055,
      "learning_rate": 3.291136384150194e-05,
      "loss": 0.0357,
      "step": 159100
    },
    {
      "epoch": 5.473988240552901,
      "grad_norm": 0.13081933557987213,
      "learning_rate": 3.290061850175579e-05,
      "loss": 0.0407,
      "step": 159200
    },
    {
      "epoch": 5.477426675377369,
      "grad_norm": 0.4006604552268982,
      "learning_rate": 3.288987316200964e-05,
      "loss": 0.0399,
      "step": 159300
    },
    {
      "epoch": 5.480865110201836,
      "grad_norm": 0.2898417115211487,
      "learning_rate": 3.2879127822263484e-05,
      "loss": 0.0392,
      "step": 159400
    },
    {
      "epoch": 5.484303545026304,
      "grad_norm": 0.2560323476791382,
      "learning_rate": 3.2868382482517336e-05,
      "loss": 0.0362,
      "step": 159500
    },
    {
      "epoch": 5.487741979850772,
      "grad_norm": 0.32557758688926697,
      "learning_rate": 3.285763714277118e-05,
      "loss": 0.04,
      "step": 159600
    },
    {
      "epoch": 5.49118041467524,
      "grad_norm": 0.10533391684293747,
      "learning_rate": 3.284689180302503e-05,
      "loss": 0.0385,
      "step": 159700
    },
    {
      "epoch": 5.494618849499708,
      "grad_norm": 0.19922500848770142,
      "learning_rate": 3.283614646327888e-05,
      "loss": 0.0391,
      "step": 159800
    },
    {
      "epoch": 5.498057284324176,
      "grad_norm": 0.1722528487443924,
      "learning_rate": 3.2825401123532724e-05,
      "loss": 0.0383,
      "step": 159900
    },
    {
      "epoch": 5.501495719148643,
      "grad_norm": 0.5221806168556213,
      "learning_rate": 3.2814655783786576e-05,
      "loss": 0.0402,
      "step": 160000
    },
    {
      "epoch": 5.504934153973111,
      "grad_norm": 0.3057906925678253,
      "learning_rate": 3.280391044404042e-05,
      "loss": 0.0359,
      "step": 160100
    },
    {
      "epoch": 5.508372588797579,
      "grad_norm": 0.3684549033641815,
      "learning_rate": 3.279316510429427e-05,
      "loss": 0.0396,
      "step": 160200
    },
    {
      "epoch": 5.511811023622047,
      "grad_norm": 0.1387093961238861,
      "learning_rate": 3.278241976454812e-05,
      "loss": 0.0387,
      "step": 160300
    },
    {
      "epoch": 5.515249458446515,
      "grad_norm": 0.16412286460399628,
      "learning_rate": 3.2771674424801964e-05,
      "loss": 0.04,
      "step": 160400
    },
    {
      "epoch": 5.518687893270983,
      "grad_norm": 0.12919463217258453,
      "learning_rate": 3.2760929085055816e-05,
      "loss": 0.0391,
      "step": 160500
    },
    {
      "epoch": 5.522126328095451,
      "grad_norm": 0.371000736951828,
      "learning_rate": 3.275018374530966e-05,
      "loss": 0.0381,
      "step": 160600
    },
    {
      "epoch": 5.5255647629199185,
      "grad_norm": 0.13712941110134125,
      "learning_rate": 3.273943840556351e-05,
      "loss": 0.0367,
      "step": 160700
    },
    {
      "epoch": 5.5290031977443865,
      "grad_norm": 0.1695787012577057,
      "learning_rate": 3.272869306581736e-05,
      "loss": 0.04,
      "step": 160800
    },
    {
      "epoch": 5.532441632568855,
      "grad_norm": 0.17923325300216675,
      "learning_rate": 3.2717947726071204e-05,
      "loss": 0.0354,
      "step": 160900
    },
    {
      "epoch": 5.535880067393323,
      "grad_norm": 0.22069166600704193,
      "learning_rate": 3.2707202386325056e-05,
      "loss": 0.0405,
      "step": 161000
    },
    {
      "epoch": 5.539318502217791,
      "grad_norm": 0.1115993782877922,
      "learning_rate": 3.26964570465789e-05,
      "loss": 0.0395,
      "step": 161100
    },
    {
      "epoch": 5.542756937042259,
      "grad_norm": 0.16835814714431763,
      "learning_rate": 3.268581916023021e-05,
      "loss": 0.0346,
      "step": 161200
    },
    {
      "epoch": 5.546195371866727,
      "grad_norm": 0.17039938271045685,
      "learning_rate": 3.2675073820484056e-05,
      "loss": 0.0355,
      "step": 161300
    },
    {
      "epoch": 5.549633806691194,
      "grad_norm": 0.08267161250114441,
      "learning_rate": 3.266432848073791e-05,
      "loss": 0.0383,
      "step": 161400
    },
    {
      "epoch": 5.553072241515662,
      "grad_norm": 0.2836832106113434,
      "learning_rate": 3.265358314099175e-05,
      "loss": 0.0369,
      "step": 161500
    },
    {
      "epoch": 5.55651067634013,
      "grad_norm": 0.37106990814208984,
      "learning_rate": 3.26428378012456e-05,
      "loss": 0.0381,
      "step": 161600
    },
    {
      "epoch": 5.559949111164598,
      "grad_norm": 0.27644476294517517,
      "learning_rate": 3.2632092461499444e-05,
      "loss": 0.0369,
      "step": 161700
    },
    {
      "epoch": 5.563387545989066,
      "grad_norm": 0.4132179021835327,
      "learning_rate": 3.2621347121753296e-05,
      "loss": 0.0372,
      "step": 161800
    },
    {
      "epoch": 5.566825980813533,
      "grad_norm": 0.17897270619869232,
      "learning_rate": 3.261060178200714e-05,
      "loss": 0.0396,
      "step": 161900
    },
    {
      "epoch": 5.570264415638001,
      "grad_norm": 0.2413921058177948,
      "learning_rate": 3.259985644226099e-05,
      "loss": 0.0413,
      "step": 162000
    },
    {
      "epoch": 5.573702850462469,
      "grad_norm": 0.11465069651603699,
      "learning_rate": 3.258911110251484e-05,
      "loss": 0.0359,
      "step": 162100
    },
    {
      "epoch": 5.577141285286937,
      "grad_norm": 0.1798824667930603,
      "learning_rate": 3.2578365762768684e-05,
      "loss": 0.0341,
      "step": 162200
    },
    {
      "epoch": 5.580579720111405,
      "grad_norm": 0.14619825780391693,
      "learning_rate": 3.2567620423022536e-05,
      "loss": 0.0368,
      "step": 162300
    },
    {
      "epoch": 5.584018154935873,
      "grad_norm": 0.12692320346832275,
      "learning_rate": 3.255687508327638e-05,
      "loss": 0.0353,
      "step": 162400
    },
    {
      "epoch": 5.587456589760341,
      "grad_norm": 0.20805084705352783,
      "learning_rate": 3.254612974353023e-05,
      "loss": 0.0338,
      "step": 162500
    },
    {
      "epoch": 5.590895024584809,
      "grad_norm": 0.2959635853767395,
      "learning_rate": 3.253538440378408e-05,
      "loss": 0.0376,
      "step": 162600
    },
    {
      "epoch": 5.594333459409277,
      "grad_norm": 0.28879469633102417,
      "learning_rate": 3.2524639064037924e-05,
      "loss": 0.0386,
      "step": 162700
    },
    {
      "epoch": 5.597771894233745,
      "grad_norm": 0.1573859304189682,
      "learning_rate": 3.2513893724291776e-05,
      "loss": 0.0356,
      "step": 162800
    },
    {
      "epoch": 5.601210329058213,
      "grad_norm": 0.1698663979768753,
      "learning_rate": 3.250314838454562e-05,
      "loss": 0.0366,
      "step": 162900
    },
    {
      "epoch": 5.604648763882681,
      "grad_norm": 0.12325206398963928,
      "learning_rate": 3.249240304479947e-05,
      "loss": 0.0359,
      "step": 163000
    },
    {
      "epoch": 5.608087198707149,
      "grad_norm": 0.11285575479269028,
      "learning_rate": 3.248165770505332e-05,
      "loss": 0.0365,
      "step": 163100
    },
    {
      "epoch": 5.611525633531617,
      "grad_norm": 0.25389811396598816,
      "learning_rate": 3.2470912365307164e-05,
      "loss": 0.0366,
      "step": 163200
    },
    {
      "epoch": 5.614964068356084,
      "grad_norm": 0.44869399070739746,
      "learning_rate": 3.2460167025561016e-05,
      "loss": 0.0374,
      "step": 163300
    },
    {
      "epoch": 5.618402503180552,
      "grad_norm": 0.37146902084350586,
      "learning_rate": 3.244942168581486e-05,
      "loss": 0.036,
      "step": 163400
    },
    {
      "epoch": 5.62184093800502,
      "grad_norm": 0.0802321806550026,
      "learning_rate": 3.243867634606871e-05,
      "loss": 0.0367,
      "step": 163500
    },
    {
      "epoch": 5.625279372829488,
      "grad_norm": 0.09361400455236435,
      "learning_rate": 3.242793100632256e-05,
      "loss": 0.0406,
      "step": 163600
    },
    {
      "epoch": 5.628717807653956,
      "grad_norm": 0.17934896051883698,
      "learning_rate": 3.2417185666576404e-05,
      "loss": 0.0356,
      "step": 163700
    },
    {
      "epoch": 5.632156242478424,
      "grad_norm": 0.18082764744758606,
      "learning_rate": 3.2406440326830256e-05,
      "loss": 0.04,
      "step": 163800
    },
    {
      "epoch": 5.635594677302892,
      "grad_norm": 0.15264086425304413,
      "learning_rate": 3.2395802440481566e-05,
      "loss": 0.0376,
      "step": 163900
    },
    {
      "epoch": 5.639033112127359,
      "grad_norm": 0.23438353836536407,
      "learning_rate": 3.238505710073541e-05,
      "loss": 0.0403,
      "step": 164000
    },
    {
      "epoch": 5.642471546951827,
      "grad_norm": 0.3737296760082245,
      "learning_rate": 3.237431176098926e-05,
      "loss": 0.0353,
      "step": 164100
    },
    {
      "epoch": 5.645909981776295,
      "grad_norm": 0.16641446948051453,
      "learning_rate": 3.236356642124311e-05,
      "loss": 0.0332,
      "step": 164200
    },
    {
      "epoch": 5.6493484166007635,
      "grad_norm": 0.07153560221195221,
      "learning_rate": 3.235282108149696e-05,
      "loss": 0.0387,
      "step": 164300
    },
    {
      "epoch": 5.6527868514252315,
      "grad_norm": 0.46373969316482544,
      "learning_rate": 3.2342075741750806e-05,
      "loss": 0.0388,
      "step": 164400
    },
    {
      "epoch": 5.656225286249699,
      "grad_norm": 0.18226118385791779,
      "learning_rate": 3.233133040200465e-05,
      "loss": 0.0393,
      "step": 164500
    },
    {
      "epoch": 5.659663721074167,
      "grad_norm": 0.1323934644460678,
      "learning_rate": 3.23205850622585e-05,
      "loss": 0.0391,
      "step": 164600
    },
    {
      "epoch": 5.663102155898635,
      "grad_norm": 0.1864161342382431,
      "learning_rate": 3.230983972251235e-05,
      "loss": 0.0359,
      "step": 164700
    },
    {
      "epoch": 5.666540590723103,
      "grad_norm": 0.10222931951284409,
      "learning_rate": 3.22990943827662e-05,
      "loss": 0.0305,
      "step": 164800
    },
    {
      "epoch": 5.669979025547571,
      "grad_norm": 0.09400559961795807,
      "learning_rate": 3.2288349043020046e-05,
      "loss": 0.0392,
      "step": 164900
    },
    {
      "epoch": 5.673417460372039,
      "grad_norm": 0.18878871202468872,
      "learning_rate": 3.227760370327389e-05,
      "loss": 0.037,
      "step": 165000
    },
    {
      "epoch": 5.676855895196507,
      "grad_norm": 0.12440863996744156,
      "learning_rate": 3.226685836352774e-05,
      "loss": 0.0401,
      "step": 165100
    },
    {
      "epoch": 5.680294330020974,
      "grad_norm": 0.33590540289878845,
      "learning_rate": 3.225611302378159e-05,
      "loss": 0.0373,
      "step": 165200
    },
    {
      "epoch": 5.683732764845442,
      "grad_norm": 0.1792110651731491,
      "learning_rate": 3.224536768403544e-05,
      "loss": 0.0359,
      "step": 165300
    },
    {
      "epoch": 5.68717119966991,
      "grad_norm": 0.1289835125207901,
      "learning_rate": 3.2234622344289286e-05,
      "loss": 0.0386,
      "step": 165400
    },
    {
      "epoch": 5.690609634494378,
      "grad_norm": 0.41829895973205566,
      "learning_rate": 3.222387700454313e-05,
      "loss": 0.0371,
      "step": 165500
    },
    {
      "epoch": 5.694048069318846,
      "grad_norm": 0.2150716632604599,
      "learning_rate": 3.221313166479698e-05,
      "loss": 0.0357,
      "step": 165600
    },
    {
      "epoch": 5.697486504143314,
      "grad_norm": 0.25450599193573,
      "learning_rate": 3.220238632505083e-05,
      "loss": 0.0391,
      "step": 165700
    },
    {
      "epoch": 5.700924938967782,
      "grad_norm": 0.12876316905021667,
      "learning_rate": 3.219164098530468e-05,
      "loss": 0.0406,
      "step": 165800
    },
    {
      "epoch": 5.7043633737922494,
      "grad_norm": 0.12418492138385773,
      "learning_rate": 3.2180895645558526e-05,
      "loss": 0.0393,
      "step": 165900
    },
    {
      "epoch": 5.7078018086167175,
      "grad_norm": 0.12979768216609955,
      "learning_rate": 3.217015030581237e-05,
      "loss": 0.0383,
      "step": 166000
    },
    {
      "epoch": 5.7112402434411855,
      "grad_norm": 0.1109568253159523,
      "learning_rate": 3.215940496606622e-05,
      "loss": 0.0342,
      "step": 166100
    },
    {
      "epoch": 5.714678678265654,
      "grad_norm": 0.20516979694366455,
      "learning_rate": 3.214865962632007e-05,
      "loss": 0.0367,
      "step": 166200
    },
    {
      "epoch": 5.718117113090122,
      "grad_norm": 0.508314311504364,
      "learning_rate": 3.2137914286573914e-05,
      "loss": 0.0369,
      "step": 166300
    },
    {
      "epoch": 5.72155554791459,
      "grad_norm": 0.3054211139678955,
      "learning_rate": 3.2127168946827766e-05,
      "loss": 0.037,
      "step": 166400
    },
    {
      "epoch": 5.724993982739057,
      "grad_norm": 0.2836494445800781,
      "learning_rate": 3.211653106047907e-05,
      "loss": 0.0387,
      "step": 166500
    },
    {
      "epoch": 5.728432417563525,
      "grad_norm": 0.07560133934020996,
      "learning_rate": 3.2105785720732914e-05,
      "loss": 0.0371,
      "step": 166600
    },
    {
      "epoch": 5.731870852387993,
      "grad_norm": 0.20333749055862427,
      "learning_rate": 3.2095040380986766e-05,
      "loss": 0.0386,
      "step": 166700
    },
    {
      "epoch": 5.735309287212461,
      "grad_norm": 0.2976475954055786,
      "learning_rate": 3.208429504124061e-05,
      "loss": 0.037,
      "step": 166800
    },
    {
      "epoch": 5.738747722036929,
      "grad_norm": 0.14603230357170105,
      "learning_rate": 3.207354970149446e-05,
      "loss": 0.0356,
      "step": 166900
    },
    {
      "epoch": 5.742186156861397,
      "grad_norm": 0.08981144428253174,
      "learning_rate": 3.206280436174831e-05,
      "loss": 0.0375,
      "step": 167000
    },
    {
      "epoch": 5.745624591685864,
      "grad_norm": 0.1746099442243576,
      "learning_rate": 3.2052059022002154e-05,
      "loss": 0.0381,
      "step": 167100
    },
    {
      "epoch": 5.749063026510332,
      "grad_norm": 0.14220482110977173,
      "learning_rate": 3.2041313682256006e-05,
      "loss": 0.0381,
      "step": 167200
    },
    {
      "epoch": 5.7525014613348,
      "grad_norm": 0.3443833291530609,
      "learning_rate": 3.203056834250985e-05,
      "loss": 0.0378,
      "step": 167300
    },
    {
      "epoch": 5.755939896159268,
      "grad_norm": 0.15342237055301666,
      "learning_rate": 3.20198230027637e-05,
      "loss": 0.0374,
      "step": 167400
    },
    {
      "epoch": 5.759378330983736,
      "grad_norm": 0.09169024974107742,
      "learning_rate": 3.200907766301755e-05,
      "loss": 0.0372,
      "step": 167500
    },
    {
      "epoch": 5.762816765808204,
      "grad_norm": 0.22522932291030884,
      "learning_rate": 3.1998332323271394e-05,
      "loss": 0.0384,
      "step": 167600
    },
    {
      "epoch": 5.766255200632672,
      "grad_norm": 0.23328687250614166,
      "learning_rate": 3.1987586983525246e-05,
      "loss": 0.0408,
      "step": 167700
    },
    {
      "epoch": 5.7696936354571395,
      "grad_norm": 0.310698002576828,
      "learning_rate": 3.197684164377909e-05,
      "loss": 0.0392,
      "step": 167800
    },
    {
      "epoch": 5.773132070281608,
      "grad_norm": 0.0894400104880333,
      "learning_rate": 3.1966096304032943e-05,
      "loss": 0.0373,
      "step": 167900
    },
    {
      "epoch": 5.776570505106076,
      "grad_norm": 0.21801677346229553,
      "learning_rate": 3.195535096428679e-05,
      "loss": 0.039,
      "step": 168000
    },
    {
      "epoch": 5.780008939930544,
      "grad_norm": 0.5266508460044861,
      "learning_rate": 3.1944605624540634e-05,
      "loss": 0.0396,
      "step": 168100
    },
    {
      "epoch": 5.783447374755012,
      "grad_norm": 0.2300540655851364,
      "learning_rate": 3.1933860284794486e-05,
      "loss": 0.0397,
      "step": 168200
    },
    {
      "epoch": 5.78688580957948,
      "grad_norm": 0.4877794086933136,
      "learning_rate": 3.192311494504833e-05,
      "loss": 0.0361,
      "step": 168300
    },
    {
      "epoch": 5.790324244403948,
      "grad_norm": 0.6607303023338318,
      "learning_rate": 3.1912369605302183e-05,
      "loss": 0.0349,
      "step": 168400
    },
    {
      "epoch": 5.793762679228415,
      "grad_norm": 0.1382141262292862,
      "learning_rate": 3.190162426555603e-05,
      "loss": 0.0368,
      "step": 168500
    },
    {
      "epoch": 5.797201114052883,
      "grad_norm": 0.27033984661102295,
      "learning_rate": 3.1890878925809874e-05,
      "loss": 0.0372,
      "step": 168600
    },
    {
      "epoch": 5.800639548877351,
      "grad_norm": 0.391202837228775,
      "learning_rate": 3.1880133586063726e-05,
      "loss": 0.0366,
      "step": 168700
    },
    {
      "epoch": 5.804077983701819,
      "grad_norm": 0.2214353233575821,
      "learning_rate": 3.186938824631757e-05,
      "loss": 0.0385,
      "step": 168800
    },
    {
      "epoch": 5.807516418526287,
      "grad_norm": 0.18066884577274323,
      "learning_rate": 3.185875035996888e-05,
      "loss": 0.0405,
      "step": 168900
    },
    {
      "epoch": 5.810954853350755,
      "grad_norm": 0.11055534332990646,
      "learning_rate": 3.184800502022273e-05,
      "loss": 0.0412,
      "step": 169000
    },
    {
      "epoch": 5.814393288175222,
      "grad_norm": 0.1211220771074295,
      "learning_rate": 3.183725968047658e-05,
      "loss": 0.0355,
      "step": 169100
    },
    {
      "epoch": 5.81783172299969,
      "grad_norm": 0.33068376779556274,
      "learning_rate": 3.182651434073043e-05,
      "loss": 0.0331,
      "step": 169200
    },
    {
      "epoch": 5.821270157824158,
      "grad_norm": 0.47596901655197144,
      "learning_rate": 3.1815769000984276e-05,
      "loss": 0.0399,
      "step": 169300
    },
    {
      "epoch": 5.824708592648626,
      "grad_norm": 0.19129496812820435,
      "learning_rate": 3.180502366123812e-05,
      "loss": 0.0372,
      "step": 169400
    },
    {
      "epoch": 5.828147027473094,
      "grad_norm": 0.13394349813461304,
      "learning_rate": 3.179427832149197e-05,
      "loss": 0.037,
      "step": 169500
    },
    {
      "epoch": 5.8315854622975625,
      "grad_norm": 0.20955802500247955,
      "learning_rate": 3.178353298174582e-05,
      "loss": 0.0386,
      "step": 169600
    },
    {
      "epoch": 5.83502389712203,
      "grad_norm": 0.35440629720687866,
      "learning_rate": 3.177278764199967e-05,
      "loss": 0.0389,
      "step": 169700
    },
    {
      "epoch": 5.838462331946498,
      "grad_norm": 0.23815478384494781,
      "learning_rate": 3.1762042302253516e-05,
      "loss": 0.0363,
      "step": 169800
    },
    {
      "epoch": 5.841900766770966,
      "grad_norm": 0.14161838591098785,
      "learning_rate": 3.175129696250736e-05,
      "loss": 0.0326,
      "step": 169900
    },
    {
      "epoch": 5.845339201595434,
      "grad_norm": 0.04718742519617081,
      "learning_rate": 3.174055162276121e-05,
      "loss": 0.0351,
      "step": 170000
    },
    {
      "epoch": 5.848777636419902,
      "grad_norm": 0.07641372829675674,
      "learning_rate": 3.172980628301506e-05,
      "loss": 0.035,
      "step": 170100
    },
    {
      "epoch": 5.85221607124437,
      "grad_norm": 0.18442773818969727,
      "learning_rate": 3.171906094326891e-05,
      "loss": 0.0379,
      "step": 170200
    },
    {
      "epoch": 5.855654506068838,
      "grad_norm": 0.12828001379966736,
      "learning_rate": 3.1708315603522756e-05,
      "loss": 0.0424,
      "step": 170300
    },
    {
      "epoch": 5.859092940893305,
      "grad_norm": 0.12230350822210312,
      "learning_rate": 3.16975702637766e-05,
      "loss": 0.036,
      "step": 170400
    },
    {
      "epoch": 5.862531375717773,
      "grad_norm": 0.14112713932991028,
      "learning_rate": 3.168682492403045e-05,
      "loss": 0.0393,
      "step": 170500
    },
    {
      "epoch": 5.865969810542241,
      "grad_norm": 0.18765054643154144,
      "learning_rate": 3.16760795842843e-05,
      "loss": 0.0341,
      "step": 170600
    },
    {
      "epoch": 5.869408245366709,
      "grad_norm": 0.22958992421627045,
      "learning_rate": 3.166533424453815e-05,
      "loss": 0.038,
      "step": 170700
    },
    {
      "epoch": 5.872846680191177,
      "grad_norm": 0.2417197823524475,
      "learning_rate": 3.1654588904791996e-05,
      "loss": 0.0386,
      "step": 170800
    },
    {
      "epoch": 5.876285115015645,
      "grad_norm": 0.4986249804496765,
      "learning_rate": 3.164384356504584e-05,
      "loss": 0.0381,
      "step": 170900
    },
    {
      "epoch": 5.879723549840113,
      "grad_norm": 0.23212021589279175,
      "learning_rate": 3.163309822529969e-05,
      "loss": 0.0378,
      "step": 171000
    },
    {
      "epoch": 5.88316198466458,
      "grad_norm": 0.6982578039169312,
      "learning_rate": 3.162235288555354e-05,
      "loss": 0.0368,
      "step": 171100
    },
    {
      "epoch": 5.886600419489048,
      "grad_norm": 0.3077849745750427,
      "learning_rate": 3.1611607545807384e-05,
      "loss": 0.0391,
      "step": 171200
    },
    {
      "epoch": 5.8900388543135165,
      "grad_norm": 0.10162672400474548,
      "learning_rate": 3.1600862206061236e-05,
      "loss": 0.0352,
      "step": 171300
    },
    {
      "epoch": 5.8934772891379845,
      "grad_norm": 0.08276708424091339,
      "learning_rate": 3.159011686631508e-05,
      "loss": 0.0391,
      "step": 171400
    },
    {
      "epoch": 5.896915723962453,
      "grad_norm": 0.2243148684501648,
      "learning_rate": 3.157947897996639e-05,
      "loss": 0.035,
      "step": 171500
    },
    {
      "epoch": 5.90035415878692,
      "grad_norm": 0.12148763984441757,
      "learning_rate": 3.1568733640220236e-05,
      "loss": 0.0405,
      "step": 171600
    },
    {
      "epoch": 5.903792593611388,
      "grad_norm": 0.13584129512310028,
      "learning_rate": 3.155798830047408e-05,
      "loss": 0.0394,
      "step": 171700
    },
    {
      "epoch": 5.907231028435856,
      "grad_norm": 0.2936306893825531,
      "learning_rate": 3.1547242960727933e-05,
      "loss": 0.0353,
      "step": 171800
    },
    {
      "epoch": 5.910669463260324,
      "grad_norm": 0.49839961528778076,
      "learning_rate": 3.153649762098178e-05,
      "loss": 0.0347,
      "step": 171900
    },
    {
      "epoch": 5.914107898084792,
      "grad_norm": 0.2591375708580017,
      "learning_rate": 3.152575228123563e-05,
      "loss": 0.0389,
      "step": 172000
    },
    {
      "epoch": 5.91754633290926,
      "grad_norm": 0.39698919653892517,
      "learning_rate": 3.1515006941489476e-05,
      "loss": 0.0363,
      "step": 172100
    },
    {
      "epoch": 5.920984767733728,
      "grad_norm": 0.24563345313072205,
      "learning_rate": 3.150426160174332e-05,
      "loss": 0.039,
      "step": 172200
    },
    {
      "epoch": 5.924423202558195,
      "grad_norm": 0.10892066359519958,
      "learning_rate": 3.1493516261997173e-05,
      "loss": 0.0393,
      "step": 172300
    },
    {
      "epoch": 5.927861637382663,
      "grad_norm": 0.08728121221065521,
      "learning_rate": 3.148277092225102e-05,
      "loss": 0.0327,
      "step": 172400
    },
    {
      "epoch": 5.931300072207131,
      "grad_norm": 0.3308677077293396,
      "learning_rate": 3.147202558250487e-05,
      "loss": 0.0361,
      "step": 172500
    },
    {
      "epoch": 5.934738507031599,
      "grad_norm": 0.2610786259174347,
      "learning_rate": 3.1461280242758716e-05,
      "loss": 0.0348,
      "step": 172600
    },
    {
      "epoch": 5.938176941856067,
      "grad_norm": 0.1296147108078003,
      "learning_rate": 3.145053490301256e-05,
      "loss": 0.0371,
      "step": 172700
    },
    {
      "epoch": 5.941615376680535,
      "grad_norm": 0.14636515080928802,
      "learning_rate": 3.1439789563266413e-05,
      "loss": 0.0328,
      "step": 172800
    },
    {
      "epoch": 5.945053811505003,
      "grad_norm": 0.16410987079143524,
      "learning_rate": 3.142904422352026e-05,
      "loss": 0.0333,
      "step": 172900
    },
    {
      "epoch": 5.9484922463294705,
      "grad_norm": 0.359663724899292,
      "learning_rate": 3.141829888377411e-05,
      "loss": 0.0338,
      "step": 173000
    },
    {
      "epoch": 5.9519306811539385,
      "grad_norm": 0.1497359722852707,
      "learning_rate": 3.1407553544027956e-05,
      "loss": 0.0411,
      "step": 173100
    },
    {
      "epoch": 5.955369115978407,
      "grad_norm": 0.09553059935569763,
      "learning_rate": 3.13968082042818e-05,
      "loss": 0.036,
      "step": 173200
    },
    {
      "epoch": 5.958807550802875,
      "grad_norm": 0.06198790669441223,
      "learning_rate": 3.1386062864535654e-05,
      "loss": 0.0363,
      "step": 173300
    },
    {
      "epoch": 5.962245985627343,
      "grad_norm": 0.1856040060520172,
      "learning_rate": 3.13753175247895e-05,
      "loss": 0.0345,
      "step": 173400
    },
    {
      "epoch": 5.965684420451811,
      "grad_norm": 0.3128887116909027,
      "learning_rate": 3.136457218504335e-05,
      "loss": 0.0423,
      "step": 173500
    },
    {
      "epoch": 5.969122855276279,
      "grad_norm": 0.15702831745147705,
      "learning_rate": 3.1353826845297196e-05,
      "loss": 0.0383,
      "step": 173600
    },
    {
      "epoch": 5.972561290100746,
      "grad_norm": 0.6590519547462463,
      "learning_rate": 3.134308150555104e-05,
      "loss": 0.0403,
      "step": 173700
    },
    {
      "epoch": 5.975999724925214,
      "grad_norm": 0.16036678850650787,
      "learning_rate": 3.1332336165804894e-05,
      "loss": 0.0362,
      "step": 173800
    },
    {
      "epoch": 5.979438159749682,
      "grad_norm": 0.2039511799812317,
      "learning_rate": 3.132159082605874e-05,
      "loss": 0.0381,
      "step": 173900
    },
    {
      "epoch": 5.98287659457415,
      "grad_norm": 0.16237792372703552,
      "learning_rate": 3.131084548631259e-05,
      "loss": 0.0362,
      "step": 174000
    },
    {
      "epoch": 5.986315029398618,
      "grad_norm": 0.23813985288143158,
      "learning_rate": 3.1300100146566436e-05,
      "loss": 0.0379,
      "step": 174100
    },
    {
      "epoch": 5.989753464223085,
      "grad_norm": 0.15456683933734894,
      "learning_rate": 3.128935480682028e-05,
      "loss": 0.0371,
      "step": 174200
    },
    {
      "epoch": 5.993191899047553,
      "grad_norm": 0.46344080567359924,
      "learning_rate": 3.1278609467074134e-05,
      "loss": 0.0341,
      "step": 174300
    },
    {
      "epoch": 5.996630333872021,
      "grad_norm": 0.2050962746143341,
      "learning_rate": 3.126786412732798e-05,
      "loss": 0.0373,
      "step": 174400
    },
    {
      "epoch": 6.0,
      "eval_accuracy_macro_0.5": 0.9842437505722046,
      "eval_accuracy_micro_0.5": 0.9842436909675598,
      "eval_accuracy_weighted_0.5": 0.9742047190666199,
      "eval_aucroc_macro": 0.9143507480621338,
      "eval_aucroc_micro": 0.9178491830825806,
      "eval_aucroc_weighted": 0.914535641670227,
      "eval_f1_macro_0.5": 0.7602725625038147,
      "eval_f1_macro_0.6": 0.7434488534927368,
      "eval_f1_macro_0.7": 0.7105284929275513,
      "eval_f1_macro_0.8": 0.5504912734031677,
      "eval_f1_micro_0.5": 0.771032989025116,
      "eval_f1_micro_0.6": 0.7577075958251953,
      "eval_f1_micro_0.7": 0.7316789627075195,
      "eval_f1_micro_0.8": 0.6857882142066956,
      "eval_f1_micro_0.9": 0.5790133476257324,
      "eval_f1_weighted_0.5": 0.7661643624305725,
      "eval_f1_weighted_0.6": 0.7483271360397339,
      "eval_f1_weighted_0.7": 0.7159422039985657,
      "eval_f1_weighted_0.8": 0.5415893197059631,
      "eval_loss": 0.034664202481508255,
      "eval_runtime": 1884.879,
      "eval_samples_per_second": 30.841,
      "eval_steps_per_second": 3.855,
      "step": 174498
    },
    {
      "epoch": 6.000068768696489,
      "grad_norm": 0.5134375691413879,
      "learning_rate": 3.125722624097929e-05,
      "loss": 0.0364,
      "step": 174500
    },
    {
      "epoch": 6.003507203520957,
      "grad_norm": 0.23784998059272766,
      "learning_rate": 3.124648090123314e-05,
      "loss": 0.0347,
      "step": 174600
    },
    {
      "epoch": 6.006945638345425,
      "grad_norm": 0.07370047271251678,
      "learning_rate": 3.1235735561486986e-05,
      "loss": 0.0364,
      "step": 174700
    },
    {
      "epoch": 6.010384073169893,
      "grad_norm": 0.16103258728981018,
      "learning_rate": 3.122499022174084e-05,
      "loss": 0.0399,
      "step": 174800
    },
    {
      "epoch": 6.013822507994361,
      "grad_norm": 0.0859275683760643,
      "learning_rate": 3.121424488199468e-05,
      "loss": 0.0362,
      "step": 174900
    },
    {
      "epoch": 6.017260942818829,
      "grad_norm": 0.07687569409608841,
      "learning_rate": 3.120349954224853e-05,
      "loss": 0.0362,
      "step": 175000
    },
    {
      "epoch": 6.020699377643297,
      "grad_norm": 0.1666719913482666,
      "learning_rate": 3.119275420250238e-05,
      "loss": 0.0359,
      "step": 175100
    },
    {
      "epoch": 6.024137812467765,
      "grad_norm": 0.06051652505993843,
      "learning_rate": 3.1182008862756226e-05,
      "loss": 0.0355,
      "step": 175200
    },
    {
      "epoch": 6.027576247292233,
      "grad_norm": 0.147805854678154,
      "learning_rate": 3.117126352301008e-05,
      "loss": 0.0398,
      "step": 175300
    },
    {
      "epoch": 6.031014682116701,
      "grad_norm": 0.025666972622275352,
      "learning_rate": 3.116051818326392e-05,
      "loss": 0.0372,
      "step": 175400
    },
    {
      "epoch": 6.034453116941169,
      "grad_norm": 0.07648605108261108,
      "learning_rate": 3.114977284351777e-05,
      "loss": 0.0371,
      "step": 175500
    },
    {
      "epoch": 6.037891551765636,
      "grad_norm": 0.2745271623134613,
      "learning_rate": 3.113902750377162e-05,
      "loss": 0.038,
      "step": 175600
    },
    {
      "epoch": 6.041329986590104,
      "grad_norm": 0.10244805365800858,
      "learning_rate": 3.1128282164025466e-05,
      "loss": 0.0354,
      "step": 175700
    },
    {
      "epoch": 6.044768421414572,
      "grad_norm": 0.0985584557056427,
      "learning_rate": 3.111753682427931e-05,
      "loss": 0.0344,
      "step": 175800
    },
    {
      "epoch": 6.04820685623904,
      "grad_norm": 0.09535259753465652,
      "learning_rate": 3.1106791484533156e-05,
      "loss": 0.0378,
      "step": 175900
    },
    {
      "epoch": 6.051645291063508,
      "grad_norm": 0.0814724788069725,
      "learning_rate": 3.109604614478701e-05,
      "loss": 0.0376,
      "step": 176000
    },
    {
      "epoch": 6.055083725887976,
      "grad_norm": 0.09111719578504562,
      "learning_rate": 3.1085300805040854e-05,
      "loss": 0.0345,
      "step": 176100
    },
    {
      "epoch": 6.058522160712443,
      "grad_norm": 0.08079033344984055,
      "learning_rate": 3.10745554652947e-05,
      "loss": 0.0362,
      "step": 176200
    },
    {
      "epoch": 6.061960595536911,
      "grad_norm": 0.25225284695625305,
      "learning_rate": 3.106381012554855e-05,
      "loss": 0.0368,
      "step": 176300
    },
    {
      "epoch": 6.065399030361379,
      "grad_norm": 0.1195794865489006,
      "learning_rate": 3.1053064785802397e-05,
      "loss": 0.034,
      "step": 176400
    },
    {
      "epoch": 6.068837465185847,
      "grad_norm": 0.11738896369934082,
      "learning_rate": 3.104231944605624e-05,
      "loss": 0.0373,
      "step": 176500
    },
    {
      "epoch": 6.0722759000103155,
      "grad_norm": 0.3096461892127991,
      "learning_rate": 3.1031574106310094e-05,
      "loss": 0.0413,
      "step": 176600
    },
    {
      "epoch": 6.0757143348347835,
      "grad_norm": 0.15498054027557373,
      "learning_rate": 3.1020936219961404e-05,
      "loss": 0.0333,
      "step": 176700
    },
    {
      "epoch": 6.079152769659251,
      "grad_norm": 0.16136564314365387,
      "learning_rate": 3.101019088021525e-05,
      "loss": 0.0345,
      "step": 176800
    },
    {
      "epoch": 6.082591204483719,
      "grad_norm": 0.3163261115550995,
      "learning_rate": 3.09994455404691e-05,
      "loss": 0.038,
      "step": 176900
    },
    {
      "epoch": 6.086029639308187,
      "grad_norm": 0.03441475331783295,
      "learning_rate": 3.0988700200722946e-05,
      "loss": 0.0378,
      "step": 177000
    },
    {
      "epoch": 6.089468074132655,
      "grad_norm": 0.1255568563938141,
      "learning_rate": 3.097795486097679e-05,
      "loss": 0.0337,
      "step": 177100
    },
    {
      "epoch": 6.092906508957123,
      "grad_norm": 0.03864351287484169,
      "learning_rate": 3.0967209521230644e-05,
      "loss": 0.0389,
      "step": 177200
    },
    {
      "epoch": 6.096344943781591,
      "grad_norm": 0.1305621862411499,
      "learning_rate": 3.095646418148449e-05,
      "loss": 0.0356,
      "step": 177300
    },
    {
      "epoch": 6.099783378606059,
      "grad_norm": 0.36393073201179504,
      "learning_rate": 3.094571884173834e-05,
      "loss": 0.0411,
      "step": 177400
    },
    {
      "epoch": 6.103221813430526,
      "grad_norm": 0.08643736690282822,
      "learning_rate": 3.0934973501992186e-05,
      "loss": 0.037,
      "step": 177500
    },
    {
      "epoch": 6.106660248254994,
      "grad_norm": 0.13520602881908417,
      "learning_rate": 3.092422816224603e-05,
      "loss": 0.036,
      "step": 177600
    },
    {
      "epoch": 6.110098683079462,
      "grad_norm": 0.23050272464752197,
      "learning_rate": 3.0913482822499884e-05,
      "loss": 0.0377,
      "step": 177700
    },
    {
      "epoch": 6.11353711790393,
      "grad_norm": 0.023021895438432693,
      "learning_rate": 3.090273748275373e-05,
      "loss": 0.0368,
      "step": 177800
    },
    {
      "epoch": 6.116975552728398,
      "grad_norm": 0.17110349237918854,
      "learning_rate": 3.089199214300758e-05,
      "loss": 0.0379,
      "step": 177900
    },
    {
      "epoch": 6.120413987552866,
      "grad_norm": 0.08306602388620377,
      "learning_rate": 3.0881246803261426e-05,
      "loss": 0.0393,
      "step": 178000
    },
    {
      "epoch": 6.123852422377333,
      "grad_norm": 0.06323015689849854,
      "learning_rate": 3.087050146351527e-05,
      "loss": 0.0366,
      "step": 178100
    },
    {
      "epoch": 6.127290857201801,
      "grad_norm": 0.03532897308468819,
      "learning_rate": 3.0859756123769124e-05,
      "loss": 0.0344,
      "step": 178200
    },
    {
      "epoch": 6.1307292920262695,
      "grad_norm": 0.062418289482593536,
      "learning_rate": 3.084901078402297e-05,
      "loss": 0.0349,
      "step": 178300
    },
    {
      "epoch": 6.1341677268507375,
      "grad_norm": 0.2493906170129776,
      "learning_rate": 3.083826544427682e-05,
      "loss": 0.0349,
      "step": 178400
    },
    {
      "epoch": 6.137606161675206,
      "grad_norm": 0.09253594279289246,
      "learning_rate": 3.0827520104530666e-05,
      "loss": 0.0392,
      "step": 178500
    },
    {
      "epoch": 6.141044596499674,
      "grad_norm": 0.17335209250450134,
      "learning_rate": 3.081677476478451e-05,
      "loss": 0.0373,
      "step": 178600
    },
    {
      "epoch": 6.144483031324142,
      "grad_norm": 0.09433379024267197,
      "learning_rate": 3.0806029425038364e-05,
      "loss": 0.0343,
      "step": 178700
    },
    {
      "epoch": 6.147921466148609,
      "grad_norm": 0.4366174638271332,
      "learning_rate": 3.079528408529221e-05,
      "loss": 0.0368,
      "step": 178800
    },
    {
      "epoch": 6.151359900973077,
      "grad_norm": 0.19533824920654297,
      "learning_rate": 3.078453874554606e-05,
      "loss": 0.0381,
      "step": 178900
    },
    {
      "epoch": 6.154798335797545,
      "grad_norm": 0.1338261514902115,
      "learning_rate": 3.077390085919737e-05,
      "loss": 0.0376,
      "step": 179000
    },
    {
      "epoch": 6.158236770622013,
      "grad_norm": 0.18330712616443634,
      "learning_rate": 3.0763155519451216e-05,
      "loss": 0.0372,
      "step": 179100
    },
    {
      "epoch": 6.161675205446481,
      "grad_norm": 0.08247853070497513,
      "learning_rate": 3.075241017970507e-05,
      "loss": 0.0368,
      "step": 179200
    },
    {
      "epoch": 6.165113640270949,
      "grad_norm": 0.16731666028499603,
      "learning_rate": 3.074166483995891e-05,
      "loss": 0.0392,
      "step": 179300
    },
    {
      "epoch": 6.168552075095416,
      "grad_norm": 0.0640079528093338,
      "learning_rate": 3.073091950021276e-05,
      "loss": 0.0379,
      "step": 179400
    },
    {
      "epoch": 6.171990509919884,
      "grad_norm": 0.35939016938209534,
      "learning_rate": 3.072017416046661e-05,
      "loss": 0.0376,
      "step": 179500
    },
    {
      "epoch": 6.175428944744352,
      "grad_norm": 0.19220945239067078,
      "learning_rate": 3.0709428820720456e-05,
      "loss": 0.0357,
      "step": 179600
    },
    {
      "epoch": 6.17886737956882,
      "grad_norm": 0.13973382115364075,
      "learning_rate": 3.069868348097431e-05,
      "loss": 0.0329,
      "step": 179700
    },
    {
      "epoch": 6.182305814393288,
      "grad_norm": 0.05288754403591156,
      "learning_rate": 3.068793814122815e-05,
      "loss": 0.0374,
      "step": 179800
    },
    {
      "epoch": 6.185744249217756,
      "grad_norm": 0.09706143289804459,
      "learning_rate": 3.0677192801482e-05,
      "loss": 0.0358,
      "step": 179900
    },
    {
      "epoch": 6.189182684042224,
      "grad_norm": 0.054428309202194214,
      "learning_rate": 3.066644746173585e-05,
      "loss": 0.0346,
      "step": 180000
    },
    {
      "epoch": 6.1926211188666915,
      "grad_norm": 0.12733589112758636,
      "learning_rate": 3.0655702121989696e-05,
      "loss": 0.0379,
      "step": 180100
    },
    {
      "epoch": 6.19605955369116,
      "grad_norm": 0.2530185878276825,
      "learning_rate": 3.064495678224354e-05,
      "loss": 0.0365,
      "step": 180200
    },
    {
      "epoch": 6.199497988515628,
      "grad_norm": 0.047553226351737976,
      "learning_rate": 3.063421144249739e-05,
      "loss": 0.0372,
      "step": 180300
    },
    {
      "epoch": 6.202936423340096,
      "grad_norm": 0.12272415310144424,
      "learning_rate": 3.062346610275124e-05,
      "loss": 0.0405,
      "step": 180400
    },
    {
      "epoch": 6.206374858164564,
      "grad_norm": 0.1321924775838852,
      "learning_rate": 3.0612720763005084e-05,
      "loss": 0.0322,
      "step": 180500
    },
    {
      "epoch": 6.209813292989032,
      "grad_norm": 0.3698720932006836,
      "learning_rate": 3.0601975423258936e-05,
      "loss": 0.0381,
      "step": 180600
    },
    {
      "epoch": 6.213251727813499,
      "grad_norm": 0.11071182042360306,
      "learning_rate": 3.059123008351278e-05,
      "loss": 0.035,
      "step": 180700
    },
    {
      "epoch": 6.216690162637967,
      "grad_norm": 0.07490082085132599,
      "learning_rate": 3.0580484743766627e-05,
      "loss": 0.0355,
      "step": 180800
    },
    {
      "epoch": 6.220128597462435,
      "grad_norm": 0.10540224611759186,
      "learning_rate": 3.056973940402048e-05,
      "loss": 0.0333,
      "step": 180900
    },
    {
      "epoch": 6.223567032286903,
      "grad_norm": 0.08117622882127762,
      "learning_rate": 3.0558994064274324e-05,
      "loss": 0.0352,
      "step": 181000
    },
    {
      "epoch": 6.227005467111371,
      "grad_norm": 0.10169588774442673,
      "learning_rate": 3.054824872452817e-05,
      "loss": 0.0352,
      "step": 181100
    },
    {
      "epoch": 6.230443901935839,
      "grad_norm": 0.1865502893924713,
      "learning_rate": 3.053750338478202e-05,
      "loss": 0.0356,
      "step": 181200
    },
    {
      "epoch": 6.233882336760307,
      "grad_norm": 0.11132381111383438,
      "learning_rate": 3.052675804503587e-05,
      "loss": 0.034,
      "step": 181300
    },
    {
      "epoch": 6.237320771584774,
      "grad_norm": Infinity,
      "learning_rate": 3.051612015868718e-05,
      "loss": 0.0348,
      "step": 181400
    },
    {
      "epoch": 6.240759206409242,
      "grad_norm": 0.17477191984653473,
      "learning_rate": 3.0505374818941028e-05,
      "loss": 0.0363,
      "step": 181500
    },
    {
      "epoch": 6.24419764123371,
      "grad_norm": 0.13029977679252625,
      "learning_rate": 3.0494629479194874e-05,
      "loss": 0.0357,
      "step": 181600
    },
    {
      "epoch": 6.247636076058178,
      "grad_norm": 0.045817356556653976,
      "learning_rate": 3.0483884139448722e-05,
      "loss": 0.0344,
      "step": 181700
    },
    {
      "epoch": 6.251074510882646,
      "grad_norm": 0.08832313120365143,
      "learning_rate": 3.047313879970257e-05,
      "loss": 0.0356,
      "step": 181800
    },
    {
      "epoch": 6.2545129457071145,
      "grad_norm": 0.19732967019081116,
      "learning_rate": 3.0462393459956416e-05,
      "loss": 0.0359,
      "step": 181900
    },
    {
      "epoch": 6.257951380531582,
      "grad_norm": 0.07970131933689117,
      "learning_rate": 3.045164812021027e-05,
      "loss": 0.0399,
      "step": 182000
    },
    {
      "epoch": 6.26138981535605,
      "grad_norm": 0.16589955985546112,
      "learning_rate": 3.0440902780464114e-05,
      "loss": 0.0366,
      "step": 182100
    },
    {
      "epoch": 6.264828250180518,
      "grad_norm": 0.2660140097141266,
      "learning_rate": 3.043015744071796e-05,
      "loss": 0.0392,
      "step": 182200
    },
    {
      "epoch": 6.268266685004986,
      "grad_norm": 0.059182558208703995,
      "learning_rate": 3.041941210097181e-05,
      "loss": 0.0371,
      "step": 182300
    },
    {
      "epoch": 6.271705119829454,
      "grad_norm": 0.13517242670059204,
      "learning_rate": 3.0408666761225656e-05,
      "loss": 0.0354,
      "step": 182400
    },
    {
      "epoch": 6.275143554653922,
      "grad_norm": 0.12396478652954102,
      "learning_rate": 3.039792142147951e-05,
      "loss": 0.0334,
      "step": 182500
    },
    {
      "epoch": 6.27858198947839,
      "grad_norm": 0.06958730518817902,
      "learning_rate": 3.0387176081733354e-05,
      "loss": 0.0345,
      "step": 182600
    },
    {
      "epoch": 6.282020424302857,
      "grad_norm": 0.4328612685203552,
      "learning_rate": 3.03764307419872e-05,
      "loss": 0.0351,
      "step": 182700
    },
    {
      "epoch": 6.285458859127325,
      "grad_norm": 0.22506359219551086,
      "learning_rate": 3.036568540224105e-05,
      "loss": 0.037,
      "step": 182800
    },
    {
      "epoch": 6.288897293951793,
      "grad_norm": 0.04901424050331116,
      "learning_rate": 3.0354940062494896e-05,
      "loss": 0.0362,
      "step": 182900
    },
    {
      "epoch": 6.292335728776261,
      "grad_norm": 0.09409283846616745,
      "learning_rate": 3.034419472274875e-05,
      "loss": 0.0374,
      "step": 183000
    },
    {
      "epoch": 6.295774163600729,
      "grad_norm": 0.15046019852161407,
      "learning_rate": 3.0333449383002594e-05,
      "loss": 0.0398,
      "step": 183100
    },
    {
      "epoch": 6.299212598425197,
      "grad_norm": 0.2063458114862442,
      "learning_rate": 3.032270404325644e-05,
      "loss": 0.0349,
      "step": 183200
    },
    {
      "epoch": 6.302651033249664,
      "grad_norm": 0.06979596614837646,
      "learning_rate": 3.031195870351029e-05,
      "loss": 0.0354,
      "step": 183300
    },
    {
      "epoch": 6.306089468074132,
      "grad_norm": 0.17333176732063293,
      "learning_rate": 3.0301213363764136e-05,
      "loss": 0.0387,
      "step": 183400
    },
    {
      "epoch": 6.3095279028986,
      "grad_norm": 0.08953429758548737,
      "learning_rate": 3.029046802401799e-05,
      "loss": 0.0352,
      "step": 183500
    },
    {
      "epoch": 6.3129663377230685,
      "grad_norm": 0.17511525750160217,
      "learning_rate": 3.0279722684271834e-05,
      "loss": 0.0356,
      "step": 183600
    },
    {
      "epoch": 6.3164047725475365,
      "grad_norm": 0.13478685915470123,
      "learning_rate": 3.026897734452568e-05,
      "loss": 0.0363,
      "step": 183700
    },
    {
      "epoch": 6.319843207372005,
      "grad_norm": 0.049342647194862366,
      "learning_rate": 3.025823200477953e-05,
      "loss": 0.0384,
      "step": 183800
    },
    {
      "epoch": 6.323281642196472,
      "grad_norm": 0.09562361240386963,
      "learning_rate": 3.0247486665033376e-05,
      "loss": 0.0351,
      "step": 183900
    },
    {
      "epoch": 6.32672007702094,
      "grad_norm": 0.15096920728683472,
      "learning_rate": 3.0236741325287225e-05,
      "loss": 0.0373,
      "step": 184000
    },
    {
      "epoch": 6.330158511845408,
      "grad_norm": 0.20383651554584503,
      "learning_rate": 3.0225995985541074e-05,
      "loss": 0.0344,
      "step": 184100
    },
    {
      "epoch": 6.333596946669876,
      "grad_norm": 0.050201524049043655,
      "learning_rate": 3.021525064579492e-05,
      "loss": 0.0327,
      "step": 184200
    },
    {
      "epoch": 6.337035381494344,
      "grad_norm": 0.024752125144004822,
      "learning_rate": 3.0204505306048768e-05,
      "loss": 0.033,
      "step": 184300
    },
    {
      "epoch": 6.340473816318812,
      "grad_norm": 0.13387663662433624,
      "learning_rate": 3.0193759966302616e-05,
      "loss": 0.0375,
      "step": 184400
    },
    {
      "epoch": 6.34391225114328,
      "grad_norm": 0.21453583240509033,
      "learning_rate": 3.0183014626556465e-05,
      "loss": 0.0347,
      "step": 184500
    },
    {
      "epoch": 6.347350685967747,
      "grad_norm": 0.1505829244852066,
      "learning_rate": 3.017226928681031e-05,
      "loss": 0.0343,
      "step": 184600
    },
    {
      "epoch": 6.350789120792215,
      "grad_norm": 0.07677838951349258,
      "learning_rate": 3.016152394706416e-05,
      "loss": 0.0378,
      "step": 184700
    },
    {
      "epoch": 6.354227555616683,
      "grad_norm": 0.10692168027162552,
      "learning_rate": 3.0150778607318008e-05,
      "loss": 0.0339,
      "step": 184800
    },
    {
      "epoch": 6.357665990441151,
      "grad_norm": 0.2707561254501343,
      "learning_rate": 3.0140033267571853e-05,
      "loss": 0.0374,
      "step": 184900
    },
    {
      "epoch": 6.361104425265619,
      "grad_norm": 0.05471137538552284,
      "learning_rate": 3.0129287927825705e-05,
      "loss": 0.0361,
      "step": 185000
    },
    {
      "epoch": 6.364542860090087,
      "grad_norm": 0.2028641700744629,
      "learning_rate": 3.0118650041477015e-05,
      "loss": 0.0385,
      "step": 185100
    },
    {
      "epoch": 6.367981294914555,
      "grad_norm": 0.11892007291316986,
      "learning_rate": 3.010790470173086e-05,
      "loss": 0.0322,
      "step": 185200
    },
    {
      "epoch": 6.3714197297390225,
      "grad_norm": 0.06694665551185608,
      "learning_rate": 3.0097159361984712e-05,
      "loss": 0.0373,
      "step": 185300
    },
    {
      "epoch": 6.3748581645634905,
      "grad_norm": 0.06042509526014328,
      "learning_rate": 3.0086414022238557e-05,
      "loss": 0.0364,
      "step": 185400
    },
    {
      "epoch": 6.378296599387959,
      "grad_norm": 0.1488579511642456,
      "learning_rate": 3.0075668682492403e-05,
      "loss": 0.036,
      "step": 185500
    },
    {
      "epoch": 6.381735034212427,
      "grad_norm": 0.4514813721179962,
      "learning_rate": 3.0064923342746255e-05,
      "loss": 0.0363,
      "step": 185600
    },
    {
      "epoch": 6.385173469036895,
      "grad_norm": 0.14166221022605896,
      "learning_rate": 3.00541780030001e-05,
      "loss": 0.0359,
      "step": 185700
    },
    {
      "epoch": 6.388611903861363,
      "grad_norm": 0.09540612995624542,
      "learning_rate": 3.0043432663253952e-05,
      "loss": 0.0396,
      "step": 185800
    },
    {
      "epoch": 6.39205033868583,
      "grad_norm": 0.0829935371875763,
      "learning_rate": 3.0032687323507797e-05,
      "loss": 0.0368,
      "step": 185900
    },
    {
      "epoch": 6.395488773510298,
      "grad_norm": 0.03216607868671417,
      "learning_rate": 3.0021941983761643e-05,
      "loss": 0.0362,
      "step": 186000
    },
    {
      "epoch": 6.398927208334766,
      "grad_norm": 0.0663815289735794,
      "learning_rate": 3.0011196644015495e-05,
      "loss": 0.034,
      "step": 186100
    },
    {
      "epoch": 6.402365643159234,
      "grad_norm": 0.0670667290687561,
      "learning_rate": 3.000045130426934e-05,
      "loss": 0.0375,
      "step": 186200
    },
    {
      "epoch": 6.405804077983702,
      "grad_norm": 0.05916188657283783,
      "learning_rate": 2.998970596452319e-05,
      "loss": 0.0363,
      "step": 186300
    },
    {
      "epoch": 6.40924251280817,
      "grad_norm": 0.11884895712137222,
      "learning_rate": 2.9978960624777037e-05,
      "loss": 0.0344,
      "step": 186400
    },
    {
      "epoch": 6.412680947632637,
      "grad_norm": 0.06249163672327995,
      "learning_rate": 2.9968215285030883e-05,
      "loss": 0.037,
      "step": 186500
    },
    {
      "epoch": 6.416119382457105,
      "grad_norm": 0.36269891262054443,
      "learning_rate": 2.995757739868219e-05,
      "loss": 0.0352,
      "step": 186600
    },
    {
      "epoch": 6.419557817281573,
      "grad_norm": 0.1803215742111206,
      "learning_rate": 2.994683205893604e-05,
      "loss": 0.0349,
      "step": 186700
    },
    {
      "epoch": 6.422996252106041,
      "grad_norm": 0.05324334278702736,
      "learning_rate": 2.9936086719189886e-05,
      "loss": 0.0358,
      "step": 186800
    },
    {
      "epoch": 6.426434686930509,
      "grad_norm": 0.1198359876871109,
      "learning_rate": 2.992534137944374e-05,
      "loss": 0.0368,
      "step": 186900
    },
    {
      "epoch": 6.429873121754977,
      "grad_norm": 0.03194654732942581,
      "learning_rate": 2.9914596039697584e-05,
      "loss": 0.0383,
      "step": 187000
    },
    {
      "epoch": 6.433311556579445,
      "grad_norm": 0.057742249220609665,
      "learning_rate": 2.990385069995143e-05,
      "loss": 0.043,
      "step": 187100
    },
    {
      "epoch": 6.436749991403913,
      "grad_norm": 0.10510116815567017,
      "learning_rate": 2.989310536020528e-05,
      "loss": 0.0371,
      "step": 187200
    },
    {
      "epoch": 6.440188426228381,
      "grad_norm": 0.17252349853515625,
      "learning_rate": 2.9882360020459126e-05,
      "loss": 0.0329,
      "step": 187300
    },
    {
      "epoch": 6.443626861052849,
      "grad_norm": 0.07966691255569458,
      "learning_rate": 2.987161468071298e-05,
      "loss": 0.0362,
      "step": 187400
    },
    {
      "epoch": 6.447065295877317,
      "grad_norm": 0.16670101881027222,
      "learning_rate": 2.9860869340966824e-05,
      "loss": 0.0371,
      "step": 187500
    },
    {
      "epoch": 6.450503730701785,
      "grad_norm": 0.3242717683315277,
      "learning_rate": 2.985012400122067e-05,
      "loss": 0.0359,
      "step": 187600
    },
    {
      "epoch": 6.453942165526253,
      "grad_norm": 0.09457986801862717,
      "learning_rate": 2.983937866147452e-05,
      "loss": 0.0343,
      "step": 187700
    },
    {
      "epoch": 6.457380600350721,
      "grad_norm": 0.5938725471496582,
      "learning_rate": 2.9828633321728366e-05,
      "loss": 0.0344,
      "step": 187800
    },
    {
      "epoch": 6.460819035175188,
      "grad_norm": 0.16153724491596222,
      "learning_rate": 2.981788798198222e-05,
      "loss": 0.0377,
      "step": 187900
    },
    {
      "epoch": 6.464257469999656,
      "grad_norm": 0.66170734167099,
      "learning_rate": 2.9807142642236064e-05,
      "loss": 0.0348,
      "step": 188000
    },
    {
      "epoch": 6.467695904824124,
      "grad_norm": 0.0425914041697979,
      "learning_rate": 2.979639730248991e-05,
      "loss": 0.0353,
      "step": 188100
    },
    {
      "epoch": 6.471134339648592,
      "grad_norm": 0.13246066868305206,
      "learning_rate": 2.978565196274376e-05,
      "loss": 0.0366,
      "step": 188200
    },
    {
      "epoch": 6.47457277447306,
      "grad_norm": 0.033371713012456894,
      "learning_rate": 2.9774906622997606e-05,
      "loss": 0.0336,
      "step": 188300
    },
    {
      "epoch": 6.478011209297528,
      "grad_norm": 0.06410319358110428,
      "learning_rate": 2.976416128325146e-05,
      "loss": 0.0373,
      "step": 188400
    },
    {
      "epoch": 6.481449644121995,
      "grad_norm": 0.2682541012763977,
      "learning_rate": 2.9753415943505304e-05,
      "loss": 0.0334,
      "step": 188500
    },
    {
      "epoch": 6.484888078946463,
      "grad_norm": 0.08957087248563766,
      "learning_rate": 2.974267060375915e-05,
      "loss": 0.0367,
      "step": 188600
    },
    {
      "epoch": 6.488326513770931,
      "grad_norm": 0.2640531659126282,
      "learning_rate": 2.9731925264013e-05,
      "loss": 0.0329,
      "step": 188700
    },
    {
      "epoch": 6.491764948595399,
      "grad_norm": 0.2923618257045746,
      "learning_rate": 2.9721179924266846e-05,
      "loss": 0.0385,
      "step": 188800
    },
    {
      "epoch": 6.4952033834198675,
      "grad_norm": 0.077718086540699,
      "learning_rate": 2.9710434584520695e-05,
      "loss": 0.0353,
      "step": 188900
    },
    {
      "epoch": 6.4986418182443355,
      "grad_norm": 0.19407886266708374,
      "learning_rate": 2.9699689244774544e-05,
      "loss": 0.04,
      "step": 189000
    },
    {
      "epoch": 6.502080253068803,
      "grad_norm": 0.21626771986484528,
      "learning_rate": 2.968894390502839e-05,
      "loss": 0.0371,
      "step": 189100
    },
    {
      "epoch": 6.505518687893271,
      "grad_norm": 0.1505170315504074,
      "learning_rate": 2.9678198565282238e-05,
      "loss": 0.0327,
      "step": 189200
    },
    {
      "epoch": 6.508957122717739,
      "grad_norm": 0.07597524672746658,
      "learning_rate": 2.9667453225536086e-05,
      "loss": 0.0322,
      "step": 189300
    },
    {
      "epoch": 6.512395557542207,
      "grad_norm": 0.15227928757667542,
      "learning_rate": 2.9656707885789935e-05,
      "loss": 0.0381,
      "step": 189400
    },
    {
      "epoch": 6.515833992366675,
      "grad_norm": 0.134536474943161,
      "learning_rate": 2.964596254604378e-05,
      "loss": 0.0345,
      "step": 189500
    },
    {
      "epoch": 6.519272427191143,
      "grad_norm": 0.28024449944496155,
      "learning_rate": 2.9635217206297626e-05,
      "loss": 0.0401,
      "step": 189600
    },
    {
      "epoch": 6.522710862015611,
      "grad_norm": 0.25385382771492004,
      "learning_rate": 2.9624471866551478e-05,
      "loss": 0.035,
      "step": 189700
    },
    {
      "epoch": 6.526149296840078,
      "grad_norm": 0.12728124856948853,
      "learning_rate": 2.9613726526805323e-05,
      "loss": 0.037,
      "step": 189800
    },
    {
      "epoch": 6.529587731664546,
      "grad_norm": 0.05034106597304344,
      "learning_rate": 2.9602981187059175e-05,
      "loss": 0.0358,
      "step": 189900
    },
    {
      "epoch": 6.533026166489014,
      "grad_norm": 0.1078886091709137,
      "learning_rate": 2.959223584731302e-05,
      "loss": 0.0334,
      "step": 190000
    },
    {
      "epoch": 6.536464601313482,
      "grad_norm": 0.11309587210416794,
      "learning_rate": 2.9581490507566866e-05,
      "loss": 0.0389,
      "step": 190100
    },
    {
      "epoch": 6.53990303613795,
      "grad_norm": 0.15190915763378143,
      "learning_rate": 2.9570745167820718e-05,
      "loss": 0.0373,
      "step": 190200
    },
    {
      "epoch": 6.543341470962418,
      "grad_norm": 0.1895645409822464,
      "learning_rate": 2.9559999828074563e-05,
      "loss": 0.0377,
      "step": 190300
    },
    {
      "epoch": 6.546779905786886,
      "grad_norm": 0.10502998530864716,
      "learning_rate": 2.9549254488328415e-05,
      "loss": 0.0329,
      "step": 190400
    },
    {
      "epoch": 6.550218340611353,
      "grad_norm": 0.22217798233032227,
      "learning_rate": 2.953850914858226e-05,
      "loss": 0.0335,
      "step": 190500
    },
    {
      "epoch": 6.5536567754358215,
      "grad_norm": 0.08126826584339142,
      "learning_rate": 2.9527763808836113e-05,
      "loss": 0.0358,
      "step": 190600
    },
    {
      "epoch": 6.5570952102602895,
      "grad_norm": 0.1048157811164856,
      "learning_rate": 2.9517018469089958e-05,
      "loss": 0.0357,
      "step": 190700
    },
    {
      "epoch": 6.560533645084758,
      "grad_norm": 0.19783741235733032,
      "learning_rate": 2.9506273129343803e-05,
      "loss": 0.037,
      "step": 190800
    },
    {
      "epoch": 6.563972079909226,
      "grad_norm": 0.4327920377254486,
      "learning_rate": 2.9495635242995113e-05,
      "loss": 0.0372,
      "step": 190900
    },
    {
      "epoch": 6.567410514733693,
      "grad_norm": 0.11481056362390518,
      "learning_rate": 2.9484889903248965e-05,
      "loss": 0.034,
      "step": 191000
    },
    {
      "epoch": 6.570848949558161,
      "grad_norm": 0.2327701300382614,
      "learning_rate": 2.947414456350281e-05,
      "loss": 0.0362,
      "step": 191100
    },
    {
      "epoch": 6.574287384382629,
      "grad_norm": 0.057511862367391586,
      "learning_rate": 2.946339922375666e-05,
      "loss": 0.0359,
      "step": 191200
    },
    {
      "epoch": 6.577725819207097,
      "grad_norm": 0.061475954949855804,
      "learning_rate": 2.9452653884010508e-05,
      "loss": 0.0384,
      "step": 191300
    },
    {
      "epoch": 6.581164254031565,
      "grad_norm": 0.15594801306724548,
      "learning_rate": 2.9441908544264353e-05,
      "loss": 0.0383,
      "step": 191400
    },
    {
      "epoch": 6.584602688856033,
      "grad_norm": 0.230272576212883,
      "learning_rate": 2.94311632045182e-05,
      "loss": 0.0377,
      "step": 191500
    },
    {
      "epoch": 6.588041123680501,
      "grad_norm": 0.06919755041599274,
      "learning_rate": 2.942041786477205e-05,
      "loss": 0.0356,
      "step": 191600
    },
    {
      "epoch": 6.591479558504968,
      "grad_norm": 0.09125222265720367,
      "learning_rate": 2.94096725250259e-05,
      "loss": 0.0332,
      "step": 191700
    },
    {
      "epoch": 6.594917993329436,
      "grad_norm": 0.06671645492315292,
      "learning_rate": 2.9398927185279744e-05,
      "loss": 0.0314,
      "step": 191800
    },
    {
      "epoch": 6.598356428153904,
      "grad_norm": 0.1985500603914261,
      "learning_rate": 2.938818184553359e-05,
      "loss": 0.0374,
      "step": 191900
    },
    {
      "epoch": 6.601794862978372,
      "grad_norm": 0.08451984822750092,
      "learning_rate": 2.937743650578744e-05,
      "loss": 0.0383,
      "step": 192000
    },
    {
      "epoch": 6.60523329780284,
      "grad_norm": 0.10289543867111206,
      "learning_rate": 2.9366691166041287e-05,
      "loss": 0.0333,
      "step": 192100
    },
    {
      "epoch": 6.608671732627308,
      "grad_norm": 0.35418668389320374,
      "learning_rate": 2.935594582629514e-05,
      "loss": 0.041,
      "step": 192200
    },
    {
      "epoch": 6.612110167451776,
      "grad_norm": 0.11586243659257889,
      "learning_rate": 2.9345200486548984e-05,
      "loss": 0.037,
      "step": 192300
    },
    {
      "epoch": 6.6155486022762435,
      "grad_norm": 0.17182967066764832,
      "learning_rate": 2.933445514680283e-05,
      "loss": 0.0367,
      "step": 192400
    },
    {
      "epoch": 6.618987037100712,
      "grad_norm": 0.12272994220256805,
      "learning_rate": 2.932370980705668e-05,
      "loss": 0.0366,
      "step": 192500
    },
    {
      "epoch": 6.62242547192518,
      "grad_norm": 0.25516319274902344,
      "learning_rate": 2.9312964467310527e-05,
      "loss": 0.0359,
      "step": 192600
    },
    {
      "epoch": 6.625863906749648,
      "grad_norm": 0.08061141520738602,
      "learning_rate": 2.930221912756438e-05,
      "loss": 0.0351,
      "step": 192700
    },
    {
      "epoch": 6.629302341574116,
      "grad_norm": 0.07541467249393463,
      "learning_rate": 2.9291473787818224e-05,
      "loss": 0.0348,
      "step": 192800
    },
    {
      "epoch": 6.632740776398584,
      "grad_norm": 0.1232631579041481,
      "learning_rate": 2.928072844807207e-05,
      "loss": 0.0402,
      "step": 192900
    },
    {
      "epoch": 6.636179211223052,
      "grad_norm": 0.129233255982399,
      "learning_rate": 2.926998310832592e-05,
      "loss": 0.0386,
      "step": 193000
    },
    {
      "epoch": 6.639617646047519,
      "grad_norm": 0.07208749651908875,
      "learning_rate": 2.9259237768579767e-05,
      "loss": 0.0321,
      "step": 193100
    },
    {
      "epoch": 6.643056080871987,
      "grad_norm": 0.10727004706859589,
      "learning_rate": 2.924849242883362e-05,
      "loss": 0.0375,
      "step": 193200
    },
    {
      "epoch": 6.646494515696455,
      "grad_norm": 0.048620183020830154,
      "learning_rate": 2.9237747089087464e-05,
      "loss": 0.0367,
      "step": 193300
    },
    {
      "epoch": 6.649932950520923,
      "grad_norm": 0.10218379646539688,
      "learning_rate": 2.9227109202738774e-05,
      "loss": 0.0393,
      "step": 193400
    },
    {
      "epoch": 6.653371385345391,
      "grad_norm": 0.06373243778944016,
      "learning_rate": 2.9216363862992623e-05,
      "loss": 0.0356,
      "step": 193500
    },
    {
      "epoch": 6.656809820169858,
      "grad_norm": 0.2656524181365967,
      "learning_rate": 2.920561852324647e-05,
      "loss": 0.0382,
      "step": 193600
    },
    {
      "epoch": 6.660248254994326,
      "grad_norm": 0.12019072473049164,
      "learning_rate": 2.9194873183500317e-05,
      "loss": 0.0349,
      "step": 193700
    },
    {
      "epoch": 6.663686689818794,
      "grad_norm": 0.18334417045116425,
      "learning_rate": 2.9184127843754165e-05,
      "loss": 0.0356,
      "step": 193800
    },
    {
      "epoch": 6.667125124643262,
      "grad_norm": 0.16081416606903076,
      "learning_rate": 2.917338250400801e-05,
      "loss": 0.0357,
      "step": 193900
    },
    {
      "epoch": 6.67056355946773,
      "grad_norm": 0.16717149317264557,
      "learning_rate": 2.9162637164261863e-05,
      "loss": 0.0385,
      "step": 194000
    },
    {
      "epoch": 6.674001994292198,
      "grad_norm": 0.21537280082702637,
      "learning_rate": 2.9151891824515708e-05,
      "loss": 0.0412,
      "step": 194100
    },
    {
      "epoch": 6.6774404291166665,
      "grad_norm": 0.06755072623491287,
      "learning_rate": 2.9141146484769553e-05,
      "loss": 0.0354,
      "step": 194200
    },
    {
      "epoch": 6.680878863941134,
      "grad_norm": 0.01882602646946907,
      "learning_rate": 2.9130401145023405e-05,
      "loss": 0.0351,
      "step": 194300
    },
    {
      "epoch": 6.684317298765602,
      "grad_norm": 0.11491513252258301,
      "learning_rate": 2.911965580527725e-05,
      "loss": 0.0375,
      "step": 194400
    },
    {
      "epoch": 6.68775573359007,
      "grad_norm": 0.08010801672935486,
      "learning_rate": 2.9108910465531103e-05,
      "loss": 0.0376,
      "step": 194500
    },
    {
      "epoch": 6.691194168414538,
      "grad_norm": 0.27108606696128845,
      "learning_rate": 2.9098165125784948e-05,
      "loss": 0.0366,
      "step": 194600
    },
    {
      "epoch": 6.694632603239006,
      "grad_norm": 0.2025858461856842,
      "learning_rate": 2.9087527239436258e-05,
      "loss": 0.0353,
      "step": 194700
    },
    {
      "epoch": 6.698071038063474,
      "grad_norm": 0.08681069314479828,
      "learning_rate": 2.9076781899690103e-05,
      "loss": 0.0368,
      "step": 194800
    },
    {
      "epoch": 6.701509472887942,
      "grad_norm": 0.08538379520177841,
      "learning_rate": 2.9066036559943955e-05,
      "loss": 0.0368,
      "step": 194900
    },
    {
      "epoch": 6.704947907712409,
      "grad_norm": 0.39091956615448,
      "learning_rate": 2.90552912201978e-05,
      "loss": 0.0379,
      "step": 195000
    },
    {
      "epoch": 6.708386342536877,
      "grad_norm": 0.06925665587186813,
      "learning_rate": 2.9044545880451652e-05,
      "loss": 0.0349,
      "step": 195100
    },
    {
      "epoch": 6.711824777361345,
      "grad_norm": 0.285645455121994,
      "learning_rate": 2.9033800540705498e-05,
      "loss": 0.0385,
      "step": 195200
    },
    {
      "epoch": 6.715263212185813,
      "grad_norm": 0.0944797620177269,
      "learning_rate": 2.9023055200959343e-05,
      "loss": 0.0363,
      "step": 195300
    },
    {
      "epoch": 6.718701647010281,
      "grad_norm": 0.0899883434176445,
      "learning_rate": 2.9012309861213195e-05,
      "loss": 0.0332,
      "step": 195400
    },
    {
      "epoch": 6.722140081834749,
      "grad_norm": 0.11121376603841782,
      "learning_rate": 2.900156452146704e-05,
      "loss": 0.0406,
      "step": 195500
    },
    {
      "epoch": 6.725578516659216,
      "grad_norm": 0.14639414846897125,
      "learning_rate": 2.8990819181720892e-05,
      "loss": 0.036,
      "step": 195600
    },
    {
      "epoch": 6.729016951483684,
      "grad_norm": 0.12214919924736023,
      "learning_rate": 2.8980073841974738e-05,
      "loss": 0.0355,
      "step": 195700
    },
    {
      "epoch": 6.732455386308152,
      "grad_norm": 0.20176880061626434,
      "learning_rate": 2.8969328502228583e-05,
      "loss": 0.0378,
      "step": 195800
    },
    {
      "epoch": 6.7358938211326205,
      "grad_norm": 0.20313788950443268,
      "learning_rate": 2.8958583162482435e-05,
      "loss": 0.0337,
      "step": 195900
    },
    {
      "epoch": 6.7393322559570885,
      "grad_norm": 0.08345627039670944,
      "learning_rate": 2.894783782273628e-05,
      "loss": 0.0318,
      "step": 196000
    },
    {
      "epoch": 6.7427706907815566,
      "grad_norm": 0.046737637370824814,
      "learning_rate": 2.893709248299013e-05,
      "loss": 0.0378,
      "step": 196100
    },
    {
      "epoch": 6.746209125606024,
      "grad_norm": 0.17699185013771057,
      "learning_rate": 2.8926347143243974e-05,
      "loss": 0.0342,
      "step": 196200
    },
    {
      "epoch": 6.749647560430492,
      "grad_norm": 0.059697020798921585,
      "learning_rate": 2.8915601803497826e-05,
      "loss": 0.0348,
      "step": 196300
    },
    {
      "epoch": 6.75308599525496,
      "grad_norm": 0.1297951638698578,
      "learning_rate": 2.890485646375167e-05,
      "loss": 0.0352,
      "step": 196400
    },
    {
      "epoch": 6.756524430079428,
      "grad_norm": 0.10217630118131638,
      "learning_rate": 2.8894111124005517e-05,
      "loss": 0.0384,
      "step": 196500
    },
    {
      "epoch": 6.759962864903896,
      "grad_norm": 0.53572678565979,
      "learning_rate": 2.888336578425937e-05,
      "loss": 0.0363,
      "step": 196600
    },
    {
      "epoch": 6.763401299728364,
      "grad_norm": 0.10593287646770477,
      "learning_rate": 2.8872620444513214e-05,
      "loss": 0.0345,
      "step": 196700
    },
    {
      "epoch": 6.766839734552832,
      "grad_norm": 0.041864536702632904,
      "learning_rate": 2.8861875104767066e-05,
      "loss": 0.0369,
      "step": 196800
    },
    {
      "epoch": 6.770278169377299,
      "grad_norm": 0.5306311845779419,
      "learning_rate": 2.885112976502091e-05,
      "loss": 0.0368,
      "step": 196900
    },
    {
      "epoch": 6.773716604201767,
      "grad_norm": 0.018890751525759697,
      "learning_rate": 2.8840384425274757e-05,
      "loss": 0.0339,
      "step": 197000
    },
    {
      "epoch": 6.777155039026235,
      "grad_norm": 0.10258742421865463,
      "learning_rate": 2.882963908552861e-05,
      "loss": 0.0367,
      "step": 197100
    },
    {
      "epoch": 6.780593473850703,
      "grad_norm": 0.09262368083000183,
      "learning_rate": 2.8818893745782454e-05,
      "loss": 0.0361,
      "step": 197200
    },
    {
      "epoch": 6.784031908675171,
      "grad_norm": 0.14660662412643433,
      "learning_rate": 2.8808148406036306e-05,
      "loss": 0.0371,
      "step": 197300
    },
    {
      "epoch": 6.787470343499639,
      "grad_norm": 0.10113578289747238,
      "learning_rate": 2.879740306629015e-05,
      "loss": 0.0336,
      "step": 197400
    },
    {
      "epoch": 6.790908778324107,
      "grad_norm": 0.18652406334877014,
      "learning_rate": 2.8786657726543997e-05,
      "loss": 0.0384,
      "step": 197500
    },
    {
      "epoch": 6.7943472131485745,
      "grad_norm": 0.16079172492027283,
      "learning_rate": 2.877591238679785e-05,
      "loss": 0.0348,
      "step": 197600
    },
    {
      "epoch": 6.7977856479730425,
      "grad_norm": 0.12906426191329956,
      "learning_rate": 2.8765167047051694e-05,
      "loss": 0.037,
      "step": 197700
    },
    {
      "epoch": 6.801224082797511,
      "grad_norm": 0.15390953421592712,
      "learning_rate": 2.8754421707305546e-05,
      "loss": 0.0359,
      "step": 197800
    },
    {
      "epoch": 6.804662517621979,
      "grad_norm": 0.11217833310365677,
      "learning_rate": 2.874367636755939e-05,
      "loss": 0.0356,
      "step": 197900
    },
    {
      "epoch": 6.808100952446447,
      "grad_norm": 0.08116314560174942,
      "learning_rate": 2.8732931027813237e-05,
      "loss": 0.0375,
      "step": 198000
    },
    {
      "epoch": 6.811539387270914,
      "grad_norm": 0.07026052474975586,
      "learning_rate": 2.872218568806709e-05,
      "loss": 0.0375,
      "step": 198100
    },
    {
      "epoch": 6.814977822095382,
      "grad_norm": 0.07192306220531464,
      "learning_rate": 2.8711440348320934e-05,
      "loss": 0.0364,
      "step": 198200
    },
    {
      "epoch": 6.81841625691985,
      "grad_norm": 0.11653175950050354,
      "learning_rate": 2.8700695008574786e-05,
      "loss": 0.0362,
      "step": 198300
    },
    {
      "epoch": 6.821854691744318,
      "grad_norm": 0.08554917573928833,
      "learning_rate": 2.8689949668828632e-05,
      "loss": 0.0352,
      "step": 198400
    },
    {
      "epoch": 6.825293126568786,
      "grad_norm": 0.13552530109882355,
      "learning_rate": 2.8679204329082477e-05,
      "loss": 0.0388,
      "step": 198500
    },
    {
      "epoch": 6.828731561393254,
      "grad_norm": 0.41535013914108276,
      "learning_rate": 2.866845898933633e-05,
      "loss": 0.0364,
      "step": 198600
    },
    {
      "epoch": 6.832169996217722,
      "grad_norm": 0.2860698401927948,
      "learning_rate": 2.8657713649590174e-05,
      "loss": 0.0365,
      "step": 198700
    },
    {
      "epoch": 6.835608431042189,
      "grad_norm": 0.18651799857616425,
      "learning_rate": 2.8646968309844023e-05,
      "loss": 0.0338,
      "step": 198800
    },
    {
      "epoch": 6.839046865866657,
      "grad_norm": 0.2998770773410797,
      "learning_rate": 2.8636330423495333e-05,
      "loss": 0.0339,
      "step": 198900
    },
    {
      "epoch": 6.842485300691125,
      "grad_norm": 0.16828539967536926,
      "learning_rate": 2.8625585083749178e-05,
      "loss": 0.0356,
      "step": 199000
    },
    {
      "epoch": 6.845923735515593,
      "grad_norm": 0.12456178665161133,
      "learning_rate": 2.8614839744003023e-05,
      "loss": 0.0362,
      "step": 199100
    },
    {
      "epoch": 6.849362170340061,
      "grad_norm": 0.053144123405218124,
      "learning_rate": 2.8604094404256875e-05,
      "loss": 0.0346,
      "step": 199200
    },
    {
      "epoch": 6.852800605164529,
      "grad_norm": 0.06081654876470566,
      "learning_rate": 2.859334906451072e-05,
      "loss": 0.0383,
      "step": 199300
    },
    {
      "epoch": 6.856239039988997,
      "grad_norm": 0.15578307211399078,
      "learning_rate": 2.8582603724764573e-05,
      "loss": 0.0372,
      "step": 199400
    },
    {
      "epoch": 6.859677474813465,
      "grad_norm": 0.08764054626226425,
      "learning_rate": 2.8571858385018418e-05,
      "loss": 0.0364,
      "step": 199500
    },
    {
      "epoch": 6.863115909637933,
      "grad_norm": 0.2584759294986725,
      "learning_rate": 2.8561113045272263e-05,
      "loss": 0.0375,
      "step": 199600
    },
    {
      "epoch": 6.866554344462401,
      "grad_norm": 0.08758439868688583,
      "learning_rate": 2.8550367705526115e-05,
      "loss": 0.0364,
      "step": 199700
    },
    {
      "epoch": 6.869992779286869,
      "grad_norm": 0.08026830106973648,
      "learning_rate": 2.853962236577996e-05,
      "loss": 0.0359,
      "step": 199800
    },
    {
      "epoch": 6.873431214111337,
      "grad_norm": 0.1850641816854477,
      "learning_rate": 2.8528877026033813e-05,
      "loss": 0.0364,
      "step": 199900
    },
    {
      "epoch": 6.876869648935805,
      "grad_norm": 0.04447604715824127,
      "learning_rate": 2.8518131686287658e-05,
      "loss": 0.0362,
      "step": 200000
    },
    {
      "epoch": 6.880308083760273,
      "grad_norm": 0.022824501618742943,
      "learning_rate": 2.8507386346541503e-05,
      "loss": 0.0334,
      "step": 200100
    },
    {
      "epoch": 6.88374651858474,
      "grad_norm": 0.09377878159284592,
      "learning_rate": 2.8496641006795355e-05,
      "loss": 0.0379,
      "step": 200200
    },
    {
      "epoch": 6.887184953409208,
      "grad_norm": 0.09979259967803955,
      "learning_rate": 2.84858956670492e-05,
      "loss": 0.0336,
      "step": 200300
    },
    {
      "epoch": 6.890623388233676,
      "grad_norm": 0.18603515625,
      "learning_rate": 2.8475150327303053e-05,
      "loss": 0.0392,
      "step": 200400
    },
    {
      "epoch": 6.894061823058144,
      "grad_norm": 0.10358452051877975,
      "learning_rate": 2.8464404987556898e-05,
      "loss": 0.0336,
      "step": 200500
    },
    {
      "epoch": 6.897500257882612,
      "grad_norm": 0.18201255798339844,
      "learning_rate": 2.8453659647810743e-05,
      "loss": 0.0359,
      "step": 200600
    },
    {
      "epoch": 6.900938692707079,
      "grad_norm": 0.03312237933278084,
      "learning_rate": 2.8442914308064595e-05,
      "loss": 0.035,
      "step": 200700
    },
    {
      "epoch": 6.904377127531547,
      "grad_norm": 0.04852636158466339,
      "learning_rate": 2.843216896831844e-05,
      "loss": 0.0337,
      "step": 200800
    },
    {
      "epoch": 6.907815562356015,
      "grad_norm": 0.10642852634191513,
      "learning_rate": 2.8421423628572293e-05,
      "loss": 0.0376,
      "step": 200900
    },
    {
      "epoch": 6.911253997180483,
      "grad_norm": 0.18504084646701813,
      "learning_rate": 2.8410678288826138e-05,
      "loss": 0.0336,
      "step": 201000
    },
    {
      "epoch": 6.914692432004951,
      "grad_norm": 0.11948863416910172,
      "learning_rate": 2.8399932949079987e-05,
      "loss": 0.0386,
      "step": 201100
    },
    {
      "epoch": 6.9181308668294195,
      "grad_norm": 0.13811103999614716,
      "learning_rate": 2.8389187609333835e-05,
      "loss": 0.0352,
      "step": 201200
    },
    {
      "epoch": 6.9215693016538875,
      "grad_norm": 0.06363514810800552,
      "learning_rate": 2.837844226958768e-05,
      "loss": 0.0352,
      "step": 201300
    },
    {
      "epoch": 6.925007736478355,
      "grad_norm": NaN,
      "learning_rate": 2.836791183663645e-05,
      "loss": 0.0359,
      "step": 201400
    },
    {
      "epoch": 6.928446171302823,
      "grad_norm": 0.06336024403572083,
      "learning_rate": 2.8357166496890303e-05,
      "loss": 0.0328,
      "step": 201500
    },
    {
      "epoch": 6.931884606127291,
      "grad_norm": 0.3112897276878357,
      "learning_rate": 2.834642115714415e-05,
      "loss": 0.0322,
      "step": 201600
    },
    {
      "epoch": 6.935323040951759,
      "grad_norm": 0.22496861219406128,
      "learning_rate": 2.8335675817397994e-05,
      "loss": 0.0368,
      "step": 201700
    },
    {
      "epoch": 6.938761475776227,
      "grad_norm": 0.08622240275144577,
      "learning_rate": 2.8324930477651846e-05,
      "loss": 0.0383,
      "step": 201800
    },
    {
      "epoch": 6.942199910600695,
      "grad_norm": 0.0903000682592392,
      "learning_rate": 2.831418513790569e-05,
      "loss": 0.0359,
      "step": 201900
    },
    {
      "epoch": 6.945638345425163,
      "grad_norm": 0.07714332640171051,
      "learning_rate": 2.8303439798159543e-05,
      "loss": 0.0359,
      "step": 202000
    },
    {
      "epoch": 6.94907678024963,
      "grad_norm": 0.14614447951316833,
      "learning_rate": 2.829269445841339e-05,
      "loss": 0.0368,
      "step": 202100
    },
    {
      "epoch": 6.952515215074098,
      "grad_norm": 0.11805911362171173,
      "learning_rate": 2.8281949118667234e-05,
      "loss": 0.0346,
      "step": 202200
    },
    {
      "epoch": 6.955953649898566,
      "grad_norm": 0.24812866747379303,
      "learning_rate": 2.8271203778921086e-05,
      "loss": 0.0404,
      "step": 202300
    },
    {
      "epoch": 6.959392084723034,
      "grad_norm": 0.032952502369880676,
      "learning_rate": 2.826045843917493e-05,
      "loss": 0.0328,
      "step": 202400
    },
    {
      "epoch": 6.962830519547502,
      "grad_norm": 0.09687872976064682,
      "learning_rate": 2.8249713099428783e-05,
      "loss": 0.0382,
      "step": 202500
    },
    {
      "epoch": 6.96626895437197,
      "grad_norm": 0.08335980772972107,
      "learning_rate": 2.823896775968263e-05,
      "loss": 0.0367,
      "step": 202600
    },
    {
      "epoch": 6.969707389196437,
      "grad_norm": 0.11527310311794281,
      "learning_rate": 2.8228222419936474e-05,
      "loss": 0.0362,
      "step": 202700
    },
    {
      "epoch": 6.973145824020905,
      "grad_norm": 0.2043408751487732,
      "learning_rate": 2.8217477080190323e-05,
      "loss": 0.0368,
      "step": 202800
    },
    {
      "epoch": 6.9765842588453735,
      "grad_norm": 0.19900302588939667,
      "learning_rate": 2.820673174044417e-05,
      "loss": 0.0356,
      "step": 202900
    },
    {
      "epoch": 6.9800226936698415,
      "grad_norm": 0.15389925241470337,
      "learning_rate": 2.819598640069802e-05,
      "loss": 0.0385,
      "step": 203000
    },
    {
      "epoch": 6.9834611284943096,
      "grad_norm": 0.18375059962272644,
      "learning_rate": 2.8185241060951865e-05,
      "loss": 0.0339,
      "step": 203100
    },
    {
      "epoch": 6.986899563318778,
      "grad_norm": 0.17621323466300964,
      "learning_rate": 2.8174495721205714e-05,
      "loss": 0.037,
      "step": 203200
    },
    {
      "epoch": 6.990337998143245,
      "grad_norm": 0.214456245303154,
      "learning_rate": 2.8163750381459563e-05,
      "loss": 0.0351,
      "step": 203300
    },
    {
      "epoch": 6.993776432967713,
      "grad_norm": 0.08539486676454544,
      "learning_rate": 2.8153005041713408e-05,
      "loss": 0.033,
      "step": 203400
    },
    {
      "epoch": 6.997214867792181,
      "grad_norm": 0.19262757897377014,
      "learning_rate": 2.814225970196726e-05,
      "loss": 0.0361,
      "step": 203500
    },
    {
      "epoch": 7.0,
      "eval_accuracy_macro_0.5": 0.984951376914978,
      "eval_accuracy_micro_0.5": 0.984951376914978,
      "eval_accuracy_weighted_0.5": 0.9753504991531372,
      "eval_aucroc_macro": 0.9160781502723694,
      "eval_aucroc_micro": 0.9201977849006653,
      "eval_aucroc_weighted": 0.9170249700546265,
      "eval_f1_macro_0.5": 0.770626425743103,
      "eval_f1_macro_0.6": 0.7534208297729492,
      "eval_f1_macro_0.7": 0.7225182056427002,
      "eval_f1_macro_0.8": 0.5576788783073425,
      "eval_f1_micro_0.5": 0.7804248929023743,
      "eval_f1_micro_0.6": 0.7676478624343872,
      "eval_f1_micro_0.7": 0.742521345615387,
      "eval_f1_micro_0.8": 0.6947716474533081,
      "eval_f1_micro_0.9": 0.5903695821762085,
      "eval_f1_weighted_0.5": 0.775737464427948,
      "eval_f1_weighted_0.6": 0.7588690519332886,
      "eval_f1_weighted_0.7": 0.7278974652290344,
      "eval_f1_weighted_0.8": 0.5519785284996033,
      "eval_loss": 0.0327252596616745,
      "eval_runtime": 2013.2043,
      "eval_samples_per_second": 28.875,
      "eval_steps_per_second": 3.61,
      "step": 203581
    },
    {
      "epoch": 7.000653302616649,
      "grad_norm": 0.08482760190963745,
      "learning_rate": 2.8131514362221105e-05,
      "loss": 0.0338,
      "step": 203600
    },
    {
      "epoch": 7.004091737441117,
      "grad_norm": 0.05276285856962204,
      "learning_rate": 2.812076902247495e-05,
      "loss": 0.037,
      "step": 203700
    },
    {
      "epoch": 7.007530172265585,
      "grad_norm": 0.1682790368795395,
      "learning_rate": 2.8110023682728803e-05,
      "loss": 0.033,
      "step": 203800
    },
    {
      "epoch": 7.010968607090053,
      "grad_norm": 0.15360480546951294,
      "learning_rate": 2.8099278342982648e-05,
      "loss": 0.0344,
      "step": 203900
    },
    {
      "epoch": 7.01440704191452,
      "grad_norm": 0.22948090732097626,
      "learning_rate": 2.80885330032365e-05,
      "loss": 0.0357,
      "step": 204000
    },
    {
      "epoch": 7.017845476738988,
      "grad_norm": 0.28517648577690125,
      "learning_rate": 2.8077787663490345e-05,
      "loss": 0.0331,
      "step": 204100
    },
    {
      "epoch": 7.021283911563456,
      "grad_norm": 0.4774629771709442,
      "learning_rate": 2.806704232374419e-05,
      "loss": 0.0377,
      "step": 204200
    },
    {
      "epoch": 7.024722346387924,
      "grad_norm": 0.3121398389339447,
      "learning_rate": 2.8056296983998043e-05,
      "loss": 0.0338,
      "step": 204300
    },
    {
      "epoch": 7.028160781212392,
      "grad_norm": 0.2301115095615387,
      "learning_rate": 2.8045551644251888e-05,
      "loss": 0.0363,
      "step": 204400
    },
    {
      "epoch": 7.03159921603686,
      "grad_norm": 0.1680702120065689,
      "learning_rate": 2.803480630450574e-05,
      "loss": 0.038,
      "step": 204500
    },
    {
      "epoch": 7.0350376508613275,
      "grad_norm": 0.1434146761894226,
      "learning_rate": 2.8024060964759585e-05,
      "loss": 0.0337,
      "step": 204600
    },
    {
      "epoch": 7.0384760856857955,
      "grad_norm": 0.14508655667304993,
      "learning_rate": 2.801331562501343e-05,
      "loss": 0.0372,
      "step": 204700
    },
    {
      "epoch": 7.041914520510264,
      "grad_norm": 0.06157751753926277,
      "learning_rate": 2.8002570285267283e-05,
      "loss": 0.033,
      "step": 204800
    },
    {
      "epoch": 7.045352955334732,
      "grad_norm": 0.23388385772705078,
      "learning_rate": 2.7991824945521128e-05,
      "loss": 0.0323,
      "step": 204900
    },
    {
      "epoch": 7.0487913901592,
      "grad_norm": 0.0772952139377594,
      "learning_rate": 2.798107960577498e-05,
      "loss": 0.0397,
      "step": 205000
    },
    {
      "epoch": 7.052229824983668,
      "grad_norm": 0.14403893053531647,
      "learning_rate": 2.7970334266028825e-05,
      "loss": 0.0333,
      "step": 205100
    },
    {
      "epoch": 7.055668259808136,
      "grad_norm": 0.3300793468952179,
      "learning_rate": 2.795958892628267e-05,
      "loss": 0.0359,
      "step": 205200
    },
    {
      "epoch": 7.059106694632603,
      "grad_norm": 0.1375490128993988,
      "learning_rate": 2.7948843586536523e-05,
      "loss": 0.0334,
      "step": 205300
    },
    {
      "epoch": 7.062545129457071,
      "grad_norm": 0.22037576138973236,
      "learning_rate": 2.7938098246790368e-05,
      "loss": 0.0344,
      "step": 205400
    },
    {
      "epoch": 7.065983564281539,
      "grad_norm": 0.22996880114078522,
      "learning_rate": 2.792735290704422e-05,
      "loss": 0.0391,
      "step": 205500
    },
    {
      "epoch": 7.069421999106007,
      "grad_norm": 0.5702494978904724,
      "learning_rate": 2.7916715020695526e-05,
      "loss": 0.0398,
      "step": 205600
    },
    {
      "epoch": 7.072860433930475,
      "grad_norm": 0.2771533727645874,
      "learning_rate": 2.7905969680949372e-05,
      "loss": 0.0368,
      "step": 205700
    },
    {
      "epoch": 7.076298868754943,
      "grad_norm": 0.12760449945926666,
      "learning_rate": 2.789522434120322e-05,
      "loss": 0.0367,
      "step": 205800
    },
    {
      "epoch": 7.07973730357941,
      "grad_norm": 0.07972566783428192,
      "learning_rate": 2.788447900145707e-05,
      "loss": 0.0351,
      "step": 205900
    },
    {
      "epoch": 7.083175738403878,
      "grad_norm": 0.23092834651470184,
      "learning_rate": 2.7873733661710914e-05,
      "loss": 0.0356,
      "step": 206000
    },
    {
      "epoch": 7.086614173228346,
      "grad_norm": 0.3383743464946747,
      "learning_rate": 2.7862988321964766e-05,
      "loss": 0.0363,
      "step": 206100
    },
    {
      "epoch": 7.090052608052814,
      "grad_norm": 0.3557669520378113,
      "learning_rate": 2.7852242982218612e-05,
      "loss": 0.0354,
      "step": 206200
    },
    {
      "epoch": 7.093491042877282,
      "grad_norm": 0.25560900568962097,
      "learning_rate": 2.7841497642472457e-05,
      "loss": 0.0397,
      "step": 206300
    },
    {
      "epoch": 7.09692947770175,
      "grad_norm": 0.7989448308944702,
      "learning_rate": 2.783075230272631e-05,
      "loss": 0.0349,
      "step": 206400
    },
    {
      "epoch": 7.1003679125262185,
      "grad_norm": 0.09972891211509705,
      "learning_rate": 2.7820006962980154e-05,
      "loss": 0.0346,
      "step": 206500
    },
    {
      "epoch": 7.103806347350686,
      "grad_norm": 0.07507215440273285,
      "learning_rate": 2.7809261623234006e-05,
      "loss": 0.0333,
      "step": 206600
    },
    {
      "epoch": 7.107244782175154,
      "grad_norm": 0.0871756449341774,
      "learning_rate": 2.7798516283487852e-05,
      "loss": 0.0334,
      "step": 206700
    },
    {
      "epoch": 7.110683216999622,
      "grad_norm": 0.5751994252204895,
      "learning_rate": 2.7787770943741704e-05,
      "loss": 0.0339,
      "step": 206800
    },
    {
      "epoch": 7.11412165182409,
      "grad_norm": 0.6474335193634033,
      "learning_rate": 2.777702560399555e-05,
      "loss": 0.0349,
      "step": 206900
    },
    {
      "epoch": 7.117560086648558,
      "grad_norm": 0.05889607593417168,
      "learning_rate": 2.7766280264249394e-05,
      "loss": 0.0359,
      "step": 207000
    },
    {
      "epoch": 7.120998521473026,
      "grad_norm": 0.10337251424789429,
      "learning_rate": 2.7755534924503247e-05,
      "loss": 0.0365,
      "step": 207100
    },
    {
      "epoch": 7.124436956297493,
      "grad_norm": 0.13990843296051025,
      "learning_rate": 2.7744789584757092e-05,
      "loss": 0.0359,
      "step": 207200
    },
    {
      "epoch": 7.127875391121961,
      "grad_norm": 0.10361985862255096,
      "learning_rate": 2.7734044245010944e-05,
      "loss": 0.0342,
      "step": 207300
    },
    {
      "epoch": 7.131313825946429,
      "grad_norm": 0.1658838987350464,
      "learning_rate": 2.772329890526479e-05,
      "loss": 0.0338,
      "step": 207400
    },
    {
      "epoch": 7.134752260770897,
      "grad_norm": 0.09036728739738464,
      "learning_rate": 2.7712553565518634e-05,
      "loss": 0.0329,
      "step": 207500
    },
    {
      "epoch": 7.138190695595365,
      "grad_norm": 0.3245740532875061,
      "learning_rate": 2.7701808225772487e-05,
      "loss": 0.0334,
      "step": 207600
    },
    {
      "epoch": 7.141629130419833,
      "grad_norm": 0.17010775208473206,
      "learning_rate": 2.7691062886026332e-05,
      "loss": 0.0358,
      "step": 207700
    },
    {
      "epoch": 7.145067565244301,
      "grad_norm": 0.2617959678173065,
      "learning_rate": 2.768042499967764e-05,
      "loss": 0.0338,
      "step": 207800
    },
    {
      "epoch": 7.148506000068768,
      "grad_norm": 0.1640176624059677,
      "learning_rate": 2.766967965993149e-05,
      "loss": 0.0361,
      "step": 207900
    },
    {
      "epoch": 7.151944434893236,
      "grad_norm": 0.27687710523605347,
      "learning_rate": 2.7658934320185335e-05,
      "loss": 0.0378,
      "step": 208000
    },
    {
      "epoch": 7.155382869717704,
      "grad_norm": 0.17681793868541718,
      "learning_rate": 2.7648188980439184e-05,
      "loss": 0.0414,
      "step": 208100
    },
    {
      "epoch": 7.1588213045421725,
      "grad_norm": 0.16257579624652863,
      "learning_rate": 2.7637443640693033e-05,
      "loss": 0.0326,
      "step": 208200
    },
    {
      "epoch": 7.1622597393666405,
      "grad_norm": 0.1860092431306839,
      "learning_rate": 2.7626698300946878e-05,
      "loss": 0.0321,
      "step": 208300
    },
    {
      "epoch": 7.1656981741911085,
      "grad_norm": 0.6521126627922058,
      "learning_rate": 2.761595296120073e-05,
      "loss": 0.036,
      "step": 208400
    },
    {
      "epoch": 7.169136609015576,
      "grad_norm": 0.13599830865859985,
      "learning_rate": 2.7605207621454575e-05,
      "loss": 0.0342,
      "step": 208500
    },
    {
      "epoch": 7.172575043840044,
      "grad_norm": 0.1464143693447113,
      "learning_rate": 2.759446228170842e-05,
      "loss": 0.0357,
      "step": 208600
    },
    {
      "epoch": 7.176013478664512,
      "grad_norm": 0.24457038938999176,
      "learning_rate": 2.7583716941962273e-05,
      "loss": 0.0342,
      "step": 208700
    },
    {
      "epoch": 7.17945191348898,
      "grad_norm": 0.07873908430337906,
      "learning_rate": 2.7572971602216118e-05,
      "loss": 0.0353,
      "step": 208800
    },
    {
      "epoch": 7.182890348313448,
      "grad_norm": 0.3217869699001312,
      "learning_rate": 2.756222626246997e-05,
      "loss": 0.0315,
      "step": 208900
    },
    {
      "epoch": 7.186328783137916,
      "grad_norm": 0.08742982149124146,
      "learning_rate": 2.7551480922723816e-05,
      "loss": 0.0343,
      "step": 209000
    },
    {
      "epoch": 7.189767217962384,
      "grad_norm": 0.15592814981937408,
      "learning_rate": 2.754073558297766e-05,
      "loss": 0.0346,
      "step": 209100
    },
    {
      "epoch": 7.193205652786851,
      "grad_norm": 0.18135273456573486,
      "learning_rate": 2.7529990243231513e-05,
      "loss": 0.0347,
      "step": 209200
    },
    {
      "epoch": 7.196644087611319,
      "grad_norm": 0.2929344177246094,
      "learning_rate": 2.7519244903485358e-05,
      "loss": 0.0349,
      "step": 209300
    },
    {
      "epoch": 7.200082522435787,
      "grad_norm": 0.3866138756275177,
      "learning_rate": 2.750849956373921e-05,
      "loss": 0.0363,
      "step": 209400
    },
    {
      "epoch": 7.203520957260255,
      "grad_norm": 0.3256296217441559,
      "learning_rate": 2.7497754223993056e-05,
      "loss": 0.0367,
      "step": 209500
    },
    {
      "epoch": 7.206959392084723,
      "grad_norm": 0.14030048251152039,
      "learning_rate": 2.74870088842469e-05,
      "loss": 0.0346,
      "step": 209600
    },
    {
      "epoch": 7.210397826909191,
      "grad_norm": 0.6274691224098206,
      "learning_rate": 2.7476263544500753e-05,
      "loss": 0.0347,
      "step": 209700
    },
    {
      "epoch": 7.213836261733658,
      "grad_norm": 0.1142241358757019,
      "learning_rate": 2.7465518204754598e-05,
      "loss": 0.0354,
      "step": 209800
    },
    {
      "epoch": 7.2172746965581265,
      "grad_norm": 0.13955986499786377,
      "learning_rate": 2.745477286500845e-05,
      "loss": 0.0323,
      "step": 209900
    },
    {
      "epoch": 7.2207131313825945,
      "grad_norm": 0.24417629837989807,
      "learning_rate": 2.7444027525262296e-05,
      "loss": 0.0381,
      "step": 210000
    },
    {
      "epoch": 7.224151566207063,
      "grad_norm": 0.112429678440094,
      "learning_rate": 2.743328218551614e-05,
      "loss": 0.0347,
      "step": 210100
    },
    {
      "epoch": 7.227590001031531,
      "grad_norm": 0.06720879673957825,
      "learning_rate": 2.7422536845769993e-05,
      "loss": 0.0356,
      "step": 210200
    },
    {
      "epoch": 7.231028435855999,
      "grad_norm": 0.10043911635875702,
      "learning_rate": 2.74118989594213e-05,
      "loss": 0.0354,
      "step": 210300
    },
    {
      "epoch": 7.234466870680467,
      "grad_norm": 0.18084928393363953,
      "learning_rate": 2.7401153619675148e-05,
      "loss": 0.0363,
      "step": 210400
    },
    {
      "epoch": 7.237905305504934,
      "grad_norm": 0.12424825131893158,
      "learning_rate": 2.7390408279928997e-05,
      "loss": 0.0333,
      "step": 210500
    },
    {
      "epoch": 7.241343740329402,
      "grad_norm": 0.34574663639068604,
      "learning_rate": 2.7379662940182842e-05,
      "loss": 0.0323,
      "step": 210600
    },
    {
      "epoch": 7.24478217515387,
      "grad_norm": 0.26392945647239685,
      "learning_rate": 2.7368917600436694e-05,
      "loss": 0.0349,
      "step": 210700
    },
    {
      "epoch": 7.248220609978338,
      "grad_norm": 0.0863996148109436,
      "learning_rate": 2.735817226069054e-05,
      "loss": 0.0388,
      "step": 210800
    },
    {
      "epoch": 7.251659044802806,
      "grad_norm": 0.14308351278305054,
      "learning_rate": 2.7347426920944384e-05,
      "loss": 0.0353,
      "step": 210900
    },
    {
      "epoch": 7.255097479627274,
      "grad_norm": 0.0784011259675026,
      "learning_rate": 2.7336681581198237e-05,
      "loss": 0.0313,
      "step": 211000
    },
    {
      "epoch": 7.258535914451741,
      "grad_norm": 0.10781586915254593,
      "learning_rate": 2.7325936241452082e-05,
      "loss": 0.036,
      "step": 211100
    },
    {
      "epoch": 7.261974349276209,
      "grad_norm": 0.19053873419761658,
      "learning_rate": 2.7315190901705934e-05,
      "loss": 0.0353,
      "step": 211200
    },
    {
      "epoch": 7.265412784100677,
      "grad_norm": 0.34886258840560913,
      "learning_rate": 2.730444556195978e-05,
      "loss": 0.0363,
      "step": 211300
    },
    {
      "epoch": 7.268851218925145,
      "grad_norm": 0.09719950705766678,
      "learning_rate": 2.7293700222213625e-05,
      "loss": 0.0348,
      "step": 211400
    },
    {
      "epoch": 7.272289653749613,
      "grad_norm": 0.11148928105831146,
      "learning_rate": 2.7282954882467477e-05,
      "loss": 0.0319,
      "step": 211500
    },
    {
      "epoch": 7.275728088574081,
      "grad_norm": 0.12165780365467072,
      "learning_rate": 2.7272209542721322e-05,
      "loss": 0.0318,
      "step": 211600
    },
    {
      "epoch": 7.279166523398549,
      "grad_norm": 0.2431362271308899,
      "learning_rate": 2.7261464202975174e-05,
      "loss": 0.0366,
      "step": 211700
    },
    {
      "epoch": 7.282604958223017,
      "grad_norm": 0.3212950825691223,
      "learning_rate": 2.725071886322902e-05,
      "loss": 0.0369,
      "step": 211800
    },
    {
      "epoch": 7.286043393047485,
      "grad_norm": 0.25307926535606384,
      "learning_rate": 2.7239973523482865e-05,
      "loss": 0.0335,
      "step": 211900
    },
    {
      "epoch": 7.289481827871953,
      "grad_norm": 0.41869881749153137,
      "learning_rate": 2.7229228183736717e-05,
      "loss": 0.0362,
      "step": 212000
    },
    {
      "epoch": 7.292920262696421,
      "grad_norm": 1.4094046354293823,
      "learning_rate": 2.7218482843990562e-05,
      "loss": 0.0357,
      "step": 212100
    },
    {
      "epoch": 7.296358697520889,
      "grad_norm": 0.05326000228524208,
      "learning_rate": 2.7207737504244414e-05,
      "loss": 0.0328,
      "step": 212200
    },
    {
      "epoch": 7.299797132345357,
      "grad_norm": 0.23316460847854614,
      "learning_rate": 2.719699216449826e-05,
      "loss": 0.0357,
      "step": 212300
    },
    {
      "epoch": 7.303235567169824,
      "grad_norm": 0.10522014647722244,
      "learning_rate": 2.718635427814957e-05,
      "loss": 0.0364,
      "step": 212400
    },
    {
      "epoch": 7.306674001994292,
      "grad_norm": 0.6899056434631348,
      "learning_rate": 2.7175608938403418e-05,
      "loss": 0.0341,
      "step": 212500
    },
    {
      "epoch": 7.31011243681876,
      "grad_norm": 0.09855975955724716,
      "learning_rate": 2.7164863598657263e-05,
      "loss": 0.0348,
      "step": 212600
    },
    {
      "epoch": 7.313550871643228,
      "grad_norm": 0.17983105778694153,
      "learning_rate": 2.7154118258911108e-05,
      "loss": 0.0337,
      "step": 212700
    },
    {
      "epoch": 7.316989306467696,
      "grad_norm": 0.12224741280078888,
      "learning_rate": 2.714337291916496e-05,
      "loss": 0.0385,
      "step": 212800
    },
    {
      "epoch": 7.320427741292164,
      "grad_norm": 0.18362051248550415,
      "learning_rate": 2.7132627579418806e-05,
      "loss": 0.0334,
      "step": 212900
    },
    {
      "epoch": 7.323866176116631,
      "grad_norm": 0.23643136024475098,
      "learning_rate": 2.7121882239672658e-05,
      "loss": 0.0331,
      "step": 213000
    },
    {
      "epoch": 7.327304610941099,
      "grad_norm": 0.22535204887390137,
      "learning_rate": 2.7111136899926503e-05,
      "loss": 0.0384,
      "step": 213100
    },
    {
      "epoch": 7.330743045765567,
      "grad_norm": 0.2039886862039566,
      "learning_rate": 2.7100391560180348e-05,
      "loss": 0.0341,
      "step": 213200
    },
    {
      "epoch": 7.334181480590035,
      "grad_norm": 0.4269005060195923,
      "learning_rate": 2.70896462204342e-05,
      "loss": 0.0363,
      "step": 213300
    },
    {
      "epoch": 7.337619915414503,
      "grad_norm": 0.3267335593700409,
      "learning_rate": 2.7078900880688046e-05,
      "loss": 0.0316,
      "step": 213400
    },
    {
      "epoch": 7.3410583502389715,
      "grad_norm": 0.19835199415683746,
      "learning_rate": 2.7068155540941898e-05,
      "loss": 0.036,
      "step": 213500
    },
    {
      "epoch": 7.3444967850634395,
      "grad_norm": 0.2255183756351471,
      "learning_rate": 2.7057410201195743e-05,
      "loss": 0.0374,
      "step": 213600
    },
    {
      "epoch": 7.347935219887907,
      "grad_norm": 0.1117405891418457,
      "learning_rate": 2.7046664861449588e-05,
      "loss": 0.0331,
      "step": 213700
    },
    {
      "epoch": 7.351373654712375,
      "grad_norm": 0.14123477041721344,
      "learning_rate": 2.7036026975100898e-05,
      "loss": 0.0354,
      "step": 213800
    },
    {
      "epoch": 7.354812089536843,
      "grad_norm": 0.13741372525691986,
      "learning_rate": 2.702528163535475e-05,
      "loss": 0.0348,
      "step": 213900
    },
    {
      "epoch": 7.358250524361311,
      "grad_norm": 0.48223677277565,
      "learning_rate": 2.7014536295608595e-05,
      "loss": 0.0372,
      "step": 214000
    },
    {
      "epoch": 7.361688959185779,
      "grad_norm": 0.14360131323337555,
      "learning_rate": 2.7003790955862447e-05,
      "loss": 0.0357,
      "step": 214100
    },
    {
      "epoch": 7.365127394010247,
      "grad_norm": 0.1330576241016388,
      "learning_rate": 2.6993045616116293e-05,
      "loss": 0.0334,
      "step": 214200
    },
    {
      "epoch": 7.368565828834715,
      "grad_norm": 0.1902051866054535,
      "learning_rate": 2.6982300276370138e-05,
      "loss": 0.0369,
      "step": 214300
    },
    {
      "epoch": 7.372004263659182,
      "grad_norm": 0.1581152379512787,
      "learning_rate": 2.697155493662399e-05,
      "loss": 0.0358,
      "step": 214400
    },
    {
      "epoch": 7.37544269848365,
      "grad_norm": 0.12539076805114746,
      "learning_rate": 2.6960809596877835e-05,
      "loss": 0.0368,
      "step": 214500
    },
    {
      "epoch": 7.378881133308118,
      "grad_norm": 0.39436134696006775,
      "learning_rate": 2.6950064257131684e-05,
      "loss": 0.0338,
      "step": 214600
    },
    {
      "epoch": 7.382319568132586,
      "grad_norm": 0.10798021405935287,
      "learning_rate": 2.6939318917385533e-05,
      "loss": 0.037,
      "step": 214700
    },
    {
      "epoch": 7.385758002957054,
      "grad_norm": 0.16295664012432098,
      "learning_rate": 2.6928573577639378e-05,
      "loss": 0.0335,
      "step": 214800
    },
    {
      "epoch": 7.389196437781522,
      "grad_norm": 0.10578995198011398,
      "learning_rate": 2.6917828237893227e-05,
      "loss": 0.0373,
      "step": 214900
    },
    {
      "epoch": 7.392634872605989,
      "grad_norm": 0.5476363897323608,
      "learning_rate": 2.6907082898147072e-05,
      "loss": 0.0385,
      "step": 215000
    },
    {
      "epoch": 7.396073307430457,
      "grad_norm": 0.13441865146160126,
      "learning_rate": 2.6896337558400924e-05,
      "loss": 0.0359,
      "step": 215100
    },
    {
      "epoch": 7.3995117422549255,
      "grad_norm": 0.18177618086338043,
      "learning_rate": 2.688559221865477e-05,
      "loss": 0.0349,
      "step": 215200
    },
    {
      "epoch": 7.4029501770793935,
      "grad_norm": 0.20430438220500946,
      "learning_rate": 2.6874846878908615e-05,
      "loss": 0.0343,
      "step": 215300
    },
    {
      "epoch": 7.4063886119038616,
      "grad_norm": 0.07833780348300934,
      "learning_rate": 2.6864101539162467e-05,
      "loss": 0.034,
      "step": 215400
    },
    {
      "epoch": 7.40982704672833,
      "grad_norm": 0.16296568512916565,
      "learning_rate": 2.6853356199416312e-05,
      "loss": 0.0397,
      "step": 215500
    },
    {
      "epoch": 7.413265481552797,
      "grad_norm": 0.23016847670078278,
      "learning_rate": 2.6842610859670164e-05,
      "loss": 0.0374,
      "step": 215600
    },
    {
      "epoch": 7.416703916377265,
      "grad_norm": 0.1366068720817566,
      "learning_rate": 2.683186551992401e-05,
      "loss": 0.0353,
      "step": 215700
    },
    {
      "epoch": 7.420142351201733,
      "grad_norm": 0.14201946556568146,
      "learning_rate": 2.6821120180177855e-05,
      "loss": 0.032,
      "step": 215800
    },
    {
      "epoch": 7.423580786026201,
      "grad_norm": 0.17940853536128998,
      "learning_rate": 2.6810374840431707e-05,
      "loss": 0.0348,
      "step": 215900
    },
    {
      "epoch": 7.427019220850669,
      "grad_norm": 0.1968860626220703,
      "learning_rate": 2.6799629500685552e-05,
      "loss": 0.0335,
      "step": 216000
    },
    {
      "epoch": 7.430457655675137,
      "grad_norm": 0.16656021773815155,
      "learning_rate": 2.6788884160939404e-05,
      "loss": 0.0363,
      "step": 216100
    },
    {
      "epoch": 7.433896090499605,
      "grad_norm": 0.26246070861816406,
      "learning_rate": 2.677813882119325e-05,
      "loss": 0.0338,
      "step": 216200
    },
    {
      "epoch": 7.437334525324072,
      "grad_norm": 0.2071705311536789,
      "learning_rate": 2.6767393481447095e-05,
      "loss": 0.0346,
      "step": 216300
    },
    {
      "epoch": 7.44077296014854,
      "grad_norm": 0.20928041636943817,
      "learning_rate": 2.6756648141700947e-05,
      "loss": 0.0336,
      "step": 216400
    },
    {
      "epoch": 7.444211394973008,
      "grad_norm": 0.13879114389419556,
      "learning_rate": 2.6745902801954792e-05,
      "loss": 0.0379,
      "step": 216500
    },
    {
      "epoch": 7.447649829797476,
      "grad_norm": 0.24795657396316528,
      "learning_rate": 2.6735157462208644e-05,
      "loss": 0.0379,
      "step": 216600
    },
    {
      "epoch": 7.451088264621944,
      "grad_norm": 0.24917878210544586,
      "learning_rate": 2.672441212246249e-05,
      "loss": 0.0373,
      "step": 216700
    },
    {
      "epoch": 7.454526699446412,
      "grad_norm": 0.2104664295911789,
      "learning_rate": 2.6713666782716335e-05,
      "loss": 0.0378,
      "step": 216800
    },
    {
      "epoch": 7.4579651342708795,
      "grad_norm": 0.352700412273407,
      "learning_rate": 2.6702921442970187e-05,
      "loss": 0.0387,
      "step": 216900
    },
    {
      "epoch": 7.4614035690953475,
      "grad_norm": 0.20766131579875946,
      "learning_rate": 2.6692176103224032e-05,
      "loss": 0.0332,
      "step": 217000
    },
    {
      "epoch": 7.464842003919816,
      "grad_norm": 0.21223169565200806,
      "learning_rate": 2.6681430763477884e-05,
      "loss": 0.0318,
      "step": 217100
    },
    {
      "epoch": 7.468280438744284,
      "grad_norm": 0.12542642652988434,
      "learning_rate": 2.667068542373173e-05,
      "loss": 0.0359,
      "step": 217200
    },
    {
      "epoch": 7.471718873568752,
      "grad_norm": 0.09419092535972595,
      "learning_rate": 2.6659940083985575e-05,
      "loss": 0.0349,
      "step": 217300
    },
    {
      "epoch": 7.47515730839322,
      "grad_norm": 0.13099034130573273,
      "learning_rate": 2.6649194744239427e-05,
      "loss": 0.0358,
      "step": 217400
    },
    {
      "epoch": 7.478595743217688,
      "grad_norm": 0.29877981543540955,
      "learning_rate": 2.6638449404493272e-05,
      "loss": 0.0365,
      "step": 217500
    },
    {
      "epoch": 7.482034178042155,
      "grad_norm": 0.5411085486412048,
      "learning_rate": 2.662770406474712e-05,
      "loss": 0.0363,
      "step": 217600
    },
    {
      "epoch": 7.485472612866623,
      "grad_norm": 0.5725331902503967,
      "learning_rate": 2.661695872500097e-05,
      "loss": 0.0343,
      "step": 217700
    },
    {
      "epoch": 7.488911047691091,
      "grad_norm": 0.3390067219734192,
      "learning_rate": 2.6606213385254818e-05,
      "loss": 0.0393,
      "step": 217800
    },
    {
      "epoch": 7.492349482515559,
      "grad_norm": 0.08878330141305923,
      "learning_rate": 2.6595468045508663e-05,
      "loss": 0.0359,
      "step": 217900
    },
    {
      "epoch": 7.495787917340027,
      "grad_norm": 0.5193510055541992,
      "learning_rate": 2.658472270576251e-05,
      "loss": 0.0339,
      "step": 218000
    },
    {
      "epoch": 7.499226352164495,
      "grad_norm": 0.34204256534576416,
      "learning_rate": 2.6574084819413818e-05,
      "loss": 0.0359,
      "step": 218100
    },
    {
      "epoch": 7.502664786988962,
      "grad_norm": 0.1750827133655548,
      "learning_rate": 2.656333947966767e-05,
      "loss": 0.0338,
      "step": 218200
    },
    {
      "epoch": 7.50610322181343,
      "grad_norm": 0.1044740304350853,
      "learning_rate": 2.6552594139921516e-05,
      "loss": 0.0347,
      "step": 218300
    },
    {
      "epoch": 7.509541656637898,
      "grad_norm": 0.11704713106155396,
      "learning_rate": 2.6541848800175368e-05,
      "loss": 0.0334,
      "step": 218400
    },
    {
      "epoch": 7.512980091462366,
      "grad_norm": 0.0879356861114502,
      "learning_rate": 2.6531103460429213e-05,
      "loss": 0.0314,
      "step": 218500
    },
    {
      "epoch": 7.516418526286834,
      "grad_norm": 0.15337257087230682,
      "learning_rate": 2.652035812068306e-05,
      "loss": 0.0326,
      "step": 218600
    },
    {
      "epoch": 7.519856961111302,
      "grad_norm": 0.08546393364667892,
      "learning_rate": 2.650961278093691e-05,
      "loss": 0.0331,
      "step": 218700
    },
    {
      "epoch": 7.5232953959357705,
      "grad_norm": 0.07540597766637802,
      "learning_rate": 2.6498867441190756e-05,
      "loss": 0.0328,
      "step": 218800
    },
    {
      "epoch": 7.526733830760238,
      "grad_norm": 0.2619979679584503,
      "learning_rate": 2.6488122101444608e-05,
      "loss": 0.0317,
      "step": 218900
    },
    {
      "epoch": 7.530172265584706,
      "grad_norm": 0.12454219162464142,
      "learning_rate": 2.6477376761698453e-05,
      "loss": 0.0327,
      "step": 219000
    },
    {
      "epoch": 7.533610700409174,
      "grad_norm": 0.18341709673404694,
      "learning_rate": 2.64666314219523e-05,
      "loss": 0.0335,
      "step": 219100
    },
    {
      "epoch": 7.537049135233642,
      "grad_norm": 0.2425154745578766,
      "learning_rate": 2.645588608220615e-05,
      "loss": 0.0327,
      "step": 219200
    },
    {
      "epoch": 7.54048757005811,
      "grad_norm": 0.06972745060920715,
      "learning_rate": 2.6445140742459996e-05,
      "loss": 0.0339,
      "step": 219300
    },
    {
      "epoch": 7.543926004882578,
      "grad_norm": 0.2633788585662842,
      "learning_rate": 2.6434395402713848e-05,
      "loss": 0.0372,
      "step": 219400
    },
    {
      "epoch": 7.547364439707046,
      "grad_norm": 0.13065001368522644,
      "learning_rate": 2.6423650062967693e-05,
      "loss": 0.0351,
      "step": 219500
    },
    {
      "epoch": 7.550802874531513,
      "grad_norm": 0.17161118984222412,
      "learning_rate": 2.641290472322154e-05,
      "loss": 0.0339,
      "step": 219600
    },
    {
      "epoch": 7.554241309355981,
      "grad_norm": 0.22383959591388702,
      "learning_rate": 2.640215938347539e-05,
      "loss": 0.0325,
      "step": 219700
    },
    {
      "epoch": 7.557679744180449,
      "grad_norm": 0.17886050045490265,
      "learning_rate": 2.6391414043729236e-05,
      "loss": 0.0336,
      "step": 219800
    },
    {
      "epoch": 7.561118179004917,
      "grad_norm": 0.14413602650165558,
      "learning_rate": 2.6380668703983084e-05,
      "loss": 0.0365,
      "step": 219900
    },
    {
      "epoch": 7.564556613829385,
      "grad_norm": 0.345016747713089,
      "learning_rate": 2.6369923364236933e-05,
      "loss": 0.0349,
      "step": 220000
    },
    {
      "epoch": 7.567995048653852,
      "grad_norm": 0.1949162483215332,
      "learning_rate": 2.635917802449078e-05,
      "loss": 0.0384,
      "step": 220100
    },
    {
      "epoch": 7.57143348347832,
      "grad_norm": 0.17634961009025574,
      "learning_rate": 2.6348432684744627e-05,
      "loss": 0.0362,
      "step": 220200
    },
    {
      "epoch": 7.574871918302788,
      "grad_norm": 0.099566251039505,
      "learning_rate": 2.6337687344998472e-05,
      "loss": 0.0359,
      "step": 220300
    },
    {
      "epoch": 7.578310353127256,
      "grad_norm": 0.11979922652244568,
      "learning_rate": 2.6326942005252324e-05,
      "loss": 0.0322,
      "step": 220400
    },
    {
      "epoch": 7.5817487879517245,
      "grad_norm": 0.04819200187921524,
      "learning_rate": 2.631619666550617e-05,
      "loss": 0.0301,
      "step": 220500
    },
    {
      "epoch": 7.5851872227761925,
      "grad_norm": 0.23702390491962433,
      "learning_rate": 2.6305451325760015e-05,
      "loss": 0.0342,
      "step": 220600
    },
    {
      "epoch": 7.5886256576006605,
      "grad_norm": 0.41590216755867004,
      "learning_rate": 2.6294705986013867e-05,
      "loss": 0.0391,
      "step": 220700
    },
    {
      "epoch": 7.592064092425128,
      "grad_norm": 0.18701428174972534,
      "learning_rate": 2.6283960646267712e-05,
      "loss": 0.034,
      "step": 220800
    },
    {
      "epoch": 7.595502527249596,
      "grad_norm": 0.21836647391319275,
      "learning_rate": 2.6273215306521564e-05,
      "loss": 0.0357,
      "step": 220900
    },
    {
      "epoch": 7.598940962074064,
      "grad_norm": 0.28688836097717285,
      "learning_rate": 2.626246996677541e-05,
      "loss": 0.0329,
      "step": 221000
    },
    {
      "epoch": 7.602379396898532,
      "grad_norm": 0.17530333995819092,
      "learning_rate": 2.6251724627029255e-05,
      "loss": 0.0342,
      "step": 221100
    },
    {
      "epoch": 7.605817831723,
      "grad_norm": 0.24055996537208557,
      "learning_rate": 2.6240979287283107e-05,
      "loss": 0.0358,
      "step": 221200
    },
    {
      "epoch": 7.609256266547468,
      "grad_norm": 0.1444084197282791,
      "learning_rate": 2.6230341400934417e-05,
      "loss": 0.0337,
      "step": 221300
    },
    {
      "epoch": 7.612694701371936,
      "grad_norm": 0.25734129548072815,
      "learning_rate": 2.6219596061188262e-05,
      "loss": 0.0345,
      "step": 221400
    },
    {
      "epoch": 7.616133136196403,
      "grad_norm": 0.09085734188556671,
      "learning_rate": 2.6208850721442114e-05,
      "loss": 0.0345,
      "step": 221500
    },
    {
      "epoch": 7.619571571020871,
      "grad_norm": 0.18859964609146118,
      "learning_rate": 2.619810538169596e-05,
      "loss": 0.0325,
      "step": 221600
    },
    {
      "epoch": 7.623010005845339,
      "grad_norm": 0.28304991126060486,
      "learning_rate": 2.618736004194981e-05,
      "loss": 0.0343,
      "step": 221700
    },
    {
      "epoch": 7.626448440669807,
      "grad_norm": 0.566309928894043,
      "learning_rate": 2.6176614702203657e-05,
      "loss": 0.0347,
      "step": 221800
    },
    {
      "epoch": 7.629886875494275,
      "grad_norm": 0.4108159840106964,
      "learning_rate": 2.6165869362457502e-05,
      "loss": 0.0374,
      "step": 221900
    },
    {
      "epoch": 7.633325310318743,
      "grad_norm": 0.16549965739250183,
      "learning_rate": 2.6155124022711354e-05,
      "loss": 0.0364,
      "step": 222000
    },
    {
      "epoch": 7.63676374514321,
      "grad_norm": 0.19628162682056427,
      "learning_rate": 2.61443786829652e-05,
      "loss": 0.0336,
      "step": 222100
    },
    {
      "epoch": 7.6402021799676785,
      "grad_norm": 0.11272677034139633,
      "learning_rate": 2.6133633343219048e-05,
      "loss": 0.0344,
      "step": 222200
    },
    {
      "epoch": 7.6436406147921465,
      "grad_norm": 0.07013292610645294,
      "learning_rate": 2.6122888003472893e-05,
      "loss": 0.0352,
      "step": 222300
    },
    {
      "epoch": 7.6470790496166146,
      "grad_norm": 0.41948947310447693,
      "learning_rate": 2.6112142663726742e-05,
      "loss": 0.0356,
      "step": 222400
    },
    {
      "epoch": 7.650517484441083,
      "grad_norm": 0.06561316549777985,
      "learning_rate": 2.610139732398059e-05,
      "loss": 0.0355,
      "step": 222500
    },
    {
      "epoch": 7.653955919265551,
      "grad_norm": 0.26241567730903625,
      "learning_rate": 2.6090651984234436e-05,
      "loss": 0.0354,
      "step": 222600
    },
    {
      "epoch": 7.657394354090018,
      "grad_norm": 0.16643428802490234,
      "learning_rate": 2.6079906644488288e-05,
      "loss": 0.0345,
      "step": 222700
    },
    {
      "epoch": 7.660832788914486,
      "grad_norm": 0.11417599022388458,
      "learning_rate": 2.6069161304742133e-05,
      "loss": 0.0327,
      "step": 222800
    },
    {
      "epoch": 7.664271223738954,
      "grad_norm": 0.27161967754364014,
      "learning_rate": 2.605841596499598e-05,
      "loss": 0.0345,
      "step": 222900
    },
    {
      "epoch": 7.667709658563422,
      "grad_norm": 0.3876155912876129,
      "learning_rate": 2.604767062524983e-05,
      "loss": 0.0342,
      "step": 223000
    },
    {
      "epoch": 7.67114809338789,
      "grad_norm": 0.502687394618988,
      "learning_rate": 2.6036925285503676e-05,
      "loss": 0.0314,
      "step": 223100
    },
    {
      "epoch": 7.674586528212358,
      "grad_norm": 0.45757707953453064,
      "learning_rate": 2.6026179945757528e-05,
      "loss": 0.0356,
      "step": 223200
    },
    {
      "epoch": 7.678024963036826,
      "grad_norm": 0.27035826444625854,
      "learning_rate": 2.6015434606011373e-05,
      "loss": 0.0386,
      "step": 223300
    },
    {
      "epoch": 7.681463397861293,
      "grad_norm": 0.10877963155508041,
      "learning_rate": 2.6004796719662683e-05,
      "loss": 0.0348,
      "step": 223400
    },
    {
      "epoch": 7.684901832685761,
      "grad_norm": 0.11700104176998138,
      "learning_rate": 2.5994051379916535e-05,
      "loss": 0.0334,
      "step": 223500
    },
    {
      "epoch": 7.688340267510229,
      "grad_norm": 0.35075199604034424,
      "learning_rate": 2.598330604017038e-05,
      "loss": 0.0335,
      "step": 223600
    },
    {
      "epoch": 7.691778702334697,
      "grad_norm": 0.12298256158828735,
      "learning_rate": 2.5972560700424226e-05,
      "loss": 0.0337,
      "step": 223700
    },
    {
      "epoch": 7.695217137159165,
      "grad_norm": 0.09221070259809494,
      "learning_rate": 2.5961815360678078e-05,
      "loss": 0.0335,
      "step": 223800
    },
    {
      "epoch": 7.698655571983633,
      "grad_norm": 0.3050064742565155,
      "learning_rate": 2.5951070020931923e-05,
      "loss": 0.0355,
      "step": 223900
    },
    {
      "epoch": 7.702094006808101,
      "grad_norm": 0.1642712950706482,
      "learning_rate": 2.5940324681185775e-05,
      "loss": 0.0318,
      "step": 224000
    },
    {
      "epoch": 7.705532441632569,
      "grad_norm": 0.408306360244751,
      "learning_rate": 2.592957934143962e-05,
      "loss": 0.0387,
      "step": 224100
    },
    {
      "epoch": 7.708970876457037,
      "grad_norm": 0.29948270320892334,
      "learning_rate": 2.5918834001693466e-05,
      "loss": 0.0327,
      "step": 224200
    },
    {
      "epoch": 7.712409311281505,
      "grad_norm": 0.0647975504398346,
      "learning_rate": 2.5908088661947318e-05,
      "loss": 0.0347,
      "step": 224300
    },
    {
      "epoch": 7.715847746105973,
      "grad_norm": 0.2217719405889511,
      "learning_rate": 2.5897343322201163e-05,
      "loss": 0.0353,
      "step": 224400
    },
    {
      "epoch": 7.719286180930441,
      "grad_norm": 0.058233682066202164,
      "learning_rate": 2.5886597982455012e-05,
      "loss": 0.0317,
      "step": 224500
    },
    {
      "epoch": 7.722724615754908,
      "grad_norm": 0.3017716705799103,
      "learning_rate": 2.5875852642708857e-05,
      "loss": 0.032,
      "step": 224600
    },
    {
      "epoch": 7.726163050579376,
      "grad_norm": 0.09239894151687622,
      "learning_rate": 2.5865107302962706e-05,
      "loss": 0.0355,
      "step": 224700
    },
    {
      "epoch": 7.729601485403844,
      "grad_norm": 0.08831837028265,
      "learning_rate": 2.5854361963216554e-05,
      "loss": 0.0369,
      "step": 224800
    },
    {
      "epoch": 7.733039920228312,
      "grad_norm": 0.1692858785390854,
      "learning_rate": 2.58436166234704e-05,
      "loss": 0.0375,
      "step": 224900
    },
    {
      "epoch": 7.73647835505278,
      "grad_norm": 0.11756749451160431,
      "learning_rate": 2.5832871283724252e-05,
      "loss": 0.0355,
      "step": 225000
    },
    {
      "epoch": 7.739916789877248,
      "grad_norm": 0.11309736967086792,
      "learning_rate": 2.5822125943978097e-05,
      "loss": 0.0316,
      "step": 225100
    },
    {
      "epoch": 7.743355224701716,
      "grad_norm": 0.22066377103328705,
      "learning_rate": 2.5811380604231942e-05,
      "loss": 0.0343,
      "step": 225200
    },
    {
      "epoch": 7.746793659526183,
      "grad_norm": 0.17885315418243408,
      "learning_rate": 2.5800635264485795e-05,
      "loss": 0.0366,
      "step": 225300
    },
    {
      "epoch": 7.750232094350651,
      "grad_norm": 0.17319534718990326,
      "learning_rate": 2.578988992473964e-05,
      "loss": 0.0363,
      "step": 225400
    },
    {
      "epoch": 7.753670529175119,
      "grad_norm": 0.14886297285556793,
      "learning_rate": 2.5779144584993492e-05,
      "loss": 0.0308,
      "step": 225500
    },
    {
      "epoch": 7.757108963999587,
      "grad_norm": 0.07219894975423813,
      "learning_rate": 2.5768399245247337e-05,
      "loss": 0.0364,
      "step": 225600
    },
    {
      "epoch": 7.760547398824055,
      "grad_norm": 0.08802544325590134,
      "learning_rate": 2.5757653905501182e-05,
      "loss": 0.0314,
      "step": 225700
    },
    {
      "epoch": 7.7639858336485235,
      "grad_norm": 0.44829750061035156,
      "learning_rate": 2.5746908565755035e-05,
      "loss": 0.0374,
      "step": 225800
    },
    {
      "epoch": 7.7674242684729915,
      "grad_norm": 0.23808428645133972,
      "learning_rate": 2.573616322600888e-05,
      "loss": 0.0314,
      "step": 225900
    },
    {
      "epoch": 7.770862703297459,
      "grad_norm": 0.33986279368400574,
      "learning_rate": 2.5725417886262732e-05,
      "loss": 0.033,
      "step": 226000
    },
    {
      "epoch": 7.774301138121927,
      "grad_norm": 0.2070099115371704,
      "learning_rate": 2.5714672546516577e-05,
      "loss": 0.034,
      "step": 226100
    },
    {
      "epoch": 7.777739572946395,
      "grad_norm": 0.07726509124040604,
      "learning_rate": 2.5703927206770423e-05,
      "loss": 0.0338,
      "step": 226200
    },
    {
      "epoch": 7.781178007770863,
      "grad_norm": 0.1444539874792099,
      "learning_rate": 2.5693181867024275e-05,
      "loss": 0.0356,
      "step": 226300
    },
    {
      "epoch": 7.784616442595331,
      "grad_norm": 0.1518436074256897,
      "learning_rate": 2.568243652727812e-05,
      "loss": 0.0356,
      "step": 226400
    },
    {
      "epoch": 7.788054877419799,
      "grad_norm": 0.15099045634269714,
      "learning_rate": 2.5671691187531972e-05,
      "loss": 0.035,
      "step": 226500
    },
    {
      "epoch": 7.791493312244267,
      "grad_norm": 0.5759970545768738,
      "learning_rate": 2.5660945847785817e-05,
      "loss": 0.0348,
      "step": 226600
    },
    {
      "epoch": 7.794931747068734,
      "grad_norm": 0.2407393604516983,
      "learning_rate": 2.5650200508039663e-05,
      "loss": 0.0354,
      "step": 226700
    },
    {
      "epoch": 7.798370181893202,
      "grad_norm": 0.26509732007980347,
      "learning_rate": 2.5639455168293515e-05,
      "loss": 0.0326,
      "step": 226800
    },
    {
      "epoch": 7.80180861671767,
      "grad_norm": 0.09510182589292526,
      "learning_rate": 2.562870982854736e-05,
      "loss": 0.0333,
      "step": 226900
    },
    {
      "epoch": 7.805247051542138,
      "grad_norm": 0.1832055151462555,
      "learning_rate": 2.561807194219867e-05,
      "loss": 0.0386,
      "step": 227000
    },
    {
      "epoch": 7.808685486366606,
      "grad_norm": 0.07346543669700623,
      "learning_rate": 2.5607326602452518e-05,
      "loss": 0.0306,
      "step": 227100
    },
    {
      "epoch": 7.812123921191073,
      "grad_norm": 0.3310014605522156,
      "learning_rate": 2.5596581262706364e-05,
      "loss": 0.0343,
      "step": 227200
    },
    {
      "epoch": 7.815562356015541,
      "grad_norm": 0.07289478927850723,
      "learning_rate": 2.5585835922960212e-05,
      "loss": 0.0334,
      "step": 227300
    },
    {
      "epoch": 7.819000790840009,
      "grad_norm": 0.49904605746269226,
      "learning_rate": 2.557509058321406e-05,
      "loss": 0.0346,
      "step": 227400
    },
    {
      "epoch": 7.8224392256644775,
      "grad_norm": 0.09313938766717911,
      "learning_rate": 2.5564345243467906e-05,
      "loss": 0.0345,
      "step": 227500
    },
    {
      "epoch": 7.8258776604889455,
      "grad_norm": 0.25665900111198425,
      "learning_rate": 2.5553599903721758e-05,
      "loss": 0.0356,
      "step": 227600
    },
    {
      "epoch": 7.8293160953134135,
      "grad_norm": 0.25915831327438354,
      "learning_rate": 2.5542854563975604e-05,
      "loss": 0.0343,
      "step": 227700
    },
    {
      "epoch": 7.832754530137882,
      "grad_norm": 0.21392212808132172,
      "learning_rate": 2.553210922422945e-05,
      "loss": 0.0355,
      "step": 227800
    },
    {
      "epoch": 7.836192964962349,
      "grad_norm": 0.09967146813869476,
      "learning_rate": 2.55213638844833e-05,
      "loss": 0.0339,
      "step": 227900
    },
    {
      "epoch": 7.839631399786817,
      "grad_norm": 0.13990063965320587,
      "learning_rate": 2.5510618544737146e-05,
      "loss": 0.0315,
      "step": 228000
    },
    {
      "epoch": 7.843069834611285,
      "grad_norm": 0.06512899696826935,
      "learning_rate": 2.5499873204990998e-05,
      "loss": 0.0342,
      "step": 228100
    },
    {
      "epoch": 7.846508269435753,
      "grad_norm": 0.15640223026275635,
      "learning_rate": 2.5489127865244844e-05,
      "loss": 0.0378,
      "step": 228200
    },
    {
      "epoch": 7.849946704260221,
      "grad_norm": 0.08509431779384613,
      "learning_rate": 2.5478382525498696e-05,
      "loss": 0.0391,
      "step": 228300
    },
    {
      "epoch": 7.853385139084689,
      "grad_norm": 0.0865117609500885,
      "learning_rate": 2.546763718575254e-05,
      "loss": 0.031,
      "step": 228400
    },
    {
      "epoch": 7.856823573909157,
      "grad_norm": 0.10302970558404922,
      "learning_rate": 2.5456891846006386e-05,
      "loss": 0.0372,
      "step": 228500
    },
    {
      "epoch": 7.860262008733624,
      "grad_norm": 0.2449306845664978,
      "learning_rate": 2.5446146506260238e-05,
      "loss": 0.0343,
      "step": 228600
    },
    {
      "epoch": 7.863700443558092,
      "grad_norm": 0.10817090421915054,
      "learning_rate": 2.5435401166514084e-05,
      "loss": 0.0367,
      "step": 228700
    },
    {
      "epoch": 7.86713887838256,
      "grad_norm": 0.10932888835668564,
      "learning_rate": 2.5424655826767936e-05,
      "loss": 0.0339,
      "step": 228800
    },
    {
      "epoch": 7.870577313207028,
      "grad_norm": 0.4547484517097473,
      "learning_rate": 2.541391048702178e-05,
      "loss": 0.0313,
      "step": 228900
    },
    {
      "epoch": 7.874015748031496,
      "grad_norm": 0.3410642445087433,
      "learning_rate": 2.5403165147275626e-05,
      "loss": 0.0331,
      "step": 229000
    },
    {
      "epoch": 7.877454182855964,
      "grad_norm": 0.47031113505363464,
      "learning_rate": 2.539241980752948e-05,
      "loss": 0.0336,
      "step": 229100
    },
    {
      "epoch": 7.880892617680432,
      "grad_norm": 0.1916617453098297,
      "learning_rate": 2.5381674467783324e-05,
      "loss": 0.0359,
      "step": 229200
    },
    {
      "epoch": 7.8843310525048995,
      "grad_norm": 0.28767862915992737,
      "learning_rate": 2.5370929128037176e-05,
      "loss": 0.0364,
      "step": 229300
    },
    {
      "epoch": 7.887769487329368,
      "grad_norm": 0.3790258467197418,
      "learning_rate": 2.536018378829102e-05,
      "loss": 0.0372,
      "step": 229400
    },
    {
      "epoch": 7.891207922153836,
      "grad_norm": 0.1885945051908493,
      "learning_rate": 2.5349438448544866e-05,
      "loss": 0.031,
      "step": 229500
    },
    {
      "epoch": 7.894646356978304,
      "grad_norm": 0.2966376543045044,
      "learning_rate": 2.533869310879872e-05,
      "loss": 0.0337,
      "step": 229600
    },
    {
      "epoch": 7.898084791802772,
      "grad_norm": 0.3235037922859192,
      "learning_rate": 2.5328055222450025e-05,
      "loss": 0.0373,
      "step": 229700
    },
    {
      "epoch": 7.901523226627239,
      "grad_norm": 0.2143879532814026,
      "learning_rate": 2.531730988270387e-05,
      "loss": 0.0351,
      "step": 229800
    },
    {
      "epoch": 7.904961661451707,
      "grad_norm": 0.3355697989463806,
      "learning_rate": 2.5306564542957722e-05,
      "loss": 0.0325,
      "step": 229900
    },
    {
      "epoch": 7.908400096276175,
      "grad_norm": 0.19202002882957458,
      "learning_rate": 2.5295819203211567e-05,
      "loss": 0.0371,
      "step": 230000
    },
    {
      "epoch": 7.911838531100643,
      "grad_norm": 0.11514599621295929,
      "learning_rate": 2.5285073863465413e-05,
      "loss": 0.0345,
      "step": 230100
    },
    {
      "epoch": 7.915276965925111,
      "grad_norm": 0.25101643800735474,
      "learning_rate": 2.5274328523719265e-05,
      "loss": 0.0334,
      "step": 230200
    },
    {
      "epoch": 7.918715400749579,
      "grad_norm": 0.18565014004707336,
      "learning_rate": 2.526358318397311e-05,
      "loss": 0.0348,
      "step": 230300
    },
    {
      "epoch": 7.922153835574047,
      "grad_norm": 0.4625757932662964,
      "learning_rate": 2.5252837844226962e-05,
      "loss": 0.0345,
      "step": 230400
    },
    {
      "epoch": 7.925592270398514,
      "grad_norm": 0.074452243745327,
      "learning_rate": 2.5242092504480807e-05,
      "loss": 0.0365,
      "step": 230500
    },
    {
      "epoch": 7.929030705222982,
      "grad_norm": 0.21470361948013306,
      "learning_rate": 2.5231347164734653e-05,
      "loss": 0.0353,
      "step": 230600
    },
    {
      "epoch": 7.93246914004745,
      "grad_norm": 0.0764741525053978,
      "learning_rate": 2.5220601824988505e-05,
      "loss": 0.0337,
      "step": 230700
    },
    {
      "epoch": 7.935907574871918,
      "grad_norm": 0.11782566457986832,
      "learning_rate": 2.520985648524235e-05,
      "loss": 0.0378,
      "step": 230800
    },
    {
      "epoch": 7.939346009696386,
      "grad_norm": 0.21549353003501892,
      "learning_rate": 2.5199111145496202e-05,
      "loss": 0.0337,
      "step": 230900
    },
    {
      "epoch": 7.942784444520854,
      "grad_norm": 0.24683471024036407,
      "learning_rate": 2.5188365805750047e-05,
      "loss": 0.0341,
      "step": 231000
    },
    {
      "epoch": 7.9462228793453225,
      "grad_norm": 0.32111677527427673,
      "learning_rate": 2.5177620466003893e-05,
      "loss": 0.0356,
      "step": 231100
    },
    {
      "epoch": 7.94966131416979,
      "grad_norm": 0.22108618915081024,
      "learning_rate": 2.5166875126257745e-05,
      "loss": 0.0321,
      "step": 231200
    },
    {
      "epoch": 7.953099748994258,
      "grad_norm": 0.1492794007062912,
      "learning_rate": 2.515612978651159e-05,
      "loss": 0.033,
      "step": 231300
    },
    {
      "epoch": 7.956538183818726,
      "grad_norm": 0.1106121614575386,
      "learning_rate": 2.5145384446765442e-05,
      "loss": 0.0346,
      "step": 231400
    },
    {
      "epoch": 7.959976618643194,
      "grad_norm": 0.23758649826049805,
      "learning_rate": 2.5134639107019287e-05,
      "loss": 0.0357,
      "step": 231500
    },
    {
      "epoch": 7.963415053467662,
      "grad_norm": 0.22900119423866272,
      "learning_rate": 2.5123893767273133e-05,
      "loss": 0.0362,
      "step": 231600
    },
    {
      "epoch": 7.96685348829213,
      "grad_norm": 0.15403079986572266,
      "learning_rate": 2.5113148427526985e-05,
      "loss": 0.0341,
      "step": 231700
    },
    {
      "epoch": 7.970291923116597,
      "grad_norm": 0.17716263234615326,
      "learning_rate": 2.510240308778083e-05,
      "loss": 0.0363,
      "step": 231800
    },
    {
      "epoch": 7.973730357941065,
      "grad_norm": 0.12561830878257751,
      "learning_rate": 2.5091657748034682e-05,
      "loss": 0.0336,
      "step": 231900
    },
    {
      "epoch": 7.977168792765533,
      "grad_norm": 0.3231070339679718,
      "learning_rate": 2.5080912408288527e-05,
      "loss": 0.0365,
      "step": 232000
    },
    {
      "epoch": 7.980607227590001,
      "grad_norm": 0.23651671409606934,
      "learning_rate": 2.5070167068542373e-05,
      "loss": 0.0357,
      "step": 232100
    },
    {
      "epoch": 7.984045662414469,
      "grad_norm": 0.4050447642803192,
      "learning_rate": 2.505942172879622e-05,
      "loss": 0.0342,
      "step": 232200
    },
    {
      "epoch": 7.987484097238937,
      "grad_norm": 0.08655335754156113,
      "learning_rate": 2.504867638905007e-05,
      "loss": 0.0325,
      "step": 232300
    },
    {
      "epoch": 7.990922532063404,
      "grad_norm": 0.11836273968219757,
      "learning_rate": 2.503793104930392e-05,
      "loss": 0.0356,
      "step": 232400
    },
    {
      "epoch": 7.994360966887872,
      "grad_norm": 0.13362619280815125,
      "learning_rate": 2.5027185709557764e-05,
      "loss": 0.0368,
      "step": 232500
    },
    {
      "epoch": 7.99779940171234,
      "grad_norm": 0.38219189643859863,
      "learning_rate": 2.5016440369811613e-05,
      "loss": 0.034,
      "step": 232600
    },
    {
      "epoch": 8.0,
      "eval_accuracy_macro_0.5": 0.9852796792984009,
      "eval_accuracy_micro_0.5": 0.9852796792984009,
      "eval_accuracy_weighted_0.5": 0.9758188128471375,
      "eval_aucroc_macro": 0.9159958362579346,
      "eval_aucroc_micro": 0.9225764274597168,
      "eval_aucroc_weighted": 0.9193881154060364,
      "eval_f1_macro_0.5": 0.7754607796669006,
      "eval_f1_macro_0.6": 0.758531391620636,
      "eval_f1_macro_0.7": 0.7276953458786011,
      "eval_f1_macro_0.8": 0.575874924659729,
      "eval_f1_micro_0.5": 0.7864964604377747,
      "eval_f1_micro_0.6": 0.7753424644470215,
      "eval_f1_micro_0.7": 0.7527250647544861,
      "eval_f1_micro_0.8": 0.7117249965667725,
      "eval_f1_micro_0.9": 0.6174753904342651,
      "eval_f1_weighted_0.5": 0.7810086607933044,
      "eval_f1_weighted_0.6": 0.7656342387199402,
      "eval_f1_weighted_0.7": 0.736739456653595,
      "eval_f1_weighted_0.8": 0.5790906548500061,
      "eval_loss": 0.03180437907576561,
      "eval_runtime": 2088.4614,
      "eval_samples_per_second": 27.835,
      "eval_steps_per_second": 3.48,
      "step": 232664
    },
    {
      "epoch": 8.00123783653681,
      "grad_norm": 0.10179109871387482,
      "learning_rate": 2.500569503006546e-05,
      "loss": 0.0356,
      "step": 232700
    },
    {
      "epoch": 8.004676271361276,
      "grad_norm": 0.1537097543478012,
      "learning_rate": 2.499505714371677e-05,
      "loss": 0.0333,
      "step": 232800
    },
    {
      "epoch": 8.008114706185744,
      "grad_norm": 0.2856849133968353,
      "learning_rate": 2.498431180397062e-05,
      "loss": 0.0328,
      "step": 232900
    },
    {
      "epoch": 8.011553141010213,
      "grad_norm": 0.12929005920886993,
      "learning_rate": 2.497356646422447e-05,
      "loss": 0.0343,
      "step": 233000
    },
    {
      "epoch": 8.01499157583468,
      "grad_norm": 0.07025869935750961,
      "learning_rate": 2.4962821124478314e-05,
      "loss": 0.035,
      "step": 233100
    },
    {
      "epoch": 8.018430010659149,
      "grad_norm": 0.14272011816501617,
      "learning_rate": 2.4952075784732162e-05,
      "loss": 0.034,
      "step": 233200
    },
    {
      "epoch": 8.021868445483616,
      "grad_norm": 0.05302642285823822,
      "learning_rate": 2.494133044498601e-05,
      "loss": 0.0321,
      "step": 233300
    },
    {
      "epoch": 8.025306880308083,
      "grad_norm": 0.3196590542793274,
      "learning_rate": 2.493058510523986e-05,
      "loss": 0.0337,
      "step": 233400
    },
    {
      "epoch": 8.028745315132552,
      "grad_norm": 0.40160030126571655,
      "learning_rate": 2.491983976549371e-05,
      "loss": 0.0318,
      "step": 233500
    },
    {
      "epoch": 8.032183749957019,
      "grad_norm": 0.21497733891010284,
      "learning_rate": 2.4909094425747554e-05,
      "loss": 0.0339,
      "step": 233600
    },
    {
      "epoch": 8.035622184781488,
      "grad_norm": 0.06074501574039459,
      "learning_rate": 2.4898349086001402e-05,
      "loss": 0.0349,
      "step": 233700
    },
    {
      "epoch": 8.039060619605955,
      "grad_norm": 0.2904319167137146,
      "learning_rate": 2.488760374625525e-05,
      "loss": 0.0309,
      "step": 233800
    },
    {
      "epoch": 8.042499054430424,
      "grad_norm": 0.2756260931491852,
      "learning_rate": 2.48768584065091e-05,
      "loss": 0.0329,
      "step": 233900
    },
    {
      "epoch": 8.045937489254891,
      "grad_norm": 0.2901250422000885,
      "learning_rate": 2.486611306676295e-05,
      "loss": 0.0343,
      "step": 234000
    },
    {
      "epoch": 8.049375924079358,
      "grad_norm": 0.17586997151374817,
      "learning_rate": 2.4855367727016794e-05,
      "loss": 0.0345,
      "step": 234100
    },
    {
      "epoch": 8.052814358903827,
      "grad_norm": 0.2645121216773987,
      "learning_rate": 2.4844622387270642e-05,
      "loss": 0.0352,
      "step": 234200
    },
    {
      "epoch": 8.056252793728294,
      "grad_norm": 0.39826908707618713,
      "learning_rate": 2.483387704752449e-05,
      "loss": 0.0381,
      "step": 234300
    },
    {
      "epoch": 8.059691228552763,
      "grad_norm": 0.24375030398368835,
      "learning_rate": 2.482313170777834e-05,
      "loss": 0.0359,
      "step": 234400
    },
    {
      "epoch": 8.06312966337723,
      "grad_norm": 0.1377667486667633,
      "learning_rate": 2.4812386368032185e-05,
      "loss": 0.0357,
      "step": 234500
    },
    {
      "epoch": 8.0665680982017,
      "grad_norm": 0.20474089682102203,
      "learning_rate": 2.4801641028286034e-05,
      "loss": 0.0322,
      "step": 234600
    },
    {
      "epoch": 8.070006533026167,
      "grad_norm": 0.14262032508850098,
      "learning_rate": 2.4790895688539882e-05,
      "loss": 0.0321,
      "step": 234700
    },
    {
      "epoch": 8.073444967850634,
      "grad_norm": 0.08484039455652237,
      "learning_rate": 2.4780150348793728e-05,
      "loss": 0.0327,
      "step": 234800
    },
    {
      "epoch": 8.076883402675103,
      "grad_norm": 0.15753519535064697,
      "learning_rate": 2.4769405009047576e-05,
      "loss": 0.0342,
      "step": 234900
    },
    {
      "epoch": 8.08032183749957,
      "grad_norm": 0.16838829219341278,
      "learning_rate": 2.4758659669301425e-05,
      "loss": 0.0295,
      "step": 235000
    },
    {
      "epoch": 8.083760272324039,
      "grad_norm": 0.5562505125999451,
      "learning_rate": 2.474791432955527e-05,
      "loss": 0.0325,
      "step": 235100
    },
    {
      "epoch": 8.087198707148506,
      "grad_norm": 0.17405138909816742,
      "learning_rate": 2.473716898980912e-05,
      "loss": 0.0334,
      "step": 235200
    },
    {
      "epoch": 8.090637141972973,
      "grad_norm": 0.4262547791004181,
      "learning_rate": 2.4726423650062968e-05,
      "loss": 0.0327,
      "step": 235300
    },
    {
      "epoch": 8.094075576797442,
      "grad_norm": 0.160894975066185,
      "learning_rate": 2.4715678310316816e-05,
      "loss": 0.0332,
      "step": 235400
    },
    {
      "epoch": 8.097514011621909,
      "grad_norm": 0.22665293514728546,
      "learning_rate": 2.4704932970570665e-05,
      "loss": 0.034,
      "step": 235500
    },
    {
      "epoch": 8.100952446446378,
      "grad_norm": 0.3306785523891449,
      "learning_rate": 2.469418763082451e-05,
      "loss": 0.0311,
      "step": 235600
    },
    {
      "epoch": 8.104390881270845,
      "grad_norm": 0.1530744582414627,
      "learning_rate": 2.468344229107836e-05,
      "loss": 0.0367,
      "step": 235700
    },
    {
      "epoch": 8.107829316095314,
      "grad_norm": 0.1681031584739685,
      "learning_rate": 2.4672696951332208e-05,
      "loss": 0.0349,
      "step": 235800
    },
    {
      "epoch": 8.111267750919781,
      "grad_norm": 0.22355316579341888,
      "learning_rate": 2.4661951611586056e-05,
      "loss": 0.0372,
      "step": 235900
    },
    {
      "epoch": 8.114706185744248,
      "grad_norm": 0.04899977147579193,
      "learning_rate": 2.4651206271839905e-05,
      "loss": 0.0329,
      "step": 236000
    },
    {
      "epoch": 8.118144620568717,
      "grad_norm": 0.11823587864637375,
      "learning_rate": 2.4640460932093754e-05,
      "loss": 0.0317,
      "step": 236100
    },
    {
      "epoch": 8.121583055393184,
      "grad_norm": 0.5837439894676208,
      "learning_rate": 2.46297155923476e-05,
      "loss": 0.0331,
      "step": 236200
    },
    {
      "epoch": 8.125021490217653,
      "grad_norm": 0.13984698057174683,
      "learning_rate": 2.4619077705998912e-05,
      "loss": 0.0349,
      "step": 236300
    },
    {
      "epoch": 8.12845992504212,
      "grad_norm": 0.272322416305542,
      "learning_rate": 2.4608332366252757e-05,
      "loss": 0.0321,
      "step": 236400
    },
    {
      "epoch": 8.13189835986659,
      "grad_norm": 0.12334040552377701,
      "learning_rate": 2.4597587026506606e-05,
      "loss": 0.0349,
      "step": 236500
    },
    {
      "epoch": 8.135336794691057,
      "grad_norm": 0.47073304653167725,
      "learning_rate": 2.4586841686760455e-05,
      "loss": 0.0334,
      "step": 236600
    },
    {
      "epoch": 8.138775229515524,
      "grad_norm": 0.7336410880088806,
      "learning_rate": 2.4576096347014303e-05,
      "loss": 0.0321,
      "step": 236700
    },
    {
      "epoch": 8.142213664339993,
      "grad_norm": 0.8158067464828491,
      "learning_rate": 2.456535100726815e-05,
      "loss": 0.0339,
      "step": 236800
    },
    {
      "epoch": 8.14565209916446,
      "grad_norm": 0.14196988940238953,
      "learning_rate": 2.4554605667521997e-05,
      "loss": 0.0337,
      "step": 236900
    },
    {
      "epoch": 8.149090533988929,
      "grad_norm": 0.11677344143390656,
      "learning_rate": 2.4543860327775846e-05,
      "loss": 0.0371,
      "step": 237000
    },
    {
      "epoch": 8.152528968813396,
      "grad_norm": 0.09583370387554169,
      "learning_rate": 2.453311498802969e-05,
      "loss": 0.033,
      "step": 237100
    },
    {
      "epoch": 8.155967403637865,
      "grad_norm": 0.2861531674861908,
      "learning_rate": 2.452236964828354e-05,
      "loss": 0.0288,
      "step": 237200
    },
    {
      "epoch": 8.159405838462332,
      "grad_norm": 0.11230731755495071,
      "learning_rate": 2.451162430853739e-05,
      "loss": 0.037,
      "step": 237300
    },
    {
      "epoch": 8.1628442732868,
      "grad_norm": 0.29192328453063965,
      "learning_rate": 2.4500878968791234e-05,
      "loss": 0.0334,
      "step": 237400
    },
    {
      "epoch": 8.166282708111268,
      "grad_norm": 0.17502862215042114,
      "learning_rate": 2.4490133629045083e-05,
      "loss": 0.0327,
      "step": 237500
    },
    {
      "epoch": 8.169721142935735,
      "grad_norm": 0.3795928359031677,
      "learning_rate": 2.447938828929893e-05,
      "loss": 0.0344,
      "step": 237600
    },
    {
      "epoch": 8.173159577760204,
      "grad_norm": 0.2481732964515686,
      "learning_rate": 2.446864294955278e-05,
      "loss": 0.0331,
      "step": 237700
    },
    {
      "epoch": 8.176598012584671,
      "grad_norm": 0.3864074647426605,
      "learning_rate": 2.445789760980663e-05,
      "loss": 0.0308,
      "step": 237800
    },
    {
      "epoch": 8.180036447409138,
      "grad_norm": 0.5226936936378479,
      "learning_rate": 2.4447152270060474e-05,
      "loss": 0.0334,
      "step": 237900
    },
    {
      "epoch": 8.183474882233607,
      "grad_norm": 0.09675175696611404,
      "learning_rate": 2.4436406930314323e-05,
      "loss": 0.035,
      "step": 238000
    },
    {
      "epoch": 8.186913317058075,
      "grad_norm": 0.2320690155029297,
      "learning_rate": 2.442566159056817e-05,
      "loss": 0.0363,
      "step": 238100
    },
    {
      "epoch": 8.190351751882543,
      "grad_norm": 0.1607554405927658,
      "learning_rate": 2.441491625082202e-05,
      "loss": 0.0387,
      "step": 238200
    },
    {
      "epoch": 8.19379018670701,
      "grad_norm": 0.32128170132637024,
      "learning_rate": 2.440417091107587e-05,
      "loss": 0.0368,
      "step": 238300
    },
    {
      "epoch": 8.19722862153148,
      "grad_norm": 0.19766932725906372,
      "learning_rate": 2.4393425571329714e-05,
      "loss": 0.0324,
      "step": 238400
    },
    {
      "epoch": 8.200667056355947,
      "grad_norm": 0.3842690885066986,
      "learning_rate": 2.4382680231583563e-05,
      "loss": 0.0367,
      "step": 238500
    },
    {
      "epoch": 8.204105491180414,
      "grad_norm": 0.15406937897205353,
      "learning_rate": 2.437193489183741e-05,
      "loss": 0.0318,
      "step": 238600
    },
    {
      "epoch": 8.207543926004883,
      "grad_norm": 0.09751054644584656,
      "learning_rate": 2.436118955209126e-05,
      "loss": 0.0305,
      "step": 238700
    },
    {
      "epoch": 8.21098236082935,
      "grad_norm": 0.09211909770965576,
      "learning_rate": 2.435044421234511e-05,
      "loss": 0.0328,
      "step": 238800
    },
    {
      "epoch": 8.214420795653819,
      "grad_norm": 0.18482930958271027,
      "learning_rate": 2.4339698872598954e-05,
      "loss": 0.0316,
      "step": 238900
    },
    {
      "epoch": 8.217859230478286,
      "grad_norm": 0.16149085760116577,
      "learning_rate": 2.4328953532852803e-05,
      "loss": 0.0305,
      "step": 239000
    },
    {
      "epoch": 8.221297665302755,
      "grad_norm": 0.05646071583032608,
      "learning_rate": 2.431820819310665e-05,
      "loss": 0.0337,
      "step": 239100
    },
    {
      "epoch": 8.224736100127222,
      "grad_norm": 0.1929892897605896,
      "learning_rate": 2.43074628533605e-05,
      "loss": 0.0325,
      "step": 239200
    },
    {
      "epoch": 8.22817453495169,
      "grad_norm": 0.11977551132440567,
      "learning_rate": 2.429671751361435e-05,
      "loss": 0.0332,
      "step": 239300
    },
    {
      "epoch": 8.231612969776158,
      "grad_norm": 0.07696054875850677,
      "learning_rate": 2.4285972173868194e-05,
      "loss": 0.0322,
      "step": 239400
    },
    {
      "epoch": 8.235051404600625,
      "grad_norm": 0.21001683175563812,
      "learning_rate": 2.4275226834122043e-05,
      "loss": 0.0348,
      "step": 239500
    },
    {
      "epoch": 8.238489839425094,
      "grad_norm": 0.41230589151382446,
      "learning_rate": 2.426458894777335e-05,
      "loss": 0.0336,
      "step": 239600
    },
    {
      "epoch": 8.241928274249561,
      "grad_norm": 0.26526132225990295,
      "learning_rate": 2.4253843608027198e-05,
      "loss": 0.0336,
      "step": 239700
    },
    {
      "epoch": 8.24536670907403,
      "grad_norm": 0.19879813492298126,
      "learning_rate": 2.4243098268281046e-05,
      "loss": 0.0336,
      "step": 239800
    },
    {
      "epoch": 8.248805143898498,
      "grad_norm": 0.7276802062988281,
      "learning_rate": 2.4232352928534895e-05,
      "loss": 0.0351,
      "step": 239900
    },
    {
      "epoch": 8.252243578722965,
      "grad_norm": 0.5955787301063538,
      "learning_rate": 2.4221607588788744e-05,
      "loss": 0.035,
      "step": 240000
    },
    {
      "epoch": 8.255682013547434,
      "grad_norm": 0.1890997588634491,
      "learning_rate": 2.421086224904259e-05,
      "loss": 0.0369,
      "step": 240100
    },
    {
      "epoch": 8.2591204483719,
      "grad_norm": 0.06278233975172043,
      "learning_rate": 2.4200116909296438e-05,
      "loss": 0.0329,
      "step": 240200
    },
    {
      "epoch": 8.26255888319637,
      "grad_norm": 0.25530338287353516,
      "learning_rate": 2.4189371569550287e-05,
      "loss": 0.0334,
      "step": 240300
    },
    {
      "epoch": 8.265997318020837,
      "grad_norm": 0.1271815150976181,
      "learning_rate": 2.4178626229804135e-05,
      "loss": 0.0337,
      "step": 240400
    },
    {
      "epoch": 8.269435752845304,
      "grad_norm": 0.12277025729417801,
      "learning_rate": 2.4167880890057984e-05,
      "loss": 0.0305,
      "step": 240500
    },
    {
      "epoch": 8.272874187669773,
      "grad_norm": 0.3574882447719574,
      "learning_rate": 2.415713555031183e-05,
      "loss": 0.0308,
      "step": 240600
    },
    {
      "epoch": 8.27631262249424,
      "grad_norm": 0.31426936388015747,
      "learning_rate": 2.4146390210565678e-05,
      "loss": 0.034,
      "step": 240700
    },
    {
      "epoch": 8.279751057318709,
      "grad_norm": 0.047242436558008194,
      "learning_rate": 2.4135644870819527e-05,
      "loss": 0.0327,
      "step": 240800
    },
    {
      "epoch": 8.283189492143176,
      "grad_norm": 0.09031462669372559,
      "learning_rate": 2.4124899531073375e-05,
      "loss": 0.0335,
      "step": 240900
    },
    {
      "epoch": 8.286627926967645,
      "grad_norm": 0.654741644859314,
      "learning_rate": 2.4114154191327224e-05,
      "loss": 0.032,
      "step": 241000
    },
    {
      "epoch": 8.290066361792112,
      "grad_norm": 0.19201797246932983,
      "learning_rate": 2.4103516304978534e-05,
      "loss": 0.034,
      "step": 241100
    },
    {
      "epoch": 8.29350479661658,
      "grad_norm": 0.12010841816663742,
      "learning_rate": 2.4092770965232382e-05,
      "loss": 0.0349,
      "step": 241200
    },
    {
      "epoch": 8.296943231441048,
      "grad_norm": 0.14278416335582733,
      "learning_rate": 2.4082025625486227e-05,
      "loss": 0.0344,
      "step": 241300
    },
    {
      "epoch": 8.300381666265515,
      "grad_norm": 0.09845907986164093,
      "learning_rate": 2.4071280285740076e-05,
      "loss": 0.0362,
      "step": 241400
    },
    {
      "epoch": 8.303820101089984,
      "grad_norm": 0.2088121622800827,
      "learning_rate": 2.4060534945993925e-05,
      "loss": 0.0366,
      "step": 241500
    },
    {
      "epoch": 8.307258535914452,
      "grad_norm": 0.07998738437891006,
      "learning_rate": 2.404978960624777e-05,
      "loss": 0.0329,
      "step": 241600
    },
    {
      "epoch": 8.31069697073892,
      "grad_norm": 0.6161878705024719,
      "learning_rate": 2.403904426650162e-05,
      "loss": 0.0355,
      "step": 241700
    },
    {
      "epoch": 8.314135405563388,
      "grad_norm": 0.20968586206436157,
      "learning_rate": 2.4028298926755468e-05,
      "loss": 0.0343,
      "step": 241800
    },
    {
      "epoch": 8.317573840387855,
      "grad_norm": 0.11574964225292206,
      "learning_rate": 2.4017553587009313e-05,
      "loss": 0.034,
      "step": 241900
    },
    {
      "epoch": 8.321012275212324,
      "grad_norm": 0.174343541264534,
      "learning_rate": 2.400680824726316e-05,
      "loss": 0.032,
      "step": 242000
    },
    {
      "epoch": 8.32445071003679,
      "grad_norm": 0.40841156244277954,
      "learning_rate": 2.399606290751701e-05,
      "loss": 0.0326,
      "step": 242100
    },
    {
      "epoch": 8.32788914486126,
      "grad_norm": 0.3392702341079712,
      "learning_rate": 2.398531756777086e-05,
      "loss": 0.0319,
      "step": 242200
    },
    {
      "epoch": 8.331327579685727,
      "grad_norm": 0.1813480705022812,
      "learning_rate": 2.3974572228024708e-05,
      "loss": 0.0322,
      "step": 242300
    },
    {
      "epoch": 8.334766014510194,
      "grad_norm": 0.1559552252292633,
      "learning_rate": 2.3963826888278553e-05,
      "loss": 0.034,
      "step": 242400
    },
    {
      "epoch": 8.338204449334663,
      "grad_norm": 0.2150932103395462,
      "learning_rate": 2.39530815485324e-05,
      "loss": 0.0345,
      "step": 242500
    },
    {
      "epoch": 8.34164288415913,
      "grad_norm": 0.6123413443565369,
      "learning_rate": 2.394233620878625e-05,
      "loss": 0.0324,
      "step": 242600
    },
    {
      "epoch": 8.345081318983599,
      "grad_norm": 0.17646652460098267,
      "learning_rate": 2.39315908690401e-05,
      "loss": 0.0388,
      "step": 242700
    },
    {
      "epoch": 8.348519753808066,
      "grad_norm": 0.28836673498153687,
      "learning_rate": 2.3920845529293948e-05,
      "loss": 0.0337,
      "step": 242800
    },
    {
      "epoch": 8.351958188632535,
      "grad_norm": 0.12483932077884674,
      "learning_rate": 2.3910100189547793e-05,
      "loss": 0.0356,
      "step": 242900
    },
    {
      "epoch": 8.355396623457002,
      "grad_norm": 0.10938037186861038,
      "learning_rate": 2.389935484980164e-05,
      "loss": 0.0318,
      "step": 243000
    },
    {
      "epoch": 8.35883505828147,
      "grad_norm": 0.06289133429527283,
      "learning_rate": 2.388860951005549e-05,
      "loss": 0.0335,
      "step": 243100
    },
    {
      "epoch": 8.362273493105938,
      "grad_norm": 0.1548614799976349,
      "learning_rate": 2.387786417030934e-05,
      "loss": 0.0308,
      "step": 243200
    },
    {
      "epoch": 8.365711927930406,
      "grad_norm": 0.12276379764080048,
      "learning_rate": 2.3867118830563188e-05,
      "loss": 0.0347,
      "step": 243300
    },
    {
      "epoch": 8.369150362754874,
      "grad_norm": 0.07688542455434799,
      "learning_rate": 2.3856373490817033e-05,
      "loss": 0.0386,
      "step": 243400
    },
    {
      "epoch": 8.372588797579342,
      "grad_norm": 0.12590084969997406,
      "learning_rate": 2.384562815107088e-05,
      "loss": 0.0317,
      "step": 243500
    },
    {
      "epoch": 8.37602723240381,
      "grad_norm": 0.12508772313594818,
      "learning_rate": 2.383488281132473e-05,
      "loss": 0.0346,
      "step": 243600
    },
    {
      "epoch": 8.379465667228278,
      "grad_norm": 0.09723776578903198,
      "learning_rate": 2.382413747157858e-05,
      "loss": 0.0305,
      "step": 243700
    },
    {
      "epoch": 8.382904102052745,
      "grad_norm": 0.3559567928314209,
      "learning_rate": 2.3813392131832428e-05,
      "loss": 0.0326,
      "step": 243800
    },
    {
      "epoch": 8.386342536877214,
      "grad_norm": 0.5358827710151672,
      "learning_rate": 2.3802646792086273e-05,
      "loss": 0.0348,
      "step": 243900
    },
    {
      "epoch": 8.389780971701681,
      "grad_norm": 0.3227541446685791,
      "learning_rate": 2.379190145234012e-05,
      "loss": 0.0409,
      "step": 244000
    },
    {
      "epoch": 8.39321940652615,
      "grad_norm": 0.23725652694702148,
      "learning_rate": 2.378115611259397e-05,
      "loss": 0.0335,
      "step": 244100
    },
    {
      "epoch": 8.396657841350617,
      "grad_norm": 0.26767775416374207,
      "learning_rate": 2.377041077284782e-05,
      "loss": 0.0352,
      "step": 244200
    },
    {
      "epoch": 8.400096276175086,
      "grad_norm": 0.2630646228790283,
      "learning_rate": 2.3759665433101668e-05,
      "loss": 0.0328,
      "step": 244300
    },
    {
      "epoch": 8.403534710999553,
      "grad_norm": 0.524925708770752,
      "learning_rate": 2.3748920093355513e-05,
      "loss": 0.0396,
      "step": 244400
    },
    {
      "epoch": 8.40697314582402,
      "grad_norm": 0.07603214681148529,
      "learning_rate": 2.373817475360936e-05,
      "loss": 0.0365,
      "step": 244500
    },
    {
      "epoch": 8.41041158064849,
      "grad_norm": 0.2646779716014862,
      "learning_rate": 2.3727429413863207e-05,
      "loss": 0.0337,
      "step": 244600
    },
    {
      "epoch": 8.413850015472956,
      "grad_norm": 0.27065739035606384,
      "learning_rate": 2.3716684074117056e-05,
      "loss": 0.0332,
      "step": 244700
    },
    {
      "epoch": 8.417288450297425,
      "grad_norm": 0.13492624461650848,
      "learning_rate": 2.3705938734370904e-05,
      "loss": 0.0367,
      "step": 244800
    },
    {
      "epoch": 8.420726885121892,
      "grad_norm": 0.13109908998012543,
      "learning_rate": 2.369519339462475e-05,
      "loss": 0.0339,
      "step": 244900
    },
    {
      "epoch": 8.424165319946361,
      "grad_norm": 0.11835672706365585,
      "learning_rate": 2.3684448054878598e-05,
      "loss": 0.0321,
      "step": 245000
    },
    {
      "epoch": 8.427603754770828,
      "grad_norm": 0.29408785700798035,
      "learning_rate": 2.3673702715132447e-05,
      "loss": 0.0339,
      "step": 245100
    },
    {
      "epoch": 8.431042189595296,
      "grad_norm": 0.17404676973819733,
      "learning_rate": 2.3662957375386296e-05,
      "loss": 0.0353,
      "step": 245200
    },
    {
      "epoch": 8.434480624419765,
      "grad_norm": 0.10991328954696655,
      "learning_rate": 2.3652212035640144e-05,
      "loss": 0.0312,
      "step": 245300
    },
    {
      "epoch": 8.437919059244232,
      "grad_norm": 0.4639429748058319,
      "learning_rate": 2.3641574149291454e-05,
      "loss": 0.0336,
      "step": 245400
    },
    {
      "epoch": 8.4413574940687,
      "grad_norm": 0.12415790557861328,
      "learning_rate": 2.3630828809545303e-05,
      "loss": 0.0361,
      "step": 245500
    },
    {
      "epoch": 8.444795928893168,
      "grad_norm": 0.10875444859266281,
      "learning_rate": 2.3620083469799148e-05,
      "loss": 0.0343,
      "step": 245600
    },
    {
      "epoch": 8.448234363717635,
      "grad_norm": 0.21301628649234772,
      "learning_rate": 2.3609338130052997e-05,
      "loss": 0.0339,
      "step": 245700
    },
    {
      "epoch": 8.451672798542104,
      "grad_norm": 0.5837141871452332,
      "learning_rate": 2.3598592790306845e-05,
      "loss": 0.0339,
      "step": 245800
    },
    {
      "epoch": 8.455111233366571,
      "grad_norm": 0.3657720386981964,
      "learning_rate": 2.3587847450560694e-05,
      "loss": 0.0361,
      "step": 245900
    },
    {
      "epoch": 8.45854966819104,
      "grad_norm": 0.182941734790802,
      "learning_rate": 2.3577102110814543e-05,
      "loss": 0.0371,
      "step": 246000
    },
    {
      "epoch": 8.461988103015507,
      "grad_norm": 0.23422478139400482,
      "learning_rate": 2.3566356771068388e-05,
      "loss": 0.0349,
      "step": 246100
    },
    {
      "epoch": 8.465426537839976,
      "grad_norm": 0.21001827716827393,
      "learning_rate": 2.3555611431322237e-05,
      "loss": 0.0358,
      "step": 246200
    },
    {
      "epoch": 8.468864972664443,
      "grad_norm": 0.13242307305335999,
      "learning_rate": 2.3544866091576085e-05,
      "loss": 0.0319,
      "step": 246300
    },
    {
      "epoch": 8.47230340748891,
      "grad_norm": 0.11822604387998581,
      "learning_rate": 2.3534120751829934e-05,
      "loss": 0.0332,
      "step": 246400
    },
    {
      "epoch": 8.47574184231338,
      "grad_norm": 0.26381227374076843,
      "learning_rate": 2.3523375412083783e-05,
      "loss": 0.0326,
      "step": 246500
    },
    {
      "epoch": 8.479180277137846,
      "grad_norm": 0.1799483299255371,
      "learning_rate": 2.3512630072337628e-05,
      "loss": 0.0308,
      "step": 246600
    },
    {
      "epoch": 8.482618711962315,
      "grad_norm": 0.27009594440460205,
      "learning_rate": 2.3501884732591477e-05,
      "loss": 0.0317,
      "step": 246700
    },
    {
      "epoch": 8.486057146786782,
      "grad_norm": 0.1474708914756775,
      "learning_rate": 2.3491139392845325e-05,
      "loss": 0.0352,
      "step": 246800
    },
    {
      "epoch": 8.489495581611251,
      "grad_norm": 0.18913395702838898,
      "learning_rate": 2.348039405309917e-05,
      "loss": 0.0346,
      "step": 246900
    },
    {
      "epoch": 8.492934016435719,
      "grad_norm": 0.30081284046173096,
      "learning_rate": 2.346964871335302e-05,
      "loss": 0.0351,
      "step": 247000
    },
    {
      "epoch": 8.496372451260186,
      "grad_norm": 0.23744983971118927,
      "learning_rate": 2.3458903373606868e-05,
      "loss": 0.0317,
      "step": 247100
    },
    {
      "epoch": 8.499810886084655,
      "grad_norm": 0.2106858640909195,
      "learning_rate": 2.3448158033860713e-05,
      "loss": 0.0341,
      "step": 247200
    },
    {
      "epoch": 8.503249320909122,
      "grad_norm": 0.3131270706653595,
      "learning_rate": 2.3437412694114562e-05,
      "loss": 0.0322,
      "step": 247300
    },
    {
      "epoch": 8.50668775573359,
      "grad_norm": 0.2783068120479584,
      "learning_rate": 2.342666735436841e-05,
      "loss": 0.0336,
      "step": 247400
    },
    {
      "epoch": 8.510126190558058,
      "grad_norm": 0.1654062122106552,
      "learning_rate": 2.341592201462226e-05,
      "loss": 0.0321,
      "step": 247500
    },
    {
      "epoch": 8.513564625382525,
      "grad_norm": 0.06404919177293777,
      "learning_rate": 2.3405176674876108e-05,
      "loss": 0.0329,
      "step": 247600
    },
    {
      "epoch": 8.517003060206994,
      "grad_norm": 0.2667219340801239,
      "learning_rate": 2.3394431335129953e-05,
      "loss": 0.0343,
      "step": 247700
    },
    {
      "epoch": 8.520441495031461,
      "grad_norm": 0.18963675200939178,
      "learning_rate": 2.3383685995383802e-05,
      "loss": 0.0345,
      "step": 247800
    },
    {
      "epoch": 8.52387992985593,
      "grad_norm": 0.33424389362335205,
      "learning_rate": 2.337294065563765e-05,
      "loss": 0.0332,
      "step": 247900
    },
    {
      "epoch": 8.527318364680397,
      "grad_norm": 0.24689483642578125,
      "learning_rate": 2.33621953158915e-05,
      "loss": 0.0325,
      "step": 248000
    },
    {
      "epoch": 8.530756799504866,
      "grad_norm": 0.15077921748161316,
      "learning_rate": 2.3351449976145348e-05,
      "loss": 0.0338,
      "step": 248100
    },
    {
      "epoch": 8.534195234329333,
      "grad_norm": 0.3414900600910187,
      "learning_rate": 2.3340704636399193e-05,
      "loss": 0.0345,
      "step": 248200
    },
    {
      "epoch": 8.5376336691538,
      "grad_norm": 0.2572190463542938,
      "learning_rate": 2.3329959296653042e-05,
      "loss": 0.0349,
      "step": 248300
    },
    {
      "epoch": 8.54107210397827,
      "grad_norm": 0.14085380733013153,
      "learning_rate": 2.331921395690689e-05,
      "loss": 0.0354,
      "step": 248400
    },
    {
      "epoch": 8.544510538802736,
      "grad_norm": 0.11323238909244537,
      "learning_rate": 2.330846861716074e-05,
      "loss": 0.0343,
      "step": 248500
    },
    {
      "epoch": 8.547948973627205,
      "grad_norm": 0.3704720437526703,
      "learning_rate": 2.3297723277414588e-05,
      "loss": 0.0353,
      "step": 248600
    },
    {
      "epoch": 8.551387408451673,
      "grad_norm": 0.22922292351722717,
      "learning_rate": 2.3286977937668433e-05,
      "loss": 0.0309,
      "step": 248700
    },
    {
      "epoch": 8.554825843276141,
      "grad_norm": 0.7922685146331787,
      "learning_rate": 2.3276340051319746e-05,
      "loss": 0.0353,
      "step": 248800
    },
    {
      "epoch": 8.558264278100609,
      "grad_norm": 0.3971424996852875,
      "learning_rate": 2.3265594711573592e-05,
      "loss": 0.0339,
      "step": 248900
    },
    {
      "epoch": 8.561702712925076,
      "grad_norm": 0.10775376856327057,
      "learning_rate": 2.325484937182744e-05,
      "loss": 0.035,
      "step": 249000
    },
    {
      "epoch": 8.565141147749545,
      "grad_norm": 0.11691530793905258,
      "learning_rate": 2.324410403208129e-05,
      "loss": 0.0341,
      "step": 249100
    },
    {
      "epoch": 8.568579582574012,
      "grad_norm": 0.2579141855239868,
      "learning_rate": 2.3233358692335134e-05,
      "loss": 0.0336,
      "step": 249200
    },
    {
      "epoch": 8.57201801739848,
      "grad_norm": 0.19046367704868317,
      "learning_rate": 2.3222613352588983e-05,
      "loss": 0.0317,
      "step": 249300
    },
    {
      "epoch": 8.575456452222948,
      "grad_norm": 0.10278398543596268,
      "learning_rate": 2.3211868012842832e-05,
      "loss": 0.03,
      "step": 249400
    },
    {
      "epoch": 8.578894887047415,
      "grad_norm": 0.3618339002132416,
      "learning_rate": 2.3201122673096677e-05,
      "loss": 0.0337,
      "step": 249500
    },
    {
      "epoch": 8.582333321871884,
      "grad_norm": 0.13866446912288666,
      "learning_rate": 2.3190377333350526e-05,
      "loss": 0.0307,
      "step": 249600
    },
    {
      "epoch": 8.585771756696351,
      "grad_norm": 0.32714155316352844,
      "learning_rate": 2.3179631993604374e-05,
      "loss": 0.0363,
      "step": 249700
    },
    {
      "epoch": 8.58921019152082,
      "grad_norm": 0.19713149964809418,
      "learning_rate": 2.3168886653858223e-05,
      "loss": 0.0324,
      "step": 249800
    },
    {
      "epoch": 8.592648626345287,
      "grad_norm": 0.07381340861320496,
      "learning_rate": 2.315814131411207e-05,
      "loss": 0.0341,
      "step": 249900
    },
    {
      "epoch": 8.596087061169756,
      "grad_norm": 0.2868513762950897,
      "learning_rate": 2.3147395974365917e-05,
      "loss": 0.0358,
      "step": 250000
    },
    {
      "epoch": 8.599525495994223,
      "grad_norm": 0.31700581312179565,
      "learning_rate": 2.3136650634619766e-05,
      "loss": 0.0362,
      "step": 250100
    },
    {
      "epoch": 8.602963930818692,
      "grad_norm": 0.0857061892747879,
      "learning_rate": 2.3125905294873614e-05,
      "loss": 0.0333,
      "step": 250200
    },
    {
      "epoch": 8.60640236564316,
      "grad_norm": 0.35038918256759644,
      "learning_rate": 2.3115159955127463e-05,
      "loss": 0.0349,
      "step": 250300
    },
    {
      "epoch": 8.609840800467627,
      "grad_norm": 0.1592058539390564,
      "learning_rate": 2.310441461538131e-05,
      "loss": 0.0348,
      "step": 250400
    },
    {
      "epoch": 8.613279235292095,
      "grad_norm": 0.27736568450927734,
      "learning_rate": 2.3093669275635157e-05,
      "loss": 0.0323,
      "step": 250500
    },
    {
      "epoch": 8.616717670116563,
      "grad_norm": 0.23790954053401947,
      "learning_rate": 2.3082923935889006e-05,
      "loss": 0.0354,
      "step": 250600
    },
    {
      "epoch": 8.620156104941032,
      "grad_norm": 0.1549578458070755,
      "learning_rate": 2.3072178596142854e-05,
      "loss": 0.0331,
      "step": 250700
    },
    {
      "epoch": 8.623594539765499,
      "grad_norm": 0.21103833615779877,
      "learning_rate": 2.3061433256396703e-05,
      "loss": 0.0331,
      "step": 250800
    },
    {
      "epoch": 8.627032974589966,
      "grad_norm": 0.09805741906166077,
      "learning_rate": 2.305068791665055e-05,
      "loss": 0.032,
      "step": 250900
    },
    {
      "epoch": 8.630471409414435,
      "grad_norm": 0.15072456002235413,
      "learning_rate": 2.3039942576904397e-05,
      "loss": 0.0312,
      "step": 251000
    },
    {
      "epoch": 8.633909844238902,
      "grad_norm": 0.9458972215652466,
      "learning_rate": 2.3029197237158246e-05,
      "loss": 0.0346,
      "step": 251100
    },
    {
      "epoch": 8.63734827906337,
      "grad_norm": 0.27405908703804016,
      "learning_rate": 2.3018451897412094e-05,
      "loss": 0.0318,
      "step": 251200
    },
    {
      "epoch": 8.640786713887838,
      "grad_norm": 0.0917491689324379,
      "learning_rate": 2.3007706557665943e-05,
      "loss": 0.0367,
      "step": 251300
    },
    {
      "epoch": 8.644225148712307,
      "grad_norm": 0.6889162063598633,
      "learning_rate": 2.299696121791979e-05,
      "loss": 0.0345,
      "step": 251400
    },
    {
      "epoch": 8.647663583536774,
      "grad_norm": 0.29281049966812134,
      "learning_rate": 2.2986215878173637e-05,
      "loss": 0.036,
      "step": 251500
    },
    {
      "epoch": 8.651102018361241,
      "grad_norm": 0.07175975292921066,
      "learning_rate": 2.2975470538427486e-05,
      "loss": 0.0365,
      "step": 251600
    },
    {
      "epoch": 8.65454045318571,
      "grad_norm": 0.354957640171051,
      "learning_rate": 2.2964725198681335e-05,
      "loss": 0.0335,
      "step": 251700
    },
    {
      "epoch": 8.657978888010177,
      "grad_norm": 0.25247034430503845,
      "learning_rate": 2.295408731233264e-05,
      "loss": 0.0332,
      "step": 251800
    },
    {
      "epoch": 8.661417322834646,
      "grad_norm": 0.1158621534705162,
      "learning_rate": 2.294334197258649e-05,
      "loss": 0.0365,
      "step": 251900
    },
    {
      "epoch": 8.664855757659113,
      "grad_norm": 0.1797620803117752,
      "learning_rate": 2.2932596632840338e-05,
      "loss": 0.0348,
      "step": 252000
    },
    {
      "epoch": 8.668294192483582,
      "grad_norm": 0.2885822355747223,
      "learning_rate": 2.2921851293094183e-05,
      "loss": 0.033,
      "step": 252100
    },
    {
      "epoch": 8.67173262730805,
      "grad_norm": 0.17630504071712494,
      "learning_rate": 2.2911105953348032e-05,
      "loss": 0.0331,
      "step": 252200
    },
    {
      "epoch": 8.675171062132517,
      "grad_norm": 0.1165885180234909,
      "learning_rate": 2.290036061360188e-05,
      "loss": 0.0331,
      "step": 252300
    },
    {
      "epoch": 8.678609496956986,
      "grad_norm": 0.28222158551216125,
      "learning_rate": 2.288961527385573e-05,
      "loss": 0.0308,
      "step": 252400
    },
    {
      "epoch": 8.682047931781453,
      "grad_norm": 0.3473457396030426,
      "learning_rate": 2.2878869934109578e-05,
      "loss": 0.0351,
      "step": 252500
    },
    {
      "epoch": 8.685486366605922,
      "grad_norm": 0.24129895865917206,
      "learning_rate": 2.2868124594363427e-05,
      "loss": 0.0374,
      "step": 252600
    },
    {
      "epoch": 8.688924801430389,
      "grad_norm": 0.06825662404298782,
      "learning_rate": 2.2857379254617272e-05,
      "loss": 0.0338,
      "step": 252700
    },
    {
      "epoch": 8.692363236254856,
      "grad_norm": 0.18851885199546814,
      "learning_rate": 2.284663391487112e-05,
      "loss": 0.0298,
      "step": 252800
    },
    {
      "epoch": 8.695801671079325,
      "grad_norm": 0.16254021227359772,
      "learning_rate": 2.283588857512497e-05,
      "loss": 0.0376,
      "step": 252900
    },
    {
      "epoch": 8.699240105903792,
      "grad_norm": 0.08897607028484344,
      "learning_rate": 2.2825143235378818e-05,
      "loss": 0.034,
      "step": 253000
    },
    {
      "epoch": 8.702678540728261,
      "grad_norm": 0.30327630043029785,
      "learning_rate": 2.2814397895632667e-05,
      "loss": 0.033,
      "step": 253100
    },
    {
      "epoch": 8.706116975552728,
      "grad_norm": 0.1313667595386505,
      "learning_rate": 2.2803652555886512e-05,
      "loss": 0.0343,
      "step": 253200
    },
    {
      "epoch": 8.709555410377197,
      "grad_norm": 0.26741987466812134,
      "learning_rate": 2.279290721614036e-05,
      "loss": 0.0335,
      "step": 253300
    },
    {
      "epoch": 8.712993845201664,
      "grad_norm": 0.11840144544839859,
      "learning_rate": 2.278216187639421e-05,
      "loss": 0.0341,
      "step": 253400
    },
    {
      "epoch": 8.716432280026131,
      "grad_norm": 0.08182767778635025,
      "learning_rate": 2.2771416536648058e-05,
      "loss": 0.0347,
      "step": 253500
    },
    {
      "epoch": 8.7198707148506,
      "grad_norm": 0.13614924252033234,
      "learning_rate": 2.2760671196901907e-05,
      "loss": 0.0323,
      "step": 253600
    },
    {
      "epoch": 8.723309149675067,
      "grad_norm": 0.07002589106559753,
      "learning_rate": 2.2749925857155752e-05,
      "loss": 0.0355,
      "step": 253700
    },
    {
      "epoch": 8.726747584499536,
      "grad_norm": 0.08942387998104095,
      "learning_rate": 2.27391805174096e-05,
      "loss": 0.0364,
      "step": 253800
    },
    {
      "epoch": 8.730186019324004,
      "grad_norm": 0.2051296830177307,
      "learning_rate": 2.272843517766345e-05,
      "loss": 0.0368,
      "step": 253900
    },
    {
      "epoch": 8.733624454148472,
      "grad_norm": 0.09172456711530685,
      "learning_rate": 2.2717689837917298e-05,
      "loss": 0.037,
      "step": 254000
    },
    {
      "epoch": 8.73706288897294,
      "grad_norm": 0.1836349368095398,
      "learning_rate": 2.2706944498171147e-05,
      "loss": 0.0342,
      "step": 254100
    },
    {
      "epoch": 8.740501323797407,
      "grad_norm": 0.20840206742286682,
      "learning_rate": 2.2696199158424992e-05,
      "loss": 0.0358,
      "step": 254200
    },
    {
      "epoch": 8.743939758621876,
      "grad_norm": 0.25704896450042725,
      "learning_rate": 2.268545381867884e-05,
      "loss": 0.0329,
      "step": 254300
    },
    {
      "epoch": 8.747378193446343,
      "grad_norm": 0.47014671564102173,
      "learning_rate": 2.267470847893269e-05,
      "loss": 0.0344,
      "step": 254400
    },
    {
      "epoch": 8.750816628270812,
      "grad_norm": 0.08031222969293594,
      "learning_rate": 2.2663963139186535e-05,
      "loss": 0.0379,
      "step": 254500
    },
    {
      "epoch": 8.754255063095279,
      "grad_norm": 0.43769994378089905,
      "learning_rate": 2.2653217799440384e-05,
      "loss": 0.0309,
      "step": 254600
    },
    {
      "epoch": 8.757693497919746,
      "grad_norm": 0.1678851991891861,
      "learning_rate": 2.2642472459694232e-05,
      "loss": 0.0323,
      "step": 254700
    },
    {
      "epoch": 8.761131932744215,
      "grad_norm": 0.47835350036621094,
      "learning_rate": 2.2631727119948078e-05,
      "loss": 0.0365,
      "step": 254800
    },
    {
      "epoch": 8.764570367568682,
      "grad_norm": 0.27369725704193115,
      "learning_rate": 2.2620981780201926e-05,
      "loss": 0.032,
      "step": 254900
    },
    {
      "epoch": 8.768008802393151,
      "grad_norm": 0.40308690071105957,
      "learning_rate": 2.2610236440455775e-05,
      "loss": 0.0358,
      "step": 255000
    },
    {
      "epoch": 8.771447237217618,
      "grad_norm": 0.19704462587833405,
      "learning_rate": 2.2599491100709624e-05,
      "loss": 0.0321,
      "step": 255100
    },
    {
      "epoch": 8.774885672042087,
      "grad_norm": 0.34575533866882324,
      "learning_rate": 2.258874576096347e-05,
      "loss": 0.0336,
      "step": 255200
    },
    {
      "epoch": 8.778324106866554,
      "grad_norm": 0.39153024554252625,
      "learning_rate": 2.2578000421217318e-05,
      "loss": 0.036,
      "step": 255300
    },
    {
      "epoch": 8.781762541691021,
      "grad_norm": 0.16199105978012085,
      "learning_rate": 2.2567255081471166e-05,
      "loss": 0.0335,
      "step": 255400
    },
    {
      "epoch": 8.78520097651549,
      "grad_norm": 0.26369422674179077,
      "learning_rate": 2.2556509741725015e-05,
      "loss": 0.0295,
      "step": 255500
    },
    {
      "epoch": 8.788639411339958,
      "grad_norm": 0.1462240368127823,
      "learning_rate": 2.2545764401978864e-05,
      "loss": 0.0335,
      "step": 255600
    },
    {
      "epoch": 8.792077846164426,
      "grad_norm": 0.15397784113883972,
      "learning_rate": 2.253501906223271e-05,
      "loss": 0.0324,
      "step": 255700
    },
    {
      "epoch": 8.795516280988894,
      "grad_norm": 0.18261921405792236,
      "learning_rate": 2.2524381175884022e-05,
      "loss": 0.0351,
      "step": 255800
    },
    {
      "epoch": 8.798954715813363,
      "grad_norm": 0.3938016891479492,
      "learning_rate": 2.2513635836137867e-05,
      "loss": 0.0343,
      "step": 255900
    },
    {
      "epoch": 8.80239315063783,
      "grad_norm": 0.32264572381973267,
      "learning_rate": 2.2502890496391716e-05,
      "loss": 0.0318,
      "step": 256000
    },
    {
      "epoch": 8.805831585462297,
      "grad_norm": 0.12327903509140015,
      "learning_rate": 2.2492252610043025e-05,
      "loss": 0.0371,
      "step": 256100
    },
    {
      "epoch": 8.809270020286766,
      "grad_norm": 0.4314582347869873,
      "learning_rate": 2.2481507270296874e-05,
      "loss": 0.0336,
      "step": 256200
    },
    {
      "epoch": 8.812708455111233,
      "grad_norm": 0.22356931865215302,
      "learning_rate": 2.247076193055072e-05,
      "loss": 0.032,
      "step": 256300
    },
    {
      "epoch": 8.816146889935702,
      "grad_norm": 0.14176228642463684,
      "learning_rate": 2.2460016590804568e-05,
      "loss": 0.0368,
      "step": 256400
    },
    {
      "epoch": 8.819585324760169,
      "grad_norm": 0.4360842704772949,
      "learning_rate": 2.2449271251058417e-05,
      "loss": 0.0311,
      "step": 256500
    },
    {
      "epoch": 8.823023759584636,
      "grad_norm": 0.09479118138551712,
      "learning_rate": 2.2438525911312262e-05,
      "loss": 0.0342,
      "step": 256600
    },
    {
      "epoch": 8.826462194409105,
      "grad_norm": 0.22585809230804443,
      "learning_rate": 2.242778057156611e-05,
      "loss": 0.0381,
      "step": 256700
    },
    {
      "epoch": 8.829900629233572,
      "grad_norm": 0.25603702664375305,
      "learning_rate": 2.241703523181996e-05,
      "loss": 0.0336,
      "step": 256800
    },
    {
      "epoch": 8.833339064058041,
      "grad_norm": 0.3123306632041931,
      "learning_rate": 2.240639734547127e-05,
      "loss": 0.0328,
      "step": 256900
    },
    {
      "epoch": 8.836777498882508,
      "grad_norm": 0.2149614691734314,
      "learning_rate": 2.2395652005725118e-05,
      "loss": 0.0325,
      "step": 257000
    },
    {
      "epoch": 8.840215933706977,
      "grad_norm": 0.3701801002025604,
      "learning_rate": 2.2384906665978966e-05,
      "loss": 0.0348,
      "step": 257100
    },
    {
      "epoch": 8.843654368531444,
      "grad_norm": 0.12644782662391663,
      "learning_rate": 2.2374161326232815e-05,
      "loss": 0.0338,
      "step": 257200
    },
    {
      "epoch": 8.847092803355913,
      "grad_norm": 0.2798102796077728,
      "learning_rate": 2.236341598648666e-05,
      "loss": 0.0321,
      "step": 257300
    },
    {
      "epoch": 8.85053123818038,
      "grad_norm": 0.21036775410175323,
      "learning_rate": 2.2352778100137973e-05,
      "loss": 0.031,
      "step": 257400
    },
    {
      "epoch": 8.853969673004848,
      "grad_norm": 0.24456505477428436,
      "learning_rate": 2.234203276039182e-05,
      "loss": 0.0356,
      "step": 257500
    },
    {
      "epoch": 8.857408107829317,
      "grad_norm": 0.13814567029476166,
      "learning_rate": 2.2331287420645667e-05,
      "loss": 0.0311,
      "step": 257600
    },
    {
      "epoch": 8.860846542653784,
      "grad_norm": 0.14184273779392242,
      "learning_rate": 2.2320542080899516e-05,
      "loss": 0.0337,
      "step": 257700
    },
    {
      "epoch": 8.864284977478253,
      "grad_norm": 0.2184218019247055,
      "learning_rate": 2.2309796741153365e-05,
      "loss": 0.0338,
      "step": 257800
    },
    {
      "epoch": 8.86772341230272,
      "grad_norm": 0.11363431811332703,
      "learning_rate": 2.229905140140721e-05,
      "loss": 0.0356,
      "step": 257900
    },
    {
      "epoch": 8.871161847127187,
      "grad_norm": 0.12201236933469772,
      "learning_rate": 2.228830606166106e-05,
      "loss": 0.0329,
      "step": 258000
    },
    {
      "epoch": 8.874600281951656,
      "grad_norm": 0.6598061919212341,
      "learning_rate": 2.2277560721914904e-05,
      "loss": 0.0341,
      "step": 258100
    },
    {
      "epoch": 8.878038716776123,
      "grad_norm": 0.19542542099952698,
      "learning_rate": 2.2266815382168753e-05,
      "loss": 0.0342,
      "step": 258200
    },
    {
      "epoch": 8.881477151600592,
      "grad_norm": 0.565388023853302,
      "learning_rate": 2.22560700424226e-05,
      "loss": 0.0337,
      "step": 258300
    },
    {
      "epoch": 8.884915586425059,
      "grad_norm": 0.15599170327186584,
      "learning_rate": 2.224532470267645e-05,
      "loss": 0.0324,
      "step": 258400
    },
    {
      "epoch": 8.888354021249528,
      "grad_norm": 0.18238656222820282,
      "learning_rate": 2.22345793629303e-05,
      "loss": 0.0353,
      "step": 258500
    },
    {
      "epoch": 8.891792456073995,
      "grad_norm": 0.8177408576011658,
      "learning_rate": 2.2223834023184144e-05,
      "loss": 0.0336,
      "step": 258600
    },
    {
      "epoch": 8.895230890898462,
      "grad_norm": 0.20426365733146667,
      "learning_rate": 2.2213088683437993e-05,
      "loss": 0.0315,
      "step": 258700
    },
    {
      "epoch": 8.898669325722931,
      "grad_norm": 0.24402830004692078,
      "learning_rate": 2.220234334369184e-05,
      "loss": 0.035,
      "step": 258800
    },
    {
      "epoch": 8.902107760547398,
      "grad_norm": 0.1835523247718811,
      "learning_rate": 2.219159800394569e-05,
      "loss": 0.0359,
      "step": 258900
    },
    {
      "epoch": 8.905546195371867,
      "grad_norm": 0.7784878611564636,
      "learning_rate": 2.218085266419954e-05,
      "loss": 0.0353,
      "step": 259000
    },
    {
      "epoch": 8.908984630196334,
      "grad_norm": 0.199868306517601,
      "learning_rate": 2.2170107324453384e-05,
      "loss": 0.0359,
      "step": 259100
    },
    {
      "epoch": 8.912423065020803,
      "grad_norm": 0.24103164672851562,
      "learning_rate": 2.2159361984707233e-05,
      "loss": 0.0338,
      "step": 259200
    },
    {
      "epoch": 8.91586149984527,
      "grad_norm": 0.14470893144607544,
      "learning_rate": 2.214861664496108e-05,
      "loss": 0.0325,
      "step": 259300
    },
    {
      "epoch": 8.919299934669738,
      "grad_norm": 0.28525254130363464,
      "learning_rate": 2.213787130521493e-05,
      "loss": 0.0384,
      "step": 259400
    },
    {
      "epoch": 8.922738369494207,
      "grad_norm": 0.12104809284210205,
      "learning_rate": 2.212712596546878e-05,
      "loss": 0.034,
      "step": 259500
    },
    {
      "epoch": 8.926176804318674,
      "grad_norm": 0.26246437430381775,
      "learning_rate": 2.2116380625722624e-05,
      "loss": 0.0317,
      "step": 259600
    },
    {
      "epoch": 8.929615239143143,
      "grad_norm": 0.0987691581249237,
      "learning_rate": 2.2105635285976473e-05,
      "loss": 0.0302,
      "step": 259700
    },
    {
      "epoch": 8.93305367396761,
      "grad_norm": 0.1837248057126999,
      "learning_rate": 2.209488994623032e-05,
      "loss": 0.0359,
      "step": 259800
    },
    {
      "epoch": 8.936492108792077,
      "grad_norm": 0.07823298126459122,
      "learning_rate": 2.208414460648417e-05,
      "loss": 0.0313,
      "step": 259900
    },
    {
      "epoch": 8.939930543616546,
      "grad_norm": 0.13678835332393646,
      "learning_rate": 2.207339926673802e-05,
      "loss": 0.0347,
      "step": 260000
    },
    {
      "epoch": 8.943368978441013,
      "grad_norm": 0.21085508167743683,
      "learning_rate": 2.2062653926991864e-05,
      "loss": 0.0329,
      "step": 260100
    },
    {
      "epoch": 8.946807413265482,
      "grad_norm": 0.17816853523254395,
      "learning_rate": 2.2051908587245713e-05,
      "loss": 0.0347,
      "step": 260200
    },
    {
      "epoch": 8.95024584808995,
      "grad_norm": 0.1449294537305832,
      "learning_rate": 2.204116324749956e-05,
      "loss": 0.0379,
      "step": 260300
    },
    {
      "epoch": 8.953684282914418,
      "grad_norm": 0.1014479324221611,
      "learning_rate": 2.203041790775341e-05,
      "loss": 0.0342,
      "step": 260400
    },
    {
      "epoch": 8.957122717738885,
      "grad_norm": 0.27761104702949524,
      "learning_rate": 2.201967256800726e-05,
      "loss": 0.0339,
      "step": 260500
    },
    {
      "epoch": 8.960561152563352,
      "grad_norm": 0.1326829344034195,
      "learning_rate": 2.2008927228261104e-05,
      "loss": 0.0322,
      "step": 260600
    },
    {
      "epoch": 8.963999587387821,
      "grad_norm": 0.1027911975979805,
      "learning_rate": 2.1998181888514953e-05,
      "loss": 0.0347,
      "step": 260700
    },
    {
      "epoch": 8.967438022212288,
      "grad_norm": 0.34887227416038513,
      "learning_rate": 2.19874365487688e-05,
      "loss": 0.0349,
      "step": 260800
    },
    {
      "epoch": 8.970876457036757,
      "grad_norm": 0.08635324239730835,
      "learning_rate": 2.1976691209022647e-05,
      "loss": 0.0352,
      "step": 260900
    },
    {
      "epoch": 8.974314891861225,
      "grad_norm": 0.46776220202445984,
      "learning_rate": 2.1965945869276496e-05,
      "loss": 0.0367,
      "step": 261000
    },
    {
      "epoch": 8.977753326685693,
      "grad_norm": 0.5272945165634155,
      "learning_rate": 2.195520052953034e-05,
      "loss": 0.0349,
      "step": 261100
    },
    {
      "epoch": 8.98119176151016,
      "grad_norm": 0.19370914995670319,
      "learning_rate": 2.194445518978419e-05,
      "loss": 0.0325,
      "step": 261200
    },
    {
      "epoch": 8.984630196334628,
      "grad_norm": 0.3220105469226837,
      "learning_rate": 2.1933709850038038e-05,
      "loss": 0.0311,
      "step": 261300
    },
    {
      "epoch": 8.988068631159097,
      "grad_norm": 0.21113380789756775,
      "learning_rate": 2.1922964510291887e-05,
      "loss": 0.0326,
      "step": 261400
    },
    {
      "epoch": 8.991507065983564,
      "grad_norm": 0.162026047706604,
      "learning_rate": 2.1912219170545736e-05,
      "loss": 0.0321,
      "step": 261500
    },
    {
      "epoch": 8.994945500808033,
      "grad_norm": 0.20535805821418762,
      "learning_rate": 2.190147383079958e-05,
      "loss": 0.0366,
      "step": 261600
    },
    {
      "epoch": 8.9983839356325,
      "grad_norm": 0.3854055404663086,
      "learning_rate": 2.189072849105343e-05,
      "loss": 0.0335,
      "step": 261700
    },
    {
      "epoch": 9.0,
      "eval_accuracy_macro_0.5": 0.9854564666748047,
      "eval_accuracy_micro_0.5": 0.9854564666748047,
      "eval_accuracy_weighted_0.5": 0.9762376546859741,
      "eval_aucroc_macro": 0.9242976307868958,
      "eval_aucroc_micro": 0.9263545274734497,
      "eval_aucroc_weighted": 0.9234532713890076,
      "eval_f1_macro_0.5": 0.783000111579895,
      "eval_f1_macro_0.6": 0.7736618518829346,
      "eval_f1_macro_0.7": 0.7519335746765137,
      "eval_f1_macro_0.8": 0.6176136136054993,
      "eval_f1_micro_0.5": 0.7910935282707214,
      "eval_f1_micro_0.6": 0.7828408479690552,
      "eval_f1_micro_0.7": 0.7630507946014404,
      "eval_f1_micro_0.8": 0.7237353920936584,
      "eval_f1_micro_0.9": 0.6349663734436035,
      "eval_f1_weighted_0.5": 0.7870585322380066,
      "eval_f1_weighted_0.6": 0.775387167930603,
      "eval_f1_weighted_0.7": 0.7507292628288269,
      "eval_f1_weighted_0.8": 0.6011016368865967,
      "eval_loss": 0.0318216048181057,
      "eval_runtime": 2104.5454,
      "eval_samples_per_second": 27.622,
      "eval_steps_per_second": 3.453,
      "step": 261747
    },
    {
      "epoch": 9.001822370456969,
      "grad_norm": 0.1757168471813202,
      "learning_rate": 2.1879983151307278e-05,
      "loss": 0.0344,
      "step": 261800
    },
    {
      "epoch": 9.005260805281436,
      "grad_norm": 0.09230261296033859,
      "learning_rate": 2.1869237811561127e-05,
      "loss": 0.0347,
      "step": 261900
    },
    {
      "epoch": 9.008699240105903,
      "grad_norm": 0.11866527795791626,
      "learning_rate": 2.1858492471814976e-05,
      "loss": 0.0316,
      "step": 262000
    },
    {
      "epoch": 9.012137674930372,
      "grad_norm": 0.11591017991304398,
      "learning_rate": 2.184774713206882e-05,
      "loss": 0.0322,
      "step": 262100
    },
    {
      "epoch": 9.01557610975484,
      "grad_norm": 0.13154484331607819,
      "learning_rate": 2.183700179232267e-05,
      "loss": 0.0356,
      "step": 262200
    },
    {
      "epoch": 9.019014544579308,
      "grad_norm": 0.10547599196434021,
      "learning_rate": 2.1826256452576518e-05,
      "loss": 0.0333,
      "step": 262300
    },
    {
      "epoch": 9.022452979403775,
      "grad_norm": 0.18447257578372955,
      "learning_rate": 2.1815511112830367e-05,
      "loss": 0.0329,
      "step": 262400
    },
    {
      "epoch": 9.025891414228242,
      "grad_norm": 0.018141698092222214,
      "learning_rate": 2.1804765773084216e-05,
      "loss": 0.032,
      "step": 262500
    },
    {
      "epoch": 9.029329849052711,
      "grad_norm": 0.04764464125037193,
      "learning_rate": 2.179402043333806e-05,
      "loss": 0.0337,
      "step": 262600
    },
    {
      "epoch": 9.032768283877179,
      "grad_norm": 0.12545275688171387,
      "learning_rate": 2.178327509359191e-05,
      "loss": 0.0326,
      "step": 262700
    },
    {
      "epoch": 9.036206718701647,
      "grad_norm": 0.19952328503131866,
      "learning_rate": 2.177252975384576e-05,
      "loss": 0.0347,
      "step": 262800
    },
    {
      "epoch": 9.039645153526115,
      "grad_norm": 0.11491231620311737,
      "learning_rate": 2.1761784414099607e-05,
      "loss": 0.0341,
      "step": 262900
    },
    {
      "epoch": 9.043083588350584,
      "grad_norm": 0.29721343517303467,
      "learning_rate": 2.1751039074353456e-05,
      "loss": 0.0317,
      "step": 263000
    },
    {
      "epoch": 9.04652202317505,
      "grad_norm": 0.17785820364952087,
      "learning_rate": 2.1740293734607304e-05,
      "loss": 0.037,
      "step": 263100
    },
    {
      "epoch": 9.049960457999518,
      "grad_norm": 0.04392829164862633,
      "learning_rate": 2.172954839486115e-05,
      "loss": 0.0358,
      "step": 263200
    },
    {
      "epoch": 9.053398892823987,
      "grad_norm": 0.041267409920692444,
      "learning_rate": 2.1718803055115e-05,
      "loss": 0.0298,
      "step": 263300
    },
    {
      "epoch": 9.056837327648454,
      "grad_norm": 0.057765014469623566,
      "learning_rate": 2.1708057715368847e-05,
      "loss": 0.0315,
      "step": 263400
    },
    {
      "epoch": 9.060275762472923,
      "grad_norm": 0.19712300598621368,
      "learning_rate": 2.1697312375622696e-05,
      "loss": 0.032,
      "step": 263500
    },
    {
      "epoch": 9.06371419729739,
      "grad_norm": 0.07614599168300629,
      "learning_rate": 2.168656703587654e-05,
      "loss": 0.0364,
      "step": 263600
    },
    {
      "epoch": 9.067152632121859,
      "grad_norm": 0.2944776117801666,
      "learning_rate": 2.167582169613039e-05,
      "loss": 0.0326,
      "step": 263700
    },
    {
      "epoch": 9.070591066946326,
      "grad_norm": 0.18280309438705444,
      "learning_rate": 2.166507635638424e-05,
      "loss": 0.0323,
      "step": 263800
    },
    {
      "epoch": 9.074029501770793,
      "grad_norm": 0.0596681647002697,
      "learning_rate": 2.1654331016638084e-05,
      "loss": 0.0328,
      "step": 263900
    },
    {
      "epoch": 9.077467936595262,
      "grad_norm": 0.18744367361068726,
      "learning_rate": 2.1643585676891932e-05,
      "loss": 0.0327,
      "step": 264000
    },
    {
      "epoch": 9.08090637141973,
      "grad_norm": 0.07528029382228851,
      "learning_rate": 2.163284033714578e-05,
      "loss": 0.0363,
      "step": 264100
    },
    {
      "epoch": 9.084344806244198,
      "grad_norm": 0.08621537685394287,
      "learning_rate": 2.1622094997399626e-05,
      "loss": 0.0289,
      "step": 264200
    },
    {
      "epoch": 9.087783241068665,
      "grad_norm": 0.21384747326374054,
      "learning_rate": 2.1611349657653475e-05,
      "loss": 0.0339,
      "step": 264300
    },
    {
      "epoch": 9.091221675893133,
      "grad_norm": 0.2356335073709488,
      "learning_rate": 2.1600604317907324e-05,
      "loss": 0.0332,
      "step": 264400
    },
    {
      "epoch": 9.094660110717601,
      "grad_norm": 0.08028047531843185,
      "learning_rate": 2.1589966431558633e-05,
      "loss": 0.0332,
      "step": 264500
    },
    {
      "epoch": 9.098098545542069,
      "grad_norm": 0.11385322362184525,
      "learning_rate": 2.1579221091812482e-05,
      "loss": 0.032,
      "step": 264600
    },
    {
      "epoch": 9.101536980366538,
      "grad_norm": 0.21709585189819336,
      "learning_rate": 2.156847575206633e-05,
      "loss": 0.0367,
      "step": 264700
    },
    {
      "epoch": 9.104975415191005,
      "grad_norm": 0.0980013906955719,
      "learning_rate": 2.155773041232018e-05,
      "loss": 0.0323,
      "step": 264800
    },
    {
      "epoch": 9.108413850015474,
      "grad_norm": 0.20639736950397491,
      "learning_rate": 2.1546985072574025e-05,
      "loss": 0.0292,
      "step": 264900
    },
    {
      "epoch": 9.11185228483994,
      "grad_norm": 0.05594344809651375,
      "learning_rate": 2.1536239732827873e-05,
      "loss": 0.0329,
      "step": 265000
    },
    {
      "epoch": 9.115290719664408,
      "grad_norm": 0.16802763938903809,
      "learning_rate": 2.1525494393081722e-05,
      "loss": 0.032,
      "step": 265100
    },
    {
      "epoch": 9.118729154488877,
      "grad_norm": 0.009890588000416756,
      "learning_rate": 2.151474905333557e-05,
      "loss": 0.0329,
      "step": 265200
    },
    {
      "epoch": 9.122167589313344,
      "grad_norm": 0.13654235005378723,
      "learning_rate": 2.150400371358942e-05,
      "loss": 0.034,
      "step": 265300
    },
    {
      "epoch": 9.125606024137813,
      "grad_norm": 0.2154305875301361,
      "learning_rate": 2.1493258373843265e-05,
      "loss": 0.0306,
      "step": 265400
    },
    {
      "epoch": 9.12904445896228,
      "grad_norm": 0.36770498752593994,
      "learning_rate": 2.1482513034097113e-05,
      "loss": 0.0359,
      "step": 265500
    },
    {
      "epoch": 9.132482893786749,
      "grad_norm": 0.07789911329746246,
      "learning_rate": 2.1471767694350962e-05,
      "loss": 0.0326,
      "step": 265600
    },
    {
      "epoch": 9.135921328611216,
      "grad_norm": 0.18458077311515808,
      "learning_rate": 2.146102235460481e-05,
      "loss": 0.0356,
      "step": 265700
    },
    {
      "epoch": 9.139359763435683,
      "grad_norm": 0.070944644510746,
      "learning_rate": 2.145027701485866e-05,
      "loss": 0.0327,
      "step": 265800
    },
    {
      "epoch": 9.142798198260152,
      "grad_norm": 0.3418249785900116,
      "learning_rate": 2.1439531675112505e-05,
      "loss": 0.0332,
      "step": 265900
    },
    {
      "epoch": 9.14623663308462,
      "grad_norm": 0.08902186155319214,
      "learning_rate": 2.1428786335366353e-05,
      "loss": 0.03,
      "step": 266000
    },
    {
      "epoch": 9.149675067909088,
      "grad_norm": 0.1286177933216095,
      "learning_rate": 2.1418040995620202e-05,
      "loss": 0.0337,
      "step": 266100
    },
    {
      "epoch": 9.153113502733556,
      "grad_norm": 0.0459354929625988,
      "learning_rate": 2.1407295655874047e-05,
      "loss": 0.0339,
      "step": 266200
    },
    {
      "epoch": 9.156551937558024,
      "grad_norm": 0.09479016065597534,
      "learning_rate": 2.1396550316127896e-05,
      "loss": 0.0353,
      "step": 266300
    },
    {
      "epoch": 9.159990372382492,
      "grad_norm": 0.18585047125816345,
      "learning_rate": 2.1385804976381745e-05,
      "loss": 0.0351,
      "step": 266400
    },
    {
      "epoch": 9.163428807206959,
      "grad_norm": 0.07124295085668564,
      "learning_rate": 2.137505963663559e-05,
      "loss": 0.0347,
      "step": 266500
    },
    {
      "epoch": 9.166867242031428,
      "grad_norm": 0.14573577046394348,
      "learning_rate": 2.136431429688944e-05,
      "loss": 0.037,
      "step": 266600
    },
    {
      "epoch": 9.170305676855895,
      "grad_norm": 0.08289884030818939,
      "learning_rate": 2.1353568957143287e-05,
      "loss": 0.0367,
      "step": 266700
    },
    {
      "epoch": 9.173744111680364,
      "grad_norm": 0.06288573890924454,
      "learning_rate": 2.1342823617397136e-05,
      "loss": 0.0321,
      "step": 266800
    },
    {
      "epoch": 9.177182546504831,
      "grad_norm": 0.363621324300766,
      "learning_rate": 2.133207827765098e-05,
      "loss": 0.0352,
      "step": 266900
    },
    {
      "epoch": 9.180620981329298,
      "grad_norm": 0.16946300864219666,
      "learning_rate": 2.132133293790483e-05,
      "loss": 0.0369,
      "step": 267000
    },
    {
      "epoch": 9.184059416153767,
      "grad_norm": 0.21550464630126953,
      "learning_rate": 2.131058759815868e-05,
      "loss": 0.0367,
      "step": 267100
    },
    {
      "epoch": 9.187497850978234,
      "grad_norm": 0.06881736218929291,
      "learning_rate": 2.1299842258412527e-05,
      "loss": 0.0295,
      "step": 267200
    },
    {
      "epoch": 9.190936285802703,
      "grad_norm": 0.13007335364818573,
      "learning_rate": 2.1289096918666376e-05,
      "loss": 0.0309,
      "step": 267300
    },
    {
      "epoch": 9.19437472062717,
      "grad_norm": 0.10720428079366684,
      "learning_rate": 2.127835157892022e-05,
      "loss": 0.0344,
      "step": 267400
    },
    {
      "epoch": 9.19781315545164,
      "grad_norm": 0.08207864314317703,
      "learning_rate": 2.1267713692571534e-05,
      "loss": 0.032,
      "step": 267500
    },
    {
      "epoch": 9.201251590276106,
      "grad_norm": 0.17115169763565063,
      "learning_rate": 2.125696835282538e-05,
      "loss": 0.0335,
      "step": 267600
    },
    {
      "epoch": 9.204690025100573,
      "grad_norm": 0.08886079490184784,
      "learning_rate": 2.124622301307923e-05,
      "loss": 0.0324,
      "step": 267700
    },
    {
      "epoch": 9.208128459925042,
      "grad_norm": 0.05893422290682793,
      "learning_rate": 2.1235477673333077e-05,
      "loss": 0.0325,
      "step": 267800
    },
    {
      "epoch": 9.21156689474951,
      "grad_norm": 0.09072431176900864,
      "learning_rate": 2.1224732333586926e-05,
      "loss": 0.0344,
      "step": 267900
    },
    {
      "epoch": 9.215005329573978,
      "grad_norm": 0.04123075306415558,
      "learning_rate": 2.1213986993840774e-05,
      "loss": 0.0361,
      "step": 268000
    },
    {
      "epoch": 9.218443764398446,
      "grad_norm": 0.3367501199245453,
      "learning_rate": 2.120324165409462e-05,
      "loss": 0.0314,
      "step": 268100
    },
    {
      "epoch": 9.221882199222915,
      "grad_norm": 0.1299559772014618,
      "learning_rate": 2.119249631434847e-05,
      "loss": 0.0316,
      "step": 268200
    },
    {
      "epoch": 9.225320634047382,
      "grad_norm": 0.14439348876476288,
      "learning_rate": 2.1181750974602317e-05,
      "loss": 0.0339,
      "step": 268300
    },
    {
      "epoch": 9.228759068871849,
      "grad_norm": 0.17153556644916534,
      "learning_rate": 2.1171005634856166e-05,
      "loss": 0.0316,
      "step": 268400
    },
    {
      "epoch": 9.232197503696318,
      "grad_norm": 0.036332231014966965,
      "learning_rate": 2.116026029511001e-05,
      "loss": 0.035,
      "step": 268500
    },
    {
      "epoch": 9.235635938520785,
      "grad_norm": 0.3363669216632843,
      "learning_rate": 2.114951495536386e-05,
      "loss": 0.0318,
      "step": 268600
    },
    {
      "epoch": 9.239074373345254,
      "grad_norm": 0.13401931524276733,
      "learning_rate": 2.1138769615617705e-05,
      "loss": 0.0318,
      "step": 268700
    },
    {
      "epoch": 9.242512808169721,
      "grad_norm": 0.03522013500332832,
      "learning_rate": 2.1128024275871554e-05,
      "loss": 0.0337,
      "step": 268800
    },
    {
      "epoch": 9.24595124299419,
      "grad_norm": 0.14914967119693756,
      "learning_rate": 2.1117278936125402e-05,
      "loss": 0.0333,
      "step": 268900
    },
    {
      "epoch": 9.249389677818657,
      "grad_norm": 0.17088943719863892,
      "learning_rate": 2.110653359637925e-05,
      "loss": 0.0335,
      "step": 269000
    },
    {
      "epoch": 9.252828112643124,
      "grad_norm": 0.17724692821502686,
      "learning_rate": 2.10957882566331e-05,
      "loss": 0.0322,
      "step": 269100
    },
    {
      "epoch": 9.256266547467593,
      "grad_norm": 0.03156431391835213,
      "learning_rate": 2.1085042916886945e-05,
      "loss": 0.0327,
      "step": 269200
    },
    {
      "epoch": 9.25970498229206,
      "grad_norm": 0.11540590226650238,
      "learning_rate": 2.1074297577140794e-05,
      "loss": 0.0282,
      "step": 269300
    },
    {
      "epoch": 9.26314341711653,
      "grad_norm": 0.1976332664489746,
      "learning_rate": 2.1063552237394642e-05,
      "loss": 0.0348,
      "step": 269400
    },
    {
      "epoch": 9.266581851940996,
      "grad_norm": 0.09458614885807037,
      "learning_rate": 2.105280689764849e-05,
      "loss": 0.0316,
      "step": 269500
    },
    {
      "epoch": 9.270020286765464,
      "grad_norm": 0.12595941126346588,
      "learning_rate": 2.104206155790234e-05,
      "loss": 0.0312,
      "step": 269600
    },
    {
      "epoch": 9.273458721589932,
      "grad_norm": 0.08134444802999496,
      "learning_rate": 2.1031316218156185e-05,
      "loss": 0.0342,
      "step": 269700
    },
    {
      "epoch": 9.2768971564144,
      "grad_norm": 0.13514560461044312,
      "learning_rate": 2.1020570878410034e-05,
      "loss": 0.0315,
      "step": 269800
    },
    {
      "epoch": 9.280335591238869,
      "grad_norm": 0.08439695090055466,
      "learning_rate": 2.1009825538663882e-05,
      "loss": 0.0314,
      "step": 269900
    },
    {
      "epoch": 9.283774026063336,
      "grad_norm": 0.20711283385753632,
      "learning_rate": 2.099908019891773e-05,
      "loss": 0.028,
      "step": 270000
    },
    {
      "epoch": 9.287212460887805,
      "grad_norm": 0.10490461438894272,
      "learning_rate": 2.098833485917158e-05,
      "loss": 0.032,
      "step": 270100
    },
    {
      "epoch": 9.290650895712272,
      "grad_norm": 0.07844922691583633,
      "learning_rate": 2.0977589519425425e-05,
      "loss": 0.0332,
      "step": 270200
    },
    {
      "epoch": 9.294089330536739,
      "grad_norm": 0.27447283267974854,
      "learning_rate": 2.0966844179679274e-05,
      "loss": 0.0324,
      "step": 270300
    },
    {
      "epoch": 9.297527765361208,
      "grad_norm": 0.04461561143398285,
      "learning_rate": 2.0956098839933123e-05,
      "loss": 0.0332,
      "step": 270400
    },
    {
      "epoch": 9.300966200185675,
      "grad_norm": 0.1327286660671234,
      "learning_rate": 2.094535350018697e-05,
      "loss": 0.0342,
      "step": 270500
    },
    {
      "epoch": 9.304404635010144,
      "grad_norm": 0.4008481204509735,
      "learning_rate": 2.093460816044082e-05,
      "loss": 0.0329,
      "step": 270600
    },
    {
      "epoch": 9.307843069834611,
      "grad_norm": 0.22443832457065582,
      "learning_rate": 2.0923862820694665e-05,
      "loss": 0.0314,
      "step": 270700
    },
    {
      "epoch": 9.31128150465908,
      "grad_norm": 0.15429016947746277,
      "learning_rate": 2.0913117480948514e-05,
      "loss": 0.0328,
      "step": 270800
    },
    {
      "epoch": 9.314719939483547,
      "grad_norm": 0.33361661434173584,
      "learning_rate": 2.0902372141202363e-05,
      "loss": 0.0384,
      "step": 270900
    },
    {
      "epoch": 9.318158374308014,
      "grad_norm": 0.06450589746236801,
      "learning_rate": 2.089162680145621e-05,
      "loss": 0.0326,
      "step": 271000
    },
    {
      "epoch": 9.321596809132483,
      "grad_norm": 0.07712934166193008,
      "learning_rate": 2.0880988915107517e-05,
      "loss": 0.0342,
      "step": 271100
    },
    {
      "epoch": 9.32503524395695,
      "grad_norm": 0.13180246949195862,
      "learning_rate": 2.0870243575361366e-05,
      "loss": 0.0335,
      "step": 271200
    },
    {
      "epoch": 9.32847367878142,
      "grad_norm": 0.13561923801898956,
      "learning_rate": 2.0859498235615215e-05,
      "loss": 0.0303,
      "step": 271300
    },
    {
      "epoch": 9.331912113605886,
      "grad_norm": 0.15219919383525848,
      "learning_rate": 2.084875289586906e-05,
      "loss": 0.034,
      "step": 271400
    },
    {
      "epoch": 9.335350548430355,
      "grad_norm": 0.08347594738006592,
      "learning_rate": 2.083800755612291e-05,
      "loss": 0.0339,
      "step": 271500
    },
    {
      "epoch": 9.338788983254823,
      "grad_norm": 0.207663431763649,
      "learning_rate": 2.0827262216376757e-05,
      "loss": 0.0371,
      "step": 271600
    },
    {
      "epoch": 9.34222741807929,
      "grad_norm": 0.1396818608045578,
      "learning_rate": 2.0816516876630606e-05,
      "loss": 0.031,
      "step": 271700
    },
    {
      "epoch": 9.345665852903759,
      "grad_norm": 0.0829823911190033,
      "learning_rate": 2.0805771536884455e-05,
      "loss": 0.0324,
      "step": 271800
    },
    {
      "epoch": 9.349104287728226,
      "grad_norm": 0.27156925201416016,
      "learning_rate": 2.07950261971383e-05,
      "loss": 0.0342,
      "step": 271900
    },
    {
      "epoch": 9.352542722552695,
      "grad_norm": 0.17032893002033234,
      "learning_rate": 2.078428085739215e-05,
      "loss": 0.0364,
      "step": 272000
    },
    {
      "epoch": 9.355981157377162,
      "grad_norm": 0.18170256912708282,
      "learning_rate": 2.0773535517645998e-05,
      "loss": 0.0346,
      "step": 272100
    },
    {
      "epoch": 9.359419592201629,
      "grad_norm": 0.10580813139677048,
      "learning_rate": 2.0762790177899846e-05,
      "loss": 0.0364,
      "step": 272200
    },
    {
      "epoch": 9.362858027026098,
      "grad_norm": 0.07777788490056992,
      "learning_rate": 2.0752044838153695e-05,
      "loss": 0.0313,
      "step": 272300
    },
    {
      "epoch": 9.366296461850565,
      "grad_norm": 0.07314418256282806,
      "learning_rate": 2.074129949840754e-05,
      "loss": 0.0316,
      "step": 272400
    },
    {
      "epoch": 9.369734896675034,
      "grad_norm": 0.17797674238681793,
      "learning_rate": 2.073055415866139e-05,
      "loss": 0.0349,
      "step": 272500
    },
    {
      "epoch": 9.373173331499501,
      "grad_norm": 0.10305897891521454,
      "learning_rate": 2.0719808818915238e-05,
      "loss": 0.0334,
      "step": 272600
    },
    {
      "epoch": 9.37661176632397,
      "grad_norm": 0.11660068482160568,
      "learning_rate": 2.0709063479169086e-05,
      "loss": 0.0325,
      "step": 272700
    },
    {
      "epoch": 9.380050201148437,
      "grad_norm": 0.1127796396613121,
      "learning_rate": 2.0698318139422935e-05,
      "loss": 0.0325,
      "step": 272800
    },
    {
      "epoch": 9.383488635972904,
      "grad_norm": 0.43034616112709045,
      "learning_rate": 2.068757279967678e-05,
      "loss": 0.0345,
      "step": 272900
    },
    {
      "epoch": 9.386927070797373,
      "grad_norm": 0.07582621276378632,
      "learning_rate": 2.067682745993063e-05,
      "loss": 0.0326,
      "step": 273000
    },
    {
      "epoch": 9.39036550562184,
      "grad_norm": 0.18538986146450043,
      "learning_rate": 2.0666082120184478e-05,
      "loss": 0.0327,
      "step": 273100
    },
    {
      "epoch": 9.39380394044631,
      "grad_norm": 0.07313457876443863,
      "learning_rate": 2.0655336780438326e-05,
      "loss": 0.0361,
      "step": 273200
    },
    {
      "epoch": 9.397242375270777,
      "grad_norm": 0.074466772377491,
      "learning_rate": 2.0644698894089632e-05,
      "loss": 0.0343,
      "step": 273300
    },
    {
      "epoch": 9.400680810095245,
      "grad_norm": 0.1853877305984497,
      "learning_rate": 2.063395355434348e-05,
      "loss": 0.0322,
      "step": 273400
    },
    {
      "epoch": 9.404119244919713,
      "grad_norm": 0.5979387760162354,
      "learning_rate": 2.062320821459733e-05,
      "loss": 0.0315,
      "step": 273500
    },
    {
      "epoch": 9.40755767974418,
      "grad_norm": 0.40508586168289185,
      "learning_rate": 2.0612462874851175e-05,
      "loss": 0.0327,
      "step": 273600
    },
    {
      "epoch": 9.410996114568649,
      "grad_norm": 0.07904145866632462,
      "learning_rate": 2.0601717535105024e-05,
      "loss": 0.0311,
      "step": 273700
    },
    {
      "epoch": 9.414434549393116,
      "grad_norm": 0.021803025156259537,
      "learning_rate": 2.0590972195358873e-05,
      "loss": 0.0296,
      "step": 273800
    },
    {
      "epoch": 9.417872984217585,
      "grad_norm": 0.0797169879078865,
      "learning_rate": 2.058022685561272e-05,
      "loss": 0.0312,
      "step": 273900
    },
    {
      "epoch": 9.421311419042052,
      "grad_norm": 0.06266803294420242,
      "learning_rate": 2.056948151586657e-05,
      "loss": 0.0337,
      "step": 274000
    },
    {
      "epoch": 9.424749853866519,
      "grad_norm": 0.531575083732605,
      "learning_rate": 2.055873617612042e-05,
      "loss": 0.0337,
      "step": 274100
    },
    {
      "epoch": 9.428188288690988,
      "grad_norm": 0.15631623566150665,
      "learning_rate": 2.0547990836374264e-05,
      "loss": 0.0327,
      "step": 274200
    },
    {
      "epoch": 9.431626723515455,
      "grad_norm": 0.15983276069164276,
      "learning_rate": 2.0537245496628113e-05,
      "loss": 0.0348,
      "step": 274300
    },
    {
      "epoch": 9.435065158339924,
      "grad_norm": 0.18989720940589905,
      "learning_rate": 2.052650015688196e-05,
      "loss": 0.0304,
      "step": 274400
    },
    {
      "epoch": 9.438503593164391,
      "grad_norm": 0.28002163767814636,
      "learning_rate": 2.051575481713581e-05,
      "loss": 0.0351,
      "step": 274500
    },
    {
      "epoch": 9.44194202798886,
      "grad_norm": 0.08862145245075226,
      "learning_rate": 2.050500947738966e-05,
      "loss": 0.0324,
      "step": 274600
    },
    {
      "epoch": 9.445380462813327,
      "grad_norm": 0.03919241204857826,
      "learning_rate": 2.0494264137643504e-05,
      "loss": 0.0303,
      "step": 274700
    },
    {
      "epoch": 9.448818897637794,
      "grad_norm": 0.258219838142395,
      "learning_rate": 2.0483518797897353e-05,
      "loss": 0.0332,
      "step": 274800
    },
    {
      "epoch": 9.452257332462263,
      "grad_norm": 0.10168904066085815,
      "learning_rate": 2.04727734581512e-05,
      "loss": 0.0316,
      "step": 274900
    },
    {
      "epoch": 9.45569576728673,
      "grad_norm": 0.10536733269691467,
      "learning_rate": 2.046202811840505e-05,
      "loss": 0.0323,
      "step": 275000
    },
    {
      "epoch": 9.4591342021112,
      "grad_norm": 0.19427689909934998,
      "learning_rate": 2.04512827786589e-05,
      "loss": 0.0345,
      "step": 275100
    },
    {
      "epoch": 9.462572636935667,
      "grad_norm": 0.06740666180849075,
      "learning_rate": 2.0440537438912744e-05,
      "loss": 0.0312,
      "step": 275200
    },
    {
      "epoch": 9.466011071760136,
      "grad_norm": 0.05353502184152603,
      "learning_rate": 2.0429792099166593e-05,
      "loss": 0.0307,
      "step": 275300
    },
    {
      "epoch": 9.469449506584603,
      "grad_norm": 0.12259788811206818,
      "learning_rate": 2.041904675942044e-05,
      "loss": 0.032,
      "step": 275400
    },
    {
      "epoch": 9.47288794140907,
      "grad_norm": 0.20730164647102356,
      "learning_rate": 2.040830141967429e-05,
      "loss": 0.0311,
      "step": 275500
    },
    {
      "epoch": 9.476326376233539,
      "grad_norm": 0.29622572660446167,
      "learning_rate": 2.0397663533325596e-05,
      "loss": 0.0357,
      "step": 275600
    },
    {
      "epoch": 9.479764811058006,
      "grad_norm": 0.14262844622135162,
      "learning_rate": 2.0386918193579445e-05,
      "loss": 0.0334,
      "step": 275700
    },
    {
      "epoch": 9.483203245882475,
      "grad_norm": 0.9255322217941284,
      "learning_rate": 2.0376172853833294e-05,
      "loss": 0.0331,
      "step": 275800
    },
    {
      "epoch": 9.486641680706942,
      "grad_norm": 0.43773722648620605,
      "learning_rate": 2.036542751408714e-05,
      "loss": 0.0341,
      "step": 275900
    },
    {
      "epoch": 9.490080115531411,
      "grad_norm": 0.1461845189332962,
      "learning_rate": 2.0354682174340988e-05,
      "loss": 0.0309,
      "step": 276000
    },
    {
      "epoch": 9.493518550355878,
      "grad_norm": 0.13628500699996948,
      "learning_rate": 2.0343936834594836e-05,
      "loss": 0.0316,
      "step": 276100
    },
    {
      "epoch": 9.496956985180345,
      "grad_norm": 0.12028060853481293,
      "learning_rate": 2.0333191494848685e-05,
      "loss": 0.031,
      "step": 276200
    },
    {
      "epoch": 9.500395420004814,
      "grad_norm": 0.027277329936623573,
      "learning_rate": 2.0322446155102534e-05,
      "loss": 0.03,
      "step": 276300
    },
    {
      "epoch": 9.503833854829281,
      "grad_norm": 0.27324581146240234,
      "learning_rate": 2.031170081535638e-05,
      "loss": 0.0294,
      "step": 276400
    },
    {
      "epoch": 9.50727228965375,
      "grad_norm": 0.15953174233436584,
      "learning_rate": 2.0300955475610228e-05,
      "loss": 0.0338,
      "step": 276500
    },
    {
      "epoch": 9.510710724478217,
      "grad_norm": 0.10367681086063385,
      "learning_rate": 2.0290210135864076e-05,
      "loss": 0.0321,
      "step": 276600
    },
    {
      "epoch": 9.514149159302686,
      "grad_norm": 0.11857626587152481,
      "learning_rate": 2.0279464796117925e-05,
      "loss": 0.0325,
      "step": 276700
    },
    {
      "epoch": 9.517587594127153,
      "grad_norm": 0.03467114269733429,
      "learning_rate": 2.0268719456371774e-05,
      "loss": 0.0334,
      "step": 276800
    },
    {
      "epoch": 9.52102602895162,
      "grad_norm": 0.1457405686378479,
      "learning_rate": 2.025797411662562e-05,
      "loss": 0.0335,
      "step": 276900
    },
    {
      "epoch": 9.52446446377609,
      "grad_norm": 0.29567375779151917,
      "learning_rate": 2.0247228776879468e-05,
      "loss": 0.0322,
      "step": 277000
    },
    {
      "epoch": 9.527902898600557,
      "grad_norm": 0.24345548450946808,
      "learning_rate": 2.0236483437133316e-05,
      "loss": 0.0304,
      "step": 277100
    },
    {
      "epoch": 9.531341333425026,
      "grad_norm": 0.3329787850379944,
      "learning_rate": 2.0225738097387165e-05,
      "loss": 0.0347,
      "step": 277200
    },
    {
      "epoch": 9.534779768249493,
      "grad_norm": 0.060626037418842316,
      "learning_rate": 2.0214992757641014e-05,
      "loss": 0.033,
      "step": 277300
    },
    {
      "epoch": 9.53821820307396,
      "grad_norm": 0.17796723544597626,
      "learning_rate": 2.020424741789486e-05,
      "loss": 0.0341,
      "step": 277400
    },
    {
      "epoch": 9.541656637898429,
      "grad_norm": 0.1233205497264862,
      "learning_rate": 2.0193502078148708e-05,
      "loss": 0.0318,
      "step": 277500
    },
    {
      "epoch": 9.545095072722896,
      "grad_norm": 0.20664367079734802,
      "learning_rate": 2.0182864191800017e-05,
      "loss": 0.034,
      "step": 277600
    },
    {
      "epoch": 9.548533507547365,
      "grad_norm": 0.23110435903072357,
      "learning_rate": 2.0172118852053866e-05,
      "loss": 0.0335,
      "step": 277700
    },
    {
      "epoch": 9.551971942371832,
      "grad_norm": 0.12366435676813126,
      "learning_rate": 2.0161373512307715e-05,
      "loss": 0.0325,
      "step": 277800
    },
    {
      "epoch": 9.555410377196301,
      "grad_norm": 0.14137743413448334,
      "learning_rate": 2.015062817256156e-05,
      "loss": 0.0326,
      "step": 277900
    },
    {
      "epoch": 9.558848812020768,
      "grad_norm": 0.37666162848472595,
      "learning_rate": 2.013988283281541e-05,
      "loss": 0.0331,
      "step": 278000
    },
    {
      "epoch": 9.562287246845235,
      "grad_norm": 0.2471286654472351,
      "learning_rate": 2.0129137493069254e-05,
      "loss": 0.0317,
      "step": 278100
    },
    {
      "epoch": 9.565725681669704,
      "grad_norm": 0.11948778480291367,
      "learning_rate": 2.0118392153323103e-05,
      "loss": 0.0344,
      "step": 278200
    },
    {
      "epoch": 9.569164116494171,
      "grad_norm": 0.5082474946975708,
      "learning_rate": 2.010764681357695e-05,
      "loss": 0.0323,
      "step": 278300
    },
    {
      "epoch": 9.57260255131864,
      "grad_norm": 0.12094688415527344,
      "learning_rate": 2.00969014738308e-05,
      "loss": 0.0327,
      "step": 278400
    },
    {
      "epoch": 9.576040986143108,
      "grad_norm": 0.09621827304363251,
      "learning_rate": 2.008615613408465e-05,
      "loss": 0.0299,
      "step": 278500
    },
    {
      "epoch": 9.579479420967576,
      "grad_norm": 0.07548986375331879,
      "learning_rate": 2.0075410794338494e-05,
      "loss": 0.0326,
      "step": 278600
    },
    {
      "epoch": 9.582917855792044,
      "grad_norm": 0.08244230598211288,
      "learning_rate": 2.0064665454592343e-05,
      "loss": 0.0306,
      "step": 278700
    },
    {
      "epoch": 9.58635629061651,
      "grad_norm": 0.07641907781362534,
      "learning_rate": 2.005392011484619e-05,
      "loss": 0.03,
      "step": 278800
    },
    {
      "epoch": 9.58979472544098,
      "grad_norm": 0.09880364686250687,
      "learning_rate": 2.004317477510004e-05,
      "loss": 0.0338,
      "step": 278900
    },
    {
      "epoch": 9.593233160265447,
      "grad_norm": 0.07305409014225006,
      "learning_rate": 2.003242943535389e-05,
      "loss": 0.0326,
      "step": 279000
    },
    {
      "epoch": 9.596671595089916,
      "grad_norm": 0.10594411939382553,
      "learning_rate": 2.0021684095607734e-05,
      "loss": 0.0351,
      "step": 279100
    },
    {
      "epoch": 9.600110029914383,
      "grad_norm": 0.062065239995718,
      "learning_rate": 2.0010938755861583e-05,
      "loss": 0.0318,
      "step": 279200
    },
    {
      "epoch": 9.60354846473885,
      "grad_norm": 0.0637236163020134,
      "learning_rate": 2.000019341611543e-05,
      "loss": 0.0323,
      "step": 279300
    },
    {
      "epoch": 9.606986899563319,
      "grad_norm": 0.15680831670761108,
      "learning_rate": 1.998944807636928e-05,
      "loss": 0.034,
      "step": 279400
    },
    {
      "epoch": 9.610425334387786,
      "grad_norm": 0.07618512958288193,
      "learning_rate": 1.997870273662313e-05,
      "loss": 0.0356,
      "step": 279500
    },
    {
      "epoch": 9.613863769212255,
      "grad_norm": 0.21638506650924683,
      "learning_rate": 1.9967957396876977e-05,
      "loss": 0.0332,
      "step": 279600
    },
    {
      "epoch": 9.617302204036722,
      "grad_norm": 0.3824589252471924,
      "learning_rate": 1.9957212057130823e-05,
      "loss": 0.0323,
      "step": 279700
    },
    {
      "epoch": 9.620740638861191,
      "grad_norm": 0.04544617980718613,
      "learning_rate": 1.994646671738467e-05,
      "loss": 0.031,
      "step": 279800
    },
    {
      "epoch": 9.624179073685658,
      "grad_norm": 0.3723829984664917,
      "learning_rate": 1.993582883103598e-05,
      "loss": 0.0342,
      "step": 279900
    },
    {
      "epoch": 9.627617508510125,
      "grad_norm": 0.05369510129094124,
      "learning_rate": 1.992508349128983e-05,
      "loss": 0.0325,
      "step": 280000
    },
    {
      "epoch": 9.631055943334594,
      "grad_norm": 0.12700793147087097,
      "learning_rate": 1.991433815154368e-05,
      "loss": 0.0338,
      "step": 280100
    },
    {
      "epoch": 9.634494378159062,
      "grad_norm": 0.16481265425682068,
      "learning_rate": 1.9903592811797524e-05,
      "loss": 0.0313,
      "step": 280200
    },
    {
      "epoch": 9.63793281298353,
      "grad_norm": 0.04071870073676109,
      "learning_rate": 1.9892847472051372e-05,
      "loss": 0.0354,
      "step": 280300
    },
    {
      "epoch": 9.641371247807998,
      "grad_norm": 0.22736340761184692,
      "learning_rate": 1.9882102132305218e-05,
      "loss": 0.0324,
      "step": 280400
    },
    {
      "epoch": 9.644809682632467,
      "grad_norm": 0.1833154410123825,
      "learning_rate": 1.987146424595653e-05,
      "loss": 0.0325,
      "step": 280500
    },
    {
      "epoch": 9.648248117456934,
      "grad_norm": 0.16654524207115173,
      "learning_rate": 1.9860718906210376e-05,
      "loss": 0.0351,
      "step": 280600
    },
    {
      "epoch": 9.6516865522814,
      "grad_norm": 0.09129206836223602,
      "learning_rate": 1.9849973566464225e-05,
      "loss": 0.0336,
      "step": 280700
    },
    {
      "epoch": 9.65512498710587,
      "grad_norm": 0.18379177153110504,
      "learning_rate": 1.9839228226718073e-05,
      "loss": 0.0348,
      "step": 280800
    },
    {
      "epoch": 9.658563421930337,
      "grad_norm": 0.0379299595952034,
      "learning_rate": 1.9828482886971922e-05,
      "loss": 0.0307,
      "step": 280900
    },
    {
      "epoch": 9.662001856754806,
      "grad_norm": 0.19640357792377472,
      "learning_rate": 1.981773754722577e-05,
      "loss": 0.037,
      "step": 281000
    },
    {
      "epoch": 9.665440291579273,
      "grad_norm": 0.25929784774780273,
      "learning_rate": 1.9806992207479616e-05,
      "loss": 0.0321,
      "step": 281100
    },
    {
      "epoch": 9.66887872640374,
      "grad_norm": 0.12069623917341232,
      "learning_rate": 1.9796246867733465e-05,
      "loss": 0.0331,
      "step": 281200
    },
    {
      "epoch": 9.672317161228209,
      "grad_norm": 0.13744325935840607,
      "learning_rate": 1.9785501527987313e-05,
      "loss": 0.0332,
      "step": 281300
    },
    {
      "epoch": 9.675755596052676,
      "grad_norm": 0.19390247762203217,
      "learning_rate": 1.9774756188241162e-05,
      "loss": 0.0301,
      "step": 281400
    },
    {
      "epoch": 9.679194030877145,
      "grad_norm": 0.05628679320216179,
      "learning_rate": 1.976401084849501e-05,
      "loss": 0.0344,
      "step": 281500
    },
    {
      "epoch": 9.682632465701612,
      "grad_norm": 0.09566963464021683,
      "learning_rate": 1.9753265508748856e-05,
      "loss": 0.031,
      "step": 281600
    },
    {
      "epoch": 9.686070900526081,
      "grad_norm": 0.17119735479354858,
      "learning_rate": 1.9742520169002705e-05,
      "loss": 0.0364,
      "step": 281700
    },
    {
      "epoch": 9.689509335350548,
      "grad_norm": 0.1559654176235199,
      "learning_rate": 1.9731774829256553e-05,
      "loss": 0.0312,
      "step": 281800
    },
    {
      "epoch": 9.692947770175016,
      "grad_norm": 0.10277355462312698,
      "learning_rate": 1.9721029489510402e-05,
      "loss": 0.0324,
      "step": 281900
    },
    {
      "epoch": 9.696386204999484,
      "grad_norm": 0.18401537835597992,
      "learning_rate": 1.971028414976425e-05,
      "loss": 0.0335,
      "step": 282000
    },
    {
      "epoch": 9.699824639823952,
      "grad_norm": 0.22325628995895386,
      "learning_rate": 1.9699538810018096e-05,
      "loss": 0.0325,
      "step": 282100
    },
    {
      "epoch": 9.70326307464842,
      "grad_norm": 0.06775125861167908,
      "learning_rate": 1.9688793470271945e-05,
      "loss": 0.0316,
      "step": 282200
    },
    {
      "epoch": 9.706701509472888,
      "grad_norm": 0.05334581807255745,
      "learning_rate": 1.9678048130525793e-05,
      "loss": 0.0338,
      "step": 282300
    },
    {
      "epoch": 9.710139944297357,
      "grad_norm": 0.07960982620716095,
      "learning_rate": 1.966730279077964e-05,
      "loss": 0.0322,
      "step": 282400
    },
    {
      "epoch": 9.713578379121824,
      "grad_norm": 0.07794122397899628,
      "learning_rate": 1.9656557451033487e-05,
      "loss": 0.0308,
      "step": 282500
    },
    {
      "epoch": 9.717016813946291,
      "grad_norm": 0.1645689159631729,
      "learning_rate": 1.9645812111287336e-05,
      "loss": 0.0328,
      "step": 282600
    },
    {
      "epoch": 9.72045524877076,
      "grad_norm": 0.049146801233291626,
      "learning_rate": 1.963506677154118e-05,
      "loss": 0.0308,
      "step": 282700
    },
    {
      "epoch": 9.723893683595227,
      "grad_norm": 0.06719783693552017,
      "learning_rate": 1.962432143179503e-05,
      "loss": 0.033,
      "step": 282800
    },
    {
      "epoch": 9.727332118419696,
      "grad_norm": 0.19351248443126678,
      "learning_rate": 1.961357609204888e-05,
      "loss": 0.0312,
      "step": 282900
    },
    {
      "epoch": 9.730770553244163,
      "grad_norm": 0.03729432076215744,
      "learning_rate": 1.9602830752302727e-05,
      "loss": 0.033,
      "step": 283000
    },
    {
      "epoch": 9.73420898806863,
      "grad_norm": 0.08393668383359909,
      "learning_rate": 1.9592085412556573e-05,
      "loss": 0.036,
      "step": 283100
    },
    {
      "epoch": 9.7376474228931,
      "grad_norm": 0.3142062723636627,
      "learning_rate": 1.958134007281042e-05,
      "loss": 0.0372,
      "step": 283200
    },
    {
      "epoch": 9.741085857717566,
      "grad_norm": 0.027124011889100075,
      "learning_rate": 1.957059473306427e-05,
      "loss": 0.0345,
      "step": 283300
    },
    {
      "epoch": 9.744524292542035,
      "grad_norm": 0.1323167234659195,
      "learning_rate": 1.955984939331812e-05,
      "loss": 0.036,
      "step": 283400
    },
    {
      "epoch": 9.747962727366502,
      "grad_norm": 0.10492116957902908,
      "learning_rate": 1.9549104053571967e-05,
      "loss": 0.0331,
      "step": 283500
    },
    {
      "epoch": 9.751401162190971,
      "grad_norm": 0.4389626681804657,
      "learning_rate": 1.9538358713825813e-05,
      "loss": 0.0314,
      "step": 283600
    },
    {
      "epoch": 9.754839597015438,
      "grad_norm": 0.2714570462703705,
      "learning_rate": 1.952761337407966e-05,
      "loss": 0.031,
      "step": 283700
    },
    {
      "epoch": 9.758278031839907,
      "grad_norm": 0.11501024663448334,
      "learning_rate": 1.951686803433351e-05,
      "loss": 0.0321,
      "step": 283800
    },
    {
      "epoch": 9.761716466664375,
      "grad_norm": 0.056237656623125076,
      "learning_rate": 1.950612269458736e-05,
      "loss": 0.0353,
      "step": 283900
    },
    {
      "epoch": 9.765154901488842,
      "grad_norm": 0.0819179117679596,
      "learning_rate": 1.9495377354841207e-05,
      "loss": 0.0352,
      "step": 284000
    },
    {
      "epoch": 9.76859333631331,
      "grad_norm": 0.1775379776954651,
      "learning_rate": 1.9484632015095053e-05,
      "loss": 0.0313,
      "step": 284100
    },
    {
      "epoch": 9.772031771137778,
      "grad_norm": 0.10731065273284912,
      "learning_rate": 1.94738866753489e-05,
      "loss": 0.031,
      "step": 284200
    },
    {
      "epoch": 9.775470205962247,
      "grad_norm": 0.18419253826141357,
      "learning_rate": 1.946314133560275e-05,
      "loss": 0.0332,
      "step": 284300
    },
    {
      "epoch": 9.778908640786714,
      "grad_norm": 0.5342983603477478,
      "learning_rate": 1.94523959958566e-05,
      "loss": 0.0349,
      "step": 284400
    },
    {
      "epoch": 9.782347075611181,
      "grad_norm": 0.2005351483821869,
      "learning_rate": 1.9441650656110447e-05,
      "loss": 0.0328,
      "step": 284500
    },
    {
      "epoch": 9.78578551043565,
      "grad_norm": 0.13165660202503204,
      "learning_rate": 1.9430905316364296e-05,
      "loss": 0.0327,
      "step": 284600
    },
    {
      "epoch": 9.789223945260117,
      "grad_norm": 0.0919165313243866,
      "learning_rate": 1.942015997661814e-05,
      "loss": 0.0321,
      "step": 284700
    },
    {
      "epoch": 9.792662380084586,
      "grad_norm": 0.013680022209882736,
      "learning_rate": 1.940941463687199e-05,
      "loss": 0.0308,
      "step": 284800
    },
    {
      "epoch": 9.796100814909053,
      "grad_norm": 0.1906769871711731,
      "learning_rate": 1.939866929712584e-05,
      "loss": 0.0348,
      "step": 284900
    },
    {
      "epoch": 9.799539249733522,
      "grad_norm": 0.08359004557132721,
      "learning_rate": 1.9387923957379687e-05,
      "loss": 0.0303,
      "step": 285000
    },
    {
      "epoch": 9.80297768455799,
      "grad_norm": 0.278110146522522,
      "learning_rate": 1.9377178617633536e-05,
      "loss": 0.0365,
      "step": 285100
    },
    {
      "epoch": 9.806416119382456,
      "grad_norm": 0.1257951259613037,
      "learning_rate": 1.936643327788738e-05,
      "loss": 0.0324,
      "step": 285200
    },
    {
      "epoch": 9.809854554206925,
      "grad_norm": 0.128396674990654,
      "learning_rate": 1.935579539153869e-05,
      "loss": 0.0324,
      "step": 285300
    },
    {
      "epoch": 9.813292989031392,
      "grad_norm": 0.25853288173675537,
      "learning_rate": 1.9345050051792536e-05,
      "loss": 0.0351,
      "step": 285400
    },
    {
      "epoch": 9.816731423855861,
      "grad_norm": 0.17924091219902039,
      "learning_rate": 1.9334304712046385e-05,
      "loss": 0.0346,
      "step": 285500
    },
    {
      "epoch": 9.820169858680329,
      "grad_norm": 0.05331500247120857,
      "learning_rate": 1.9323559372300234e-05,
      "loss": 0.0351,
      "step": 285600
    },
    {
      "epoch": 9.823608293504797,
      "grad_norm": 0.7119519114494324,
      "learning_rate": 1.9312814032554082e-05,
      "loss": 0.0362,
      "step": 285700
    },
    {
      "epoch": 9.827046728329265,
      "grad_norm": 0.1835222989320755,
      "learning_rate": 1.930206869280793e-05,
      "loss": 0.0324,
      "step": 285800
    },
    {
      "epoch": 9.830485163153732,
      "grad_norm": 0.21561957895755768,
      "learning_rate": 1.9291323353061776e-05,
      "loss": 0.0317,
      "step": 285900
    },
    {
      "epoch": 9.8339235979782,
      "grad_norm": 0.024379001930356026,
      "learning_rate": 1.9280578013315625e-05,
      "loss": 0.0317,
      "step": 286000
    },
    {
      "epoch": 9.837362032802668,
      "grad_norm": 0.17871171236038208,
      "learning_rate": 1.9269832673569474e-05,
      "loss": 0.0333,
      "step": 286100
    },
    {
      "epoch": 9.840800467627137,
      "grad_norm": 0.3811705410480499,
      "learning_rate": 1.9259087333823322e-05,
      "loss": 0.0332,
      "step": 286200
    },
    {
      "epoch": 9.844238902451604,
      "grad_norm": 0.049129631370306015,
      "learning_rate": 1.924834199407717e-05,
      "loss": 0.0352,
      "step": 286300
    },
    {
      "epoch": 9.847677337276071,
      "grad_norm": 0.1943552941083908,
      "learning_rate": 1.9237596654331016e-05,
      "loss": 0.0304,
      "step": 286400
    },
    {
      "epoch": 9.85111577210054,
      "grad_norm": 0.2351721078157425,
      "learning_rate": 1.9226851314584865e-05,
      "loss": 0.0312,
      "step": 286500
    },
    {
      "epoch": 9.854554206925007,
      "grad_norm": 0.08528151363134384,
      "learning_rate": 1.9216105974838714e-05,
      "loss": 0.0347,
      "step": 286600
    },
    {
      "epoch": 9.857992641749476,
      "grad_norm": 0.3740190863609314,
      "learning_rate": 1.9205360635092562e-05,
      "loss": 0.0325,
      "step": 286700
    },
    {
      "epoch": 9.861431076573943,
      "grad_norm": 0.17350129783153534,
      "learning_rate": 1.919461529534641e-05,
      "loss": 0.03,
      "step": 286800
    },
    {
      "epoch": 9.864869511398412,
      "grad_norm": 0.06681693345308304,
      "learning_rate": 1.9183869955600256e-05,
      "loss": 0.0341,
      "step": 286900
    },
    {
      "epoch": 9.86830794622288,
      "grad_norm": 0.1982094645500183,
      "learning_rate": 1.9173124615854105e-05,
      "loss": 0.0362,
      "step": 287000
    },
    {
      "epoch": 9.871746381047346,
      "grad_norm": 0.0751936063170433,
      "learning_rate": 1.9162379276107954e-05,
      "loss": 0.0348,
      "step": 287100
    },
    {
      "epoch": 9.875184815871815,
      "grad_norm": 0.20745249092578888,
      "learning_rate": 1.9151633936361803e-05,
      "loss": 0.0338,
      "step": 287200
    },
    {
      "epoch": 9.878623250696283,
      "grad_norm": 0.1665017306804657,
      "learning_rate": 1.914099605001311e-05,
      "loss": 0.0347,
      "step": 287300
    },
    {
      "epoch": 9.882061685520751,
      "grad_norm": 0.0997626781463623,
      "learning_rate": 1.9130250710266957e-05,
      "loss": 0.0306,
      "step": 287400
    },
    {
      "epoch": 9.885500120345219,
      "grad_norm": 0.12586887180805206,
      "learning_rate": 1.9119505370520806e-05,
      "loss": 0.0356,
      "step": 287500
    },
    {
      "epoch": 9.888938555169688,
      "grad_norm": 0.13115070760250092,
      "learning_rate": 1.910876003077465e-05,
      "loss": 0.0319,
      "step": 287600
    },
    {
      "epoch": 9.892376989994155,
      "grad_norm": 0.08319742977619171,
      "learning_rate": 1.90980146910285e-05,
      "loss": 0.033,
      "step": 287700
    },
    {
      "epoch": 9.895815424818622,
      "grad_norm": 0.020995501428842545,
      "learning_rate": 1.908726935128235e-05,
      "loss": 0.0309,
      "step": 287800
    },
    {
      "epoch": 9.89925385964309,
      "grad_norm": 0.12049934267997742,
      "learning_rate": 1.9076524011536197e-05,
      "loss": 0.0341,
      "step": 287900
    },
    {
      "epoch": 9.902692294467558,
      "grad_norm": 0.4545948803424835,
      "learning_rate": 1.9065778671790046e-05,
      "loss": 0.0349,
      "step": 288000
    },
    {
      "epoch": 9.906130729292027,
      "grad_norm": 0.10095474869012833,
      "learning_rate": 1.905503333204389e-05,
      "loss": 0.0294,
      "step": 288100
    },
    {
      "epoch": 9.909569164116494,
      "grad_norm": 0.13430094718933105,
      "learning_rate": 1.904428799229774e-05,
      "loss": 0.033,
      "step": 288200
    },
    {
      "epoch": 9.913007598940961,
      "grad_norm": 0.06228064373135567,
      "learning_rate": 1.903354265255159e-05,
      "loss": 0.0348,
      "step": 288300
    },
    {
      "epoch": 9.91644603376543,
      "grad_norm": 0.08903231471776962,
      "learning_rate": 1.9022797312805437e-05,
      "loss": 0.032,
      "step": 288400
    },
    {
      "epoch": 9.919884468589897,
      "grad_norm": 0.09899142384529114,
      "learning_rate": 1.9012051973059286e-05,
      "loss": 0.033,
      "step": 288500
    },
    {
      "epoch": 9.923322903414366,
      "grad_norm": 0.20119325816631317,
      "learning_rate": 1.900130663331313e-05,
      "loss": 0.0343,
      "step": 288600
    },
    {
      "epoch": 9.926761338238833,
      "grad_norm": 0.07060899585485458,
      "learning_rate": 1.899056129356698e-05,
      "loss": 0.0333,
      "step": 288700
    },
    {
      "epoch": 9.930199773063302,
      "grad_norm": 0.163227379322052,
      "learning_rate": 1.897981595382083e-05,
      "loss": 0.032,
      "step": 288800
    },
    {
      "epoch": 9.93363820788777,
      "grad_norm": 0.1597377210855484,
      "learning_rate": 1.8969070614074678e-05,
      "loss": 0.0325,
      "step": 288900
    },
    {
      "epoch": 9.937076642712237,
      "grad_norm": 0.06896547973155975,
      "learning_rate": 1.8958325274328526e-05,
      "loss": 0.0318,
      "step": 289000
    },
    {
      "epoch": 9.940515077536705,
      "grad_norm": 0.08173469454050064,
      "learning_rate": 1.894757993458237e-05,
      "loss": 0.0357,
      "step": 289100
    },
    {
      "epoch": 9.943953512361173,
      "grad_norm": 0.19208209216594696,
      "learning_rate": 1.893683459483622e-05,
      "loss": 0.0343,
      "step": 289200
    },
    {
      "epoch": 9.947391947185642,
      "grad_norm": 0.051619865000247955,
      "learning_rate": 1.892608925509007e-05,
      "loss": 0.0333,
      "step": 289300
    },
    {
      "epoch": 9.950830382010109,
      "grad_norm": 0.07568376511335373,
      "learning_rate": 1.8915343915343918e-05,
      "loss": 0.0337,
      "step": 289400
    },
    {
      "epoch": 9.954268816834578,
      "grad_norm": 0.0844101831316948,
      "learning_rate": 1.8904598575597766e-05,
      "loss": 0.0345,
      "step": 289500
    },
    {
      "epoch": 9.957707251659045,
      "grad_norm": 0.26275861263275146,
      "learning_rate": 1.889385323585161e-05,
      "loss": 0.0343,
      "step": 289600
    },
    {
      "epoch": 9.961145686483512,
      "grad_norm": 0.08358784765005112,
      "learning_rate": 1.888321534950292e-05,
      "loss": 0.0345,
      "step": 289700
    },
    {
      "epoch": 9.96458412130798,
      "grad_norm": 0.4506332576274872,
      "learning_rate": 1.8872470009756766e-05,
      "loss": 0.0333,
      "step": 289800
    },
    {
      "epoch": 9.968022556132448,
      "grad_norm": 0.11646924912929535,
      "learning_rate": 1.8861724670010615e-05,
      "loss": 0.0277,
      "step": 289900
    },
    {
      "epoch": 9.971460990956917,
      "grad_norm": 0.13789249956607819,
      "learning_rate": 1.8850979330264464e-05,
      "loss": 0.033,
      "step": 290000
    },
    {
      "epoch": 9.974899425781384,
      "grad_norm": 0.04840574041008949,
      "learning_rate": 1.8840233990518312e-05,
      "loss": 0.0335,
      "step": 290100
    },
    {
      "epoch": 9.978337860605853,
      "grad_norm": 0.1856532096862793,
      "learning_rate": 1.882948865077216e-05,
      "loss": 0.0312,
      "step": 290200
    },
    {
      "epoch": 9.98177629543032,
      "grad_norm": 0.0814800038933754,
      "learning_rate": 1.881874331102601e-05,
      "loss": 0.03,
      "step": 290300
    },
    {
      "epoch": 9.985214730254787,
      "grad_norm": 0.14561158418655396,
      "learning_rate": 1.8807997971279855e-05,
      "loss": 0.0316,
      "step": 290400
    },
    {
      "epoch": 9.988653165079256,
      "grad_norm": 0.12204854935407639,
      "learning_rate": 1.8797252631533704e-05,
      "loss": 0.0326,
      "step": 290500
    },
    {
      "epoch": 9.992091599903723,
      "grad_norm": 0.160537451505661,
      "learning_rate": 1.8786507291787553e-05,
      "loss": 0.0305,
      "step": 290600
    },
    {
      "epoch": 9.995530034728192,
      "grad_norm": 0.05126897245645523,
      "learning_rate": 1.87757619520414e-05,
      "loss": 0.0291,
      "step": 290700
    },
    {
      "epoch": 9.99896846955266,
      "grad_norm": 0.3782157599925995,
      "learning_rate": 1.876501661229525e-05,
      "loss": 0.0314,
      "step": 290800
    },
    {
      "epoch": 10.0,
      "eval_accuracy_macro_0.5": 0.9858071804046631,
      "eval_accuracy_micro_0.5": 0.9858071804046631,
      "eval_accuracy_weighted_0.5": 0.9767125248908997,
      "eval_aucroc_macro": 0.921069860458374,
      "eval_aucroc_micro": 0.9261786341667175,
      "eval_aucroc_weighted": 0.9232959151268005,
      "eval_f1_macro_0.5": 0.7863503098487854,
      "eval_f1_macro_0.6": 0.7735003232955933,
      "eval_f1_macro_0.7": 0.7497045397758484,
      "eval_f1_macro_0.8": 0.6115301847457886,
      "eval_f1_micro_0.5": 0.7952969670295715,
      "eval_f1_micro_0.6": 0.7857890725135803,
      "eval_f1_micro_0.7": 0.7654427289962769,
      "eval_f1_micro_0.8": 0.7265878319740295,
      "eval_f1_micro_0.9": 0.6421362161636353,
      "eval_f1_weighted_0.5": 0.7907236218452454,
      "eval_f1_weighted_0.6": 0.7775752544403076,
      "eval_f1_weighted_0.7": 0.752302885055542,
      "eval_f1_weighted_0.8": 0.6078721880912781,
      "eval_loss": 0.030670003965497017,
      "eval_runtime": 2411.0664,
      "eval_samples_per_second": 24.11,
      "eval_steps_per_second": 3.014,
      "step": 290830
    },
    {
      "epoch": 10.002406904377127,
      "grad_norm": 0.07440654933452606,
      "learning_rate": 1.8754271272549095e-05,
      "loss": 0.03,
      "step": 290900
    },
    {
      "epoch": 10.005845339201596,
      "grad_norm": 0.2345685064792633,
      "learning_rate": 1.8743525932802944e-05,
      "loss": 0.0309,
      "step": 291000
    },
    {
      "epoch": 10.009283774026063,
      "grad_norm": 0.13632941246032715,
      "learning_rate": 1.8732780593056793e-05,
      "loss": 0.0326,
      "step": 291100
    },
    {
      "epoch": 10.012722208850532,
      "grad_norm": 0.37206557393074036,
      "learning_rate": 1.872203525331064e-05,
      "loss": 0.0346,
      "step": 291200
    },
    {
      "epoch": 10.016160643674999,
      "grad_norm": 0.19364707171916962,
      "learning_rate": 1.871128991356449e-05,
      "loss": 0.0298,
      "step": 291300
    },
    {
      "epoch": 10.019599078499468,
      "grad_norm": 0.1862994283437729,
      "learning_rate": 1.8700544573818335e-05,
      "loss": 0.0355,
      "step": 291400
    },
    {
      "epoch": 10.023037513323935,
      "grad_norm": 0.11711405217647552,
      "learning_rate": 1.8689799234072184e-05,
      "loss": 0.0293,
      "step": 291500
    },
    {
      "epoch": 10.026475948148402,
      "grad_norm": 0.12052395939826965,
      "learning_rate": 1.8679053894326033e-05,
      "loss": 0.0342,
      "step": 291600
    },
    {
      "epoch": 10.029914382972871,
      "grad_norm": 0.4196318984031677,
      "learning_rate": 1.866830855457988e-05,
      "loss": 0.0319,
      "step": 291700
    },
    {
      "epoch": 10.033352817797338,
      "grad_norm": 0.06027008965611458,
      "learning_rate": 1.865756321483373e-05,
      "loss": 0.0356,
      "step": 291800
    },
    {
      "epoch": 10.036791252621807,
      "grad_norm": 0.24953681230545044,
      "learning_rate": 1.8646817875087575e-05,
      "loss": 0.0338,
      "step": 291900
    },
    {
      "epoch": 10.040229687446274,
      "grad_norm": 0.15212710201740265,
      "learning_rate": 1.8636072535341424e-05,
      "loss": 0.0307,
      "step": 292000
    },
    {
      "epoch": 10.043668122270743,
      "grad_norm": 0.20657578110694885,
      "learning_rate": 1.862543464899273e-05,
      "loss": 0.0297,
      "step": 292100
    },
    {
      "epoch": 10.04710655709521,
      "grad_norm": 0.32689952850341797,
      "learning_rate": 1.861468930924658e-05,
      "loss": 0.0316,
      "step": 292200
    },
    {
      "epoch": 10.050544991919677,
      "grad_norm": 0.29672932624816895,
      "learning_rate": 1.8603943969500428e-05,
      "loss": 0.0364,
      "step": 292300
    },
    {
      "epoch": 10.053983426744146,
      "grad_norm": 0.22480496764183044,
      "learning_rate": 1.8593198629754276e-05,
      "loss": 0.0314,
      "step": 292400
    },
    {
      "epoch": 10.057421861568614,
      "grad_norm": 0.1315794140100479,
      "learning_rate": 1.8582453290008125e-05,
      "loss": 0.031,
      "step": 292500
    },
    {
      "epoch": 10.060860296393082,
      "grad_norm": 0.46124106645584106,
      "learning_rate": 1.857170795026197e-05,
      "loss": 0.0336,
      "step": 292600
    },
    {
      "epoch": 10.06429873121755,
      "grad_norm": 0.240591362118721,
      "learning_rate": 1.856096261051582e-05,
      "loss": 0.0303,
      "step": 292700
    },
    {
      "epoch": 10.067737166042019,
      "grad_norm": 0.20354492962360382,
      "learning_rate": 1.8550217270769668e-05,
      "loss": 0.031,
      "step": 292800
    },
    {
      "epoch": 10.071175600866486,
      "grad_norm": 0.1398727297782898,
      "learning_rate": 1.8539471931023516e-05,
      "loss": 0.0308,
      "step": 292900
    },
    {
      "epoch": 10.074614035690953,
      "grad_norm": 0.5579637289047241,
      "learning_rate": 1.8528726591277365e-05,
      "loss": 0.0326,
      "step": 293000
    },
    {
      "epoch": 10.078052470515422,
      "grad_norm": 0.41755086183547974,
      "learning_rate": 1.851798125153121e-05,
      "loss": 0.0326,
      "step": 293100
    },
    {
      "epoch": 10.081490905339889,
      "grad_norm": 0.0960274487733841,
      "learning_rate": 1.850723591178506e-05,
      "loss": 0.0315,
      "step": 293200
    },
    {
      "epoch": 10.084929340164358,
      "grad_norm": 0.4086694121360779,
      "learning_rate": 1.8496490572038908e-05,
      "loss": 0.031,
      "step": 293300
    },
    {
      "epoch": 10.088367774988825,
      "grad_norm": 0.13697199523448944,
      "learning_rate": 1.8485745232292756e-05,
      "loss": 0.0304,
      "step": 293400
    },
    {
      "epoch": 10.091806209813292,
      "grad_norm": 0.2129688262939453,
      "learning_rate": 1.8474999892546605e-05,
      "loss": 0.0318,
      "step": 293500
    },
    {
      "epoch": 10.095244644637761,
      "grad_norm": 0.4099033772945404,
      "learning_rate": 1.846425455280045e-05,
      "loss": 0.0339,
      "step": 293600
    },
    {
      "epoch": 10.098683079462228,
      "grad_norm": 0.10811250656843185,
      "learning_rate": 1.84535092130543e-05,
      "loss": 0.0338,
      "step": 293700
    },
    {
      "epoch": 10.102121514286697,
      "grad_norm": 0.41433602571487427,
      "learning_rate": 1.8442763873308148e-05,
      "loss": 0.0363,
      "step": 293800
    },
    {
      "epoch": 10.105559949111164,
      "grad_norm": 0.1422058492898941,
      "learning_rate": 1.8432018533561996e-05,
      "loss": 0.0304,
      "step": 293900
    },
    {
      "epoch": 10.108998383935633,
      "grad_norm": 0.8487994074821472,
      "learning_rate": 1.8421273193815845e-05,
      "loss": 0.0321,
      "step": 294000
    },
    {
      "epoch": 10.1124368187601,
      "grad_norm": 0.39258474111557007,
      "learning_rate": 1.841052785406969e-05,
      "loss": 0.0326,
      "step": 294100
    },
    {
      "epoch": 10.115875253584568,
      "grad_norm": 0.11709049344062805,
      "learning_rate": 1.839978251432354e-05,
      "loss": 0.0299,
      "step": 294200
    },
    {
      "epoch": 10.119313688409036,
      "grad_norm": 0.09596381336450577,
      "learning_rate": 1.8389037174577388e-05,
      "loss": 0.033,
      "step": 294300
    },
    {
      "epoch": 10.122752123233504,
      "grad_norm": 0.05963996425271034,
      "learning_rate": 1.8378291834831236e-05,
      "loss": 0.0299,
      "step": 294400
    },
    {
      "epoch": 10.126190558057973,
      "grad_norm": 0.06131009757518768,
      "learning_rate": 1.8367653948482543e-05,
      "loss": 0.0292,
      "step": 294500
    },
    {
      "epoch": 10.12962899288244,
      "grad_norm": 0.06337913125753403,
      "learning_rate": 1.835690860873639e-05,
      "loss": 0.031,
      "step": 294600
    },
    {
      "epoch": 10.133067427706909,
      "grad_norm": 0.1590069681406021,
      "learning_rate": 1.834616326899024e-05,
      "loss": 0.0327,
      "step": 294700
    },
    {
      "epoch": 10.136505862531376,
      "grad_norm": 0.3372907340526581,
      "learning_rate": 1.8335417929244085e-05,
      "loss": 0.0332,
      "step": 294800
    },
    {
      "epoch": 10.139944297355843,
      "grad_norm": 0.6333072185516357,
      "learning_rate": 1.8324672589497934e-05,
      "loss": 0.0333,
      "step": 294900
    },
    {
      "epoch": 10.143382732180312,
      "grad_norm": 0.19274626672267914,
      "learning_rate": 1.8313927249751783e-05,
      "loss": 0.0333,
      "step": 295000
    },
    {
      "epoch": 10.146821167004779,
      "grad_norm": 0.1254281997680664,
      "learning_rate": 1.830318191000563e-05,
      "loss": 0.0315,
      "step": 295100
    },
    {
      "epoch": 10.150259601829248,
      "grad_norm": 0.2797373831272125,
      "learning_rate": 1.829243657025948e-05,
      "loss": 0.0288,
      "step": 295200
    },
    {
      "epoch": 10.153698036653715,
      "grad_norm": 0.1524355709552765,
      "learning_rate": 1.8281691230513325e-05,
      "loss": 0.0321,
      "step": 295300
    },
    {
      "epoch": 10.157136471478184,
      "grad_norm": 0.05435919389128685,
      "learning_rate": 1.8270945890767174e-05,
      "loss": 0.033,
      "step": 295400
    },
    {
      "epoch": 10.160574906302651,
      "grad_norm": 0.15290533006191254,
      "learning_rate": 1.8260200551021023e-05,
      "loss": 0.0317,
      "step": 295500
    },
    {
      "epoch": 10.164013341127118,
      "grad_norm": 0.5458109974861145,
      "learning_rate": 1.824945521127487e-05,
      "loss": 0.0325,
      "step": 295600
    },
    {
      "epoch": 10.167451775951587,
      "grad_norm": 0.37266287207603455,
      "learning_rate": 1.823870987152872e-05,
      "loss": 0.0324,
      "step": 295700
    },
    {
      "epoch": 10.170890210776054,
      "grad_norm": 0.19234633445739746,
      "learning_rate": 1.822796453178257e-05,
      "loss": 0.0349,
      "step": 295800
    },
    {
      "epoch": 10.174328645600523,
      "grad_norm": 0.12871263921260834,
      "learning_rate": 1.8217219192036414e-05,
      "loss": 0.0355,
      "step": 295900
    },
    {
      "epoch": 10.17776708042499,
      "grad_norm": 0.19454215466976166,
      "learning_rate": 1.8206473852290263e-05,
      "loss": 0.0353,
      "step": 296000
    },
    {
      "epoch": 10.181205515249458,
      "grad_norm": 0.34345322847366333,
      "learning_rate": 1.819572851254411e-05,
      "loss": 0.0299,
      "step": 296100
    },
    {
      "epoch": 10.184643950073927,
      "grad_norm": 0.4232478141784668,
      "learning_rate": 1.818498317279796e-05,
      "loss": 0.0304,
      "step": 296200
    },
    {
      "epoch": 10.188082384898394,
      "grad_norm": 0.28898516297340393,
      "learning_rate": 1.817423783305181e-05,
      "loss": 0.0325,
      "step": 296300
    },
    {
      "epoch": 10.191520819722863,
      "grad_norm": 0.22482888400554657,
      "learning_rate": 1.8163492493305654e-05,
      "loss": 0.0355,
      "step": 296400
    },
    {
      "epoch": 10.19495925454733,
      "grad_norm": 0.07376062124967575,
      "learning_rate": 1.8152854606956964e-05,
      "loss": 0.0337,
      "step": 296500
    },
    {
      "epoch": 10.198397689371799,
      "grad_norm": 0.35497039556503296,
      "learning_rate": 1.8142216720608273e-05,
      "loss": 0.0344,
      "step": 296600
    },
    {
      "epoch": 10.201836124196266,
      "grad_norm": 0.08068981766700745,
      "learning_rate": 1.8131471380862122e-05,
      "loss": 0.0306,
      "step": 296700
    },
    {
      "epoch": 10.205274559020733,
      "grad_norm": 0.25552886724472046,
      "learning_rate": 1.8120726041115967e-05,
      "loss": 0.0328,
      "step": 296800
    },
    {
      "epoch": 10.208712993845202,
      "grad_norm": 0.12972423434257507,
      "learning_rate": 1.8109980701369816e-05,
      "loss": 0.0337,
      "step": 296900
    },
    {
      "epoch": 10.212151428669669,
      "grad_norm": 0.32763296365737915,
      "learning_rate": 1.8099235361623665e-05,
      "loss": 0.0323,
      "step": 297000
    },
    {
      "epoch": 10.215589863494138,
      "grad_norm": 0.335426926612854,
      "learning_rate": 1.8088490021877513e-05,
      "loss": 0.0305,
      "step": 297100
    },
    {
      "epoch": 10.219028298318605,
      "grad_norm": 0.14839909970760345,
      "learning_rate": 1.8077744682131362e-05,
      "loss": 0.0314,
      "step": 297200
    },
    {
      "epoch": 10.222466733143074,
      "grad_norm": 0.27175039052963257,
      "learning_rate": 1.8066999342385207e-05,
      "loss": 0.0351,
      "step": 297300
    },
    {
      "epoch": 10.225905167967541,
      "grad_norm": 0.2856709063053131,
      "learning_rate": 1.8056254002639056e-05,
      "loss": 0.0349,
      "step": 297400
    },
    {
      "epoch": 10.229343602792008,
      "grad_norm": 0.15823321044445038,
      "learning_rate": 1.8045508662892905e-05,
      "loss": 0.0299,
      "step": 297500
    },
    {
      "epoch": 10.232782037616477,
      "grad_norm": 0.14261648058891296,
      "learning_rate": 1.8034763323146753e-05,
      "loss": 0.0291,
      "step": 297600
    },
    {
      "epoch": 10.236220472440944,
      "grad_norm": 0.16173434257507324,
      "learning_rate": 1.8024017983400602e-05,
      "loss": 0.0342,
      "step": 297700
    },
    {
      "epoch": 10.239658907265413,
      "grad_norm": 0.3059254586696625,
      "learning_rate": 1.8013272643654447e-05,
      "loss": 0.0341,
      "step": 297800
    },
    {
      "epoch": 10.24309734208988,
      "grad_norm": 0.4909851849079132,
      "learning_rate": 1.8002527303908296e-05,
      "loss": 0.0324,
      "step": 297900
    },
    {
      "epoch": 10.24653577691435,
      "grad_norm": 0.18081989884376526,
      "learning_rate": 1.7991781964162145e-05,
      "loss": 0.0303,
      "step": 298000
    },
    {
      "epoch": 10.249974211738817,
      "grad_norm": 0.12730611860752106,
      "learning_rate": 1.7981036624415993e-05,
      "loss": 0.0355,
      "step": 298100
    },
    {
      "epoch": 10.253412646563284,
      "grad_norm": 0.553511917591095,
      "learning_rate": 1.7970291284669842e-05,
      "loss": 0.0339,
      "step": 298200
    },
    {
      "epoch": 10.256851081387753,
      "grad_norm": 0.0958951786160469,
      "learning_rate": 1.7959545944923687e-05,
      "loss": 0.0286,
      "step": 298300
    },
    {
      "epoch": 10.26028951621222,
      "grad_norm": 0.1112222746014595,
      "learning_rate": 1.7948800605177536e-05,
      "loss": 0.0304,
      "step": 298400
    },
    {
      "epoch": 10.263727951036689,
      "grad_norm": 0.10049312561750412,
      "learning_rate": 1.7938055265431385e-05,
      "loss": 0.0292,
      "step": 298500
    },
    {
      "epoch": 10.267166385861156,
      "grad_norm": 0.5838879942893982,
      "learning_rate": 1.7927309925685233e-05,
      "loss": 0.0304,
      "step": 298600
    },
    {
      "epoch": 10.270604820685623,
      "grad_norm": 0.0820595920085907,
      "learning_rate": 1.791656458593908e-05,
      "loss": 0.0326,
      "step": 298700
    },
    {
      "epoch": 10.274043255510092,
      "grad_norm": 0.12012197077274323,
      "learning_rate": 1.7905819246192927e-05,
      "loss": 0.0309,
      "step": 298800
    },
    {
      "epoch": 10.27748169033456,
      "grad_norm": 0.07395835220813751,
      "learning_rate": 1.7895073906446773e-05,
      "loss": 0.029,
      "step": 298900
    },
    {
      "epoch": 10.280920125159028,
      "grad_norm": 0.21288169920444489,
      "learning_rate": 1.788432856670062e-05,
      "loss": 0.0286,
      "step": 299000
    },
    {
      "epoch": 10.284358559983495,
      "grad_norm": 0.13645237684249878,
      "learning_rate": 1.787358322695447e-05,
      "loss": 0.0336,
      "step": 299100
    },
    {
      "epoch": 10.287796994807964,
      "grad_norm": 0.23540522158145905,
      "learning_rate": 1.786283788720832e-05,
      "loss": 0.0332,
      "step": 299200
    },
    {
      "epoch": 10.291235429632431,
      "grad_norm": 0.2693014442920685,
      "learning_rate": 1.7852092547462164e-05,
      "loss": 0.035,
      "step": 299300
    },
    {
      "epoch": 10.294673864456898,
      "grad_norm": 0.1784733235836029,
      "learning_rate": 1.7841347207716013e-05,
      "loss": 0.0312,
      "step": 299400
    },
    {
      "epoch": 10.298112299281367,
      "grad_norm": 0.3042905032634735,
      "learning_rate": 1.783060186796986e-05,
      "loss": 0.033,
      "step": 299500
    },
    {
      "epoch": 10.301550734105835,
      "grad_norm": 0.1794808954000473,
      "learning_rate": 1.781985652822371e-05,
      "loss": 0.0319,
      "step": 299600
    },
    {
      "epoch": 10.304989168930303,
      "grad_norm": 0.20617468655109406,
      "learning_rate": 1.780911118847756e-05,
      "loss": 0.0318,
      "step": 299700
    },
    {
      "epoch": 10.30842760375477,
      "grad_norm": 0.08480504155158997,
      "learning_rate": 1.7798365848731404e-05,
      "loss": 0.0314,
      "step": 299800
    },
    {
      "epoch": 10.31186603857924,
      "grad_norm": 0.380285382270813,
      "learning_rate": 1.7787620508985253e-05,
      "loss": 0.0263,
      "step": 299900
    },
    {
      "epoch": 10.315304473403707,
      "grad_norm": 0.3447032868862152,
      "learning_rate": 1.77768751692391e-05,
      "loss": 0.0331,
      "step": 300000
    },
    {
      "epoch": 10.318742908228174,
      "grad_norm": 0.13591496646404266,
      "learning_rate": 1.776612982949295e-05,
      "loss": 0.0306,
      "step": 300100
    },
    {
      "epoch": 10.322181343052643,
      "grad_norm": 0.11518465727567673,
      "learning_rate": 1.77553844897468e-05,
      "loss": 0.0313,
      "step": 300200
    },
    {
      "epoch": 10.32561977787711,
      "grad_norm": 0.668250560760498,
      "learning_rate": 1.7744639150000644e-05,
      "loss": 0.0329,
      "step": 300300
    },
    {
      "epoch": 10.329058212701579,
      "grad_norm": 0.15416061878204346,
      "learning_rate": 1.7733893810254493e-05,
      "loss": 0.032,
      "step": 300400
    },
    {
      "epoch": 10.332496647526046,
      "grad_norm": 0.2196778655052185,
      "learning_rate": 1.772314847050834e-05,
      "loss": 0.0302,
      "step": 300500
    },
    {
      "epoch": 10.335935082350513,
      "grad_norm": 0.17395026981830597,
      "learning_rate": 1.771240313076219e-05,
      "loss": 0.0318,
      "step": 300600
    },
    {
      "epoch": 10.339373517174982,
      "grad_norm": 0.1601167768239975,
      "learning_rate": 1.77017652444135e-05,
      "loss": 0.0308,
      "step": 300700
    },
    {
      "epoch": 10.34281195199945,
      "grad_norm": 0.3992578387260437,
      "learning_rate": 1.769101990466735e-05,
      "loss": 0.0352,
      "step": 300800
    },
    {
      "epoch": 10.346250386823918,
      "grad_norm": 0.3728373050689697,
      "learning_rate": 1.7680274564921197e-05,
      "loss": 0.0284,
      "step": 300900
    },
    {
      "epoch": 10.349688821648385,
      "grad_norm": 0.12213684618473053,
      "learning_rate": 1.7669529225175042e-05,
      "loss": 0.0337,
      "step": 301000
    },
    {
      "epoch": 10.353127256472854,
      "grad_norm": 0.2814265191555023,
      "learning_rate": 1.765878388542889e-05,
      "loss": 0.0315,
      "step": 301100
    },
    {
      "epoch": 10.356565691297321,
      "grad_norm": 0.11232741922140121,
      "learning_rate": 1.7648038545682736e-05,
      "loss": 0.0343,
      "step": 301200
    },
    {
      "epoch": 10.360004126121789,
      "grad_norm": 0.1374543309211731,
      "learning_rate": 1.7637293205936585e-05,
      "loss": 0.0323,
      "step": 301300
    },
    {
      "epoch": 10.363442560946257,
      "grad_norm": 0.14037516713142395,
      "learning_rate": 1.7626547866190434e-05,
      "loss": 0.0335,
      "step": 301400
    },
    {
      "epoch": 10.366880995770725,
      "grad_norm": 0.052684273570775986,
      "learning_rate": 1.7615802526444282e-05,
      "loss": 0.0343,
      "step": 301500
    },
    {
      "epoch": 10.370319430595194,
      "grad_norm": 0.12862715125083923,
      "learning_rate": 1.7605057186698128e-05,
      "loss": 0.0291,
      "step": 301600
    },
    {
      "epoch": 10.37375786541966,
      "grad_norm": 0.21490760147571564,
      "learning_rate": 1.7594311846951976e-05,
      "loss": 0.0327,
      "step": 301700
    },
    {
      "epoch": 10.37719630024413,
      "grad_norm": 0.09770217537879944,
      "learning_rate": 1.7583566507205825e-05,
      "loss": 0.0316,
      "step": 301800
    },
    {
      "epoch": 10.380634735068597,
      "grad_norm": 0.6756622791290283,
      "learning_rate": 1.7572821167459674e-05,
      "loss": 0.034,
      "step": 301900
    },
    {
      "epoch": 10.384073169893064,
      "grad_norm": 0.7389856576919556,
      "learning_rate": 1.7562075827713522e-05,
      "loss": 0.0313,
      "step": 302000
    },
    {
      "epoch": 10.387511604717533,
      "grad_norm": 0.3081577718257904,
      "learning_rate": 1.7551330487967368e-05,
      "loss": 0.0319,
      "step": 302100
    },
    {
      "epoch": 10.390950039542,
      "grad_norm": 1.3539042472839355,
      "learning_rate": 1.7540585148221216e-05,
      "loss": 0.0343,
      "step": 302200
    },
    {
      "epoch": 10.394388474366469,
      "grad_norm": 0.1516679972410202,
      "learning_rate": 1.7529839808475065e-05,
      "loss": 0.0296,
      "step": 302300
    },
    {
      "epoch": 10.397826909190936,
      "grad_norm": 0.11824854463338852,
      "learning_rate": 1.7519094468728914e-05,
      "loss": 0.0321,
      "step": 302400
    },
    {
      "epoch": 10.401265344015405,
      "grad_norm": 0.5213984251022339,
      "learning_rate": 1.7508349128982762e-05,
      "loss": 0.0314,
      "step": 302500
    },
    {
      "epoch": 10.404703778839872,
      "grad_norm": 0.24114100635051727,
      "learning_rate": 1.7497603789236608e-05,
      "loss": 0.033,
      "step": 302600
    },
    {
      "epoch": 10.40814221366434,
      "grad_norm": 0.43725112080574036,
      "learning_rate": 1.748696590288792e-05,
      "loss": 0.0324,
      "step": 302700
    },
    {
      "epoch": 10.411580648488808,
      "grad_norm": 0.47686758637428284,
      "learning_rate": 1.7476220563141766e-05,
      "loss": 0.0333,
      "step": 302800
    },
    {
      "epoch": 10.415019083313275,
      "grad_norm": 0.10751093178987503,
      "learning_rate": 1.7465475223395615e-05,
      "loss": 0.032,
      "step": 302900
    },
    {
      "epoch": 10.418457518137744,
      "grad_norm": 0.46405482292175293,
      "learning_rate": 1.7454729883649463e-05,
      "loss": 0.0318,
      "step": 303000
    },
    {
      "epoch": 10.421895952962211,
      "grad_norm": 0.18970179557800293,
      "learning_rate": 1.7443984543903312e-05,
      "loss": 0.0298,
      "step": 303100
    },
    {
      "epoch": 10.425334387786679,
      "grad_norm": 0.26870688796043396,
      "learning_rate": 1.7433346657554618e-05,
      "loss": 0.0333,
      "step": 303200
    },
    {
      "epoch": 10.428772822611148,
      "grad_norm": 0.15114592015743256,
      "learning_rate": 1.7422601317808467e-05,
      "loss": 0.0346,
      "step": 303300
    },
    {
      "epoch": 10.432211257435615,
      "grad_norm": 0.0914747416973114,
      "learning_rate": 1.7411855978062316e-05,
      "loss": 0.0291,
      "step": 303400
    },
    {
      "epoch": 10.435649692260084,
      "grad_norm": 0.17152144014835358,
      "learning_rate": 1.740111063831616e-05,
      "loss": 0.0318,
      "step": 303500
    },
    {
      "epoch": 10.43908812708455,
      "grad_norm": 0.07280327379703522,
      "learning_rate": 1.739036529857001e-05,
      "loss": 0.0336,
      "step": 303600
    },
    {
      "epoch": 10.44252656190902,
      "grad_norm": 0.18623808026313782,
      "learning_rate": 1.737961995882386e-05,
      "loss": 0.0317,
      "step": 303700
    },
    {
      "epoch": 10.445964996733487,
      "grad_norm": 0.18397116661071777,
      "learning_rate": 1.7368874619077707e-05,
      "loss": 0.0334,
      "step": 303800
    },
    {
      "epoch": 10.449403431557954,
      "grad_norm": 0.13198523223400116,
      "learning_rate": 1.7358129279331556e-05,
      "loss": 0.0338,
      "step": 303900
    },
    {
      "epoch": 10.452841866382423,
      "grad_norm": 0.04671928659081459,
      "learning_rate": 1.73473839395854e-05,
      "loss": 0.0318,
      "step": 304000
    },
    {
      "epoch": 10.45628030120689,
      "grad_norm": 0.07302248477935791,
      "learning_rate": 1.733663859983925e-05,
      "loss": 0.0325,
      "step": 304100
    },
    {
      "epoch": 10.459718736031359,
      "grad_norm": 0.14904677867889404,
      "learning_rate": 1.73258932600931e-05,
      "loss": 0.032,
      "step": 304200
    },
    {
      "epoch": 10.463157170855826,
      "grad_norm": 0.10491279512643814,
      "learning_rate": 1.7315147920346947e-05,
      "loss": 0.0327,
      "step": 304300
    },
    {
      "epoch": 10.466595605680295,
      "grad_norm": 0.30096763372421265,
      "learning_rate": 1.7304402580600796e-05,
      "loss": 0.0339,
      "step": 304400
    },
    {
      "epoch": 10.470034040504762,
      "grad_norm": 0.27852120995521545,
      "learning_rate": 1.729365724085464e-05,
      "loss": 0.0322,
      "step": 304500
    },
    {
      "epoch": 10.47347247532923,
      "grad_norm": 0.05386687442660332,
      "learning_rate": 1.728291190110849e-05,
      "loss": 0.0369,
      "step": 304600
    },
    {
      "epoch": 10.476910910153698,
      "grad_norm": 0.4222683608531952,
      "learning_rate": 1.727216656136234e-05,
      "loss": 0.0321,
      "step": 304700
    },
    {
      "epoch": 10.480349344978166,
      "grad_norm": 0.32193097472190857,
      "learning_rate": 1.7261421221616187e-05,
      "loss": 0.0309,
      "step": 304800
    },
    {
      "epoch": 10.483787779802634,
      "grad_norm": 0.3183857500553131,
      "learning_rate": 1.7250675881870036e-05,
      "loss": 0.0337,
      "step": 304900
    },
    {
      "epoch": 10.487226214627102,
      "grad_norm": 0.4578506648540497,
      "learning_rate": 1.723993054212388e-05,
      "loss": 0.0346,
      "step": 305000
    },
    {
      "epoch": 10.49066464945157,
      "grad_norm": 0.13123834133148193,
      "learning_rate": 1.722918520237773e-05,
      "loss": 0.0318,
      "step": 305100
    },
    {
      "epoch": 10.494103084276038,
      "grad_norm": 0.04425197094678879,
      "learning_rate": 1.721843986263158e-05,
      "loss": 0.0317,
      "step": 305200
    },
    {
      "epoch": 10.497541519100505,
      "grad_norm": 0.24939008057117462,
      "learning_rate": 1.7207694522885427e-05,
      "loss": 0.0317,
      "step": 305300
    },
    {
      "epoch": 10.500979953924974,
      "grad_norm": 0.17157426476478577,
      "learning_rate": 1.7196949183139276e-05,
      "loss": 0.0345,
      "step": 305400
    },
    {
      "epoch": 10.504418388749441,
      "grad_norm": 0.16512861847877502,
      "learning_rate": 1.718620384339312e-05,
      "loss": 0.0344,
      "step": 305500
    },
    {
      "epoch": 10.50785682357391,
      "grad_norm": 0.2851554751396179,
      "learning_rate": 1.717545850364697e-05,
      "loss": 0.031,
      "step": 305600
    },
    {
      "epoch": 10.511295258398377,
      "grad_norm": 0.13769908249378204,
      "learning_rate": 1.716471316390082e-05,
      "loss": 0.0308,
      "step": 305700
    },
    {
      "epoch": 10.514733693222844,
      "grad_norm": 0.4586954116821289,
      "learning_rate": 1.7153967824154664e-05,
      "loss": 0.0332,
      "step": 305800
    },
    {
      "epoch": 10.518172128047313,
      "grad_norm": 0.8034850358963013,
      "learning_rate": 1.7143222484408512e-05,
      "loss": 0.0339,
      "step": 305900
    },
    {
      "epoch": 10.52161056287178,
      "grad_norm": 0.18811361491680145,
      "learning_rate": 1.713247714466236e-05,
      "loss": 0.0339,
      "step": 306000
    },
    {
      "epoch": 10.52504899769625,
      "grad_norm": 0.10683984309434891,
      "learning_rate": 1.7121731804916206e-05,
      "loss": 0.03,
      "step": 306100
    },
    {
      "epoch": 10.528487432520716,
      "grad_norm": 0.12132542580366135,
      "learning_rate": 1.7110986465170055e-05,
      "loss": 0.0312,
      "step": 306200
    },
    {
      "epoch": 10.531925867345185,
      "grad_norm": 0.12509065866470337,
      "learning_rate": 1.7100241125423904e-05,
      "loss": 0.0331,
      "step": 306300
    },
    {
      "epoch": 10.535364302169652,
      "grad_norm": 0.308228999376297,
      "learning_rate": 1.7089495785677752e-05,
      "loss": 0.0301,
      "step": 306400
    },
    {
      "epoch": 10.53880273699412,
      "grad_norm": 0.2985842525959015,
      "learning_rate": 1.7078750445931598e-05,
      "loss": 0.0319,
      "step": 306500
    },
    {
      "epoch": 10.542241171818588,
      "grad_norm": 0.12900158762931824,
      "learning_rate": 1.7068005106185446e-05,
      "loss": 0.0297,
      "step": 306600
    },
    {
      "epoch": 10.545679606643056,
      "grad_norm": 0.1194344162940979,
      "learning_rate": 1.7057259766439295e-05,
      "loss": 0.0313,
      "step": 306700
    },
    {
      "epoch": 10.549118041467525,
      "grad_norm": 0.2727866768836975,
      "learning_rate": 1.7046514426693144e-05,
      "loss": 0.0328,
      "step": 306800
    },
    {
      "epoch": 10.552556476291992,
      "grad_norm": 0.18849144876003265,
      "learning_rate": 1.7035769086946992e-05,
      "loss": 0.0328,
      "step": 306900
    },
    {
      "epoch": 10.55599491111646,
      "grad_norm": 0.19657137989997864,
      "learning_rate": 1.702502374720084e-05,
      "loss": 0.0347,
      "step": 307000
    },
    {
      "epoch": 10.559433345940928,
      "grad_norm": 0.45959004759788513,
      "learning_rate": 1.7014278407454686e-05,
      "loss": 0.0368,
      "step": 307100
    },
    {
      "epoch": 10.562871780765395,
      "grad_norm": 0.11366944015026093,
      "learning_rate": 1.7003533067708535e-05,
      "loss": 0.0305,
      "step": 307200
    },
    {
      "epoch": 10.566310215589864,
      "grad_norm": 0.14870713651180267,
      "learning_rate": 1.6992787727962384e-05,
      "loss": 0.0338,
      "step": 307300
    },
    {
      "epoch": 10.569748650414331,
      "grad_norm": 0.6701621413230896,
      "learning_rate": 1.6982042388216232e-05,
      "loss": 0.0337,
      "step": 307400
    },
    {
      "epoch": 10.5731870852388,
      "grad_norm": 0.1985659897327423,
      "learning_rate": 1.697129704847008e-05,
      "loss": 0.0356,
      "step": 307500
    },
    {
      "epoch": 10.576625520063267,
      "grad_norm": 0.1128322184085846,
      "learning_rate": 1.6960551708723926e-05,
      "loss": 0.0328,
      "step": 307600
    },
    {
      "epoch": 10.580063954887734,
      "grad_norm": 0.10252890735864639,
      "learning_rate": 1.6949806368977775e-05,
      "loss": 0.0318,
      "step": 307700
    },
    {
      "epoch": 10.583502389712203,
      "grad_norm": 0.198902890086174,
      "learning_rate": 1.6939061029231624e-05,
      "loss": 0.0333,
      "step": 307800
    },
    {
      "epoch": 10.58694082453667,
      "grad_norm": 0.08475831896066666,
      "learning_rate": 1.6928315689485473e-05,
      "loss": 0.036,
      "step": 307900
    },
    {
      "epoch": 10.59037925936114,
      "grad_norm": 0.13498376309871674,
      "learning_rate": 1.6917677803136782e-05,
      "loss": 0.0342,
      "step": 308000
    },
    {
      "epoch": 10.593817694185606,
      "grad_norm": 0.20127908885478973,
      "learning_rate": 1.6906932463390627e-05,
      "loss": 0.0366,
      "step": 308100
    },
    {
      "epoch": 10.597256129010075,
      "grad_norm": 0.12151686102151871,
      "learning_rate": 1.6896187123644476e-05,
      "loss": 0.0336,
      "step": 308200
    },
    {
      "epoch": 10.600694563834542,
      "grad_norm": 0.3695388734340668,
      "learning_rate": 1.688544178389832e-05,
      "loss": 0.0337,
      "step": 308300
    },
    {
      "epoch": 10.60413299865901,
      "grad_norm": 0.0884656086564064,
      "learning_rate": 1.687469644415217e-05,
      "loss": 0.0311,
      "step": 308400
    },
    {
      "epoch": 10.607571433483479,
      "grad_norm": 0.13571573793888092,
      "learning_rate": 1.686395110440602e-05,
      "loss": 0.0353,
      "step": 308500
    },
    {
      "epoch": 10.611009868307946,
      "grad_norm": 0.2361643761396408,
      "learning_rate": 1.6853205764659867e-05,
      "loss": 0.0312,
      "step": 308600
    },
    {
      "epoch": 10.614448303132415,
      "grad_norm": 0.11932291835546494,
      "learning_rate": 1.6842460424913716e-05,
      "loss": 0.0325,
      "step": 308700
    },
    {
      "epoch": 10.617886737956882,
      "grad_norm": 0.10218243300914764,
      "learning_rate": 1.683171508516756e-05,
      "loss": 0.031,
      "step": 308800
    },
    {
      "epoch": 10.62132517278135,
      "grad_norm": 0.1639232337474823,
      "learning_rate": 1.682096974542141e-05,
      "loss": 0.034,
      "step": 308900
    },
    {
      "epoch": 10.624763607605818,
      "grad_norm": 0.1343051642179489,
      "learning_rate": 1.681022440567526e-05,
      "loss": 0.0301,
      "step": 309000
    },
    {
      "epoch": 10.628202042430285,
      "grad_norm": 0.1743195652961731,
      "learning_rate": 1.6799479065929107e-05,
      "loss": 0.0328,
      "step": 309100
    },
    {
      "epoch": 10.631640477254754,
      "grad_norm": 0.32598739862442017,
      "learning_rate": 1.6788733726182956e-05,
      "loss": 0.0345,
      "step": 309200
    },
    {
      "epoch": 10.635078912079221,
      "grad_norm": 0.2746061086654663,
      "learning_rate": 1.67779883864368e-05,
      "loss": 0.0323,
      "step": 309300
    },
    {
      "epoch": 10.63851734690369,
      "grad_norm": 0.24545763432979584,
      "learning_rate": 1.676724304669065e-05,
      "loss": 0.0322,
      "step": 309400
    },
    {
      "epoch": 10.641955781728157,
      "grad_norm": 0.15812437236309052,
      "learning_rate": 1.67564977069445e-05,
      "loss": 0.0338,
      "step": 309500
    },
    {
      "epoch": 10.645394216552626,
      "grad_norm": 0.37022900581359863,
      "learning_rate": 1.6745752367198348e-05,
      "loss": 0.0314,
      "step": 309600
    },
    {
      "epoch": 10.648832651377093,
      "grad_norm": 0.061496999114751816,
      "learning_rate": 1.6735007027452196e-05,
      "loss": 0.0308,
      "step": 309700
    },
    {
      "epoch": 10.65227108620156,
      "grad_norm": 0.10375656187534332,
      "learning_rate": 1.672426168770604e-05,
      "loss": 0.0316,
      "step": 309800
    },
    {
      "epoch": 10.65570952102603,
      "grad_norm": 0.25771012902259827,
      "learning_rate": 1.671351634795989e-05,
      "loss": 0.0321,
      "step": 309900
    },
    {
      "epoch": 10.659147955850496,
      "grad_norm": 0.16771313548088074,
      "learning_rate": 1.670277100821374e-05,
      "loss": 0.0334,
      "step": 310000
    },
    {
      "epoch": 10.662586390674965,
      "grad_norm": 0.22411054372787476,
      "learning_rate": 1.6692025668467588e-05,
      "loss": 0.0336,
      "step": 310100
    },
    {
      "epoch": 10.666024825499433,
      "grad_norm": 0.14820311963558197,
      "learning_rate": 1.6681280328721436e-05,
      "loss": 0.0329,
      "step": 310200
    },
    {
      "epoch": 10.669463260323901,
      "grad_norm": 0.36918526887893677,
      "learning_rate": 1.667053498897528e-05,
      "loss": 0.0283,
      "step": 310300
    },
    {
      "epoch": 10.672901695148369,
      "grad_norm": 0.0985659584403038,
      "learning_rate": 1.665978964922913e-05,
      "loss": 0.0343,
      "step": 310400
    },
    {
      "epoch": 10.676340129972836,
      "grad_norm": 0.29427510499954224,
      "learning_rate": 1.664904430948298e-05,
      "loss": 0.0323,
      "step": 310500
    },
    {
      "epoch": 10.679778564797305,
      "grad_norm": 0.4085349142551422,
      "learning_rate": 1.6638298969736828e-05,
      "loss": 0.032,
      "step": 310600
    },
    {
      "epoch": 10.683216999621772,
      "grad_norm": 0.08032131940126419,
      "learning_rate": 1.6627553629990676e-05,
      "loss": 0.0306,
      "step": 310700
    },
    {
      "epoch": 10.68665543444624,
      "grad_norm": 0.28436875343322754,
      "learning_rate": 1.661680829024452e-05,
      "loss": 0.0347,
      "step": 310800
    },
    {
      "epoch": 10.690093869270708,
      "grad_norm": 0.5456932187080383,
      "learning_rate": 1.660606295049837e-05,
      "loss": 0.0348,
      "step": 310900
    },
    {
      "epoch": 10.693532304095175,
      "grad_norm": 0.41460883617401123,
      "learning_rate": 1.659531761075222e-05,
      "loss": 0.0312,
      "step": 311000
    },
    {
      "epoch": 10.696970738919644,
      "grad_norm": 0.31942275166511536,
      "learning_rate": 1.6584572271006064e-05,
      "loss": 0.0358,
      "step": 311100
    },
    {
      "epoch": 10.700409173744111,
      "grad_norm": 0.18057595193386078,
      "learning_rate": 1.6573934384657374e-05,
      "loss": 0.0323,
      "step": 311200
    },
    {
      "epoch": 10.70384760856858,
      "grad_norm": 0.31600451469421387,
      "learning_rate": 1.6563189044911223e-05,
      "loss": 0.0344,
      "step": 311300
    },
    {
      "epoch": 10.707286043393047,
      "grad_norm": 0.34954819083213806,
      "learning_rate": 1.655244370516507e-05,
      "loss": 0.0321,
      "step": 311400
    },
    {
      "epoch": 10.710724478217516,
      "grad_norm": 0.3023189902305603,
      "learning_rate": 1.6541698365418917e-05,
      "loss": 0.0322,
      "step": 311500
    },
    {
      "epoch": 10.714162913041983,
      "grad_norm": 0.1779317706823349,
      "learning_rate": 1.6530953025672765e-05,
      "loss": 0.0327,
      "step": 311600
    },
    {
      "epoch": 10.71760134786645,
      "grad_norm": 0.2778303325176239,
      "learning_rate": 1.6520207685926614e-05,
      "loss": 0.0333,
      "step": 311700
    },
    {
      "epoch": 10.72103978269092,
      "grad_norm": 0.07342876493930817,
      "learning_rate": 1.6509462346180463e-05,
      "loss": 0.0325,
      "step": 311800
    },
    {
      "epoch": 10.724478217515387,
      "grad_norm": 0.2934260070323944,
      "learning_rate": 1.649871700643431e-05,
      "loss": 0.0325,
      "step": 311900
    },
    {
      "epoch": 10.727916652339855,
      "grad_norm": 0.05675162002444267,
      "learning_rate": 1.648797166668816e-05,
      "loss": 0.0353,
      "step": 312000
    },
    {
      "epoch": 10.731355087164323,
      "grad_norm": 0.48510509729385376,
      "learning_rate": 1.647733378033947e-05,
      "loss": 0.0322,
      "step": 312100
    },
    {
      "epoch": 10.734793521988792,
      "grad_norm": 0.30299460887908936,
      "learning_rate": 1.6466588440593318e-05,
      "loss": 0.0331,
      "step": 312200
    },
    {
      "epoch": 10.738231956813259,
      "grad_norm": 0.10626497864723206,
      "learning_rate": 1.6455843100847164e-05,
      "loss": 0.0312,
      "step": 312300
    },
    {
      "epoch": 10.741670391637726,
      "grad_norm": 0.11553531885147095,
      "learning_rate": 1.6445097761101012e-05,
      "loss": 0.0294,
      "step": 312400
    },
    {
      "epoch": 10.745108826462195,
      "grad_norm": 0.40065741539001465,
      "learning_rate": 1.643435242135486e-05,
      "loss": 0.0307,
      "step": 312500
    },
    {
      "epoch": 10.748547261286662,
      "grad_norm": 0.059523604810237885,
      "learning_rate": 1.6423607081608706e-05,
      "loss": 0.0329,
      "step": 312600
    },
    {
      "epoch": 10.75198569611113,
      "grad_norm": 0.060618504881858826,
      "learning_rate": 1.6412861741862555e-05,
      "loss": 0.0348,
      "step": 312700
    },
    {
      "epoch": 10.755424130935598,
      "grad_norm": 0.07724583148956299,
      "learning_rate": 1.6402116402116404e-05,
      "loss": 0.0341,
      "step": 312800
    },
    {
      "epoch": 10.758862565760065,
      "grad_norm": 0.27646133303642273,
      "learning_rate": 1.639137106237025e-05,
      "loss": 0.0343,
      "step": 312900
    },
    {
      "epoch": 10.762301000584534,
      "grad_norm": 0.3684157133102417,
      "learning_rate": 1.6380625722624098e-05,
      "loss": 0.0326,
      "step": 313000
    },
    {
      "epoch": 10.765739435409001,
      "grad_norm": 0.140107661485672,
      "learning_rate": 1.6369880382877946e-05,
      "loss": 0.0318,
      "step": 313100
    },
    {
      "epoch": 10.76917787023347,
      "grad_norm": 0.2017667293548584,
      "learning_rate": 1.6359135043131795e-05,
      "loss": 0.033,
      "step": 313200
    },
    {
      "epoch": 10.772616305057937,
      "grad_norm": 0.2697453498840332,
      "learning_rate": 1.634838970338564e-05,
      "loss": 0.0325,
      "step": 313300
    },
    {
      "epoch": 10.776054739882406,
      "grad_norm": 0.11978030949831009,
      "learning_rate": 1.633764436363949e-05,
      "loss": 0.0299,
      "step": 313400
    },
    {
      "epoch": 10.779493174706873,
      "grad_norm": 0.05389317125082016,
      "learning_rate": 1.6326899023893338e-05,
      "loss": 0.0322,
      "step": 313500
    },
    {
      "epoch": 10.78293160953134,
      "grad_norm": 0.3031795620918274,
      "learning_rate": 1.6316153684147186e-05,
      "loss": 0.0322,
      "step": 313600
    },
    {
      "epoch": 10.78637004435581,
      "grad_norm": 0.4154883027076721,
      "learning_rate": 1.6305408344401035e-05,
      "loss": 0.0307,
      "step": 313700
    },
    {
      "epoch": 10.789808479180277,
      "grad_norm": 0.4403482973575592,
      "learning_rate": 1.629466300465488e-05,
      "loss": 0.0314,
      "step": 313800
    },
    {
      "epoch": 10.793246914004746,
      "grad_norm": 0.2015272080898285,
      "learning_rate": 1.628391766490873e-05,
      "loss": 0.0324,
      "step": 313900
    },
    {
      "epoch": 10.796685348829213,
      "grad_norm": 0.15060120820999146,
      "learning_rate": 1.6273172325162578e-05,
      "loss": 0.0329,
      "step": 314000
    },
    {
      "epoch": 10.800123783653682,
      "grad_norm": 0.45628583431243896,
      "learning_rate": 1.6262426985416426e-05,
      "loss": 0.0295,
      "step": 314100
    },
    {
      "epoch": 10.803562218478149,
      "grad_norm": 0.32217860221862793,
      "learning_rate": 1.6251681645670275e-05,
      "loss": 0.0318,
      "step": 314200
    },
    {
      "epoch": 10.807000653302616,
      "grad_norm": 0.14934591948986053,
      "learning_rate": 1.624093630592412e-05,
      "loss": 0.0329,
      "step": 314300
    },
    {
      "epoch": 10.810439088127085,
      "grad_norm": 0.0648433268070221,
      "learning_rate": 1.623019096617797e-05,
      "loss": 0.0322,
      "step": 314400
    },
    {
      "epoch": 10.813877522951552,
      "grad_norm": 0.10123367607593536,
      "learning_rate": 1.6219445626431818e-05,
      "loss": 0.0307,
      "step": 314500
    },
    {
      "epoch": 10.817315957776021,
      "grad_norm": 0.2416323870420456,
      "learning_rate": 1.6208700286685666e-05,
      "loss": 0.0318,
      "step": 314600
    },
    {
      "epoch": 10.820754392600488,
      "grad_norm": 0.11644270271062851,
      "learning_rate": 1.6197954946939515e-05,
      "loss": 0.0312,
      "step": 314700
    },
    {
      "epoch": 10.824192827424955,
      "grad_norm": 0.2401510626077652,
      "learning_rate": 1.618720960719336e-05,
      "loss": 0.0328,
      "step": 314800
    },
    {
      "epoch": 10.827631262249424,
      "grad_norm": 0.21264907717704773,
      "learning_rate": 1.617646426744721e-05,
      "loss": 0.0342,
      "step": 314900
    },
    {
      "epoch": 10.831069697073891,
      "grad_norm": 0.2318071573972702,
      "learning_rate": 1.6165718927701058e-05,
      "loss": 0.0339,
      "step": 315000
    },
    {
      "epoch": 10.83450813189836,
      "grad_norm": 0.24066631495952606,
      "learning_rate": 1.6154973587954906e-05,
      "loss": 0.0328,
      "step": 315100
    },
    {
      "epoch": 10.837946566722827,
      "grad_norm": 0.41499871015548706,
      "learning_rate": 1.6144228248208755e-05,
      "loss": 0.0319,
      "step": 315200
    },
    {
      "epoch": 10.841385001547296,
      "grad_norm": 0.18723377585411072,
      "learning_rate": 1.61334829084626e-05,
      "loss": 0.0325,
      "step": 315300
    },
    {
      "epoch": 10.844823436371763,
      "grad_norm": 0.1379435509443283,
      "learning_rate": 1.612273756871645e-05,
      "loss": 0.0311,
      "step": 315400
    },
    {
      "epoch": 10.84826187119623,
      "grad_norm": 0.16742509603500366,
      "learning_rate": 1.6111992228970298e-05,
      "loss": 0.0341,
      "step": 315500
    },
    {
      "epoch": 10.8517003060207,
      "grad_norm": 0.14683657884597778,
      "learning_rate": 1.6101246889224146e-05,
      "loss": 0.0316,
      "step": 315600
    },
    {
      "epoch": 10.855138740845167,
      "grad_norm": 0.24336443841457367,
      "learning_rate": 1.609050154947799e-05,
      "loss": 0.0334,
      "step": 315700
    },
    {
      "epoch": 10.858577175669636,
      "grad_norm": 0.1926824450492859,
      "learning_rate": 1.607975620973184e-05,
      "loss": 0.0338,
      "step": 315800
    },
    {
      "epoch": 10.862015610494103,
      "grad_norm": 0.27033212780952454,
      "learning_rate": 1.6069010869985686e-05,
      "loss": 0.0301,
      "step": 315900
    },
    {
      "epoch": 10.865454045318572,
      "grad_norm": 0.11462073773145676,
      "learning_rate": 1.6058265530239534e-05,
      "loss": 0.0331,
      "step": 316000
    },
    {
      "epoch": 10.868892480143039,
      "grad_norm": 0.1935870200395584,
      "learning_rate": 1.6047520190493383e-05,
      "loss": 0.0322,
      "step": 316100
    },
    {
      "epoch": 10.872330914967506,
      "grad_norm": 0.4408571720123291,
      "learning_rate": 1.603677485074723e-05,
      "loss": 0.0326,
      "step": 316200
    },
    {
      "epoch": 10.875769349791975,
      "grad_norm": 0.10944703221321106,
      "learning_rate": 1.6026029511001077e-05,
      "loss": 0.0327,
      "step": 316300
    },
    {
      "epoch": 10.879207784616442,
      "grad_norm": 0.20771220326423645,
      "learning_rate": 1.601539162465239e-05,
      "loss": 0.03,
      "step": 316400
    },
    {
      "epoch": 10.882646219440911,
      "grad_norm": 0.17142388224601746,
      "learning_rate": 1.6004646284906235e-05,
      "loss": 0.0326,
      "step": 316500
    },
    {
      "epoch": 10.886084654265378,
      "grad_norm": 0.15958116948604584,
      "learning_rate": 1.5993900945160084e-05,
      "loss": 0.0324,
      "step": 316600
    },
    {
      "epoch": 10.889523089089847,
      "grad_norm": 0.12727007269859314,
      "learning_rate": 1.5983155605413933e-05,
      "loss": 0.0326,
      "step": 316700
    },
    {
      "epoch": 10.892961523914314,
      "grad_norm": 0.19441717863082886,
      "learning_rate": 1.597241026566778e-05,
      "loss": 0.0324,
      "step": 316800
    },
    {
      "epoch": 10.896399958738781,
      "grad_norm": 0.31306034326553345,
      "learning_rate": 1.596166492592163e-05,
      "loss": 0.0347,
      "step": 316900
    },
    {
      "epoch": 10.89983839356325,
      "grad_norm": 0.7803118824958801,
      "learning_rate": 1.5950919586175475e-05,
      "loss": 0.0318,
      "step": 317000
    },
    {
      "epoch": 10.903276828387718,
      "grad_norm": 0.12674228847026825,
      "learning_rate": 1.5940174246429324e-05,
      "loss": 0.0336,
      "step": 317100
    },
    {
      "epoch": 10.906715263212186,
      "grad_norm": 0.07244234532117844,
      "learning_rate": 1.5929428906683173e-05,
      "loss": 0.0305,
      "step": 317200
    },
    {
      "epoch": 10.910153698036654,
      "grad_norm": 0.11942937970161438,
      "learning_rate": 1.591868356693702e-05,
      "loss": 0.0321,
      "step": 317300
    },
    {
      "epoch": 10.913592132861123,
      "grad_norm": 0.1311875730752945,
      "learning_rate": 1.590793822719087e-05,
      "loss": 0.0308,
      "step": 317400
    },
    {
      "epoch": 10.91703056768559,
      "grad_norm": 0.10248033702373505,
      "learning_rate": 1.589719288744472e-05,
      "loss": 0.031,
      "step": 317500
    },
    {
      "epoch": 10.920469002510057,
      "grad_norm": 0.11257553845643997,
      "learning_rate": 1.5886447547698564e-05,
      "loss": 0.0322,
      "step": 317600
    },
    {
      "epoch": 10.923907437334526,
      "grad_norm": 0.23636677861213684,
      "learning_rate": 1.5875702207952413e-05,
      "loss": 0.0304,
      "step": 317700
    },
    {
      "epoch": 10.927345872158993,
      "grad_norm": 0.11763905733823776,
      "learning_rate": 1.586495686820626e-05,
      "loss": 0.0329,
      "step": 317800
    },
    {
      "epoch": 10.930784306983462,
      "grad_norm": 0.14354871213436127,
      "learning_rate": 1.585421152846011e-05,
      "loss": 0.0306,
      "step": 317900
    },
    {
      "epoch": 10.934222741807929,
      "grad_norm": 0.08010287582874298,
      "learning_rate": 1.5843466188713955e-05,
      "loss": 0.0308,
      "step": 318000
    },
    {
      "epoch": 10.937661176632396,
      "grad_norm": 0.12889158725738525,
      "learning_rate": 1.5832720848967804e-05,
      "loss": 0.0344,
      "step": 318100
    },
    {
      "epoch": 10.941099611456865,
      "grad_norm": 0.25378069281578064,
      "learning_rate": 1.582197550922165e-05,
      "loss": 0.0327,
      "step": 318200
    },
    {
      "epoch": 10.944538046281332,
      "grad_norm": 0.20593467354774475,
      "learning_rate": 1.5811230169475498e-05,
      "loss": 0.0327,
      "step": 318300
    },
    {
      "epoch": 10.947976481105801,
      "grad_norm": 0.07503917813301086,
      "learning_rate": 1.5800484829729347e-05,
      "loss": 0.0298,
      "step": 318400
    },
    {
      "epoch": 10.951414915930268,
      "grad_norm": 0.09305108338594437,
      "learning_rate": 1.5789739489983195e-05,
      "loss": 0.0324,
      "step": 318500
    },
    {
      "epoch": 10.954853350754737,
      "grad_norm": 0.14479944109916687,
      "learning_rate": 1.577899415023704e-05,
      "loss": 0.0345,
      "step": 318600
    },
    {
      "epoch": 10.958291785579204,
      "grad_norm": 0.22371414303779602,
      "learning_rate": 1.576824881049089e-05,
      "loss": 0.0342,
      "step": 318700
    },
    {
      "epoch": 10.961730220403672,
      "grad_norm": 0.08391276746988297,
      "learning_rate": 1.5757503470744738e-05,
      "loss": 0.0336,
      "step": 318800
    },
    {
      "epoch": 10.96516865522814,
      "grad_norm": 0.12643037736415863,
      "learning_rate": 1.5746758130998587e-05,
      "loss": 0.0345,
      "step": 318900
    },
    {
      "epoch": 10.968607090052608,
      "grad_norm": 0.08271029591560364,
      "learning_rate": 1.5736012791252435e-05,
      "loss": 0.0312,
      "step": 319000
    },
    {
      "epoch": 10.972045524877077,
      "grad_norm": 0.12817728519439697,
      "learning_rate": 1.572526745150628e-05,
      "loss": 0.0293,
      "step": 319100
    },
    {
      "epoch": 10.975483959701544,
      "grad_norm": 0.34207746386528015,
      "learning_rate": 1.571452211176013e-05,
      "loss": 0.0309,
      "step": 319200
    },
    {
      "epoch": 10.978922394526013,
      "grad_norm": 0.346890389919281,
      "learning_rate": 1.570388422541144e-05,
      "loss": 0.0375,
      "step": 319300
    },
    {
      "epoch": 10.98236082935048,
      "grad_norm": 0.0898086205124855,
      "learning_rate": 1.5693138885665288e-05,
      "loss": 0.0344,
      "step": 319400
    },
    {
      "epoch": 10.985799264174947,
      "grad_norm": 0.12711964547634125,
      "learning_rate": 1.5682393545919136e-05,
      "loss": 0.0301,
      "step": 319500
    },
    {
      "epoch": 10.989237698999416,
      "grad_norm": 0.41452762484550476,
      "learning_rate": 1.5671648206172985e-05,
      "loss": 0.0293,
      "step": 319600
    },
    {
      "epoch": 10.992676133823883,
      "grad_norm": 0.5802924633026123,
      "learning_rate": 1.5660902866426834e-05,
      "loss": 0.0338,
      "step": 319700
    },
    {
      "epoch": 10.996114568648352,
      "grad_norm": 0.16965636610984802,
      "learning_rate": 1.565015752668068e-05,
      "loss": 0.0343,
      "step": 319800
    },
    {
      "epoch": 10.999553003472819,
      "grad_norm": 0.21691931784152985,
      "learning_rate": 1.5639412186934528e-05,
      "loss": 0.0291,
      "step": 319900
    },
    {
      "epoch": 11.0,
      "eval_accuracy_macro_0.5": 0.9860652089118958,
      "eval_accuracy_micro_0.5": 0.9860652089118958,
      "eval_accuracy_weighted_0.5": 0.977146327495575,
      "eval_aucroc_macro": 0.923431932926178,
      "eval_aucroc_micro": 0.9281027913093567,
      "eval_aucroc_weighted": 0.925150990486145,
      "eval_f1_macro_0.5": 0.7913908362388611,
      "eval_f1_macro_0.6": 0.7798728346824646,
      "eval_f1_macro_0.7": 0.7563303112983704,
      "eval_f1_macro_0.8": 0.6213836669921875,
      "eval_f1_micro_0.5": 0.7993670701980591,
      "eval_f1_micro_0.6": 0.7900822162628174,
      "eval_f1_micro_0.7": 0.7704727649688721,
      "eval_f1_micro_0.8": 0.7335098385810852,
      "eval_f1_micro_0.9": 0.6499117612838745,
      "eval_f1_weighted_0.5": 0.7954167723655701,
      "eval_f1_weighted_0.6": 0.7829499840736389,
      "eval_f1_weighted_0.7": 0.7586132287979126,
      "eval_f1_weighted_0.8": 0.6160903573036194,
      "eval_loss": 0.030080532655119896,
      "eval_runtime": 1944.4959,
      "eval_samples_per_second": 29.896,
      "eval_steps_per_second": 3.737,
      "step": 319913
    },
    {
      "epoch": 11.002991438297286,
      "grad_norm": 0.4144335091114044,
      "learning_rate": 1.5628666847188376e-05,
      "loss": 0.0316,
      "step": 320000
    },
    {
      "epoch": 11.006429873121755,
      "grad_norm": 0.21502427756786346,
      "learning_rate": 1.5617921507442225e-05,
      "loss": 0.03,
      "step": 320100
    },
    {
      "epoch": 11.009868307946222,
      "grad_norm": 0.11026795953512192,
      "learning_rate": 1.560717616769607e-05,
      "loss": 0.0313,
      "step": 320200
    },
    {
      "epoch": 11.013306742770691,
      "grad_norm": 0.11530885845422745,
      "learning_rate": 1.559643082794992e-05,
      "loss": 0.0323,
      "step": 320300
    },
    {
      "epoch": 11.016745177595158,
      "grad_norm": 0.33637735247612,
      "learning_rate": 1.5585685488203768e-05,
      "loss": 0.0317,
      "step": 320400
    },
    {
      "epoch": 11.020183612419627,
      "grad_norm": 0.15583789348602295,
      "learning_rate": 1.5574940148457613e-05,
      "loss": 0.033,
      "step": 320500
    },
    {
      "epoch": 11.023622047244094,
      "grad_norm": 0.1998479664325714,
      "learning_rate": 1.5564194808711462e-05,
      "loss": 0.031,
      "step": 320600
    },
    {
      "epoch": 11.027060482068562,
      "grad_norm": 0.2629743218421936,
      "learning_rate": 1.555355692236277e-05,
      "loss": 0.032,
      "step": 320700
    },
    {
      "epoch": 11.03049891689303,
      "grad_norm": 0.1920090913772583,
      "learning_rate": 1.554281158261662e-05,
      "loss": 0.0327,
      "step": 320800
    },
    {
      "epoch": 11.033937351717498,
      "grad_norm": 0.2501097023487091,
      "learning_rate": 1.553206624287047e-05,
      "loss": 0.0331,
      "step": 320900
    },
    {
      "epoch": 11.037375786541967,
      "grad_norm": 0.24781695008277893,
      "learning_rate": 1.5521320903124314e-05,
      "loss": 0.0317,
      "step": 321000
    },
    {
      "epoch": 11.040814221366434,
      "grad_norm": 0.31554144620895386,
      "learning_rate": 1.5510575563378163e-05,
      "loss": 0.0292,
      "step": 321100
    },
    {
      "epoch": 11.044252656190903,
      "grad_norm": 0.3581957221031189,
      "learning_rate": 1.549983022363201e-05,
      "loss": 0.0312,
      "step": 321200
    },
    {
      "epoch": 11.04769109101537,
      "grad_norm": 0.26691561937332153,
      "learning_rate": 1.548908488388586e-05,
      "loss": 0.0328,
      "step": 321300
    },
    {
      "epoch": 11.051129525839837,
      "grad_norm": 0.14795784652233124,
      "learning_rate": 1.547833954413971e-05,
      "loss": 0.0298,
      "step": 321400
    },
    {
      "epoch": 11.054567960664306,
      "grad_norm": 0.5322697162628174,
      "learning_rate": 1.5467594204393554e-05,
      "loss": 0.0312,
      "step": 321500
    },
    {
      "epoch": 11.058006395488773,
      "grad_norm": 0.24243442714214325,
      "learning_rate": 1.5456848864647403e-05,
      "loss": 0.0299,
      "step": 321600
    },
    {
      "epoch": 11.061444830313242,
      "grad_norm": 0.12144187837839127,
      "learning_rate": 1.544610352490125e-05,
      "loss": 0.029,
      "step": 321700
    },
    {
      "epoch": 11.06488326513771,
      "grad_norm": 0.2234804332256317,
      "learning_rate": 1.54353581851551e-05,
      "loss": 0.0315,
      "step": 321800
    },
    {
      "epoch": 11.068321699962178,
      "grad_norm": 0.11139020323753357,
      "learning_rate": 1.542461284540895e-05,
      "loss": 0.0287,
      "step": 321900
    },
    {
      "epoch": 11.071760134786645,
      "grad_norm": 0.1918589323759079,
      "learning_rate": 1.5413867505662794e-05,
      "loss": 0.0284,
      "step": 322000
    },
    {
      "epoch": 11.075198569611112,
      "grad_norm": 0.14605927467346191,
      "learning_rate": 1.5403122165916643e-05,
      "loss": 0.0326,
      "step": 322100
    },
    {
      "epoch": 11.078637004435581,
      "grad_norm": 0.23844711482524872,
      "learning_rate": 1.539237682617049e-05,
      "loss": 0.0332,
      "step": 322200
    },
    {
      "epoch": 11.082075439260048,
      "grad_norm": 0.46350154280662537,
      "learning_rate": 1.538163148642434e-05,
      "loss": 0.033,
      "step": 322300
    },
    {
      "epoch": 11.085513874084517,
      "grad_norm": 0.20718662440776825,
      "learning_rate": 1.537088614667819e-05,
      "loss": 0.0349,
      "step": 322400
    },
    {
      "epoch": 11.088952308908985,
      "grad_norm": 0.46238207817077637,
      "learning_rate": 1.5360140806932034e-05,
      "loss": 0.0386,
      "step": 322500
    },
    {
      "epoch": 11.092390743733452,
      "grad_norm": 0.5658135414123535,
      "learning_rate": 1.5349395467185883e-05,
      "loss": 0.04,
      "step": 322600
    },
    {
      "epoch": 11.09582917855792,
      "grad_norm": 0.35610902309417725,
      "learning_rate": 1.533865012743973e-05,
      "loss": 0.0298,
      "step": 322700
    },
    {
      "epoch": 11.099267613382388,
      "grad_norm": 0.18565477430820465,
      "learning_rate": 1.5327904787693577e-05,
      "loss": 0.0317,
      "step": 322800
    },
    {
      "epoch": 11.102706048206857,
      "grad_norm": 0.14679858088493347,
      "learning_rate": 1.5317159447947425e-05,
      "loss": 0.0317,
      "step": 322900
    },
    {
      "epoch": 11.106144483031324,
      "grad_norm": 0.131211519241333,
      "learning_rate": 1.5306414108201274e-05,
      "loss": 0.0321,
      "step": 323000
    },
    {
      "epoch": 11.109582917855793,
      "grad_norm": 0.135823056101799,
      "learning_rate": 1.529566876845512e-05,
      "loss": 0.0328,
      "step": 323100
    },
    {
      "epoch": 11.11302135268026,
      "grad_norm": 0.40545573830604553,
      "learning_rate": 1.5284923428708968e-05,
      "loss": 0.0332,
      "step": 323200
    },
    {
      "epoch": 11.116459787504727,
      "grad_norm": 0.07674450427293777,
      "learning_rate": 1.5274178088962817e-05,
      "loss": 0.0319,
      "step": 323300
    },
    {
      "epoch": 11.119898222329196,
      "grad_norm": 1.0753215551376343,
      "learning_rate": 1.5263432749216665e-05,
      "loss": 0.0334,
      "step": 323400
    },
    {
      "epoch": 11.123336657153663,
      "grad_norm": 0.21800599992275238,
      "learning_rate": 1.5252687409470514e-05,
      "loss": 0.0307,
      "step": 323500
    },
    {
      "epoch": 11.126775091978132,
      "grad_norm": 0.22107315063476562,
      "learning_rate": 1.5241942069724361e-05,
      "loss": 0.0288,
      "step": 323600
    },
    {
      "epoch": 11.1302135268026,
      "grad_norm": 0.11158333718776703,
      "learning_rate": 1.5231196729978208e-05,
      "loss": 0.0317,
      "step": 323700
    },
    {
      "epoch": 11.133651961627068,
      "grad_norm": 0.2348404973745346,
      "learning_rate": 1.5220451390232057e-05,
      "loss": 0.0322,
      "step": 323800
    },
    {
      "epoch": 11.137090396451535,
      "grad_norm": 0.39208468794822693,
      "learning_rate": 1.5209706050485905e-05,
      "loss": 0.0332,
      "step": 323900
    },
    {
      "epoch": 11.140528831276002,
      "grad_norm": 0.2202828824520111,
      "learning_rate": 1.5198960710739754e-05,
      "loss": 0.0303,
      "step": 324000
    },
    {
      "epoch": 11.143967266100471,
      "grad_norm": 0.13157431781291962,
      "learning_rate": 1.51882153709936e-05,
      "loss": 0.0343,
      "step": 324100
    },
    {
      "epoch": 11.147405700924939,
      "grad_norm": 0.13164442777633667,
      "learning_rate": 1.5177470031247448e-05,
      "loss": 0.029,
      "step": 324200
    },
    {
      "epoch": 11.150844135749407,
      "grad_norm": 0.105425626039505,
      "learning_rate": 1.5166724691501297e-05,
      "loss": 0.0332,
      "step": 324300
    },
    {
      "epoch": 11.154282570573875,
      "grad_norm": 0.219721257686615,
      "learning_rate": 1.5155979351755146e-05,
      "loss": 0.0308,
      "step": 324400
    },
    {
      "epoch": 11.157721005398344,
      "grad_norm": 0.15168261528015137,
      "learning_rate": 1.5145234012008994e-05,
      "loss": 0.0349,
      "step": 324500
    },
    {
      "epoch": 11.16115944022281,
      "grad_norm": 0.555916428565979,
      "learning_rate": 1.513448867226284e-05,
      "loss": 0.0329,
      "step": 324600
    },
    {
      "epoch": 11.164597875047278,
      "grad_norm": 0.33061498403549194,
      "learning_rate": 1.5123743332516688e-05,
      "loss": 0.029,
      "step": 324700
    },
    {
      "epoch": 11.168036309871747,
      "grad_norm": 0.23129692673683167,
      "learning_rate": 1.5112997992770537e-05,
      "loss": 0.0341,
      "step": 324800
    },
    {
      "epoch": 11.171474744696214,
      "grad_norm": 0.12518198788166046,
      "learning_rate": 1.5102252653024384e-05,
      "loss": 0.0301,
      "step": 324900
    },
    {
      "epoch": 11.174913179520683,
      "grad_norm": 0.09762317687273026,
      "learning_rate": 1.5091507313278233e-05,
      "loss": 0.0299,
      "step": 325000
    },
    {
      "epoch": 11.17835161434515,
      "grad_norm": 0.24099400639533997,
      "learning_rate": 1.508076197353208e-05,
      "loss": 0.0323,
      "step": 325100
    },
    {
      "epoch": 11.181790049169617,
      "grad_norm": 0.12577702105045319,
      "learning_rate": 1.5070016633785927e-05,
      "loss": 0.0296,
      "step": 325200
    },
    {
      "epoch": 11.185228483994086,
      "grad_norm": 0.10720426589250565,
      "learning_rate": 1.5059271294039775e-05,
      "loss": 0.0299,
      "step": 325300
    },
    {
      "epoch": 11.188666918818553,
      "grad_norm": 0.4682602882385254,
      "learning_rate": 1.5048633407691085e-05,
      "loss": 0.0344,
      "step": 325400
    },
    {
      "epoch": 11.192105353643022,
      "grad_norm": 0.34355953335762024,
      "learning_rate": 1.5037888067944934e-05,
      "loss": 0.0349,
      "step": 325500
    },
    {
      "epoch": 11.19554378846749,
      "grad_norm": 0.09153740853071213,
      "learning_rate": 1.5027142728198782e-05,
      "loss": 0.0304,
      "step": 325600
    },
    {
      "epoch": 11.198982223291958,
      "grad_norm": 0.15741512179374695,
      "learning_rate": 1.501639738845263e-05,
      "loss": 0.0313,
      "step": 325700
    },
    {
      "epoch": 11.202420658116425,
      "grad_norm": 0.15845714509487152,
      "learning_rate": 1.5005652048706476e-05,
      "loss": 0.0289,
      "step": 325800
    },
    {
      "epoch": 11.205859092940893,
      "grad_norm": 0.557195782661438,
      "learning_rate": 1.4994906708960325e-05,
      "loss": 0.0314,
      "step": 325900
    },
    {
      "epoch": 11.209297527765361,
      "grad_norm": 0.18127553164958954,
      "learning_rate": 1.4984161369214172e-05,
      "loss": 0.0324,
      "step": 326000
    },
    {
      "epoch": 11.212735962589829,
      "grad_norm": 0.1575690060853958,
      "learning_rate": 1.497341602946802e-05,
      "loss": 0.0344,
      "step": 326100
    },
    {
      "epoch": 11.216174397414298,
      "grad_norm": 0.1455802172422409,
      "learning_rate": 1.496267068972187e-05,
      "loss": 0.0289,
      "step": 326200
    },
    {
      "epoch": 11.219612832238765,
      "grad_norm": 0.0879678800702095,
      "learning_rate": 1.4951925349975715e-05,
      "loss": 0.0307,
      "step": 326300
    },
    {
      "epoch": 11.223051267063234,
      "grad_norm": 0.1736762374639511,
      "learning_rate": 1.4941180010229563e-05,
      "loss": 0.0294,
      "step": 326400
    },
    {
      "epoch": 11.2264897018877,
      "grad_norm": 0.14730016887187958,
      "learning_rate": 1.4930434670483412e-05,
      "loss": 0.0326,
      "step": 326500
    },
    {
      "epoch": 11.229928136712168,
      "grad_norm": 0.8214172720909119,
      "learning_rate": 1.491968933073726e-05,
      "loss": 0.0318,
      "step": 326600
    },
    {
      "epoch": 11.233366571536637,
      "grad_norm": 0.6722052693367004,
      "learning_rate": 1.490894399099111e-05,
      "loss": 0.0319,
      "step": 326700
    },
    {
      "epoch": 11.236805006361104,
      "grad_norm": 0.16909238696098328,
      "learning_rate": 1.4898198651244955e-05,
      "loss": 0.0278,
      "step": 326800
    },
    {
      "epoch": 11.240243441185573,
      "grad_norm": 0.20900101959705353,
      "learning_rate": 1.4887453311498803e-05,
      "loss": 0.0303,
      "step": 326900
    },
    {
      "epoch": 11.24368187601004,
      "grad_norm": 0.7244646549224854,
      "learning_rate": 1.4876707971752652e-05,
      "loss": 0.0338,
      "step": 327000
    },
    {
      "epoch": 11.247120310834507,
      "grad_norm": 0.23110152781009674,
      "learning_rate": 1.486607008540396e-05,
      "loss": 0.0324,
      "step": 327100
    },
    {
      "epoch": 11.250558745658976,
      "grad_norm": 0.3763173222541809,
      "learning_rate": 1.4855324745657809e-05,
      "loss": 0.0326,
      "step": 327200
    },
    {
      "epoch": 11.253997180483443,
      "grad_norm": 0.1656598299741745,
      "learning_rate": 1.4844579405911657e-05,
      "loss": 0.0324,
      "step": 327300
    },
    {
      "epoch": 11.257435615307912,
      "grad_norm": 0.106440968811512,
      "learning_rate": 1.4833834066165506e-05,
      "loss": 0.0333,
      "step": 327400
    },
    {
      "epoch": 11.26087405013238,
      "grad_norm": 0.2453012615442276,
      "learning_rate": 1.4823088726419351e-05,
      "loss": 0.032,
      "step": 327500
    },
    {
      "epoch": 11.264312484956848,
      "grad_norm": 0.08894402533769608,
      "learning_rate": 1.48123433866732e-05,
      "loss": 0.0312,
      "step": 327600
    },
    {
      "epoch": 11.267750919781315,
      "grad_norm": 0.17335735261440277,
      "learning_rate": 1.4801598046927049e-05,
      "loss": 0.0315,
      "step": 327700
    },
    {
      "epoch": 11.271189354605783,
      "grad_norm": 0.14953695237636566,
      "learning_rate": 1.4790852707180897e-05,
      "loss": 0.0308,
      "step": 327800
    },
    {
      "epoch": 11.274627789430252,
      "grad_norm": 0.561809241771698,
      "learning_rate": 1.4780107367434746e-05,
      "loss": 0.0336,
      "step": 327900
    },
    {
      "epoch": 11.278066224254719,
      "grad_norm": 0.18442319333553314,
      "learning_rate": 1.4769362027688591e-05,
      "loss": 0.0331,
      "step": 328000
    },
    {
      "epoch": 11.281504659079188,
      "grad_norm": 0.09744993597269058,
      "learning_rate": 1.475861668794244e-05,
      "loss": 0.0316,
      "step": 328100
    },
    {
      "epoch": 11.284943093903655,
      "grad_norm": 0.20288164913654327,
      "learning_rate": 1.4747871348196287e-05,
      "loss": 0.0295,
      "step": 328200
    },
    {
      "epoch": 11.288381528728124,
      "grad_norm": 0.43702372908592224,
      "learning_rate": 1.4737126008450136e-05,
      "loss": 0.03,
      "step": 328300
    },
    {
      "epoch": 11.29181996355259,
      "grad_norm": 0.32667872309684753,
      "learning_rate": 1.4726380668703984e-05,
      "loss": 0.032,
      "step": 328400
    },
    {
      "epoch": 11.295258398377058,
      "grad_norm": 0.12588472664356232,
      "learning_rate": 1.4715635328957833e-05,
      "loss": 0.0326,
      "step": 328500
    },
    {
      "epoch": 11.298696833201527,
      "grad_norm": 0.16733120381832123,
      "learning_rate": 1.4704889989211678e-05,
      "loss": 0.0325,
      "step": 328600
    },
    {
      "epoch": 11.302135268025994,
      "grad_norm": 0.169023334980011,
      "learning_rate": 1.4694144649465527e-05,
      "loss": 0.0308,
      "step": 328700
    },
    {
      "epoch": 11.305573702850463,
      "grad_norm": 0.17396476864814758,
      "learning_rate": 1.4683399309719376e-05,
      "loss": 0.0305,
      "step": 328800
    },
    {
      "epoch": 11.30901213767493,
      "grad_norm": 0.2351507842540741,
      "learning_rate": 1.4672653969973224e-05,
      "loss": 0.0354,
      "step": 328900
    },
    {
      "epoch": 11.3124505724994,
      "grad_norm": 0.11176495999097824,
      "learning_rate": 1.4661908630227073e-05,
      "loss": 0.0367,
      "step": 329000
    },
    {
      "epoch": 11.315889007323866,
      "grad_norm": 0.22938275337219238,
      "learning_rate": 1.4651163290480918e-05,
      "loss": 0.0294,
      "step": 329100
    },
    {
      "epoch": 11.319327442148333,
      "grad_norm": 0.1025756299495697,
      "learning_rate": 1.4640417950734767e-05,
      "loss": 0.0324,
      "step": 329200
    },
    {
      "epoch": 11.322765876972802,
      "grad_norm": 0.1580677330493927,
      "learning_rate": 1.4629672610988616e-05,
      "loss": 0.0334,
      "step": 329300
    },
    {
      "epoch": 11.32620431179727,
      "grad_norm": 0.24143850803375244,
      "learning_rate": 1.4618927271242464e-05,
      "loss": 0.0331,
      "step": 329400
    },
    {
      "epoch": 11.329642746621738,
      "grad_norm": 0.1772792637348175,
      "learning_rate": 1.4608181931496311e-05,
      "loss": 0.0299,
      "step": 329500
    },
    {
      "epoch": 11.333081181446206,
      "grad_norm": 0.11653381586074829,
      "learning_rate": 1.4597436591750158e-05,
      "loss": 0.0304,
      "step": 329600
    },
    {
      "epoch": 11.336519616270675,
      "grad_norm": 0.3504071533679962,
      "learning_rate": 1.4586691252004005e-05,
      "loss": 0.031,
      "step": 329700
    },
    {
      "epoch": 11.339958051095142,
      "grad_norm": 0.2211769074201584,
      "learning_rate": 1.4575945912257854e-05,
      "loss": 0.0315,
      "step": 329800
    },
    {
      "epoch": 11.343396485919609,
      "grad_norm": 0.08887558430433273,
      "learning_rate": 1.4565200572511703e-05,
      "loss": 0.0318,
      "step": 329900
    },
    {
      "epoch": 11.346834920744078,
      "grad_norm": 0.6370178461074829,
      "learning_rate": 1.4554455232765551e-05,
      "loss": 0.03,
      "step": 330000
    },
    {
      "epoch": 11.350273355568545,
      "grad_norm": 0.1566113829612732,
      "learning_rate": 1.4543709893019397e-05,
      "loss": 0.0292,
      "step": 330100
    },
    {
      "epoch": 11.353711790393014,
      "grad_norm": 0.18357597291469574,
      "learning_rate": 1.4532964553273245e-05,
      "loss": 0.0284,
      "step": 330200
    },
    {
      "epoch": 11.357150225217481,
      "grad_norm": 0.23443438112735748,
      "learning_rate": 1.4522219213527094e-05,
      "loss": 0.0307,
      "step": 330300
    },
    {
      "epoch": 11.360588660041948,
      "grad_norm": 0.11906622350215912,
      "learning_rate": 1.4511473873780943e-05,
      "loss": 0.0332,
      "step": 330400
    },
    {
      "epoch": 11.364027094866417,
      "grad_norm": 0.20095279812812805,
      "learning_rate": 1.4500728534034791e-05,
      "loss": 0.0326,
      "step": 330500
    },
    {
      "epoch": 11.367465529690884,
      "grad_norm": 0.23003177344799042,
      "learning_rate": 1.4489983194288637e-05,
      "loss": 0.0335,
      "step": 330600
    },
    {
      "epoch": 11.370903964515353,
      "grad_norm": 0.3307036757469177,
      "learning_rate": 1.4479237854542485e-05,
      "loss": 0.0304,
      "step": 330700
    },
    {
      "epoch": 11.37434239933982,
      "grad_norm": 0.09595616906881332,
      "learning_rate": 1.4468492514796334e-05,
      "loss": 0.0315,
      "step": 330800
    },
    {
      "epoch": 11.37778083416429,
      "grad_norm": 0.15967509150505066,
      "learning_rate": 1.4457747175050183e-05,
      "loss": 0.032,
      "step": 330900
    },
    {
      "epoch": 11.381219268988756,
      "grad_norm": 0.193669855594635,
      "learning_rate": 1.444700183530403e-05,
      "loss": 0.0318,
      "step": 331000
    },
    {
      "epoch": 11.384657703813224,
      "grad_norm": 0.2701661288738251,
      "learning_rate": 1.443636394895534e-05,
      "loss": 0.0326,
      "step": 331100
    },
    {
      "epoch": 11.388096138637692,
      "grad_norm": 0.3448553681373596,
      "learning_rate": 1.4425618609209188e-05,
      "loss": 0.0316,
      "step": 331200
    },
    {
      "epoch": 11.39153457346216,
      "grad_norm": 0.08553224802017212,
      "learning_rate": 1.4414873269463033e-05,
      "loss": 0.033,
      "step": 331300
    },
    {
      "epoch": 11.394973008286629,
      "grad_norm": 0.1825137883424759,
      "learning_rate": 1.4404127929716882e-05,
      "loss": 0.0348,
      "step": 331400
    },
    {
      "epoch": 11.398411443111096,
      "grad_norm": 0.11701200902462006,
      "learning_rate": 1.439338258997073e-05,
      "loss": 0.0318,
      "step": 331500
    },
    {
      "epoch": 11.401849877935565,
      "grad_norm": 0.06572102010250092,
      "learning_rate": 1.438263725022458e-05,
      "loss": 0.0273,
      "step": 331600
    },
    {
      "epoch": 11.405288312760032,
      "grad_norm": 0.23973535001277924,
      "learning_rate": 1.4371891910478428e-05,
      "loss": 0.0308,
      "step": 331700
    },
    {
      "epoch": 11.408726747584499,
      "grad_norm": 0.19608469307422638,
      "learning_rate": 1.4361146570732273e-05,
      "loss": 0.0328,
      "step": 331800
    },
    {
      "epoch": 11.412165182408968,
      "grad_norm": 0.13856875896453857,
      "learning_rate": 1.4350508684383585e-05,
      "loss": 0.0334,
      "step": 331900
    },
    {
      "epoch": 11.415603617233435,
      "grad_norm": 0.3696756660938263,
      "learning_rate": 1.433976334463743e-05,
      "loss": 0.032,
      "step": 332000
    },
    {
      "epoch": 11.419042052057904,
      "grad_norm": 0.28143829107284546,
      "learning_rate": 1.4329018004891279e-05,
      "loss": 0.0344,
      "step": 332100
    },
    {
      "epoch": 11.422480486882371,
      "grad_norm": 0.25160202383995056,
      "learning_rate": 1.4318272665145127e-05,
      "loss": 0.0331,
      "step": 332200
    },
    {
      "epoch": 11.425918921706838,
      "grad_norm": 0.27024516463279724,
      "learning_rate": 1.4307527325398976e-05,
      "loss": 0.0342,
      "step": 332300
    },
    {
      "epoch": 11.429357356531307,
      "grad_norm": 0.4244014024734497,
      "learning_rate": 1.4296781985652825e-05,
      "loss": 0.0332,
      "step": 332400
    },
    {
      "epoch": 11.432795791355774,
      "grad_norm": 0.35033470392227173,
      "learning_rate": 1.428603664590667e-05,
      "loss": 0.0318,
      "step": 332500
    },
    {
      "epoch": 11.436234226180243,
      "grad_norm": 0.11284242570400238,
      "learning_rate": 1.4275291306160519e-05,
      "loss": 0.0325,
      "step": 332600
    },
    {
      "epoch": 11.43967266100471,
      "grad_norm": 0.15005050599575043,
      "learning_rate": 1.4264545966414367e-05,
      "loss": 0.0311,
      "step": 332700
    },
    {
      "epoch": 11.44311109582918,
      "grad_norm": 0.09037231653928757,
      "learning_rate": 1.4253800626668214e-05,
      "loss": 0.0304,
      "step": 332800
    },
    {
      "epoch": 11.446549530653646,
      "grad_norm": 0.24716722965240479,
      "learning_rate": 1.4243055286922063e-05,
      "loss": 0.0317,
      "step": 332900
    },
    {
      "epoch": 11.449987965478114,
      "grad_norm": 0.29473334550857544,
      "learning_rate": 1.423230994717591e-05,
      "loss": 0.0333,
      "step": 333000
    },
    {
      "epoch": 11.453426400302583,
      "grad_norm": 0.44415366649627686,
      "learning_rate": 1.4221564607429757e-05,
      "loss": 0.0336,
      "step": 333100
    },
    {
      "epoch": 11.45686483512705,
      "grad_norm": 0.2049691081047058,
      "learning_rate": 1.4210819267683606e-05,
      "loss": 0.0309,
      "step": 333200
    },
    {
      "epoch": 11.460303269951519,
      "grad_norm": 0.2870310842990875,
      "learning_rate": 1.4200073927937454e-05,
      "loss": 0.0306,
      "step": 333300
    },
    {
      "epoch": 11.463741704775986,
      "grad_norm": 0.38507527112960815,
      "learning_rate": 1.4189328588191303e-05,
      "loss": 0.034,
      "step": 333400
    },
    {
      "epoch": 11.467180139600455,
      "grad_norm": 0.16816994547843933,
      "learning_rate": 1.4178583248445152e-05,
      "loss": 0.0316,
      "step": 333500
    },
    {
      "epoch": 11.470618574424922,
      "grad_norm": 0.18075019121170044,
      "learning_rate": 1.4167837908698997e-05,
      "loss": 0.0296,
      "step": 333600
    },
    {
      "epoch": 11.474057009249389,
      "grad_norm": 0.36331450939178467,
      "learning_rate": 1.4157092568952846e-05,
      "loss": 0.0322,
      "step": 333700
    },
    {
      "epoch": 11.477495444073858,
      "grad_norm": 0.22722071409225464,
      "learning_rate": 1.4146347229206694e-05,
      "loss": 0.0319,
      "step": 333800
    },
    {
      "epoch": 11.480933878898325,
      "grad_norm": 0.2479674369096756,
      "learning_rate": 1.4135601889460543e-05,
      "loss": 0.0315,
      "step": 333900
    },
    {
      "epoch": 11.484372313722794,
      "grad_norm": 0.34735023975372314,
      "learning_rate": 1.4124856549714392e-05,
      "loss": 0.0334,
      "step": 334000
    },
    {
      "epoch": 11.487810748547261,
      "grad_norm": 0.18758101761341095,
      "learning_rate": 1.4114111209968237e-05,
      "loss": 0.0301,
      "step": 334100
    },
    {
      "epoch": 11.491249183371728,
      "grad_norm": 0.32541579008102417,
      "learning_rate": 1.4103365870222086e-05,
      "loss": 0.0286,
      "step": 334200
    },
    {
      "epoch": 11.494687618196197,
      "grad_norm": 0.13998077809810638,
      "learning_rate": 1.4092620530475933e-05,
      "loss": 0.0341,
      "step": 334300
    },
    {
      "epoch": 11.498126053020664,
      "grad_norm": 0.22009605169296265,
      "learning_rate": 1.4081875190729781e-05,
      "loss": 0.0365,
      "step": 334400
    },
    {
      "epoch": 11.501564487845133,
      "grad_norm": 0.284900039434433,
      "learning_rate": 1.407112985098363e-05,
      "loss": 0.0319,
      "step": 334500
    },
    {
      "epoch": 11.5050029226696,
      "grad_norm": 0.17840127646923065,
      "learning_rate": 1.4060384511237475e-05,
      "loss": 0.0336,
      "step": 334600
    },
    {
      "epoch": 11.50844135749407,
      "grad_norm": 0.24417895078659058,
      "learning_rate": 1.4049639171491324e-05,
      "loss": 0.0315,
      "step": 334700
    },
    {
      "epoch": 11.511879792318537,
      "grad_norm": 0.1751941442489624,
      "learning_rate": 1.4038893831745173e-05,
      "loss": 0.0346,
      "step": 334800
    },
    {
      "epoch": 11.515318227143004,
      "grad_norm": 0.3418242931365967,
      "learning_rate": 1.4028148491999021e-05,
      "loss": 0.0349,
      "step": 334900
    },
    {
      "epoch": 11.518756661967473,
      "grad_norm": 0.11680509895086288,
      "learning_rate": 1.401740315225287e-05,
      "loss": 0.0312,
      "step": 335000
    },
    {
      "epoch": 11.52219509679194,
      "grad_norm": 0.23688748478889465,
      "learning_rate": 1.4006657812506715e-05,
      "loss": 0.0319,
      "step": 335100
    },
    {
      "epoch": 11.525633531616409,
      "grad_norm": 0.24221691489219666,
      "learning_rate": 1.3995912472760564e-05,
      "loss": 0.0294,
      "step": 335200
    },
    {
      "epoch": 11.529071966440876,
      "grad_norm": 0.19118911027908325,
      "learning_rate": 1.3985167133014413e-05,
      "loss": 0.0317,
      "step": 335300
    },
    {
      "epoch": 11.532510401265345,
      "grad_norm": 1.510367751121521,
      "learning_rate": 1.3974421793268261e-05,
      "loss": 0.0319,
      "step": 335400
    },
    {
      "epoch": 11.535948836089812,
      "grad_norm": 0.43138229846954346,
      "learning_rate": 1.396367645352211e-05,
      "loss": 0.0323,
      "step": 335500
    },
    {
      "epoch": 11.539387270914279,
      "grad_norm": 0.10024265944957733,
      "learning_rate": 1.3952931113775955e-05,
      "loss": 0.0302,
      "step": 335600
    },
    {
      "epoch": 11.542825705738748,
      "grad_norm": 0.4719792306423187,
      "learning_rate": 1.3942185774029804e-05,
      "loss": 0.0315,
      "step": 335700
    },
    {
      "epoch": 11.546264140563215,
      "grad_norm": 0.0812317430973053,
      "learning_rate": 1.3931440434283651e-05,
      "loss": 0.0295,
      "step": 335800
    },
    {
      "epoch": 11.549702575387684,
      "grad_norm": 0.1306333690881729,
      "learning_rate": 1.39206950945375e-05,
      "loss": 0.033,
      "step": 335900
    },
    {
      "epoch": 11.553141010212151,
      "grad_norm": 0.12590661644935608,
      "learning_rate": 1.3909949754791348e-05,
      "loss": 0.0264,
      "step": 336000
    },
    {
      "epoch": 11.55657944503662,
      "grad_norm": 0.2461063265800476,
      "learning_rate": 1.3899204415045194e-05,
      "loss": 0.0339,
      "step": 336100
    },
    {
      "epoch": 11.560017879861087,
      "grad_norm": 0.20694059133529663,
      "learning_rate": 1.3888459075299042e-05,
      "loss": 0.0354,
      "step": 336200
    },
    {
      "epoch": 11.563456314685554,
      "grad_norm": 0.4706999361515045,
      "learning_rate": 1.3877821188950352e-05,
      "loss": 0.0313,
      "step": 336300
    },
    {
      "epoch": 11.566894749510023,
      "grad_norm": 0.34693971276283264,
      "learning_rate": 1.3867183302601663e-05,
      "loss": 0.0294,
      "step": 336400
    },
    {
      "epoch": 11.57033318433449,
      "grad_norm": 0.18602697551250458,
      "learning_rate": 1.3856437962855509e-05,
      "loss": 0.0297,
      "step": 336500
    },
    {
      "epoch": 11.57377161915896,
      "grad_norm": 0.16059443354606628,
      "learning_rate": 1.3845692623109357e-05,
      "loss": 0.029,
      "step": 336600
    },
    {
      "epoch": 11.577210053983427,
      "grad_norm": 0.6647694110870361,
      "learning_rate": 1.3834947283363206e-05,
      "loss": 0.0312,
      "step": 336700
    },
    {
      "epoch": 11.580648488807896,
      "grad_norm": 0.14366409182548523,
      "learning_rate": 1.3824201943617055e-05,
      "loss": 0.0314,
      "step": 336800
    },
    {
      "epoch": 11.584086923632363,
      "grad_norm": 0.08412306755781174,
      "learning_rate": 1.3813456603870903e-05,
      "loss": 0.0308,
      "step": 336900
    },
    {
      "epoch": 11.58752535845683,
      "grad_norm": 0.09986259043216705,
      "learning_rate": 1.3802711264124749e-05,
      "loss": 0.0326,
      "step": 337000
    },
    {
      "epoch": 11.590963793281299,
      "grad_norm": 0.12164480239152908,
      "learning_rate": 1.3791965924378597e-05,
      "loss": 0.0303,
      "step": 337100
    },
    {
      "epoch": 11.594402228105766,
      "grad_norm": 0.2503896653652191,
      "learning_rate": 1.3781220584632446e-05,
      "loss": 0.0322,
      "step": 337200
    },
    {
      "epoch": 11.597840662930235,
      "grad_norm": 0.12810955941677094,
      "learning_rate": 1.3770475244886295e-05,
      "loss": 0.0317,
      "step": 337300
    },
    {
      "epoch": 11.601279097754702,
      "grad_norm": 0.09709461778402328,
      "learning_rate": 1.3759729905140142e-05,
      "loss": 0.0301,
      "step": 337400
    },
    {
      "epoch": 11.60471753257917,
      "grad_norm": 0.3260085880756378,
      "learning_rate": 1.3748984565393989e-05,
      "loss": 0.0327,
      "step": 337500
    },
    {
      "epoch": 11.608155967403638,
      "grad_norm": 0.1421639621257782,
      "learning_rate": 1.3738239225647836e-05,
      "loss": 0.0348,
      "step": 337600
    },
    {
      "epoch": 11.611594402228105,
      "grad_norm": 0.16691473126411438,
      "learning_rate": 1.3727493885901684e-05,
      "loss": 0.0317,
      "step": 337700
    },
    {
      "epoch": 11.615032837052574,
      "grad_norm": 0.18035189807415009,
      "learning_rate": 1.3716748546155533e-05,
      "loss": 0.027,
      "step": 337800
    },
    {
      "epoch": 11.618471271877041,
      "grad_norm": 0.3900512456893921,
      "learning_rate": 1.3706003206409382e-05,
      "loss": 0.0309,
      "step": 337900
    },
    {
      "epoch": 11.62190970670151,
      "grad_norm": 0.13695037364959717,
      "learning_rate": 1.3695257866663227e-05,
      "loss": 0.0317,
      "step": 338000
    },
    {
      "epoch": 11.625348141525977,
      "grad_norm": 0.13530007004737854,
      "learning_rate": 1.3684512526917076e-05,
      "loss": 0.0355,
      "step": 338100
    },
    {
      "epoch": 11.628786576350445,
      "grad_norm": 0.08693164587020874,
      "learning_rate": 1.3673767187170924e-05,
      "loss": 0.0303,
      "step": 338200
    },
    {
      "epoch": 11.632225011174913,
      "grad_norm": 0.10541235655546188,
      "learning_rate": 1.3663021847424773e-05,
      "loss": 0.0324,
      "step": 338300
    },
    {
      "epoch": 11.63566344599938,
      "grad_norm": 0.14476695656776428,
      "learning_rate": 1.3652276507678622e-05,
      "loss": 0.0329,
      "step": 338400
    },
    {
      "epoch": 11.63910188082385,
      "grad_norm": 0.15154875814914703,
      "learning_rate": 1.3641531167932467e-05,
      "loss": 0.0278,
      "step": 338500
    },
    {
      "epoch": 11.642540315648317,
      "grad_norm": 0.2673952877521515,
      "learning_rate": 1.3630785828186316e-05,
      "loss": 0.0269,
      "step": 338600
    },
    {
      "epoch": 11.645978750472786,
      "grad_norm": 0.13909584283828735,
      "learning_rate": 1.3620040488440164e-05,
      "loss": 0.0354,
      "step": 338700
    },
    {
      "epoch": 11.649417185297253,
      "grad_norm": 0.23145702481269836,
      "learning_rate": 1.3609295148694013e-05,
      "loss": 0.0327,
      "step": 338800
    },
    {
      "epoch": 11.65285562012172,
      "grad_norm": 0.09824790805578232,
      "learning_rate": 1.359854980894786e-05,
      "loss": 0.032,
      "step": 338900
    },
    {
      "epoch": 11.656294054946189,
      "grad_norm": 0.3013884723186493,
      "learning_rate": 1.3587804469201709e-05,
      "loss": 0.031,
      "step": 339000
    },
    {
      "epoch": 11.659732489770656,
      "grad_norm": 0.40547874569892883,
      "learning_rate": 1.3577059129455554e-05,
      "loss": 0.0305,
      "step": 339100
    },
    {
      "epoch": 11.663170924595125,
      "grad_norm": 0.06621517241001129,
      "learning_rate": 1.3566313789709403e-05,
      "loss": 0.0318,
      "step": 339200
    },
    {
      "epoch": 11.666609359419592,
      "grad_norm": 0.31050488352775574,
      "learning_rate": 1.3555568449963251e-05,
      "loss": 0.0327,
      "step": 339300
    },
    {
      "epoch": 11.67004779424406,
      "grad_norm": 0.1161452978849411,
      "learning_rate": 1.35448231102171e-05,
      "loss": 0.0287,
      "step": 339400
    },
    {
      "epoch": 11.673486229068528,
      "grad_norm": 0.30344337224960327,
      "learning_rate": 1.3534077770470949e-05,
      "loss": 0.0337,
      "step": 339500
    },
    {
      "epoch": 11.676924663892995,
      "grad_norm": 0.18309788405895233,
      "learning_rate": 1.3523332430724794e-05,
      "loss": 0.0312,
      "step": 339600
    },
    {
      "epoch": 11.680363098717464,
      "grad_norm": 0.20450012385845184,
      "learning_rate": 1.3512587090978643e-05,
      "loss": 0.0323,
      "step": 339700
    },
    {
      "epoch": 11.683801533541931,
      "grad_norm": 0.11887753009796143,
      "learning_rate": 1.3501841751232491e-05,
      "loss": 0.0306,
      "step": 339800
    },
    {
      "epoch": 11.6872399683664,
      "grad_norm": 0.19699321687221527,
      "learning_rate": 1.349109641148634e-05,
      "loss": 0.03,
      "step": 339900
    },
    {
      "epoch": 11.690678403190867,
      "grad_norm": 0.11048144102096558,
      "learning_rate": 1.3480351071740189e-05,
      "loss": 0.0305,
      "step": 340000
    },
    {
      "epoch": 11.694116838015335,
      "grad_norm": 0.23917919397354126,
      "learning_rate": 1.3469713185391497e-05,
      "loss": 0.0314,
      "step": 340100
    },
    {
      "epoch": 11.697555272839804,
      "grad_norm": 0.2929377853870392,
      "learning_rate": 1.3458967845645345e-05,
      "loss": 0.0336,
      "step": 340200
    },
    {
      "epoch": 11.70099370766427,
      "grad_norm": 0.09728480130434036,
      "learning_rate": 1.344822250589919e-05,
      "loss": 0.0304,
      "step": 340300
    },
    {
      "epoch": 11.70443214248874,
      "grad_norm": 0.34820520877838135,
      "learning_rate": 1.343747716615304e-05,
      "loss": 0.0281,
      "step": 340400
    },
    {
      "epoch": 11.707870577313207,
      "grad_norm": 0.2522757053375244,
      "learning_rate": 1.3426731826406888e-05,
      "loss": 0.0336,
      "step": 340500
    },
    {
      "epoch": 11.711309012137676,
      "grad_norm": 0.43231597542762756,
      "learning_rate": 1.3415986486660737e-05,
      "loss": 0.0298,
      "step": 340600
    },
    {
      "epoch": 11.714747446962143,
      "grad_norm": 0.05699988082051277,
      "learning_rate": 1.3405241146914585e-05,
      "loss": 0.0335,
      "step": 340700
    },
    {
      "epoch": 11.71818588178661,
      "grad_norm": 0.2477443963289261,
      "learning_rate": 1.339449580716843e-05,
      "loss": 0.0292,
      "step": 340800
    },
    {
      "epoch": 11.721624316611079,
      "grad_norm": 0.102091483771801,
      "learning_rate": 1.338375046742228e-05,
      "loss": 0.0331,
      "step": 340900
    },
    {
      "epoch": 11.725062751435546,
      "grad_norm": 0.22315925359725952,
      "learning_rate": 1.3373005127676128e-05,
      "loss": 0.0302,
      "step": 341000
    },
    {
      "epoch": 11.728501186260015,
      "grad_norm": 0.08319558948278427,
      "learning_rate": 1.3362259787929977e-05,
      "loss": 0.032,
      "step": 341100
    },
    {
      "epoch": 11.731939621084482,
      "grad_norm": 0.09489408880472183,
      "learning_rate": 1.3351514448183824e-05,
      "loss": 0.0308,
      "step": 341200
    },
    {
      "epoch": 11.73537805590895,
      "grad_norm": 0.3162175416946411,
      "learning_rate": 1.334076910843767e-05,
      "loss": 0.0332,
      "step": 341300
    },
    {
      "epoch": 11.738816490733418,
      "grad_norm": 0.18510977923870087,
      "learning_rate": 1.3330023768691518e-05,
      "loss": 0.0317,
      "step": 341400
    },
    {
      "epoch": 11.742254925557885,
      "grad_norm": 0.10461410880088806,
      "learning_rate": 1.3319278428945366e-05,
      "loss": 0.0313,
      "step": 341500
    },
    {
      "epoch": 11.745693360382354,
      "grad_norm": 0.1737472414970398,
      "learning_rate": 1.3308533089199215e-05,
      "loss": 0.0326,
      "step": 341600
    },
    {
      "epoch": 11.749131795206821,
      "grad_norm": 0.06680682301521301,
      "learning_rate": 1.3297787749453064e-05,
      "loss": 0.0313,
      "step": 341700
    },
    {
      "epoch": 11.75257023003129,
      "grad_norm": 0.3497888445854187,
      "learning_rate": 1.3287042409706909e-05,
      "loss": 0.033,
      "step": 341800
    },
    {
      "epoch": 11.756008664855758,
      "grad_norm": 0.23145101964473724,
      "learning_rate": 1.3276297069960758e-05,
      "loss": 0.033,
      "step": 341900
    },
    {
      "epoch": 11.759447099680227,
      "grad_norm": 0.21471881866455078,
      "learning_rate": 1.3265551730214607e-05,
      "loss": 0.0307,
      "step": 342000
    },
    {
      "epoch": 11.762885534504694,
      "grad_norm": 0.3008374869823456,
      "learning_rate": 1.3254806390468455e-05,
      "loss": 0.0273,
      "step": 342100
    },
    {
      "epoch": 11.76632396932916,
      "grad_norm": 0.35300254821777344,
      "learning_rate": 1.3244061050722304e-05,
      "loss": 0.0297,
      "step": 342200
    },
    {
      "epoch": 11.76976240415363,
      "grad_norm": 0.35524192452430725,
      "learning_rate": 1.323331571097615e-05,
      "loss": 0.029,
      "step": 342300
    },
    {
      "epoch": 11.773200838978097,
      "grad_norm": 0.0998140275478363,
      "learning_rate": 1.3222570371229998e-05,
      "loss": 0.0332,
      "step": 342400
    },
    {
      "epoch": 11.776639273802566,
      "grad_norm": 0.18189877271652222,
      "learning_rate": 1.3211825031483847e-05,
      "loss": 0.0324,
      "step": 342500
    },
    {
      "epoch": 11.780077708627033,
      "grad_norm": 0.07025047391653061,
      "learning_rate": 1.3201079691737695e-05,
      "loss": 0.0312,
      "step": 342600
    },
    {
      "epoch": 11.7835161434515,
      "grad_norm": 0.3733048737049103,
      "learning_rate": 1.3190334351991542e-05,
      "loss": 0.0345,
      "step": 342700
    },
    {
      "epoch": 11.786954578275969,
      "grad_norm": 0.32692405581474304,
      "learning_rate": 1.317958901224539e-05,
      "loss": 0.0339,
      "step": 342800
    },
    {
      "epoch": 11.790393013100436,
      "grad_norm": 0.19045834243297577,
      "learning_rate": 1.3168843672499236e-05,
      "loss": 0.0315,
      "step": 342900
    },
    {
      "epoch": 11.793831447924905,
      "grad_norm": 0.23853428661823273,
      "learning_rate": 1.3158098332753085e-05,
      "loss": 0.0331,
      "step": 343000
    },
    {
      "epoch": 11.797269882749372,
      "grad_norm": 0.35779625177383423,
      "learning_rate": 1.3147352993006934e-05,
      "loss": 0.0319,
      "step": 343100
    },
    {
      "epoch": 11.800708317573841,
      "grad_norm": 0.1848064661026001,
      "learning_rate": 1.3136607653260782e-05,
      "loss": 0.0308,
      "step": 343200
    },
    {
      "epoch": 11.804146752398308,
      "grad_norm": 0.2599000036716461,
      "learning_rate": 1.3125862313514628e-05,
      "loss": 0.0338,
      "step": 343300
    },
    {
      "epoch": 11.807585187222776,
      "grad_norm": 0.211164653301239,
      "learning_rate": 1.3115116973768476e-05,
      "loss": 0.0323,
      "step": 343400
    },
    {
      "epoch": 11.811023622047244,
      "grad_norm": 0.11109404265880585,
      "learning_rate": 1.3104479087419786e-05,
      "loss": 0.0286,
      "step": 343500
    },
    {
      "epoch": 11.814462056871712,
      "grad_norm": 0.21551860868930817,
      "learning_rate": 1.3093733747673635e-05,
      "loss": 0.0334,
      "step": 343600
    },
    {
      "epoch": 11.81790049169618,
      "grad_norm": 0.7614363431930542,
      "learning_rate": 1.3082988407927482e-05,
      "loss": 0.0309,
      "step": 343700
    },
    {
      "epoch": 11.821338926520648,
      "grad_norm": 0.24584230780601501,
      "learning_rate": 1.307224306818133e-05,
      "loss": 0.0313,
      "step": 343800
    },
    {
      "epoch": 11.824777361345117,
      "grad_norm": 0.10374350845813751,
      "learning_rate": 1.3061497728435179e-05,
      "loss": 0.0329,
      "step": 343900
    },
    {
      "epoch": 11.828215796169584,
      "grad_norm": 0.08957556635141373,
      "learning_rate": 1.3050752388689024e-05,
      "loss": 0.0312,
      "step": 344000
    },
    {
      "epoch": 11.831654230994051,
      "grad_norm": 0.40849822759628296,
      "learning_rate": 1.3040007048942873e-05,
      "loss": 0.0365,
      "step": 344100
    },
    {
      "epoch": 11.83509266581852,
      "grad_norm": 0.4173130989074707,
      "learning_rate": 1.3029261709196722e-05,
      "loss": 0.0345,
      "step": 344200
    },
    {
      "epoch": 11.838531100642987,
      "grad_norm": 0.18212741613388062,
      "learning_rate": 1.301851636945057e-05,
      "loss": 0.0356,
      "step": 344300
    },
    {
      "epoch": 11.841969535467456,
      "grad_norm": 0.4848736524581909,
      "learning_rate": 1.3007771029704419e-05,
      "loss": 0.0291,
      "step": 344400
    },
    {
      "epoch": 11.845407970291923,
      "grad_norm": 0.21606013178825378,
      "learning_rate": 1.2997025689958268e-05,
      "loss": 0.0322,
      "step": 344500
    },
    {
      "epoch": 11.84884640511639,
      "grad_norm": 0.1716015487909317,
      "learning_rate": 1.2986280350212113e-05,
      "loss": 0.0308,
      "step": 344600
    },
    {
      "epoch": 11.85228483994086,
      "grad_norm": 0.3683498501777649,
      "learning_rate": 1.2975535010465962e-05,
      "loss": 0.031,
      "step": 344700
    },
    {
      "epoch": 11.855723274765326,
      "grad_norm": 0.1955859363079071,
      "learning_rate": 1.296478967071981e-05,
      "loss": 0.0271,
      "step": 344800
    },
    {
      "epoch": 11.859161709589795,
      "grad_norm": 0.13576851785182953,
      "learning_rate": 1.2954044330973659e-05,
      "loss": 0.0314,
      "step": 344900
    },
    {
      "epoch": 11.862600144414262,
      "grad_norm": 0.12480566650629044,
      "learning_rate": 1.2943298991227506e-05,
      "loss": 0.0315,
      "step": 345000
    },
    {
      "epoch": 11.866038579238731,
      "grad_norm": 0.11849773675203323,
      "learning_rate": 1.2932553651481353e-05,
      "loss": 0.0329,
      "step": 345100
    },
    {
      "epoch": 11.869477014063198,
      "grad_norm": 0.07286746799945831,
      "learning_rate": 1.29218083117352e-05,
      "loss": 0.0335,
      "step": 345200
    },
    {
      "epoch": 11.872915448887666,
      "grad_norm": 0.40474337339401245,
      "learning_rate": 1.2911062971989049e-05,
      "loss": 0.0296,
      "step": 345300
    },
    {
      "epoch": 11.876353883712135,
      "grad_norm": 0.16013287007808685,
      "learning_rate": 1.2900317632242897e-05,
      "loss": 0.0298,
      "step": 345400
    },
    {
      "epoch": 11.879792318536602,
      "grad_norm": 0.18871250748634338,
      "learning_rate": 1.2889572292496746e-05,
      "loss": 0.0303,
      "step": 345500
    },
    {
      "epoch": 11.88323075336107,
      "grad_norm": 0.3826790452003479,
      "learning_rate": 1.2878826952750591e-05,
      "loss": 0.0308,
      "step": 345600
    },
    {
      "epoch": 11.886669188185538,
      "grad_norm": 0.4090689718723297,
      "learning_rate": 1.286808161300444e-05,
      "loss": 0.0319,
      "step": 345700
    },
    {
      "epoch": 11.890107623010007,
      "grad_norm": 0.3381612002849579,
      "learning_rate": 1.2857336273258289e-05,
      "loss": 0.0309,
      "step": 345800
    },
    {
      "epoch": 11.893546057834474,
      "grad_norm": 0.23796877264976501,
      "learning_rate": 1.2846590933512137e-05,
      "loss": 0.032,
      "step": 345900
    },
    {
      "epoch": 11.896984492658941,
      "grad_norm": 0.08720812201499939,
      "learning_rate": 1.2835845593765986e-05,
      "loss": 0.0331,
      "step": 346000
    },
    {
      "epoch": 11.90042292748341,
      "grad_norm": 0.45722582936286926,
      "learning_rate": 1.2825100254019831e-05,
      "loss": 0.0316,
      "step": 346100
    },
    {
      "epoch": 11.903861362307877,
      "grad_norm": 0.17690540850162506,
      "learning_rate": 1.281435491427368e-05,
      "loss": 0.0329,
      "step": 346200
    },
    {
      "epoch": 11.907299797132346,
      "grad_norm": 0.11188311129808426,
      "learning_rate": 1.2803609574527529e-05,
      "loss": 0.0336,
      "step": 346300
    },
    {
      "epoch": 11.910738231956813,
      "grad_norm": 0.21681930124759674,
      "learning_rate": 1.2792864234781377e-05,
      "loss": 0.0346,
      "step": 346400
    },
    {
      "epoch": 11.91417666678128,
      "grad_norm": 0.5617921948432922,
      "learning_rate": 1.2782118895035224e-05,
      "loss": 0.0327,
      "step": 346500
    },
    {
      "epoch": 11.91761510160575,
      "grad_norm": 0.06589075922966003,
      "learning_rate": 1.2771373555289071e-05,
      "loss": 0.0302,
      "step": 346600
    },
    {
      "epoch": 11.921053536430216,
      "grad_norm": 0.12277229130268097,
      "learning_rate": 1.2760628215542918e-05,
      "loss": 0.0333,
      "step": 346700
    },
    {
      "epoch": 11.924491971254685,
      "grad_norm": 0.32120320200920105,
      "learning_rate": 1.2749882875796767e-05,
      "loss": 0.0307,
      "step": 346800
    },
    {
      "epoch": 11.927930406079152,
      "grad_norm": 0.16547584533691406,
      "learning_rate": 1.2739137536050616e-05,
      "loss": 0.0293,
      "step": 346900
    },
    {
      "epoch": 11.931368840903621,
      "grad_norm": 0.39087414741516113,
      "learning_rate": 1.2728499649701925e-05,
      "loss": 0.0315,
      "step": 347000
    },
    {
      "epoch": 11.934807275728089,
      "grad_norm": 0.4615529477596283,
      "learning_rate": 1.2717754309955774e-05,
      "loss": 0.0332,
      "step": 347100
    },
    {
      "epoch": 11.938245710552556,
      "grad_norm": 0.3958636224269867,
      "learning_rate": 1.2707008970209621e-05,
      "loss": 0.0348,
      "step": 347200
    },
    {
      "epoch": 11.941684145377025,
      "grad_norm": 0.1510176956653595,
      "learning_rate": 1.2696263630463468e-05,
      "loss": 0.0347,
      "step": 347300
    },
    {
      "epoch": 11.945122580201492,
      "grad_norm": 0.09654037654399872,
      "learning_rate": 1.2685518290717317e-05,
      "loss": 0.0309,
      "step": 347400
    },
    {
      "epoch": 11.94856101502596,
      "grad_norm": 0.12464994937181473,
      "learning_rate": 1.2674772950971164e-05,
      "loss": 0.0306,
      "step": 347500
    },
    {
      "epoch": 11.951999449850428,
      "grad_norm": 0.1485084444284439,
      "learning_rate": 1.2664027611225012e-05,
      "loss": 0.0292,
      "step": 347600
    },
    {
      "epoch": 11.955437884674897,
      "grad_norm": 0.08779069036245346,
      "learning_rate": 1.2653282271478861e-05,
      "loss": 0.0281,
      "step": 347700
    },
    {
      "epoch": 11.958876319499364,
      "grad_norm": 0.18305344879627228,
      "learning_rate": 1.2642536931732706e-05,
      "loss": 0.0326,
      "step": 347800
    },
    {
      "epoch": 11.962314754323831,
      "grad_norm": 0.20260922610759735,
      "learning_rate": 1.2631791591986555e-05,
      "loss": 0.0286,
      "step": 347900
    },
    {
      "epoch": 11.9657531891483,
      "grad_norm": 0.1220037043094635,
      "learning_rate": 1.2621046252240404e-05,
      "loss": 0.0337,
      "step": 348000
    },
    {
      "epoch": 11.969191623972767,
      "grad_norm": 0.18945129215717316,
      "learning_rate": 1.2610300912494252e-05,
      "loss": 0.0325,
      "step": 348100
    },
    {
      "epoch": 11.972630058797236,
      "grad_norm": 0.21218551695346832,
      "learning_rate": 1.2599555572748101e-05,
      "loss": 0.0285,
      "step": 348200
    },
    {
      "epoch": 11.976068493621703,
      "grad_norm": 0.2548803389072418,
      "learning_rate": 1.2588810233001946e-05,
      "loss": 0.03,
      "step": 348300
    },
    {
      "epoch": 11.97950692844617,
      "grad_norm": 0.34789392352104187,
      "learning_rate": 1.2578064893255795e-05,
      "loss": 0.0307,
      "step": 348400
    },
    {
      "epoch": 11.98294536327064,
      "grad_norm": 0.10685965418815613,
      "learning_rate": 1.2567319553509644e-05,
      "loss": 0.0305,
      "step": 348500
    },
    {
      "epoch": 11.986383798095106,
      "grad_norm": 0.17571625113487244,
      "learning_rate": 1.2556574213763492e-05,
      "loss": 0.032,
      "step": 348600
    },
    {
      "epoch": 11.989822232919575,
      "grad_norm": 0.22658321261405945,
      "learning_rate": 1.2545828874017341e-05,
      "loss": 0.0313,
      "step": 348700
    },
    {
      "epoch": 11.993260667744043,
      "grad_norm": 0.21939770877361298,
      "learning_rate": 1.2535083534271186e-05,
      "loss": 0.0315,
      "step": 348800
    },
    {
      "epoch": 11.996699102568511,
      "grad_norm": 0.09258730709552765,
      "learning_rate": 1.2524338194525035e-05,
      "loss": 0.0359,
      "step": 348900
    },
    {
      "epoch": 12.0,
      "eval_accuracy_macro_0.5": 0.9860957860946655,
      "eval_accuracy_micro_0.5": 0.9860958456993103,
      "eval_accuracy_weighted_0.5": 0.9773315191268921,
      "eval_aucroc_macro": 0.9293369650840759,
      "eval_aucroc_micro": 0.9303603172302246,
      "eval_aucroc_weighted": 0.9276348948478699,
      "eval_f1_macro_0.5": 0.7946520447731018,
      "eval_f1_macro_0.6": 0.7864633202552795,
      "eval_f1_macro_0.7": 0.7683466076850891,
      "eval_f1_macro_0.8": 0.6448866128921509,
      "eval_f1_micro_0.5": 0.8010529279708862,
      "eval_f1_micro_0.6": 0.7934190630912781,
      "eval_f1_micro_0.7": 0.7754465341567993,
      "eval_f1_micro_0.8": 0.7400805354118347,
      "eval_f1_micro_0.9": 0.6599519848823547,
      "eval_f1_weighted_0.5": 0.7979002594947815,
      "eval_f1_weighted_0.6": 0.7870889902114868,
      "eval_f1_weighted_0.7": 0.7648374438285828,
      "eval_f1_weighted_0.8": 0.6288984417915344,
      "eval_loss": 0.03026275709271431,
      "eval_runtime": 1980.5112,
      "eval_samples_per_second": 29.352,
      "eval_steps_per_second": 3.669,
      "step": 348996
    },
    {
      "epoch": 12.000137537392979,
      "grad_norm": 0.04460803419351578,
      "learning_rate": 1.2513592854778882e-05,
      "loss": 0.03,
      "step": 349000
    },
    {
      "epoch": 12.003575972217446,
      "grad_norm": 0.0660453513264656,
      "learning_rate": 1.250284751503273e-05,
      "loss": 0.0342,
      "step": 349100
    },
    {
      "epoch": 12.007014407041915,
      "grad_norm": 0.12112873047590256,
      "learning_rate": 1.2492102175286578e-05,
      "loss": 0.0295,
      "step": 349200
    },
    {
      "epoch": 12.010452841866382,
      "grad_norm": 0.10413629561662674,
      "learning_rate": 1.2481356835540426e-05,
      "loss": 0.0285,
      "step": 349300
    },
    {
      "epoch": 12.01389127669085,
      "grad_norm": 0.08075045794248581,
      "learning_rate": 1.2470611495794275e-05,
      "loss": 0.0338,
      "step": 349400
    },
    {
      "epoch": 12.017329711515318,
      "grad_norm": 0.21732276678085327,
      "learning_rate": 1.2459866156048122e-05,
      "loss": 0.032,
      "step": 349500
    },
    {
      "epoch": 12.020768146339787,
      "grad_norm": 0.09676641970872879,
      "learning_rate": 1.244912081630197e-05,
      "loss": 0.0311,
      "step": 349600
    },
    {
      "epoch": 12.024206581164254,
      "grad_norm": 0.11973439157009125,
      "learning_rate": 1.2438375476555818e-05,
      "loss": 0.0295,
      "step": 349700
    },
    {
      "epoch": 12.027645015988721,
      "grad_norm": 0.10714694857597351,
      "learning_rate": 1.2427630136809666e-05,
      "loss": 0.0318,
      "step": 349800
    },
    {
      "epoch": 12.03108345081319,
      "grad_norm": 0.418478399515152,
      "learning_rate": 1.2416884797063515e-05,
      "loss": 0.0332,
      "step": 349900
    },
    {
      "epoch": 12.034521885637657,
      "grad_norm": 0.2578808069229126,
      "learning_rate": 1.2406139457317362e-05,
      "loss": 0.0267,
      "step": 350000
    },
    {
      "epoch": 12.037960320462126,
      "grad_norm": 0.09978310763835907,
      "learning_rate": 1.239539411757121e-05,
      "loss": 0.0314,
      "step": 350100
    },
    {
      "epoch": 12.041398755286593,
      "grad_norm": 0.17684197425842285,
      "learning_rate": 1.2384648777825058e-05,
      "loss": 0.0319,
      "step": 350200
    },
    {
      "epoch": 12.044837190111062,
      "grad_norm": 0.12621663510799408,
      "learning_rate": 1.2373903438078906e-05,
      "loss": 0.0366,
      "step": 350300
    },
    {
      "epoch": 12.04827562493553,
      "grad_norm": 0.14762148261070251,
      "learning_rate": 1.2363158098332753e-05,
      "loss": 0.0335,
      "step": 350400
    },
    {
      "epoch": 12.051714059759997,
      "grad_norm": 0.09218719601631165,
      "learning_rate": 1.23524127585866e-05,
      "loss": 0.0299,
      "step": 350500
    },
    {
      "epoch": 12.055152494584465,
      "grad_norm": 0.5775774121284485,
      "learning_rate": 1.2341667418840449e-05,
      "loss": 0.032,
      "step": 350600
    },
    {
      "epoch": 12.058590929408933,
      "grad_norm": 0.10535070300102234,
      "learning_rate": 1.2330922079094298e-05,
      "loss": 0.0304,
      "step": 350700
    },
    {
      "epoch": 12.062029364233402,
      "grad_norm": 0.06600414961576462,
      "learning_rate": 1.2320176739348145e-05,
      "loss": 0.0327,
      "step": 350800
    },
    {
      "epoch": 12.065467799057869,
      "grad_norm": 0.03039158321917057,
      "learning_rate": 1.2309431399601993e-05,
      "loss": 0.0282,
      "step": 350900
    },
    {
      "epoch": 12.068906233882338,
      "grad_norm": 0.15494173765182495,
      "learning_rate": 1.229868605985584e-05,
      "loss": 0.0314,
      "step": 351000
    },
    {
      "epoch": 12.072344668706805,
      "grad_norm": 0.4548380672931671,
      "learning_rate": 1.2288048173507152e-05,
      "loss": 0.0305,
      "step": 351100
    },
    {
      "epoch": 12.075783103531272,
      "grad_norm": 0.13164731860160828,
      "learning_rate": 1.2277302833760999e-05,
      "loss": 0.0289,
      "step": 351200
    },
    {
      "epoch": 12.07922153835574,
      "grad_norm": 0.06989409774541855,
      "learning_rate": 1.2266557494014846e-05,
      "loss": 0.0299,
      "step": 351300
    },
    {
      "epoch": 12.082659973180208,
      "grad_norm": 0.02135929837822914,
      "learning_rate": 1.2255812154268694e-05,
      "loss": 0.033,
      "step": 351400
    },
    {
      "epoch": 12.086098408004677,
      "grad_norm": 0.11141541600227356,
      "learning_rate": 1.2245066814522541e-05,
      "loss": 0.0324,
      "step": 351500
    },
    {
      "epoch": 12.089536842829144,
      "grad_norm": 0.14710284769535065,
      "learning_rate": 1.223432147477639e-05,
      "loss": 0.0311,
      "step": 351600
    },
    {
      "epoch": 12.092975277653611,
      "grad_norm": 0.2537248134613037,
      "learning_rate": 1.2223576135030237e-05,
      "loss": 0.0321,
      "step": 351700
    },
    {
      "epoch": 12.09641371247808,
      "grad_norm": 0.10562960803508759,
      "learning_rate": 1.2212830795284086e-05,
      "loss": 0.0314,
      "step": 351800
    },
    {
      "epoch": 12.099852147302547,
      "grad_norm": 0.19785957038402557,
      "learning_rate": 1.2202085455537934e-05,
      "loss": 0.0288,
      "step": 351900
    },
    {
      "epoch": 12.103290582127016,
      "grad_norm": 0.11544974893331528,
      "learning_rate": 1.2191340115791781e-05,
      "loss": 0.0309,
      "step": 352000
    },
    {
      "epoch": 12.106729016951483,
      "grad_norm": 0.28637033700942993,
      "learning_rate": 1.218059477604563e-05,
      "loss": 0.0268,
      "step": 352100
    },
    {
      "epoch": 12.110167451775952,
      "grad_norm": 0.18163786828517914,
      "learning_rate": 1.2169849436299477e-05,
      "loss": 0.0343,
      "step": 352200
    },
    {
      "epoch": 12.11360588660042,
      "grad_norm": 0.5377743244171143,
      "learning_rate": 1.2159104096553326e-05,
      "loss": 0.0316,
      "step": 352300
    },
    {
      "epoch": 12.117044321424887,
      "grad_norm": 0.440771222114563,
      "learning_rate": 1.2148358756807174e-05,
      "loss": 0.0307,
      "step": 352400
    },
    {
      "epoch": 12.120482756249356,
      "grad_norm": 0.23219887912273407,
      "learning_rate": 1.2137613417061021e-05,
      "loss": 0.0325,
      "step": 352500
    },
    {
      "epoch": 12.123921191073823,
      "grad_norm": 0.11815883219242096,
      "learning_rate": 1.212686807731487e-05,
      "loss": 0.0309,
      "step": 352600
    },
    {
      "epoch": 12.127359625898292,
      "grad_norm": 0.39111843705177307,
      "learning_rate": 1.2116122737568717e-05,
      "loss": 0.0335,
      "step": 352700
    },
    {
      "epoch": 12.130798060722759,
      "grad_norm": 0.07711737602949142,
      "learning_rate": 1.2105377397822564e-05,
      "loss": 0.0305,
      "step": 352800
    },
    {
      "epoch": 12.134236495547228,
      "grad_norm": 0.10345486551523209,
      "learning_rate": 1.2094632058076413e-05,
      "loss": 0.0289,
      "step": 352900
    },
    {
      "epoch": 12.137674930371695,
      "grad_norm": 0.17893387377262115,
      "learning_rate": 1.208388671833026e-05,
      "loss": 0.0308,
      "step": 353000
    },
    {
      "epoch": 12.141113365196162,
      "grad_norm": 0.1346377581357956,
      "learning_rate": 1.2073141378584108e-05,
      "loss": 0.0337,
      "step": 353100
    },
    {
      "epoch": 12.144551800020631,
      "grad_norm": 0.1923443078994751,
      "learning_rate": 1.2062396038837955e-05,
      "loss": 0.0291,
      "step": 353200
    },
    {
      "epoch": 12.147990234845098,
      "grad_norm": 0.3385268747806549,
      "learning_rate": 1.2051650699091804e-05,
      "loss": 0.0318,
      "step": 353300
    },
    {
      "epoch": 12.151428669669567,
      "grad_norm": 0.0912795215845108,
      "learning_rate": 1.2041012812743114e-05,
      "loss": 0.0297,
      "step": 353400
    },
    {
      "epoch": 12.154867104494034,
      "grad_norm": 0.185996875166893,
      "learning_rate": 1.2030267472996962e-05,
      "loss": 0.0324,
      "step": 353500
    },
    {
      "epoch": 12.158305539318501,
      "grad_norm": 0.04880880191922188,
      "learning_rate": 1.201952213325081e-05,
      "loss": 0.0342,
      "step": 353600
    },
    {
      "epoch": 12.16174397414297,
      "grad_norm": 0.12134109437465668,
      "learning_rate": 1.2008776793504656e-05,
      "loss": 0.0298,
      "step": 353700
    },
    {
      "epoch": 12.165182408967437,
      "grad_norm": 0.1829887330532074,
      "learning_rate": 1.1998031453758505e-05,
      "loss": 0.0324,
      "step": 353800
    },
    {
      "epoch": 12.168620843791906,
      "grad_norm": 0.1765746772289276,
      "learning_rate": 1.1987286114012354e-05,
      "loss": 0.0328,
      "step": 353900
    },
    {
      "epoch": 12.172059278616373,
      "grad_norm": 0.13146701455116272,
      "learning_rate": 1.19765407742662e-05,
      "loss": 0.033,
      "step": 354000
    },
    {
      "epoch": 12.175497713440842,
      "grad_norm": 0.11858052760362625,
      "learning_rate": 1.196579543452005e-05,
      "loss": 0.0312,
      "step": 354100
    },
    {
      "epoch": 12.17893614826531,
      "grad_norm": 0.07750377058982849,
      "learning_rate": 1.1955050094773896e-05,
      "loss": 0.0291,
      "step": 354200
    },
    {
      "epoch": 12.182374583089777,
      "grad_norm": 0.16875645518302917,
      "learning_rate": 1.1944304755027745e-05,
      "loss": 0.0284,
      "step": 354300
    },
    {
      "epoch": 12.185813017914246,
      "grad_norm": 0.0655401200056076,
      "learning_rate": 1.1933559415281594e-05,
      "loss": 0.0309,
      "step": 354400
    },
    {
      "epoch": 12.189251452738713,
      "grad_norm": 0.4612916111946106,
      "learning_rate": 1.192281407553544e-05,
      "loss": 0.0306,
      "step": 354500
    },
    {
      "epoch": 12.192689887563182,
      "grad_norm": 0.21507132053375244,
      "learning_rate": 1.191206873578929e-05,
      "loss": 0.0295,
      "step": 354600
    },
    {
      "epoch": 12.196128322387649,
      "grad_norm": 0.08166912943124771,
      "learning_rate": 1.1901323396043136e-05,
      "loss": 0.0316,
      "step": 354700
    },
    {
      "epoch": 12.199566757212118,
      "grad_norm": 0.07346207648515701,
      "learning_rate": 1.1890578056296985e-05,
      "loss": 0.032,
      "step": 354800
    },
    {
      "epoch": 12.203005192036585,
      "grad_norm": 0.0715377926826477,
      "learning_rate": 1.1879832716550834e-05,
      "loss": 0.0342,
      "step": 354900
    },
    {
      "epoch": 12.206443626861052,
      "grad_norm": 0.40998005867004395,
      "learning_rate": 1.186908737680468e-05,
      "loss": 0.0304,
      "step": 355000
    },
    {
      "epoch": 12.209882061685521,
      "grad_norm": 0.170582577586174,
      "learning_rate": 1.1858342037058528e-05,
      "loss": 0.0289,
      "step": 355100
    },
    {
      "epoch": 12.213320496509988,
      "grad_norm": 0.2621442675590515,
      "learning_rate": 1.1847596697312375e-05,
      "loss": 0.0325,
      "step": 355200
    },
    {
      "epoch": 12.216758931334457,
      "grad_norm": 0.07052253186702728,
      "learning_rate": 1.1836851357566223e-05,
      "loss": 0.0308,
      "step": 355300
    },
    {
      "epoch": 12.220197366158924,
      "grad_norm": 0.14416341483592987,
      "learning_rate": 1.1826106017820072e-05,
      "loss": 0.0306,
      "step": 355400
    },
    {
      "epoch": 12.223635800983393,
      "grad_norm": 0.10233069211244583,
      "learning_rate": 1.181536067807392e-05,
      "loss": 0.0316,
      "step": 355500
    },
    {
      "epoch": 12.22707423580786,
      "grad_norm": 0.05525273084640503,
      "learning_rate": 1.1804615338327768e-05,
      "loss": 0.0296,
      "step": 355600
    },
    {
      "epoch": 12.230512670632327,
      "grad_norm": 0.08011379092931747,
      "learning_rate": 1.1793977451979077e-05,
      "loss": 0.031,
      "step": 355700
    },
    {
      "epoch": 12.233951105456796,
      "grad_norm": 0.09307944029569626,
      "learning_rate": 1.1783232112232926e-05,
      "loss": 0.0315,
      "step": 355800
    },
    {
      "epoch": 12.237389540281264,
      "grad_norm": 0.1964120864868164,
      "learning_rate": 1.1772486772486773e-05,
      "loss": 0.0275,
      "step": 355900
    },
    {
      "epoch": 12.240827975105733,
      "grad_norm": 0.04423532634973526,
      "learning_rate": 1.176174143274062e-05,
      "loss": 0.0321,
      "step": 356000
    },
    {
      "epoch": 12.2442664099302,
      "grad_norm": 0.07063832134008408,
      "learning_rate": 1.1750996092994469e-05,
      "loss": 0.031,
      "step": 356100
    },
    {
      "epoch": 12.247704844754667,
      "grad_norm": 0.06131713464856148,
      "learning_rate": 1.1740250753248316e-05,
      "loss": 0.0343,
      "step": 356200
    },
    {
      "epoch": 12.251143279579136,
      "grad_norm": 0.2625451385974884,
      "learning_rate": 1.1729505413502164e-05,
      "loss": 0.0327,
      "step": 356300
    },
    {
      "epoch": 12.254581714403603,
      "grad_norm": 0.0949750691652298,
      "learning_rate": 1.1718760073756013e-05,
      "loss": 0.03,
      "step": 356400
    },
    {
      "epoch": 12.258020149228072,
      "grad_norm": 0.048083338886499405,
      "learning_rate": 1.170801473400986e-05,
      "loss": 0.032,
      "step": 356500
    },
    {
      "epoch": 12.261458584052539,
      "grad_norm": 0.15684406459331512,
      "learning_rate": 1.1697269394263709e-05,
      "loss": 0.0319,
      "step": 356600
    },
    {
      "epoch": 12.264897018877008,
      "grad_norm": 0.15242095291614532,
      "learning_rate": 1.1686524054517556e-05,
      "loss": 0.0332,
      "step": 356700
    },
    {
      "epoch": 12.268335453701475,
      "grad_norm": 0.22085954248905182,
      "learning_rate": 1.1675778714771405e-05,
      "loss": 0.0328,
      "step": 356800
    },
    {
      "epoch": 12.271773888525942,
      "grad_norm": 0.047234296798706055,
      "learning_rate": 1.1665033375025253e-05,
      "loss": 0.0327,
      "step": 356900
    },
    {
      "epoch": 12.275212323350411,
      "grad_norm": 0.062083788216114044,
      "learning_rate": 1.16542880352791e-05,
      "loss": 0.0301,
      "step": 357000
    },
    {
      "epoch": 12.278650758174878,
      "grad_norm": 0.35969313979148865,
      "learning_rate": 1.1643542695532949e-05,
      "loss": 0.0321,
      "step": 357100
    },
    {
      "epoch": 12.282089192999347,
      "grad_norm": 0.14887697994709015,
      "learning_rate": 1.1632797355786796e-05,
      "loss": 0.0309,
      "step": 357200
    },
    {
      "epoch": 12.285527627823814,
      "grad_norm": 0.5666443109512329,
      "learning_rate": 1.1622052016040645e-05,
      "loss": 0.0277,
      "step": 357300
    },
    {
      "epoch": 12.288966062648283,
      "grad_norm": 0.24581825733184814,
      "learning_rate": 1.1611306676294492e-05,
      "loss": 0.0339,
      "step": 357400
    },
    {
      "epoch": 12.29240449747275,
      "grad_norm": 0.11560031771659851,
      "learning_rate": 1.1600561336548339e-05,
      "loss": 0.0335,
      "step": 357500
    },
    {
      "epoch": 12.295842932297218,
      "grad_norm": 0.16394537687301636,
      "learning_rate": 1.1589815996802187e-05,
      "loss": 0.0345,
      "step": 357600
    },
    {
      "epoch": 12.299281367121687,
      "grad_norm": 0.4009002149105072,
      "learning_rate": 1.1579070657056034e-05,
      "loss": 0.0357,
      "step": 357700
    },
    {
      "epoch": 12.302719801946154,
      "grad_norm": 0.04862011596560478,
      "learning_rate": 1.1568325317309883e-05,
      "loss": 0.0302,
      "step": 357800
    },
    {
      "epoch": 12.306158236770623,
      "grad_norm": 0.24036668241024017,
      "learning_rate": 1.1557579977563732e-05,
      "loss": 0.0297,
      "step": 357900
    },
    {
      "epoch": 12.30959667159509,
      "grad_norm": 0.0837659016251564,
      "learning_rate": 1.1546834637817579e-05,
      "loss": 0.0299,
      "step": 358000
    },
    {
      "epoch": 12.313035106419559,
      "grad_norm": 0.23831762373447418,
      "learning_rate": 1.1536089298071427e-05,
      "loss": 0.0329,
      "step": 358100
    },
    {
      "epoch": 12.316473541244026,
      "grad_norm": 0.17198650538921356,
      "learning_rate": 1.1525343958325274e-05,
      "loss": 0.0312,
      "step": 358200
    },
    {
      "epoch": 12.319911976068493,
      "grad_norm": 0.1504020094871521,
      "learning_rate": 1.1514598618579123e-05,
      "loss": 0.0317,
      "step": 358300
    },
    {
      "epoch": 12.323350410892962,
      "grad_norm": 0.04726567491889,
      "learning_rate": 1.1503853278832972e-05,
      "loss": 0.0294,
      "step": 358400
    },
    {
      "epoch": 12.326788845717429,
      "grad_norm": 0.06558766216039658,
      "learning_rate": 1.1493107939086819e-05,
      "loss": 0.0337,
      "step": 358500
    },
    {
      "epoch": 12.330227280541898,
      "grad_norm": 0.0387941412627697,
      "learning_rate": 1.1482362599340667e-05,
      "loss": 0.032,
      "step": 358600
    },
    {
      "epoch": 12.333665715366365,
      "grad_norm": 0.3521232604980469,
      "learning_rate": 1.1471617259594514e-05,
      "loss": 0.0332,
      "step": 358700
    },
    {
      "epoch": 12.337104150190832,
      "grad_norm": 1.0839263200759888,
      "learning_rate": 1.1460979373245824e-05,
      "loss": 0.0336,
      "step": 358800
    },
    {
      "epoch": 12.340542585015301,
      "grad_norm": 0.3542105257511139,
      "learning_rate": 1.1450234033499671e-05,
      "loss": 0.0316,
      "step": 358900
    },
    {
      "epoch": 12.343981019839768,
      "grad_norm": 0.306898832321167,
      "learning_rate": 1.143948869375352e-05,
      "loss": 0.0302,
      "step": 359000
    },
    {
      "epoch": 12.347419454664237,
      "grad_norm": 0.14322781562805176,
      "learning_rate": 1.1428743354007368e-05,
      "loss": 0.0318,
      "step": 359100
    },
    {
      "epoch": 12.350857889488704,
      "grad_norm": 0.0657462477684021,
      "learning_rate": 1.1417998014261215e-05,
      "loss": 0.028,
      "step": 359200
    },
    {
      "epoch": 12.354296324313173,
      "grad_norm": 0.17503812909126282,
      "learning_rate": 1.1407360127912525e-05,
      "loss": 0.03,
      "step": 359300
    },
    {
      "epoch": 12.35773475913764,
      "grad_norm": 0.10807760059833527,
      "learning_rate": 1.1396614788166372e-05,
      "loss": 0.0274,
      "step": 359400
    },
    {
      "epoch": 12.361173193962108,
      "grad_norm": 0.09288188070058823,
      "learning_rate": 1.138586944842022e-05,
      "loss": 0.0314,
      "step": 359500
    },
    {
      "epoch": 12.364611628786577,
      "grad_norm": 0.09000248461961746,
      "learning_rate": 1.137512410867407e-05,
      "loss": 0.0284,
      "step": 359600
    },
    {
      "epoch": 12.368050063611044,
      "grad_norm": 0.21907570958137512,
      "learning_rate": 1.1364378768927916e-05,
      "loss": 0.0324,
      "step": 359700
    },
    {
      "epoch": 12.371488498435513,
      "grad_norm": 0.24470825493335724,
      "learning_rate": 1.1353633429181765e-05,
      "loss": 0.0334,
      "step": 359800
    },
    {
      "epoch": 12.37492693325998,
      "grad_norm": 0.11677959561347961,
      "learning_rate": 1.1342888089435612e-05,
      "loss": 0.0333,
      "step": 359900
    },
    {
      "epoch": 12.378365368084449,
      "grad_norm": 0.04292543604969978,
      "learning_rate": 1.133214274968946e-05,
      "loss": 0.031,
      "step": 360000
    },
    {
      "epoch": 12.381803802908916,
      "grad_norm": 0.1842544674873352,
      "learning_rate": 1.132139740994331e-05,
      "loss": 0.0265,
      "step": 360100
    },
    {
      "epoch": 12.385242237733383,
      "grad_norm": 0.19368916749954224,
      "learning_rate": 1.1310652070197156e-05,
      "loss": 0.0313,
      "step": 360200
    },
    {
      "epoch": 12.388680672557852,
      "grad_norm": 0.375344842672348,
      "learning_rate": 1.1299906730451005e-05,
      "loss": 0.0324,
      "step": 360300
    },
    {
      "epoch": 12.39211910738232,
      "grad_norm": 0.07484927773475647,
      "learning_rate": 1.1289161390704852e-05,
      "loss": 0.0333,
      "step": 360400
    },
    {
      "epoch": 12.395557542206788,
      "grad_norm": 0.16174207627773285,
      "learning_rate": 1.12784160509587e-05,
      "loss": 0.0311,
      "step": 360500
    },
    {
      "epoch": 12.398995977031255,
      "grad_norm": 0.06072233244776726,
      "learning_rate": 1.1267670711212548e-05,
      "loss": 0.0294,
      "step": 360600
    },
    {
      "epoch": 12.402434411855722,
      "grad_norm": 0.09744122624397278,
      "learning_rate": 1.1256925371466395e-05,
      "loss": 0.0322,
      "step": 360700
    },
    {
      "epoch": 12.405872846680191,
      "grad_norm": 0.24647256731987,
      "learning_rate": 1.1246180031720243e-05,
      "loss": 0.0329,
      "step": 360800
    },
    {
      "epoch": 12.409311281504658,
      "grad_norm": 0.272825688123703,
      "learning_rate": 1.123543469197409e-05,
      "loss": 0.0312,
      "step": 360900
    },
    {
      "epoch": 12.412749716329127,
      "grad_norm": 0.10259784758090973,
      "learning_rate": 1.1224689352227939e-05,
      "loss": 0.0302,
      "step": 361000
    },
    {
      "epoch": 12.416188151153595,
      "grad_norm": 0.20269449055194855,
      "learning_rate": 1.1213944012481788e-05,
      "loss": 0.0298,
      "step": 361100
    },
    {
      "epoch": 12.419626585978063,
      "grad_norm": 0.16460855305194855,
      "learning_rate": 1.1203198672735635e-05,
      "loss": 0.0305,
      "step": 361200
    },
    {
      "epoch": 12.42306502080253,
      "grad_norm": 0.029930932447314262,
      "learning_rate": 1.1192453332989483e-05,
      "loss": 0.0308,
      "step": 361300
    },
    {
      "epoch": 12.426503455626998,
      "grad_norm": 0.14418946206569672,
      "learning_rate": 1.118170799324333e-05,
      "loss": 0.0289,
      "step": 361400
    },
    {
      "epoch": 12.429941890451467,
      "grad_norm": 0.27982231974601746,
      "learning_rate": 1.1170962653497179e-05,
      "loss": 0.0311,
      "step": 361500
    },
    {
      "epoch": 12.433380325275934,
      "grad_norm": 0.15711836516857147,
      "learning_rate": 1.1160217313751028e-05,
      "loss": 0.0326,
      "step": 361600
    },
    {
      "epoch": 12.436818760100403,
      "grad_norm": 0.5254893898963928,
      "learning_rate": 1.1149471974004875e-05,
      "loss": 0.0326,
      "step": 361700
    },
    {
      "epoch": 12.44025719492487,
      "grad_norm": 0.07678819447755814,
      "learning_rate": 1.1138726634258723e-05,
      "loss": 0.0306,
      "step": 361800
    },
    {
      "epoch": 12.443695629749339,
      "grad_norm": 0.14133095741271973,
      "learning_rate": 1.112798129451257e-05,
      "loss": 0.0327,
      "step": 361900
    },
    {
      "epoch": 12.447134064573806,
      "grad_norm": 0.26756125688552856,
      "learning_rate": 1.1117235954766419e-05,
      "loss": 0.032,
      "step": 362000
    },
    {
      "epoch": 12.450572499398273,
      "grad_norm": 0.2343074232339859,
      "learning_rate": 1.1106490615020266e-05,
      "loss": 0.028,
      "step": 362100
    },
    {
      "epoch": 12.454010934222742,
      "grad_norm": 0.40165606141090393,
      "learning_rate": 1.1095745275274113e-05,
      "loss": 0.0379,
      "step": 362200
    },
    {
      "epoch": 12.45744936904721,
      "grad_norm": 0.24613238871097565,
      "learning_rate": 1.1084999935527962e-05,
      "loss": 0.0302,
      "step": 362300
    },
    {
      "epoch": 12.460887803871678,
      "grad_norm": 0.05659310892224312,
      "learning_rate": 1.107425459578181e-05,
      "loss": 0.0329,
      "step": 362400
    },
    {
      "epoch": 12.464326238696145,
      "grad_norm": 0.37643131613731384,
      "learning_rate": 1.1063509256035657e-05,
      "loss": 0.0306,
      "step": 362500
    },
    {
      "epoch": 12.467764673520614,
      "grad_norm": 0.23364607989788055,
      "learning_rate": 1.1052763916289506e-05,
      "loss": 0.0332,
      "step": 362600
    },
    {
      "epoch": 12.471203108345081,
      "grad_norm": 0.06544768810272217,
      "learning_rate": 1.1042018576543353e-05,
      "loss": 0.0324,
      "step": 362700
    },
    {
      "epoch": 12.474641543169549,
      "grad_norm": 0.10964390635490417,
      "learning_rate": 1.1031273236797202e-05,
      "loss": 0.0326,
      "step": 362800
    },
    {
      "epoch": 12.478079977994017,
      "grad_norm": 0.04206759110093117,
      "learning_rate": 1.102052789705105e-05,
      "loss": 0.031,
      "step": 362900
    },
    {
      "epoch": 12.481518412818485,
      "grad_norm": 0.2610205411911011,
      "learning_rate": 1.1009782557304897e-05,
      "loss": 0.0311,
      "step": 363000
    },
    {
      "epoch": 12.484956847642954,
      "grad_norm": 0.15985605120658875,
      "learning_rate": 1.0999037217558746e-05,
      "loss": 0.0318,
      "step": 363100
    },
    {
      "epoch": 12.48839528246742,
      "grad_norm": 0.07101152837276459,
      "learning_rate": 1.0988291877812593e-05,
      "loss": 0.032,
      "step": 363200
    },
    {
      "epoch": 12.49183371729189,
      "grad_norm": 0.35241684317588806,
      "learning_rate": 1.0977546538066442e-05,
      "loss": 0.0314,
      "step": 363300
    },
    {
      "epoch": 12.495272152116357,
      "grad_norm": 0.10765651613473892,
      "learning_rate": 1.096680119832029e-05,
      "loss": 0.0353,
      "step": 363400
    },
    {
      "epoch": 12.498710586940824,
      "grad_norm": 0.20403237640857697,
      "learning_rate": 1.0956055858574137e-05,
      "loss": 0.0315,
      "step": 363500
    },
    {
      "epoch": 12.502149021765293,
      "grad_norm": 0.13128988444805145,
      "learning_rate": 1.0945310518827984e-05,
      "loss": 0.0308,
      "step": 363600
    },
    {
      "epoch": 12.50558745658976,
      "grad_norm": 0.13202473521232605,
      "learning_rate": 1.0934565179081831e-05,
      "loss": 0.0278,
      "step": 363700
    },
    {
      "epoch": 12.509025891414229,
      "grad_norm": 0.12963150441646576,
      "learning_rate": 1.092381983933568e-05,
      "loss": 0.0314,
      "step": 363800
    },
    {
      "epoch": 12.512464326238696,
      "grad_norm": 0.19907903671264648,
      "learning_rate": 1.0913074499589529e-05,
      "loss": 0.0306,
      "step": 363900
    },
    {
      "epoch": 12.515902761063163,
      "grad_norm": 0.05195869132876396,
      "learning_rate": 1.0902329159843376e-05,
      "loss": 0.0312,
      "step": 364000
    },
    {
      "epoch": 12.519341195887632,
      "grad_norm": 0.2412968873977661,
      "learning_rate": 1.0891691273494687e-05,
      "loss": 0.0317,
      "step": 364100
    },
    {
      "epoch": 12.5227796307121,
      "grad_norm": 0.654617190361023,
      "learning_rate": 1.0880945933748534e-05,
      "loss": 0.0321,
      "step": 364200
    },
    {
      "epoch": 12.526218065536568,
      "grad_norm": 0.1303831934928894,
      "learning_rate": 1.0870200594002383e-05,
      "loss": 0.0321,
      "step": 364300
    },
    {
      "epoch": 12.529656500361035,
      "grad_norm": 0.05334089323878288,
      "learning_rate": 1.085945525425623e-05,
      "loss": 0.0318,
      "step": 364400
    },
    {
      "epoch": 12.533094935185504,
      "grad_norm": 0.15691977739334106,
      "learning_rate": 1.0848709914510077e-05,
      "loss": 0.03,
      "step": 364500
    },
    {
      "epoch": 12.536533370009971,
      "grad_norm": 0.19361509382724762,
      "learning_rate": 1.0837964574763925e-05,
      "loss": 0.0319,
      "step": 364600
    },
    {
      "epoch": 12.539971804834439,
      "grad_norm": 0.09404260665178299,
      "learning_rate": 1.0827219235017772e-05,
      "loss": 0.0311,
      "step": 364700
    },
    {
      "epoch": 12.543410239658908,
      "grad_norm": 0.581104040145874,
      "learning_rate": 1.0816473895271621e-05,
      "loss": 0.0286,
      "step": 364800
    },
    {
      "epoch": 12.546848674483375,
      "grad_norm": 0.09808909893035889,
      "learning_rate": 1.080583600892293e-05,
      "loss": 0.0366,
      "step": 364900
    },
    {
      "epoch": 12.550287109307844,
      "grad_norm": 0.1538705676794052,
      "learning_rate": 1.079509066917678e-05,
      "loss": 0.032,
      "step": 365000
    },
    {
      "epoch": 12.55372554413231,
      "grad_norm": 0.21154902875423431,
      "learning_rate": 1.0784345329430626e-05,
      "loss": 0.0331,
      "step": 365100
    },
    {
      "epoch": 12.55716397895678,
      "grad_norm": 0.4684416651725769,
      "learning_rate": 1.0773599989684475e-05,
      "loss": 0.0325,
      "step": 365200
    },
    {
      "epoch": 12.560602413781247,
      "grad_norm": 0.14856572449207306,
      "learning_rate": 1.0762854649938322e-05,
      "loss": 0.0303,
      "step": 365300
    },
    {
      "epoch": 12.564040848605714,
      "grad_norm": 0.11429575830698013,
      "learning_rate": 1.0752109310192169e-05,
      "loss": 0.0319,
      "step": 365400
    },
    {
      "epoch": 12.567479283430183,
      "grad_norm": 0.16811241209506989,
      "learning_rate": 1.0741363970446018e-05,
      "loss": 0.034,
      "step": 365500
    },
    {
      "epoch": 12.57091771825465,
      "grad_norm": 0.21348321437835693,
      "learning_rate": 1.0730618630699866e-05,
      "loss": 0.0285,
      "step": 365600
    },
    {
      "epoch": 12.574356153079119,
      "grad_norm": 0.0580110028386116,
      "learning_rate": 1.0719873290953713e-05,
      "loss": 0.0315,
      "step": 365700
    },
    {
      "epoch": 12.577794587903586,
      "grad_norm": 0.07912936061620712,
      "learning_rate": 1.0709127951207562e-05,
      "loss": 0.0287,
      "step": 365800
    },
    {
      "epoch": 12.581233022728053,
      "grad_norm": 0.29689693450927734,
      "learning_rate": 1.0698382611461409e-05,
      "loss": 0.0306,
      "step": 365900
    },
    {
      "epoch": 12.584671457552522,
      "grad_norm": 0.29175615310668945,
      "learning_rate": 1.0687637271715258e-05,
      "loss": 0.0307,
      "step": 366000
    },
    {
      "epoch": 12.58810989237699,
      "grad_norm": 0.21087698638439178,
      "learning_rate": 1.0676891931969106e-05,
      "loss": 0.0298,
      "step": 366100
    },
    {
      "epoch": 12.591548327201458,
      "grad_norm": 0.05661790445446968,
      "learning_rate": 1.0666146592222953e-05,
      "loss": 0.0302,
      "step": 366200
    },
    {
      "epoch": 12.594986762025925,
      "grad_norm": 0.11222666501998901,
      "learning_rate": 1.0655401252476802e-05,
      "loss": 0.0314,
      "step": 366300
    },
    {
      "epoch": 12.598425196850394,
      "grad_norm": 0.15095460414886475,
      "learning_rate": 1.0644655912730649e-05,
      "loss": 0.0302,
      "step": 366400
    },
    {
      "epoch": 12.601863631674862,
      "grad_norm": 0.06007092818617821,
      "learning_rate": 1.0633910572984498e-05,
      "loss": 0.0313,
      "step": 366500
    },
    {
      "epoch": 12.605302066499329,
      "grad_norm": 0.17413732409477234,
      "learning_rate": 1.0623165233238345e-05,
      "loss": 0.0303,
      "step": 366600
    },
    {
      "epoch": 12.608740501323798,
      "grad_norm": 0.2735932171344757,
      "learning_rate": 1.0612419893492193e-05,
      "loss": 0.0309,
      "step": 366700
    },
    {
      "epoch": 12.612178936148265,
      "grad_norm": 0.49916425347328186,
      "learning_rate": 1.060167455374604e-05,
      "loss": 0.0313,
      "step": 366800
    },
    {
      "epoch": 12.615617370972734,
      "grad_norm": 0.078230120241642,
      "learning_rate": 1.0590929213999887e-05,
      "loss": 0.0277,
      "step": 366900
    },
    {
      "epoch": 12.6190558057972,
      "grad_norm": 0.03707247972488403,
      "learning_rate": 1.0580183874253736e-05,
      "loss": 0.0306,
      "step": 367000
    },
    {
      "epoch": 12.62249424062167,
      "grad_norm": 0.05430673062801361,
      "learning_rate": 1.0569438534507585e-05,
      "loss": 0.0326,
      "step": 367100
    },
    {
      "epoch": 12.625932675446137,
      "grad_norm": 0.16540995240211487,
      "learning_rate": 1.0558693194761432e-05,
      "loss": 0.0292,
      "step": 367200
    },
    {
      "epoch": 12.629371110270604,
      "grad_norm": 0.09762837737798691,
      "learning_rate": 1.054794785501528e-05,
      "loss": 0.0302,
      "step": 367300
    },
    {
      "epoch": 12.632809545095073,
      "grad_norm": 0.04440625384449959,
      "learning_rate": 1.0537202515269129e-05,
      "loss": 0.0302,
      "step": 367400
    },
    {
      "epoch": 12.63624797991954,
      "grad_norm": 0.07508482038974762,
      "learning_rate": 1.0526457175522976e-05,
      "loss": 0.0304,
      "step": 367500
    },
    {
      "epoch": 12.63968641474401,
      "grad_norm": 0.05237508937716484,
      "learning_rate": 1.0515711835776825e-05,
      "loss": 0.0286,
      "step": 367600
    },
    {
      "epoch": 12.643124849568476,
      "grad_norm": 0.0358257032930851,
      "learning_rate": 1.0504966496030672e-05,
      "loss": 0.0323,
      "step": 367700
    },
    {
      "epoch": 12.646563284392943,
      "grad_norm": 0.2619894742965698,
      "learning_rate": 1.049422115628452e-05,
      "loss": 0.0333,
      "step": 367800
    },
    {
      "epoch": 12.650001719217412,
      "grad_norm": 0.0715777575969696,
      "learning_rate": 1.0483475816538369e-05,
      "loss": 0.0321,
      "step": 367900
    },
    {
      "epoch": 12.65344015404188,
      "grad_norm": 0.13205306231975555,
      "learning_rate": 1.0472730476792216e-05,
      "loss": 0.0333,
      "step": 368000
    },
    {
      "epoch": 12.656878588866348,
      "grad_norm": 0.07331696152687073,
      "learning_rate": 1.0461985137046065e-05,
      "loss": 0.0283,
      "step": 368100
    },
    {
      "epoch": 12.660317023690816,
      "grad_norm": 0.24862831830978394,
      "learning_rate": 1.0451239797299912e-05,
      "loss": 0.029,
      "step": 368200
    },
    {
      "epoch": 12.663755458515285,
      "grad_norm": 0.1421622931957245,
      "learning_rate": 1.0440494457553759e-05,
      "loss": 0.0311,
      "step": 368300
    },
    {
      "epoch": 12.667193893339752,
      "grad_norm": 0.08848671615123749,
      "learning_rate": 1.0429749117807607e-05,
      "loss": 0.0316,
      "step": 368400
    },
    {
      "epoch": 12.67063232816422,
      "grad_norm": 0.1461174339056015,
      "learning_rate": 1.0419003778061454e-05,
      "loss": 0.0311,
      "step": 368500
    },
    {
      "epoch": 12.674070762988688,
      "grad_norm": 0.24408937990665436,
      "learning_rate": 1.0408258438315303e-05,
      "loss": 0.0324,
      "step": 368600
    },
    {
      "epoch": 12.677509197813155,
      "grad_norm": 0.26086992025375366,
      "learning_rate": 1.039751309856915e-05,
      "loss": 0.0344,
      "step": 368700
    },
    {
      "epoch": 12.680947632637624,
      "grad_norm": 0.4470601975917816,
      "learning_rate": 1.0386767758822999e-05,
      "loss": 0.0302,
      "step": 368800
    },
    {
      "epoch": 12.684386067462091,
      "grad_norm": 0.1434590369462967,
      "learning_rate": 1.0376022419076847e-05,
      "loss": 0.0313,
      "step": 368900
    },
    {
      "epoch": 12.68782450228656,
      "grad_norm": 0.47557300329208374,
      "learning_rate": 1.0365277079330694e-05,
      "loss": 0.0285,
      "step": 369000
    },
    {
      "epoch": 12.691262937111027,
      "grad_norm": 0.13606305420398712,
      "learning_rate": 1.0354531739584543e-05,
      "loss": 0.0317,
      "step": 369100
    },
    {
      "epoch": 12.694701371935494,
      "grad_norm": 0.07317245006561279,
      "learning_rate": 1.034378639983839e-05,
      "loss": 0.0319,
      "step": 369200
    },
    {
      "epoch": 12.698139806759963,
      "grad_norm": 0.3252491056919098,
      "learning_rate": 1.0333041060092239e-05,
      "loss": 0.0304,
      "step": 369300
    },
    {
      "epoch": 12.70157824158443,
      "grad_norm": 0.10156052559614182,
      "learning_rate": 1.0322295720346087e-05,
      "loss": 0.0322,
      "step": 369400
    },
    {
      "epoch": 12.7050166764089,
      "grad_norm": 0.1378590613603592,
      "learning_rate": 1.0311550380599934e-05,
      "loss": 0.0302,
      "step": 369500
    },
    {
      "epoch": 12.708455111233366,
      "grad_norm": 0.18663257360458374,
      "learning_rate": 1.0300805040853783e-05,
      "loss": 0.0302,
      "step": 369600
    },
    {
      "epoch": 12.711893546057835,
      "grad_norm": 0.11830152571201324,
      "learning_rate": 1.029005970110763e-05,
      "loss": 0.0342,
      "step": 369700
    },
    {
      "epoch": 12.715331980882302,
      "grad_norm": 0.11357123404741287,
      "learning_rate": 1.0279314361361477e-05,
      "loss": 0.0326,
      "step": 369800
    },
    {
      "epoch": 12.71877041570677,
      "grad_norm": 0.13508519530296326,
      "learning_rate": 1.0268569021615326e-05,
      "loss": 0.0308,
      "step": 369900
    },
    {
      "epoch": 12.722208850531239,
      "grad_norm": 0.10201320797204971,
      "learning_rate": 1.0257823681869173e-05,
      "loss": 0.0342,
      "step": 370000
    },
    {
      "epoch": 12.725647285355706,
      "grad_norm": 0.3624360263347626,
      "learning_rate": 1.0247078342123021e-05,
      "loss": 0.0311,
      "step": 370100
    },
    {
      "epoch": 12.729085720180175,
      "grad_norm": 0.08812201023101807,
      "learning_rate": 1.0236440455774331e-05,
      "loss": 0.0302,
      "step": 370200
    },
    {
      "epoch": 12.732524155004642,
      "grad_norm": 0.3113425076007843,
      "learning_rate": 1.022569511602818e-05,
      "loss": 0.033,
      "step": 370300
    },
    {
      "epoch": 12.73596258982911,
      "grad_norm": 0.24623516201972961,
      "learning_rate": 1.0214949776282027e-05,
      "loss": 0.0318,
      "step": 370400
    },
    {
      "epoch": 12.739401024653578,
      "grad_norm": 0.13928434252738953,
      "learning_rate": 1.0204204436535875e-05,
      "loss": 0.031,
      "step": 370500
    },
    {
      "epoch": 12.742839459478045,
      "grad_norm": 0.15843242406845093,
      "learning_rate": 1.0193459096789722e-05,
      "loss": 0.0291,
      "step": 370600
    },
    {
      "epoch": 12.746277894302514,
      "grad_norm": 0.09859567880630493,
      "learning_rate": 1.018271375704357e-05,
      "loss": 0.0314,
      "step": 370700
    },
    {
      "epoch": 12.749716329126981,
      "grad_norm": 0.030240854248404503,
      "learning_rate": 1.0171968417297418e-05,
      "loss": 0.0312,
      "step": 370800
    },
    {
      "epoch": 12.75315476395145,
      "grad_norm": 0.06520906835794449,
      "learning_rate": 1.0161223077551267e-05,
      "loss": 0.0303,
      "step": 370900
    },
    {
      "epoch": 12.756593198775917,
      "grad_norm": 0.06075633317232132,
      "learning_rate": 1.0150477737805114e-05,
      "loss": 0.0291,
      "step": 371000
    },
    {
      "epoch": 12.760031633600384,
      "grad_norm": 0.13762648403644562,
      "learning_rate": 1.0139732398058962e-05,
      "loss": 0.0336,
      "step": 371100
    },
    {
      "epoch": 12.763470068424853,
      "grad_norm": 0.04722673445940018,
      "learning_rate": 1.012898705831281e-05,
      "loss": 0.0322,
      "step": 371200
    },
    {
      "epoch": 12.76690850324932,
      "grad_norm": 0.16847097873687744,
      "learning_rate": 1.0118241718566658e-05,
      "loss": 0.034,
      "step": 371300
    },
    {
      "epoch": 12.77034693807379,
      "grad_norm": 0.035732924938201904,
      "learning_rate": 1.0107496378820507e-05,
      "loss": 0.0264,
      "step": 371400
    },
    {
      "epoch": 12.773785372898256,
      "grad_norm": 0.15897350013256073,
      "learning_rate": 1.0096751039074354e-05,
      "loss": 0.0326,
      "step": 371500
    },
    {
      "epoch": 12.777223807722725,
      "grad_norm": 0.2399791181087494,
      "learning_rate": 1.0086005699328203e-05,
      "loss": 0.0325,
      "step": 371600
    },
    {
      "epoch": 12.780662242547193,
      "grad_norm": 0.1300797313451767,
      "learning_rate": 1.007526035958205e-05,
      "loss": 0.0286,
      "step": 371700
    },
    {
      "epoch": 12.78410067737166,
      "grad_norm": 0.13131582736968994,
      "learning_rate": 1.0064515019835898e-05,
      "loss": 0.033,
      "step": 371800
    },
    {
      "epoch": 12.787539112196129,
      "grad_norm": 0.24829715490341187,
      "learning_rate": 1.0053769680089747e-05,
      "loss": 0.0302,
      "step": 371900
    },
    {
      "epoch": 12.790977547020596,
      "grad_norm": 0.043965812772512436,
      "learning_rate": 1.0043024340343594e-05,
      "loss": 0.03,
      "step": 372000
    },
    {
      "epoch": 12.794415981845065,
      "grad_norm": 0.2718638777732849,
      "learning_rate": 1.003227900059744e-05,
      "loss": 0.0336,
      "step": 372100
    },
    {
      "epoch": 12.797854416669532,
      "grad_norm": 0.04370981082320213,
      "learning_rate": 1.0021533660851288e-05,
      "loss": 0.0273,
      "step": 372200
    },
    {
      "epoch": 12.801292851494,
      "grad_norm": 0.364249050617218,
      "learning_rate": 1.0010788321105137e-05,
      "loss": 0.0342,
      "step": 372300
    },
    {
      "epoch": 12.804731286318468,
      "grad_norm": 0.03375129774212837,
      "learning_rate": 1.0000042981358985e-05,
      "loss": 0.0324,
      "step": 372400
    },
    {
      "epoch": 12.808169721142935,
      "grad_norm": 0.6553435325622559,
      "learning_rate": 9.989297641612832e-06,
      "loss": 0.0309,
      "step": 372500
    },
    {
      "epoch": 12.811608155967404,
      "grad_norm": 0.049739111214876175,
      "learning_rate": 9.978659755264143e-06,
      "loss": 0.0318,
      "step": 372600
    },
    {
      "epoch": 12.815046590791871,
      "grad_norm": 0.14862331748008728,
      "learning_rate": 9.96791441551799e-06,
      "loss": 0.0298,
      "step": 372700
    },
    {
      "epoch": 12.81848502561634,
      "grad_norm": 0.054786454886198044,
      "learning_rate": 9.95716907577184e-06,
      "loss": 0.0299,
      "step": 372800
    },
    {
      "epoch": 12.821923460440807,
      "grad_norm": 0.08445773273706436,
      "learning_rate": 9.946423736025686e-06,
      "loss": 0.0296,
      "step": 372900
    },
    {
      "epoch": 12.825361895265274,
      "grad_norm": 0.0513460710644722,
      "learning_rate": 9.935678396279533e-06,
      "loss": 0.0305,
      "step": 373000
    },
    {
      "epoch": 12.828800330089743,
      "grad_norm": 0.2104981243610382,
      "learning_rate": 9.924933056533382e-06,
      "loss": 0.029,
      "step": 373100
    },
    {
      "epoch": 12.83223876491421,
      "grad_norm": 0.04837123677134514,
      "learning_rate": 9.914187716787229e-06,
      "loss": 0.0299,
      "step": 373200
    },
    {
      "epoch": 12.83567719973868,
      "grad_norm": 0.09493119269609451,
      "learning_rate": 9.903442377041078e-06,
      "loss": 0.0307,
      "step": 373300
    },
    {
      "epoch": 12.839115634563147,
      "grad_norm": 0.04022540524601936,
      "learning_rate": 9.892697037294926e-06,
      "loss": 0.0304,
      "step": 373400
    },
    {
      "epoch": 12.842554069387615,
      "grad_norm": 0.22367562353610992,
      "learning_rate": 9.881951697548773e-06,
      "loss": 0.0275,
      "step": 373500
    },
    {
      "epoch": 12.845992504212083,
      "grad_norm": 0.46222370862960815,
      "learning_rate": 9.871206357802622e-06,
      "loss": 0.028,
      "step": 373600
    },
    {
      "epoch": 12.84943093903655,
      "grad_norm": 0.06573068350553513,
      "learning_rate": 9.860461018056469e-06,
      "loss": 0.0328,
      "step": 373700
    },
    {
      "epoch": 12.852869373861019,
      "grad_norm": 0.14722779393196106,
      "learning_rate": 9.849715678310318e-06,
      "loss": 0.0305,
      "step": 373800
    },
    {
      "epoch": 12.856307808685486,
      "grad_norm": 0.10145102441310883,
      "learning_rate": 9.838970338564166e-06,
      "loss": 0.0306,
      "step": 373900
    },
    {
      "epoch": 12.859746243509955,
      "grad_norm": 0.15570709109306335,
      "learning_rate": 9.828224998818013e-06,
      "loss": 0.0348,
      "step": 374000
    },
    {
      "epoch": 12.863184678334422,
      "grad_norm": 0.2553960382938385,
      "learning_rate": 9.817479659071862e-06,
      "loss": 0.0342,
      "step": 374100
    },
    {
      "epoch": 12.86662311315889,
      "grad_norm": 0.41012367606163025,
      "learning_rate": 9.806734319325709e-06,
      "loss": 0.0299,
      "step": 374200
    },
    {
      "epoch": 12.870061547983358,
      "grad_norm": 0.2958129048347473,
      "learning_rate": 9.795988979579558e-06,
      "loss": 0.0345,
      "step": 374300
    },
    {
      "epoch": 12.873499982807825,
      "grad_norm": 0.26713117957115173,
      "learning_rate": 9.785243639833405e-06,
      "loss": 0.0325,
      "step": 374400
    },
    {
      "epoch": 12.876938417632294,
      "grad_norm": 0.09403593093156815,
      "learning_rate": 9.774498300087252e-06,
      "loss": 0.0354,
      "step": 374500
    },
    {
      "epoch": 12.880376852456761,
      "grad_norm": 0.14653804898262024,
      "learning_rate": 9.7637529603411e-06,
      "loss": 0.0307,
      "step": 374600
    },
    {
      "epoch": 12.88381528728123,
      "grad_norm": 0.5620066523551941,
      "learning_rate": 9.753007620594947e-06,
      "loss": 0.0318,
      "step": 374700
    },
    {
      "epoch": 12.887253722105697,
      "grad_norm": 0.2541216313838959,
      "learning_rate": 9.742262280848796e-06,
      "loss": 0.031,
      "step": 374800
    },
    {
      "epoch": 12.890692156930164,
      "grad_norm": 0.11929719150066376,
      "learning_rate": 9.731516941102645e-06,
      "loss": 0.0345,
      "step": 374900
    },
    {
      "epoch": 12.894130591754633,
      "grad_norm": 0.0890994668006897,
      "learning_rate": 9.720771601356492e-06,
      "loss": 0.0296,
      "step": 375000
    },
    {
      "epoch": 12.8975690265791,
      "grad_norm": 0.14332011342048645,
      "learning_rate": 9.71002626161034e-06,
      "loss": 0.034,
      "step": 375100
    },
    {
      "epoch": 12.90100746140357,
      "grad_norm": 0.13087086379528046,
      "learning_rate": 9.69938837526165e-06,
      "loss": 0.0281,
      "step": 375200
    },
    {
      "epoch": 12.904445896228037,
      "grad_norm": 0.3299899697303772,
      "learning_rate": 9.688643035515497e-06,
      "loss": 0.03,
      "step": 375300
    },
    {
      "epoch": 12.907884331052506,
      "grad_norm": 0.36347800493240356,
      "learning_rate": 9.677897695769346e-06,
      "loss": 0.0307,
      "step": 375400
    },
    {
      "epoch": 12.911322765876973,
      "grad_norm": 0.08154461532831192,
      "learning_rate": 9.667152356023193e-06,
      "loss": 0.0304,
      "step": 375500
    },
    {
      "epoch": 12.914761200701442,
      "grad_norm": 0.029040614143013954,
      "learning_rate": 9.656407016277041e-06,
      "loss": 0.0312,
      "step": 375600
    },
    {
      "epoch": 12.918199635525909,
      "grad_norm": 0.12317044287919998,
      "learning_rate": 9.645661676530888e-06,
      "loss": 0.0325,
      "step": 375700
    },
    {
      "epoch": 12.921638070350376,
      "grad_norm": 0.09116680175065994,
      "learning_rate": 9.634916336784737e-06,
      "loss": 0.031,
      "step": 375800
    },
    {
      "epoch": 12.925076505174845,
      "grad_norm": 0.11698371917009354,
      "learning_rate": 9.624170997038586e-06,
      "loss": 0.0288,
      "step": 375900
    },
    {
      "epoch": 12.928514939999312,
      "grad_norm": 0.09137358516454697,
      "learning_rate": 9.613425657292433e-06,
      "loss": 0.0273,
      "step": 376000
    },
    {
      "epoch": 12.931953374823781,
      "grad_norm": 0.10467462241649628,
      "learning_rate": 9.602680317546281e-06,
      "loss": 0.031,
      "step": 376100
    },
    {
      "epoch": 12.935391809648248,
      "grad_norm": 0.11674115061759949,
      "learning_rate": 9.591934977800128e-06,
      "loss": 0.0322,
      "step": 376200
    },
    {
      "epoch": 12.938830244472715,
      "grad_norm": 0.08124080300331116,
      "learning_rate": 9.581189638053977e-06,
      "loss": 0.0306,
      "step": 376300
    },
    {
      "epoch": 12.942268679297184,
      "grad_norm": 0.4301467835903168,
      "learning_rate": 9.570444298307826e-06,
      "loss": 0.0319,
      "step": 376400
    },
    {
      "epoch": 12.945707114121651,
      "grad_norm": 0.08929378539323807,
      "learning_rate": 9.559698958561673e-06,
      "loss": 0.0297,
      "step": 376500
    },
    {
      "epoch": 12.94914554894612,
      "grad_norm": 0.05701650306582451,
      "learning_rate": 9.54895361881552e-06,
      "loss": 0.0287,
      "step": 376600
    },
    {
      "epoch": 12.952583983770587,
      "grad_norm": 0.1938466876745224,
      "learning_rate": 9.538208279069368e-06,
      "loss": 0.0336,
      "step": 376700
    },
    {
      "epoch": 12.956022418595056,
      "grad_norm": 0.0903356522321701,
      "learning_rate": 9.527462939323215e-06,
      "loss": 0.0307,
      "step": 376800
    },
    {
      "epoch": 12.959460853419523,
      "grad_norm": 0.16216957569122314,
      "learning_rate": 9.516717599577064e-06,
      "loss": 0.0302,
      "step": 376900
    },
    {
      "epoch": 12.96289928824399,
      "grad_norm": 0.11480825394392014,
      "learning_rate": 9.505972259830911e-06,
      "loss": 0.0326,
      "step": 377000
    },
    {
      "epoch": 12.96633772306846,
      "grad_norm": 0.041439302265644073,
      "learning_rate": 9.49522692008476e-06,
      "loss": 0.0305,
      "step": 377100
    },
    {
      "epoch": 12.969776157892927,
      "grad_norm": 0.17716391384601593,
      "learning_rate": 9.484481580338607e-06,
      "loss": 0.0321,
      "step": 377200
    },
    {
      "epoch": 12.973214592717396,
      "grad_norm": 0.07573647052049637,
      "learning_rate": 9.473736240592455e-06,
      "loss": 0.0344,
      "step": 377300
    },
    {
      "epoch": 12.976653027541863,
      "grad_norm": 0.18246859312057495,
      "learning_rate": 9.462990900846304e-06,
      "loss": 0.0295,
      "step": 377400
    },
    {
      "epoch": 12.980091462366332,
      "grad_norm": 0.1843600571155548,
      "learning_rate": 9.452245561100151e-06,
      "loss": 0.0307,
      "step": 377500
    },
    {
      "epoch": 12.983529897190799,
      "grad_norm": 0.02030053362250328,
      "learning_rate": 9.441500221354e-06,
      "loss": 0.0332,
      "step": 377600
    },
    {
      "epoch": 12.986968332015266,
      "grad_norm": 0.061960071325302124,
      "learning_rate": 9.430754881607848e-06,
      "loss": 0.0305,
      "step": 377700
    },
    {
      "epoch": 12.990406766839735,
      "grad_norm": 0.2853705585002899,
      "learning_rate": 9.420009541861695e-06,
      "loss": 0.0355,
      "step": 377800
    },
    {
      "epoch": 12.993845201664202,
      "grad_norm": 0.11011091619729996,
      "learning_rate": 9.409264202115544e-06,
      "loss": 0.0316,
      "step": 377900
    },
    {
      "epoch": 12.997283636488671,
      "grad_norm": 0.12524907290935516,
      "learning_rate": 9.398518862369391e-06,
      "loss": 0.0298,
      "step": 378000
    },
    {
      "epoch": 13.0,
      "eval_accuracy_macro_0.5": 0.9863524436950684,
      "eval_accuracy_micro_0.5": 0.9863524436950684,
      "eval_accuracy_weighted_0.5": 0.9776084423065186,
      "eval_aucroc_macro": 0.9270299077033997,
      "eval_aucroc_micro": 0.9296979308128357,
      "eval_aucroc_weighted": 0.9269871711730957,
      "eval_f1_macro_0.5": 0.7971972227096558,
      "eval_f1_macro_0.6": 0.7871518731117249,
      "eval_f1_macro_0.7": 0.7653659582138062,
      "eval_f1_macro_0.8": 0.6388188004493713,
      "eval_f1_micro_0.5": 0.8037813305854797,
      "eval_f1_micro_0.6": 0.7955964207649231,
      "eval_f1_micro_0.7": 0.7765337824821472,
      "eval_f1_micro_0.8": 0.7396156191825867,
      "eval_f1_micro_0.9": 0.6579994559288025,
      "eval_f1_weighted_0.5": 0.8002321720123291,
      "eval_f1_weighted_0.6": 0.7889779210090637,
      "eval_f1_weighted_0.7": 0.7655597925186157,
      "eval_f1_weighted_0.8": 0.627246618270874,
      "eval_loss": 0.029541000723838806,
      "eval_runtime": 2037.3857,
      "eval_samples_per_second": 28.533,
      "eval_steps_per_second": 3.567,
      "step": 378079
    },
    {
      "epoch": 13.000722071313138,
      "grad_norm": 0.18827982246875763,
      "learning_rate": 9.38777352262324e-06,
      "loss": 0.0288,
      "step": 378100
    },
    {
      "epoch": 13.004160506137605,
      "grad_norm": 0.12809054553508759,
      "learning_rate": 9.377028182877087e-06,
      "loss": 0.0317,
      "step": 378200
    },
    {
      "epoch": 13.007598940962074,
      "grad_norm": 0.1566687822341919,
      "learning_rate": 9.366282843130934e-06,
      "loss": 0.0336,
      "step": 378300
    },
    {
      "epoch": 13.011037375786541,
      "grad_norm": 0.1985727995634079,
      "learning_rate": 9.355537503384782e-06,
      "loss": 0.0301,
      "step": 378400
    },
    {
      "epoch": 13.01447581061101,
      "grad_norm": 0.3422132432460785,
      "learning_rate": 9.34479216363863e-06,
      "loss": 0.0315,
      "step": 378500
    },
    {
      "epoch": 13.017914245435477,
      "grad_norm": 0.08523762226104736,
      "learning_rate": 9.334046823892478e-06,
      "loss": 0.0319,
      "step": 378600
    },
    {
      "epoch": 13.021352680259946,
      "grad_norm": 0.19967368245124817,
      "learning_rate": 9.323408937543788e-06,
      "loss": 0.0323,
      "step": 378700
    },
    {
      "epoch": 13.024791115084414,
      "grad_norm": 0.13021031022071838,
      "learning_rate": 9.312663597797636e-06,
      "loss": 0.0298,
      "step": 378800
    },
    {
      "epoch": 13.02822954990888,
      "grad_norm": 0.18743665516376495,
      "learning_rate": 9.301918258051483e-06,
      "loss": 0.0314,
      "step": 378900
    },
    {
      "epoch": 13.03166798473335,
      "grad_norm": 0.2845488488674164,
      "learning_rate": 9.291172918305332e-06,
      "loss": 0.0321,
      "step": 379000
    },
    {
      "epoch": 13.035106419557817,
      "grad_norm": 0.12373420596122742,
      "learning_rate": 9.280427578559179e-06,
      "loss": 0.0332,
      "step": 379100
    },
    {
      "epoch": 13.038544854382286,
      "grad_norm": 0.48537585139274597,
      "learning_rate": 9.269682238813026e-06,
      "loss": 0.0271,
      "step": 379200
    },
    {
      "epoch": 13.041983289206753,
      "grad_norm": 0.4783196747303009,
      "learning_rate": 9.258936899066875e-06,
      "loss": 0.0316,
      "step": 379300
    },
    {
      "epoch": 13.045421724031222,
      "grad_norm": 0.39203959703445435,
      "learning_rate": 9.248191559320723e-06,
      "loss": 0.0313,
      "step": 379400
    },
    {
      "epoch": 13.048860158855689,
      "grad_norm": 0.17440582811832428,
      "learning_rate": 9.23744621957457e-06,
      "loss": 0.0321,
      "step": 379500
    },
    {
      "epoch": 13.052298593680156,
      "grad_norm": 0.18150021135807037,
      "learning_rate": 9.226700879828419e-06,
      "loss": 0.0358,
      "step": 379600
    },
    {
      "epoch": 13.055737028504625,
      "grad_norm": 0.386279433965683,
      "learning_rate": 9.215955540082266e-06,
      "loss": 0.0322,
      "step": 379700
    },
    {
      "epoch": 13.059175463329092,
      "grad_norm": 0.5324090719223022,
      "learning_rate": 9.205210200336115e-06,
      "loss": 0.032,
      "step": 379800
    },
    {
      "epoch": 13.062613898153561,
      "grad_norm": 0.18151092529296875,
      "learning_rate": 9.194464860589963e-06,
      "loss": 0.0328,
      "step": 379900
    },
    {
      "epoch": 13.066052332978028,
      "grad_norm": 0.22373777627944946,
      "learning_rate": 9.18371952084381e-06,
      "loss": 0.0328,
      "step": 380000
    },
    {
      "epoch": 13.069490767802495,
      "grad_norm": 0.21820585429668427,
      "learning_rate": 9.172974181097659e-06,
      "loss": 0.0303,
      "step": 380100
    },
    {
      "epoch": 13.072929202626964,
      "grad_norm": 0.40115246176719666,
      "learning_rate": 9.162228841351506e-06,
      "loss": 0.0324,
      "step": 380200
    },
    {
      "epoch": 13.076367637451431,
      "grad_norm": 0.32188427448272705,
      "learning_rate": 9.151483501605355e-06,
      "loss": 0.0302,
      "step": 380300
    },
    {
      "epoch": 13.0798060722759,
      "grad_norm": 0.1421903669834137,
      "learning_rate": 9.140738161859202e-06,
      "loss": 0.0286,
      "step": 380400
    },
    {
      "epoch": 13.083244507100368,
      "grad_norm": 0.5178787112236023,
      "learning_rate": 9.12999282211305e-06,
      "loss": 0.0347,
      "step": 380500
    },
    {
      "epoch": 13.086682941924836,
      "grad_norm": 0.11807040125131607,
      "learning_rate": 9.119247482366897e-06,
      "loss": 0.0336,
      "step": 380600
    },
    {
      "epoch": 13.090121376749304,
      "grad_norm": 0.10787113010883331,
      "learning_rate": 9.108502142620746e-06,
      "loss": 0.0308,
      "step": 380700
    },
    {
      "epoch": 13.09355981157377,
      "grad_norm": 0.05373625084757805,
      "learning_rate": 9.097756802874593e-06,
      "loss": 0.0318,
      "step": 380800
    },
    {
      "epoch": 13.09699824639824,
      "grad_norm": 0.5399754047393799,
      "learning_rate": 9.087011463128442e-06,
      "loss": 0.0317,
      "step": 380900
    },
    {
      "epoch": 13.100436681222707,
      "grad_norm": 0.46572932600975037,
      "learning_rate": 9.076266123382289e-06,
      "loss": 0.0295,
      "step": 381000
    },
    {
      "epoch": 13.103875116047176,
      "grad_norm": 0.09100071340799332,
      "learning_rate": 9.065520783636137e-06,
      "loss": 0.0305,
      "step": 381100
    },
    {
      "epoch": 13.107313550871643,
      "grad_norm": 0.47461774945259094,
      "learning_rate": 9.054775443889986e-06,
      "loss": 0.0309,
      "step": 381200
    },
    {
      "epoch": 13.110751985696112,
      "grad_norm": 0.2823227047920227,
      "learning_rate": 9.044137557541294e-06,
      "loss": 0.0297,
      "step": 381300
    },
    {
      "epoch": 13.114190420520579,
      "grad_norm": 0.16647528111934662,
      "learning_rate": 9.033392217795143e-06,
      "loss": 0.0326,
      "step": 381400
    },
    {
      "epoch": 13.117628855345046,
      "grad_norm": 0.4336353540420532,
      "learning_rate": 9.02264687804899e-06,
      "loss": 0.0278,
      "step": 381500
    },
    {
      "epoch": 13.121067290169515,
      "grad_norm": 0.4237448275089264,
      "learning_rate": 9.011901538302838e-06,
      "loss": 0.0346,
      "step": 381600
    },
    {
      "epoch": 13.124505724993982,
      "grad_norm": 0.08317356556653976,
      "learning_rate": 9.001156198556685e-06,
      "loss": 0.0299,
      "step": 381700
    },
    {
      "epoch": 13.127944159818451,
      "grad_norm": 0.1773788332939148,
      "learning_rate": 8.990410858810534e-06,
      "loss": 0.0282,
      "step": 381800
    },
    {
      "epoch": 13.131382594642918,
      "grad_norm": 0.18260464072227478,
      "learning_rate": 8.979665519064383e-06,
      "loss": 0.0317,
      "step": 381900
    },
    {
      "epoch": 13.134821029467387,
      "grad_norm": 0.13423670828342438,
      "learning_rate": 8.96892017931823e-06,
      "loss": 0.031,
      "step": 382000
    },
    {
      "epoch": 13.138259464291854,
      "grad_norm": 0.27264806628227234,
      "learning_rate": 8.958174839572078e-06,
      "loss": 0.03,
      "step": 382100
    },
    {
      "epoch": 13.141697899116322,
      "grad_norm": 0.2150254249572754,
      "learning_rate": 8.947429499825925e-06,
      "loss": 0.0299,
      "step": 382200
    },
    {
      "epoch": 13.14513633394079,
      "grad_norm": 0.2911936044692993,
      "learning_rate": 8.936684160079774e-06,
      "loss": 0.0323,
      "step": 382300
    },
    {
      "epoch": 13.148574768765258,
      "grad_norm": 0.14482082426548004,
      "learning_rate": 8.925938820333623e-06,
      "loss": 0.0308,
      "step": 382400
    },
    {
      "epoch": 13.152013203589727,
      "grad_norm": 0.09003905951976776,
      "learning_rate": 8.91519348058747e-06,
      "loss": 0.0279,
      "step": 382500
    },
    {
      "epoch": 13.155451638414194,
      "grad_norm": 0.10905340313911438,
      "learning_rate": 8.904448140841318e-06,
      "loss": 0.0297,
      "step": 382600
    },
    {
      "epoch": 13.158890073238661,
      "grad_norm": 0.0797385573387146,
      "learning_rate": 8.893702801095165e-06,
      "loss": 0.0334,
      "step": 382700
    },
    {
      "epoch": 13.16232850806313,
      "grad_norm": 0.1292351931333542,
      "learning_rate": 8.882957461349014e-06,
      "loss": 0.0304,
      "step": 382800
    },
    {
      "epoch": 13.165766942887597,
      "grad_norm": 0.14437967538833618,
      "learning_rate": 8.872212121602861e-06,
      "loss": 0.034,
      "step": 382900
    },
    {
      "epoch": 13.169205377712066,
      "grad_norm": 0.25133016705513,
      "learning_rate": 8.861466781856708e-06,
      "loss": 0.0321,
      "step": 383000
    },
    {
      "epoch": 13.172643812536533,
      "grad_norm": 0.269560307264328,
      "learning_rate": 8.850721442110557e-06,
      "loss": 0.0283,
      "step": 383100
    },
    {
      "epoch": 13.176082247361002,
      "grad_norm": 0.14908947050571442,
      "learning_rate": 8.839976102364405e-06,
      "loss": 0.03,
      "step": 383200
    },
    {
      "epoch": 13.17952068218547,
      "grad_norm": 0.3791363835334778,
      "learning_rate": 8.829230762618252e-06,
      "loss": 0.0336,
      "step": 383300
    },
    {
      "epoch": 13.182959117009936,
      "grad_norm": 0.07780229300260544,
      "learning_rate": 8.818592876269564e-06,
      "loss": 0.0312,
      "step": 383400
    },
    {
      "epoch": 13.186397551834405,
      "grad_norm": 0.08575239777565002,
      "learning_rate": 8.80784753652341e-06,
      "loss": 0.0303,
      "step": 383500
    },
    {
      "epoch": 13.189835986658872,
      "grad_norm": 0.36956584453582764,
      "learning_rate": 8.797102196777258e-06,
      "loss": 0.0297,
      "step": 383600
    },
    {
      "epoch": 13.193274421483341,
      "grad_norm": 0.1589687168598175,
      "learning_rate": 8.786356857031106e-06,
      "loss": 0.0311,
      "step": 383700
    },
    {
      "epoch": 13.196712856307808,
      "grad_norm": 0.1368430107831955,
      "learning_rate": 8.775611517284953e-06,
      "loss": 0.0299,
      "step": 383800
    },
    {
      "epoch": 13.200151291132277,
      "grad_norm": 0.12377077341079712,
      "learning_rate": 8.764866177538802e-06,
      "loss": 0.0309,
      "step": 383900
    },
    {
      "epoch": 13.203589725956745,
      "grad_norm": 0.14777222275733948,
      "learning_rate": 8.754120837792649e-06,
      "loss": 0.0294,
      "step": 384000
    },
    {
      "epoch": 13.207028160781212,
      "grad_norm": 0.6415836811065674,
      "learning_rate": 8.743375498046498e-06,
      "loss": 0.0314,
      "step": 384100
    },
    {
      "epoch": 13.21046659560568,
      "grad_norm": 0.4057469964027405,
      "learning_rate": 8.732630158300345e-06,
      "loss": 0.0329,
      "step": 384200
    },
    {
      "epoch": 13.213905030430148,
      "grad_norm": 0.10797491669654846,
      "learning_rate": 8.721884818554193e-06,
      "loss": 0.0314,
      "step": 384300
    },
    {
      "epoch": 13.217343465254617,
      "grad_norm": 0.12044110149145126,
      "learning_rate": 8.711139478808042e-06,
      "loss": 0.0311,
      "step": 384400
    },
    {
      "epoch": 13.220781900079084,
      "grad_norm": 0.06968750059604645,
      "learning_rate": 8.700394139061889e-06,
      "loss": 0.0282,
      "step": 384500
    },
    {
      "epoch": 13.224220334903553,
      "grad_norm": 0.049319375306367874,
      "learning_rate": 8.689648799315738e-06,
      "loss": 0.0321,
      "step": 384600
    },
    {
      "epoch": 13.22765876972802,
      "grad_norm": 0.18493957817554474,
      "learning_rate": 8.678903459569585e-06,
      "loss": 0.0302,
      "step": 384700
    },
    {
      "epoch": 13.231097204552487,
      "grad_norm": 0.12278235703706741,
      "learning_rate": 8.668158119823433e-06,
      "loss": 0.0305,
      "step": 384800
    },
    {
      "epoch": 13.234535639376956,
      "grad_norm": 0.14291876554489136,
      "learning_rate": 8.657412780077282e-06,
      "loss": 0.0315,
      "step": 384900
    },
    {
      "epoch": 13.237974074201423,
      "grad_norm": 0.4977094233036041,
      "learning_rate": 8.646667440331129e-06,
      "loss": 0.0302,
      "step": 385000
    },
    {
      "epoch": 13.241412509025892,
      "grad_norm": 0.10592807084321976,
      "learning_rate": 8.635922100584976e-06,
      "loss": 0.0332,
      "step": 385100
    },
    {
      "epoch": 13.24485094385036,
      "grad_norm": 0.12589958310127258,
      "learning_rate": 8.625176760838825e-06,
      "loss": 0.0293,
      "step": 385200
    },
    {
      "epoch": 13.248289378674826,
      "grad_norm": 0.288135826587677,
      "learning_rate": 8.614431421092672e-06,
      "loss": 0.0335,
      "step": 385300
    },
    {
      "epoch": 13.251727813499295,
      "grad_norm": 0.16216270625591278,
      "learning_rate": 8.60368608134652e-06,
      "loss": 0.0289,
      "step": 385400
    },
    {
      "epoch": 13.255166248323762,
      "grad_norm": 0.3563954830169678,
      "learning_rate": 8.59304819499783e-06,
      "loss": 0.0319,
      "step": 385500
    },
    {
      "epoch": 13.258604683148231,
      "grad_norm": 0.13587398827075958,
      "learning_rate": 8.582302855251679e-06,
      "loss": 0.0316,
      "step": 385600
    },
    {
      "epoch": 13.262043117972699,
      "grad_norm": 0.5967779755592346,
      "learning_rate": 8.571557515505526e-06,
      "loss": 0.0303,
      "step": 385700
    },
    {
      "epoch": 13.265481552797167,
      "grad_norm": 0.4283977448940277,
      "learning_rate": 8.560812175759374e-06,
      "loss": 0.0315,
      "step": 385800
    },
    {
      "epoch": 13.268919987621635,
      "grad_norm": 0.27514564990997314,
      "learning_rate": 8.550066836013221e-06,
      "loss": 0.0307,
      "step": 385900
    },
    {
      "epoch": 13.272358422446102,
      "grad_norm": 0.0788874551653862,
      "learning_rate": 8.539321496267068e-06,
      "loss": 0.0304,
      "step": 386000
    },
    {
      "epoch": 13.27579685727057,
      "grad_norm": 0.22218389809131622,
      "learning_rate": 8.528576156520917e-06,
      "loss": 0.0336,
      "step": 386100
    },
    {
      "epoch": 13.279235292095038,
      "grad_norm": 0.23813983798027039,
      "learning_rate": 8.517830816774764e-06,
      "loss": 0.0286,
      "step": 386200
    },
    {
      "epoch": 13.282673726919507,
      "grad_norm": 0.33577683568000793,
      "learning_rate": 8.507085477028613e-06,
      "loss": 0.033,
      "step": 386300
    },
    {
      "epoch": 13.286112161743974,
      "grad_norm": 0.14649763703346252,
      "learning_rate": 8.496340137282461e-06,
      "loss": 0.0305,
      "step": 386400
    },
    {
      "epoch": 13.289550596568443,
      "grad_norm": 0.17519357800483704,
      "learning_rate": 8.485594797536308e-06,
      "loss": 0.0323,
      "step": 386500
    },
    {
      "epoch": 13.29298903139291,
      "grad_norm": 0.09887172281742096,
      "learning_rate": 8.474849457790157e-06,
      "loss": 0.0297,
      "step": 386600
    },
    {
      "epoch": 13.296427466217377,
      "grad_norm": 0.24354952573776245,
      "learning_rate": 8.464104118044004e-06,
      "loss": 0.0316,
      "step": 386700
    },
    {
      "epoch": 13.299865901041846,
      "grad_norm": 0.24789299070835114,
      "learning_rate": 8.453358778297853e-06,
      "loss": 0.0286,
      "step": 386800
    },
    {
      "epoch": 13.303304335866313,
      "grad_norm": 0.08629126101732254,
      "learning_rate": 8.442613438551701e-06,
      "loss": 0.0314,
      "step": 386900
    },
    {
      "epoch": 13.306742770690782,
      "grad_norm": 0.24639445543289185,
      "learning_rate": 8.431868098805548e-06,
      "loss": 0.0334,
      "step": 387000
    },
    {
      "epoch": 13.31018120551525,
      "grad_norm": 0.29860931634902954,
      "learning_rate": 8.421122759059397e-06,
      "loss": 0.0328,
      "step": 387100
    },
    {
      "epoch": 13.313619640339716,
      "grad_norm": 0.3724975883960724,
      "learning_rate": 8.410377419313244e-06,
      "loss": 0.032,
      "step": 387200
    },
    {
      "epoch": 13.317058075164185,
      "grad_norm": 0.3716179430484772,
      "learning_rate": 8.399632079567093e-06,
      "loss": 0.0323,
      "step": 387300
    },
    {
      "epoch": 13.320496509988653,
      "grad_norm": 0.09224610030651093,
      "learning_rate": 8.38888673982094e-06,
      "loss": 0.0309,
      "step": 387400
    },
    {
      "epoch": 13.323934944813121,
      "grad_norm": 0.12229756265878677,
      "learning_rate": 8.378141400074788e-06,
      "loss": 0.0317,
      "step": 387500
    },
    {
      "epoch": 13.327373379637589,
      "grad_norm": 0.13964171707630157,
      "learning_rate": 8.367396060328635e-06,
      "loss": 0.032,
      "step": 387600
    },
    {
      "epoch": 13.330811814462058,
      "grad_norm": 0.17337951064109802,
      "learning_rate": 8.356650720582482e-06,
      "loss": 0.0337,
      "step": 387700
    },
    {
      "epoch": 13.334250249286525,
      "grad_norm": 0.23832175135612488,
      "learning_rate": 8.345905380836331e-06,
      "loss": 0.0297,
      "step": 387800
    },
    {
      "epoch": 13.337688684110992,
      "grad_norm": 0.06881297379732132,
      "learning_rate": 8.33516004109018e-06,
      "loss": 0.0305,
      "step": 387900
    },
    {
      "epoch": 13.34112711893546,
      "grad_norm": 0.1112975925207138,
      "learning_rate": 8.324414701344027e-06,
      "loss": 0.0283,
      "step": 388000
    },
    {
      "epoch": 13.344565553759928,
      "grad_norm": 0.06505338847637177,
      "learning_rate": 8.313669361597876e-06,
      "loss": 0.0322,
      "step": 388100
    },
    {
      "epoch": 13.348003988584397,
      "grad_norm": 0.22055408358573914,
      "learning_rate": 8.302924021851722e-06,
      "loss": 0.0308,
      "step": 388200
    },
    {
      "epoch": 13.351442423408864,
      "grad_norm": 0.3359282910823822,
      "learning_rate": 8.292178682105571e-06,
      "loss": 0.0263,
      "step": 388300
    },
    {
      "epoch": 13.354880858233333,
      "grad_norm": 0.10081642866134644,
      "learning_rate": 8.28143334235942e-06,
      "loss": 0.0308,
      "step": 388400
    },
    {
      "epoch": 13.3583192930578,
      "grad_norm": 0.18835115432739258,
      "learning_rate": 8.270688002613267e-06,
      "loss": 0.0324,
      "step": 388500
    },
    {
      "epoch": 13.361757727882267,
      "grad_norm": 0.09643029421567917,
      "learning_rate": 8.259942662867116e-06,
      "loss": 0.029,
      "step": 388600
    },
    {
      "epoch": 13.365196162706736,
      "grad_norm": 0.10295598208904266,
      "learning_rate": 8.249197323120964e-06,
      "loss": 0.0316,
      "step": 388700
    },
    {
      "epoch": 13.368634597531203,
      "grad_norm": 0.16623364388942719,
      "learning_rate": 8.238559436772272e-06,
      "loss": 0.0279,
      "step": 388800
    },
    {
      "epoch": 13.372073032355672,
      "grad_norm": 0.1558467000722885,
      "learning_rate": 8.22781409702612e-06,
      "loss": 0.0285,
      "step": 388900
    },
    {
      "epoch": 13.37551146718014,
      "grad_norm": 0.12407658994197845,
      "learning_rate": 8.217068757279968e-06,
      "loss": 0.0295,
      "step": 389000
    },
    {
      "epoch": 13.378949902004608,
      "grad_norm": 0.20397165417671204,
      "learning_rate": 8.206323417533816e-06,
      "loss": 0.0305,
      "step": 389100
    },
    {
      "epoch": 13.382388336829075,
      "grad_norm": 0.20953300595283508,
      "learning_rate": 8.195578077787663e-06,
      "loss": 0.0271,
      "step": 389200
    },
    {
      "epoch": 13.385826771653543,
      "grad_norm": 0.13473516702651978,
      "learning_rate": 8.184832738041512e-06,
      "loss": 0.0298,
      "step": 389300
    },
    {
      "epoch": 13.389265206478012,
      "grad_norm": 0.4302980899810791,
      "learning_rate": 8.174087398295361e-06,
      "loss": 0.0317,
      "step": 389400
    },
    {
      "epoch": 13.392703641302479,
      "grad_norm": 0.2776954174041748,
      "learning_rate": 8.163342058549208e-06,
      "loss": 0.0319,
      "step": 389500
    },
    {
      "epoch": 13.396142076126948,
      "grad_norm": 0.06655475497245789,
      "learning_rate": 8.152596718803057e-06,
      "loss": 0.0356,
      "step": 389600
    },
    {
      "epoch": 13.399580510951415,
      "grad_norm": 0.09260846674442291,
      "learning_rate": 8.141851379056904e-06,
      "loss": 0.0342,
      "step": 389700
    },
    {
      "epoch": 13.403018945775884,
      "grad_norm": 0.13350462913513184,
      "learning_rate": 8.13110603931075e-06,
      "loss": 0.0295,
      "step": 389800
    },
    {
      "epoch": 13.40645738060035,
      "grad_norm": 0.13838441669940948,
      "learning_rate": 8.1203606995646e-06,
      "loss": 0.0326,
      "step": 389900
    },
    {
      "epoch": 13.409895815424818,
      "grad_norm": 0.23521895706653595,
      "learning_rate": 8.109615359818446e-06,
      "loss": 0.029,
      "step": 390000
    },
    {
      "epoch": 13.413334250249287,
      "grad_norm": 0.14291779696941376,
      "learning_rate": 8.098870020072295e-06,
      "loss": 0.0294,
      "step": 390100
    },
    {
      "epoch": 13.416772685073754,
      "grad_norm": 0.10622958838939667,
      "learning_rate": 8.088124680326142e-06,
      "loss": 0.0336,
      "step": 390200
    },
    {
      "epoch": 13.420211119898223,
      "grad_norm": 0.12604761123657227,
      "learning_rate": 8.07737934057999e-06,
      "loss": 0.0315,
      "step": 390300
    },
    {
      "epoch": 13.42364955472269,
      "grad_norm": 0.10577455908060074,
      "learning_rate": 8.06663400083384e-06,
      "loss": 0.0273,
      "step": 390400
    },
    {
      "epoch": 13.427087989547157,
      "grad_norm": 0.34475016593933105,
      "learning_rate": 8.055888661087686e-06,
      "loss": 0.0304,
      "step": 390500
    },
    {
      "epoch": 13.430526424371626,
      "grad_norm": 0.12902803719043732,
      "learning_rate": 8.045143321341535e-06,
      "loss": 0.034,
      "step": 390600
    },
    {
      "epoch": 13.433964859196093,
      "grad_norm": 0.08276243507862091,
      "learning_rate": 8.034397981595382e-06,
      "loss": 0.0308,
      "step": 390700
    },
    {
      "epoch": 13.437403294020562,
      "grad_norm": 0.18004953861236572,
      "learning_rate": 8.02365264184923e-06,
      "loss": 0.0305,
      "step": 390800
    },
    {
      "epoch": 13.44084172884503,
      "grad_norm": 0.08125188201665878,
      "learning_rate": 8.01290730210308e-06,
      "loss": 0.0282,
      "step": 390900
    },
    {
      "epoch": 13.444280163669498,
      "grad_norm": 0.08246546238660812,
      "learning_rate": 8.002161962356926e-06,
      "loss": 0.0306,
      "step": 391000
    },
    {
      "epoch": 13.447718598493966,
      "grad_norm": 0.25723037123680115,
      "learning_rate": 7.991416622610775e-06,
      "loss": 0.0298,
      "step": 391100
    },
    {
      "epoch": 13.451157033318433,
      "grad_norm": 0.056214865297079086,
      "learning_rate": 7.980671282864622e-06,
      "loss": 0.0293,
      "step": 391200
    },
    {
      "epoch": 13.454595468142902,
      "grad_norm": 0.20163899660110474,
      "learning_rate": 7.96992594311847e-06,
      "loss": 0.0312,
      "step": 391300
    },
    {
      "epoch": 13.458033902967369,
      "grad_norm": 0.20943626761436462,
      "learning_rate": 7.959180603372318e-06,
      "loss": 0.0318,
      "step": 391400
    },
    {
      "epoch": 13.461472337791838,
      "grad_norm": 0.13994337618350983,
      "learning_rate": 7.948435263626165e-06,
      "loss": 0.0301,
      "step": 391500
    },
    {
      "epoch": 13.464910772616305,
      "grad_norm": 0.49138912558555603,
      "learning_rate": 7.937689923880013e-06,
      "loss": 0.0309,
      "step": 391600
    },
    {
      "epoch": 13.468349207440774,
      "grad_norm": 0.49540451169013977,
      "learning_rate": 7.926944584133862e-06,
      "loss": 0.0303,
      "step": 391700
    },
    {
      "epoch": 13.471787642265241,
      "grad_norm": 0.11897909641265869,
      "learning_rate": 7.916199244387709e-06,
      "loss": 0.0297,
      "step": 391800
    },
    {
      "epoch": 13.475226077089708,
      "grad_norm": 0.16874580085277557,
      "learning_rate": 7.905453904641558e-06,
      "loss": 0.0323,
      "step": 391900
    },
    {
      "epoch": 13.478664511914177,
      "grad_norm": 0.21584026515483856,
      "learning_rate": 7.894708564895405e-06,
      "loss": 0.0288,
      "step": 392000
    },
    {
      "epoch": 13.482102946738644,
      "grad_norm": 0.20559914410114288,
      "learning_rate": 7.884070678546714e-06,
      "loss": 0.0318,
      "step": 392100
    },
    {
      "epoch": 13.485541381563113,
      "grad_norm": 0.3070647418498993,
      "learning_rate": 7.873325338800563e-06,
      "loss": 0.0311,
      "step": 392200
    },
    {
      "epoch": 13.48897981638758,
      "grad_norm": 0.31094980239868164,
      "learning_rate": 7.86257999905441e-06,
      "loss": 0.0322,
      "step": 392300
    },
    {
      "epoch": 13.492418251212047,
      "grad_norm": 0.1258653700351715,
      "learning_rate": 7.851834659308259e-06,
      "loss": 0.032,
      "step": 392400
    },
    {
      "epoch": 13.495856686036516,
      "grad_norm": 0.198289692401886,
      "learning_rate": 7.841089319562106e-06,
      "loss": 0.0347,
      "step": 392500
    },
    {
      "epoch": 13.499295120860983,
      "grad_norm": 0.1779533177614212,
      "learning_rate": 7.830343979815954e-06,
      "loss": 0.0295,
      "step": 392600
    },
    {
      "epoch": 13.502733555685452,
      "grad_norm": 0.3415961265563965,
      "learning_rate": 7.819598640069801e-06,
      "loss": 0.0316,
      "step": 392700
    },
    {
      "epoch": 13.50617199050992,
      "grad_norm": 0.1927577704191208,
      "learning_rate": 7.80885330032365e-06,
      "loss": 0.0339,
      "step": 392800
    },
    {
      "epoch": 13.509610425334388,
      "grad_norm": 0.18054628372192383,
      "learning_rate": 7.798107960577499e-06,
      "loss": 0.0315,
      "step": 392900
    },
    {
      "epoch": 13.513048860158856,
      "grad_norm": 0.19427335262298584,
      "learning_rate": 7.787362620831346e-06,
      "loss": 0.0312,
      "step": 393000
    },
    {
      "epoch": 13.516487294983323,
      "grad_norm": 0.2833400368690491,
      "learning_rate": 7.776617281085194e-06,
      "loss": 0.03,
      "step": 393100
    },
    {
      "epoch": 13.519925729807792,
      "grad_norm": 0.09064759314060211,
      "learning_rate": 7.765871941339041e-06,
      "loss": 0.0335,
      "step": 393200
    },
    {
      "epoch": 13.523364164632259,
      "grad_norm": 0.21055446565151215,
      "learning_rate": 7.75512660159289e-06,
      "loss": 0.0321,
      "step": 393300
    },
    {
      "epoch": 13.526802599456728,
      "grad_norm": 0.16719993948936462,
      "learning_rate": 7.744381261846739e-06,
      "loss": 0.0288,
      "step": 393400
    },
    {
      "epoch": 13.530241034281195,
      "grad_norm": 0.3243168294429779,
      "learning_rate": 7.733635922100586e-06,
      "loss": 0.0317,
      "step": 393500
    },
    {
      "epoch": 13.533679469105664,
      "grad_norm": 0.5484539866447449,
      "learning_rate": 7.722890582354433e-06,
      "loss": 0.0287,
      "step": 393600
    },
    {
      "epoch": 13.537117903930131,
      "grad_norm": 0.07539105415344238,
      "learning_rate": 7.712145242608281e-06,
      "loss": 0.0307,
      "step": 393700
    },
    {
      "epoch": 13.540556338754598,
      "grad_norm": 0.12888750433921814,
      "learning_rate": 7.701399902862128e-06,
      "loss": 0.0304,
      "step": 393800
    },
    {
      "epoch": 13.543994773579067,
      "grad_norm": 0.511042594909668,
      "learning_rate": 7.690654563115977e-06,
      "loss": 0.029,
      "step": 393900
    },
    {
      "epoch": 13.547433208403534,
      "grad_norm": 0.1768866926431656,
      "learning_rate": 7.679909223369824e-06,
      "loss": 0.0275,
      "step": 394000
    },
    {
      "epoch": 13.550871643228003,
      "grad_norm": 0.2034875899553299,
      "learning_rate": 7.669163883623673e-06,
      "loss": 0.0318,
      "step": 394100
    },
    {
      "epoch": 13.55431007805247,
      "grad_norm": 0.1669805645942688,
      "learning_rate": 7.658418543877521e-06,
      "loss": 0.029,
      "step": 394200
    },
    {
      "epoch": 13.557748512876937,
      "grad_norm": 0.15600286424160004,
      "learning_rate": 7.647673204131368e-06,
      "loss": 0.027,
      "step": 394300
    },
    {
      "epoch": 13.561186947701406,
      "grad_norm": 0.16137781739234924,
      "learning_rate": 7.636927864385217e-06,
      "loss": 0.0276,
      "step": 394400
    },
    {
      "epoch": 13.564625382525874,
      "grad_norm": 0.3743627965450287,
      "learning_rate": 7.626182524639064e-06,
      "loss": 0.0337,
      "step": 394500
    },
    {
      "epoch": 13.568063817350343,
      "grad_norm": 0.13226118683815002,
      "learning_rate": 7.615437184892913e-06,
      "loss": 0.0337,
      "step": 394600
    },
    {
      "epoch": 13.57150225217481,
      "grad_norm": 0.12930993735790253,
      "learning_rate": 7.6046918451467605e-06,
      "loss": 0.0287,
      "step": 394700
    },
    {
      "epoch": 13.574940686999279,
      "grad_norm": 0.11965695023536682,
      "learning_rate": 7.5939465054006075e-06,
      "loss": 0.0295,
      "step": 394800
    },
    {
      "epoch": 13.578379121823746,
      "grad_norm": 0.1852789670228958,
      "learning_rate": 7.583308619051918e-06,
      "loss": 0.0312,
      "step": 394900
    },
    {
      "epoch": 13.581817556648215,
      "grad_norm": 0.13148193061351776,
      "learning_rate": 7.572563279305765e-06,
      "loss": 0.0346,
      "step": 395000
    },
    {
      "epoch": 13.585255991472682,
      "grad_norm": 0.14467841386795044,
      "learning_rate": 7.561817939559614e-06,
      "loss": 0.0306,
      "step": 395100
    },
    {
      "epoch": 13.588694426297149,
      "grad_norm": 0.4141218662261963,
      "learning_rate": 7.551072599813461e-06,
      "loss": 0.0338,
      "step": 395200
    },
    {
      "epoch": 13.592132861121618,
      "grad_norm": 0.1597679853439331,
      "learning_rate": 7.540327260067309e-06,
      "loss": 0.0325,
      "step": 395300
    },
    {
      "epoch": 13.595571295946085,
      "grad_norm": 0.20304672420024872,
      "learning_rate": 7.529581920321158e-06,
      "loss": 0.032,
      "step": 395400
    },
    {
      "epoch": 13.599009730770554,
      "grad_norm": 0.1577489674091339,
      "learning_rate": 7.518836580575005e-06,
      "loss": 0.0287,
      "step": 395500
    },
    {
      "epoch": 13.602448165595021,
      "grad_norm": 0.3565552532672882,
      "learning_rate": 7.508091240828853e-06,
      "loss": 0.0302,
      "step": 395600
    },
    {
      "epoch": 13.605886600419488,
      "grad_norm": 0.15578433871269226,
      "learning_rate": 7.4973459010827e-06,
      "loss": 0.0285,
      "step": 395700
    },
    {
      "epoch": 13.609325035243957,
      "grad_norm": 0.2289889007806778,
      "learning_rate": 7.4866005613365485e-06,
      "loss": 0.031,
      "step": 395800
    },
    {
      "epoch": 13.612763470068424,
      "grad_norm": 0.12005411833524704,
      "learning_rate": 7.475855221590397e-06,
      "loss": 0.0322,
      "step": 395900
    },
    {
      "epoch": 13.616201904892893,
      "grad_norm": 0.11372745782136917,
      "learning_rate": 7.465109881844244e-06,
      "loss": 0.029,
      "step": 396000
    },
    {
      "epoch": 13.61964033971736,
      "grad_norm": 0.1852540671825409,
      "learning_rate": 7.454364542098093e-06,
      "loss": 0.0313,
      "step": 396100
    },
    {
      "epoch": 13.62307877454183,
      "grad_norm": 0.6020321846008301,
      "learning_rate": 7.44361920235194e-06,
      "loss": 0.0288,
      "step": 396200
    },
    {
      "epoch": 13.626517209366297,
      "grad_norm": 0.4064886271953583,
      "learning_rate": 7.4328738626057885e-06,
      "loss": 0.0286,
      "step": 396300
    },
    {
      "epoch": 13.629955644190764,
      "grad_norm": 0.5704376697540283,
      "learning_rate": 7.422128522859636e-06,
      "loss": 0.0317,
      "step": 396400
    },
    {
      "epoch": 13.633394079015233,
      "grad_norm": 0.09816944599151611,
      "learning_rate": 7.411383183113483e-06,
      "loss": 0.0307,
      "step": 396500
    },
    {
      "epoch": 13.6368325138397,
      "grad_norm": 0.2514600455760956,
      "learning_rate": 7.400637843367332e-06,
      "loss": 0.0305,
      "step": 396600
    },
    {
      "epoch": 13.640270948664169,
      "grad_norm": 0.18561121821403503,
      "learning_rate": 7.389892503621181e-06,
      "loss": 0.029,
      "step": 396700
    },
    {
      "epoch": 13.643709383488636,
      "grad_norm": 0.4702189564704895,
      "learning_rate": 7.379147163875028e-06,
      "loss": 0.0306,
      "step": 396800
    },
    {
      "epoch": 13.647147818313105,
      "grad_norm": 0.2331550568342209,
      "learning_rate": 7.368401824128876e-06,
      "loss": 0.0298,
      "step": 396900
    },
    {
      "epoch": 13.650586253137572,
      "grad_norm": 0.3423648774623871,
      "learning_rate": 7.357656484382723e-06,
      "loss": 0.0309,
      "step": 397000
    },
    {
      "epoch": 13.654024687962039,
      "grad_norm": 0.2600574493408203,
      "learning_rate": 7.346911144636571e-06,
      "loss": 0.0308,
      "step": 397100
    },
    {
      "epoch": 13.657463122786508,
      "grad_norm": 0.2891062796115875,
      "learning_rate": 7.336273258287881e-06,
      "loss": 0.0285,
      "step": 397200
    },
    {
      "epoch": 13.660901557610975,
      "grad_norm": 0.30338171124458313,
      "learning_rate": 7.325527918541729e-06,
      "loss": 0.0348,
      "step": 397300
    },
    {
      "epoch": 13.664339992435444,
      "grad_norm": 0.06466207653284073,
      "learning_rate": 7.314782578795577e-06,
      "loss": 0.03,
      "step": 397400
    },
    {
      "epoch": 13.667778427259911,
      "grad_norm": 0.2361009567975998,
      "learning_rate": 7.304144692446886e-06,
      "loss": 0.0321,
      "step": 397500
    },
    {
      "epoch": 13.671216862084378,
      "grad_norm": 0.32085564732551575,
      "learning_rate": 7.293399352700735e-06,
      "loss": 0.0328,
      "step": 397600
    },
    {
      "epoch": 13.674655296908847,
      "grad_norm": 0.09189900755882263,
      "learning_rate": 7.282654012954582e-06,
      "loss": 0.0322,
      "step": 397700
    },
    {
      "epoch": 13.678093731733314,
      "grad_norm": 0.10193195194005966,
      "learning_rate": 7.2719086732084305e-06,
      "loss": 0.0288,
      "step": 397800
    },
    {
      "epoch": 13.681532166557783,
      "grad_norm": 0.37594324350357056,
      "learning_rate": 7.2611633334622775e-06,
      "loss": 0.0332,
      "step": 397900
    },
    {
      "epoch": 13.68497060138225,
      "grad_norm": 0.10657107084989548,
      "learning_rate": 7.250417993716125e-06,
      "loss": 0.0293,
      "step": 398000
    },
    {
      "epoch": 13.68840903620672,
      "grad_norm": 0.07071681320667267,
      "learning_rate": 7.239672653969974e-06,
      "loss": 0.0286,
      "step": 398100
    },
    {
      "epoch": 13.691847471031187,
      "grad_norm": 0.2681894600391388,
      "learning_rate": 7.228927314223821e-06,
      "loss": 0.0297,
      "step": 398200
    },
    {
      "epoch": 13.695285905855654,
      "grad_norm": 0.7733541131019592,
      "learning_rate": 7.21818197447767e-06,
      "loss": 0.0289,
      "step": 398300
    },
    {
      "epoch": 13.698724340680123,
      "grad_norm": 0.5388179421424866,
      "learning_rate": 7.207436634731517e-06,
      "loss": 0.0316,
      "step": 398400
    },
    {
      "epoch": 13.70216277550459,
      "grad_norm": 0.497646301984787,
      "learning_rate": 7.196691294985365e-06,
      "loss": 0.0289,
      "step": 398500
    },
    {
      "epoch": 13.705601210329059,
      "grad_norm": 0.22016677260398865,
      "learning_rate": 7.185945955239214e-06,
      "loss": 0.0318,
      "step": 398600
    },
    {
      "epoch": 13.709039645153526,
      "grad_norm": 0.17338451743125916,
      "learning_rate": 7.175200615493061e-06,
      "loss": 0.0289,
      "step": 398700
    },
    {
      "epoch": 13.712478079977995,
      "grad_norm": 0.42032384872436523,
      "learning_rate": 7.164455275746909e-06,
      "loss": 0.0319,
      "step": 398800
    },
    {
      "epoch": 13.715916514802462,
      "grad_norm": 0.4586728513240814,
      "learning_rate": 7.153709936000756e-06,
      "loss": 0.0315,
      "step": 398900
    },
    {
      "epoch": 13.71935494962693,
      "grad_norm": 0.33546146750450134,
      "learning_rate": 7.1429645962546045e-06,
      "loss": 0.0353,
      "step": 399000
    },
    {
      "epoch": 13.722793384451398,
      "grad_norm": 0.2482229471206665,
      "learning_rate": 7.132219256508453e-06,
      "loss": 0.0296,
      "step": 399100
    },
    {
      "epoch": 13.726231819275865,
      "grad_norm": 0.2891889810562134,
      "learning_rate": 7.1214739167623e-06,
      "loss": 0.0281,
      "step": 399200
    },
    {
      "epoch": 13.729670254100334,
      "grad_norm": 0.30408987402915955,
      "learning_rate": 7.110728577016149e-06,
      "loss": 0.0316,
      "step": 399300
    },
    {
      "epoch": 13.733108688924801,
      "grad_norm": 0.12224463373422623,
      "learning_rate": 7.099983237269997e-06,
      "loss": 0.0291,
      "step": 399400
    },
    {
      "epoch": 13.736547123749268,
      "grad_norm": 0.16683506965637207,
      "learning_rate": 7.089237897523844e-06,
      "loss": 0.03,
      "step": 399500
    },
    {
      "epoch": 13.739985558573737,
      "grad_norm": 0.16779594123363495,
      "learning_rate": 7.078492557777692e-06,
      "loss": 0.0324,
      "step": 399600
    },
    {
      "epoch": 13.743423993398205,
      "grad_norm": 0.052758220583200455,
      "learning_rate": 7.067747218031539e-06,
      "loss": 0.0338,
      "step": 399700
    },
    {
      "epoch": 13.746862428222673,
      "grad_norm": 0.3332105875015259,
      "learning_rate": 7.057001878285388e-06,
      "loss": 0.0311,
      "step": 399800
    },
    {
      "epoch": 13.75030086304714,
      "grad_norm": 0.19681096076965332,
      "learning_rate": 7.046256538539237e-06,
      "loss": 0.0295,
      "step": 399900
    },
    {
      "epoch": 13.75373929787161,
      "grad_norm": 0.14480410516262054,
      "learning_rate": 7.035511198793084e-06,
      "loss": 0.03,
      "step": 400000
    },
    {
      "epoch": 13.757177732696077,
      "grad_norm": 0.14335280656814575,
      "learning_rate": 7.024765859046932e-06,
      "loss": 0.031,
      "step": 400100
    },
    {
      "epoch": 13.760616167520544,
      "grad_norm": 0.13350290060043335,
      "learning_rate": 7.014020519300779e-06,
      "loss": 0.0296,
      "step": 400200
    },
    {
      "epoch": 13.764054602345013,
      "grad_norm": 0.2577427625656128,
      "learning_rate": 7.003275179554627e-06,
      "loss": 0.0334,
      "step": 400300
    },
    {
      "epoch": 13.76749303716948,
      "grad_norm": 0.12679819762706757,
      "learning_rate": 6.992529839808476e-06,
      "loss": 0.0304,
      "step": 400400
    },
    {
      "epoch": 13.770931471993949,
      "grad_norm": 0.17540299892425537,
      "learning_rate": 6.981784500062323e-06,
      "loss": 0.0337,
      "step": 400500
    },
    {
      "epoch": 13.774369906818416,
      "grad_norm": 0.06662535667419434,
      "learning_rate": 6.9710391603161716e-06,
      "loss": 0.0269,
      "step": 400600
    },
    {
      "epoch": 13.777808341642885,
      "grad_norm": 0.24663345515727997,
      "learning_rate": 6.9602938205700186e-06,
      "loss": 0.0313,
      "step": 400700
    },
    {
      "epoch": 13.781246776467352,
      "grad_norm": 0.2489345818758011,
      "learning_rate": 6.949548480823867e-06,
      "loss": 0.0301,
      "step": 400800
    },
    {
      "epoch": 13.78468521129182,
      "grad_norm": 0.15593759715557098,
      "learning_rate": 6.938910594475176e-06,
      "loss": 0.0305,
      "step": 400900
    },
    {
      "epoch": 13.788123646116288,
      "grad_norm": 0.21345990896224976,
      "learning_rate": 6.928165254729025e-06,
      "loss": 0.0295,
      "step": 401000
    },
    {
      "epoch": 13.791562080940755,
      "grad_norm": 0.1873740404844284,
      "learning_rate": 6.9174199149828725e-06,
      "loss": 0.0316,
      "step": 401100
    },
    {
      "epoch": 13.795000515765224,
      "grad_norm": 0.20365206897258759,
      "learning_rate": 6.9066745752367195e-06,
      "loss": 0.0341,
      "step": 401200
    },
    {
      "epoch": 13.798438950589691,
      "grad_norm": 0.17143654823303223,
      "learning_rate": 6.895929235490568e-06,
      "loss": 0.0294,
      "step": 401300
    },
    {
      "epoch": 13.801877385414159,
      "grad_norm": 0.7303486466407776,
      "learning_rate": 6.885183895744415e-06,
      "loss": 0.0338,
      "step": 401400
    },
    {
      "epoch": 13.805315820238627,
      "grad_norm": 0.2526295483112335,
      "learning_rate": 6.874438555998264e-06,
      "loss": 0.0312,
      "step": 401500
    },
    {
      "epoch": 13.808754255063095,
      "grad_norm": 0.11999534070491791,
      "learning_rate": 6.8636932162521126e-06,
      "loss": 0.0262,
      "step": 401600
    },
    {
      "epoch": 13.812192689887564,
      "grad_norm": 0.25681594014167786,
      "learning_rate": 6.8529478765059596e-06,
      "loss": 0.0286,
      "step": 401700
    },
    {
      "epoch": 13.81563112471203,
      "grad_norm": 0.19903022050857544,
      "learning_rate": 6.842202536759807e-06,
      "loss": 0.0298,
      "step": 401800
    },
    {
      "epoch": 13.8190695595365,
      "grad_norm": 0.13713885843753815,
      "learning_rate": 6.831457197013655e-06,
      "loss": 0.0331,
      "step": 401900
    },
    {
      "epoch": 13.822507994360967,
      "grad_norm": 0.15407444536685944,
      "learning_rate": 6.820711857267503e-06,
      "loss": 0.0352,
      "step": 402000
    },
    {
      "epoch": 13.825946429185436,
      "grad_norm": 0.12719930708408356,
      "learning_rate": 6.809966517521352e-06,
      "loss": 0.0299,
      "step": 402100
    },
    {
      "epoch": 13.829384864009903,
      "grad_norm": 0.17505405843257904,
      "learning_rate": 6.799221177775199e-06,
      "loss": 0.0314,
      "step": 402200
    },
    {
      "epoch": 13.83282329883437,
      "grad_norm": 0.2022716999053955,
      "learning_rate": 6.788475838029047e-06,
      "loss": 0.0321,
      "step": 402300
    },
    {
      "epoch": 13.836261733658839,
      "grad_norm": 0.13567878305912018,
      "learning_rate": 6.777730498282896e-06,
      "loss": 0.0288,
      "step": 402400
    },
    {
      "epoch": 13.839700168483306,
      "grad_norm": 0.2523568272590637,
      "learning_rate": 6.766985158536743e-06,
      "loss": 0.032,
      "step": 402500
    },
    {
      "epoch": 13.843138603307775,
      "grad_norm": 0.1793307363986969,
      "learning_rate": 6.756239818790591e-06,
      "loss": 0.0295,
      "step": 402600
    },
    {
      "epoch": 13.846577038132242,
      "grad_norm": 0.6104684472084045,
      "learning_rate": 6.745494479044438e-06,
      "loss": 0.0301,
      "step": 402700
    },
    {
      "epoch": 13.85001547295671,
      "grad_norm": 0.14704851806163788,
      "learning_rate": 6.734749139298287e-06,
      "loss": 0.034,
      "step": 402800
    },
    {
      "epoch": 13.853453907781178,
      "grad_norm": 0.2586357593536377,
      "learning_rate": 6.724003799552135e-06,
      "loss": 0.0288,
      "step": 402900
    },
    {
      "epoch": 13.856892342605645,
      "grad_norm": 0.10190524905920029,
      "learning_rate": 6.713258459805982e-06,
      "loss": 0.0303,
      "step": 403000
    },
    {
      "epoch": 13.860330777430114,
      "grad_norm": 0.0818423330783844,
      "learning_rate": 6.702513120059831e-06,
      "loss": 0.0277,
      "step": 403100
    },
    {
      "epoch": 13.863769212254581,
      "grad_norm": 0.21146570146083832,
      "learning_rate": 6.691767780313678e-06,
      "loss": 0.031,
      "step": 403200
    },
    {
      "epoch": 13.86720764707905,
      "grad_norm": 0.15899957716464996,
      "learning_rate": 6.681022440567526e-06,
      "loss": 0.0268,
      "step": 403300
    },
    {
      "epoch": 13.870646081903518,
      "grad_norm": 0.22111867368221283,
      "learning_rate": 6.6702771008213745e-06,
      "loss": 0.0331,
      "step": 403400
    },
    {
      "epoch": 13.874084516727985,
      "grad_norm": 0.1557796448469162,
      "learning_rate": 6.6595317610752215e-06,
      "loss": 0.0361,
      "step": 403500
    },
    {
      "epoch": 13.877522951552454,
      "grad_norm": 0.10712037980556488,
      "learning_rate": 6.64878642132907e-06,
      "loss": 0.0309,
      "step": 403600
    },
    {
      "epoch": 13.88096138637692,
      "grad_norm": 0.25343334674835205,
      "learning_rate": 6.638041081582917e-06,
      "loss": 0.0343,
      "step": 403700
    },
    {
      "epoch": 13.88439982120139,
      "grad_norm": 0.6595837473869324,
      "learning_rate": 6.627295741836766e-06,
      "loss": 0.0312,
      "step": 403800
    },
    {
      "epoch": 13.887838256025857,
      "grad_norm": 0.2424807846546173,
      "learning_rate": 6.6165504020906145e-06,
      "loss": 0.0316,
      "step": 403900
    },
    {
      "epoch": 13.891276690850326,
      "grad_norm": 0.27615979313850403,
      "learning_rate": 6.6058050623444615e-06,
      "loss": 0.0302,
      "step": 404000
    },
    {
      "epoch": 13.894715125674793,
      "grad_norm": 0.19950221478939056,
      "learning_rate": 6.595059722598309e-06,
      "loss": 0.0343,
      "step": 404100
    },
    {
      "epoch": 13.89815356049926,
      "grad_norm": 0.11369697749614716,
      "learning_rate": 6.584314382852156e-06,
      "loss": 0.0283,
      "step": 404200
    },
    {
      "epoch": 13.901591995323729,
      "grad_norm": 0.25011971592903137,
      "learning_rate": 6.573569043106005e-06,
      "loss": 0.0316,
      "step": 404300
    },
    {
      "epoch": 13.905030430148196,
      "grad_norm": 0.1139376312494278,
      "learning_rate": 6.562823703359854e-06,
      "loss": 0.0321,
      "step": 404400
    },
    {
      "epoch": 13.908468864972665,
      "grad_norm": 0.45056870579719543,
      "learning_rate": 6.552078363613701e-06,
      "loss": 0.0294,
      "step": 404500
    },
    {
      "epoch": 13.911907299797132,
      "grad_norm": 0.2862241864204407,
      "learning_rate": 6.541333023867549e-06,
      "loss": 0.0299,
      "step": 404600
    },
    {
      "epoch": 13.9153457346216,
      "grad_norm": 0.1378829926252365,
      "learning_rate": 6.530587684121397e-06,
      "loss": 0.0315,
      "step": 404700
    },
    {
      "epoch": 13.918784169446068,
      "grad_norm": 0.14552636444568634,
      "learning_rate": 6.519842344375245e-06,
      "loss": 0.0256,
      "step": 404800
    },
    {
      "epoch": 13.922222604270535,
      "grad_norm": 0.0966028943657875,
      "learning_rate": 6.509097004629093e-06,
      "loss": 0.0265,
      "step": 404900
    },
    {
      "epoch": 13.925661039095004,
      "grad_norm": 0.15127529203891754,
      "learning_rate": 6.49835166488294e-06,
      "loss": 0.0295,
      "step": 405000
    },
    {
      "epoch": 13.929099473919472,
      "grad_norm": 0.16640305519104004,
      "learning_rate": 6.48771377853425e-06,
      "loss": 0.0319,
      "step": 405100
    },
    {
      "epoch": 13.93253790874394,
      "grad_norm": 0.39117395877838135,
      "learning_rate": 6.476968438788097e-06,
      "loss": 0.0362,
      "step": 405200
    },
    {
      "epoch": 13.935976343568408,
      "grad_norm": 0.5828857421875,
      "learning_rate": 6.466223099041946e-06,
      "loss": 0.03,
      "step": 405300
    },
    {
      "epoch": 13.939414778392875,
      "grad_norm": 0.31861191987991333,
      "learning_rate": 6.455477759295795e-06,
      "loss": 0.0321,
      "step": 405400
    },
    {
      "epoch": 13.942853213217344,
      "grad_norm": 0.1701941341161728,
      "learning_rate": 6.444732419549642e-06,
      "loss": 0.0278,
      "step": 405500
    },
    {
      "epoch": 13.94629164804181,
      "grad_norm": 0.2898957133293152,
      "learning_rate": 6.4339870798034895e-06,
      "loss": 0.0296,
      "step": 405600
    },
    {
      "epoch": 13.94973008286628,
      "grad_norm": 0.18867282569408417,
      "learning_rate": 6.423241740057337e-06,
      "loss": 0.0286,
      "step": 405700
    },
    {
      "epoch": 13.953168517690747,
      "grad_norm": 0.06297697871923447,
      "learning_rate": 6.412496400311185e-06,
      "loss": 0.0288,
      "step": 405800
    },
    {
      "epoch": 13.956606952515216,
      "grad_norm": 0.3227952718734741,
      "learning_rate": 6.401751060565034e-06,
      "loss": 0.029,
      "step": 405900
    },
    {
      "epoch": 13.960045387339683,
      "grad_norm": 0.29064667224884033,
      "learning_rate": 6.391005720818881e-06,
      "loss": 0.0323,
      "step": 406000
    },
    {
      "epoch": 13.96348382216415,
      "grad_norm": 0.13126172125339508,
      "learning_rate": 6.3802603810727295e-06,
      "loss": 0.0311,
      "step": 406100
    },
    {
      "epoch": 13.966922256988619,
      "grad_norm": 0.24595457315444946,
      "learning_rate": 6.3695150413265765e-06,
      "loss": 0.0301,
      "step": 406200
    },
    {
      "epoch": 13.970360691813086,
      "grad_norm": 0.3352530896663666,
      "learning_rate": 6.358769701580425e-06,
      "loss": 0.0309,
      "step": 406300
    },
    {
      "epoch": 13.973799126637555,
      "grad_norm": 0.23255555331707,
      "learning_rate": 6.348024361834273e-06,
      "loss": 0.0299,
      "step": 406400
    },
    {
      "epoch": 13.977237561462022,
      "grad_norm": 0.06800463795661926,
      "learning_rate": 6.33727902208812e-06,
      "loss": 0.0295,
      "step": 406500
    },
    {
      "epoch": 13.98067599628649,
      "grad_norm": 0.1435731202363968,
      "learning_rate": 6.326533682341969e-06,
      "loss": 0.0312,
      "step": 406600
    },
    {
      "epoch": 13.984114431110958,
      "grad_norm": 0.39100727438926697,
      "learning_rate": 6.315788342595816e-06,
      "loss": 0.0317,
      "step": 406700
    },
    {
      "epoch": 13.987552865935426,
      "grad_norm": 0.1857212483882904,
      "learning_rate": 6.305043002849664e-06,
      "loss": 0.0289,
      "step": 406800
    },
    {
      "epoch": 13.990991300759895,
      "grad_norm": 0.14640386402606964,
      "learning_rate": 6.294297663103513e-06,
      "loss": 0.0301,
      "step": 406900
    },
    {
      "epoch": 13.994429735584362,
      "grad_norm": 0.2620713412761688,
      "learning_rate": 6.28355232335736e-06,
      "loss": 0.0327,
      "step": 407000
    },
    {
      "epoch": 13.99786817040883,
      "grad_norm": 0.29389771819114685,
      "learning_rate": 6.272806983611208e-06,
      "loss": 0.0322,
      "step": 407100
    },
    {
      "epoch": 14.0,
      "eval_accuracy_macro_0.5": 0.9864165186882019,
      "eval_accuracy_micro_0.5": 0.9864164590835571,
      "eval_accuracy_weighted_0.5": 0.9777398109436035,
      "eval_aucroc_macro": 0.9274517893791199,
      "eval_aucroc_micro": 0.9304773211479187,
      "eval_aucroc_weighted": 0.9278266429901123,
      "eval_f1_macro_0.5": 0.7992602586746216,
      "eval_f1_macro_0.6": 0.7895097732543945,
      "eval_f1_macro_0.7": 0.7681711316108704,
      "eval_f1_macro_0.8": 0.644822895526886,
      "eval_f1_micro_0.5": 0.804817259311676,
      "eval_f1_micro_0.6": 0.7971988916397095,
      "eval_f1_micro_0.7": 0.7779978513717651,
      "eval_f1_micro_0.8": 0.7428929805755615,
      "eval_f1_micro_0.9": 0.6636914014816284,
      "eval_f1_weighted_0.5": 0.8013722896575928,
      "eval_f1_weighted_0.6": 0.7906568050384521,
      "eval_f1_weighted_0.7": 0.7670909762382507,
      "eval_f1_weighted_0.8": 0.6328874826431274,
      "eval_loss": 0.029224155470728874,
      "eval_runtime": 2023.9503,
      "eval_samples_per_second": 28.722,
      "eval_steps_per_second": 3.591,
      "step": 407162
    },
    {
      "epoch": 14.001306605233298,
      "grad_norm": 0.18044786155223846,
      "learning_rate": 6.2621690972625175e-06,
      "loss": 0.028,
      "step": 407200
    },
    {
      "epoch": 14.004745040057765,
      "grad_norm": 0.22069256007671356,
      "learning_rate": 6.251423757516365e-06,
      "loss": 0.0326,
      "step": 407300
    },
    {
      "epoch": 14.008183474882234,
      "grad_norm": 0.07610799372196198,
      "learning_rate": 6.240678417770213e-06,
      "loss": 0.0308,
      "step": 407400
    },
    {
      "epoch": 14.011621909706701,
      "grad_norm": 0.09302373230457306,
      "learning_rate": 6.229933078024061e-06,
      "loss": 0.0283,
      "step": 407500
    },
    {
      "epoch": 14.01506034453117,
      "grad_norm": 0.1781996786594391,
      "learning_rate": 6.219187738277909e-06,
      "loss": 0.0297,
      "step": 407600
    },
    {
      "epoch": 14.018498779355637,
      "grad_norm": 0.8045949935913086,
      "learning_rate": 6.2084423985317575e-06,
      "loss": 0.0281,
      "step": 407700
    },
    {
      "epoch": 14.021937214180106,
      "grad_norm": 0.35183846950531006,
      "learning_rate": 6.197697058785605e-06,
      "loss": 0.0275,
      "step": 407800
    },
    {
      "epoch": 14.025375649004573,
      "grad_norm": 0.41120463609695435,
      "learning_rate": 6.186951719039453e-06,
      "loss": 0.0339,
      "step": 407900
    },
    {
      "epoch": 14.02881408382904,
      "grad_norm": 0.18472781777381897,
      "learning_rate": 6.1762063792933e-06,
      "loss": 0.0307,
      "step": 408000
    },
    {
      "epoch": 14.03225251865351,
      "grad_norm": 0.17250540852546692,
      "learning_rate": 6.165461039547149e-06,
      "loss": 0.0318,
      "step": 408100
    },
    {
      "epoch": 14.035690953477976,
      "grad_norm": 0.29386070370674133,
      "learning_rate": 6.154715699800997e-06,
      "loss": 0.0331,
      "step": 408200
    },
    {
      "epoch": 14.039129388302445,
      "grad_norm": 0.30453142523765564,
      "learning_rate": 6.1439703600548445e-06,
      "loss": 0.0334,
      "step": 408300
    },
    {
      "epoch": 14.042567823126912,
      "grad_norm": 0.15283629298210144,
      "learning_rate": 6.133225020308692e-06,
      "loss": 0.0305,
      "step": 408400
    },
    {
      "epoch": 14.046006257951381,
      "grad_norm": 0.5337367653846741,
      "learning_rate": 6.12247968056254e-06,
      "loss": 0.0337,
      "step": 408500
    },
    {
      "epoch": 14.049444692775849,
      "grad_norm": 0.22795534133911133,
      "learning_rate": 6.111734340816389e-06,
      "loss": 0.028,
      "step": 408600
    },
    {
      "epoch": 14.052883127600316,
      "grad_norm": 0.356008380651474,
      "learning_rate": 6.100989001070236e-06,
      "loss": 0.0312,
      "step": 408700
    },
    {
      "epoch": 14.056321562424785,
      "grad_norm": 0.29117071628570557,
      "learning_rate": 6.090243661324084e-06,
      "loss": 0.0299,
      "step": 408800
    },
    {
      "epoch": 14.059759997249252,
      "grad_norm": 0.1748768836259842,
      "learning_rate": 6.0794983215779316e-06,
      "loss": 0.0318,
      "step": 408900
    },
    {
      "epoch": 14.06319843207372,
      "grad_norm": 0.15814273059368134,
      "learning_rate": 6.068752981831779e-06,
      "loss": 0.0277,
      "step": 409000
    },
    {
      "epoch": 14.066636866898188,
      "grad_norm": 0.6867030262947083,
      "learning_rate": 6.058007642085628e-06,
      "loss": 0.0317,
      "step": 409100
    },
    {
      "epoch": 14.070075301722655,
      "grad_norm": 0.457976758480072,
      "learning_rate": 6.047262302339476e-06,
      "loss": 0.0301,
      "step": 409200
    },
    {
      "epoch": 14.073513736547124,
      "grad_norm": 0.32267332077026367,
      "learning_rate": 6.036516962593324e-06,
      "loss": 0.0295,
      "step": 409300
    },
    {
      "epoch": 14.076952171371591,
      "grad_norm": 0.16605310142040253,
      "learning_rate": 6.025771622847172e-06,
      "loss": 0.0298,
      "step": 409400
    },
    {
      "epoch": 14.08039060619606,
      "grad_norm": 0.0798419639468193,
      "learning_rate": 6.0150262831010194e-06,
      "loss": 0.0284,
      "step": 409500
    },
    {
      "epoch": 14.083829041020527,
      "grad_norm": 0.10908066481351852,
      "learning_rate": 6.004388396752328e-06,
      "loss": 0.0337,
      "step": 409600
    },
    {
      "epoch": 14.087267475844996,
      "grad_norm": 0.14973987638950348,
      "learning_rate": 5.993643057006177e-06,
      "loss": 0.0341,
      "step": 409700
    },
    {
      "epoch": 14.090705910669463,
      "grad_norm": 0.11857081949710846,
      "learning_rate": 5.982897717260025e-06,
      "loss": 0.0278,
      "step": 409800
    },
    {
      "epoch": 14.09414434549393,
      "grad_norm": 0.23600620031356812,
      "learning_rate": 5.9721523775138726e-06,
      "loss": 0.03,
      "step": 409900
    },
    {
      "epoch": 14.0975827803184,
      "grad_norm": 0.15203917026519775,
      "learning_rate": 5.96140703776772e-06,
      "loss": 0.0319,
      "step": 410000
    },
    {
      "epoch": 14.101021215142866,
      "grad_norm": 0.31345805525779724,
      "learning_rate": 5.950661698021568e-06,
      "loss": 0.0322,
      "step": 410100
    },
    {
      "epoch": 14.104459649967335,
      "grad_norm": 0.3051491379737854,
      "learning_rate": 5.939916358275417e-06,
      "loss": 0.0338,
      "step": 410200
    },
    {
      "epoch": 14.107898084791803,
      "grad_norm": 0.178163081407547,
      "learning_rate": 5.929171018529264e-06,
      "loss": 0.0315,
      "step": 410300
    },
    {
      "epoch": 14.111336519616271,
      "grad_norm": 0.09874832630157471,
      "learning_rate": 5.918425678783112e-06,
      "loss": 0.029,
      "step": 410400
    },
    {
      "epoch": 14.114774954440739,
      "grad_norm": 0.11726836860179901,
      "learning_rate": 5.90768033903696e-06,
      "loss": 0.0314,
      "step": 410500
    },
    {
      "epoch": 14.118213389265206,
      "grad_norm": 0.22323475778102875,
      "learning_rate": 5.896934999290807e-06,
      "loss": 0.0301,
      "step": 410600
    },
    {
      "epoch": 14.121651824089675,
      "grad_norm": 0.22759024798870087,
      "learning_rate": 5.886189659544656e-06,
      "loss": 0.0328,
      "step": 410700
    },
    {
      "epoch": 14.125090258914142,
      "grad_norm": 0.15135574340820312,
      "learning_rate": 5.875444319798504e-06,
      "loss": 0.0294,
      "step": 410800
    },
    {
      "epoch": 14.12852869373861,
      "grad_norm": 0.3131360411643982,
      "learning_rate": 5.864698980052352e-06,
      "loss": 0.027,
      "step": 410900
    },
    {
      "epoch": 14.131967128563078,
      "grad_norm": 0.8400447964668274,
      "learning_rate": 5.8539536403062e-06,
      "loss": 0.0354,
      "step": 411000
    },
    {
      "epoch": 14.135405563387547,
      "grad_norm": 0.2645881474018097,
      "learning_rate": 5.8432083005600474e-06,
      "loss": 0.0333,
      "step": 411100
    },
    {
      "epoch": 14.138843998212014,
      "grad_norm": 0.13785545527935028,
      "learning_rate": 5.832462960813895e-06,
      "loss": 0.0288,
      "step": 411200
    },
    {
      "epoch": 14.142282433036481,
      "grad_norm": 0.17445436120033264,
      "learning_rate": 5.821717621067743e-06,
      "loss": 0.0313,
      "step": 411300
    },
    {
      "epoch": 14.14572086786095,
      "grad_norm": 0.21724443137645721,
      "learning_rate": 5.810972281321591e-06,
      "loss": 0.0327,
      "step": 411400
    },
    {
      "epoch": 14.149159302685417,
      "grad_norm": 0.20483921468257904,
      "learning_rate": 5.800226941575439e-06,
      "loss": 0.0294,
      "step": 411500
    },
    {
      "epoch": 14.152597737509886,
      "grad_norm": 0.15097178518772125,
      "learning_rate": 5.7894816018292875e-06,
      "loss": 0.0276,
      "step": 411600
    },
    {
      "epoch": 14.156036172334353,
      "grad_norm": 0.20374806225299835,
      "learning_rate": 5.778736262083135e-06,
      "loss": 0.0324,
      "step": 411700
    },
    {
      "epoch": 14.15947460715882,
      "grad_norm": 0.23895500600337982,
      "learning_rate": 5.768098375734445e-06,
      "loss": 0.0279,
      "step": 411800
    },
    {
      "epoch": 14.16291304198329,
      "grad_norm": 0.2236708402633667,
      "learning_rate": 5.757353035988292e-06,
      "loss": 0.0314,
      "step": 411900
    },
    {
      "epoch": 14.166351476807757,
      "grad_norm": 0.11695066839456558,
      "learning_rate": 5.74660769624214e-06,
      "loss": 0.0287,
      "step": 412000
    },
    {
      "epoch": 14.169789911632225,
      "grad_norm": 0.18744520843029022,
      "learning_rate": 5.735862356495988e-06,
      "loss": 0.0286,
      "step": 412100
    },
    {
      "epoch": 14.173228346456693,
      "grad_norm": 0.20594266057014465,
      "learning_rate": 5.7251170167498354e-06,
      "loss": 0.0289,
      "step": 412200
    },
    {
      "epoch": 14.176666781281162,
      "grad_norm": 0.2738836109638214,
      "learning_rate": 5.714371677003684e-06,
      "loss": 0.0299,
      "step": 412300
    },
    {
      "epoch": 14.180105216105629,
      "grad_norm": 0.2571038603782654,
      "learning_rate": 5.703626337257532e-06,
      "loss": 0.0266,
      "step": 412400
    },
    {
      "epoch": 14.183543650930096,
      "grad_norm": 0.1850830316543579,
      "learning_rate": 5.69288099751138e-06,
      "loss": 0.031,
      "step": 412500
    },
    {
      "epoch": 14.186982085754565,
      "grad_norm": 0.5581968426704407,
      "learning_rate": 5.682135657765228e-06,
      "loss": 0.0321,
      "step": 412600
    },
    {
      "epoch": 14.190420520579032,
      "grad_norm": 0.404607355594635,
      "learning_rate": 5.6713903180190755e-06,
      "loss": 0.0329,
      "step": 412700
    },
    {
      "epoch": 14.1938589554035,
      "grad_norm": 0.19778791069984436,
      "learning_rate": 5.660644978272923e-06,
      "loss": 0.031,
      "step": 412800
    },
    {
      "epoch": 14.197297390227968,
      "grad_norm": 0.08558131009340286,
      "learning_rate": 5.649899638526771e-06,
      "loss": 0.031,
      "step": 412900
    },
    {
      "epoch": 14.200735825052437,
      "grad_norm": 0.12541578710079193,
      "learning_rate": 5.639154298780619e-06,
      "loss": 0.0296,
      "step": 413000
    },
    {
      "epoch": 14.204174259876904,
      "grad_norm": 0.04967939108610153,
      "learning_rate": 5.628408959034467e-06,
      "loss": 0.0301,
      "step": 413100
    },
    {
      "epoch": 14.207612694701371,
      "grad_norm": 0.314816415309906,
      "learning_rate": 5.6176636192883155e-06,
      "loss": 0.0291,
      "step": 413200
    },
    {
      "epoch": 14.21105112952584,
      "grad_norm": 0.115814708173275,
      "learning_rate": 5.606918279542163e-06,
      "loss": 0.0293,
      "step": 413300
    },
    {
      "epoch": 14.214489564350307,
      "grad_norm": 0.07773581892251968,
      "learning_rate": 5.59617293979601e-06,
      "loss": 0.0315,
      "step": 413400
    },
    {
      "epoch": 14.217927999174776,
      "grad_norm": 0.33139747381210327,
      "learning_rate": 5.585427600049858e-06,
      "loss": 0.0308,
      "step": 413500
    },
    {
      "epoch": 14.221366433999243,
      "grad_norm": 0.19294168055057526,
      "learning_rate": 5.574682260303707e-06,
      "loss": 0.0292,
      "step": 413600
    },
    {
      "epoch": 14.224804868823712,
      "grad_norm": 0.2009640485048294,
      "learning_rate": 5.563936920557555e-06,
      "loss": 0.0296,
      "step": 413700
    },
    {
      "epoch": 14.22824330364818,
      "grad_norm": 0.5137731432914734,
      "learning_rate": 5.5531915808114025e-06,
      "loss": 0.0317,
      "step": 413800
    },
    {
      "epoch": 14.231681738472647,
      "grad_norm": 0.3449648916721344,
      "learning_rate": 5.54244624106525e-06,
      "loss": 0.0317,
      "step": 413900
    },
    {
      "epoch": 14.235120173297116,
      "grad_norm": 0.3255554437637329,
      "learning_rate": 5.531700901319098e-06,
      "loss": 0.0308,
      "step": 414000
    },
    {
      "epoch": 14.238558608121583,
      "grad_norm": 0.11677873879671097,
      "learning_rate": 5.520955561572946e-06,
      "loss": 0.0295,
      "step": 414100
    },
    {
      "epoch": 14.241997042946052,
      "grad_norm": 0.35646894574165344,
      "learning_rate": 5.510210221826794e-06,
      "loss": 0.0303,
      "step": 414200
    },
    {
      "epoch": 14.245435477770519,
      "grad_norm": 0.34962013363838196,
      "learning_rate": 5.499464882080642e-06,
      "loss": 0.0293,
      "step": 414300
    },
    {
      "epoch": 14.248873912594986,
      "grad_norm": 0.12751424312591553,
      "learning_rate": 5.4887195423344895e-06,
      "loss": 0.0321,
      "step": 414400
    },
    {
      "epoch": 14.252312347419455,
      "grad_norm": 0.2439807802438736,
      "learning_rate": 5.477974202588337e-06,
      "loss": 0.0264,
      "step": 414500
    },
    {
      "epoch": 14.255750782243922,
      "grad_norm": 0.38351520895957947,
      "learning_rate": 5.467228862842186e-06,
      "loss": 0.03,
      "step": 414600
    },
    {
      "epoch": 14.259189217068391,
      "grad_norm": 0.15817047655582428,
      "learning_rate": 5.456483523096034e-06,
      "loss": 0.0278,
      "step": 414700
    },
    {
      "epoch": 14.262627651892858,
      "grad_norm": 0.06359530985355377,
      "learning_rate": 5.445738183349882e-06,
      "loss": 0.032,
      "step": 414800
    },
    {
      "epoch": 14.266066086717327,
      "grad_norm": 0.1428508311510086,
      "learning_rate": 5.434992843603729e-06,
      "loss": 0.0282,
      "step": 414900
    },
    {
      "epoch": 14.269504521541794,
      "grad_norm": 0.1055258959531784,
      "learning_rate": 5.424247503857577e-06,
      "loss": 0.0305,
      "step": 415000
    },
    {
      "epoch": 14.272942956366261,
      "grad_norm": 0.29098671674728394,
      "learning_rate": 5.413609617508886e-06,
      "loss": 0.0315,
      "step": 415100
    },
    {
      "epoch": 14.27638139119073,
      "grad_norm": 0.17813681066036224,
      "learning_rate": 5.402864277762735e-06,
      "loss": 0.0317,
      "step": 415200
    },
    {
      "epoch": 14.279819826015197,
      "grad_norm": 0.09552177786827087,
      "learning_rate": 5.392118938016583e-06,
      "loss": 0.0279,
      "step": 415300
    },
    {
      "epoch": 14.283258260839666,
      "grad_norm": 0.30623435974121094,
      "learning_rate": 5.3813735982704305e-06,
      "loss": 0.0341,
      "step": 415400
    },
    {
      "epoch": 14.286696695664133,
      "grad_norm": 0.1759883016347885,
      "learning_rate": 5.370628258524278e-06,
      "loss": 0.0339,
      "step": 415500
    },
    {
      "epoch": 14.290135130488602,
      "grad_norm": 0.3908371031284332,
      "learning_rate": 5.359882918778126e-06,
      "loss": 0.0289,
      "step": 415600
    },
    {
      "epoch": 14.29357356531307,
      "grad_norm": 0.191980242729187,
      "learning_rate": 5.349137579031974e-06,
      "loss": 0.0307,
      "step": 415700
    },
    {
      "epoch": 14.297012000137537,
      "grad_norm": 0.13330234587192535,
      "learning_rate": 5.338392239285822e-06,
      "loss": 0.0272,
      "step": 415800
    },
    {
      "epoch": 14.300450434962006,
      "grad_norm": 0.22286653518676758,
      "learning_rate": 5.32764689953967e-06,
      "loss": 0.0295,
      "step": 415900
    },
    {
      "epoch": 14.303888869786473,
      "grad_norm": 0.32747718691825867,
      "learning_rate": 5.3169015597935175e-06,
      "loss": 0.027,
      "step": 416000
    },
    {
      "epoch": 14.307327304610942,
      "grad_norm": 0.11108339577913284,
      "learning_rate": 5.306156220047365e-06,
      "loss": 0.0275,
      "step": 416100
    },
    {
      "epoch": 14.310765739435409,
      "grad_norm": 0.14371375739574432,
      "learning_rate": 5.295410880301214e-06,
      "loss": 0.0296,
      "step": 416200
    },
    {
      "epoch": 14.314204174259878,
      "grad_norm": 0.2923782467842102,
      "learning_rate": 5.284665540555062e-06,
      "loss": 0.0305,
      "step": 416300
    },
    {
      "epoch": 14.317642609084345,
      "grad_norm": 0.16376465559005737,
      "learning_rate": 5.27392020080891e-06,
      "loss": 0.0311,
      "step": 416400
    },
    {
      "epoch": 14.321081043908812,
      "grad_norm": 0.2953343093395233,
      "learning_rate": 5.263174861062757e-06,
      "loss": 0.0312,
      "step": 416500
    },
    {
      "epoch": 14.324519478733281,
      "grad_norm": 0.12134745717048645,
      "learning_rate": 5.252429521316605e-06,
      "loss": 0.0315,
      "step": 416600
    },
    {
      "epoch": 14.327957913557748,
      "grad_norm": 0.1656484752893448,
      "learning_rate": 5.241684181570453e-06,
      "loss": 0.0305,
      "step": 416700
    },
    {
      "epoch": 14.331396348382217,
      "grad_norm": 0.13859562575817108,
      "learning_rate": 5.230938841824301e-06,
      "loss": 0.0313,
      "step": 416800
    },
    {
      "epoch": 14.334834783206684,
      "grad_norm": 0.2981049120426178,
      "learning_rate": 5.220300955475611e-06,
      "loss": 0.0275,
      "step": 416900
    },
    {
      "epoch": 14.338273218031151,
      "grad_norm": 0.08205923438072205,
      "learning_rate": 5.2095556157294585e-06,
      "loss": 0.03,
      "step": 417000
    },
    {
      "epoch": 14.34171165285562,
      "grad_norm": 0.20593027770519257,
      "learning_rate": 5.198810275983306e-06,
      "loss": 0.0317,
      "step": 417100
    },
    {
      "epoch": 14.345150087680087,
      "grad_norm": 0.5205937623977661,
      "learning_rate": 5.188064936237154e-06,
      "loss": 0.0327,
      "step": 417200
    },
    {
      "epoch": 14.348588522504556,
      "grad_norm": 0.24304425716400146,
      "learning_rate": 5.177319596491002e-06,
      "loss": 0.0285,
      "step": 417300
    },
    {
      "epoch": 14.352026957329024,
      "grad_norm": 0.11389221996068954,
      "learning_rate": 5.16657425674485e-06,
      "loss": 0.0337,
      "step": 417400
    },
    {
      "epoch": 14.355465392153492,
      "grad_norm": 0.12760870158672333,
      "learning_rate": 5.155828916998698e-06,
      "loss": 0.0304,
      "step": 417500
    },
    {
      "epoch": 14.35890382697796,
      "grad_norm": 0.09653033316135406,
      "learning_rate": 5.1450835772525455e-06,
      "loss": 0.0299,
      "step": 417600
    },
    {
      "epoch": 14.362342261802427,
      "grad_norm": 0.11466678231954575,
      "learning_rate": 5.134338237506394e-06,
      "loss": 0.0258,
      "step": 417700
    },
    {
      "epoch": 14.365780696626896,
      "grad_norm": 0.3421015739440918,
      "learning_rate": 5.123592897760242e-06,
      "loss": 0.0322,
      "step": 417800
    },
    {
      "epoch": 14.369219131451363,
      "grad_norm": 0.1583372950553894,
      "learning_rate": 5.11284755801409e-06,
      "loss": 0.0336,
      "step": 417900
    },
    {
      "epoch": 14.372657566275832,
      "grad_norm": 0.12998618185520172,
      "learning_rate": 5.102102218267938e-06,
      "loss": 0.0283,
      "step": 418000
    },
    {
      "epoch": 14.376096001100299,
      "grad_norm": 0.19313250482082367,
      "learning_rate": 5.091356878521785e-06,
      "loss": 0.0297,
      "step": 418100
    },
    {
      "epoch": 14.379534435924768,
      "grad_norm": 0.12658251821994781,
      "learning_rate": 5.080611538775633e-06,
      "loss": 0.0325,
      "step": 418200
    },
    {
      "epoch": 14.382972870749235,
      "grad_norm": 0.28886133432388306,
      "learning_rate": 5.069866199029481e-06,
      "loss": 0.033,
      "step": 418300
    },
    {
      "epoch": 14.386411305573702,
      "grad_norm": 0.2989457845687866,
      "learning_rate": 5.059120859283329e-06,
      "loss": 0.0272,
      "step": 418400
    },
    {
      "epoch": 14.389849740398171,
      "grad_norm": 0.10997632145881653,
      "learning_rate": 5.048375519537177e-06,
      "loss": 0.033,
      "step": 418500
    },
    {
      "epoch": 14.393288175222638,
      "grad_norm": 0.3295844495296478,
      "learning_rate": 5.037630179791025e-06,
      "loss": 0.0318,
      "step": 418600
    },
    {
      "epoch": 14.396726610047107,
      "grad_norm": 0.6864277124404907,
      "learning_rate": 5.0268848400448734e-06,
      "loss": 0.0303,
      "step": 418700
    },
    {
      "epoch": 14.400165044871574,
      "grad_norm": 0.18814538419246674,
      "learning_rate": 5.01613950029872e-06,
      "loss": 0.0331,
      "step": 418800
    },
    {
      "epoch": 14.403603479696041,
      "grad_norm": 0.1312103569507599,
      "learning_rate": 5.005394160552568e-06,
      "loss": 0.032,
      "step": 418900
    },
    {
      "epoch": 14.40704191452051,
      "grad_norm": 0.2726203203201294,
      "learning_rate": 4.994648820806416e-06,
      "loss": 0.0276,
      "step": 419000
    },
    {
      "epoch": 14.410480349344978,
      "grad_norm": 0.35371291637420654,
      "learning_rate": 4.983903481060265e-06,
      "loss": 0.0302,
      "step": 419100
    },
    {
      "epoch": 14.413918784169446,
      "grad_norm": 0.2465018630027771,
      "learning_rate": 4.973158141314113e-06,
      "loss": 0.0308,
      "step": 419200
    },
    {
      "epoch": 14.417357218993914,
      "grad_norm": 0.09945793449878693,
      "learning_rate": 4.9624128015679604e-06,
      "loss": 0.0292,
      "step": 419300
    },
    {
      "epoch": 14.420795653818383,
      "grad_norm": 0.19495287537574768,
      "learning_rate": 4.951667461821808e-06,
      "loss": 0.0307,
      "step": 419400
    },
    {
      "epoch": 14.42423408864285,
      "grad_norm": 0.07936671376228333,
      "learning_rate": 4.940922122075656e-06,
      "loss": 0.0324,
      "step": 419500
    },
    {
      "epoch": 14.427672523467317,
      "grad_norm": 0.08923310786485672,
      "learning_rate": 4.930176782329504e-06,
      "loss": 0.032,
      "step": 419600
    },
    {
      "epoch": 14.431110958291786,
      "grad_norm": 0.15864844620227814,
      "learning_rate": 4.919431442583352e-06,
      "loss": 0.0297,
      "step": 419700
    },
    {
      "epoch": 14.434549393116253,
      "grad_norm": 0.1129859909415245,
      "learning_rate": 4.9086861028372e-06,
      "loss": 0.0264,
      "step": 419800
    },
    {
      "epoch": 14.437987827940722,
      "grad_norm": 0.12102504074573517,
      "learning_rate": 4.8979407630910475e-06,
      "loss": 0.031,
      "step": 419900
    },
    {
      "epoch": 14.441426262765189,
      "grad_norm": 0.25203561782836914,
      "learning_rate": 4.887195423344895e-06,
      "loss": 0.0289,
      "step": 420000
    },
    {
      "epoch": 14.444864697589658,
      "grad_norm": 0.40684497356414795,
      "learning_rate": 4.876450083598744e-06,
      "loss": 0.0316,
      "step": 420100
    },
    {
      "epoch": 14.448303132414125,
      "grad_norm": 0.26074230670928955,
      "learning_rate": 4.865704743852592e-06,
      "loss": 0.0285,
      "step": 420200
    },
    {
      "epoch": 14.451741567238592,
      "grad_norm": 0.10272032767534256,
      "learning_rate": 4.854959404106439e-06,
      "loss": 0.03,
      "step": 420300
    },
    {
      "epoch": 14.455180002063061,
      "grad_norm": 0.15074045956134796,
      "learning_rate": 4.844214064360287e-06,
      "loss": 0.0304,
      "step": 420400
    },
    {
      "epoch": 14.458618436887528,
      "grad_norm": 0.08580659329891205,
      "learning_rate": 4.833468724614135e-06,
      "loss": 0.0315,
      "step": 420500
    },
    {
      "epoch": 14.462056871711997,
      "grad_norm": 0.2261829823255539,
      "learning_rate": 4.822723384867983e-06,
      "loss": 0.0308,
      "step": 420600
    },
    {
      "epoch": 14.465495306536464,
      "grad_norm": 0.10634049028158188,
      "learning_rate": 4.811978045121831e-06,
      "loss": 0.0318,
      "step": 420700
    },
    {
      "epoch": 14.468933741360933,
      "grad_norm": 0.11307746917009354,
      "learning_rate": 4.801232705375679e-06,
      "loss": 0.0296,
      "step": 420800
    },
    {
      "epoch": 14.4723721761854,
      "grad_norm": 0.18264387547969818,
      "learning_rate": 4.790487365629527e-06,
      "loss": 0.0345,
      "step": 420900
    },
    {
      "epoch": 14.475810611009868,
      "grad_norm": 0.3498768210411072,
      "learning_rate": 4.7797420258833745e-06,
      "loss": 0.0306,
      "step": 421000
    },
    {
      "epoch": 14.479249045834337,
      "grad_norm": 0.1577005833387375,
      "learning_rate": 4.768996686137222e-06,
      "loss": 0.03,
      "step": 421100
    },
    {
      "epoch": 14.482687480658804,
      "grad_norm": 0.4326731264591217,
      "learning_rate": 4.75825134639107e-06,
      "loss": 0.0329,
      "step": 421200
    },
    {
      "epoch": 14.486125915483273,
      "grad_norm": 0.17535485327243805,
      "learning_rate": 4.747506006644918e-06,
      "loss": 0.0318,
      "step": 421300
    },
    {
      "epoch": 14.48956435030774,
      "grad_norm": 0.5225241184234619,
      "learning_rate": 4.736760666898767e-06,
      "loss": 0.0279,
      "step": 421400
    },
    {
      "epoch": 14.493002785132207,
      "grad_norm": 0.4273475110530853,
      "learning_rate": 4.7260153271526145e-06,
      "loss": 0.0313,
      "step": 421500
    },
    {
      "epoch": 14.496441219956676,
      "grad_norm": 0.41475963592529297,
      "learning_rate": 4.715269987406462e-06,
      "loss": 0.0314,
      "step": 421600
    },
    {
      "epoch": 14.499879654781143,
      "grad_norm": 0.20361417531967163,
      "learning_rate": 4.70452464766031e-06,
      "loss": 0.0323,
      "step": 421700
    },
    {
      "epoch": 14.503318089605612,
      "grad_norm": 0.4563240110874176,
      "learning_rate": 4.693779307914157e-06,
      "loss": 0.0295,
      "step": 421800
    },
    {
      "epoch": 14.50675652443008,
      "grad_norm": 0.09675080329179764,
      "learning_rate": 4.683033968168006e-06,
      "loss": 0.028,
      "step": 421900
    },
    {
      "epoch": 14.510194959254548,
      "grad_norm": 0.4391794204711914,
      "learning_rate": 4.672396081819315e-06,
      "loss": 0.0312,
      "step": 422000
    },
    {
      "epoch": 14.513633394079015,
      "grad_norm": 0.1205201968550682,
      "learning_rate": 4.661650742073163e-06,
      "loss": 0.0289,
      "step": 422100
    },
    {
      "epoch": 14.517071828903482,
      "grad_norm": 0.18434736132621765,
      "learning_rate": 4.650905402327011e-06,
      "loss": 0.0306,
      "step": 422200
    },
    {
      "epoch": 14.520510263727951,
      "grad_norm": 0.08684976398944855,
      "learning_rate": 4.640160062580859e-06,
      "loss": 0.0281,
      "step": 422300
    },
    {
      "epoch": 14.523948698552418,
      "grad_norm": 0.15232312679290771,
      "learning_rate": 4.629414722834707e-06,
      "loss": 0.0326,
      "step": 422400
    },
    {
      "epoch": 14.527387133376887,
      "grad_norm": 0.24763919413089752,
      "learning_rate": 4.618669383088555e-06,
      "loss": 0.0334,
      "step": 422500
    },
    {
      "epoch": 14.530825568201355,
      "grad_norm": 0.10986808687448502,
      "learning_rate": 4.6079240433424025e-06,
      "loss": 0.0289,
      "step": 422600
    },
    {
      "epoch": 14.534264003025823,
      "grad_norm": 0.11495940387248993,
      "learning_rate": 4.59717870359625e-06,
      "loss": 0.0295,
      "step": 422700
    },
    {
      "epoch": 14.53770243785029,
      "grad_norm": 0.17237868905067444,
      "learning_rate": 4.586433363850098e-06,
      "loss": 0.0337,
      "step": 422800
    },
    {
      "epoch": 14.541140872674758,
      "grad_norm": 0.14340443909168243,
      "learning_rate": 4.575688024103946e-06,
      "loss": 0.0309,
      "step": 422900
    },
    {
      "epoch": 14.544579307499227,
      "grad_norm": 0.3098447620868683,
      "learning_rate": 4.564942684357795e-06,
      "loss": 0.0359,
      "step": 423000
    },
    {
      "epoch": 14.548017742323694,
      "grad_norm": 0.8318169116973877,
      "learning_rate": 4.5541973446116425e-06,
      "loss": 0.0292,
      "step": 423100
    },
    {
      "epoch": 14.551456177148163,
      "grad_norm": 0.18502216041088104,
      "learning_rate": 4.54345200486549e-06,
      "loss": 0.031,
      "step": 423200
    },
    {
      "epoch": 14.55489461197263,
      "grad_norm": 0.21782678365707397,
      "learning_rate": 4.532706665119338e-06,
      "loss": 0.0305,
      "step": 423300
    },
    {
      "epoch": 14.558333046797099,
      "grad_norm": 0.11474723368883133,
      "learning_rate": 4.521961325373185e-06,
      "loss": 0.0305,
      "step": 423400
    },
    {
      "epoch": 14.561771481621566,
      "grad_norm": 0.12820124626159668,
      "learning_rate": 4.511215985627034e-06,
      "loss": 0.0323,
      "step": 423500
    },
    {
      "epoch": 14.565209916446033,
      "grad_norm": 0.14481323957443237,
      "learning_rate": 4.500470645880882e-06,
      "loss": 0.0316,
      "step": 423600
    },
    {
      "epoch": 14.568648351270502,
      "grad_norm": 0.47288185358047485,
      "learning_rate": 4.4897253061347296e-06,
      "loss": 0.031,
      "step": 423700
    },
    {
      "epoch": 14.57208678609497,
      "grad_norm": 0.25629615783691406,
      "learning_rate": 4.478979966388577e-06,
      "loss": 0.0291,
      "step": 423800
    },
    {
      "epoch": 14.575525220919438,
      "grad_norm": 0.2161531150341034,
      "learning_rate": 4.468234626642425e-06,
      "loss": 0.0275,
      "step": 423900
    },
    {
      "epoch": 14.578963655743905,
      "grad_norm": 0.40580660104751587,
      "learning_rate": 4.457489286896274e-06,
      "loss": 0.0273,
      "step": 424000
    },
    {
      "epoch": 14.582402090568372,
      "grad_norm": 0.147610142827034,
      "learning_rate": 4.446743947150121e-06,
      "loss": 0.0326,
      "step": 424100
    },
    {
      "epoch": 14.585840525392841,
      "grad_norm": 0.3805188238620758,
      "learning_rate": 4.435998607403969e-06,
      "loss": 0.0282,
      "step": 424200
    },
    {
      "epoch": 14.589278960217309,
      "grad_norm": 0.3209894895553589,
      "learning_rate": 4.425253267657817e-06,
      "loss": 0.0314,
      "step": 424300
    },
    {
      "epoch": 14.592717395041777,
      "grad_norm": 0.15396569669246674,
      "learning_rate": 4.414615381309126e-06,
      "loss": 0.0304,
      "step": 424400
    },
    {
      "epoch": 14.596155829866245,
      "grad_norm": 0.1936168670654297,
      "learning_rate": 4.403870041562974e-06,
      "loss": 0.0307,
      "step": 424500
    },
    {
      "epoch": 14.599594264690714,
      "grad_norm": 0.1777539700269699,
      "learning_rate": 4.393124701816823e-06,
      "loss": 0.0306,
      "step": 424600
    },
    {
      "epoch": 14.60303269951518,
      "grad_norm": 0.19220112264156342,
      "learning_rate": 4.3823793620706706e-06,
      "loss": 0.0301,
      "step": 424700
    },
    {
      "epoch": 14.606471134339648,
      "grad_norm": 0.2822074294090271,
      "learning_rate": 4.371634022324518e-06,
      "loss": 0.0326,
      "step": 424800
    },
    {
      "epoch": 14.609909569164117,
      "grad_norm": 0.3791184425354004,
      "learning_rate": 4.360888682578366e-06,
      "loss": 0.0299,
      "step": 424900
    },
    {
      "epoch": 14.613348003988584,
      "grad_norm": 0.34969645738601685,
      "learning_rate": 4.350143342832213e-06,
      "loss": 0.0282,
      "step": 425000
    },
    {
      "epoch": 14.616786438813053,
      "grad_norm": 0.23031237721443176,
      "learning_rate": 4.339398003086062e-06,
      "loss": 0.034,
      "step": 425100
    },
    {
      "epoch": 14.62022487363752,
      "grad_norm": 0.18307268619537354,
      "learning_rate": 4.32865266333991e-06,
      "loss": 0.0281,
      "step": 425200
    },
    {
      "epoch": 14.623663308461989,
      "grad_norm": 0.12014254927635193,
      "learning_rate": 4.3179073235937576e-06,
      "loss": 0.03,
      "step": 425300
    },
    {
      "epoch": 14.627101743286456,
      "grad_norm": 0.23883256316184998,
      "learning_rate": 4.307161983847605e-06,
      "loss": 0.0292,
      "step": 425400
    },
    {
      "epoch": 14.630540178110923,
      "grad_norm": 0.22932776808738708,
      "learning_rate": 4.296416644101453e-06,
      "loss": 0.0299,
      "step": 425500
    },
    {
      "epoch": 14.633978612935392,
      "grad_norm": 0.2309735268354416,
      "learning_rate": 4.285671304355302e-06,
      "loss": 0.0296,
      "step": 425600
    },
    {
      "epoch": 14.63741704775986,
      "grad_norm": 0.26820072531700134,
      "learning_rate": 4.274925964609149e-06,
      "loss": 0.0305,
      "step": 425700
    },
    {
      "epoch": 14.640855482584328,
      "grad_norm": 0.09233631938695908,
      "learning_rate": 4.264180624862997e-06,
      "loss": 0.032,
      "step": 425800
    },
    {
      "epoch": 14.644293917408795,
      "grad_norm": 0.15771131217479706,
      "learning_rate": 4.253435285116845e-06,
      "loss": 0.0322,
      "step": 425900
    },
    {
      "epoch": 14.647732352233263,
      "grad_norm": 0.04799345135688782,
      "learning_rate": 4.242689945370693e-06,
      "loss": 0.0306,
      "step": 426000
    },
    {
      "epoch": 14.651170787057731,
      "grad_norm": 0.3015132546424866,
      "learning_rate": 4.231944605624541e-06,
      "loss": 0.0297,
      "step": 426100
    },
    {
      "epoch": 14.654609221882199,
      "grad_norm": 0.13767549395561218,
      "learning_rate": 4.221199265878389e-06,
      "loss": 0.0333,
      "step": 426200
    },
    {
      "epoch": 14.658047656706668,
      "grad_norm": 0.43398112058639526,
      "learning_rate": 4.210453926132237e-06,
      "loss": 0.0296,
      "step": 426300
    },
    {
      "epoch": 14.661486091531135,
      "grad_norm": 0.1830717921257019,
      "learning_rate": 4.199708586386085e-06,
      "loss": 0.0324,
      "step": 426400
    },
    {
      "epoch": 14.664924526355604,
      "grad_norm": 0.11393129825592041,
      "learning_rate": 4.1889632466399325e-06,
      "loss": 0.0289,
      "step": 426500
    },
    {
      "epoch": 14.66836296118007,
      "grad_norm": 0.18081620335578918,
      "learning_rate": 4.17821790689378e-06,
      "loss": 0.0288,
      "step": 426600
    },
    {
      "epoch": 14.671801396004538,
      "grad_norm": 0.46538713574409485,
      "learning_rate": 4.167472567147628e-06,
      "loss": 0.0332,
      "step": 426700
    },
    {
      "epoch": 14.675239830829007,
      "grad_norm": 0.3230186998844147,
      "learning_rate": 4.156834680798938e-06,
      "loss": 0.032,
      "step": 426800
    },
    {
      "epoch": 14.678678265653474,
      "grad_norm": 0.22967638075351715,
      "learning_rate": 4.146089341052786e-06,
      "loss": 0.0346,
      "step": 426900
    },
    {
      "epoch": 14.682116700477943,
      "grad_norm": 0.13089513778686523,
      "learning_rate": 4.135344001306633e-06,
      "loss": 0.0299,
      "step": 427000
    },
    {
      "epoch": 14.68555513530241,
      "grad_norm": 0.16866730153560638,
      "learning_rate": 4.124598661560482e-06,
      "loss": 0.031,
      "step": 427100
    },
    {
      "epoch": 14.688993570126879,
      "grad_norm": 0.5749500393867493,
      "learning_rate": 4.113853321814329e-06,
      "loss": 0.028,
      "step": 427200
    },
    {
      "epoch": 14.692432004951346,
      "grad_norm": 0.5675979256629944,
      "learning_rate": 4.103107982068177e-06,
      "loss": 0.0344,
      "step": 427300
    },
    {
      "epoch": 14.695870439775813,
      "grad_norm": 0.37959587574005127,
      "learning_rate": 4.092362642322025e-06,
      "loss": 0.0308,
      "step": 427400
    },
    {
      "epoch": 14.699308874600282,
      "grad_norm": 0.11211837083101273,
      "learning_rate": 4.081617302575873e-06,
      "loss": 0.0306,
      "step": 427500
    },
    {
      "epoch": 14.70274730942475,
      "grad_norm": 0.28166526556015015,
      "learning_rate": 4.070871962829721e-06,
      "loss": 0.0284,
      "step": 427600
    },
    {
      "epoch": 14.706185744249218,
      "grad_norm": 0.35235342383384705,
      "learning_rate": 4.060126623083569e-06,
      "loss": 0.0318,
      "step": 427700
    },
    {
      "epoch": 14.709624179073685,
      "grad_norm": 0.09181956201791763,
      "learning_rate": 4.049381283337417e-06,
      "loss": 0.0281,
      "step": 427800
    },
    {
      "epoch": 14.713062613898153,
      "grad_norm": 0.5219662189483643,
      "learning_rate": 4.038635943591265e-06,
      "loss": 0.031,
      "step": 427900
    },
    {
      "epoch": 14.716501048722622,
      "grad_norm": 0.14432324469089508,
      "learning_rate": 4.027890603845113e-06,
      "loss": 0.031,
      "step": 428000
    },
    {
      "epoch": 14.719939483547089,
      "grad_norm": 0.07208237797021866,
      "learning_rate": 4.0171452640989605e-06,
      "loss": 0.0264,
      "step": 428100
    },
    {
      "epoch": 14.723377918371558,
      "grad_norm": 0.13491903245449066,
      "learning_rate": 4.006399924352808e-06,
      "loss": 0.0313,
      "step": 428200
    },
    {
      "epoch": 14.726816353196025,
      "grad_norm": 0.45847925543785095,
      "learning_rate": 3.995654584606656e-06,
      "loss": 0.0308,
      "step": 428300
    },
    {
      "epoch": 14.730254788020494,
      "grad_norm": 0.28233543038368225,
      "learning_rate": 3.984909244860504e-06,
      "loss": 0.0294,
      "step": 428400
    },
    {
      "epoch": 14.73369322284496,
      "grad_norm": 0.19022104144096375,
      "learning_rate": 3.974163905114353e-06,
      "loss": 0.0313,
      "step": 428500
    },
    {
      "epoch": 14.73713165766943,
      "grad_norm": 0.11065198481082916,
      "learning_rate": 3.9634185653682005e-06,
      "loss": 0.0303,
      "step": 428600
    },
    {
      "epoch": 14.740570092493897,
      "grad_norm": 0.2357044667005539,
      "learning_rate": 3.952673225622048e-06,
      "loss": 0.0295,
      "step": 428700
    },
    {
      "epoch": 14.744008527318364,
      "grad_norm": 0.21702952682971954,
      "learning_rate": 3.941927885875895e-06,
      "loss": 0.0296,
      "step": 428800
    },
    {
      "epoch": 14.747446962142833,
      "grad_norm": 0.27711471915245056,
      "learning_rate": 3.931182546129743e-06,
      "loss": 0.0318,
      "step": 428900
    },
    {
      "epoch": 14.7508853969673,
      "grad_norm": 0.43995872139930725,
      "learning_rate": 3.920437206383592e-06,
      "loss": 0.0289,
      "step": 429000
    },
    {
      "epoch": 14.754323831791769,
      "grad_norm": 0.31630340218544006,
      "learning_rate": 3.90969186663744e-06,
      "loss": 0.0308,
      "step": 429100
    },
    {
      "epoch": 14.757762266616236,
      "grad_norm": 0.1523323655128479,
      "learning_rate": 3.8989465268912875e-06,
      "loss": 0.0303,
      "step": 429200
    },
    {
      "epoch": 14.761200701440703,
      "grad_norm": 0.612673819065094,
      "learning_rate": 3.888308640542597e-06,
      "loss": 0.0304,
      "step": 429300
    },
    {
      "epoch": 14.764639136265172,
      "grad_norm": 0.14989572763442993,
      "learning_rate": 3.877563300796445e-06,
      "loss": 0.0311,
      "step": 429400
    },
    {
      "epoch": 14.76807757108964,
      "grad_norm": 0.12924900650978088,
      "learning_rate": 3.866817961050293e-06,
      "loss": 0.0306,
      "step": 429500
    },
    {
      "epoch": 14.771516005914108,
      "grad_norm": 0.20552566647529602,
      "learning_rate": 3.856072621304141e-06,
      "loss": 0.0307,
      "step": 429600
    },
    {
      "epoch": 14.774954440738576,
      "grad_norm": 0.20658260583877563,
      "learning_rate": 3.8453272815579885e-06,
      "loss": 0.0338,
      "step": 429700
    },
    {
      "epoch": 14.778392875563044,
      "grad_norm": 0.5373874306678772,
      "learning_rate": 3.834581941811836e-06,
      "loss": 0.0291,
      "step": 429800
    },
    {
      "epoch": 14.781831310387512,
      "grad_norm": 0.1128140538930893,
      "learning_rate": 3.823836602065684e-06,
      "loss": 0.0332,
      "step": 429900
    },
    {
      "epoch": 14.785269745211979,
      "grad_norm": 0.22278697788715363,
      "learning_rate": 3.813091262319532e-06,
      "loss": 0.0331,
      "step": 430000
    },
    {
      "epoch": 14.788708180036448,
      "grad_norm": 0.05959901213645935,
      "learning_rate": 3.8023459225733802e-06,
      "loss": 0.0309,
      "step": 430100
    },
    {
      "epoch": 14.792146614860915,
      "grad_norm": 0.2410355806350708,
      "learning_rate": 3.791600582827228e-06,
      "loss": 0.0338,
      "step": 430200
    },
    {
      "epoch": 14.795585049685384,
      "grad_norm": 0.25684258341789246,
      "learning_rate": 3.780855243081076e-06,
      "loss": 0.031,
      "step": 430300
    },
    {
      "epoch": 14.799023484509851,
      "grad_norm": 0.06930138170719147,
      "learning_rate": 3.7701099033349238e-06,
      "loss": 0.0301,
      "step": 430400
    },
    {
      "epoch": 14.80246191933432,
      "grad_norm": 0.1730048805475235,
      "learning_rate": 3.7593645635887716e-06,
      "loss": 0.029,
      "step": 430500
    },
    {
      "epoch": 14.805900354158787,
      "grad_norm": 0.14474953711032867,
      "learning_rate": 3.74861922384262e-06,
      "loss": 0.0322,
      "step": 430600
    },
    {
      "epoch": 14.809338788983254,
      "grad_norm": 0.05448588356375694,
      "learning_rate": 3.7378738840964677e-06,
      "loss": 0.0318,
      "step": 430700
    },
    {
      "epoch": 14.812777223807723,
      "grad_norm": 0.06934448331594467,
      "learning_rate": 3.7271285443503155e-06,
      "loss": 0.0301,
      "step": 430800
    },
    {
      "epoch": 14.81621565863219,
      "grad_norm": 0.35903099179267883,
      "learning_rate": 3.716383204604163e-06,
      "loss": 0.0299,
      "step": 430900
    },
    {
      "epoch": 14.81965409345666,
      "grad_norm": 0.20308449864387512,
      "learning_rate": 3.7056378648580116e-06,
      "loss": 0.0283,
      "step": 431000
    },
    {
      "epoch": 14.823092528281126,
      "grad_norm": 1.10037362575531,
      "learning_rate": 3.6948925251118595e-06,
      "loss": 0.0356,
      "step": 431100
    },
    {
      "epoch": 14.826530963105593,
      "grad_norm": 0.13248632848262787,
      "learning_rate": 3.6841471853657073e-06,
      "loss": 0.0271,
      "step": 431200
    },
    {
      "epoch": 14.829969397930062,
      "grad_norm": 0.6564549207687378,
      "learning_rate": 3.6734018456195547e-06,
      "loss": 0.0308,
      "step": 431300
    },
    {
      "epoch": 14.83340783275453,
      "grad_norm": 0.1875985860824585,
      "learning_rate": 3.6626565058734025e-06,
      "loss": 0.0317,
      "step": 431400
    },
    {
      "epoch": 14.836846267578998,
      "grad_norm": 0.09856091439723969,
      "learning_rate": 3.6519111661272512e-06,
      "loss": 0.0298,
      "step": 431500
    },
    {
      "epoch": 14.840284702403466,
      "grad_norm": 0.32785362005233765,
      "learning_rate": 3.6411658263810986e-06,
      "loss": 0.0301,
      "step": 431600
    },
    {
      "epoch": 14.843723137227935,
      "grad_norm": 0.3310891389846802,
      "learning_rate": 3.6304204866349465e-06,
      "loss": 0.0304,
      "step": 431700
    },
    {
      "epoch": 14.847161572052402,
      "grad_norm": 0.204366073012352,
      "learning_rate": 3.6196751468887943e-06,
      "loss": 0.0304,
      "step": 431800
    },
    {
      "epoch": 14.850600006876869,
      "grad_norm": 0.3056527078151703,
      "learning_rate": 3.608929807142642e-06,
      "loss": 0.0294,
      "step": 431900
    },
    {
      "epoch": 14.854038441701338,
      "grad_norm": 0.9561220407485962,
      "learning_rate": 3.5981844673964904e-06,
      "loss": 0.0315,
      "step": 432000
    },
    {
      "epoch": 14.857476876525805,
      "grad_norm": 0.5405786633491516,
      "learning_rate": 3.5874391276503382e-06,
      "loss": 0.0295,
      "step": 432100
    },
    {
      "epoch": 14.860915311350274,
      "grad_norm": 0.2567354142665863,
      "learning_rate": 3.576693787904186e-06,
      "loss": 0.0282,
      "step": 432200
    },
    {
      "epoch": 14.864353746174741,
      "grad_norm": 0.1842803955078125,
      "learning_rate": 3.565948448158034e-06,
      "loss": 0.0281,
      "step": 432300
    },
    {
      "epoch": 14.86779218099921,
      "grad_norm": 0.6311932802200317,
      "learning_rate": 3.555203108411882e-06,
      "loss": 0.0334,
      "step": 432400
    },
    {
      "epoch": 14.871230615823677,
      "grad_norm": 0.1730382740497589,
      "learning_rate": 3.54445776866573e-06,
      "loss": 0.0309,
      "step": 432500
    },
    {
      "epoch": 14.874669050648144,
      "grad_norm": 0.42680877447128296,
      "learning_rate": 3.533712428919578e-06,
      "loss": 0.0283,
      "step": 432600
    },
    {
      "epoch": 14.878107485472613,
      "grad_norm": 0.258775919675827,
      "learning_rate": 3.5230745425708875e-06,
      "loss": 0.0301,
      "step": 432700
    },
    {
      "epoch": 14.88154592029708,
      "grad_norm": 0.08546050637960434,
      "learning_rate": 3.5123292028247353e-06,
      "loss": 0.0302,
      "step": 432800
    },
    {
      "epoch": 14.88498435512155,
      "grad_norm": 0.31378522515296936,
      "learning_rate": 3.5015838630785827e-06,
      "loss": 0.0296,
      "step": 432900
    },
    {
      "epoch": 14.888422789946016,
      "grad_norm": 0.26879867911338806,
      "learning_rate": 3.4908385233324306e-06,
      "loss": 0.0293,
      "step": 433000
    },
    {
      "epoch": 14.891861224770484,
      "grad_norm": 0.7483718395233154,
      "learning_rate": 3.4800931835862792e-06,
      "loss": 0.0301,
      "step": 433100
    },
    {
      "epoch": 14.895299659594953,
      "grad_norm": 0.24206148087978363,
      "learning_rate": 3.4693478438401266e-06,
      "loss": 0.0297,
      "step": 433200
    },
    {
      "epoch": 14.89873809441942,
      "grad_norm": 0.3333147168159485,
      "learning_rate": 3.4586025040939745e-06,
      "loss": 0.0327,
      "step": 433300
    },
    {
      "epoch": 14.902176529243889,
      "grad_norm": 0.24937793612480164,
      "learning_rate": 3.4478571643478223e-06,
      "loss": 0.029,
      "step": 433400
    },
    {
      "epoch": 14.905614964068356,
      "grad_norm": 0.43190523982048035,
      "learning_rate": 3.43711182460167e-06,
      "loss": 0.0327,
      "step": 433500
    },
    {
      "epoch": 14.909053398892825,
      "grad_norm": 0.2025899440050125,
      "learning_rate": 3.4263664848555184e-06,
      "loss": 0.0283,
      "step": 433600
    },
    {
      "epoch": 14.912491833717292,
      "grad_norm": 0.16780316829681396,
      "learning_rate": 3.4156211451093663e-06,
      "loss": 0.0302,
      "step": 433700
    },
    {
      "epoch": 14.915930268541759,
      "grad_norm": 0.12689723074436188,
      "learning_rate": 3.404875805363214e-06,
      "loss": 0.0287,
      "step": 433800
    },
    {
      "epoch": 14.919368703366228,
      "grad_norm": 0.19168996810913086,
      "learning_rate": 3.394130465617062e-06,
      "loss": 0.0304,
      "step": 433900
    },
    {
      "epoch": 14.922807138190695,
      "grad_norm": 0.25185930728912354,
      "learning_rate": 3.3834925792683715e-06,
      "loss": 0.0309,
      "step": 434000
    },
    {
      "epoch": 14.926245573015164,
      "grad_norm": 0.15439096093177795,
      "learning_rate": 3.372747239522219e-06,
      "loss": 0.0305,
      "step": 434100
    },
    {
      "epoch": 14.929684007839631,
      "grad_norm": 0.19398309290409088,
      "learning_rate": 3.3620018997760676e-06,
      "loss": 0.0295,
      "step": 434200
    },
    {
      "epoch": 14.9331224426641,
      "grad_norm": 0.4000253975391388,
      "learning_rate": 3.3512565600299155e-06,
      "loss": 0.0345,
      "step": 434300
    },
    {
      "epoch": 14.936560877488567,
      "grad_norm": 0.20070737600326538,
      "learning_rate": 3.340511220283763e-06,
      "loss": 0.0333,
      "step": 434400
    },
    {
      "epoch": 14.939999312313034,
      "grad_norm": 0.5976412892341614,
      "learning_rate": 3.3297658805376107e-06,
      "loss": 0.0311,
      "step": 434500
    },
    {
      "epoch": 14.943437747137503,
      "grad_norm": 0.5057016611099243,
      "learning_rate": 3.3190205407914586e-06,
      "loss": 0.0298,
      "step": 434600
    },
    {
      "epoch": 14.94687618196197,
      "grad_norm": 0.2117527276277542,
      "learning_rate": 3.3082752010453072e-06,
      "loss": 0.028,
      "step": 434700
    },
    {
      "epoch": 14.95031461678644,
      "grad_norm": 0.2635992169380188,
      "learning_rate": 3.2975298612991547e-06,
      "loss": 0.0277,
      "step": 434800
    },
    {
      "epoch": 14.953753051610907,
      "grad_norm": 0.22439821064472198,
      "learning_rate": 3.2867845215530025e-06,
      "loss": 0.0305,
      "step": 434900
    },
    {
      "epoch": 14.957191486435375,
      "grad_norm": 0.3385249376296997,
      "learning_rate": 3.2760391818068503e-06,
      "loss": 0.0323,
      "step": 435000
    },
    {
      "epoch": 14.960629921259843,
      "grad_norm": 0.30461227893829346,
      "learning_rate": 3.2652938420606986e-06,
      "loss": 0.0292,
      "step": 435100
    },
    {
      "epoch": 14.96406835608431,
      "grad_norm": 0.16031542420387268,
      "learning_rate": 3.2545485023145464e-06,
      "loss": 0.0315,
      "step": 435200
    },
    {
      "epoch": 14.967506790908779,
      "grad_norm": 0.2671385109424591,
      "learning_rate": 3.2438031625683943e-06,
      "loss": 0.0269,
      "step": 435300
    },
    {
      "epoch": 14.970945225733246,
      "grad_norm": 0.4072926938533783,
      "learning_rate": 3.233057822822242e-06,
      "loss": 0.0303,
      "step": 435400
    },
    {
      "epoch": 14.974383660557715,
      "grad_norm": 0.14015933871269226,
      "learning_rate": 3.22231248307609e-06,
      "loss": 0.0296,
      "step": 435500
    },
    {
      "epoch": 14.977822095382182,
      "grad_norm": 0.43548163771629333,
      "learning_rate": 3.211567143329938e-06,
      "loss": 0.0277,
      "step": 435600
    },
    {
      "epoch": 14.98126053020665,
      "grad_norm": 0.178167924284935,
      "learning_rate": 3.200821803583786e-06,
      "loss": 0.0317,
      "step": 435700
    },
    {
      "epoch": 14.984698965031118,
      "grad_norm": 0.2829568088054657,
      "learning_rate": 3.190076463837634e-06,
      "loss": 0.0315,
      "step": 435800
    },
    {
      "epoch": 14.988137399855585,
      "grad_norm": 0.17697317898273468,
      "learning_rate": 3.1793311240914817e-06,
      "loss": 0.0331,
      "step": 435900
    },
    {
      "epoch": 14.991575834680054,
      "grad_norm": 0.5012985467910767,
      "learning_rate": 3.168585784345329e-06,
      "loss": 0.0302,
      "step": 436000
    },
    {
      "epoch": 14.995014269504521,
      "grad_norm": 0.3182559609413147,
      "learning_rate": 3.157840444599178e-06,
      "loss": 0.0328,
      "step": 436100
    },
    {
      "epoch": 14.99845270432899,
      "grad_norm": 0.0793100968003273,
      "learning_rate": 3.1470951048530256e-06,
      "loss": 0.0342,
      "step": 436200
    },
    {
      "epoch": 15.0,
      "eval_accuracy_macro_0.5": 0.9864093065261841,
      "eval_accuracy_micro_0.5": 0.9864093065261841,
      "eval_accuracy_weighted_0.5": 0.9778057336807251,
      "eval_aucroc_macro": 0.9309640526771545,
      "eval_aucroc_micro": 0.9321601390838623,
      "eval_aucroc_weighted": 0.9295316934585571,
      "eval_f1_macro_0.5": 0.800777018070221,
      "eval_f1_macro_0.6": 0.7930419445037842,
      "eval_f1_macro_0.7": 0.7760197520256042,
      "eval_f1_macro_0.8": 0.6582730412483215,
      "eval_f1_micro_0.5": 0.8060261607170105,
      "eval_f1_micro_0.6": 0.7991741895675659,
      "eval_f1_micro_0.7": 0.7831574082374573,
      "eval_f1_micro_0.8": 0.7493305802345276,
      "eval_f1_micro_0.9": 0.672744870185852,
      "eval_f1_weighted_0.5": 0.8032252788543701,
      "eval_f1_weighted_0.6": 0.7935184240341187,
      "eval_f1_weighted_0.7": 0.7736368775367737,
      "eval_f1_weighted_0.8": 0.643789529800415,
      "eval_loss": 0.0295206718146801,
      "eval_runtime": 1892.7863,
      "eval_samples_per_second": 30.712,
      "eval_steps_per_second": 3.839,
      "step": 436245
    },
    {
      "epoch": 15.001891139153457,
      "grad_norm": 0.20660871267318726,
      "learning_rate": 3.136349765106873e-06,
      "loss": 0.0317,
      "step": 436300
    },
    {
      "epoch": 15.005329573977924,
      "grad_norm": 0.1678391396999359,
      "learning_rate": 3.125604425360721e-06,
      "loss": 0.0285,
      "step": 436400
    },
    {
      "epoch": 15.008768008802393,
      "grad_norm": 0.06418133527040482,
      "learning_rate": 3.114859085614569e-06,
      "loss": 0.0297,
      "step": 436500
    },
    {
      "epoch": 15.01220644362686,
      "grad_norm": 0.1954617202281952,
      "learning_rate": 3.104113745868417e-06,
      "loss": 0.0296,
      "step": 436600
    },
    {
      "epoch": 15.01564487845133,
      "grad_norm": 0.24110746383666992,
      "learning_rate": 3.093368406122265e-06,
      "loss": 0.0298,
      "step": 436700
    },
    {
      "epoch": 15.019083313275797,
      "grad_norm": 0.3013915419578552,
      "learning_rate": 3.0826230663761127e-06,
      "loss": 0.0307,
      "step": 436800
    },
    {
      "epoch": 15.022521748100266,
      "grad_norm": 0.10104037821292877,
      "learning_rate": 3.071877726629961e-06,
      "loss": 0.0293,
      "step": 436900
    },
    {
      "epoch": 15.025960182924733,
      "grad_norm": 0.06228005141019821,
      "learning_rate": 3.0611323868838088e-06,
      "loss": 0.029,
      "step": 437000
    },
    {
      "epoch": 15.0293986177492,
      "grad_norm": 0.11493314802646637,
      "learning_rate": 3.0503870471376566e-06,
      "loss": 0.0307,
      "step": 437100
    },
    {
      "epoch": 15.032837052573669,
      "grad_norm": 0.32561349868774414,
      "learning_rate": 3.0396417073915044e-06,
      "loss": 0.033,
      "step": 437200
    },
    {
      "epoch": 15.036275487398136,
      "grad_norm": 0.03666665777564049,
      "learning_rate": 3.0288963676453527e-06,
      "loss": 0.0283,
      "step": 437300
    },
    {
      "epoch": 15.039713922222605,
      "grad_norm": 0.045503079891204834,
      "learning_rate": 3.0181510278992e-06,
      "loss": 0.0292,
      "step": 437400
    },
    {
      "epoch": 15.043152357047072,
      "grad_norm": 0.20801720023155212,
      "learning_rate": 3.007405688153048e-06,
      "loss": 0.0305,
      "step": 437500
    },
    {
      "epoch": 15.046590791871541,
      "grad_norm": 0.22347472608089447,
      "learning_rate": 2.996660348406896e-06,
      "loss": 0.0324,
      "step": 437600
    },
    {
      "epoch": 15.050029226696008,
      "grad_norm": 0.19323085248470306,
      "learning_rate": 2.985915008660744e-06,
      "loss": 0.0309,
      "step": 437700
    },
    {
      "epoch": 15.053467661520475,
      "grad_norm": 0.10373904556035995,
      "learning_rate": 2.975169668914592e-06,
      "loss": 0.0315,
      "step": 437800
    },
    {
      "epoch": 15.056906096344944,
      "grad_norm": 0.1336238533258438,
      "learning_rate": 2.9644243291684397e-06,
      "loss": 0.0304,
      "step": 437900
    },
    {
      "epoch": 15.060344531169411,
      "grad_norm": 0.2544471025466919,
      "learning_rate": 2.953678989422288e-06,
      "loss": 0.0318,
      "step": 438000
    },
    {
      "epoch": 15.06378296599388,
      "grad_norm": 0.27513960003852844,
      "learning_rate": 2.942933649676136e-06,
      "loss": 0.0293,
      "step": 438100
    },
    {
      "epoch": 15.067221400818347,
      "grad_norm": 0.17532692849636078,
      "learning_rate": 2.932188309929983e-06,
      "loss": 0.0321,
      "step": 438200
    },
    {
      "epoch": 15.070659835642815,
      "grad_norm": 0.12829527258872986,
      "learning_rate": 2.9214429701838315e-06,
      "loss": 0.0311,
      "step": 438300
    },
    {
      "epoch": 15.074098270467283,
      "grad_norm": 0.1623721867799759,
      "learning_rate": 2.9106976304376793e-06,
      "loss": 0.0274,
      "step": 438400
    },
    {
      "epoch": 15.07753670529175,
      "grad_norm": 0.12677180767059326,
      "learning_rate": 2.899952290691527e-06,
      "loss": 0.0284,
      "step": 438500
    },
    {
      "epoch": 15.08097514011622,
      "grad_norm": 0.10634070634841919,
      "learning_rate": 2.889206950945375e-06,
      "loss": 0.0298,
      "step": 438600
    },
    {
      "epoch": 15.084413574940687,
      "grad_norm": 0.3264510929584503,
      "learning_rate": 2.8784616111992232e-06,
      "loss": 0.0331,
      "step": 438700
    },
    {
      "epoch": 15.087852009765156,
      "grad_norm": 0.05595560371875763,
      "learning_rate": 2.8678237248505324e-06,
      "loss": 0.0283,
      "step": 438800
    },
    {
      "epoch": 15.091290444589623,
      "grad_norm": 0.303384006023407,
      "learning_rate": 2.8570783851043807e-06,
      "loss": 0.0289,
      "step": 438900
    },
    {
      "epoch": 15.09472887941409,
      "grad_norm": 0.04669997841119766,
      "learning_rate": 2.846333045358228e-06,
      "loss": 0.0301,
      "step": 439000
    },
    {
      "epoch": 15.098167314238559,
      "grad_norm": 0.21442604064941406,
      "learning_rate": 2.835587705612076e-06,
      "loss": 0.0318,
      "step": 439100
    },
    {
      "epoch": 15.101605749063026,
      "grad_norm": 0.06438533216714859,
      "learning_rate": 2.824842365865924e-06,
      "loss": 0.0313,
      "step": 439200
    },
    {
      "epoch": 15.105044183887495,
      "grad_norm": 0.07333329319953918,
      "learning_rate": 2.814097026119772e-06,
      "loss": 0.0306,
      "step": 439300
    },
    {
      "epoch": 15.108482618711962,
      "grad_norm": 0.013944246806204319,
      "learning_rate": 2.80335168637362e-06,
      "loss": 0.0302,
      "step": 439400
    },
    {
      "epoch": 15.111921053536431,
      "grad_norm": 0.23511958122253418,
      "learning_rate": 2.7926063466274677e-06,
      "loss": 0.031,
      "step": 439500
    },
    {
      "epoch": 15.115359488360898,
      "grad_norm": 0.13693569600582123,
      "learning_rate": 2.781861006881316e-06,
      "loss": 0.0303,
      "step": 439600
    },
    {
      "epoch": 15.118797923185365,
      "grad_norm": 0.20784735679626465,
      "learning_rate": 2.771115667135164e-06,
      "loss": 0.0288,
      "step": 439700
    },
    {
      "epoch": 15.122236358009834,
      "grad_norm": 0.11632067710161209,
      "learning_rate": 2.7603703273890112e-06,
      "loss": 0.0304,
      "step": 439800
    },
    {
      "epoch": 15.125674792834301,
      "grad_norm": 0.0630495622754097,
      "learning_rate": 2.7496249876428595e-06,
      "loss": 0.0323,
      "step": 439900
    },
    {
      "epoch": 15.12911322765877,
      "grad_norm": 0.19283822178840637,
      "learning_rate": 2.7388796478967073e-06,
      "loss": 0.0298,
      "step": 440000
    },
    {
      "epoch": 15.132551662483237,
      "grad_norm": 0.15000072121620178,
      "learning_rate": 2.728134308150555e-06,
      "loss": 0.0285,
      "step": 440100
    },
    {
      "epoch": 15.135990097307706,
      "grad_norm": 0.13417084515094757,
      "learning_rate": 2.717388968404403e-06,
      "loss": 0.0315,
      "step": 440200
    },
    {
      "epoch": 15.139428532132174,
      "grad_norm": 0.3510677218437195,
      "learning_rate": 2.7066436286582512e-06,
      "loss": 0.0299,
      "step": 440300
    },
    {
      "epoch": 15.14286696695664,
      "grad_norm": 0.14434733986854553,
      "learning_rate": 2.695898288912099e-06,
      "loss": 0.033,
      "step": 440400
    },
    {
      "epoch": 15.14630540178111,
      "grad_norm": 0.11937025934457779,
      "learning_rate": 2.6851529491659465e-06,
      "loss": 0.0294,
      "step": 440500
    },
    {
      "epoch": 15.149743836605577,
      "grad_norm": 0.07726963609457016,
      "learning_rate": 2.6744076094197948e-06,
      "loss": 0.0315,
      "step": 440600
    },
    {
      "epoch": 15.153182271430046,
      "grad_norm": 0.10037489235401154,
      "learning_rate": 2.6636622696736426e-06,
      "loss": 0.0349,
      "step": 440700
    },
    {
      "epoch": 15.156620706254513,
      "grad_norm": 0.07657641917467117,
      "learning_rate": 2.652916929927491e-06,
      "loss": 0.0285,
      "step": 440800
    },
    {
      "epoch": 15.16005914107898,
      "grad_norm": 0.21035003662109375,
      "learning_rate": 2.6421715901813383e-06,
      "loss": 0.0284,
      "step": 440900
    },
    {
      "epoch": 15.163497575903449,
      "grad_norm": 0.09895746409893036,
      "learning_rate": 2.6314262504351865e-06,
      "loss": 0.0302,
      "step": 441000
    },
    {
      "epoch": 15.166936010727916,
      "grad_norm": 0.24494731426239014,
      "learning_rate": 2.6206809106890344e-06,
      "loss": 0.0302,
      "step": 441100
    },
    {
      "epoch": 15.170374445552385,
      "grad_norm": 0.14708779752254486,
      "learning_rate": 2.610043024340344e-06,
      "loss": 0.0299,
      "step": 441200
    },
    {
      "epoch": 15.173812880376852,
      "grad_norm": 0.07406315207481384,
      "learning_rate": 2.5992976845941914e-06,
      "loss": 0.0325,
      "step": 441300
    },
    {
      "epoch": 15.177251315201321,
      "grad_norm": 0.08792181313037872,
      "learning_rate": 2.5885523448480397e-06,
      "loss": 0.0314,
      "step": 441400
    },
    {
      "epoch": 15.180689750025788,
      "grad_norm": 0.17785072326660156,
      "learning_rate": 2.5778070051018875e-06,
      "loss": 0.0284,
      "step": 441500
    },
    {
      "epoch": 15.184128184850255,
      "grad_norm": 0.10853832215070724,
      "learning_rate": 2.5670616653557353e-06,
      "loss": 0.0313,
      "step": 441600
    },
    {
      "epoch": 15.187566619674724,
      "grad_norm": 0.47963041067123413,
      "learning_rate": 2.556316325609583e-06,
      "loss": 0.0317,
      "step": 441700
    },
    {
      "epoch": 15.191005054499191,
      "grad_norm": 0.035011399537324905,
      "learning_rate": 2.545570985863431e-06,
      "loss": 0.0325,
      "step": 441800
    },
    {
      "epoch": 15.19444348932366,
      "grad_norm": 0.16283243894577026,
      "learning_rate": 2.5348256461172793e-06,
      "loss": 0.0306,
      "step": 441900
    },
    {
      "epoch": 15.197881924148128,
      "grad_norm": 0.10158002376556396,
      "learning_rate": 2.524080306371127e-06,
      "loss": 0.0327,
      "step": 442000
    },
    {
      "epoch": 15.201320358972596,
      "grad_norm": 0.1372329294681549,
      "learning_rate": 2.513334966624975e-06,
      "loss": 0.0341,
      "step": 442100
    },
    {
      "epoch": 15.204758793797064,
      "grad_norm": 0.4373733699321747,
      "learning_rate": 2.5025896268788228e-06,
      "loss": 0.0324,
      "step": 442200
    },
    {
      "epoch": 15.20819722862153,
      "grad_norm": 0.1793755292892456,
      "learning_rate": 2.4918442871326706e-06,
      "loss": 0.0294,
      "step": 442300
    },
    {
      "epoch": 15.211635663446,
      "grad_norm": 0.12960241734981537,
      "learning_rate": 2.4810989473865184e-06,
      "loss": 0.0346,
      "step": 442400
    },
    {
      "epoch": 15.215074098270467,
      "grad_norm": 0.3530426323413849,
      "learning_rate": 2.4703536076403663e-06,
      "loss": 0.0316,
      "step": 442500
    },
    {
      "epoch": 15.218512533094936,
      "grad_norm": 0.08257872611284256,
      "learning_rate": 2.4596082678942145e-06,
      "loss": 0.031,
      "step": 442600
    },
    {
      "epoch": 15.221950967919403,
      "grad_norm": 0.0514862984418869,
      "learning_rate": 2.4488629281480624e-06,
      "loss": 0.0276,
      "step": 442700
    },
    {
      "epoch": 15.225389402743872,
      "grad_norm": 0.1768200397491455,
      "learning_rate": 2.43811758840191e-06,
      "loss": 0.0311,
      "step": 442800
    },
    {
      "epoch": 15.228827837568339,
      "grad_norm": 0.14431217312812805,
      "learning_rate": 2.427372248655758e-06,
      "loss": 0.0296,
      "step": 442900
    },
    {
      "epoch": 15.232266272392806,
      "grad_norm": 0.11810657382011414,
      "learning_rate": 2.416626908909606e-06,
      "loss": 0.0291,
      "step": 443000
    },
    {
      "epoch": 15.235704707217275,
      "grad_norm": 0.251694917678833,
      "learning_rate": 2.405881569163454e-06,
      "loss": 0.0294,
      "step": 443100
    },
    {
      "epoch": 15.239143142041742,
      "grad_norm": 0.20716901123523712,
      "learning_rate": 2.3951362294173016e-06,
      "loss": 0.0328,
      "step": 443200
    },
    {
      "epoch": 15.242581576866211,
      "grad_norm": 0.06012272834777832,
      "learning_rate": 2.38439088967115e-06,
      "loss": 0.0309,
      "step": 443300
    },
    {
      "epoch": 15.246020011690678,
      "grad_norm": 0.08874311298131943,
      "learning_rate": 2.3736455499249976e-06,
      "loss": 0.0299,
      "step": 443400
    },
    {
      "epoch": 15.249458446515145,
      "grad_norm": 0.0797906219959259,
      "learning_rate": 2.3630076635763073e-06,
      "loss": 0.0289,
      "step": 443500
    },
    {
      "epoch": 15.252896881339614,
      "grad_norm": 0.16026853024959564,
      "learning_rate": 2.352262323830155e-06,
      "loss": 0.0307,
      "step": 443600
    },
    {
      "epoch": 15.256335316164082,
      "grad_norm": 0.10817816108465195,
      "learning_rate": 2.341516984084003e-06,
      "loss": 0.0304,
      "step": 443700
    },
    {
      "epoch": 15.25977375098855,
      "grad_norm": 0.24084344506263733,
      "learning_rate": 2.3307716443378508e-06,
      "loss": 0.0306,
      "step": 443800
    },
    {
      "epoch": 15.263212185813018,
      "grad_norm": 0.33462366461753845,
      "learning_rate": 2.3200263045916986e-06,
      "loss": 0.0307,
      "step": 443900
    },
    {
      "epoch": 15.266650620637487,
      "grad_norm": 0.04730077460408211,
      "learning_rate": 2.3092809648455464e-06,
      "loss": 0.0306,
      "step": 444000
    },
    {
      "epoch": 15.270089055461954,
      "grad_norm": 0.16937115788459778,
      "learning_rate": 2.2985356250993943e-06,
      "loss": 0.0339,
      "step": 444100
    },
    {
      "epoch": 15.27352749028642,
      "grad_norm": 0.09558884054422379,
      "learning_rate": 2.2877902853532425e-06,
      "loss": 0.0307,
      "step": 444200
    },
    {
      "epoch": 15.27696592511089,
      "grad_norm": 0.06473028659820557,
      "learning_rate": 2.2770449456070904e-06,
      "loss": 0.0307,
      "step": 444300
    },
    {
      "epoch": 15.280404359935357,
      "grad_norm": 0.14820297062397003,
      "learning_rate": 2.2662996058609382e-06,
      "loss": 0.0322,
      "step": 444400
    },
    {
      "epoch": 15.283842794759826,
      "grad_norm": 0.08175255358219147,
      "learning_rate": 2.255554266114786e-06,
      "loss": 0.0285,
      "step": 444500
    },
    {
      "epoch": 15.287281229584293,
      "grad_norm": 0.08184928447008133,
      "learning_rate": 2.244808926368634e-06,
      "loss": 0.0295,
      "step": 444600
    },
    {
      "epoch": 15.290719664408762,
      "grad_norm": 0.12197743356227875,
      "learning_rate": 2.234063586622482e-06,
      "loss": 0.0293,
      "step": 444700
    },
    {
      "epoch": 15.294158099233229,
      "grad_norm": 0.22954316437244415,
      "learning_rate": 2.2233182468763296e-06,
      "loss": 0.0305,
      "step": 444800
    },
    {
      "epoch": 15.297596534057696,
      "grad_norm": 0.11957757920026779,
      "learning_rate": 2.212572907130178e-06,
      "loss": 0.0329,
      "step": 444900
    },
    {
      "epoch": 15.301034968882165,
      "grad_norm": 0.13291935622692108,
      "learning_rate": 2.2018275673840257e-06,
      "loss": 0.0283,
      "step": 445000
    },
    {
      "epoch": 15.304473403706632,
      "grad_norm": 0.024563018232584,
      "learning_rate": 2.1910822276378735e-06,
      "loss": 0.0284,
      "step": 445100
    },
    {
      "epoch": 15.307911838531101,
      "grad_norm": 0.153364896774292,
      "learning_rate": 2.1803368878917213e-06,
      "loss": 0.0316,
      "step": 445200
    },
    {
      "epoch": 15.311350273355568,
      "grad_norm": 0.07406876981258392,
      "learning_rate": 2.169591548145569e-06,
      "loss": 0.0302,
      "step": 445300
    },
    {
      "epoch": 15.314788708180036,
      "grad_norm": 0.08827165514230728,
      "learning_rate": 2.1588462083994174e-06,
      "loss": 0.0308,
      "step": 445400
    },
    {
      "epoch": 15.318227143004504,
      "grad_norm": 0.11254402250051498,
      "learning_rate": 2.1481008686532653e-06,
      "loss": 0.0352,
      "step": 445500
    },
    {
      "epoch": 15.321665577828972,
      "grad_norm": 0.1343490034341812,
      "learning_rate": 2.137355528907113e-06,
      "loss": 0.0306,
      "step": 445600
    },
    {
      "epoch": 15.32510401265344,
      "grad_norm": 0.12157043814659119,
      "learning_rate": 2.126610189160961e-06,
      "loss": 0.0317,
      "step": 445700
    },
    {
      "epoch": 15.328542447477908,
      "grad_norm": 0.31547415256500244,
      "learning_rate": 2.1159723028122706e-06,
      "loss": 0.0315,
      "step": 445800
    },
    {
      "epoch": 15.331980882302377,
      "grad_norm": 0.1029561385512352,
      "learning_rate": 2.1052269630661184e-06,
      "loss": 0.0283,
      "step": 445900
    },
    {
      "epoch": 15.335419317126844,
      "grad_norm": 0.09916342049837112,
      "learning_rate": 2.0944816233199662e-06,
      "loss": 0.0289,
      "step": 446000
    },
    {
      "epoch": 15.338857751951311,
      "grad_norm": 0.15273229777812958,
      "learning_rate": 2.083736283573814e-06,
      "loss": 0.0307,
      "step": 446100
    },
    {
      "epoch": 15.34229618677578,
      "grad_norm": 0.17041105031967163,
      "learning_rate": 2.0729909438276623e-06,
      "loss": 0.0283,
      "step": 446200
    },
    {
      "epoch": 15.345734621600247,
      "grad_norm": 0.039199721068143845,
      "learning_rate": 2.06224560408151e-06,
      "loss": 0.0288,
      "step": 446300
    },
    {
      "epoch": 15.349173056424716,
      "grad_norm": 0.05025266110897064,
      "learning_rate": 2.0515002643353576e-06,
      "loss": 0.0281,
      "step": 446400
    },
    {
      "epoch": 15.352611491249183,
      "grad_norm": 0.1712942123413086,
      "learning_rate": 2.040754924589206e-06,
      "loss": 0.0308,
      "step": 446500
    },
    {
      "epoch": 15.356049926073652,
      "grad_norm": 0.11425141990184784,
      "learning_rate": 2.0300095848430537e-06,
      "loss": 0.0312,
      "step": 446600
    },
    {
      "epoch": 15.35948836089812,
      "grad_norm": 0.17065374553203583,
      "learning_rate": 2.0192642450969015e-06,
      "loss": 0.0314,
      "step": 446700
    },
    {
      "epoch": 15.362926795722586,
      "grad_norm": 0.10299646109342575,
      "learning_rate": 2.0085189053507493e-06,
      "loss": 0.0318,
      "step": 446800
    },
    {
      "epoch": 15.366365230547055,
      "grad_norm": 0.39380958676338196,
      "learning_rate": 1.9977735656045976e-06,
      "loss": 0.0275,
      "step": 446900
    },
    {
      "epoch": 15.369803665371522,
      "grad_norm": 0.14509369432926178,
      "learning_rate": 1.9870282258584454e-06,
      "loss": 0.0318,
      "step": 447000
    },
    {
      "epoch": 15.373242100195991,
      "grad_norm": 0.056177105754613876,
      "learning_rate": 1.976282886112293e-06,
      "loss": 0.0307,
      "step": 447100
    },
    {
      "epoch": 15.376680535020459,
      "grad_norm": 0.19154374301433563,
      "learning_rate": 1.965537546366141e-06,
      "loss": 0.028,
      "step": 447200
    },
    {
      "epoch": 15.380118969844927,
      "grad_norm": 0.15248888731002808,
      "learning_rate": 1.954792206619989e-06,
      "loss": 0.0277,
      "step": 447300
    },
    {
      "epoch": 15.383557404669395,
      "grad_norm": 0.11248204857110977,
      "learning_rate": 1.944046866873837e-06,
      "loss": 0.0277,
      "step": 447400
    },
    {
      "epoch": 15.386995839493862,
      "grad_norm": 0.17450262606143951,
      "learning_rate": 1.9333015271276846e-06,
      "loss": 0.0286,
      "step": 447500
    },
    {
      "epoch": 15.39043427431833,
      "grad_norm": 0.18089014291763306,
      "learning_rate": 1.922556187381533e-06,
      "loss": 0.0302,
      "step": 447600
    },
    {
      "epoch": 15.393872709142798,
      "grad_norm": 0.14227508008480072,
      "learning_rate": 1.9118108476353807e-06,
      "loss": 0.0329,
      "step": 447700
    },
    {
      "epoch": 15.397311143967267,
      "grad_norm": 0.30364835262298584,
      "learning_rate": 1.9010655078892283e-06,
      "loss": 0.0319,
      "step": 447800
    },
    {
      "epoch": 15.400749578791734,
      "grad_norm": 0.11203619092702866,
      "learning_rate": 1.8903201681430764e-06,
      "loss": 0.0319,
      "step": 447900
    },
    {
      "epoch": 15.404188013616201,
      "grad_norm": 0.10523504763841629,
      "learning_rate": 1.8795748283969242e-06,
      "loss": 0.0278,
      "step": 448000
    },
    {
      "epoch": 15.40762644844067,
      "grad_norm": 0.09053918719291687,
      "learning_rate": 1.8688294886507723e-06,
      "loss": 0.0292,
      "step": 448100
    },
    {
      "epoch": 15.411064883265137,
      "grad_norm": 0.3336065709590912,
      "learning_rate": 1.8580841489046201e-06,
      "loss": 0.0314,
      "step": 448200
    },
    {
      "epoch": 15.414503318089606,
      "grad_norm": 0.14204661548137665,
      "learning_rate": 1.8473388091584682e-06,
      "loss": 0.0283,
      "step": 448300
    },
    {
      "epoch": 15.417941752914073,
      "grad_norm": 0.06407956033945084,
      "learning_rate": 1.836593469412316e-06,
      "loss": 0.0278,
      "step": 448400
    },
    {
      "epoch": 15.421380187738542,
      "grad_norm": 0.14588773250579834,
      "learning_rate": 1.8259555830636256e-06,
      "loss": 0.0348,
      "step": 448500
    },
    {
      "epoch": 15.42481862256301,
      "grad_norm": 0.06331098079681396,
      "learning_rate": 1.8152102433174732e-06,
      "loss": 0.0296,
      "step": 448600
    },
    {
      "epoch": 15.428257057387476,
      "grad_norm": 0.23412024974822998,
      "learning_rate": 1.804464903571321e-06,
      "loss": 0.0305,
      "step": 448700
    },
    {
      "epoch": 15.431695492211945,
      "grad_norm": 0.04470299556851387,
      "learning_rate": 1.7937195638251691e-06,
      "loss": 0.0305,
      "step": 448800
    },
    {
      "epoch": 15.435133927036413,
      "grad_norm": 0.14128199219703674,
      "learning_rate": 1.782974224079017e-06,
      "loss": 0.0312,
      "step": 448900
    },
    {
      "epoch": 15.438572361860881,
      "grad_norm": 0.20167185366153717,
      "learning_rate": 1.772228884332865e-06,
      "loss": 0.0293,
      "step": 449000
    },
    {
      "epoch": 15.442010796685349,
      "grad_norm": 0.3219890892505646,
      "learning_rate": 1.7614835445867128e-06,
      "loss": 0.0323,
      "step": 449100
    },
    {
      "epoch": 15.445449231509818,
      "grad_norm": 0.14231909811496735,
      "learning_rate": 1.7507382048405609e-06,
      "loss": 0.0302,
      "step": 449200
    },
    {
      "epoch": 15.448887666334285,
      "grad_norm": 0.13836219906806946,
      "learning_rate": 1.7399928650944085e-06,
      "loss": 0.0288,
      "step": 449300
    },
    {
      "epoch": 15.452326101158752,
      "grad_norm": 0.2587316930294037,
      "learning_rate": 1.7292475253482564e-06,
      "loss": 0.0334,
      "step": 449400
    },
    {
      "epoch": 15.45576453598322,
      "grad_norm": 0.17938721179962158,
      "learning_rate": 1.7185021856021044e-06,
      "loss": 0.0294,
      "step": 449500
    },
    {
      "epoch": 15.459202970807688,
      "grad_norm": 0.0964806005358696,
      "learning_rate": 1.7077568458559522e-06,
      "loss": 0.0301,
      "step": 449600
    },
    {
      "epoch": 15.462641405632157,
      "grad_norm": 0.08043032884597778,
      "learning_rate": 1.6970115061098003e-06,
      "loss": 0.0296,
      "step": 449700
    },
    {
      "epoch": 15.466079840456624,
      "grad_norm": 0.3973913788795471,
      "learning_rate": 1.6862661663636481e-06,
      "loss": 0.0313,
      "step": 449800
    },
    {
      "epoch": 15.469518275281093,
      "grad_norm": 0.16494260728359222,
      "learning_rate": 1.6755208266174962e-06,
      "loss": 0.0297,
      "step": 449900
    },
    {
      "epoch": 15.47295671010556,
      "grad_norm": 0.24853003025054932,
      "learning_rate": 1.664775486871344e-06,
      "loss": 0.0308,
      "step": 450000
    },
    {
      "epoch": 15.476395144930027,
      "grad_norm": 0.08813869953155518,
      "learning_rate": 1.654030147125192e-06,
      "loss": 0.0276,
      "step": 450100
    },
    {
      "epoch": 15.479833579754496,
      "grad_norm": 0.08843445032835007,
      "learning_rate": 1.6432848073790399e-06,
      "loss": 0.0296,
      "step": 450200
    },
    {
      "epoch": 15.483272014578963,
      "grad_norm": 0.19493386149406433,
      "learning_rate": 1.6325394676328875e-06,
      "loss": 0.0296,
      "step": 450300
    },
    {
      "epoch": 15.486710449403432,
      "grad_norm": 0.3098257780075073,
      "learning_rate": 1.6217941278867358e-06,
      "loss": 0.0321,
      "step": 450400
    },
    {
      "epoch": 15.4901488842279,
      "grad_norm": 0.13336272537708282,
      "learning_rate": 1.6110487881405834e-06,
      "loss": 0.0325,
      "step": 450500
    },
    {
      "epoch": 15.493587319052367,
      "grad_norm": 0.2793543338775635,
      "learning_rate": 1.6003034483944314e-06,
      "loss": 0.027,
      "step": 450600
    },
    {
      "epoch": 15.497025753876835,
      "grad_norm": 0.4307129979133606,
      "learning_rate": 1.5896655620457409e-06,
      "loss": 0.0312,
      "step": 450700
    },
    {
      "epoch": 15.500464188701303,
      "grad_norm": 0.07588671892881393,
      "learning_rate": 1.578920222299589e-06,
      "loss": 0.0302,
      "step": 450800
    },
    {
      "epoch": 15.503902623525772,
      "grad_norm": 0.06868540495634079,
      "learning_rate": 1.5681748825534365e-06,
      "loss": 0.0324,
      "step": 450900
    },
    {
      "epoch": 15.507341058350239,
      "grad_norm": 0.22360092401504517,
      "learning_rate": 1.5574295428072846e-06,
      "loss": 0.0319,
      "step": 451000
    },
    {
      "epoch": 15.510779493174708,
      "grad_norm": 0.3894059360027313,
      "learning_rate": 1.5466842030611324e-06,
      "loss": 0.0272,
      "step": 451100
    },
    {
      "epoch": 15.514217927999175,
      "grad_norm": 0.06331767141819,
      "learning_rate": 1.5359388633149805e-06,
      "loss": 0.0334,
      "step": 451200
    },
    {
      "epoch": 15.517656362823642,
      "grad_norm": 0.24519942700862885,
      "learning_rate": 1.5251935235688283e-06,
      "loss": 0.0311,
      "step": 451300
    },
    {
      "epoch": 15.52109479764811,
      "grad_norm": 0.0325293131172657,
      "learning_rate": 1.5144481838226763e-06,
      "loss": 0.0312,
      "step": 451400
    },
    {
      "epoch": 15.524533232472578,
      "grad_norm": 0.15575812757015228,
      "learning_rate": 1.503702844076524e-06,
      "loss": 0.0269,
      "step": 451500
    },
    {
      "epoch": 15.527971667297047,
      "grad_norm": 0.37036842107772827,
      "learning_rate": 1.492957504330372e-06,
      "loss": 0.0329,
      "step": 451600
    },
    {
      "epoch": 15.531410102121514,
      "grad_norm": 0.17520369589328766,
      "learning_rate": 1.4822121645842198e-06,
      "loss": 0.0307,
      "step": 451700
    },
    {
      "epoch": 15.534848536945983,
      "grad_norm": 0.11689573526382446,
      "learning_rate": 1.471466824838068e-06,
      "loss": 0.0333,
      "step": 451800
    },
    {
      "epoch": 15.53828697177045,
      "grad_norm": 0.146609365940094,
      "learning_rate": 1.4607214850919157e-06,
      "loss": 0.0292,
      "step": 451900
    },
    {
      "epoch": 15.541725406594917,
      "grad_norm": 0.1055133268237114,
      "learning_rate": 1.4499761453457636e-06,
      "loss": 0.0323,
      "step": 452000
    },
    {
      "epoch": 15.545163841419386,
      "grad_norm": 0.2545747756958008,
      "learning_rate": 1.4392308055996116e-06,
      "loss": 0.0334,
      "step": 452100
    },
    {
      "epoch": 15.548602276243853,
      "grad_norm": 0.16465462744235992,
      "learning_rate": 1.4284854658534592e-06,
      "loss": 0.0301,
      "step": 452200
    },
    {
      "epoch": 15.552040711068322,
      "grad_norm": 0.07747077941894531,
      "learning_rate": 1.4177401261073073e-06,
      "loss": 0.0331,
      "step": 452300
    },
    {
      "epoch": 15.55547914589279,
      "grad_norm": 0.42263704538345337,
      "learning_rate": 1.4069947863611551e-06,
      "loss": 0.0338,
      "step": 452400
    },
    {
      "epoch": 15.558917580717257,
      "grad_norm": 0.049784205853939056,
      "learning_rate": 1.3962494466150032e-06,
      "loss": 0.0297,
      "step": 452500
    },
    {
      "epoch": 15.562356015541726,
      "grad_norm": 0.10553041845560074,
      "learning_rate": 1.385504106868851e-06,
      "loss": 0.0329,
      "step": 452600
    },
    {
      "epoch": 15.565794450366193,
      "grad_norm": 0.20101787149906158,
      "learning_rate": 1.374758767122699e-06,
      "loss": 0.0281,
      "step": 452700
    },
    {
      "epoch": 15.569232885190662,
      "grad_norm": 0.27416396141052246,
      "learning_rate": 1.364013427376547e-06,
      "loss": 0.0269,
      "step": 452800
    },
    {
      "epoch": 15.572671320015129,
      "grad_norm": 0.14188992977142334,
      "learning_rate": 1.3532680876303947e-06,
      "loss": 0.0329,
      "step": 452900
    },
    {
      "epoch": 15.576109754839598,
      "grad_norm": 0.08316150307655334,
      "learning_rate": 1.3426302012817044e-06,
      "loss": 0.0314,
      "step": 453000
    },
    {
      "epoch": 15.579548189664065,
      "grad_norm": 0.17326848208904266,
      "learning_rate": 1.331884861535552e-06,
      "loss": 0.0294,
      "step": 453100
    },
    {
      "epoch": 15.582986624488532,
      "grad_norm": 0.1556590050458908,
      "learning_rate": 1.3211395217894e-06,
      "loss": 0.0294,
      "step": 453200
    },
    {
      "epoch": 15.586425059313001,
      "grad_norm": 0.1619873344898224,
      "learning_rate": 1.3103941820432479e-06,
      "loss": 0.0306,
      "step": 453300
    },
    {
      "epoch": 15.589863494137468,
      "grad_norm": 0.048881977796554565,
      "learning_rate": 1.2996488422970957e-06,
      "loss": 0.0293,
      "step": 453400
    },
    {
      "epoch": 15.593301928961937,
      "grad_norm": 0.33377838134765625,
      "learning_rate": 1.2889035025509437e-06,
      "loss": 0.0318,
      "step": 453500
    },
    {
      "epoch": 15.596740363786404,
      "grad_norm": 0.09457006305456161,
      "learning_rate": 1.2781581628047916e-06,
      "loss": 0.0284,
      "step": 453600
    },
    {
      "epoch": 15.600178798610873,
      "grad_norm": 0.09386689960956573,
      "learning_rate": 1.2674128230586396e-06,
      "loss": 0.028,
      "step": 453700
    },
    {
      "epoch": 15.60361723343534,
      "grad_norm": 0.05130927264690399,
      "learning_rate": 1.2566674833124875e-06,
      "loss": 0.0323,
      "step": 453800
    },
    {
      "epoch": 15.607055668259807,
      "grad_norm": 0.08455172926187515,
      "learning_rate": 1.2459221435663353e-06,
      "loss": 0.0298,
      "step": 453900
    },
    {
      "epoch": 15.610494103084276,
      "grad_norm": 0.07561929523944855,
      "learning_rate": 1.2351768038201831e-06,
      "loss": 0.0328,
      "step": 454000
    },
    {
      "epoch": 15.613932537908743,
      "grad_norm": 0.06631895899772644,
      "learning_rate": 1.2244314640740312e-06,
      "loss": 0.0314,
      "step": 454100
    },
    {
      "epoch": 15.617370972733212,
      "grad_norm": 0.03564690053462982,
      "learning_rate": 1.213686124327879e-06,
      "loss": 0.0305,
      "step": 454200
    },
    {
      "epoch": 15.62080940755768,
      "grad_norm": 0.9344100952148438,
      "learning_rate": 1.202940784581727e-06,
      "loss": 0.0295,
      "step": 454300
    },
    {
      "epoch": 15.624247842382148,
      "grad_norm": 0.16730156540870667,
      "learning_rate": 1.192195444835575e-06,
      "loss": 0.0324,
      "step": 454400
    },
    {
      "epoch": 15.627686277206616,
      "grad_norm": 0.2237774282693863,
      "learning_rate": 1.1815575584868843e-06,
      "loss": 0.0309,
      "step": 454500
    },
    {
      "epoch": 15.631124712031083,
      "grad_norm": 0.05876051262021065,
      "learning_rate": 1.1708122187407322e-06,
      "loss": 0.0291,
      "step": 454600
    },
    {
      "epoch": 15.634563146855552,
      "grad_norm": 0.03848675265908241,
      "learning_rate": 1.1600668789945802e-06,
      "loss": 0.0324,
      "step": 454700
    },
    {
      "epoch": 15.638001581680019,
      "grad_norm": 0.3362024128437042,
      "learning_rate": 1.149321539248428e-06,
      "loss": 0.0274,
      "step": 454800
    },
    {
      "epoch": 15.641440016504488,
      "grad_norm": 0.1497829258441925,
      "learning_rate": 1.1385761995022759e-06,
      "loss": 0.0305,
      "step": 454900
    },
    {
      "epoch": 15.644878451328955,
      "grad_norm": 0.07347594201564789,
      "learning_rate": 1.1278308597561237e-06,
      "loss": 0.0331,
      "step": 455000
    },
    {
      "epoch": 15.648316886153424,
      "grad_norm": 0.11188000440597534,
      "learning_rate": 1.1170855200099718e-06,
      "loss": 0.0306,
      "step": 455100
    },
    {
      "epoch": 15.651755320977891,
      "grad_norm": 0.1973702311515808,
      "learning_rate": 1.1063401802638196e-06,
      "loss": 0.0317,
      "step": 455200
    },
    {
      "epoch": 15.655193755802358,
      "grad_norm": 0.33057647943496704,
      "learning_rate": 1.0955948405176676e-06,
      "loss": 0.0296,
      "step": 455300
    },
    {
      "epoch": 15.658632190626827,
      "grad_norm": 0.17068499326705933,
      "learning_rate": 1.0848495007715155e-06,
      "loss": 0.0318,
      "step": 455400
    },
    {
      "epoch": 15.662070625451294,
      "grad_norm": 0.0904395654797554,
      "learning_rate": 1.0741041610253633e-06,
      "loss": 0.0298,
      "step": 455500
    },
    {
      "epoch": 15.665509060275763,
      "grad_norm": 0.12447991222143173,
      "learning_rate": 1.0633588212792111e-06,
      "loss": 0.0282,
      "step": 455600
    },
    {
      "epoch": 15.66894749510023,
      "grad_norm": 0.17770695686340332,
      "learning_rate": 1.0526134815330592e-06,
      "loss": 0.0328,
      "step": 455700
    },
    {
      "epoch": 15.672385929924697,
      "grad_norm": 0.4549097418785095,
      "learning_rate": 1.041868141786907e-06,
      "loss": 0.0307,
      "step": 455800
    },
    {
      "epoch": 15.675824364749166,
      "grad_norm": 0.07907450199127197,
      "learning_rate": 1.031122802040755e-06,
      "loss": 0.0334,
      "step": 455900
    },
    {
      "epoch": 15.679262799573634,
      "grad_norm": 0.0741267129778862,
      "learning_rate": 1.020377462294603e-06,
      "loss": 0.0313,
      "step": 456000
    },
    {
      "epoch": 15.682701234398102,
      "grad_norm": 0.0805453285574913,
      "learning_rate": 1.0096321225484508e-06,
      "loss": 0.032,
      "step": 456100
    },
    {
      "epoch": 15.68613966922257,
      "grad_norm": 0.03807886689901352,
      "learning_rate": 9.988867828022988e-07,
      "loss": 0.0282,
      "step": 456200
    },
    {
      "epoch": 15.689578104047039,
      "grad_norm": 0.08255884796380997,
      "learning_rate": 9.881414430561464e-07,
      "loss": 0.0308,
      "step": 456300
    },
    {
      "epoch": 15.693016538871506,
      "grad_norm": 0.07744286954402924,
      "learning_rate": 9.773961033099945e-07,
      "loss": 0.033,
      "step": 456400
    },
    {
      "epoch": 15.696454973695973,
      "grad_norm": 0.07490311563014984,
      "learning_rate": 9.666507635638423e-07,
      "loss": 0.0314,
      "step": 456500
    },
    {
      "epoch": 15.699893408520442,
      "grad_norm": 0.10151851922273636,
      "learning_rate": 9.559054238176904e-07,
      "loss": 0.0302,
      "step": 456600
    },
    {
      "epoch": 15.703331843344909,
      "grad_norm": 0.14437992870807648,
      "learning_rate": 9.451600840715382e-07,
      "loss": 0.0313,
      "step": 456700
    },
    {
      "epoch": 15.706770278169378,
      "grad_norm": 0.14782869815826416,
      "learning_rate": 9.344147443253861e-07,
      "loss": 0.03,
      "step": 456800
    },
    {
      "epoch": 15.710208712993845,
      "grad_norm": 0.1714210957288742,
      "learning_rate": 9.236694045792341e-07,
      "loss": 0.0267,
      "step": 456900
    },
    {
      "epoch": 15.713647147818314,
      "grad_norm": 0.08312273770570755,
      "learning_rate": 9.129240648330818e-07,
      "loss": 0.033,
      "step": 457000
    },
    {
      "epoch": 15.717085582642781,
      "grad_norm": 0.20583012700080872,
      "learning_rate": 9.021787250869298e-07,
      "loss": 0.0286,
      "step": 457100
    },
    {
      "epoch": 15.720524017467248,
      "grad_norm": 0.10076604783535004,
      "learning_rate": 8.914333853407777e-07,
      "loss": 0.0289,
      "step": 457200
    },
    {
      "epoch": 15.723962452291717,
      "grad_norm": 0.18872475624084473,
      "learning_rate": 8.806880455946256e-07,
      "loss": 0.0311,
      "step": 457300
    },
    {
      "epoch": 15.727400887116184,
      "grad_norm": 0.16374506056308746,
      "learning_rate": 8.699427058484736e-07,
      "loss": 0.0339,
      "step": 457400
    },
    {
      "epoch": 15.730839321940653,
      "grad_norm": 0.14972922205924988,
      "learning_rate": 8.591973661023215e-07,
      "loss": 0.0335,
      "step": 457500
    },
    {
      "epoch": 15.73427775676512,
      "grad_norm": 0.2596700191497803,
      "learning_rate": 8.484520263561695e-07,
      "loss": 0.0293,
      "step": 457600
    },
    {
      "epoch": 15.737716191589588,
      "grad_norm": 0.08082647621631622,
      "learning_rate": 8.377066866100174e-07,
      "loss": 0.0349,
      "step": 457700
    },
    {
      "epoch": 15.741154626414056,
      "grad_norm": 0.47748667001724243,
      "learning_rate": 8.269613468638651e-07,
      "loss": 0.0309,
      "step": 457800
    },
    {
      "epoch": 15.744593061238524,
      "grad_norm": 0.06982700526714325,
      "learning_rate": 8.162160071177131e-07,
      "loss": 0.0285,
      "step": 457900
    },
    {
      "epoch": 15.748031496062993,
      "grad_norm": 0.08828442543745041,
      "learning_rate": 8.05470667371561e-07,
      "loss": 0.0305,
      "step": 458000
    },
    {
      "epoch": 15.75146993088746,
      "grad_norm": 0.07234737277030945,
      "learning_rate": 7.947253276254089e-07,
      "loss": 0.0311,
      "step": 458100
    },
    {
      "epoch": 15.754908365711929,
      "grad_norm": 0.12432540953159332,
      "learning_rate": 7.839799878792568e-07,
      "loss": 0.0294,
      "step": 458200
    },
    {
      "epoch": 15.758346800536396,
      "grad_norm": 0.09404388070106506,
      "learning_rate": 7.732346481331046e-07,
      "loss": 0.0287,
      "step": 458300
    },
    {
      "epoch": 15.761785235360863,
      "grad_norm": 0.13015809655189514,
      "learning_rate": 7.624893083869526e-07,
      "loss": 0.0289,
      "step": 458400
    },
    {
      "epoch": 15.765223670185332,
      "grad_norm": 0.20989422500133514,
      "learning_rate": 7.517439686408005e-07,
      "loss": 0.0293,
      "step": 458500
    },
    {
      "epoch": 15.768662105009799,
      "grad_norm": 0.1018393337726593,
      "learning_rate": 7.409986288946485e-07,
      "loss": 0.0298,
      "step": 458600
    },
    {
      "epoch": 15.772100539834268,
      "grad_norm": 0.07760371267795563,
      "learning_rate": 7.302532891484963e-07,
      "loss": 0.0277,
      "step": 458700
    },
    {
      "epoch": 15.775538974658735,
      "grad_norm": Infinity,
      "learning_rate": 7.196154027998058e-07,
      "loss": 0.0303,
      "step": 458800
    },
    {
      "epoch": 15.778977409483204,
      "grad_norm": 0.4317518174648285,
      "learning_rate": 7.088700630536536e-07,
      "loss": 0.0327,
      "step": 458900
    },
    {
      "epoch": 15.782415844307671,
      "grad_norm": 0.8493267297744751,
      "learning_rate": 6.981247233075016e-07,
      "loss": 0.0311,
      "step": 459000
    },
    {
      "epoch": 15.785854279132138,
      "grad_norm": 0.09691411256790161,
      "learning_rate": 6.873793835613495e-07,
      "loss": 0.0266,
      "step": 459100
    },
    {
      "epoch": 15.789292713956607,
      "grad_norm": 0.15841403603553772,
      "learning_rate": 6.766340438151974e-07,
      "loss": 0.0323,
      "step": 459200
    },
    {
      "epoch": 15.792731148781074,
      "grad_norm": 0.08478699624538422,
      "learning_rate": 6.658887040690453e-07,
      "loss": 0.0308,
      "step": 459300
    },
    {
      "epoch": 15.796169583605543,
      "grad_norm": 0.03134123980998993,
      "learning_rate": 6.551433643228932e-07,
      "loss": 0.0276,
      "step": 459400
    },
    {
      "epoch": 15.79960801843001,
      "grad_norm": 0.46845853328704834,
      "learning_rate": 6.443980245767411e-07,
      "loss": 0.029,
      "step": 459500
    },
    {
      "epoch": 15.803046453254478,
      "grad_norm": 0.06002126634120941,
      "learning_rate": 6.336526848305889e-07,
      "loss": 0.0284,
      "step": 459600
    },
    {
      "epoch": 15.806484888078947,
      "grad_norm": 0.04777207970619202,
      "learning_rate": 6.229073450844369e-07,
      "loss": 0.0296,
      "step": 459700
    },
    {
      "epoch": 15.809923322903414,
      "grad_norm": 0.22460703551769257,
      "learning_rate": 6.121620053382848e-07,
      "loss": 0.0353,
      "step": 459800
    },
    {
      "epoch": 15.813361757727883,
      "grad_norm": 0.10445520281791687,
      "learning_rate": 6.014166655921327e-07,
      "loss": 0.0306,
      "step": 459900
    },
    {
      "epoch": 15.81680019255235,
      "grad_norm": 0.11299122869968414,
      "learning_rate": 5.906713258459806e-07,
      "loss": 0.0297,
      "step": 460000
    },
    {
      "epoch": 15.820238627376819,
      "grad_norm": 0.41538098454475403,
      "learning_rate": 5.799259860998285e-07,
      "loss": 0.0326,
      "step": 460100
    },
    {
      "epoch": 15.823677062201286,
      "grad_norm": 0.09555574506521225,
      "learning_rate": 5.691806463536765e-07,
      "loss": 0.0317,
      "step": 460200
    },
    {
      "epoch": 15.827115497025755,
      "grad_norm": 0.1730344444513321,
      "learning_rate": 5.584353066075244e-07,
      "loss": 0.0322,
      "step": 460300
    },
    {
      "epoch": 15.830553931850222,
      "grad_norm": 1.5586365461349487,
      "learning_rate": 5.476899668613722e-07,
      "loss": 0.0294,
      "step": 460400
    },
    {
      "epoch": 15.83399236667469,
      "grad_norm": 0.1824442595243454,
      "learning_rate": 5.369446271152202e-07,
      "loss": 0.0289,
      "step": 460500
    },
    {
      "epoch": 15.837430801499158,
      "grad_norm": 0.2339330017566681,
      "learning_rate": 5.261992873690681e-07,
      "loss": 0.0312,
      "step": 460600
    },
    {
      "epoch": 15.840869236323625,
      "grad_norm": 0.15157610177993774,
      "learning_rate": 5.15453947622916e-07,
      "loss": 0.0274,
      "step": 460700
    },
    {
      "epoch": 15.844307671148094,
      "grad_norm": 0.1274467557668686,
      "learning_rate": 5.047086078767639e-07,
      "loss": 0.0295,
      "step": 460800
    },
    {
      "epoch": 15.847746105972561,
      "grad_norm": 0.14823681116104126,
      "learning_rate": 4.939632681306117e-07,
      "loss": 0.0309,
      "step": 460900
    },
    {
      "epoch": 15.851184540797028,
      "grad_norm": 0.19547583162784576,
      "learning_rate": 4.832179283844597e-07,
      "loss": 0.0316,
      "step": 461000
    },
    {
      "epoch": 15.854622975621497,
      "grad_norm": 0.2891964614391327,
      "learning_rate": 4.724725886383076e-07,
      "loss": 0.0283,
      "step": 461100
    },
    {
      "epoch": 15.858061410445965,
      "grad_norm": 0.11166907846927643,
      "learning_rate": 4.6172724889215547e-07,
      "loss": 0.0295,
      "step": 461200
    },
    {
      "epoch": 15.861499845270433,
      "grad_norm": 0.19830745458602905,
      "learning_rate": 4.509819091460034e-07,
      "loss": 0.0308,
      "step": 461300
    },
    {
      "epoch": 15.8649382800949,
      "grad_norm": 0.16834382712841034,
      "learning_rate": 4.4023656939985135e-07,
      "loss": 0.0308,
      "step": 461400
    },
    {
      "epoch": 15.86837671491937,
      "grad_norm": 0.05242300406098366,
      "learning_rate": 4.2959868305116076e-07,
      "loss": 0.0308,
      "step": 461500
    },
    {
      "epoch": 15.871815149743837,
      "grad_norm": 0.22382041811943054,
      "learning_rate": 4.188533433050087e-07,
      "loss": 0.0286,
      "step": 461600
    },
    {
      "epoch": 15.875253584568304,
      "grad_norm": 0.3903610408306122,
      "learning_rate": 4.0810800355885654e-07,
      "loss": 0.0326,
      "step": 461700
    },
    {
      "epoch": 15.878692019392773,
      "grad_norm": 0.05652875080704689,
      "learning_rate": 3.9736266381270443e-07,
      "loss": 0.0257,
      "step": 461800
    },
    {
      "epoch": 15.88213045421724,
      "grad_norm": 0.2617081105709076,
      "learning_rate": 3.866173240665523e-07,
      "loss": 0.0295,
      "step": 461900
    },
    {
      "epoch": 15.885568889041709,
      "grad_norm": 0.25103560090065,
      "learning_rate": 3.7587198432040026e-07,
      "loss": 0.0301,
      "step": 462000
    },
    {
      "epoch": 15.889007323866176,
      "grad_norm": 0.0864206850528717,
      "learning_rate": 3.6512664457424815e-07,
      "loss": 0.0308,
      "step": 462100
    },
    {
      "epoch": 15.892445758690645,
      "grad_norm": 0.20289015769958496,
      "learning_rate": 3.543813048280961e-07,
      "loss": 0.0304,
      "step": 462200
    },
    {
      "epoch": 15.895884193515112,
      "grad_norm": 0.4639836847782135,
      "learning_rate": 3.43635965081944e-07,
      "loss": 0.0285,
      "step": 462300
    },
    {
      "epoch": 15.89932262833958,
      "grad_norm": 0.10654595494270325,
      "learning_rate": 3.328906253357919e-07,
      "loss": 0.0304,
      "step": 462400
    },
    {
      "epoch": 15.902761063164048,
      "grad_norm": 0.06107347831130028,
      "learning_rate": 3.2214528558963976e-07,
      "loss": 0.029,
      "step": 462500
    },
    {
      "epoch": 15.906199497988515,
      "grad_norm": 0.21698792278766632,
      "learning_rate": 3.113999458434877e-07,
      "loss": 0.0302,
      "step": 462600
    },
    {
      "epoch": 15.909637932812984,
      "grad_norm": 0.09654492139816284,
      "learning_rate": 3.006546060973356e-07,
      "loss": 0.0302,
      "step": 462700
    },
    {
      "epoch": 15.913076367637451,
      "grad_norm": 0.09035919606685638,
      "learning_rate": 2.8990926635118353e-07,
      "loss": 0.0295,
      "step": 462800
    },
    {
      "epoch": 15.916514802461919,
      "grad_norm": 0.14303985238075256,
      "learning_rate": 2.791639266050314e-07,
      "loss": 0.0309,
      "step": 462900
    },
    {
      "epoch": 15.919953237286387,
      "grad_norm": 0.1380966752767563,
      "learning_rate": 2.684185868588793e-07,
      "loss": 0.03,
      "step": 463000
    },
    {
      "epoch": 15.923391672110855,
      "grad_norm": 0.08069825917482376,
      "learning_rate": 2.5767324711272725e-07,
      "loss": 0.0315,
      "step": 463100
    },
    {
      "epoch": 15.926830106935324,
      "grad_norm": 0.2036592960357666,
      "learning_rate": 2.4692790736657514e-07,
      "loss": 0.0305,
      "step": 463200
    },
    {
      "epoch": 15.93026854175979,
      "grad_norm": 0.05669596791267395,
      "learning_rate": 2.3618256762042306e-07,
      "loss": 0.0319,
      "step": 463300
    },
    {
      "epoch": 15.93370697658426,
      "grad_norm": 0.2291995882987976,
      "learning_rate": 2.2543722787427092e-07,
      "loss": 0.0286,
      "step": 463400
    },
    {
      "epoch": 15.937145411408727,
      "grad_norm": 0.05521993711590767,
      "learning_rate": 2.1469188812811886e-07,
      "loss": 0.031,
      "step": 463500
    },
    {
      "epoch": 15.940583846233194,
      "grad_norm": 0.2895757853984833,
      "learning_rate": 2.0394654838196675e-07,
      "loss": 0.0323,
      "step": 463600
    },
    {
      "epoch": 15.944022281057663,
      "grad_norm": 0.15250776708126068,
      "learning_rate": 1.9320120863581464e-07,
      "loss": 0.0292,
      "step": 463700
    },
    {
      "epoch": 15.94746071588213,
      "grad_norm": 0.3433978855609894,
      "learning_rate": 1.8245586888966255e-07,
      "loss": 0.0283,
      "step": 463800
    },
    {
      "epoch": 15.950899150706599,
      "grad_norm": 0.04753962531685829,
      "learning_rate": 1.7171052914351047e-07,
      "loss": 0.0265,
      "step": 463900
    },
    {
      "epoch": 15.954337585531066,
      "grad_norm": 0.1655765026807785,
      "learning_rate": 1.6107264279481988e-07,
      "loss": 0.0302,
      "step": 464000
    },
    {
      "epoch": 15.957776020355535,
      "grad_norm": 0.1361803263425827,
      "learning_rate": 1.503273030486678e-07,
      "loss": 0.0333,
      "step": 464100
    },
    {
      "epoch": 15.961214455180002,
      "grad_norm": 0.15111956000328064,
      "learning_rate": 1.395819633025157e-07,
      "loss": 0.0333,
      "step": 464200
    },
    {
      "epoch": 15.96465289000447,
      "grad_norm": 0.3310128450393677,
      "learning_rate": 1.2883662355636363e-07,
      "loss": 0.0274,
      "step": 464300
    },
    {
      "epoch": 15.968091324828938,
      "grad_norm": 0.15360188484191895,
      "learning_rate": 1.1809128381021153e-07,
      "loss": 0.032,
      "step": 464400
    },
    {
      "epoch": 15.971529759653405,
      "grad_norm": 0.13579154014587402,
      "learning_rate": 1.0734594406405943e-07,
      "loss": 0.0333,
      "step": 464500
    },
    {
      "epoch": 15.974968194477874,
      "grad_norm": 0.3966180980205536,
      "learning_rate": 9.660060431790732e-08,
      "loss": 0.0291,
      "step": 464600
    },
    {
      "epoch": 15.978406629302341,
      "grad_norm": 0.1742396503686905,
      "learning_rate": 8.585526457175523e-08,
      "loss": 0.0302,
      "step": 464700
    },
    {
      "epoch": 15.981845064126809,
      "grad_norm": 0.28570541739463806,
      "learning_rate": 7.510992482560314e-08,
      "loss": 0.029,
      "step": 464800
    },
    {
      "epoch": 15.985283498951278,
      "grad_norm": 0.08144797384738922,
      "learning_rate": 6.436458507945105e-08,
      "loss": 0.0327,
      "step": 464900
    },
    {
      "epoch": 15.988721933775745,
      "grad_norm": 0.07218754291534424,
      "learning_rate": 5.3619245333298955e-08,
      "loss": 0.0308,
      "step": 465000
    },
    {
      "epoch": 15.992160368600214,
      "grad_norm": 0.12392664700746536,
      "learning_rate": 4.287390558714686e-08,
      "loss": 0.0285,
      "step": 465100
    },
    {
      "epoch": 15.99559880342468,
      "grad_norm": 0.15237843990325928,
      "learning_rate": 3.212856584099476e-08,
      "loss": 0.0281,
      "step": 465200
    },
    {
      "epoch": 15.99903723824915,
      "grad_norm": 0.08857478201389313,
      "learning_rate": 2.138322609484267e-08,
      "loss": 0.0291,
      "step": 465300
    },
    {
      "epoch": 16.0,
      "eval_accuracy_macro_0.5": 0.9865100979804993,
      "eval_accuracy_micro_0.5": 0.9865100979804993,
      "eval_accuracy_weighted_0.5": 0.9778859615325928,
      "eval_aucroc_macro": 0.9289421439170837,
      "eval_aucroc_micro": 0.9311344623565674,
      "eval_aucroc_weighted": 0.9284951090812683,
      "eval_f1_macro_0.5": 0.8010575771331787,
      "eval_f1_macro_0.6": 0.7929177284240723,
      "eval_f1_macro_0.7": 0.7730318307876587,
      "eval_f1_macro_0.8": 0.6523025035858154,
      "eval_f1_micro_0.5": 0.8066065311431885,
      "eval_f1_micro_0.6": 0.7991763949394226,
      "eval_f1_micro_0.7": 0.7811440229415894,
      "eval_f1_micro_0.8": 0.746442437171936,
      "eval_f1_micro_0.9": 0.6680228114128113,
      "eval_f1_weighted_0.5": 0.8034489750862122,
      "eval_f1_weighted_0.6": 0.7930763959884644,
      "eval_f1_weighted_0.7": 0.7709925174713135,
      "eval_f1_weighted_0.8": 0.6382253766059875,
      "eval_loss": 0.029151981696486473,
      "eval_runtime": 2566.8766,
      "eval_samples_per_second": 22.647,
      "eval_steps_per_second": 2.831,
      "step": 465328
    }
  ],
  "logging_steps": 100,
  "max_steps": 465328,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 16,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.957788222939477e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
