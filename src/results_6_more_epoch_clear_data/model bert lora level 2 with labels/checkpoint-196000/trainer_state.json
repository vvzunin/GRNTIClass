{
  "best_metric": 0.0072485520504415035,
  "best_model_checkpoint": "results_6_more_epoch_clear_data/model bert lora level 2 with labels/checkpoint-196000",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 196000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0035714285714285713,
      "grad_norm": 0.40869003534317017,
      "learning_rate": 4.9979909817402566e-05,
      "loss": 0.6658,
      "step": 100
    },
    {
      "epoch": 0.007142857142857143,
      "grad_norm": 0.09985783696174622,
      "learning_rate": 4.9957587392294306e-05,
      "loss": 0.0857,
      "step": 200
    },
    {
      "epoch": 0.010714285714285714,
      "grad_norm": 0.06746967881917953,
      "learning_rate": 4.993526496718603e-05,
      "loss": 0.0388,
      "step": 300
    },
    {
      "epoch": 0.014285714285714285,
      "grad_norm": 0.06872254610061646,
      "learning_rate": 4.991294254207777e-05,
      "loss": 0.0314,
      "step": 400
    },
    {
      "epoch": 0.017857142857142856,
      "grad_norm": 0.05978674441576004,
      "learning_rate": 4.989062011696951e-05,
      "loss": 0.0297,
      "step": 500
    },
    {
      "epoch": 0.02142857142857143,
      "grad_norm": 0.06612329930067062,
      "learning_rate": 4.986829769186125e-05,
      "loss": 0.0282,
      "step": 600
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.05450468510389328,
      "learning_rate": 4.9845975266752984e-05,
      "loss": 0.0265,
      "step": 700
    },
    {
      "epoch": 0.02857142857142857,
      "grad_norm": 0.06962275505065918,
      "learning_rate": 4.982365284164472e-05,
      "loss": 0.027,
      "step": 800
    },
    {
      "epoch": 0.03214285714285714,
      "grad_norm": 0.6884397864341736,
      "learning_rate": 4.980133041653646e-05,
      "loss": 0.0278,
      "step": 900
    },
    {
      "epoch": 0.03571428571428571,
      "grad_norm": 0.05922694504261017,
      "learning_rate": 4.977900799142819e-05,
      "loss": 0.0267,
      "step": 1000
    },
    {
      "epoch": 0.039285714285714285,
      "grad_norm": 0.05276137962937355,
      "learning_rate": 4.975668556631993e-05,
      "loss": 0.0269,
      "step": 1100
    },
    {
      "epoch": 0.04285714285714286,
      "grad_norm": 0.08017599582672119,
      "learning_rate": 4.973436314121166e-05,
      "loss": 0.0262,
      "step": 1200
    },
    {
      "epoch": 0.04642857142857143,
      "grad_norm": 0.03099626488983631,
      "learning_rate": 4.9712040716103396e-05,
      "loss": 0.0282,
      "step": 1300
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.06950672715902328,
      "learning_rate": 4.9689718290995136e-05,
      "loss": 0.0279,
      "step": 1400
    },
    {
      "epoch": 0.05357142857142857,
      "grad_norm": 0.05382993817329407,
      "learning_rate": 4.9667395865886875e-05,
      "loss": 0.0261,
      "step": 1500
    },
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 0.08286482840776443,
      "learning_rate": 4.964507344077861e-05,
      "loss": 0.0262,
      "step": 1600
    },
    {
      "epoch": 0.060714285714285714,
      "grad_norm": 0.07085806876420975,
      "learning_rate": 4.962275101567034e-05,
      "loss": 0.0267,
      "step": 1700
    },
    {
      "epoch": 0.06428571428571428,
      "grad_norm": 0.05820431560277939,
      "learning_rate": 4.960042859056208e-05,
      "loss": 0.027,
      "step": 1800
    },
    {
      "epoch": 0.06785714285714285,
      "grad_norm": 0.060742445290088654,
      "learning_rate": 4.957810616545382e-05,
      "loss": 0.0259,
      "step": 1900
    },
    {
      "epoch": 0.07142857142857142,
      "grad_norm": 0.09905136376619339,
      "learning_rate": 4.9555783740345554e-05,
      "loss": 0.0277,
      "step": 2000
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.06287707388401031,
      "learning_rate": 4.953346131523729e-05,
      "loss": 0.0274,
      "step": 2100
    },
    {
      "epoch": 0.07857142857142857,
      "grad_norm": 0.08204560726881027,
      "learning_rate": 4.9511138890129026e-05,
      "loss": 0.0264,
      "step": 2200
    },
    {
      "epoch": 0.08214285714285714,
      "grad_norm": 0.04578246921300888,
      "learning_rate": 4.948881646502076e-05,
      "loss": 0.0259,
      "step": 2300
    },
    {
      "epoch": 0.08571428571428572,
      "grad_norm": 0.07153341174125671,
      "learning_rate": 4.94664940399125e-05,
      "loss": 0.0286,
      "step": 2400
    },
    {
      "epoch": 0.08928571428571429,
      "grad_norm": 0.07301384955644608,
      "learning_rate": 4.944417161480424e-05,
      "loss": 0.0279,
      "step": 2500
    },
    {
      "epoch": 0.09285714285714286,
      "grad_norm": 0.0628177598118782,
      "learning_rate": 4.942184918969597e-05,
      "loss": 0.027,
      "step": 2600
    },
    {
      "epoch": 0.09642857142857143,
      "grad_norm": 0.07773593813180923,
      "learning_rate": 4.9399526764587705e-05,
      "loss": 0.0287,
      "step": 2700
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.06703822314739227,
      "learning_rate": 4.9377204339479445e-05,
      "loss": 0.0268,
      "step": 2800
    },
    {
      "epoch": 0.10357142857142858,
      "grad_norm": 0.06568951159715652,
      "learning_rate": 4.9354881914371184e-05,
      "loss": 0.0264,
      "step": 2900
    },
    {
      "epoch": 0.10714285714285714,
      "grad_norm": 0.0473555251955986,
      "learning_rate": 4.933255948926291e-05,
      "loss": 0.0282,
      "step": 3000
    },
    {
      "epoch": 0.11071428571428571,
      "grad_norm": 0.08494297415018082,
      "learning_rate": 4.931023706415465e-05,
      "loss": 0.0273,
      "step": 3100
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 0.06024670973420143,
      "learning_rate": 4.928791463904639e-05,
      "loss": 0.0262,
      "step": 3200
    },
    {
      "epoch": 0.11785714285714285,
      "grad_norm": 0.06762290000915527,
      "learning_rate": 4.926559221393812e-05,
      "loss": 0.0259,
      "step": 3300
    },
    {
      "epoch": 0.12142857142857143,
      "grad_norm": 0.0803644135594368,
      "learning_rate": 4.924326978882986e-05,
      "loss": 0.0279,
      "step": 3400
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.05580554157495499,
      "learning_rate": 4.9220947363721596e-05,
      "loss": 0.0264,
      "step": 3500
    },
    {
      "epoch": 0.12857142857142856,
      "grad_norm": 0.07354927808046341,
      "learning_rate": 4.9198624938613336e-05,
      "loss": 0.0272,
      "step": 3600
    },
    {
      "epoch": 0.13214285714285715,
      "grad_norm": 0.05537733808159828,
      "learning_rate": 4.917630251350507e-05,
      "loss": 0.0268,
      "step": 3700
    },
    {
      "epoch": 0.1357142857142857,
      "grad_norm": 0.0970190092921257,
      "learning_rate": 4.915398008839681e-05,
      "loss": 0.0275,
      "step": 3800
    },
    {
      "epoch": 0.1392857142857143,
      "grad_norm": 0.04770582914352417,
      "learning_rate": 4.913165766328854e-05,
      "loss": 0.0266,
      "step": 3900
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 0.042280785739421844,
      "learning_rate": 4.9109335238180274e-05,
      "loss": 0.0268,
      "step": 4000
    },
    {
      "epoch": 0.14642857142857144,
      "grad_norm": 0.06106196716427803,
      "learning_rate": 4.9087012813072014e-05,
      "loss": 0.0285,
      "step": 4100
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.06573644280433655,
      "learning_rate": 4.9064690387963754e-05,
      "loss": 0.028,
      "step": 4200
    },
    {
      "epoch": 0.15357142857142858,
      "grad_norm": 0.0706372857093811,
      "learning_rate": 4.904236796285549e-05,
      "loss": 0.0285,
      "step": 4300
    },
    {
      "epoch": 0.15714285714285714,
      "grad_norm": 0.06466375291347504,
      "learning_rate": 4.902004553774722e-05,
      "loss": 0.028,
      "step": 4400
    },
    {
      "epoch": 0.16071428571428573,
      "grad_norm": 0.0775320902466774,
      "learning_rate": 4.899772311263896e-05,
      "loss": 0.027,
      "step": 4500
    },
    {
      "epoch": 0.16428571428571428,
      "grad_norm": 0.08150437474250793,
      "learning_rate": 4.89754006875307e-05,
      "loss": 0.0272,
      "step": 4600
    },
    {
      "epoch": 0.16785714285714284,
      "grad_norm": 0.051430754363536835,
      "learning_rate": 4.895307826242243e-05,
      "loss": 0.0271,
      "step": 4700
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 0.06220008432865143,
      "learning_rate": 4.8930755837314165e-05,
      "loss": 0.0275,
      "step": 4800
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.06900220364332199,
      "learning_rate": 4.8908433412205905e-05,
      "loss": 0.0285,
      "step": 4900
    },
    {
      "epoch": 0.17857142857142858,
      "grad_norm": 0.028913570567965508,
      "learning_rate": 4.888611098709764e-05,
      "loss": 0.0287,
      "step": 5000
    },
    {
      "epoch": 0.18214285714285713,
      "grad_norm": 0.031157879158854485,
      "learning_rate": 4.886378856198938e-05,
      "loss": 0.0273,
      "step": 5100
    },
    {
      "epoch": 0.18571428571428572,
      "grad_norm": 0.05169012397527695,
      "learning_rate": 4.884146613688112e-05,
      "loss": 0.0278,
      "step": 5200
    },
    {
      "epoch": 0.18928571428571428,
      "grad_norm": 0.03820740059018135,
      "learning_rate": 4.8819143711772844e-05,
      "loss": 0.0267,
      "step": 5300
    },
    {
      "epoch": 0.19285714285714287,
      "grad_norm": 0.05382721126079559,
      "learning_rate": 4.879682128666458e-05,
      "loss": 0.0274,
      "step": 5400
    },
    {
      "epoch": 0.19642857142857142,
      "grad_norm": 0.0531950406730175,
      "learning_rate": 4.8774722085807405e-05,
      "loss": 0.0275,
      "step": 5500
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.06336934119462967,
      "learning_rate": 4.875239966069914e-05,
      "loss": 0.0265,
      "step": 5600
    },
    {
      "epoch": 0.20357142857142857,
      "grad_norm": 0.05604959651827812,
      "learning_rate": 4.873007723559088e-05,
      "loss": 0.0275,
      "step": 5700
    },
    {
      "epoch": 0.20714285714285716,
      "grad_norm": 0.05928751453757286,
      "learning_rate": 4.870775481048262e-05,
      "loss": 0.0271,
      "step": 5800
    },
    {
      "epoch": 0.21071428571428572,
      "grad_norm": 0.06466837227344513,
      "learning_rate": 4.868543238537435e-05,
      "loss": 0.026,
      "step": 5900
    },
    {
      "epoch": 0.21428571428571427,
      "grad_norm": 0.06185619905591011,
      "learning_rate": 4.866310996026608e-05,
      "loss": 0.0273,
      "step": 6000
    },
    {
      "epoch": 0.21785714285714286,
      "grad_norm": 0.062289509922266006,
      "learning_rate": 4.864078753515782e-05,
      "loss": 0.0279,
      "step": 6100
    },
    {
      "epoch": 0.22142857142857142,
      "grad_norm": 0.05324774980545044,
      "learning_rate": 4.861846511004956e-05,
      "loss": 0.0286,
      "step": 6200
    },
    {
      "epoch": 0.225,
      "grad_norm": 0.06595184653997421,
      "learning_rate": 4.8596142684941296e-05,
      "loss": 0.0269,
      "step": 6300
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 0.07088848203420639,
      "learning_rate": 4.857382025983303e-05,
      "loss": 0.0284,
      "step": 6400
    },
    {
      "epoch": 0.23214285714285715,
      "grad_norm": 0.05060148611664772,
      "learning_rate": 4.855149783472477e-05,
      "loss": 0.0274,
      "step": 6500
    },
    {
      "epoch": 0.2357142857142857,
      "grad_norm": 0.045932527631521225,
      "learning_rate": 4.85291754096165e-05,
      "loss": 0.0251,
      "step": 6600
    },
    {
      "epoch": 0.2392857142857143,
      "grad_norm": 0.04833772033452988,
      "learning_rate": 4.850685298450824e-05,
      "loss": 0.0272,
      "step": 6700
    },
    {
      "epoch": 0.24285714285714285,
      "grad_norm": 0.043456196784973145,
      "learning_rate": 4.8484530559399974e-05,
      "loss": 0.026,
      "step": 6800
    },
    {
      "epoch": 0.24642857142857144,
      "grad_norm": 0.03729372099041939,
      "learning_rate": 4.8462208134291714e-05,
      "loss": 0.0279,
      "step": 6900
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.05708789452910423,
      "learning_rate": 4.843988570918345e-05,
      "loss": 0.0254,
      "step": 7000
    },
    {
      "epoch": 0.25357142857142856,
      "grad_norm": 0.07366801053285599,
      "learning_rate": 4.841756328407519e-05,
      "loss": 0.0271,
      "step": 7100
    },
    {
      "epoch": 0.2571428571428571,
      "grad_norm": 0.051970936357975006,
      "learning_rate": 4.839524085896692e-05,
      "loss": 0.025,
      "step": 7200
    },
    {
      "epoch": 0.26071428571428573,
      "grad_norm": 0.044997986406087875,
      "learning_rate": 4.837291843385865e-05,
      "loss": 0.0259,
      "step": 7300
    },
    {
      "epoch": 0.2642857142857143,
      "grad_norm": 0.04813357815146446,
      "learning_rate": 4.835059600875039e-05,
      "loss": 0.0268,
      "step": 7400
    },
    {
      "epoch": 0.26785714285714285,
      "grad_norm": 0.06241261959075928,
      "learning_rate": 4.832827358364213e-05,
      "loss": 0.0264,
      "step": 7500
    },
    {
      "epoch": 0.2714285714285714,
      "grad_norm": 0.05512277036905289,
      "learning_rate": 4.8305951158533865e-05,
      "loss": 0.0279,
      "step": 7600
    },
    {
      "epoch": 0.275,
      "grad_norm": 0.05275978147983551,
      "learning_rate": 4.82836287334256e-05,
      "loss": 0.0257,
      "step": 7700
    },
    {
      "epoch": 0.2785714285714286,
      "grad_norm": 0.06900084018707275,
      "learning_rate": 4.826130630831734e-05,
      "loss": 0.0255,
      "step": 7800
    },
    {
      "epoch": 0.28214285714285714,
      "grad_norm": 0.05000532418489456,
      "learning_rate": 4.823898388320908e-05,
      "loss": 0.0263,
      "step": 7900
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 0.04335126280784607,
      "learning_rate": 4.821666145810081e-05,
      "loss": 0.0266,
      "step": 8000
    },
    {
      "epoch": 0.2892857142857143,
      "grad_norm": 0.05376337096095085,
      "learning_rate": 4.819433903299255e-05,
      "loss": 0.0274,
      "step": 8100
    },
    {
      "epoch": 0.29285714285714287,
      "grad_norm": 0.035762518644332886,
      "learning_rate": 4.817201660788428e-05,
      "loss": 0.0243,
      "step": 8200
    },
    {
      "epoch": 0.29642857142857143,
      "grad_norm": 0.06725254654884338,
      "learning_rate": 4.8149694182776016e-05,
      "loss": 0.0278,
      "step": 8300
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.04624298959970474,
      "learning_rate": 4.8127371757667756e-05,
      "loss": 0.0265,
      "step": 8400
    },
    {
      "epoch": 0.30357142857142855,
      "grad_norm": 0.04240325465798378,
      "learning_rate": 4.8105049332559496e-05,
      "loss": 0.0262,
      "step": 8500
    },
    {
      "epoch": 0.30714285714285716,
      "grad_norm": 0.04081284999847412,
      "learning_rate": 4.808272690745123e-05,
      "loss": 0.0265,
      "step": 8600
    },
    {
      "epoch": 0.3107142857142857,
      "grad_norm": 0.04266988858580589,
      "learning_rate": 4.806040448234296e-05,
      "loss": 0.0263,
      "step": 8700
    },
    {
      "epoch": 0.3142857142857143,
      "grad_norm": 0.06604614853858948,
      "learning_rate": 4.80380820572347e-05,
      "loss": 0.0281,
      "step": 8800
    },
    {
      "epoch": 0.31785714285714284,
      "grad_norm": 0.030190814286470413,
      "learning_rate": 4.801575963212644e-05,
      "loss": 0.0259,
      "step": 8900
    },
    {
      "epoch": 0.32142857142857145,
      "grad_norm": 0.045795030891895294,
      "learning_rate": 4.7993437207018174e-05,
      "loss": 0.0259,
      "step": 9000
    },
    {
      "epoch": 0.325,
      "grad_norm": 0.040109217166900635,
      "learning_rate": 4.797111478190991e-05,
      "loss": 0.0266,
      "step": 9100
    },
    {
      "epoch": 0.32857142857142857,
      "grad_norm": 0.06646282225847244,
      "learning_rate": 4.794879235680165e-05,
      "loss": 0.0258,
      "step": 9200
    },
    {
      "epoch": 0.33214285714285713,
      "grad_norm": 0.054785240441560745,
      "learning_rate": 4.792646993169338e-05,
      "loss": 0.027,
      "step": 9300
    },
    {
      "epoch": 0.3357142857142857,
      "grad_norm": 0.04522830992937088,
      "learning_rate": 4.790414750658512e-05,
      "loss": 0.0276,
      "step": 9400
    },
    {
      "epoch": 0.3392857142857143,
      "grad_norm": 0.04621046036481857,
      "learning_rate": 4.788182508147685e-05,
      "loss": 0.0245,
      "step": 9500
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 0.06046750769019127,
      "learning_rate": 4.7859502656368586e-05,
      "loss": 0.0258,
      "step": 9600
    },
    {
      "epoch": 0.3464285714285714,
      "grad_norm": 0.053175970911979675,
      "learning_rate": 4.7837180231260325e-05,
      "loss": 0.0259,
      "step": 9700
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.05556821823120117,
      "learning_rate": 4.7814857806152065e-05,
      "loss": 0.0255,
      "step": 9800
    },
    {
      "epoch": 0.3535714285714286,
      "grad_norm": 0.055965349078178406,
      "learning_rate": 4.77925353810438e-05,
      "loss": 0.026,
      "step": 9900
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 0.039104804396629333,
      "learning_rate": 4.777021295593553e-05,
      "loss": 0.0268,
      "step": 10000
    },
    {
      "epoch": 0.3607142857142857,
      "grad_norm": 0.04435192048549652,
      "learning_rate": 4.774789053082727e-05,
      "loss": 0.0264,
      "step": 10100
    },
    {
      "epoch": 0.36428571428571427,
      "grad_norm": 0.045034199953079224,
      "learning_rate": 4.772556810571901e-05,
      "loss": 0.0253,
      "step": 10200
    },
    {
      "epoch": 0.3678571428571429,
      "grad_norm": 0.03638432174921036,
      "learning_rate": 4.7703245680610744e-05,
      "loss": 0.0244,
      "step": 10300
    },
    {
      "epoch": 0.37142857142857144,
      "grad_norm": 0.0517074391245842,
      "learning_rate": 4.7680923255502477e-05,
      "loss": 0.0254,
      "step": 10400
    },
    {
      "epoch": 0.375,
      "grad_norm": 0.03895793855190277,
      "learning_rate": 4.7658600830394216e-05,
      "loss": 0.026,
      "step": 10500
    },
    {
      "epoch": 0.37857142857142856,
      "grad_norm": 0.058897100389003754,
      "learning_rate": 4.763627840528595e-05,
      "loss": 0.0269,
      "step": 10600
    },
    {
      "epoch": 0.3821428571428571,
      "grad_norm": 0.065644770860672,
      "learning_rate": 4.761395598017769e-05,
      "loss": 0.0261,
      "step": 10700
    },
    {
      "epoch": 0.38571428571428573,
      "grad_norm": 0.0355754978954792,
      "learning_rate": 4.759163355506943e-05,
      "loss": 0.0263,
      "step": 10800
    },
    {
      "epoch": 0.3892857142857143,
      "grad_norm": 0.0556127205491066,
      "learning_rate": 4.756931112996116e-05,
      "loss": 0.0265,
      "step": 10900
    },
    {
      "epoch": 0.39285714285714285,
      "grad_norm": 0.07039391994476318,
      "learning_rate": 4.7546988704852895e-05,
      "loss": 0.0272,
      "step": 11000
    },
    {
      "epoch": 0.3964285714285714,
      "grad_norm": 0.040302615612745285,
      "learning_rate": 4.7524666279744634e-05,
      "loss": 0.0246,
      "step": 11100
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.04335801675915718,
      "learning_rate": 4.7502343854636374e-05,
      "loss": 0.0252,
      "step": 11200
    },
    {
      "epoch": 0.4035714285714286,
      "grad_norm": 0.0559590607881546,
      "learning_rate": 4.748002142952811e-05,
      "loss": 0.0257,
      "step": 11300
    },
    {
      "epoch": 0.40714285714285714,
      "grad_norm": 0.049650002270936966,
      "learning_rate": 4.745769900441984e-05,
      "loss": 0.0268,
      "step": 11400
    },
    {
      "epoch": 0.4107142857142857,
      "grad_norm": 0.05749571695923805,
      "learning_rate": 4.743537657931158e-05,
      "loss": 0.026,
      "step": 11500
    },
    {
      "epoch": 0.4142857142857143,
      "grad_norm": 0.034187037497758865,
      "learning_rate": 4.741305415420331e-05,
      "loss": 0.0259,
      "step": 11600
    },
    {
      "epoch": 0.41785714285714287,
      "grad_norm": 0.05365593731403351,
      "learning_rate": 4.739073172909505e-05,
      "loss": 0.0262,
      "step": 11700
    },
    {
      "epoch": 0.42142857142857143,
      "grad_norm": 0.05881662666797638,
      "learning_rate": 4.7368409303986786e-05,
      "loss": 0.0265,
      "step": 11800
    },
    {
      "epoch": 0.425,
      "grad_norm": 0.07257132977247238,
      "learning_rate": 4.7346086878878525e-05,
      "loss": 0.0245,
      "step": 11900
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 0.03514279052615166,
      "learning_rate": 4.732376445377026e-05,
      "loss": 0.0251,
      "step": 12000
    },
    {
      "epoch": 0.43214285714285716,
      "grad_norm": 0.045879196375608444,
      "learning_rate": 4.7301442028662e-05,
      "loss": 0.0264,
      "step": 12100
    },
    {
      "epoch": 0.4357142857142857,
      "grad_norm": 0.03290573135018349,
      "learning_rate": 4.727911960355373e-05,
      "loss": 0.0278,
      "step": 12200
    },
    {
      "epoch": 0.4392857142857143,
      "grad_norm": 0.044587258249521255,
      "learning_rate": 4.7256797178445464e-05,
      "loss": 0.026,
      "step": 12300
    },
    {
      "epoch": 0.44285714285714284,
      "grad_norm": 0.03561578691005707,
      "learning_rate": 4.7234697977588286e-05,
      "loss": 0.0256,
      "step": 12400
    },
    {
      "epoch": 0.44642857142857145,
      "grad_norm": 0.044170040637254715,
      "learning_rate": 4.7212375552480025e-05,
      "loss": 0.0257,
      "step": 12500
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.04673714190721512,
      "learning_rate": 4.719005312737176e-05,
      "loss": 0.0257,
      "step": 12600
    },
    {
      "epoch": 0.45357142857142857,
      "grad_norm": 0.06157201901078224,
      "learning_rate": 4.71677307022635e-05,
      "loss": 0.0255,
      "step": 12700
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 0.031077230349183083,
      "learning_rate": 4.714540827715523e-05,
      "loss": 0.026,
      "step": 12800
    },
    {
      "epoch": 0.4607142857142857,
      "grad_norm": 0.03594949096441269,
      "learning_rate": 4.7123085852046964e-05,
      "loss": 0.0251,
      "step": 12900
    },
    {
      "epoch": 0.4642857142857143,
      "grad_norm": 0.04948945343494415,
      "learning_rate": 4.7100763426938704e-05,
      "loss": 0.0253,
      "step": 13000
    },
    {
      "epoch": 0.46785714285714286,
      "grad_norm": 0.04434724897146225,
      "learning_rate": 4.7078441001830444e-05,
      "loss": 0.0262,
      "step": 13100
    },
    {
      "epoch": 0.4714285714285714,
      "grad_norm": 0.047492869198322296,
      "learning_rate": 4.7056118576722176e-05,
      "loss": 0.0254,
      "step": 13200
    },
    {
      "epoch": 0.475,
      "grad_norm": 0.04982377216219902,
      "learning_rate": 4.703379615161391e-05,
      "loss": 0.0245,
      "step": 13300
    },
    {
      "epoch": 0.4785714285714286,
      "grad_norm": 0.05249207094311714,
      "learning_rate": 4.701147372650565e-05,
      "loss": 0.0247,
      "step": 13400
    },
    {
      "epoch": 0.48214285714285715,
      "grad_norm": 0.04317379370331764,
      "learning_rate": 4.698915130139739e-05,
      "loss": 0.0256,
      "step": 13500
    },
    {
      "epoch": 0.4857142857142857,
      "grad_norm": 0.037565283477306366,
      "learning_rate": 4.696682887628912e-05,
      "loss": 0.0264,
      "step": 13600
    },
    {
      "epoch": 0.48928571428571427,
      "grad_norm": 0.032813455909490585,
      "learning_rate": 4.694450645118086e-05,
      "loss": 0.026,
      "step": 13700
    },
    {
      "epoch": 0.4928571428571429,
      "grad_norm": 0.06556917726993561,
      "learning_rate": 4.6922184026072595e-05,
      "loss": 0.0251,
      "step": 13800
    },
    {
      "epoch": 0.49642857142857144,
      "grad_norm": 0.027298735454678535,
      "learning_rate": 4.689986160096433e-05,
      "loss": 0.0245,
      "step": 13900
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.05918337404727936,
      "learning_rate": 4.687753917585607e-05,
      "loss": 0.0256,
      "step": 14000
    },
    {
      "epoch": 0.5035714285714286,
      "grad_norm": 0.053287431597709656,
      "learning_rate": 4.685521675074781e-05,
      "loss": 0.0262,
      "step": 14100
    },
    {
      "epoch": 0.5071428571428571,
      "grad_norm": 0.03414732590317726,
      "learning_rate": 4.683289432563954e-05,
      "loss": 0.0248,
      "step": 14200
    },
    {
      "epoch": 0.5107142857142857,
      "grad_norm": 0.03743847459554672,
      "learning_rate": 4.681057190053127e-05,
      "loss": 0.0257,
      "step": 14300
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 0.03063744306564331,
      "learning_rate": 4.678824947542301e-05,
      "loss": 0.0246,
      "step": 14400
    },
    {
      "epoch": 0.5178571428571429,
      "grad_norm": 0.05823468789458275,
      "learning_rate": 4.676592705031475e-05,
      "loss": 0.0238,
      "step": 14500
    },
    {
      "epoch": 0.5214285714285715,
      "grad_norm": 0.04601152986288071,
      "learning_rate": 4.6743604625206486e-05,
      "loss": 0.0264,
      "step": 14600
    },
    {
      "epoch": 0.525,
      "grad_norm": 0.050309084355831146,
      "learning_rate": 4.672128220009822e-05,
      "loss": 0.0265,
      "step": 14700
    },
    {
      "epoch": 0.5285714285714286,
      "grad_norm": 0.04094235226511955,
      "learning_rate": 4.669895977498996e-05,
      "loss": 0.0243,
      "step": 14800
    },
    {
      "epoch": 0.5321428571428571,
      "grad_norm": 0.050618983805179596,
      "learning_rate": 4.667663734988169e-05,
      "loss": 0.0259,
      "step": 14900
    },
    {
      "epoch": 0.5357142857142857,
      "grad_norm": 0.04971340671181679,
      "learning_rate": 4.665431492477343e-05,
      "loss": 0.0249,
      "step": 15000
    },
    {
      "epoch": 0.5392857142857143,
      "grad_norm": 0.042686332017183304,
      "learning_rate": 4.6631992499665164e-05,
      "loss": 0.0249,
      "step": 15100
    },
    {
      "epoch": 0.5428571428571428,
      "grad_norm": 0.04909147694706917,
      "learning_rate": 4.6609670074556904e-05,
      "loss": 0.0264,
      "step": 15200
    },
    {
      "epoch": 0.5464285714285714,
      "grad_norm": 0.042197201400995255,
      "learning_rate": 4.658734764944864e-05,
      "loss": 0.0234,
      "step": 15300
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.05079769715666771,
      "learning_rate": 4.6565025224340377e-05,
      "loss": 0.0263,
      "step": 15400
    },
    {
      "epoch": 0.5535714285714286,
      "grad_norm": 0.0455901212990284,
      "learning_rate": 4.6542702799232116e-05,
      "loss": 0.0248,
      "step": 15500
    },
    {
      "epoch": 0.5571428571428572,
      "grad_norm": 0.03816642612218857,
      "learning_rate": 4.652038037412384e-05,
      "loss": 0.0242,
      "step": 15600
    },
    {
      "epoch": 0.5607142857142857,
      "grad_norm": 0.037276338785886765,
      "learning_rate": 4.649805794901558e-05,
      "loss": 0.0234,
      "step": 15700
    },
    {
      "epoch": 0.5642857142857143,
      "grad_norm": 0.05021105706691742,
      "learning_rate": 4.647573552390732e-05,
      "loss": 0.0244,
      "step": 15800
    },
    {
      "epoch": 0.5678571428571428,
      "grad_norm": 0.03596867248415947,
      "learning_rate": 4.6453413098799055e-05,
      "loss": 0.0234,
      "step": 15900
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.044025786221027374,
      "learning_rate": 4.6431090673690795e-05,
      "loss": 0.0241,
      "step": 16000
    },
    {
      "epoch": 0.575,
      "grad_norm": 0.0520499050617218,
      "learning_rate": 4.640876824858253e-05,
      "loss": 0.0243,
      "step": 16100
    },
    {
      "epoch": 0.5785714285714286,
      "grad_norm": 0.05036952346563339,
      "learning_rate": 4.638644582347427e-05,
      "loss": 0.023,
      "step": 16200
    },
    {
      "epoch": 0.5821428571428572,
      "grad_norm": 0.0542956180870533,
      "learning_rate": 4.6364123398366e-05,
      "loss": 0.0251,
      "step": 16300
    },
    {
      "epoch": 0.5857142857142857,
      "grad_norm": 0.03829862177371979,
      "learning_rate": 4.634180097325774e-05,
      "loss": 0.0248,
      "step": 16400
    },
    {
      "epoch": 0.5892857142857143,
      "grad_norm": 0.04834425449371338,
      "learning_rate": 4.631947854814947e-05,
      "loss": 0.0237,
      "step": 16500
    },
    {
      "epoch": 0.5928571428571429,
      "grad_norm": 0.032367829233407974,
      "learning_rate": 4.6297156123041206e-05,
      "loss": 0.0246,
      "step": 16600
    },
    {
      "epoch": 0.5964285714285714,
      "grad_norm": 0.03241773694753647,
      "learning_rate": 4.6274833697932946e-05,
      "loss": 0.0238,
      "step": 16700
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.03512357547879219,
      "learning_rate": 4.625273449707577e-05,
      "loss": 0.025,
      "step": 16800
    },
    {
      "epoch": 0.6035714285714285,
      "grad_norm": 0.039464790374040604,
      "learning_rate": 4.62304120719675e-05,
      "loss": 0.0254,
      "step": 16900
    },
    {
      "epoch": 0.6071428571428571,
      "grad_norm": 0.036956269294023514,
      "learning_rate": 4.620808964685924e-05,
      "loss": 0.0249,
      "step": 17000
    },
    {
      "epoch": 0.6107142857142858,
      "grad_norm": 0.044883452355861664,
      "learning_rate": 4.618576722175097e-05,
      "loss": 0.0252,
      "step": 17100
    },
    {
      "epoch": 0.6142857142857143,
      "grad_norm": 0.03827071934938431,
      "learning_rate": 4.6163444796642706e-05,
      "loss": 0.024,
      "step": 17200
    },
    {
      "epoch": 0.6178571428571429,
      "grad_norm": 0.0684104934334755,
      "learning_rate": 4.6141122371534446e-05,
      "loss": 0.0253,
      "step": 17300
    },
    {
      "epoch": 0.6214285714285714,
      "grad_norm": 0.02613765560090542,
      "learning_rate": 4.6118799946426186e-05,
      "loss": 0.0241,
      "step": 17400
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.034317463636398315,
      "learning_rate": 4.609647752131792e-05,
      "loss": 0.0235,
      "step": 17500
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 0.04896404594182968,
      "learning_rate": 4.607415509620965e-05,
      "loss": 0.0236,
      "step": 17600
    },
    {
      "epoch": 0.6321428571428571,
      "grad_norm": 0.046125005930662155,
      "learning_rate": 4.605183267110139e-05,
      "loss": 0.0243,
      "step": 17700
    },
    {
      "epoch": 0.6357142857142857,
      "grad_norm": 0.053108204156160355,
      "learning_rate": 4.602951024599313e-05,
      "loss": 0.0244,
      "step": 17800
    },
    {
      "epoch": 0.6392857142857142,
      "grad_norm": 0.033720653504133224,
      "learning_rate": 4.6007187820884864e-05,
      "loss": 0.0237,
      "step": 17900
    },
    {
      "epoch": 0.6428571428571429,
      "grad_norm": 0.027872180566191673,
      "learning_rate": 4.59848653957766e-05,
      "loss": 0.0244,
      "step": 18000
    },
    {
      "epoch": 0.6464285714285715,
      "grad_norm": 0.023865273222327232,
      "learning_rate": 4.596254297066834e-05,
      "loss": 0.0251,
      "step": 18100
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.03177544102072716,
      "learning_rate": 4.594022054556007e-05,
      "loss": 0.0236,
      "step": 18200
    },
    {
      "epoch": 0.6535714285714286,
      "grad_norm": 0.05233053117990494,
      "learning_rate": 4.591789812045181e-05,
      "loss": 0.0229,
      "step": 18300
    },
    {
      "epoch": 0.6571428571428571,
      "grad_norm": 0.047903887927532196,
      "learning_rate": 4.589557569534354e-05,
      "loss": 0.0246,
      "step": 18400
    },
    {
      "epoch": 0.6607142857142857,
      "grad_norm": 0.03024550899863243,
      "learning_rate": 4.5873253270235275e-05,
      "loss": 0.0245,
      "step": 18500
    },
    {
      "epoch": 0.6642857142857143,
      "grad_norm": 0.05324868857860565,
      "learning_rate": 4.5850930845127015e-05,
      "loss": 0.0235,
      "step": 18600
    },
    {
      "epoch": 0.6678571428571428,
      "grad_norm": 0.04592378810048103,
      "learning_rate": 4.5828608420018755e-05,
      "loss": 0.0252,
      "step": 18700
    },
    {
      "epoch": 0.6714285714285714,
      "grad_norm": 0.05612765625119209,
      "learning_rate": 4.5806285994910495e-05,
      "loss": 0.0255,
      "step": 18800
    },
    {
      "epoch": 0.675,
      "grad_norm": 0.032125115394592285,
      "learning_rate": 4.578396356980222e-05,
      "loss": 0.0254,
      "step": 18900
    },
    {
      "epoch": 0.6785714285714286,
      "grad_norm": 0.02532394975423813,
      "learning_rate": 4.576164114469396e-05,
      "loss": 0.024,
      "step": 19000
    },
    {
      "epoch": 0.6821428571428572,
      "grad_norm": 0.03465219959616661,
      "learning_rate": 4.57393187195857e-05,
      "loss": 0.0225,
      "step": 19100
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 0.05278262123465538,
      "learning_rate": 4.571699629447743e-05,
      "loss": 0.0244,
      "step": 19200
    },
    {
      "epoch": 0.6892857142857143,
      "grad_norm": 0.04834670573472977,
      "learning_rate": 4.5694897093620255e-05,
      "loss": 0.0235,
      "step": 19300
    },
    {
      "epoch": 0.6928571428571428,
      "grad_norm": 0.02693162113428116,
      "learning_rate": 4.5672574668511995e-05,
      "loss": 0.0232,
      "step": 19400
    },
    {
      "epoch": 0.6964285714285714,
      "grad_norm": 0.05051807686686516,
      "learning_rate": 4.565025224340372e-05,
      "loss": 0.0222,
      "step": 19500
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.033552899956703186,
      "learning_rate": 4.562792981829546e-05,
      "loss": 0.0239,
      "step": 19600
    },
    {
      "epoch": 0.7035714285714286,
      "grad_norm": 0.04313245415687561,
      "learning_rate": 4.56056073931872e-05,
      "loss": 0.0228,
      "step": 19700
    },
    {
      "epoch": 0.7071428571428572,
      "grad_norm": 0.040372345596551895,
      "learning_rate": 4.558328496807893e-05,
      "loss": 0.0229,
      "step": 19800
    },
    {
      "epoch": 0.7107142857142857,
      "grad_norm": 0.022228198125958443,
      "learning_rate": 4.556096254297067e-05,
      "loss": 0.0224,
      "step": 19900
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.022247249260544777,
      "learning_rate": 4.5538640117862406e-05,
      "loss": 0.0236,
      "step": 20000
    },
    {
      "epoch": 0.7178571428571429,
      "grad_norm": 0.05431930348277092,
      "learning_rate": 4.5516317692754146e-05,
      "loss": 0.023,
      "step": 20100
    },
    {
      "epoch": 0.7214285714285714,
      "grad_norm": 0.04179965704679489,
      "learning_rate": 4.549399526764588e-05,
      "loss": 0.0229,
      "step": 20200
    },
    {
      "epoch": 0.725,
      "grad_norm": 0.03211864084005356,
      "learning_rate": 4.547167284253762e-05,
      "loss": 0.022,
      "step": 20300
    },
    {
      "epoch": 0.7285714285714285,
      "grad_norm": 0.05747918412089348,
      "learning_rate": 4.544935041742935e-05,
      "loss": 0.0219,
      "step": 20400
    },
    {
      "epoch": 0.7321428571428571,
      "grad_norm": 0.03510627895593643,
      "learning_rate": 4.5427027992321084e-05,
      "loss": 0.0227,
      "step": 20500
    },
    {
      "epoch": 0.7357142857142858,
      "grad_norm": 0.03322860226035118,
      "learning_rate": 4.5404705567212824e-05,
      "loss": 0.023,
      "step": 20600
    },
    {
      "epoch": 0.7392857142857143,
      "grad_norm": 0.02890438213944435,
      "learning_rate": 4.5382383142104564e-05,
      "loss": 0.023,
      "step": 20700
    },
    {
      "epoch": 0.7428571428571429,
      "grad_norm": 0.04359173774719238,
      "learning_rate": 4.53600607169963e-05,
      "loss": 0.0223,
      "step": 20800
    },
    {
      "epoch": 0.7464285714285714,
      "grad_norm": 0.04653281345963478,
      "learning_rate": 4.533773829188803e-05,
      "loss": 0.0228,
      "step": 20900
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.043095238506793976,
      "learning_rate": 4.531541586677977e-05,
      "loss": 0.024,
      "step": 21000
    },
    {
      "epoch": 0.7535714285714286,
      "grad_norm": 0.037853628396987915,
      "learning_rate": 4.529309344167151e-05,
      "loss": 0.0233,
      "step": 21100
    },
    {
      "epoch": 0.7571428571428571,
      "grad_norm": 0.03655197471380234,
      "learning_rate": 4.527077101656324e-05,
      "loss": 0.0222,
      "step": 21200
    },
    {
      "epoch": 0.7607142857142857,
      "grad_norm": 0.032259371131658554,
      "learning_rate": 4.5248671815706064e-05,
      "loss": 0.0245,
      "step": 21300
    },
    {
      "epoch": 0.7642857142857142,
      "grad_norm": 0.04261751472949982,
      "learning_rate": 4.52263493905978e-05,
      "loss": 0.022,
      "step": 21400
    },
    {
      "epoch": 0.7678571428571429,
      "grad_norm": 0.04353218898177147,
      "learning_rate": 4.520402696548953e-05,
      "loss": 0.0212,
      "step": 21500
    },
    {
      "epoch": 0.7714285714285715,
      "grad_norm": 0.024278491735458374,
      "learning_rate": 4.518170454038127e-05,
      "loss": 0.0219,
      "step": 21600
    },
    {
      "epoch": 0.775,
      "grad_norm": 0.03560546785593033,
      "learning_rate": 4.515938211527301e-05,
      "loss": 0.0229,
      "step": 21700
    },
    {
      "epoch": 0.7785714285714286,
      "grad_norm": 0.040031470358371735,
      "learning_rate": 4.513705969016474e-05,
      "loss": 0.0212,
      "step": 21800
    },
    {
      "epoch": 0.7821428571428571,
      "grad_norm": 0.054485950618982315,
      "learning_rate": 4.5114737265056475e-05,
      "loss": 0.0219,
      "step": 21900
    },
    {
      "epoch": 0.7857142857142857,
      "grad_norm": 0.045594774186611176,
      "learning_rate": 4.5092414839948215e-05,
      "loss": 0.0217,
      "step": 22000
    },
    {
      "epoch": 0.7892857142857143,
      "grad_norm": 0.03487605229020119,
      "learning_rate": 4.507009241483995e-05,
      "loss": 0.022,
      "step": 22100
    },
    {
      "epoch": 0.7928571428571428,
      "grad_norm": 0.04383428767323494,
      "learning_rate": 4.504776998973169e-05,
      "loss": 0.0219,
      "step": 22200
    },
    {
      "epoch": 0.7964285714285714,
      "grad_norm": 0.028969664126634598,
      "learning_rate": 4.502544756462343e-05,
      "loss": 0.0218,
      "step": 22300
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.03717765584588051,
      "learning_rate": 4.5003125139515154e-05,
      "loss": 0.0233,
      "step": 22400
    },
    {
      "epoch": 0.8035714285714286,
      "grad_norm": 0.04011484608054161,
      "learning_rate": 4.4980802714406893e-05,
      "loss": 0.0213,
      "step": 22500
    },
    {
      "epoch": 0.8071428571428572,
      "grad_norm": 0.07631250470876694,
      "learning_rate": 4.495848028929863e-05,
      "loss": 0.0208,
      "step": 22600
    },
    {
      "epoch": 0.8107142857142857,
      "grad_norm": 0.04579991474747658,
      "learning_rate": 4.493615786419037e-05,
      "loss": 0.022,
      "step": 22700
    },
    {
      "epoch": 0.8142857142857143,
      "grad_norm": 0.037170518189668655,
      "learning_rate": 4.4913835439082106e-05,
      "loss": 0.0216,
      "step": 22800
    },
    {
      "epoch": 0.8178571428571428,
      "grad_norm": 0.04063284024596214,
      "learning_rate": 4.489151301397384e-05,
      "loss": 0.0208,
      "step": 22900
    },
    {
      "epoch": 0.8214285714285714,
      "grad_norm": 0.04481274634599686,
      "learning_rate": 4.486919058886558e-05,
      "loss": 0.0207,
      "step": 23000
    },
    {
      "epoch": 0.825,
      "grad_norm": 0.04242805764079094,
      "learning_rate": 4.484686816375731e-05,
      "loss": 0.0212,
      "step": 23100
    },
    {
      "epoch": 0.8285714285714286,
      "grad_norm": 0.053075723350048065,
      "learning_rate": 4.482454573864905e-05,
      "loss": 0.021,
      "step": 23200
    },
    {
      "epoch": 0.8321428571428572,
      "grad_norm": 0.05828382447361946,
      "learning_rate": 4.4802223313540784e-05,
      "loss": 0.0213,
      "step": 23300
    },
    {
      "epoch": 0.8357142857142857,
      "grad_norm": 0.050550080835819244,
      "learning_rate": 4.477990088843252e-05,
      "loss": 0.0203,
      "step": 23400
    },
    {
      "epoch": 0.8392857142857143,
      "grad_norm": 0.10233387351036072,
      "learning_rate": 4.475757846332426e-05,
      "loss": 0.0213,
      "step": 23500
    },
    {
      "epoch": 0.8428571428571429,
      "grad_norm": 0.04789102450013161,
      "learning_rate": 4.4735256038216e-05,
      "loss": 0.0216,
      "step": 23600
    },
    {
      "epoch": 0.8464285714285714,
      "grad_norm": 0.04624393582344055,
      "learning_rate": 4.471293361310773e-05,
      "loss": 0.022,
      "step": 23700
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.04342648759484291,
      "learning_rate": 4.469061118799946e-05,
      "loss": 0.022,
      "step": 23800
    },
    {
      "epoch": 0.8535714285714285,
      "grad_norm": 0.04870545119047165,
      "learning_rate": 4.46682887628912e-05,
      "loss": 0.0199,
      "step": 23900
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.06710722297430038,
      "learning_rate": 4.464596633778294e-05,
      "loss": 0.0206,
      "step": 24000
    },
    {
      "epoch": 0.8607142857142858,
      "grad_norm": 0.03509724140167236,
      "learning_rate": 4.4623643912674675e-05,
      "loss": 0.0217,
      "step": 24100
    },
    {
      "epoch": 0.8642857142857143,
      "grad_norm": 0.04860355705022812,
      "learning_rate": 4.460132148756641e-05,
      "loss": 0.0211,
      "step": 24200
    },
    {
      "epoch": 0.8678571428571429,
      "grad_norm": 0.019541682675480843,
      "learning_rate": 4.457899906245815e-05,
      "loss": 0.0197,
      "step": 24300
    },
    {
      "epoch": 0.8714285714285714,
      "grad_norm": 0.05868828669190407,
      "learning_rate": 4.455667663734988e-05,
      "loss": 0.0211,
      "step": 24400
    },
    {
      "epoch": 0.875,
      "grad_norm": 0.042583219707012177,
      "learning_rate": 4.453435421224162e-05,
      "loss": 0.0206,
      "step": 24500
    },
    {
      "epoch": 0.8785714285714286,
      "grad_norm": 0.05775422602891922,
      "learning_rate": 4.4512031787133354e-05,
      "loss": 0.0205,
      "step": 24600
    },
    {
      "epoch": 0.8821428571428571,
      "grad_norm": 0.04984911531209946,
      "learning_rate": 4.4489709362025094e-05,
      "loss": 0.0206,
      "step": 24700
    },
    {
      "epoch": 0.8857142857142857,
      "grad_norm": 0.03594547137618065,
      "learning_rate": 4.4467386936916826e-05,
      "loss": 0.0196,
      "step": 24800
    },
    {
      "epoch": 0.8892857142857142,
      "grad_norm": 0.022578371688723564,
      "learning_rate": 4.444528773605965e-05,
      "loss": 0.0192,
      "step": 24900
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 0.04513833671808243,
      "learning_rate": 4.442296531095139e-05,
      "loss": 0.0195,
      "step": 25000
    },
    {
      "epoch": 0.8964285714285715,
      "grad_norm": 0.049058277159929276,
      "learning_rate": 4.440064288584312e-05,
      "loss": 0.0195,
      "step": 25100
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.041993483901023865,
      "learning_rate": 4.4378320460734854e-05,
      "loss": 0.02,
      "step": 25200
    },
    {
      "epoch": 0.9035714285714286,
      "grad_norm": 0.02842293120920658,
      "learning_rate": 4.4355998035626593e-05,
      "loss": 0.0194,
      "step": 25300
    },
    {
      "epoch": 0.9071428571428571,
      "grad_norm": 0.030618272721767426,
      "learning_rate": 4.4333675610518326e-05,
      "loss": 0.0196,
      "step": 25400
    },
    {
      "epoch": 0.9107142857142857,
      "grad_norm": 0.03470015898346901,
      "learning_rate": 4.4311353185410066e-05,
      "loss": 0.0183,
      "step": 25500
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 0.06738034635782242,
      "learning_rate": 4.4289030760301806e-05,
      "loss": 0.0192,
      "step": 25600
    },
    {
      "epoch": 0.9178571428571428,
      "grad_norm": 0.03057534247636795,
      "learning_rate": 4.426670833519353e-05,
      "loss": 0.0196,
      "step": 25700
    },
    {
      "epoch": 0.9214285714285714,
      "grad_norm": 0.04962807148694992,
      "learning_rate": 4.424438591008527e-05,
      "loss": 0.0193,
      "step": 25800
    },
    {
      "epoch": 0.925,
      "grad_norm": 0.03475271165370941,
      "learning_rate": 4.422206348497701e-05,
      "loss": 0.0193,
      "step": 25900
    },
    {
      "epoch": 0.9285714285714286,
      "grad_norm": 0.03457895293831825,
      "learning_rate": 4.419974105986875e-05,
      "loss": 0.0196,
      "step": 26000
    },
    {
      "epoch": 0.9321428571428572,
      "grad_norm": 0.046219099313020706,
      "learning_rate": 4.4177418634760484e-05,
      "loss": 0.0194,
      "step": 26100
    },
    {
      "epoch": 0.9357142857142857,
      "grad_norm": 0.05268463119864464,
      "learning_rate": 4.415509620965222e-05,
      "loss": 0.0194,
      "step": 26200
    },
    {
      "epoch": 0.9392857142857143,
      "grad_norm": 0.05255267396569252,
      "learning_rate": 4.413277378454396e-05,
      "loss": 0.0202,
      "step": 26300
    },
    {
      "epoch": 0.9428571428571428,
      "grad_norm": 0.05035940557718277,
      "learning_rate": 4.411045135943569e-05,
      "loss": 0.0189,
      "step": 26400
    },
    {
      "epoch": 0.9464285714285714,
      "grad_norm": 0.03504815697669983,
      "learning_rate": 4.408812893432743e-05,
      "loss": 0.0192,
      "step": 26500
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.03998294472694397,
      "learning_rate": 4.406580650921916e-05,
      "loss": 0.0189,
      "step": 26600
    },
    {
      "epoch": 0.9535714285714286,
      "grad_norm": 0.03948059305548668,
      "learning_rate": 4.4043484084110896e-05,
      "loss": 0.0194,
      "step": 26700
    },
    {
      "epoch": 0.9571428571428572,
      "grad_norm": 0.04548575356602669,
      "learning_rate": 4.4021161659002636e-05,
      "loss": 0.0195,
      "step": 26800
    },
    {
      "epoch": 0.9607142857142857,
      "grad_norm": 0.03728114068508148,
      "learning_rate": 4.3998839233894375e-05,
      "loss": 0.0186,
      "step": 26900
    },
    {
      "epoch": 0.9642857142857143,
      "grad_norm": 0.031296536326408386,
      "learning_rate": 4.397651680878611e-05,
      "loss": 0.0197,
      "step": 27000
    },
    {
      "epoch": 0.9678571428571429,
      "grad_norm": 0.039191316813230515,
      "learning_rate": 4.395419438367784e-05,
      "loss": 0.0193,
      "step": 27100
    },
    {
      "epoch": 0.9714285714285714,
      "grad_norm": 0.040655139833688736,
      "learning_rate": 4.393187195856958e-05,
      "loss": 0.0195,
      "step": 27200
    },
    {
      "epoch": 0.975,
      "grad_norm": 0.03647545352578163,
      "learning_rate": 4.390954953346132e-05,
      "loss": 0.019,
      "step": 27300
    },
    {
      "epoch": 0.9785714285714285,
      "grad_norm": 0.03845875710248947,
      "learning_rate": 4.3887227108353054e-05,
      "loss": 0.0195,
      "step": 27400
    },
    {
      "epoch": 0.9821428571428571,
      "grad_norm": 0.0904846265912056,
      "learning_rate": 4.386490468324479e-05,
      "loss": 0.0193,
      "step": 27500
    },
    {
      "epoch": 0.9857142857142858,
      "grad_norm": 0.03164698928594589,
      "learning_rate": 4.3842582258136526e-05,
      "loss": 0.0193,
      "step": 27600
    },
    {
      "epoch": 0.9892857142857143,
      "grad_norm": 0.026827611029148102,
      "learning_rate": 4.382025983302826e-05,
      "loss": 0.0177,
      "step": 27700
    },
    {
      "epoch": 0.9928571428571429,
      "grad_norm": 0.02938690036535263,
      "learning_rate": 4.379793740792e-05,
      "loss": 0.0199,
      "step": 27800
    },
    {
      "epoch": 0.9964285714285714,
      "grad_norm": 0.04585050046443939,
      "learning_rate": 4.377561498281174e-05,
      "loss": 0.0196,
      "step": 27900
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.04855179414153099,
      "learning_rate": 4.3753515781954554e-05,
      "loss": 0.0189,
      "step": 28000
    },
    {
      "epoch": 1.0,
      "eval_accuracy_macro_0.5": 0.9945312142372131,
      "eval_accuracy_micro_0.5": 0.9945311546325684,
      "eval_accuracy_weighted_0.5": 0.9866402745246887,
      "eval_aucroc_macro": 0.5224112868309021,
      "eval_aucroc_micro": 0.583669126033783,
      "eval_aucroc_weighted": 0.5813645124435425,
      "eval_f1_macro_0.5": 0.010311615653336048,
      "eval_f1_macro_0.6": 0.0046495841816067696,
      "eval_f1_macro_0.7": 0.0009384853183291852,
      "eval_f1_macro_0.8": 0.0,
      "eval_f1_micro_0.5": 0.07621608674526215,
      "eval_f1_micro_0.6": 0.0318930558860302,
      "eval_f1_micro_0.7": 0.005877282470464706,
      "eval_f1_micro_0.8": 0.0004194960929453373,
      "eval_f1_micro_0.9": 0.0,
      "eval_f1_weighted_0.5": 0.04976670816540718,
      "eval_f1_weighted_0.6": 0.024213138967752457,
      "eval_f1_weighted_0.7": 0.005404936149716377,
      "eval_f1_weighted_0.8": 0.0,
      "eval_loss": 0.017214439809322357,
      "eval_runtime": 2091.9397,
      "eval_samples_per_second": 26.607,
      "eval_steps_per_second": 3.326,
      "step": 28000
    },
    {
      "epoch": 1.0035714285714286,
      "grad_norm": 0.052286114543676376,
      "learning_rate": 4.3731193356846287e-05,
      "loss": 0.0185,
      "step": 28100
    },
    {
      "epoch": 1.0071428571428571,
      "grad_norm": 0.05006534606218338,
      "learning_rate": 4.3708870931738026e-05,
      "loss": 0.0185,
      "step": 28200
    },
    {
      "epoch": 1.0107142857142857,
      "grad_norm": 0.04065599665045738,
      "learning_rate": 4.368654850662976e-05,
      "loss": 0.0184,
      "step": 28300
    },
    {
      "epoch": 1.0142857142857142,
      "grad_norm": 0.032977789640426636,
      "learning_rate": 4.36642260815215e-05,
      "loss": 0.0173,
      "step": 28400
    },
    {
      "epoch": 1.0178571428571428,
      "grad_norm": 0.03591436520218849,
      "learning_rate": 4.364190365641324e-05,
      "loss": 0.019,
      "step": 28500
    },
    {
      "epoch": 1.0214285714285714,
      "grad_norm": 0.023507649078965187,
      "learning_rate": 4.361958123130497e-05,
      "loss": 0.018,
      "step": 28600
    },
    {
      "epoch": 1.025,
      "grad_norm": 0.02919323556125164,
      "learning_rate": 4.3597258806196705e-05,
      "loss": 0.0185,
      "step": 28700
    },
    {
      "epoch": 1.0285714285714285,
      "grad_norm": 0.034898433834314346,
      "learning_rate": 4.3574936381088445e-05,
      "loss": 0.018,
      "step": 28800
    },
    {
      "epoch": 1.032142857142857,
      "grad_norm": 0.04661189764738083,
      "learning_rate": 4.3552613955980184e-05,
      "loss": 0.0192,
      "step": 28900
    },
    {
      "epoch": 1.0357142857142858,
      "grad_norm": 0.04743726924061775,
      "learning_rate": 4.353029153087192e-05,
      "loss": 0.0171,
      "step": 29000
    },
    {
      "epoch": 1.0392857142857144,
      "grad_norm": 0.02029608003795147,
      "learning_rate": 4.350796910576365e-05,
      "loss": 0.0177,
      "step": 29100
    },
    {
      "epoch": 1.042857142857143,
      "grad_norm": 0.04082192853093147,
      "learning_rate": 4.348564668065539e-05,
      "loss": 0.0169,
      "step": 29200
    },
    {
      "epoch": 1.0464285714285715,
      "grad_norm": 0.035418763756752014,
      "learning_rate": 4.346332425554712e-05,
      "loss": 0.0189,
      "step": 29300
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.03187683969736099,
      "learning_rate": 4.344100183043886e-05,
      "loss": 0.0169,
      "step": 29400
    },
    {
      "epoch": 1.0535714285714286,
      "grad_norm": 0.026368273422122,
      "learning_rate": 4.3418679405330596e-05,
      "loss": 0.0175,
      "step": 29500
    },
    {
      "epoch": 1.0571428571428572,
      "grad_norm": 0.04214717820286751,
      "learning_rate": 4.3396356980222335e-05,
      "loss": 0.0174,
      "step": 29600
    },
    {
      "epoch": 1.0607142857142857,
      "grad_norm": 0.04714960977435112,
      "learning_rate": 4.337403455511407e-05,
      "loss": 0.0171,
      "step": 29700
    },
    {
      "epoch": 1.0642857142857143,
      "grad_norm": 0.03498190641403198,
      "learning_rate": 4.335171213000581e-05,
      "loss": 0.0175,
      "step": 29800
    },
    {
      "epoch": 1.0678571428571428,
      "grad_norm": 0.03127241134643555,
      "learning_rate": 4.332938970489754e-05,
      "loss": 0.0173,
      "step": 29900
    },
    {
      "epoch": 1.0714285714285714,
      "grad_norm": 0.04167581722140312,
      "learning_rate": 4.3307067279789274e-05,
      "loss": 0.0179,
      "step": 30000
    },
    {
      "epoch": 1.075,
      "grad_norm": 0.04206140711903572,
      "learning_rate": 4.3284744854681014e-05,
      "loss": 0.0156,
      "step": 30100
    },
    {
      "epoch": 1.0785714285714285,
      "grad_norm": 0.03525786101818085,
      "learning_rate": 4.3262422429572754e-05,
      "loss": 0.0178,
      "step": 30200
    },
    {
      "epoch": 1.082142857142857,
      "grad_norm": 0.04097754880785942,
      "learning_rate": 4.324010000446449e-05,
      "loss": 0.0171,
      "step": 30300
    },
    {
      "epoch": 1.0857142857142856,
      "grad_norm": 0.05076528340578079,
      "learning_rate": 4.321777757935622e-05,
      "loss": 0.0172,
      "step": 30400
    },
    {
      "epoch": 1.0892857142857142,
      "grad_norm": 0.04340384528040886,
      "learning_rate": 4.319545515424796e-05,
      "loss": 0.017,
      "step": 30500
    },
    {
      "epoch": 1.092857142857143,
      "grad_norm": 0.09824149310588837,
      "learning_rate": 4.31731327291397e-05,
      "loss": 0.0172,
      "step": 30600
    },
    {
      "epoch": 1.0964285714285715,
      "grad_norm": 0.032212477177381516,
      "learning_rate": 4.3151033528282514e-05,
      "loss": 0.0171,
      "step": 30700
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.052359603345394135,
      "learning_rate": 4.3128711103174254e-05,
      "loss": 0.0172,
      "step": 30800
    },
    {
      "epoch": 1.1035714285714286,
      "grad_norm": 0.031651366502046585,
      "learning_rate": 4.3106388678065987e-05,
      "loss": 0.0172,
      "step": 30900
    },
    {
      "epoch": 1.1071428571428572,
      "grad_norm": 0.061479486525058746,
      "learning_rate": 4.308406625295772e-05,
      "loss": 0.018,
      "step": 31000
    },
    {
      "epoch": 1.1107142857142858,
      "grad_norm": 0.038709528744220734,
      "learning_rate": 4.306174382784946e-05,
      "loss": 0.0168,
      "step": 31100
    },
    {
      "epoch": 1.1142857142857143,
      "grad_norm": 0.03736381605267525,
      "learning_rate": 4.30394214027412e-05,
      "loss": 0.0176,
      "step": 31200
    },
    {
      "epoch": 1.1178571428571429,
      "grad_norm": 0.05344027280807495,
      "learning_rate": 4.301709897763293e-05,
      "loss": 0.0174,
      "step": 31300
    },
    {
      "epoch": 1.1214285714285714,
      "grad_norm": 0.04639120027422905,
      "learning_rate": 4.2994776552524665e-05,
      "loss": 0.0167,
      "step": 31400
    },
    {
      "epoch": 1.125,
      "grad_norm": 0.0429094061255455,
      "learning_rate": 4.2972454127416405e-05,
      "loss": 0.0166,
      "step": 31500
    },
    {
      "epoch": 1.1285714285714286,
      "grad_norm": 0.0440763458609581,
      "learning_rate": 4.295013170230814e-05,
      "loss": 0.016,
      "step": 31600
    },
    {
      "epoch": 1.1321428571428571,
      "grad_norm": 0.02828970178961754,
      "learning_rate": 4.292780927719988e-05,
      "loss": 0.0171,
      "step": 31700
    },
    {
      "epoch": 1.1357142857142857,
      "grad_norm": 0.043907757848501205,
      "learning_rate": 4.290548685209162e-05,
      "loss": 0.0166,
      "step": 31800
    },
    {
      "epoch": 1.1392857142857142,
      "grad_norm": 0.02819795161485672,
      "learning_rate": 4.288316442698335e-05,
      "loss": 0.0171,
      "step": 31900
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.042117539793252945,
      "learning_rate": 4.286084200187508e-05,
      "loss": 0.0168,
      "step": 32000
    },
    {
      "epoch": 1.1464285714285714,
      "grad_norm": 0.041518211364746094,
      "learning_rate": 4.283851957676682e-05,
      "loss": 0.0169,
      "step": 32100
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.03930224850773811,
      "learning_rate": 4.281619715165856e-05,
      "loss": 0.0159,
      "step": 32200
    },
    {
      "epoch": 1.1535714285714285,
      "grad_norm": 0.04598070681095123,
      "learning_rate": 4.2793874726550296e-05,
      "loss": 0.0173,
      "step": 32300
    },
    {
      "epoch": 1.157142857142857,
      "grad_norm": 0.05164780840277672,
      "learning_rate": 4.277155230144203e-05,
      "loss": 0.0169,
      "step": 32400
    },
    {
      "epoch": 1.1607142857142858,
      "grad_norm": 0.04538783058524132,
      "learning_rate": 4.274922987633377e-05,
      "loss": 0.0162,
      "step": 32500
    },
    {
      "epoch": 1.1642857142857144,
      "grad_norm": 0.035741161555051804,
      "learning_rate": 4.27269074512255e-05,
      "loss": 0.0169,
      "step": 32600
    },
    {
      "epoch": 1.167857142857143,
      "grad_norm": 0.040407270193099976,
      "learning_rate": 4.270458502611724e-05,
      "loss": 0.017,
      "step": 32700
    },
    {
      "epoch": 1.1714285714285715,
      "grad_norm": 0.03232518956065178,
      "learning_rate": 4.2682262601008974e-05,
      "loss": 0.0171,
      "step": 32800
    },
    {
      "epoch": 1.175,
      "grad_norm": 0.03781035542488098,
      "learning_rate": 4.2659940175900714e-05,
      "loss": 0.0173,
      "step": 32900
    },
    {
      "epoch": 1.1785714285714286,
      "grad_norm": 0.04090375080704689,
      "learning_rate": 4.263761775079245e-05,
      "loss": 0.0157,
      "step": 33000
    },
    {
      "epoch": 1.1821428571428572,
      "grad_norm": 0.04647458344697952,
      "learning_rate": 4.2615295325684187e-05,
      "loss": 0.0173,
      "step": 33100
    },
    {
      "epoch": 1.1857142857142857,
      "grad_norm": 0.05613487586379051,
      "learning_rate": 4.259297290057592e-05,
      "loss": 0.017,
      "step": 33200
    },
    {
      "epoch": 1.1892857142857143,
      "grad_norm": 0.0246176365762949,
      "learning_rate": 4.257065047546765e-05,
      "loss": 0.0167,
      "step": 33300
    },
    {
      "epoch": 1.1928571428571428,
      "grad_norm": 0.040945686399936676,
      "learning_rate": 4.254832805035939e-05,
      "loss": 0.0172,
      "step": 33400
    },
    {
      "epoch": 1.1964285714285714,
      "grad_norm": 0.05416754633188248,
      "learning_rate": 4.252600562525113e-05,
      "loss": 0.017,
      "step": 33500
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.047419559210538864,
      "learning_rate": 4.2503683200142865e-05,
      "loss": 0.0165,
      "step": 33600
    },
    {
      "epoch": 1.2035714285714285,
      "grad_norm": 0.030259108170866966,
      "learning_rate": 4.24813607750346e-05,
      "loss": 0.0165,
      "step": 33700
    },
    {
      "epoch": 1.207142857142857,
      "grad_norm": 0.03915025666356087,
      "learning_rate": 4.245903834992634e-05,
      "loss": 0.0165,
      "step": 33800
    },
    {
      "epoch": 1.2107142857142856,
      "grad_norm": 0.13239632546901703,
      "learning_rate": 4.243671592481808e-05,
      "loss": 0.0161,
      "step": 33900
    },
    {
      "epoch": 1.2142857142857142,
      "grad_norm": 0.045727767050266266,
      "learning_rate": 4.241439349970981e-05,
      "loss": 0.0158,
      "step": 34000
    },
    {
      "epoch": 1.217857142857143,
      "grad_norm": 0.039531074464321136,
      "learning_rate": 4.239207107460155e-05,
      "loss": 0.0158,
      "step": 34100
    },
    {
      "epoch": 1.2214285714285715,
      "grad_norm": 0.19476330280303955,
      "learning_rate": 4.236974864949328e-05,
      "loss": 0.0156,
      "step": 34200
    },
    {
      "epoch": 1.225,
      "grad_norm": 0.05186909809708595,
      "learning_rate": 4.2347426224385016e-05,
      "loss": 0.0155,
      "step": 34300
    },
    {
      "epoch": 1.2285714285714286,
      "grad_norm": 0.08518209308385849,
      "learning_rate": 4.2325103799276756e-05,
      "loss": 0.0155,
      "step": 34400
    },
    {
      "epoch": 1.2321428571428572,
      "grad_norm": 0.0580308735370636,
      "learning_rate": 4.2302781374168496e-05,
      "loss": 0.0166,
      "step": 34500
    },
    {
      "epoch": 1.2357142857142858,
      "grad_norm": 0.044764209538698196,
      "learning_rate": 4.228045894906023e-05,
      "loss": 0.0167,
      "step": 34600
    },
    {
      "epoch": 1.2392857142857143,
      "grad_norm": 0.023503990843892097,
      "learning_rate": 4.225813652395196e-05,
      "loss": 0.0154,
      "step": 34700
    },
    {
      "epoch": 1.2428571428571429,
      "grad_norm": 0.054728489369153976,
      "learning_rate": 4.22358140988437e-05,
      "loss": 0.0157,
      "step": 34800
    },
    {
      "epoch": 1.2464285714285714,
      "grad_norm": 0.04066908359527588,
      "learning_rate": 4.221349167373544e-05,
      "loss": 0.0167,
      "step": 34900
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.04733705893158913,
      "learning_rate": 4.2191169248627174e-05,
      "loss": 0.0161,
      "step": 35000
    },
    {
      "epoch": 1.2535714285714286,
      "grad_norm": 0.029943350702524185,
      "learning_rate": 4.216884682351891e-05,
      "loss": 0.0154,
      "step": 35100
    },
    {
      "epoch": 1.2571428571428571,
      "grad_norm": 0.04683784767985344,
      "learning_rate": 4.214652439841065e-05,
      "loss": 0.0148,
      "step": 35200
    },
    {
      "epoch": 1.2607142857142857,
      "grad_norm": 0.037877023220062256,
      "learning_rate": 4.212420197330238e-05,
      "loss": 0.0155,
      "step": 35300
    },
    {
      "epoch": 1.2642857142857142,
      "grad_norm": 0.04154098033905029,
      "learning_rate": 4.210187954819412e-05,
      "loss": 0.0151,
      "step": 35400
    },
    {
      "epoch": 1.2678571428571428,
      "grad_norm": 0.03877919539809227,
      "learning_rate": 4.207955712308585e-05,
      "loss": 0.0162,
      "step": 35500
    },
    {
      "epoch": 1.2714285714285714,
      "grad_norm": 0.0444847047328949,
      "learning_rate": 4.2057234697977586e-05,
      "loss": 0.0164,
      "step": 35600
    },
    {
      "epoch": 1.275,
      "grad_norm": 0.12589089572429657,
      "learning_rate": 4.2034912272869325e-05,
      "loss": 0.0163,
      "step": 35700
    },
    {
      "epoch": 1.2785714285714285,
      "grad_norm": 0.04575078561902046,
      "learning_rate": 4.2012589847761065e-05,
      "loss": 0.016,
      "step": 35800
    },
    {
      "epoch": 1.282142857142857,
      "grad_norm": 0.06538575887680054,
      "learning_rate": 4.199049064690388e-05,
      "loss": 0.0153,
      "step": 35900
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 0.054470378905534744,
      "learning_rate": 4.196816822179562e-05,
      "loss": 0.0158,
      "step": 36000
    },
    {
      "epoch": 1.2892857142857144,
      "grad_norm": 0.039469920098781586,
      "learning_rate": 4.194584579668735e-05,
      "loss": 0.0157,
      "step": 36100
    },
    {
      "epoch": 1.292857142857143,
      "grad_norm": 0.04322943463921547,
      "learning_rate": 4.1923523371579085e-05,
      "loss": 0.0153,
      "step": 36200
    },
    {
      "epoch": 1.2964285714285715,
      "grad_norm": 0.039708659052848816,
      "learning_rate": 4.1901200946470825e-05,
      "loss": 0.0157,
      "step": 36300
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.05378870666027069,
      "learning_rate": 4.1878878521362565e-05,
      "loss": 0.0151,
      "step": 36400
    },
    {
      "epoch": 1.3035714285714286,
      "grad_norm": 0.05597369000315666,
      "learning_rate": 4.18565560962543e-05,
      "loss": 0.0153,
      "step": 36500
    },
    {
      "epoch": 1.3071428571428572,
      "grad_norm": 0.041413601487874985,
      "learning_rate": 4.183423367114603e-05,
      "loss": 0.0149,
      "step": 36600
    },
    {
      "epoch": 1.3107142857142857,
      "grad_norm": 0.048483140766620636,
      "learning_rate": 4.181191124603777e-05,
      "loss": 0.0154,
      "step": 36700
    },
    {
      "epoch": 1.3142857142857143,
      "grad_norm": 0.03930966183543205,
      "learning_rate": 4.178958882092951e-05,
      "loss": 0.0153,
      "step": 36800
    },
    {
      "epoch": 1.3178571428571428,
      "grad_norm": 0.030978623777627945,
      "learning_rate": 4.1767266395821243e-05,
      "loss": 0.0156,
      "step": 36900
    },
    {
      "epoch": 1.3214285714285714,
      "grad_norm": 0.07833048701286316,
      "learning_rate": 4.1744943970712976e-05,
      "loss": 0.0158,
      "step": 37000
    },
    {
      "epoch": 1.325,
      "grad_norm": 0.1146756187081337,
      "learning_rate": 4.1722621545604716e-05,
      "loss": 0.0155,
      "step": 37100
    },
    {
      "epoch": 1.3285714285714285,
      "grad_norm": 0.05370471999049187,
      "learning_rate": 4.1700299120496456e-05,
      "loss": 0.0151,
      "step": 37200
    },
    {
      "epoch": 1.332142857142857,
      "grad_norm": 0.041283585131168365,
      "learning_rate": 4.167797669538819e-05,
      "loss": 0.0149,
      "step": 37300
    },
    {
      "epoch": 1.3357142857142856,
      "grad_norm": 0.033231303095817566,
      "learning_rate": 4.165587749453101e-05,
      "loss": 0.0149,
      "step": 37400
    },
    {
      "epoch": 1.3392857142857144,
      "grad_norm": 0.04613910987973213,
      "learning_rate": 4.163355506942274e-05,
      "loss": 0.0155,
      "step": 37500
    },
    {
      "epoch": 1.342857142857143,
      "grad_norm": 0.10342606902122498,
      "learning_rate": 4.1611232644314476e-05,
      "loss": 0.0147,
      "step": 37600
    },
    {
      "epoch": 1.3464285714285715,
      "grad_norm": 0.04672117158770561,
      "learning_rate": 4.1588910219206216e-05,
      "loss": 0.0164,
      "step": 37700
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.04213939979672432,
      "learning_rate": 4.1566587794097956e-05,
      "loss": 0.015,
      "step": 37800
    },
    {
      "epoch": 1.3535714285714286,
      "grad_norm": 0.02953590266406536,
      "learning_rate": 4.154426536898969e-05,
      "loss": 0.0154,
      "step": 37900
    },
    {
      "epoch": 1.3571428571428572,
      "grad_norm": 0.039923567324876785,
      "learning_rate": 4.152194294388143e-05,
      "loss": 0.0153,
      "step": 38000
    },
    {
      "epoch": 1.3607142857142858,
      "grad_norm": 0.0486515611410141,
      "learning_rate": 4.149962051877316e-05,
      "loss": 0.0161,
      "step": 38100
    },
    {
      "epoch": 1.3642857142857143,
      "grad_norm": 0.11959552019834518,
      "learning_rate": 4.1477298093664894e-05,
      "loss": 0.0153,
      "step": 38200
    },
    {
      "epoch": 1.3678571428571429,
      "grad_norm": 0.067497618496418,
      "learning_rate": 4.1454975668556634e-05,
      "loss": 0.0161,
      "step": 38300
    },
    {
      "epoch": 1.3714285714285714,
      "grad_norm": 0.12823006510734558,
      "learning_rate": 4.1432653243448374e-05,
      "loss": 0.0148,
      "step": 38400
    },
    {
      "epoch": 1.375,
      "grad_norm": 0.050975251942873,
      "learning_rate": 4.141033081834011e-05,
      "loss": 0.0153,
      "step": 38500
    },
    {
      "epoch": 1.3785714285714286,
      "grad_norm": 0.036912113428115845,
      "learning_rate": 4.138800839323184e-05,
      "loss": 0.0154,
      "step": 38600
    },
    {
      "epoch": 1.3821428571428571,
      "grad_norm": 0.042599257081747055,
      "learning_rate": 4.136568596812358e-05,
      "loss": 0.0157,
      "step": 38700
    },
    {
      "epoch": 1.3857142857142857,
      "grad_norm": 0.04446742311120033,
      "learning_rate": 4.134336354301532e-05,
      "loss": 0.0151,
      "step": 38800
    },
    {
      "epoch": 1.3892857142857142,
      "grad_norm": 0.03156682848930359,
      "learning_rate": 4.132104111790705e-05,
      "loss": 0.0152,
      "step": 38900
    },
    {
      "epoch": 1.3928571428571428,
      "grad_norm": 0.044942811131477356,
      "learning_rate": 4.1298718692798785e-05,
      "loss": 0.0149,
      "step": 39000
    },
    {
      "epoch": 1.3964285714285714,
      "grad_norm": 0.03597060963511467,
      "learning_rate": 4.1276396267690525e-05,
      "loss": 0.015,
      "step": 39100
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.04247095808386803,
      "learning_rate": 4.125407384258226e-05,
      "loss": 0.0147,
      "step": 39200
    },
    {
      "epoch": 1.4035714285714285,
      "grad_norm": 0.02918514423072338,
      "learning_rate": 4.1231751417474e-05,
      "loss": 0.0147,
      "step": 39300
    },
    {
      "epoch": 1.407142857142857,
      "grad_norm": 0.0456940233707428,
      "learning_rate": 4.120942899236573e-05,
      "loss": 0.0152,
      "step": 39400
    },
    {
      "epoch": 1.4107142857142856,
      "grad_norm": 0.04495077207684517,
      "learning_rate": 4.1187106567257464e-05,
      "loss": 0.0149,
      "step": 39500
    },
    {
      "epoch": 1.4142857142857144,
      "grad_norm": 0.042695172131061554,
      "learning_rate": 4.1164784142149204e-05,
      "loss": 0.0151,
      "step": 39600
    },
    {
      "epoch": 1.417857142857143,
      "grad_norm": 0.061187993735075,
      "learning_rate": 4.114246171704094e-05,
      "loss": 0.0146,
      "step": 39700
    },
    {
      "epoch": 1.4214285714285715,
      "grad_norm": 0.050680067390203476,
      "learning_rate": 4.112013929193268e-05,
      "loss": 0.0153,
      "step": 39800
    },
    {
      "epoch": 1.425,
      "grad_norm": 0.09955490380525589,
      "learning_rate": 4.109781686682441e-05,
      "loss": 0.0146,
      "step": 39900
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.060633741319179535,
      "learning_rate": 4.107549444171615e-05,
      "loss": 0.0151,
      "step": 40000
    },
    {
      "epoch": 1.4321428571428572,
      "grad_norm": 0.0443614162504673,
      "learning_rate": 4.105317201660789e-05,
      "loss": 0.0142,
      "step": 40100
    },
    {
      "epoch": 1.4357142857142857,
      "grad_norm": NaN,
      "learning_rate": 4.1031072815750704e-05,
      "loss": 0.0149,
      "step": 40200
    },
    {
      "epoch": 1.4392857142857143,
      "grad_norm": 0.059920139610767365,
      "learning_rate": 4.100875039064244e-05,
      "loss": 0.0152,
      "step": 40300
    },
    {
      "epoch": 1.4428571428571428,
      "grad_norm": 0.02811179682612419,
      "learning_rate": 4.098642796553418e-05,
      "loss": 0.014,
      "step": 40400
    },
    {
      "epoch": 1.4464285714285714,
      "grad_norm": 0.054797373712062836,
      "learning_rate": 4.096410554042591e-05,
      "loss": 0.0151,
      "step": 40500
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.034917768090963364,
      "learning_rate": 4.094178311531765e-05,
      "loss": 0.0141,
      "step": 40600
    },
    {
      "epoch": 1.4535714285714285,
      "grad_norm": 0.04024196043610573,
      "learning_rate": 4.091946069020939e-05,
      "loss": 0.0147,
      "step": 40700
    },
    {
      "epoch": 1.457142857142857,
      "grad_norm": 0.07559243589639664,
      "learning_rate": 4.089713826510112e-05,
      "loss": 0.0153,
      "step": 40800
    },
    {
      "epoch": 1.4607142857142856,
      "grad_norm": 0.03548119589686394,
      "learning_rate": 4.087481583999286e-05,
      "loss": 0.0154,
      "step": 40900
    },
    {
      "epoch": 1.4642857142857144,
      "grad_norm": 0.04632887989282608,
      "learning_rate": 4.0852493414884594e-05,
      "loss": 0.0145,
      "step": 41000
    },
    {
      "epoch": 1.467857142857143,
      "grad_norm": 0.06335532665252686,
      "learning_rate": 4.083017098977633e-05,
      "loss": 0.0149,
      "step": 41100
    },
    {
      "epoch": 1.4714285714285715,
      "grad_norm": 0.05230218917131424,
      "learning_rate": 4.080784856466807e-05,
      "loss": 0.0157,
      "step": 41200
    },
    {
      "epoch": 1.475,
      "grad_norm": 0.032220784574747086,
      "learning_rate": 4.078552613955981e-05,
      "loss": 0.0132,
      "step": 41300
    },
    {
      "epoch": 1.4785714285714286,
      "grad_norm": 0.04502205550670624,
      "learning_rate": 4.076320371445154e-05,
      "loss": 0.0144,
      "step": 41400
    },
    {
      "epoch": 1.4821428571428572,
      "grad_norm": 0.03364134207367897,
      "learning_rate": 4.074088128934327e-05,
      "loss": 0.0143,
      "step": 41500
    },
    {
      "epoch": 1.4857142857142858,
      "grad_norm": 0.05116620287299156,
      "learning_rate": 4.071855886423501e-05,
      "loss": 0.0146,
      "step": 41600
    },
    {
      "epoch": 1.4892857142857143,
      "grad_norm": 0.06740182638168335,
      "learning_rate": 4.069623643912675e-05,
      "loss": 0.0157,
      "step": 41700
    },
    {
      "epoch": 1.4928571428571429,
      "grad_norm": 0.0356348417699337,
      "learning_rate": 4.0673914014018485e-05,
      "loss": 0.0141,
      "step": 41800
    },
    {
      "epoch": 1.4964285714285714,
      "grad_norm": 0.042503587901592255,
      "learning_rate": 4.065159158891022e-05,
      "loss": 0.0147,
      "step": 41900
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.05535263195633888,
      "learning_rate": 4.062926916380196e-05,
      "loss": 0.0141,
      "step": 42000
    },
    {
      "epoch": 1.5035714285714286,
      "grad_norm": 0.035306647419929504,
      "learning_rate": 4.06069467386937e-05,
      "loss": 0.0143,
      "step": 42100
    },
    {
      "epoch": 1.5071428571428571,
      "grad_norm": 0.04910838231444359,
      "learning_rate": 4.058462431358543e-05,
      "loss": 0.0146,
      "step": 42200
    },
    {
      "epoch": 1.5107142857142857,
      "grad_norm": 0.05343836918473244,
      "learning_rate": 4.0562301888477164e-05,
      "loss": 0.0145,
      "step": 42300
    },
    {
      "epoch": 1.5142857142857142,
      "grad_norm": 0.02099592238664627,
      "learning_rate": 4.0539979463368904e-05,
      "loss": 0.014,
      "step": 42400
    },
    {
      "epoch": 1.5178571428571428,
      "grad_norm": 0.021107757464051247,
      "learning_rate": 4.0517657038260637e-05,
      "loss": 0.0142,
      "step": 42500
    },
    {
      "epoch": 1.5214285714285714,
      "grad_norm": 0.041473161429166794,
      "learning_rate": 4.0495334613152376e-05,
      "loss": 0.0146,
      "step": 42600
    },
    {
      "epoch": 1.525,
      "grad_norm": 0.03770758956670761,
      "learning_rate": 4.0473012188044116e-05,
      "loss": 0.0144,
      "step": 42700
    },
    {
      "epoch": 1.5285714285714285,
      "grad_norm": 0.041696228086948395,
      "learning_rate": 4.045068976293584e-05,
      "loss": 0.0138,
      "step": 42800
    },
    {
      "epoch": 1.532142857142857,
      "grad_norm": 0.057961005717515945,
      "learning_rate": 4.042836733782758e-05,
      "loss": 0.0149,
      "step": 42900
    },
    {
      "epoch": 1.5357142857142856,
      "grad_norm": 0.040083132684230804,
      "learning_rate": 4.040604491271932e-05,
      "loss": 0.0147,
      "step": 43000
    },
    {
      "epoch": 1.5392857142857141,
      "grad_norm": 0.02966941148042679,
      "learning_rate": 4.038372248761106e-05,
      "loss": 0.0141,
      "step": 43100
    },
    {
      "epoch": 1.5428571428571427,
      "grad_norm": 0.04459155350923538,
      "learning_rate": 4.036140006250279e-05,
      "loss": 0.0146,
      "step": 43200
    },
    {
      "epoch": 1.5464285714285713,
      "grad_norm": 0.04264666512608528,
      "learning_rate": 4.033907763739453e-05,
      "loss": 0.014,
      "step": 43300
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.042249687016010284,
      "learning_rate": 4.031675521228627e-05,
      "loss": 0.0147,
      "step": 43400
    },
    {
      "epoch": 1.5535714285714286,
      "grad_norm": 0.07810892164707184,
      "learning_rate": 4.0294432787178e-05,
      "loss": 0.0143,
      "step": 43500
    },
    {
      "epoch": 1.5571428571428572,
      "grad_norm": 0.03751160204410553,
      "learning_rate": 4.027211036206974e-05,
      "loss": 0.0141,
      "step": 43600
    },
    {
      "epoch": 1.5607142857142857,
      "grad_norm": 0.03936002030968666,
      "learning_rate": 4.024978793696147e-05,
      "loss": 0.0149,
      "step": 43700
    },
    {
      "epoch": 1.5642857142857143,
      "grad_norm": 0.050902750343084335,
      "learning_rate": 4.0227465511853206e-05,
      "loss": 0.0141,
      "step": 43800
    },
    {
      "epoch": 1.5678571428571428,
      "grad_norm": 0.054834526032209396,
      "learning_rate": 4.0205143086744946e-05,
      "loss": 0.0137,
      "step": 43900
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 0.026766346767544746,
      "learning_rate": 4.0182820661636685e-05,
      "loss": 0.0139,
      "step": 44000
    },
    {
      "epoch": 1.575,
      "grad_norm": 0.03919273987412453,
      "learning_rate": 4.016049823652842e-05,
      "loss": 0.0137,
      "step": 44100
    },
    {
      "epoch": 1.5785714285714287,
      "grad_norm": 0.04643071070313454,
      "learning_rate": 4.013817581142015e-05,
      "loss": 0.0143,
      "step": 44200
    },
    {
      "epoch": 1.5821428571428573,
      "grad_norm": 0.061074335128068924,
      "learning_rate": 4.011585338631189e-05,
      "loss": 0.0144,
      "step": 44300
    },
    {
      "epoch": 1.5857142857142859,
      "grad_norm": 0.045669201761484146,
      "learning_rate": 4.009353096120363e-05,
      "loss": 0.0134,
      "step": 44400
    },
    {
      "epoch": 1.5892857142857144,
      "grad_norm": 0.029851872473955154,
      "learning_rate": 4.0071208536095364e-05,
      "loss": 0.0136,
      "step": 44500
    },
    {
      "epoch": 1.592857142857143,
      "grad_norm": 0.033148590475320816,
      "learning_rate": 4.00488861109871e-05,
      "loss": 0.0133,
      "step": 44600
    },
    {
      "epoch": 1.5964285714285715,
      "grad_norm": 0.03418328985571861,
      "learning_rate": 4.0026563685878837e-05,
      "loss": 0.0141,
      "step": 44700
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.0496181882917881,
      "learning_rate": 4.000424126077057e-05,
      "loss": 0.0145,
      "step": 44800
    },
    {
      "epoch": 1.6035714285714286,
      "grad_norm": 0.0739586353302002,
      "learning_rate": 3.998191883566231e-05,
      "loss": 0.014,
      "step": 44900
    },
    {
      "epoch": 1.6071428571428572,
      "grad_norm": 0.04836259037256241,
      "learning_rate": 3.995959641055404e-05,
      "loss": 0.0138,
      "step": 45000
    },
    {
      "epoch": 1.6107142857142858,
      "grad_norm": 0.06776996701955795,
      "learning_rate": 3.993727398544578e-05,
      "loss": 0.0139,
      "step": 45100
    },
    {
      "epoch": 1.6142857142857143,
      "grad_norm": 0.04444722458720207,
      "learning_rate": 3.9914951560337515e-05,
      "loss": 0.0143,
      "step": 45200
    },
    {
      "epoch": 1.6178571428571429,
      "grad_norm": 0.06477754563093185,
      "learning_rate": 3.9892629135229255e-05,
      "loss": 0.015,
      "step": 45300
    },
    {
      "epoch": 1.6214285714285714,
      "grad_norm": 0.031372230499982834,
      "learning_rate": 3.9870306710120995e-05,
      "loss": 0.0147,
      "step": 45400
    },
    {
      "epoch": 1.625,
      "grad_norm": 0.04581987112760544,
      "learning_rate": 3.984798428501272e-05,
      "loss": 0.0149,
      "step": 45500
    },
    {
      "epoch": 1.6285714285714286,
      "grad_norm": 0.04581116512417793,
      "learning_rate": 3.982566185990446e-05,
      "loss": 0.0132,
      "step": 45600
    },
    {
      "epoch": 1.6321428571428571,
      "grad_norm": 0.04378347098827362,
      "learning_rate": 3.98033394347962e-05,
      "loss": 0.0139,
      "step": 45700
    },
    {
      "epoch": 1.6357142857142857,
      "grad_norm": 0.052941758185625076,
      "learning_rate": 3.978101700968793e-05,
      "loss": 0.0133,
      "step": 45800
    },
    {
      "epoch": 1.6392857142857142,
      "grad_norm": 0.06632764637470245,
      "learning_rate": 3.975869458457967e-05,
      "loss": 0.0136,
      "step": 45900
    },
    {
      "epoch": 1.6428571428571428,
      "grad_norm": 0.047214165329933167,
      "learning_rate": 3.9736372159471406e-05,
      "loss": 0.0139,
      "step": 46000
    },
    {
      "epoch": 1.6464285714285714,
      "grad_norm": 0.03054434061050415,
      "learning_rate": 3.9714049734363146e-05,
      "loss": 0.0145,
      "step": 46100
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.03530247509479523,
      "learning_rate": 3.969172730925488e-05,
      "loss": 0.0138,
      "step": 46200
    },
    {
      "epoch": 1.6535714285714285,
      "grad_norm": 0.05416150391101837,
      "learning_rate": 3.966940488414662e-05,
      "loss": 0.0136,
      "step": 46300
    },
    {
      "epoch": 1.657142857142857,
      "grad_norm": 0.03179861605167389,
      "learning_rate": 3.964708245903835e-05,
      "loss": 0.0139,
      "step": 46400
    },
    {
      "epoch": 1.6607142857142856,
      "grad_norm": 0.021218780428171158,
      "learning_rate": 3.9624760033930084e-05,
      "loss": 0.0141,
      "step": 46500
    },
    {
      "epoch": 1.6642857142857141,
      "grad_norm": 0.06537862122058868,
      "learning_rate": 3.9602437608821824e-05,
      "loss": 0.0135,
      "step": 46600
    },
    {
      "epoch": 1.6678571428571427,
      "grad_norm": 0.05082083120942116,
      "learning_rate": 3.9580115183713564e-05,
      "loss": 0.0137,
      "step": 46700
    },
    {
      "epoch": 1.6714285714285713,
      "grad_norm": 0.044375352561473846,
      "learning_rate": 3.95577927586053e-05,
      "loss": 0.0135,
      "step": 46800
    },
    {
      "epoch": 1.675,
      "grad_norm": 0.04460558295249939,
      "learning_rate": 3.953547033349703e-05,
      "loss": 0.0141,
      "step": 46900
    },
    {
      "epoch": 1.6785714285714286,
      "grad_norm": 0.03685133531689644,
      "learning_rate": 3.951314790838877e-05,
      "loss": 0.0141,
      "step": 47000
    },
    {
      "epoch": 1.6821428571428572,
      "grad_norm": 0.06807833164930344,
      "learning_rate": 3.949082548328051e-05,
      "loss": 0.0142,
      "step": 47100
    },
    {
      "epoch": 1.6857142857142857,
      "grad_norm": 0.055548328906297684,
      "learning_rate": 3.946850305817224e-05,
      "loss": 0.0135,
      "step": 47200
    },
    {
      "epoch": 1.6892857142857143,
      "grad_norm": 0.056651558727025986,
      "learning_rate": 3.9446180633063975e-05,
      "loss": 0.014,
      "step": 47300
    },
    {
      "epoch": 1.6928571428571428,
      "grad_norm": 0.030492618680000305,
      "learning_rate": 3.9423858207955715e-05,
      "loss": 0.0148,
      "step": 47400
    },
    {
      "epoch": 1.6964285714285714,
      "grad_norm": 0.0412619486451149,
      "learning_rate": 3.940153578284745e-05,
      "loss": 0.0127,
      "step": 47500
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.04705934226512909,
      "learning_rate": 3.937921335773919e-05,
      "loss": 0.0136,
      "step": 47600
    },
    {
      "epoch": 1.7035714285714287,
      "grad_norm": 0.03058231808245182,
      "learning_rate": 3.935689093263093e-05,
      "loss": 0.0132,
      "step": 47700
    },
    {
      "epoch": 1.7071428571428573,
      "grad_norm": 0.05445046350359917,
      "learning_rate": 3.9334568507522654e-05,
      "loss": 0.0124,
      "step": 47800
    },
    {
      "epoch": 1.7107142857142859,
      "grad_norm": 0.043442659080028534,
      "learning_rate": 3.9312246082414393e-05,
      "loss": 0.0141,
      "step": 47900
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.037310585379600525,
      "learning_rate": 3.928992365730613e-05,
      "loss": 0.0143,
      "step": 48000
    },
    {
      "epoch": 1.717857142857143,
      "grad_norm": 0.03499481454491615,
      "learning_rate": 3.926760123219787e-05,
      "loss": 0.0134,
      "step": 48100
    },
    {
      "epoch": 1.7214285714285715,
      "grad_norm": 0.04945674538612366,
      "learning_rate": 3.9245278807089606e-05,
      "loss": 0.0131,
      "step": 48200
    },
    {
      "epoch": 1.725,
      "grad_norm": 0.06121746450662613,
      "learning_rate": 3.922295638198134e-05,
      "loss": 0.0129,
      "step": 48300
    },
    {
      "epoch": 1.7285714285714286,
      "grad_norm": 0.035746704787015915,
      "learning_rate": 3.9200857181124154e-05,
      "loss": 0.0129,
      "step": 48400
    },
    {
      "epoch": 1.7321428571428572,
      "grad_norm": 0.04149426892399788,
      "learning_rate": 3.917853475601589e-05,
      "loss": 0.0135,
      "step": 48500
    },
    {
      "epoch": 1.7357142857142858,
      "grad_norm": 0.0552976094186306,
      "learning_rate": 3.9156435555158715e-05,
      "loss": 0.0147,
      "step": 48600
    },
    {
      "epoch": 1.7392857142857143,
      "grad_norm": 0.02966136857867241,
      "learning_rate": 3.913411313005045e-05,
      "loss": 0.0132,
      "step": 48700
    },
    {
      "epoch": 1.7428571428571429,
      "grad_norm": 0.02107101120054722,
      "learning_rate": 3.911179070494219e-05,
      "loss": 0.0134,
      "step": 48800
    },
    {
      "epoch": 1.7464285714285714,
      "grad_norm": 0.051111046224832535,
      "learning_rate": 3.908946827983393e-05,
      "loss": 0.0137,
      "step": 48900
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.03300679475069046,
      "learning_rate": 3.906714585472566e-05,
      "loss": 0.0131,
      "step": 49000
    },
    {
      "epoch": 1.7535714285714286,
      "grad_norm": 0.04244111105799675,
      "learning_rate": 3.904482342961739e-05,
      "loss": 0.0128,
      "step": 49100
    },
    {
      "epoch": 1.7571428571428571,
      "grad_norm": 0.031554773449897766,
      "learning_rate": 3.902250100450913e-05,
      "loss": 0.0125,
      "step": 49200
    },
    {
      "epoch": 1.7607142857142857,
      "grad_norm": 0.0385144017636776,
      "learning_rate": 3.900017857940087e-05,
      "loss": 0.0141,
      "step": 49300
    },
    {
      "epoch": 1.7642857142857142,
      "grad_norm": 0.04876549169421196,
      "learning_rate": 3.8977856154292606e-05,
      "loss": 0.0129,
      "step": 49400
    },
    {
      "epoch": 1.7678571428571428,
      "grad_norm": 0.07995649427175522,
      "learning_rate": 3.895553372918434e-05,
      "loss": 0.0135,
      "step": 49500
    },
    {
      "epoch": 1.7714285714285714,
      "grad_norm": 0.053684551268815994,
      "learning_rate": 3.893321130407608e-05,
      "loss": 0.0131,
      "step": 49600
    },
    {
      "epoch": 1.775,
      "grad_norm": 0.0440257303416729,
      "learning_rate": 3.891088887896781e-05,
      "loss": 0.0129,
      "step": 49700
    },
    {
      "epoch": 1.7785714285714285,
      "grad_norm": 0.048423245549201965,
      "learning_rate": 3.888856645385955e-05,
      "loss": 0.0137,
      "step": 49800
    },
    {
      "epoch": 1.782142857142857,
      "grad_norm": 0.04544924572110176,
      "learning_rate": 3.8866244028751284e-05,
      "loss": 0.0134,
      "step": 49900
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.06652010977268219,
      "learning_rate": 3.8843921603643024e-05,
      "loss": 0.013,
      "step": 50000
    },
    {
      "epoch": 1.7892857142857141,
      "grad_norm": 0.03944939002394676,
      "learning_rate": 3.882159917853476e-05,
      "loss": 0.0129,
      "step": 50100
    },
    {
      "epoch": 1.7928571428571427,
      "grad_norm": 0.0490628145635128,
      "learning_rate": 3.87992767534265e-05,
      "loss": 0.0128,
      "step": 50200
    },
    {
      "epoch": 1.7964285714285713,
      "grad_norm": 0.029201382771134377,
      "learning_rate": 3.877695432831823e-05,
      "loss": 0.0127,
      "step": 50300
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.016440918669104576,
      "learning_rate": 3.875463190320996e-05,
      "loss": 0.0132,
      "step": 50400
    },
    {
      "epoch": 1.8035714285714286,
      "grad_norm": 0.032023314386606216,
      "learning_rate": 3.87323094781017e-05,
      "loss": 0.0138,
      "step": 50500
    },
    {
      "epoch": 1.8071428571428572,
      "grad_norm": 0.06095957010984421,
      "learning_rate": 3.870998705299344e-05,
      "loss": 0.0136,
      "step": 50600
    },
    {
      "epoch": 1.8107142857142857,
      "grad_norm": 0.03340252488851547,
      "learning_rate": 3.8687664627885175e-05,
      "loss": 0.013,
      "step": 50700
    },
    {
      "epoch": 1.8142857142857143,
      "grad_norm": 0.05623567849397659,
      "learning_rate": 3.866534220277691e-05,
      "loss": 0.0142,
      "step": 50800
    },
    {
      "epoch": 1.8178571428571428,
      "grad_norm": 0.04897165298461914,
      "learning_rate": 3.864301977766865e-05,
      "loss": 0.0133,
      "step": 50900
    },
    {
      "epoch": 1.8214285714285714,
      "grad_norm": 0.03641398623585701,
      "learning_rate": 3.862069735256039e-05,
      "loss": 0.0129,
      "step": 51000
    },
    {
      "epoch": 1.825,
      "grad_norm": 0.04592540115118027,
      "learning_rate": 3.859837492745212e-05,
      "loss": 0.0131,
      "step": 51100
    },
    {
      "epoch": 1.8285714285714287,
      "grad_norm": 0.03809722885489464,
      "learning_rate": 3.8576052502343854e-05,
      "loss": 0.0124,
      "step": 51200
    },
    {
      "epoch": 1.8321428571428573,
      "grad_norm": 0.05024750903248787,
      "learning_rate": 3.855373007723559e-05,
      "loss": 0.0137,
      "step": 51300
    },
    {
      "epoch": 1.8357142857142859,
      "grad_norm": 0.04332369565963745,
      "learning_rate": 3.8531407652127326e-05,
      "loss": 0.0137,
      "step": 51400
    },
    {
      "epoch": 1.8392857142857144,
      "grad_norm": 0.05705792456865311,
      "learning_rate": 3.8509085227019066e-05,
      "loss": 0.0127,
      "step": 51500
    },
    {
      "epoch": 1.842857142857143,
      "grad_norm": 0.05560900643467903,
      "learning_rate": 3.8486762801910806e-05,
      "loss": 0.0118,
      "step": 51600
    },
    {
      "epoch": 1.8464285714285715,
      "grad_norm": 0.05511679872870445,
      "learning_rate": 3.846444037680253e-05,
      "loss": 0.0126,
      "step": 51700
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.05101795122027397,
      "learning_rate": 3.844211795169427e-05,
      "loss": 0.0131,
      "step": 51800
    },
    {
      "epoch": 1.8535714285714286,
      "grad_norm": 0.057851407676935196,
      "learning_rate": 3.841979552658601e-05,
      "loss": 0.0127,
      "step": 51900
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 0.024459796026349068,
      "learning_rate": 3.839747310147775e-05,
      "loss": 0.0128,
      "step": 52000
    },
    {
      "epoch": 1.8607142857142858,
      "grad_norm": 0.050057802349328995,
      "learning_rate": 3.8375373900620566e-05,
      "loss": 0.0133,
      "step": 52100
    },
    {
      "epoch": 1.8642857142857143,
      "grad_norm": 0.06185644119977951,
      "learning_rate": 3.8353051475512306e-05,
      "loss": 0.0129,
      "step": 52200
    },
    {
      "epoch": 1.8678571428571429,
      "grad_norm": 0.04786514863371849,
      "learning_rate": 3.833072905040403e-05,
      "loss": 0.0131,
      "step": 52300
    },
    {
      "epoch": 1.8714285714285714,
      "grad_norm": 0.029286785051226616,
      "learning_rate": 3.830840662529577e-05,
      "loss": 0.0127,
      "step": 52400
    },
    {
      "epoch": 1.875,
      "grad_norm": 0.10368750244379044,
      "learning_rate": 3.828608420018751e-05,
      "loss": 0.0123,
      "step": 52500
    },
    {
      "epoch": 1.8785714285714286,
      "grad_norm": 0.06216742843389511,
      "learning_rate": 3.826376177507925e-05,
      "loss": 0.0133,
      "step": 52600
    },
    {
      "epoch": 1.8821428571428571,
      "grad_norm": 0.038121920078992844,
      "learning_rate": 3.8241439349970984e-05,
      "loss": 0.0129,
      "step": 52700
    },
    {
      "epoch": 1.8857142857142857,
      "grad_norm": 0.05181246995925903,
      "learning_rate": 3.821911692486272e-05,
      "loss": 0.0129,
      "step": 52800
    },
    {
      "epoch": 1.8892857142857142,
      "grad_norm": 0.020952533930540085,
      "learning_rate": 3.819679449975446e-05,
      "loss": 0.013,
      "step": 52900
    },
    {
      "epoch": 1.8928571428571428,
      "grad_norm": 0.08365033566951752,
      "learning_rate": 3.817447207464619e-05,
      "loss": 0.0133,
      "step": 53000
    },
    {
      "epoch": 1.8964285714285714,
      "grad_norm": 0.02855895459651947,
      "learning_rate": 3.815214964953793e-05,
      "loss": 0.0133,
      "step": 53100
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.0600130632519722,
      "learning_rate": 3.812982722442966e-05,
      "loss": 0.013,
      "step": 53200
    },
    {
      "epoch": 1.9035714285714285,
      "grad_norm": 0.04331488534808159,
      "learning_rate": 3.8107504799321396e-05,
      "loss": 0.0125,
      "step": 53300
    },
    {
      "epoch": 1.907142857142857,
      "grad_norm": 0.06955660879611969,
      "learning_rate": 3.8085182374213135e-05,
      "loss": 0.0131,
      "step": 53400
    },
    {
      "epoch": 1.9107142857142856,
      "grad_norm": 0.0634915679693222,
      "learning_rate": 3.8062859949104875e-05,
      "loss": 0.0131,
      "step": 53500
    },
    {
      "epoch": 1.9142857142857141,
      "grad_norm": 0.05471139773726463,
      "learning_rate": 3.804053752399661e-05,
      "loss": 0.0127,
      "step": 53600
    },
    {
      "epoch": 1.9178571428571427,
      "grad_norm": 0.06115933507680893,
      "learning_rate": 3.801821509888834e-05,
      "loss": 0.0128,
      "step": 53700
    },
    {
      "epoch": 1.9214285714285713,
      "grad_norm": 0.04990437254309654,
      "learning_rate": 3.799589267378008e-05,
      "loss": 0.0136,
      "step": 53800
    },
    {
      "epoch": 1.925,
      "grad_norm": 0.03077796846628189,
      "learning_rate": 3.797357024867182e-05,
      "loss": 0.0133,
      "step": 53900
    },
    {
      "epoch": 1.9285714285714286,
      "grad_norm": 0.06993765383958817,
      "learning_rate": 3.7951247823563554e-05,
      "loss": 0.013,
      "step": 54000
    },
    {
      "epoch": 1.9321428571428572,
      "grad_norm": 0.027917807921767235,
      "learning_rate": 3.7928925398455287e-05,
      "loss": 0.0125,
      "step": 54100
    },
    {
      "epoch": 1.9357142857142857,
      "grad_norm": 0.05062791705131531,
      "learning_rate": 3.7906602973347026e-05,
      "loss": 0.0136,
      "step": 54200
    },
    {
      "epoch": 1.9392857142857143,
      "grad_norm": 0.0988985225558281,
      "learning_rate": 3.788428054823876e-05,
      "loss": 0.0124,
      "step": 54300
    },
    {
      "epoch": 1.9428571428571428,
      "grad_norm": 0.05796297267079353,
      "learning_rate": 3.78619581231305e-05,
      "loss": 0.0135,
      "step": 54400
    },
    {
      "epoch": 1.9464285714285714,
      "grad_norm": 0.0631914809346199,
      "learning_rate": 3.783963569802224e-05,
      "loss": 0.0132,
      "step": 54500
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.052581533789634705,
      "learning_rate": 3.781731327291397e-05,
      "loss": 0.0126,
      "step": 54600
    },
    {
      "epoch": 1.9535714285714287,
      "grad_norm": 0.04331311583518982,
      "learning_rate": 3.7794990847805705e-05,
      "loss": 0.0124,
      "step": 54700
    },
    {
      "epoch": 1.9571428571428573,
      "grad_norm": 0.042062439024448395,
      "learning_rate": 3.7772668422697444e-05,
      "loss": 0.0123,
      "step": 54800
    },
    {
      "epoch": 1.9607142857142859,
      "grad_norm": 0.02467876859009266,
      "learning_rate": 3.7750345997589184e-05,
      "loss": 0.0128,
      "step": 54900
    },
    {
      "epoch": 1.9642857142857144,
      "grad_norm": 0.03283166140317917,
      "learning_rate": 3.7728246796732e-05,
      "loss": 0.0123,
      "step": 55000
    },
    {
      "epoch": 1.967857142857143,
      "grad_norm": 0.020041536539793015,
      "learning_rate": 3.770592437162374e-05,
      "loss": 0.0126,
      "step": 55100
    },
    {
      "epoch": 1.9714285714285715,
      "grad_norm": 0.035345129668712616,
      "learning_rate": 3.768360194651547e-05,
      "loss": 0.0118,
      "step": 55200
    },
    {
      "epoch": 1.975,
      "grad_norm": 0.021339189261198044,
      "learning_rate": 3.7661279521407205e-05,
      "loss": 0.0132,
      "step": 55300
    },
    {
      "epoch": 1.9785714285714286,
      "grad_norm": 0.043340522795915604,
      "learning_rate": 3.7638957096298944e-05,
      "loss": 0.0121,
      "step": 55400
    },
    {
      "epoch": 1.9821428571428572,
      "grad_norm": 0.05318373441696167,
      "learning_rate": 3.7616634671190684e-05,
      "loss": 0.0133,
      "step": 55500
    },
    {
      "epoch": 1.9857142857142858,
      "grad_norm": 0.0473618321120739,
      "learning_rate": 3.759431224608242e-05,
      "loss": 0.0122,
      "step": 55600
    },
    {
      "epoch": 1.9892857142857143,
      "grad_norm": 0.0478997528553009,
      "learning_rate": 3.757198982097415e-05,
      "loss": 0.0129,
      "step": 55700
    },
    {
      "epoch": 1.9928571428571429,
      "grad_norm": 0.026755720376968384,
      "learning_rate": 3.754966739586589e-05,
      "loss": 0.0127,
      "step": 55800
    },
    {
      "epoch": 1.9964285714285714,
      "grad_norm": 0.06506624817848206,
      "learning_rate": 3.752734497075763e-05,
      "loss": 0.0128,
      "step": 55900
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.10073398053646088,
      "learning_rate": 3.750502254564936e-05,
      "loss": 0.0137,
      "step": 56000
    },
    {
      "epoch": 2.0,
      "eval_accuracy_macro_0.5": 0.9953719973564148,
      "eval_accuracy_micro_0.5": 0.9953721165657043,
      "eval_accuracy_weighted_0.5": 0.9893978834152222,
      "eval_aucroc_macro": 0.6755794286727905,
      "eval_aucroc_micro": 0.7769649028778076,
      "eval_aucroc_weighted": 0.7743046283721924,
      "eval_f1_macro_0.5": 0.16185614466667175,
      "eval_f1_macro_0.6": 0.11074259877204895,
      "eval_f1_macro_0.7": 0.07077891379594803,
      "eval_f1_macro_0.8": 0.012978658080101013,
      "eval_f1_micro_0.5": 0.388980507850647,
      "eval_f1_micro_0.6": 0.2839444875717163,
      "eval_f1_micro_0.7": 0.1915363371372223,
      "eval_f1_micro_0.8": 0.10339121520519257,
      "eval_f1_micro_0.9": 0.025519249960780144,
      "eval_f1_weighted_0.5": 0.2982958257198334,
      "eval_f1_weighted_0.6": 0.20994782447814941,
      "eval_f1_weighted_0.7": 0.1418057680130005,
      "eval_f1_weighted_0.8": 0.021937359124422073,
      "eval_loss": 0.011272122152149677,
      "eval_runtime": 2198.2879,
      "eval_samples_per_second": 25.32,
      "eval_steps_per_second": 3.165,
      "step": 56000
    },
    {
      "epoch": 2.0035714285714286,
      "grad_norm": 0.037665288895368576,
      "learning_rate": 3.7482700120541096e-05,
      "loss": 0.0127,
      "step": 56100
    },
    {
      "epoch": 2.007142857142857,
      "grad_norm": 0.08710577338933945,
      "learning_rate": 3.7460377695432835e-05,
      "loss": 0.0121,
      "step": 56200
    },
    {
      "epoch": 2.0107142857142857,
      "grad_norm": 0.037202369421720505,
      "learning_rate": 3.743805527032457e-05,
      "loss": 0.0131,
      "step": 56300
    },
    {
      "epoch": 2.0142857142857142,
      "grad_norm": 0.08766549825668335,
      "learning_rate": 3.741573284521631e-05,
      "loss": 0.0122,
      "step": 56400
    },
    {
      "epoch": 2.017857142857143,
      "grad_norm": 0.04455186054110527,
      "learning_rate": 3.739341042010804e-05,
      "loss": 0.0127,
      "step": 56500
    },
    {
      "epoch": 2.0214285714285714,
      "grad_norm": 0.04291452839970589,
      "learning_rate": 3.7371087994999774e-05,
      "loss": 0.0118,
      "step": 56600
    },
    {
      "epoch": 2.025,
      "grad_norm": 0.04054424166679382,
      "learning_rate": 3.7348765569891514e-05,
      "loss": 0.0127,
      "step": 56700
    },
    {
      "epoch": 2.0285714285714285,
      "grad_norm": 0.02818557620048523,
      "learning_rate": 3.7326443144783253e-05,
      "loss": 0.0124,
      "step": 56800
    },
    {
      "epoch": 2.032142857142857,
      "grad_norm": 0.05052913352847099,
      "learning_rate": 3.7304120719674986e-05,
      "loss": 0.0128,
      "step": 56900
    },
    {
      "epoch": 2.0357142857142856,
      "grad_norm": 0.08138680458068848,
      "learning_rate": 3.728179829456672e-05,
      "loss": 0.0125,
      "step": 57000
    },
    {
      "epoch": 2.039285714285714,
      "grad_norm": 0.04402155429124832,
      "learning_rate": 3.725947586945846e-05,
      "loss": 0.0124,
      "step": 57100
    },
    {
      "epoch": 2.0428571428571427,
      "grad_norm": 0.05686093866825104,
      "learning_rate": 3.72371534443502e-05,
      "loss": 0.0123,
      "step": 57200
    },
    {
      "epoch": 2.0464285714285713,
      "grad_norm": 0.03448238968849182,
      "learning_rate": 3.721483101924193e-05,
      "loss": 0.0124,
      "step": 57300
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.06954263895750046,
      "learning_rate": 3.7192508594133665e-05,
      "loss": 0.013,
      "step": 57400
    },
    {
      "epoch": 2.0535714285714284,
      "grad_norm": 0.05252993851900101,
      "learning_rate": 3.7170186169025405e-05,
      "loss": 0.0129,
      "step": 57500
    },
    {
      "epoch": 2.057142857142857,
      "grad_norm": 0.04577519744634628,
      "learning_rate": 3.714808696816822e-05,
      "loss": 0.0125,
      "step": 57600
    },
    {
      "epoch": 2.0607142857142855,
      "grad_norm": 0.06054643169045448,
      "learning_rate": 3.712576454305996e-05,
      "loss": 0.0131,
      "step": 57700
    },
    {
      "epoch": 2.064285714285714,
      "grad_norm": 0.02676154114305973,
      "learning_rate": 3.71034421179517e-05,
      "loss": 0.0137,
      "step": 57800
    },
    {
      "epoch": 2.067857142857143,
      "grad_norm": 0.06722523272037506,
      "learning_rate": 3.708111969284343e-05,
      "loss": 0.013,
      "step": 57900
    },
    {
      "epoch": 2.0714285714285716,
      "grad_norm": 0.050519198179244995,
      "learning_rate": 3.7058797267735165e-05,
      "loss": 0.0136,
      "step": 58000
    },
    {
      "epoch": 2.075,
      "grad_norm": 0.02767420932650566,
      "learning_rate": 3.7036474842626905e-05,
      "loss": 0.0121,
      "step": 58100
    },
    {
      "epoch": 2.0785714285714287,
      "grad_norm": 0.06060938164591789,
      "learning_rate": 3.701415241751864e-05,
      "loss": 0.0129,
      "step": 58200
    },
    {
      "epoch": 2.0821428571428573,
      "grad_norm": 0.05014254152774811,
      "learning_rate": 3.699182999241038e-05,
      "loss": 0.0126,
      "step": 58300
    },
    {
      "epoch": 2.085714285714286,
      "grad_norm": 0.041356462985277176,
      "learning_rate": 3.696950756730212e-05,
      "loss": 0.0118,
      "step": 58400
    },
    {
      "epoch": 2.0892857142857144,
      "grad_norm": 0.037458401173353195,
      "learning_rate": 3.694718514219385e-05,
      "loss": 0.0129,
      "step": 58500
    },
    {
      "epoch": 2.092857142857143,
      "grad_norm": 0.03643977642059326,
      "learning_rate": 3.6925085941336665e-05,
      "loss": 0.0136,
      "step": 58600
    },
    {
      "epoch": 2.0964285714285715,
      "grad_norm": 0.052056245505809784,
      "learning_rate": 3.6902763516228404e-05,
      "loss": 0.0119,
      "step": 58700
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.06514599919319153,
      "learning_rate": 3.6880441091120144e-05,
      "loss": 0.0127,
      "step": 58800
    },
    {
      "epoch": 2.1035714285714286,
      "grad_norm": 0.041901517659425735,
      "learning_rate": 3.685811866601188e-05,
      "loss": 0.0129,
      "step": 58900
    },
    {
      "epoch": 2.107142857142857,
      "grad_norm": 0.0505569763481617,
      "learning_rate": 3.683579624090362e-05,
      "loss": 0.0114,
      "step": 59000
    },
    {
      "epoch": 2.1107142857142858,
      "grad_norm": 0.04074171558022499,
      "learning_rate": 3.681347381579535e-05,
      "loss": 0.012,
      "step": 59100
    },
    {
      "epoch": 2.1142857142857143,
      "grad_norm": 0.026971016079187393,
      "learning_rate": 3.679115139068708e-05,
      "loss": 0.0128,
      "step": 59200
    },
    {
      "epoch": 2.117857142857143,
      "grad_norm": 0.025673341006040573,
      "learning_rate": 3.676882896557882e-05,
      "loss": 0.0116,
      "step": 59300
    },
    {
      "epoch": 2.1214285714285714,
      "grad_norm": 0.03229592368006706,
      "learning_rate": 3.674650654047056e-05,
      "loss": 0.0123,
      "step": 59400
    },
    {
      "epoch": 2.125,
      "grad_norm": 0.03996353968977928,
      "learning_rate": 3.6724184115362295e-05,
      "loss": 0.0124,
      "step": 59500
    },
    {
      "epoch": 2.1285714285714286,
      "grad_norm": 0.03643063083291054,
      "learning_rate": 3.670186169025403e-05,
      "loss": 0.0125,
      "step": 59600
    },
    {
      "epoch": 2.132142857142857,
      "grad_norm": 0.05451308563351631,
      "learning_rate": 3.667953926514577e-05,
      "loss": 0.0118,
      "step": 59700
    },
    {
      "epoch": 2.1357142857142857,
      "grad_norm": 0.031139088794589043,
      "learning_rate": 3.665721684003751e-05,
      "loss": 0.0122,
      "step": 59800
    },
    {
      "epoch": 2.1392857142857142,
      "grad_norm": 0.03164667263627052,
      "learning_rate": 3.663489441492924e-05,
      "loss": 0.0128,
      "step": 59900
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.06475549191236496,
      "learning_rate": 3.6612571989820974e-05,
      "loss": 0.0118,
      "step": 60000
    },
    {
      "epoch": 2.1464285714285714,
      "grad_norm": 0.06047171726822853,
      "learning_rate": 3.6590249564712714e-05,
      "loss": 0.0117,
      "step": 60100
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.06554457545280457,
      "learning_rate": 3.6567927139604447e-05,
      "loss": 0.0117,
      "step": 60200
    },
    {
      "epoch": 2.1535714285714285,
      "grad_norm": 0.049412213265895844,
      "learning_rate": 3.6545604714496186e-05,
      "loss": 0.0121,
      "step": 60300
    },
    {
      "epoch": 2.157142857142857,
      "grad_norm": 0.03755930811166763,
      "learning_rate": 3.652328228938792e-05,
      "loss": 0.0122,
      "step": 60400
    },
    {
      "epoch": 2.1607142857142856,
      "grad_norm": 0.034049246460199356,
      "learning_rate": 3.650095986427965e-05,
      "loss": 0.0114,
      "step": 60500
    },
    {
      "epoch": 2.164285714285714,
      "grad_norm": 0.05558786541223526,
      "learning_rate": 3.647863743917139e-05,
      "loss": 0.0121,
      "step": 60600
    },
    {
      "epoch": 2.1678571428571427,
      "grad_norm": 0.06992550194263458,
      "learning_rate": 3.645631501406313e-05,
      "loss": 0.0131,
      "step": 60700
    },
    {
      "epoch": 2.1714285714285713,
      "grad_norm": 0.03670739382505417,
      "learning_rate": 3.643399258895487e-05,
      "loss": 0.0132,
      "step": 60800
    },
    {
      "epoch": 2.175,
      "grad_norm": 0.11253571510314941,
      "learning_rate": 3.64116701638466e-05,
      "loss": 0.0118,
      "step": 60900
    },
    {
      "epoch": 2.1785714285714284,
      "grad_norm": 0.0489613339304924,
      "learning_rate": 3.638957096298942e-05,
      "loss": 0.0126,
      "step": 61000
    },
    {
      "epoch": 2.182142857142857,
      "grad_norm": 0.05422314628958702,
      "learning_rate": 3.636724853788115e-05,
      "loss": 0.013,
      "step": 61100
    },
    {
      "epoch": 2.185714285714286,
      "grad_norm": 0.03585229068994522,
      "learning_rate": 3.634492611277289e-05,
      "loss": 0.0117,
      "step": 61200
    },
    {
      "epoch": 2.189285714285714,
      "grad_norm": 0.022077368572354317,
      "learning_rate": 3.632260368766463e-05,
      "loss": 0.0112,
      "step": 61300
    },
    {
      "epoch": 2.192857142857143,
      "grad_norm": 0.051878951489925385,
      "learning_rate": 3.630028126255637e-05,
      "loss": 0.0117,
      "step": 61400
    },
    {
      "epoch": 2.1964285714285716,
      "grad_norm": 0.05063323676586151,
      "learning_rate": 3.62779588374481e-05,
      "loss": 0.0119,
      "step": 61500
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.05378507450222969,
      "learning_rate": 3.625563641233984e-05,
      "loss": 0.0112,
      "step": 61600
    },
    {
      "epoch": 2.2035714285714287,
      "grad_norm": 0.04333246499300003,
      "learning_rate": 3.623331398723158e-05,
      "loss": 0.012,
      "step": 61700
    },
    {
      "epoch": 2.2071428571428573,
      "grad_norm": 0.03969573602080345,
      "learning_rate": 3.621099156212331e-05,
      "loss": 0.0118,
      "step": 61800
    },
    {
      "epoch": 2.210714285714286,
      "grad_norm": 0.023632287979125977,
      "learning_rate": 3.618866913701505e-05,
      "loss": 0.0121,
      "step": 61900
    },
    {
      "epoch": 2.2142857142857144,
      "grad_norm": 0.06194296479225159,
      "learning_rate": 3.616634671190678e-05,
      "loss": 0.0123,
      "step": 62000
    },
    {
      "epoch": 2.217857142857143,
      "grad_norm": 0.08062399923801422,
      "learning_rate": 3.6144024286798516e-05,
      "loss": 0.0121,
      "step": 62100
    },
    {
      "epoch": 2.2214285714285715,
      "grad_norm": 0.030111394822597504,
      "learning_rate": 3.6121701861690256e-05,
      "loss": 0.0111,
      "step": 62200
    },
    {
      "epoch": 2.225,
      "grad_norm": 0.03320014849305153,
      "learning_rate": 3.6099379436581995e-05,
      "loss": 0.0129,
      "step": 62300
    },
    {
      "epoch": 2.2285714285714286,
      "grad_norm": 0.04636969044804573,
      "learning_rate": 3.607705701147373e-05,
      "loss": 0.0123,
      "step": 62400
    },
    {
      "epoch": 2.232142857142857,
      "grad_norm": 0.05511732026934624,
      "learning_rate": 3.605473458636546e-05,
      "loss": 0.0118,
      "step": 62500
    },
    {
      "epoch": 2.2357142857142858,
      "grad_norm": 0.05939038470387459,
      "learning_rate": 3.60324121612572e-05,
      "loss": 0.0118,
      "step": 62600
    },
    {
      "epoch": 2.2392857142857143,
      "grad_norm": 0.04507322236895561,
      "learning_rate": 3.601008973614894e-05,
      "loss": 0.0115,
      "step": 62700
    },
    {
      "epoch": 2.242857142857143,
      "grad_norm": 0.03340921178460121,
      "learning_rate": 3.5987767311040674e-05,
      "loss": 0.0127,
      "step": 62800
    },
    {
      "epoch": 2.2464285714285714,
      "grad_norm": 0.08463020622730255,
      "learning_rate": 3.596544488593241e-05,
      "loss": 0.0125,
      "step": 62900
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.05004395171999931,
      "learning_rate": 3.5943122460824147e-05,
      "loss": 0.0125,
      "step": 63000
    },
    {
      "epoch": 2.2535714285714286,
      "grad_norm": 0.04713205620646477,
      "learning_rate": 3.592080003571588e-05,
      "loss": 0.0119,
      "step": 63100
    },
    {
      "epoch": 2.257142857142857,
      "grad_norm": 0.03036661446094513,
      "learning_rate": 3.589847761060762e-05,
      "loss": 0.0128,
      "step": 63200
    },
    {
      "epoch": 2.2607142857142857,
      "grad_norm": 0.029349258169531822,
      "learning_rate": 3.587615518549935e-05,
      "loss": 0.0118,
      "step": 63300
    },
    {
      "epoch": 2.2642857142857142,
      "grad_norm": 0.05236417055130005,
      "learning_rate": 3.585383276039109e-05,
      "loss": 0.0123,
      "step": 63400
    },
    {
      "epoch": 2.267857142857143,
      "grad_norm": 0.04078684002161026,
      "learning_rate": 3.5831510335282825e-05,
      "loss": 0.0122,
      "step": 63500
    },
    {
      "epoch": 2.2714285714285714,
      "grad_norm": 0.03556029126048088,
      "learning_rate": 3.5809187910174565e-05,
      "loss": 0.0115,
      "step": 63600
    },
    {
      "epoch": 2.275,
      "grad_norm": 0.035531364381313324,
      "learning_rate": 3.57868654850663e-05,
      "loss": 0.0126,
      "step": 63700
    },
    {
      "epoch": 2.2785714285714285,
      "grad_norm": 0.03996919095516205,
      "learning_rate": 3.576454305995803e-05,
      "loss": 0.0111,
      "step": 63800
    },
    {
      "epoch": 2.282142857142857,
      "grad_norm": 0.04824240878224373,
      "learning_rate": 3.574222063484977e-05,
      "loss": 0.012,
      "step": 63900
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.029412707313895226,
      "learning_rate": 3.571989820974151e-05,
      "loss": 0.0125,
      "step": 64000
    },
    {
      "epoch": 2.289285714285714,
      "grad_norm": 0.03051125630736351,
      "learning_rate": 3.569757578463325e-05,
      "loss": 0.0121,
      "step": 64100
    },
    {
      "epoch": 2.2928571428571427,
      "grad_norm": 0.043142303824424744,
      "learning_rate": 3.5675253359524976e-05,
      "loss": 0.012,
      "step": 64200
    },
    {
      "epoch": 2.2964285714285713,
      "grad_norm": 0.052338480949401855,
      "learning_rate": 3.5652930934416716e-05,
      "loss": 0.0125,
      "step": 64300
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.048518795520067215,
      "learning_rate": 3.5630608509308456e-05,
      "loss": 0.0115,
      "step": 64400
    },
    {
      "epoch": 2.3035714285714284,
      "grad_norm": 0.07120093703269958,
      "learning_rate": 3.560828608420019e-05,
      "loss": 0.0125,
      "step": 64500
    },
    {
      "epoch": 2.307142857142857,
      "grad_norm": 0.03227224573493004,
      "learning_rate": 3.558596365909193e-05,
      "loss": 0.0123,
      "step": 64600
    },
    {
      "epoch": 2.310714285714286,
      "grad_norm": 0.06757891923189163,
      "learning_rate": 3.556364123398366e-05,
      "loss": 0.012,
      "step": 64700
    },
    {
      "epoch": 2.314285714285714,
      "grad_norm": 0.030087096616625786,
      "learning_rate": 3.5541318808875394e-05,
      "loss": 0.0125,
      "step": 64800
    },
    {
      "epoch": 2.317857142857143,
      "grad_norm": 0.10194378346204758,
      "learning_rate": 3.5518996383767134e-05,
      "loss": 0.0121,
      "step": 64900
    },
    {
      "epoch": 2.3214285714285716,
      "grad_norm": 0.03188665956258774,
      "learning_rate": 3.5496897182909956e-05,
      "loss": 0.0117,
      "step": 65000
    },
    {
      "epoch": 2.325,
      "grad_norm": 0.04727959632873535,
      "learning_rate": 3.547457475780169e-05,
      "loss": 0.0118,
      "step": 65100
    },
    {
      "epoch": 2.3285714285714287,
      "grad_norm": 0.038679905235767365,
      "learning_rate": 3.545225233269343e-05,
      "loss": 0.0117,
      "step": 65200
    },
    {
      "epoch": 2.3321428571428573,
      "grad_norm": 0.04234761744737625,
      "learning_rate": 3.542992990758516e-05,
      "loss": 0.0106,
      "step": 65300
    },
    {
      "epoch": 2.335714285714286,
      "grad_norm": 0.03960335627198219,
      "learning_rate": 3.5407607482476894e-05,
      "loss": 0.0116,
      "step": 65400
    },
    {
      "epoch": 2.3392857142857144,
      "grad_norm": 0.06669922173023224,
      "learning_rate": 3.5385285057368634e-05,
      "loss": 0.0118,
      "step": 65500
    },
    {
      "epoch": 2.342857142857143,
      "grad_norm": 0.049560125917196274,
      "learning_rate": 3.5362962632260374e-05,
      "loss": 0.0117,
      "step": 65600
    },
    {
      "epoch": 2.3464285714285715,
      "grad_norm": 0.03924836590886116,
      "learning_rate": 3.534064020715211e-05,
      "loss": 0.012,
      "step": 65700
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.04428369551897049,
      "learning_rate": 3.531831778204384e-05,
      "loss": 0.0124,
      "step": 65800
    },
    {
      "epoch": 2.3535714285714286,
      "grad_norm": 0.043100666254758835,
      "learning_rate": 3.529599535693558e-05,
      "loss": 0.0117,
      "step": 65900
    },
    {
      "epoch": 2.357142857142857,
      "grad_norm": 0.040504634380340576,
      "learning_rate": 3.527367293182732e-05,
      "loss": 0.0128,
      "step": 66000
    },
    {
      "epoch": 2.3607142857142858,
      "grad_norm": 0.0659143477678299,
      "learning_rate": 3.525135050671905e-05,
      "loss": 0.0119,
      "step": 66100
    },
    {
      "epoch": 2.3642857142857143,
      "grad_norm": 0.03206509351730347,
      "learning_rate": 3.5229028081610785e-05,
      "loss": 0.0112,
      "step": 66200
    },
    {
      "epoch": 2.367857142857143,
      "grad_norm": 0.03125782683491707,
      "learning_rate": 3.5206705656502525e-05,
      "loss": 0.0121,
      "step": 66300
    },
    {
      "epoch": 2.3714285714285714,
      "grad_norm": 0.0632282942533493,
      "learning_rate": 3.518438323139426e-05,
      "loss": 0.0126,
      "step": 66400
    },
    {
      "epoch": 2.375,
      "grad_norm": 0.033996935933828354,
      "learning_rate": 3.5162060806286e-05,
      "loss": 0.0108,
      "step": 66500
    },
    {
      "epoch": 2.3785714285714286,
      "grad_norm": 0.05797909200191498,
      "learning_rate": 3.513973838117773e-05,
      "loss": 0.0116,
      "step": 66600
    },
    {
      "epoch": 2.382142857142857,
      "grad_norm": 0.041202545166015625,
      "learning_rate": 3.511763918032055e-05,
      "loss": 0.0115,
      "step": 66700
    },
    {
      "epoch": 2.3857142857142857,
      "grad_norm": 0.037514593452215195,
      "learning_rate": 3.5095316755212285e-05,
      "loss": 0.0116,
      "step": 66800
    },
    {
      "epoch": 2.3892857142857142,
      "grad_norm": 0.12655147910118103,
      "learning_rate": 3.5072994330104025e-05,
      "loss": 0.0127,
      "step": 66900
    },
    {
      "epoch": 2.392857142857143,
      "grad_norm": 0.046133894473314285,
      "learning_rate": 3.505067190499576e-05,
      "loss": 0.0117,
      "step": 67000
    },
    {
      "epoch": 2.3964285714285714,
      "grad_norm": 0.03228539600968361,
      "learning_rate": 3.50283494798875e-05,
      "loss": 0.0123,
      "step": 67100
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.06128574162721634,
      "learning_rate": 3.500602705477923e-05,
      "loss": 0.0121,
      "step": 67200
    },
    {
      "epoch": 2.4035714285714285,
      "grad_norm": 0.033329229801893234,
      "learning_rate": 3.498370462967097e-05,
      "loss": 0.0123,
      "step": 67300
    },
    {
      "epoch": 2.407142857142857,
      "grad_norm": 0.060392629355192184,
      "learning_rate": 3.49613822045627e-05,
      "loss": 0.0124,
      "step": 67400
    },
    {
      "epoch": 2.4107142857142856,
      "grad_norm": 0.04100874811410904,
      "learning_rate": 3.493905977945444e-05,
      "loss": 0.0112,
      "step": 67500
    },
    {
      "epoch": 2.414285714285714,
      "grad_norm": 0.038665808737277985,
      "learning_rate": 3.491673735434618e-05,
      "loss": 0.012,
      "step": 67600
    },
    {
      "epoch": 2.4178571428571427,
      "grad_norm": 0.03800300136208534,
      "learning_rate": 3.489441492923791e-05,
      "loss": 0.0111,
      "step": 67700
    },
    {
      "epoch": 2.4214285714285713,
      "grad_norm": 0.043888501822948456,
      "learning_rate": 3.487209250412965e-05,
      "loss": 0.0119,
      "step": 67800
    },
    {
      "epoch": 2.425,
      "grad_norm": 0.03004315122961998,
      "learning_rate": 3.484977007902139e-05,
      "loss": 0.0114,
      "step": 67900
    },
    {
      "epoch": 2.4285714285714284,
      "grad_norm": 0.10322686284780502,
      "learning_rate": 3.482744765391312e-05,
      "loss": 0.0121,
      "step": 68000
    },
    {
      "epoch": 2.432142857142857,
      "grad_norm": 0.03264196589589119,
      "learning_rate": 3.480512522880486e-05,
      "loss": 0.0116,
      "step": 68100
    },
    {
      "epoch": 2.435714285714286,
      "grad_norm": 0.05525267496705055,
      "learning_rate": 3.4782802803696594e-05,
      "loss": 0.0113,
      "step": 68200
    },
    {
      "epoch": 2.439285714285714,
      "grad_norm": 0.05164681002497673,
      "learning_rate": 3.4760480378588334e-05,
      "loss": 0.0131,
      "step": 68300
    },
    {
      "epoch": 2.442857142857143,
      "grad_norm": 0.03408181667327881,
      "learning_rate": 3.473815795348007e-05,
      "loss": 0.011,
      "step": 68400
    },
    {
      "epoch": 2.4464285714285716,
      "grad_norm": 0.05860309302806854,
      "learning_rate": 3.471583552837181e-05,
      "loss": 0.0116,
      "step": 68500
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.039540886878967285,
      "learning_rate": 3.469351310326354e-05,
      "loss": 0.0122,
      "step": 68600
    },
    {
      "epoch": 2.4535714285714287,
      "grad_norm": 0.03591962903738022,
      "learning_rate": 3.467119067815527e-05,
      "loss": 0.012,
      "step": 68700
    },
    {
      "epoch": 2.4571428571428573,
      "grad_norm": 0.05271061509847641,
      "learning_rate": 3.464886825304701e-05,
      "loss": 0.0107,
      "step": 68800
    },
    {
      "epoch": 2.460714285714286,
      "grad_norm": 0.05829276144504547,
      "learning_rate": 3.462654582793875e-05,
      "loss": 0.0112,
      "step": 68900
    },
    {
      "epoch": 2.4642857142857144,
      "grad_norm": 0.05518759414553642,
      "learning_rate": 3.4604223402830485e-05,
      "loss": 0.0124,
      "step": 69000
    },
    {
      "epoch": 2.467857142857143,
      "grad_norm": 0.031746361404657364,
      "learning_rate": 3.458190097772222e-05,
      "loss": 0.0101,
      "step": 69100
    },
    {
      "epoch": 2.4714285714285715,
      "grad_norm": 0.02653409354388714,
      "learning_rate": 3.455957855261396e-05,
      "loss": 0.0117,
      "step": 69200
    },
    {
      "epoch": 2.475,
      "grad_norm": 0.053853243589401245,
      "learning_rate": 3.45372561275057e-05,
      "loss": 0.0116,
      "step": 69300
    },
    {
      "epoch": 2.4785714285714286,
      "grad_norm": 0.05622580274939537,
      "learning_rate": 3.451493370239743e-05,
      "loss": 0.0116,
      "step": 69400
    },
    {
      "epoch": 2.482142857142857,
      "grad_norm": 0.036105938255786896,
      "learning_rate": 3.4492611277289164e-05,
      "loss": 0.0115,
      "step": 69500
    },
    {
      "epoch": 2.4857142857142858,
      "grad_norm": 0.04926472157239914,
      "learning_rate": 3.44702888521809e-05,
      "loss": 0.0119,
      "step": 69600
    },
    {
      "epoch": 2.4892857142857143,
      "grad_norm": 0.03590511158108711,
      "learning_rate": 3.4447966427072636e-05,
      "loss": 0.011,
      "step": 69700
    },
    {
      "epoch": 2.492857142857143,
      "grad_norm": 0.050432238727808,
      "learning_rate": 3.4425644001964376e-05,
      "loss": 0.0115,
      "step": 69800
    },
    {
      "epoch": 2.4964285714285714,
      "grad_norm": 0.043642107397317886,
      "learning_rate": 3.440332157685611e-05,
      "loss": 0.0118,
      "step": 69900
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.02944433130323887,
      "learning_rate": 3.438099915174785e-05,
      "loss": 0.0119,
      "step": 70000
    },
    {
      "epoch": 2.5035714285714286,
      "grad_norm": 0.046009887009859085,
      "learning_rate": 3.435867672663958e-05,
      "loss": 0.0121,
      "step": 70100
    },
    {
      "epoch": 2.507142857142857,
      "grad_norm": 0.042834702879190445,
      "learning_rate": 3.433635430153132e-05,
      "loss": 0.011,
      "step": 70200
    },
    {
      "epoch": 2.5107142857142857,
      "grad_norm": 0.025696000084280968,
      "learning_rate": 3.431403187642306e-05,
      "loss": 0.0108,
      "step": 70300
    },
    {
      "epoch": 2.5142857142857142,
      "grad_norm": 0.03634769096970558,
      "learning_rate": 3.429170945131479e-05,
      "loss": 0.0118,
      "step": 70400
    },
    {
      "epoch": 2.517857142857143,
      "grad_norm": 0.03469894081354141,
      "learning_rate": 3.426938702620653e-05,
      "loss": 0.0113,
      "step": 70500
    },
    {
      "epoch": 2.5214285714285714,
      "grad_norm": 0.05610901862382889,
      "learning_rate": 3.424706460109827e-05,
      "loss": 0.0116,
      "step": 70600
    },
    {
      "epoch": 2.525,
      "grad_norm": 0.047401633113622665,
      "learning_rate": 3.422496540024108e-05,
      "loss": 0.012,
      "step": 70700
    },
    {
      "epoch": 2.5285714285714285,
      "grad_norm": 0.041435424238443375,
      "learning_rate": 3.420264297513282e-05,
      "loss": 0.0109,
      "step": 70800
    },
    {
      "epoch": 2.532142857142857,
      "grad_norm": 0.05495315045118332,
      "learning_rate": 3.418032055002456e-05,
      "loss": 0.0115,
      "step": 70900
    },
    {
      "epoch": 2.5357142857142856,
      "grad_norm": 0.04214420169591904,
      "learning_rate": 3.4158221349167376e-05,
      "loss": 0.0103,
      "step": 71000
    },
    {
      "epoch": 2.539285714285714,
      "grad_norm": 0.05352845415472984,
      "learning_rate": 3.413589892405911e-05,
      "loss": 0.0111,
      "step": 71100
    },
    {
      "epoch": 2.5428571428571427,
      "grad_norm": 0.060339923948049545,
      "learning_rate": 3.411357649895085e-05,
      "loss": 0.0118,
      "step": 71200
    },
    {
      "epoch": 2.5464285714285713,
      "grad_norm": 0.020461605861783028,
      "learning_rate": 3.409125407384258e-05,
      "loss": 0.0117,
      "step": 71300
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.029396336525678635,
      "learning_rate": 3.406893164873432e-05,
      "loss": 0.011,
      "step": 71400
    },
    {
      "epoch": 2.553571428571429,
      "grad_norm": 0.04934822395443916,
      "learning_rate": 3.404660922362606e-05,
      "loss": 0.0117,
      "step": 71500
    },
    {
      "epoch": 2.557142857142857,
      "grad_norm": 0.09949489682912827,
      "learning_rate": 3.402428679851779e-05,
      "loss": 0.0117,
      "step": 71600
    },
    {
      "epoch": 2.560714285714286,
      "grad_norm": 0.03423207253217697,
      "learning_rate": 3.400196437340953e-05,
      "loss": 0.0116,
      "step": 71700
    },
    {
      "epoch": 2.564285714285714,
      "grad_norm": 0.03822922706604004,
      "learning_rate": 3.397964194830127e-05,
      "loss": 0.0112,
      "step": 71800
    },
    {
      "epoch": 2.567857142857143,
      "grad_norm": 0.02589467167854309,
      "learning_rate": 3.3957319523193e-05,
      "loss": 0.0116,
      "step": 71900
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 0.04403116926550865,
      "learning_rate": 3.393499709808474e-05,
      "loss": 0.0114,
      "step": 72000
    },
    {
      "epoch": 2.575,
      "grad_norm": 0.04243721440434456,
      "learning_rate": 3.391267467297647e-05,
      "loss": 0.0118,
      "step": 72100
    },
    {
      "epoch": 2.5785714285714287,
      "grad_norm": 0.03811337798833847,
      "learning_rate": 3.389035224786821e-05,
      "loss": 0.0115,
      "step": 72200
    },
    {
      "epoch": 2.5821428571428573,
      "grad_norm": 0.02256792224943638,
      "learning_rate": 3.3868029822759945e-05,
      "loss": 0.0105,
      "step": 72300
    },
    {
      "epoch": 2.585714285714286,
      "grad_norm": 0.07528834044933319,
      "learning_rate": 3.3845707397651685e-05,
      "loss": 0.0112,
      "step": 72400
    },
    {
      "epoch": 2.5892857142857144,
      "grad_norm": 0.03783903643488884,
      "learning_rate": 3.382338497254342e-05,
      "loss": 0.0113,
      "step": 72500
    },
    {
      "epoch": 2.592857142857143,
      "grad_norm": 0.035856492817401886,
      "learning_rate": 3.380106254743515e-05,
      "loss": 0.0109,
      "step": 72600
    },
    {
      "epoch": 2.5964285714285715,
      "grad_norm": 0.0815909281373024,
      "learning_rate": 3.377874012232689e-05,
      "loss": 0.0107,
      "step": 72700
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.049503445625305176,
      "learning_rate": 3.375641769721863e-05,
      "loss": 0.0116,
      "step": 72800
    },
    {
      "epoch": 2.6035714285714286,
      "grad_norm": 0.04288579151034355,
      "learning_rate": 3.3734095272110363e-05,
      "loss": 0.0111,
      "step": 72900
    },
    {
      "epoch": 2.607142857142857,
      "grad_norm": 0.05681615322828293,
      "learning_rate": 3.3711772847002096e-05,
      "loss": 0.0112,
      "step": 73000
    },
    {
      "epoch": 2.6107142857142858,
      "grad_norm": 0.05273529887199402,
      "learning_rate": 3.3689450421893836e-05,
      "loss": 0.0117,
      "step": 73100
    },
    {
      "epoch": 2.6142857142857143,
      "grad_norm": 0.05746331438422203,
      "learning_rate": 3.3667127996785576e-05,
      "loss": 0.0109,
      "step": 73200
    },
    {
      "epoch": 2.617857142857143,
      "grad_norm": 0.046984780579805374,
      "learning_rate": 3.364480557167731e-05,
      "loss": 0.0111,
      "step": 73300
    },
    {
      "epoch": 2.6214285714285714,
      "grad_norm": 0.03109307773411274,
      "learning_rate": 3.362248314656904e-05,
      "loss": 0.0123,
      "step": 73400
    },
    {
      "epoch": 2.625,
      "grad_norm": 0.03561633080244064,
      "learning_rate": 3.360016072146078e-05,
      "loss": 0.0109,
      "step": 73500
    },
    {
      "epoch": 2.6285714285714286,
      "grad_norm": 0.057420846074819565,
      "learning_rate": 3.3577838296352515e-05,
      "loss": 0.0122,
      "step": 73600
    },
    {
      "epoch": 2.632142857142857,
      "grad_norm": 0.03582911193370819,
      "learning_rate": 3.3555515871244254e-05,
      "loss": 0.0103,
      "step": 73700
    },
    {
      "epoch": 2.6357142857142857,
      "grad_norm": 0.07015491276979446,
      "learning_rate": 3.3533193446135994e-05,
      "loss": 0.0112,
      "step": 73800
    },
    {
      "epoch": 2.6392857142857142,
      "grad_norm": 0.06159522011876106,
      "learning_rate": 3.351087102102773e-05,
      "loss": 0.0119,
      "step": 73900
    },
    {
      "epoch": 2.642857142857143,
      "grad_norm": 0.030170829966664314,
      "learning_rate": 3.348854859591946e-05,
      "loss": 0.0119,
      "step": 74000
    },
    {
      "epoch": 2.6464285714285714,
      "grad_norm": 0.045445673167705536,
      "learning_rate": 3.34662261708112e-05,
      "loss": 0.0116,
      "step": 74100
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.07280046492815018,
      "learning_rate": 3.3444126969954014e-05,
      "loss": 0.0119,
      "step": 74200
    },
    {
      "epoch": 2.6535714285714285,
      "grad_norm": 0.06653501838445663,
      "learning_rate": 3.3421804544845754e-05,
      "loss": 0.0105,
      "step": 74300
    },
    {
      "epoch": 2.657142857142857,
      "grad_norm": 0.05761482194066048,
      "learning_rate": 3.3399482119737494e-05,
      "loss": 0.0114,
      "step": 74400
    },
    {
      "epoch": 2.6607142857142856,
      "grad_norm": 0.0667508915066719,
      "learning_rate": 3.337715969462923e-05,
      "loss": 0.012,
      "step": 74500
    },
    {
      "epoch": 2.664285714285714,
      "grad_norm": 0.07596644759178162,
      "learning_rate": 3.335483726952096e-05,
      "loss": 0.0115,
      "step": 74600
    },
    {
      "epoch": 2.6678571428571427,
      "grad_norm": 0.02313130535185337,
      "learning_rate": 3.33325148444127e-05,
      "loss": 0.0118,
      "step": 74700
    },
    {
      "epoch": 2.6714285714285713,
      "grad_norm": 0.055444978177547455,
      "learning_rate": 3.331019241930444e-05,
      "loss": 0.0119,
      "step": 74800
    },
    {
      "epoch": 2.675,
      "grad_norm": 0.052710700780153275,
      "learning_rate": 3.328786999419617e-05,
      "loss": 0.0105,
      "step": 74900
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 0.043551187962293625,
      "learning_rate": 3.3265547569087905e-05,
      "loss": 0.0117,
      "step": 75000
    },
    {
      "epoch": 2.682142857142857,
      "grad_norm": 0.05509265884757042,
      "learning_rate": 3.3243225143979645e-05,
      "loss": 0.0112,
      "step": 75100
    },
    {
      "epoch": 2.685714285714286,
      "grad_norm": 0.08416257053613663,
      "learning_rate": 3.322090271887138e-05,
      "loss": 0.0115,
      "step": 75200
    },
    {
      "epoch": 2.689285714285714,
      "grad_norm": 0.0294705368578434,
      "learning_rate": 3.319858029376312e-05,
      "loss": 0.0114,
      "step": 75300
    },
    {
      "epoch": 2.692857142857143,
      "grad_norm": 0.04309344291687012,
      "learning_rate": 3.317625786865485e-05,
      "loss": 0.0111,
      "step": 75400
    },
    {
      "epoch": 2.696428571428571,
      "grad_norm": 0.06562978774309158,
      "learning_rate": 3.315393544354659e-05,
      "loss": 0.0114,
      "step": 75500
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.05599016696214676,
      "learning_rate": 3.3131613018438324e-05,
      "loss": 0.0109,
      "step": 75600
    },
    {
      "epoch": 2.7035714285714287,
      "grad_norm": 0.051275499165058136,
      "learning_rate": 3.310929059333006e-05,
      "loss": 0.0103,
      "step": 75700
    },
    {
      "epoch": 2.7071428571428573,
      "grad_norm": 0.030346190556883812,
      "learning_rate": 3.3086968168221796e-05,
      "loss": 0.0111,
      "step": 75800
    },
    {
      "epoch": 2.710714285714286,
      "grad_norm": 0.08489793539047241,
      "learning_rate": 3.306464574311353e-05,
      "loss": 0.0111,
      "step": 75900
    },
    {
      "epoch": 2.7142857142857144,
      "grad_norm": 0.056613147258758545,
      "learning_rate": 3.304232331800527e-05,
      "loss": 0.0113,
      "step": 76000
    },
    {
      "epoch": 2.717857142857143,
      "grad_norm": 0.055798061192035675,
      "learning_rate": 3.302000089289701e-05,
      "loss": 0.0102,
      "step": 76100
    },
    {
      "epoch": 2.7214285714285715,
      "grad_norm": 0.05553612858057022,
      "learning_rate": 3.299767846778874e-05,
      "loss": 0.0115,
      "step": 76200
    },
    {
      "epoch": 2.725,
      "grad_norm": 0.07886793464422226,
      "learning_rate": 3.2975356042680475e-05,
      "loss": 0.011,
      "step": 76300
    },
    {
      "epoch": 2.7285714285714286,
      "grad_norm": 0.0478518009185791,
      "learning_rate": 3.2953033617572215e-05,
      "loss": 0.0107,
      "step": 76400
    },
    {
      "epoch": 2.732142857142857,
      "grad_norm": 0.049936629831790924,
      "learning_rate": 3.2930711192463954e-05,
      "loss": 0.0119,
      "step": 76500
    },
    {
      "epoch": 2.7357142857142858,
      "grad_norm": 0.050732824951410294,
      "learning_rate": 3.290838876735569e-05,
      "loss": 0.0109,
      "step": 76600
    },
    {
      "epoch": 2.7392857142857143,
      "grad_norm": 0.06809360533952713,
      "learning_rate": 3.288606634224742e-05,
      "loss": 0.0116,
      "step": 76700
    },
    {
      "epoch": 2.742857142857143,
      "grad_norm": 0.029729332774877548,
      "learning_rate": 3.286374391713916e-05,
      "loss": 0.0107,
      "step": 76800
    },
    {
      "epoch": 2.7464285714285714,
      "grad_norm": 0.05444511026144028,
      "learning_rate": 3.284142149203089e-05,
      "loss": 0.0117,
      "step": 76900
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.043240129947662354,
      "learning_rate": 3.281909906692263e-05,
      "loss": 0.0111,
      "step": 77000
    },
    {
      "epoch": 2.7535714285714286,
      "grad_norm": 0.06688830256462097,
      "learning_rate": 3.279677664181437e-05,
      "loss": 0.0121,
      "step": 77100
    },
    {
      "epoch": 2.757142857142857,
      "grad_norm": 0.04658425971865654,
      "learning_rate": 3.27744542167061e-05,
      "loss": 0.0109,
      "step": 77200
    },
    {
      "epoch": 2.7607142857142857,
      "grad_norm": 0.04690004885196686,
      "learning_rate": 3.275213179159784e-05,
      "loss": 0.0113,
      "step": 77300
    },
    {
      "epoch": 2.7642857142857142,
      "grad_norm": 0.038177844136953354,
      "learning_rate": 3.272980936648958e-05,
      "loss": 0.0113,
      "step": 77400
    },
    {
      "epoch": 2.767857142857143,
      "grad_norm": 0.0586845837533474,
      "learning_rate": 3.270748694138132e-05,
      "loss": 0.0104,
      "step": 77500
    },
    {
      "epoch": 2.7714285714285714,
      "grad_norm": 0.04758647084236145,
      "learning_rate": 3.268516451627305e-05,
      "loss": 0.0108,
      "step": 77600
    },
    {
      "epoch": 2.775,
      "grad_norm": 0.0731603130698204,
      "learning_rate": 3.2662842091164784e-05,
      "loss": 0.0113,
      "step": 77700
    },
    {
      "epoch": 2.7785714285714285,
      "grad_norm": 0.04332106560468674,
      "learning_rate": 3.2640519666056524e-05,
      "loss": 0.0108,
      "step": 77800
    },
    {
      "epoch": 2.782142857142857,
      "grad_norm": 0.03343648836016655,
      "learning_rate": 3.2618197240948257e-05,
      "loss": 0.0112,
      "step": 77900
    },
    {
      "epoch": 2.7857142857142856,
      "grad_norm": 0.045421551913022995,
      "learning_rate": 3.2595874815839996e-05,
      "loss": 0.0103,
      "step": 78000
    },
    {
      "epoch": 2.789285714285714,
      "grad_norm": 0.029001716524362564,
      "learning_rate": 3.257355239073173e-05,
      "loss": 0.0099,
      "step": 78100
    },
    {
      "epoch": 2.7928571428571427,
      "grad_norm": 0.036640364676713943,
      "learning_rate": 3.255122996562346e-05,
      "loss": 0.0116,
      "step": 78200
    },
    {
      "epoch": 2.7964285714285713,
      "grad_norm": 0.05855223163962364,
      "learning_rate": 3.25289075405152e-05,
      "loss": 0.0113,
      "step": 78300
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.056604690849781036,
      "learning_rate": 3.250658511540694e-05,
      "loss": 0.0106,
      "step": 78400
    },
    {
      "epoch": 2.803571428571429,
      "grad_norm": 0.05227674916386604,
      "learning_rate": 3.2484262690298675e-05,
      "loss": 0.01,
      "step": 78500
    },
    {
      "epoch": 2.807142857142857,
      "grad_norm": 0.11006846278905869,
      "learning_rate": 3.246194026519041e-05,
      "loss": 0.0118,
      "step": 78600
    },
    {
      "epoch": 2.810714285714286,
      "grad_norm": 0.09574660658836365,
      "learning_rate": 3.243984106433323e-05,
      "loss": 0.0108,
      "step": 78700
    },
    {
      "epoch": 2.814285714285714,
      "grad_norm": 0.060262374579906464,
      "learning_rate": 3.241751863922497e-05,
      "loss": 0.0119,
      "step": 78800
    },
    {
      "epoch": 2.817857142857143,
      "grad_norm": 0.08944173902273178,
      "learning_rate": 3.23951962141167e-05,
      "loss": 0.0112,
      "step": 78900
    },
    {
      "epoch": 2.821428571428571,
      "grad_norm": 0.05473598465323448,
      "learning_rate": 3.237287378900844e-05,
      "loss": 0.0105,
      "step": 79000
    },
    {
      "epoch": 2.825,
      "grad_norm": 0.02891603857278824,
      "learning_rate": 3.2350551363900175e-05,
      "loss": 0.0116,
      "step": 79100
    },
    {
      "epoch": 2.8285714285714287,
      "grad_norm": 0.03828886151313782,
      "learning_rate": 3.232822893879191e-05,
      "loss": 0.0105,
      "step": 79200
    },
    {
      "epoch": 2.8321428571428573,
      "grad_norm": 0.03026266023516655,
      "learning_rate": 3.230590651368365e-05,
      "loss": 0.0108,
      "step": 79300
    },
    {
      "epoch": 2.835714285714286,
      "grad_norm": 0.029193228110671043,
      "learning_rate": 3.228358408857539e-05,
      "loss": 0.0113,
      "step": 79400
    },
    {
      "epoch": 2.8392857142857144,
      "grad_norm": 0.02833101525902748,
      "learning_rate": 3.226126166346712e-05,
      "loss": 0.0115,
      "step": 79500
    },
    {
      "epoch": 2.842857142857143,
      "grad_norm": 0.0711713656783104,
      "learning_rate": 3.223893923835885e-05,
      "loss": 0.0115,
      "step": 79600
    },
    {
      "epoch": 2.8464285714285715,
      "grad_norm": 0.019110577180981636,
      "learning_rate": 3.221661681325059e-05,
      "loss": 0.0104,
      "step": 79700
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.04728327691555023,
      "learning_rate": 3.219429438814233e-05,
      "loss": 0.0115,
      "step": 79800
    },
    {
      "epoch": 2.8535714285714286,
      "grad_norm": 0.02145206928253174,
      "learning_rate": 3.2171971963034066e-05,
      "loss": 0.0105,
      "step": 79900
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.06082352623343468,
      "learning_rate": 3.2149649537925805e-05,
      "loss": 0.0108,
      "step": 80000
    },
    {
      "epoch": 2.8607142857142858,
      "grad_norm": 0.04872925207018852,
      "learning_rate": 3.212732711281754e-05,
      "loss": 0.0119,
      "step": 80100
    },
    {
      "epoch": 2.8642857142857143,
      "grad_norm": 0.05544055998325348,
      "learning_rate": 3.210500468770927e-05,
      "loss": 0.0114,
      "step": 80200
    },
    {
      "epoch": 2.867857142857143,
      "grad_norm": 0.039828747510910034,
      "learning_rate": 3.208268226260101e-05,
      "loss": 0.0112,
      "step": 80300
    },
    {
      "epoch": 2.8714285714285714,
      "grad_norm": 0.03900111839175224,
      "learning_rate": 3.206035983749275e-05,
      "loss": 0.0107,
      "step": 80400
    },
    {
      "epoch": 2.875,
      "grad_norm": 0.05657806620001793,
      "learning_rate": 3.2038037412384484e-05,
      "loss": 0.0109,
      "step": 80500
    },
    {
      "epoch": 2.8785714285714286,
      "grad_norm": 0.04818575829267502,
      "learning_rate": 3.201571498727622e-05,
      "loss": 0.0108,
      "step": 80600
    },
    {
      "epoch": 2.882142857142857,
      "grad_norm": 0.03906846046447754,
      "learning_rate": 3.1993392562167957e-05,
      "loss": 0.0106,
      "step": 80700
    },
    {
      "epoch": 2.8857142857142857,
      "grad_norm": 0.05094781145453453,
      "learning_rate": 3.1971070137059696e-05,
      "loss": 0.0108,
      "step": 80800
    },
    {
      "epoch": 2.8892857142857142,
      "grad_norm": 0.03548441827297211,
      "learning_rate": 3.194874771195143e-05,
      "loss": 0.0111,
      "step": 80900
    },
    {
      "epoch": 2.892857142857143,
      "grad_norm": 0.044832125306129456,
      "learning_rate": 3.192642528684316e-05,
      "loss": 0.0106,
      "step": 81000
    },
    {
      "epoch": 2.8964285714285714,
      "grad_norm": 0.03845597058534622,
      "learning_rate": 3.19041028617349e-05,
      "loss": 0.0107,
      "step": 81100
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.06098533421754837,
      "learning_rate": 3.188200366087772e-05,
      "loss": 0.0112,
      "step": 81200
    },
    {
      "epoch": 2.9035714285714285,
      "grad_norm": 0.06647566705942154,
      "learning_rate": 3.1859681235769456e-05,
      "loss": 0.0113,
      "step": 81300
    },
    {
      "epoch": 2.907142857142857,
      "grad_norm": 0.04009908810257912,
      "learning_rate": 3.1837358810661196e-05,
      "loss": 0.0109,
      "step": 81400
    },
    {
      "epoch": 2.9107142857142856,
      "grad_norm": 0.05320777744054794,
      "learning_rate": 3.181503638555293e-05,
      "loss": 0.0109,
      "step": 81500
    },
    {
      "epoch": 2.914285714285714,
      "grad_norm": 0.031091459095478058,
      "learning_rate": 3.179271396044466e-05,
      "loss": 0.0113,
      "step": 81600
    },
    {
      "epoch": 2.9178571428571427,
      "grad_norm": 0.022560780867934227,
      "learning_rate": 3.17703915353364e-05,
      "loss": 0.0112,
      "step": 81700
    },
    {
      "epoch": 2.9214285714285713,
      "grad_norm": 0.04780444875359535,
      "learning_rate": 3.1748069110228135e-05,
      "loss": 0.0114,
      "step": 81800
    },
    {
      "epoch": 2.925,
      "grad_norm": 0.06275850534439087,
      "learning_rate": 3.1725746685119875e-05,
      "loss": 0.0113,
      "step": 81900
    },
    {
      "epoch": 2.928571428571429,
      "grad_norm": 0.0792418047785759,
      "learning_rate": 3.170342426001161e-05,
      "loss": 0.0113,
      "step": 82000
    },
    {
      "epoch": 2.932142857142857,
      "grad_norm": 0.05461742356419563,
      "learning_rate": 3.168110183490334e-05,
      "loss": 0.0105,
      "step": 82100
    },
    {
      "epoch": 2.935714285714286,
      "grad_norm": 0.04016923904418945,
      "learning_rate": 3.165877940979508e-05,
      "loss": 0.011,
      "step": 82200
    },
    {
      "epoch": 2.939285714285714,
      "grad_norm": 0.05134567245841026,
      "learning_rate": 3.163645698468682e-05,
      "loss": 0.0109,
      "step": 82300
    },
    {
      "epoch": 2.942857142857143,
      "grad_norm": 0.07656464725732803,
      "learning_rate": 3.161413455957856e-05,
      "loss": 0.011,
      "step": 82400
    },
    {
      "epoch": 2.946428571428571,
      "grad_norm": 0.04292411729693413,
      "learning_rate": 3.1591812134470286e-05,
      "loss": 0.0113,
      "step": 82500
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.0418730154633522,
      "learning_rate": 3.1569489709362026e-05,
      "loss": 0.0112,
      "step": 82600
    },
    {
      "epoch": 2.9535714285714287,
      "grad_norm": 0.05013249069452286,
      "learning_rate": 3.1547167284253766e-05,
      "loss": 0.0108,
      "step": 82700
    },
    {
      "epoch": 2.9571428571428573,
      "grad_norm": 0.049887195229530334,
      "learning_rate": 3.15248448591455e-05,
      "loss": 0.0097,
      "step": 82800
    },
    {
      "epoch": 2.960714285714286,
      "grad_norm": 0.0811387300491333,
      "learning_rate": 3.150252243403723e-05,
      "loss": 0.0112,
      "step": 82900
    },
    {
      "epoch": 2.9642857142857144,
      "grad_norm": 0.050845883786678314,
      "learning_rate": 3.148020000892897e-05,
      "loss": 0.011,
      "step": 83000
    },
    {
      "epoch": 2.967857142857143,
      "grad_norm": 0.05254856124520302,
      "learning_rate": 3.1457877583820704e-05,
      "loss": 0.0105,
      "step": 83100
    },
    {
      "epoch": 2.9714285714285715,
      "grad_norm": 0.07257677614688873,
      "learning_rate": 3.1435555158712444e-05,
      "loss": 0.0112,
      "step": 83200
    },
    {
      "epoch": 2.975,
      "grad_norm": 0.039022158831357956,
      "learning_rate": 3.1413232733604184e-05,
      "loss": 0.0102,
      "step": 83300
    },
    {
      "epoch": 2.9785714285714286,
      "grad_norm": 0.049221791326999664,
      "learning_rate": 3.139091030849592e-05,
      "loss": 0.0107,
      "step": 83400
    },
    {
      "epoch": 2.982142857142857,
      "grad_norm": 0.0277657900005579,
      "learning_rate": 3.136858788338765e-05,
      "loss": 0.0102,
      "step": 83500
    },
    {
      "epoch": 2.9857142857142858,
      "grad_norm": 0.061073046177625656,
      "learning_rate": 3.134626545827939e-05,
      "loss": 0.0109,
      "step": 83600
    },
    {
      "epoch": 2.9892857142857143,
      "grad_norm": 0.07386547327041626,
      "learning_rate": 3.132416625742221e-05,
      "loss": 0.0111,
      "step": 83700
    },
    {
      "epoch": 2.992857142857143,
      "grad_norm": 0.04349859431385994,
      "learning_rate": 3.1301843832313944e-05,
      "loss": 0.0114,
      "step": 83800
    },
    {
      "epoch": 2.9964285714285714,
      "grad_norm": 0.05264179781079292,
      "learning_rate": 3.1279521407205684e-05,
      "loss": 0.0108,
      "step": 83900
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.04122820496559143,
      "learning_rate": 3.125719898209742e-05,
      "loss": 0.0102,
      "step": 84000
    },
    {
      "epoch": 3.0,
      "eval_accuracy_macro_0.5": 0.9959058165550232,
      "eval_accuracy_micro_0.5": 0.9959058165550232,
      "eval_accuracy_weighted_0.5": 0.990726113319397,
      "eval_aucroc_macro": 0.7516735792160034,
      "eval_aucroc_micro": 0.8270954489707947,
      "eval_aucroc_weighted": 0.8252253532409668,
      "eval_f1_macro_0.5": 0.2762102484703064,
      "eval_f1_macro_0.6": 0.21123698353767395,
      "eval_f1_macro_0.7": 0.15309913456439972,
      "eval_f1_macro_0.8": 0.03688640519976616,
      "eval_f1_micro_0.5": 0.5038543343544006,
      "eval_f1_micro_0.6": 0.42129960656166077,
      "eval_f1_micro_0.7": 0.32352250814437866,
      "eval_f1_micro_0.8": 0.20129014551639557,
      "eval_f1_micro_0.9": 0.0774727612733841,
      "eval_f1_weighted_0.5": 0.41893014311790466,
      "eval_f1_weighted_0.6": 0.3346352279186249,
      "eval_f1_weighted_0.7": 0.2515681982040405,
      "eval_f1_weighted_0.8": 0.06095576658844948,
      "eval_loss": 0.009481274522840977,
      "eval_runtime": 1358.7711,
      "eval_samples_per_second": 40.963,
      "eval_steps_per_second": 5.121,
      "step": 84000
    },
    {
      "epoch": 3.0035714285714286,
      "grad_norm": 0.04268069565296173,
      "learning_rate": 3.123487655698915e-05,
      "loss": 0.0105,
      "step": 84100
    },
    {
      "epoch": 3.007142857142857,
      "grad_norm": 0.03929920867085457,
      "learning_rate": 3.121255413188089e-05,
      "loss": 0.0101,
      "step": 84200
    },
    {
      "epoch": 3.0107142857142857,
      "grad_norm": 0.025872081518173218,
      "learning_rate": 3.119023170677263e-05,
      "loss": 0.0109,
      "step": 84300
    },
    {
      "epoch": 3.0142857142857142,
      "grad_norm": 0.033158913254737854,
      "learning_rate": 3.116790928166436e-05,
      "loss": 0.0118,
      "step": 84400
    },
    {
      "epoch": 3.017857142857143,
      "grad_norm": 0.02633681148290634,
      "learning_rate": 3.1145586856556095e-05,
      "loss": 0.0107,
      "step": 84500
    },
    {
      "epoch": 3.0214285714285714,
      "grad_norm": 0.03280484303832054,
      "learning_rate": 3.1123264431447835e-05,
      "loss": 0.0114,
      "step": 84600
    },
    {
      "epoch": 3.025,
      "grad_norm": 0.05930010601878166,
      "learning_rate": 3.1100942006339575e-05,
      "loss": 0.0109,
      "step": 84700
    },
    {
      "epoch": 3.0285714285714285,
      "grad_norm": 0.05941011756658554,
      "learning_rate": 3.107861958123131e-05,
      "loss": 0.0116,
      "step": 84800
    },
    {
      "epoch": 3.032142857142857,
      "grad_norm": 0.029414083808660507,
      "learning_rate": 3.105629715612304e-05,
      "loss": 0.0111,
      "step": 84900
    },
    {
      "epoch": 3.0357142857142856,
      "grad_norm": 0.06062637269496918,
      "learning_rate": 3.103397473101478e-05,
      "loss": 0.0108,
      "step": 85000
    },
    {
      "epoch": 3.039285714285714,
      "grad_norm": 0.052830733358860016,
      "learning_rate": 3.101165230590651e-05,
      "loss": 0.0106,
      "step": 85100
    },
    {
      "epoch": 3.0428571428571427,
      "grad_norm": 0.04294675588607788,
      "learning_rate": 3.098932988079825e-05,
      "loss": 0.0099,
      "step": 85200
    },
    {
      "epoch": 3.0464285714285713,
      "grad_norm": 0.042152538895606995,
      "learning_rate": 3.0967007455689986e-05,
      "loss": 0.0107,
      "step": 85300
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.03595013916492462,
      "learning_rate": 3.094468503058172e-05,
      "loss": 0.0118,
      "step": 85400
    },
    {
      "epoch": 3.0535714285714284,
      "grad_norm": 0.03622603416442871,
      "learning_rate": 3.092258582972454e-05,
      "loss": 0.0101,
      "step": 85500
    },
    {
      "epoch": 3.057142857142857,
      "grad_norm": 0.03180573135614395,
      "learning_rate": 3.090026340461628e-05,
      "loss": 0.0103,
      "step": 85600
    },
    {
      "epoch": 3.0607142857142855,
      "grad_norm": 0.02809412032365799,
      "learning_rate": 3.087794097950801e-05,
      "loss": 0.011,
      "step": 85700
    },
    {
      "epoch": 3.064285714285714,
      "grad_norm": 0.03971981629729271,
      "learning_rate": 3.085561855439975e-05,
      "loss": 0.0112,
      "step": 85800
    },
    {
      "epoch": 3.067857142857143,
      "grad_norm": 0.05475136265158653,
      "learning_rate": 3.0833296129291486e-05,
      "loss": 0.0105,
      "step": 85900
    },
    {
      "epoch": 3.0714285714285716,
      "grad_norm": 0.048770491033792496,
      "learning_rate": 3.081097370418322e-05,
      "loss": 0.0104,
      "step": 86000
    },
    {
      "epoch": 3.075,
      "grad_norm": 0.045689262449741364,
      "learning_rate": 3.078865127907496e-05,
      "loss": 0.0112,
      "step": 86100
    },
    {
      "epoch": 3.0785714285714287,
      "grad_norm": 0.04590784013271332,
      "learning_rate": 3.07663288539667e-05,
      "loss": 0.0108,
      "step": 86200
    },
    {
      "epoch": 3.0821428571428573,
      "grad_norm": 0.04303855076432228,
      "learning_rate": 3.074400642885844e-05,
      "loss": 0.0109,
      "step": 86300
    },
    {
      "epoch": 3.085714285714286,
      "grad_norm": 0.026422370225191116,
      "learning_rate": 3.0721684003750164e-05,
      "loss": 0.0112,
      "step": 86400
    },
    {
      "epoch": 3.0892857142857144,
      "grad_norm": 0.040363043546676636,
      "learning_rate": 3.0699361578641904e-05,
      "loss": 0.0116,
      "step": 86500
    },
    {
      "epoch": 3.092857142857143,
      "grad_norm": 0.028695885092020035,
      "learning_rate": 3.0677039153533644e-05,
      "loss": 0.0114,
      "step": 86600
    },
    {
      "epoch": 3.0964285714285715,
      "grad_norm": 0.03502947837114334,
      "learning_rate": 3.065471672842538e-05,
      "loss": 0.0105,
      "step": 86700
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.02634342573583126,
      "learning_rate": 3.063239430331712e-05,
      "loss": 0.0111,
      "step": 86800
    },
    {
      "epoch": 3.1035714285714286,
      "grad_norm": 0.044232651591300964,
      "learning_rate": 3.061007187820885e-05,
      "loss": 0.0106,
      "step": 86900
    },
    {
      "epoch": 3.107142857142857,
      "grad_norm": 0.09533174335956573,
      "learning_rate": 3.058774945310058e-05,
      "loss": 0.0107,
      "step": 87000
    },
    {
      "epoch": 3.1107142857142858,
      "grad_norm": 0.05493714287877083,
      "learning_rate": 3.056542702799232e-05,
      "loss": 0.0103,
      "step": 87100
    },
    {
      "epoch": 3.1142857142857143,
      "grad_norm": 0.018983948975801468,
      "learning_rate": 3.054310460288406e-05,
      "loss": 0.0102,
      "step": 87200
    },
    {
      "epoch": 3.117857142857143,
      "grad_norm": 0.0340411476790905,
      "learning_rate": 3.0520782177775795e-05,
      "loss": 0.0109,
      "step": 87300
    },
    {
      "epoch": 3.1214285714285714,
      "grad_norm": 0.045041076838970184,
      "learning_rate": 3.049845975266753e-05,
      "loss": 0.0103,
      "step": 87400
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.07197900861501694,
      "learning_rate": 3.0476137327559268e-05,
      "loss": 0.0105,
      "step": 87500
    },
    {
      "epoch": 3.1285714285714286,
      "grad_norm": 0.04275546967983246,
      "learning_rate": 3.0453814902451004e-05,
      "loss": 0.0112,
      "step": 87600
    },
    {
      "epoch": 3.132142857142857,
      "grad_norm": 0.04527350887656212,
      "learning_rate": 3.0431492477342737e-05,
      "loss": 0.0105,
      "step": 87700
    },
    {
      "epoch": 3.1357142857142857,
      "grad_norm": 0.033082302659749985,
      "learning_rate": 3.0409170052234477e-05,
      "loss": 0.0105,
      "step": 87800
    },
    {
      "epoch": 3.1392857142857142,
      "grad_norm": 0.06616102159023285,
      "learning_rate": 3.0386847627126213e-05,
      "loss": 0.0105,
      "step": 87900
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 0.04623596370220184,
      "learning_rate": 3.0364525202017946e-05,
      "loss": 0.0106,
      "step": 88000
    },
    {
      "epoch": 3.1464285714285714,
      "grad_norm": 0.029507145285606384,
      "learning_rate": 3.0342202776909683e-05,
      "loss": 0.0104,
      "step": 88100
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.04131158068776131,
      "learning_rate": 3.0319880351801422e-05,
      "loss": 0.0102,
      "step": 88200
    },
    {
      "epoch": 3.1535714285714285,
      "grad_norm": 0.03883776813745499,
      "learning_rate": 3.029755792669316e-05,
      "loss": 0.0097,
      "step": 88300
    },
    {
      "epoch": 3.157142857142857,
      "grad_norm": 0.05456976220011711,
      "learning_rate": 3.0275458725835977e-05,
      "loss": 0.011,
      "step": 88400
    },
    {
      "epoch": 3.1607142857142856,
      "grad_norm": 0.02148784138262272,
      "learning_rate": 3.0253136300727713e-05,
      "loss": 0.0107,
      "step": 88500
    },
    {
      "epoch": 3.164285714285714,
      "grad_norm": 0.03925046697258949,
      "learning_rate": 3.0230813875619453e-05,
      "loss": 0.0104,
      "step": 88600
    },
    {
      "epoch": 3.1678571428571427,
      "grad_norm": 0.025224393233656883,
      "learning_rate": 3.0208491450511182e-05,
      "loss": 0.0114,
      "step": 88700
    },
    {
      "epoch": 3.1714285714285713,
      "grad_norm": 0.04078091308474541,
      "learning_rate": 3.0186169025402922e-05,
      "loss": 0.011,
      "step": 88800
    },
    {
      "epoch": 3.175,
      "grad_norm": 0.040005043148994446,
      "learning_rate": 3.016384660029466e-05,
      "loss": 0.0111,
      "step": 88900
    },
    {
      "epoch": 3.1785714285714284,
      "grad_norm": 0.0527791753411293,
      "learning_rate": 3.014152417518639e-05,
      "loss": 0.0118,
      "step": 89000
    },
    {
      "epoch": 3.182142857142857,
      "grad_norm": 0.019878217950463295,
      "learning_rate": 3.011920175007813e-05,
      "loss": 0.0103,
      "step": 89100
    },
    {
      "epoch": 3.185714285714286,
      "grad_norm": 0.07266772538423538,
      "learning_rate": 3.0096879324969868e-05,
      "loss": 0.0105,
      "step": 89200
    },
    {
      "epoch": 3.189285714285714,
      "grad_norm": 0.05223524570465088,
      "learning_rate": 3.00745568998616e-05,
      "loss": 0.0101,
      "step": 89300
    },
    {
      "epoch": 3.192857142857143,
      "grad_norm": 0.01873023435473442,
      "learning_rate": 3.0052234474753337e-05,
      "loss": 0.0095,
      "step": 89400
    },
    {
      "epoch": 3.1964285714285716,
      "grad_norm": 0.042499836534261703,
      "learning_rate": 3.0029912049645077e-05,
      "loss": 0.0107,
      "step": 89500
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.03736044466495514,
      "learning_rate": 3.0007589624536813e-05,
      "loss": 0.01,
      "step": 89600
    },
    {
      "epoch": 3.2035714285714287,
      "grad_norm": 0.06970074027776718,
      "learning_rate": 2.9985267199428546e-05,
      "loss": 0.0114,
      "step": 89700
    },
    {
      "epoch": 3.2071428571428573,
      "grad_norm": 0.03663264214992523,
      "learning_rate": 2.9962944774320283e-05,
      "loss": 0.0103,
      "step": 89800
    },
    {
      "epoch": 3.210714285714286,
      "grad_norm": 0.048554036766290665,
      "learning_rate": 2.9940622349212022e-05,
      "loss": 0.0102,
      "step": 89900
    },
    {
      "epoch": 3.2142857142857144,
      "grad_norm": 0.054115328937768936,
      "learning_rate": 2.9918299924103755e-05,
      "loss": 0.0102,
      "step": 90000
    },
    {
      "epoch": 3.217857142857143,
      "grad_norm": 0.035477414727211,
      "learning_rate": 2.989597749899549e-05,
      "loss": 0.0108,
      "step": 90100
    },
    {
      "epoch": 3.2214285714285715,
      "grad_norm": 0.06273267418146133,
      "learning_rate": 2.987365507388723e-05,
      "loss": 0.0101,
      "step": 90200
    },
    {
      "epoch": 3.225,
      "grad_norm": 0.08952486515045166,
      "learning_rate": 2.985133264877896e-05,
      "loss": 0.0104,
      "step": 90300
    },
    {
      "epoch": 3.2285714285714286,
      "grad_norm": 0.03564079478383064,
      "learning_rate": 2.98290102236707e-05,
      "loss": 0.0106,
      "step": 90400
    },
    {
      "epoch": 3.232142857142857,
      "grad_norm": 0.03134463354945183,
      "learning_rate": 2.9806687798562437e-05,
      "loss": 0.0105,
      "step": 90500
    },
    {
      "epoch": 3.2357142857142858,
      "grad_norm": 0.027876997366547585,
      "learning_rate": 2.9784365373454177e-05,
      "loss": 0.0096,
      "step": 90600
    },
    {
      "epoch": 3.2392857142857143,
      "grad_norm": 0.04653230682015419,
      "learning_rate": 2.976204294834591e-05,
      "loss": 0.0105,
      "step": 90700
    },
    {
      "epoch": 3.242857142857143,
      "grad_norm": 0.04514637961983681,
      "learning_rate": 2.9739720523237646e-05,
      "loss": 0.0099,
      "step": 90800
    },
    {
      "epoch": 3.2464285714285714,
      "grad_norm": 0.060345832258462906,
      "learning_rate": 2.9717398098129386e-05,
      "loss": 0.011,
      "step": 90900
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.03484727442264557,
      "learning_rate": 2.9695075673021116e-05,
      "loss": 0.0101,
      "step": 91000
    },
    {
      "epoch": 3.2535714285714286,
      "grad_norm": 0.06595105677843094,
      "learning_rate": 2.9672753247912855e-05,
      "loss": 0.0102,
      "step": 91100
    },
    {
      "epoch": 3.257142857142857,
      "grad_norm": 0.033320631831884384,
      "learning_rate": 2.965043082280459e-05,
      "loss": 0.0103,
      "step": 91200
    },
    {
      "epoch": 3.2607142857142857,
      "grad_norm": 0.04614589735865593,
      "learning_rate": 2.9628108397696325e-05,
      "loss": 0.0096,
      "step": 91300
    },
    {
      "epoch": 3.2642857142857142,
      "grad_norm": 0.03225366398692131,
      "learning_rate": 2.960578597258806e-05,
      "loss": 0.0107,
      "step": 91400
    },
    {
      "epoch": 3.267857142857143,
      "grad_norm": 0.03913255035877228,
      "learning_rate": 2.95834635474798e-05,
      "loss": 0.0108,
      "step": 91500
    },
    {
      "epoch": 3.2714285714285714,
      "grad_norm": 0.04671141877770424,
      "learning_rate": 2.9561141122371537e-05,
      "loss": 0.0109,
      "step": 91600
    },
    {
      "epoch": 3.275,
      "grad_norm": 0.02912682667374611,
      "learning_rate": 2.953881869726327e-05,
      "loss": 0.0108,
      "step": 91700
    },
    {
      "epoch": 3.2785714285714285,
      "grad_norm": 0.03754647448658943,
      "learning_rate": 2.951649627215501e-05,
      "loss": 0.0095,
      "step": 91800
    },
    {
      "epoch": 3.282142857142857,
      "grad_norm": 0.04981799051165581,
      "learning_rate": 2.9494173847046746e-05,
      "loss": 0.0103,
      "step": 91900
    },
    {
      "epoch": 3.2857142857142856,
      "grad_norm": 0.032743725925683975,
      "learning_rate": 2.947185142193848e-05,
      "loss": 0.0108,
      "step": 92000
    },
    {
      "epoch": 3.289285714285714,
      "grad_norm": 0.03948519006371498,
      "learning_rate": 2.9449528996830216e-05,
      "loss": 0.0103,
      "step": 92100
    },
    {
      "epoch": 3.2928571428571427,
      "grad_norm": 0.06307660043239594,
      "learning_rate": 2.9427206571721955e-05,
      "loss": 0.0101,
      "step": 92200
    },
    {
      "epoch": 3.2964285714285713,
      "grad_norm": 0.04768649488687515,
      "learning_rate": 2.9404884146613688e-05,
      "loss": 0.0097,
      "step": 92300
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.06767535954713821,
      "learning_rate": 2.9382561721505425e-05,
      "loss": 0.0099,
      "step": 92400
    },
    {
      "epoch": 3.3035714285714284,
      "grad_norm": 0.042051441967487335,
      "learning_rate": 2.9360239296397164e-05,
      "loss": 0.0102,
      "step": 92500
    },
    {
      "epoch": 3.307142857142857,
      "grad_norm": 0.03881387785077095,
      "learning_rate": 2.93379168712889e-05,
      "loss": 0.0104,
      "step": 92600
    },
    {
      "epoch": 3.310714285714286,
      "grad_norm": 0.018820691853761673,
      "learning_rate": 2.9315594446180634e-05,
      "loss": 0.0101,
      "step": 92700
    },
    {
      "epoch": 3.314285714285714,
      "grad_norm": 0.05217605456709862,
      "learning_rate": 2.929327202107237e-05,
      "loss": 0.0102,
      "step": 92800
    },
    {
      "epoch": 3.317857142857143,
      "grad_norm": 0.050333619117736816,
      "learning_rate": 2.927094959596411e-05,
      "loss": 0.0106,
      "step": 92900
    },
    {
      "epoch": 3.3214285714285716,
      "grad_norm": 0.051430217921733856,
      "learning_rate": 2.9248627170855843e-05,
      "loss": 0.0102,
      "step": 93000
    },
    {
      "epoch": 3.325,
      "grad_norm": 0.06341225653886795,
      "learning_rate": 2.9226527969998664e-05,
      "loss": 0.0108,
      "step": 93100
    },
    {
      "epoch": 3.3285714285714287,
      "grad_norm": 0.048079103231430054,
      "learning_rate": 2.92042055448904e-05,
      "loss": 0.0101,
      "step": 93200
    },
    {
      "epoch": 3.3321428571428573,
      "grad_norm": 0.040024105459451675,
      "learning_rate": 2.9181883119782134e-05,
      "loss": 0.0101,
      "step": 93300
    },
    {
      "epoch": 3.335714285714286,
      "grad_norm": 0.05856850743293762,
      "learning_rate": 2.915956069467387e-05,
      "loss": 0.0106,
      "step": 93400
    },
    {
      "epoch": 3.3392857142857144,
      "grad_norm": 0.03265538439154625,
      "learning_rate": 2.913723826956561e-05,
      "loss": 0.0105,
      "step": 93500
    },
    {
      "epoch": 3.342857142857143,
      "grad_norm": 0.041431207209825516,
      "learning_rate": 2.9114915844457343e-05,
      "loss": 0.0105,
      "step": 93600
    },
    {
      "epoch": 3.3464285714285715,
      "grad_norm": 0.06600893288850784,
      "learning_rate": 2.909259341934908e-05,
      "loss": 0.0102,
      "step": 93700
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.04209386929869652,
      "learning_rate": 2.9070270994240815e-05,
      "loss": 0.0105,
      "step": 93800
    },
    {
      "epoch": 3.3535714285714286,
      "grad_norm": 0.05242135003209114,
      "learning_rate": 2.904794856913255e-05,
      "loss": 0.0109,
      "step": 93900
    },
    {
      "epoch": 3.357142857142857,
      "grad_norm": 0.0374913327395916,
      "learning_rate": 2.9025626144024288e-05,
      "loss": 0.0113,
      "step": 94000
    },
    {
      "epoch": 3.3607142857142858,
      "grad_norm": 0.061028968542814255,
      "learning_rate": 2.9003303718916025e-05,
      "loss": 0.0109,
      "step": 94100
    },
    {
      "epoch": 3.3642857142857143,
      "grad_norm": 0.030207408592104912,
      "learning_rate": 2.8980981293807764e-05,
      "loss": 0.0109,
      "step": 94200
    },
    {
      "epoch": 3.367857142857143,
      "grad_norm": 0.044930599629879,
      "learning_rate": 2.8958658868699494e-05,
      "loss": 0.0105,
      "step": 94300
    },
    {
      "epoch": 3.3714285714285714,
      "grad_norm": 0.02738279663026333,
      "learning_rate": 2.8936336443591234e-05,
      "loss": 0.0108,
      "step": 94400
    },
    {
      "epoch": 3.375,
      "grad_norm": 0.042876873165369034,
      "learning_rate": 2.891401401848297e-05,
      "loss": 0.0099,
      "step": 94500
    },
    {
      "epoch": 3.3785714285714286,
      "grad_norm": 0.05629152059555054,
      "learning_rate": 2.8891691593374703e-05,
      "loss": 0.0107,
      "step": 94600
    },
    {
      "epoch": 3.382142857142857,
      "grad_norm": 0.03923799842596054,
      "learning_rate": 2.8869369168266443e-05,
      "loss": 0.011,
      "step": 94700
    },
    {
      "epoch": 3.3857142857142857,
      "grad_norm": 0.07192613929510117,
      "learning_rate": 2.884704674315818e-05,
      "loss": 0.0098,
      "step": 94800
    },
    {
      "epoch": 3.3892857142857142,
      "grad_norm": 0.03651988506317139,
      "learning_rate": 2.8824724318049912e-05,
      "loss": 0.0102,
      "step": 94900
    },
    {
      "epoch": 3.392857142857143,
      "grad_norm": 0.032760050147771835,
      "learning_rate": 2.880240189294165e-05,
      "loss": 0.0099,
      "step": 95000
    },
    {
      "epoch": 3.3964285714285714,
      "grad_norm": 0.03228231146931648,
      "learning_rate": 2.8780079467833388e-05,
      "loss": 0.0101,
      "step": 95100
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.05700097605586052,
      "learning_rate": 2.8757757042725125e-05,
      "loss": 0.0102,
      "step": 95200
    },
    {
      "epoch": 3.4035714285714285,
      "grad_norm": 0.06843943893909454,
      "learning_rate": 2.8735434617616858e-05,
      "loss": 0.01,
      "step": 95300
    },
    {
      "epoch": 3.407142857142857,
      "grad_norm": 0.016509918496012688,
      "learning_rate": 2.871333541675968e-05,
      "loss": 0.01,
      "step": 95400
    },
    {
      "epoch": 3.4107142857142856,
      "grad_norm": 0.025406448170542717,
      "learning_rate": 2.8691012991651415e-05,
      "loss": 0.0099,
      "step": 95500
    },
    {
      "epoch": 3.414285714285714,
      "grad_norm": 0.04149993881583214,
      "learning_rate": 2.866869056654315e-05,
      "loss": 0.0104,
      "step": 95600
    },
    {
      "epoch": 3.4178571428571427,
      "grad_norm": 0.106309674680233,
      "learning_rate": 2.8646368141434888e-05,
      "loss": 0.0107,
      "step": 95700
    },
    {
      "epoch": 3.4214285714285713,
      "grad_norm": 0.05120474845170975,
      "learning_rate": 2.8624045716326624e-05,
      "loss": 0.0101,
      "step": 95800
    },
    {
      "epoch": 3.425,
      "grad_norm": 0.05138356238603592,
      "learning_rate": 2.8601723291218357e-05,
      "loss": 0.0105,
      "step": 95900
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 0.06513306498527527,
      "learning_rate": 2.8579400866110094e-05,
      "loss": 0.0103,
      "step": 96000
    },
    {
      "epoch": 3.432142857142857,
      "grad_norm": 0.04072814807295799,
      "learning_rate": 2.8557078441001834e-05,
      "loss": 0.01,
      "step": 96100
    },
    {
      "epoch": 3.435714285714286,
      "grad_norm": 0.050315480679273605,
      "learning_rate": 2.8534756015893567e-05,
      "loss": 0.0102,
      "step": 96200
    },
    {
      "epoch": 3.439285714285714,
      "grad_norm": 0.0930410772562027,
      "learning_rate": 2.8512433590785303e-05,
      "loss": 0.0098,
      "step": 96300
    },
    {
      "epoch": 3.442857142857143,
      "grad_norm": 0.03914381563663483,
      "learning_rate": 2.8490111165677043e-05,
      "loss": 0.0101,
      "step": 96400
    },
    {
      "epoch": 3.4464285714285716,
      "grad_norm": 0.05750691890716553,
      "learning_rate": 2.846778874056878e-05,
      "loss": 0.0103,
      "step": 96500
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.0449671596288681,
      "learning_rate": 2.8445466315460512e-05,
      "loss": 0.01,
      "step": 96600
    },
    {
      "epoch": 3.4535714285714287,
      "grad_norm": 0.04875179007649422,
      "learning_rate": 2.842314389035225e-05,
      "loss": 0.01,
      "step": 96700
    },
    {
      "epoch": 3.4571428571428573,
      "grad_norm": 0.04304729029536247,
      "learning_rate": 2.8400821465243988e-05,
      "loss": 0.0102,
      "step": 96800
    },
    {
      "epoch": 3.460714285714286,
      "grad_norm": 0.0794062688946724,
      "learning_rate": 2.837849904013572e-05,
      "loss": 0.0106,
      "step": 96900
    },
    {
      "epoch": 3.4642857142857144,
      "grad_norm": 0.038667742162942886,
      "learning_rate": 2.8356176615027457e-05,
      "loss": 0.01,
      "step": 97000
    },
    {
      "epoch": 3.467857142857143,
      "grad_norm": 0.06985009461641312,
      "learning_rate": 2.8333854189919197e-05,
      "loss": 0.0105,
      "step": 97100
    },
    {
      "epoch": 3.4714285714285715,
      "grad_norm": 0.04074350371956825,
      "learning_rate": 2.8311531764810927e-05,
      "loss": 0.0108,
      "step": 97200
    },
    {
      "epoch": 3.475,
      "grad_norm": 0.057351253926754,
      "learning_rate": 2.8289209339702667e-05,
      "loss": 0.0099,
      "step": 97300
    },
    {
      "epoch": 3.4785714285714286,
      "grad_norm": 0.043139487504959106,
      "learning_rate": 2.8266886914594403e-05,
      "loss": 0.0097,
      "step": 97400
    },
    {
      "epoch": 3.482142857142857,
      "grad_norm": 0.04835626855492592,
      "learning_rate": 2.8244564489486143e-05,
      "loss": 0.0102,
      "step": 97500
    },
    {
      "epoch": 3.4857142857142858,
      "grad_norm": 0.030927611514925957,
      "learning_rate": 2.8222465288628957e-05,
      "loss": 0.0101,
      "step": 97600
    },
    {
      "epoch": 3.4892857142857143,
      "grad_norm": 0.027082866057753563,
      "learning_rate": 2.8200142863520694e-05,
      "loss": 0.01,
      "step": 97700
    },
    {
      "epoch": 3.492857142857143,
      "grad_norm": 0.06084005534648895,
      "learning_rate": 2.8177820438412427e-05,
      "loss": 0.0108,
      "step": 97800
    },
    {
      "epoch": 3.4964285714285714,
      "grad_norm": 0.046614330261945724,
      "learning_rate": 2.8155498013304166e-05,
      "loss": 0.0101,
      "step": 97900
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.03234317526221275,
      "learning_rate": 2.8133175588195903e-05,
      "loss": 0.0092,
      "step": 98000
    },
    {
      "epoch": 3.5035714285714286,
      "grad_norm": 0.04287172481417656,
      "learning_rate": 2.8110853163087643e-05,
      "loss": 0.0107,
      "step": 98100
    },
    {
      "epoch": 3.507142857142857,
      "grad_norm": 0.030948620289564133,
      "learning_rate": 2.8088530737979372e-05,
      "loss": 0.0103,
      "step": 98200
    },
    {
      "epoch": 3.5107142857142857,
      "grad_norm": 0.03302612528204918,
      "learning_rate": 2.8066208312871112e-05,
      "loss": 0.0099,
      "step": 98300
    },
    {
      "epoch": 3.5142857142857142,
      "grad_norm": 0.04381100833415985,
      "learning_rate": 2.804388588776285e-05,
      "loss": 0.0102,
      "step": 98400
    },
    {
      "epoch": 3.517857142857143,
      "grad_norm": 0.05426756292581558,
      "learning_rate": 2.802156346265458e-05,
      "loss": 0.0095,
      "step": 98500
    },
    {
      "epoch": 3.5214285714285714,
      "grad_norm": 0.029445528984069824,
      "learning_rate": 2.799924103754632e-05,
      "loss": 0.0108,
      "step": 98600
    },
    {
      "epoch": 3.525,
      "grad_norm": 0.06762831658124924,
      "learning_rate": 2.7976918612438057e-05,
      "loss": 0.0104,
      "step": 98700
    },
    {
      "epoch": 3.5285714285714285,
      "grad_norm": 0.03892352804541588,
      "learning_rate": 2.795459618732979e-05,
      "loss": 0.0097,
      "step": 98800
    },
    {
      "epoch": 3.532142857142857,
      "grad_norm": 0.05917505919933319,
      "learning_rate": 2.7932273762221527e-05,
      "loss": 0.0108,
      "step": 98900
    },
    {
      "epoch": 3.5357142857142856,
      "grad_norm": 0.0738554298877716,
      "learning_rate": 2.7909951337113267e-05,
      "loss": 0.0092,
      "step": 99000
    },
    {
      "epoch": 3.539285714285714,
      "grad_norm": 0.02717747539281845,
      "learning_rate": 2.7887628912005003e-05,
      "loss": 0.0106,
      "step": 99100
    },
    {
      "epoch": 3.5428571428571427,
      "grad_norm": 0.026814427226781845,
      "learning_rate": 2.7865306486896736e-05,
      "loss": 0.0094,
      "step": 99200
    },
    {
      "epoch": 3.5464285714285713,
      "grad_norm": 0.0249557513743639,
      "learning_rate": 2.7842984061788476e-05,
      "loss": 0.01,
      "step": 99300
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.03365035355091095,
      "learning_rate": 2.7820661636680212e-05,
      "loss": 0.0093,
      "step": 99400
    },
    {
      "epoch": 3.553571428571429,
      "grad_norm": 0.03080889768898487,
      "learning_rate": 2.7798339211571945e-05,
      "loss": 0.0105,
      "step": 99500
    },
    {
      "epoch": 3.557142857142857,
      "grad_norm": 0.07728565484285355,
      "learning_rate": 2.777601678646368e-05,
      "loss": 0.0098,
      "step": 99600
    },
    {
      "epoch": 3.560714285714286,
      "grad_norm": 0.06620636582374573,
      "learning_rate": 2.775369436135542e-05,
      "loss": 0.0099,
      "step": 99700
    },
    {
      "epoch": 3.564285714285714,
      "grad_norm": 0.05244073644280434,
      "learning_rate": 2.7731371936247154e-05,
      "loss": 0.0103,
      "step": 99800
    },
    {
      "epoch": 3.567857142857143,
      "grad_norm": 0.06469859182834625,
      "learning_rate": 2.7709272735389976e-05,
      "loss": 0.0107,
      "step": 99900
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.06432408094406128,
      "learning_rate": 2.7686950310281712e-05,
      "loss": 0.0109,
      "step": 100000
    },
    {
      "epoch": 3.575,
      "grad_norm": 0.04031969979405403,
      "learning_rate": 2.7664627885173445e-05,
      "loss": 0.0101,
      "step": 100100
    },
    {
      "epoch": 3.5785714285714287,
      "grad_norm": 0.028505144640803337,
      "learning_rate": 2.764230546006518e-05,
      "loss": 0.01,
      "step": 100200
    },
    {
      "epoch": 3.5821428571428573,
      "grad_norm": 0.025436455383896828,
      "learning_rate": 2.761998303495692e-05,
      "loss": 0.01,
      "step": 100300
    },
    {
      "epoch": 3.585714285714286,
      "grad_norm": 0.0612473264336586,
      "learning_rate": 2.7597660609848657e-05,
      "loss": 0.0106,
      "step": 100400
    },
    {
      "epoch": 3.5892857142857144,
      "grad_norm": 0.045548874884843826,
      "learning_rate": 2.757533818474039e-05,
      "loss": 0.0103,
      "step": 100500
    },
    {
      "epoch": 3.592857142857143,
      "grad_norm": 0.051656510680913925,
      "learning_rate": 2.7553015759632127e-05,
      "loss": 0.0101,
      "step": 100600
    },
    {
      "epoch": 3.5964285714285715,
      "grad_norm": 0.05844491720199585,
      "learning_rate": 2.7530693334523866e-05,
      "loss": 0.0095,
      "step": 100700
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.026365213096141815,
      "learning_rate": 2.75083709094156e-05,
      "loss": 0.0098,
      "step": 100800
    },
    {
      "epoch": 3.6035714285714286,
      "grad_norm": 0.0573769211769104,
      "learning_rate": 2.7486048484307336e-05,
      "loss": 0.0102,
      "step": 100900
    },
    {
      "epoch": 3.607142857142857,
      "grad_norm": 0.05724872648715973,
      "learning_rate": 2.7463726059199076e-05,
      "loss": 0.0094,
      "step": 101000
    },
    {
      "epoch": 3.6107142857142858,
      "grad_norm": 0.026267828419804573,
      "learning_rate": 2.7441403634090805e-05,
      "loss": 0.0111,
      "step": 101100
    },
    {
      "epoch": 3.6142857142857143,
      "grad_norm": 0.049401674419641495,
      "learning_rate": 2.7419081208982545e-05,
      "loss": 0.01,
      "step": 101200
    },
    {
      "epoch": 3.617857142857143,
      "grad_norm": 0.01816256158053875,
      "learning_rate": 2.739675878387428e-05,
      "loss": 0.0098,
      "step": 101300
    },
    {
      "epoch": 3.6214285714285714,
      "grad_norm": 0.02978379651904106,
      "learning_rate": 2.737443635876602e-05,
      "loss": 0.0102,
      "step": 101400
    },
    {
      "epoch": 3.625,
      "grad_norm": 0.06152496859431267,
      "learning_rate": 2.7352113933657754e-05,
      "loss": 0.0101,
      "step": 101500
    },
    {
      "epoch": 3.6285714285714286,
      "grad_norm": 0.06962167471647263,
      "learning_rate": 2.732979150854949e-05,
      "loss": 0.01,
      "step": 101600
    },
    {
      "epoch": 3.632142857142857,
      "grad_norm": 0.03597908839583397,
      "learning_rate": 2.7307469083441227e-05,
      "loss": 0.0105,
      "step": 101700
    },
    {
      "epoch": 3.6357142857142857,
      "grad_norm": 0.05746204033493996,
      "learning_rate": 2.728514665833296e-05,
      "loss": 0.01,
      "step": 101800
    },
    {
      "epoch": 3.6392857142857142,
      "grad_norm": 0.04164579510688782,
      "learning_rate": 2.72628242332247e-05,
      "loss": 0.0095,
      "step": 101900
    },
    {
      "epoch": 3.642857142857143,
      "grad_norm": 0.06006699800491333,
      "learning_rate": 2.7240501808116436e-05,
      "loss": 0.0095,
      "step": 102000
    },
    {
      "epoch": 3.6464285714285714,
      "grad_norm": 0.05029406398534775,
      "learning_rate": 2.721817938300817e-05,
      "loss": 0.0103,
      "step": 102100
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.04130697250366211,
      "learning_rate": 2.7195856957899905e-05,
      "loss": 0.0102,
      "step": 102200
    },
    {
      "epoch": 3.6535714285714285,
      "grad_norm": 0.07484474778175354,
      "learning_rate": 2.7173534532791645e-05,
      "loss": 0.0103,
      "step": 102300
    },
    {
      "epoch": 3.657142857142857,
      "grad_norm": 0.03559987619519234,
      "learning_rate": 2.715121210768338e-05,
      "loss": 0.0097,
      "step": 102400
    },
    {
      "epoch": 3.6607142857142856,
      "grad_norm": 0.02255195565521717,
      "learning_rate": 2.7128889682575114e-05,
      "loss": 0.0101,
      "step": 102500
    },
    {
      "epoch": 3.664285714285714,
      "grad_norm": 0.07376809418201447,
      "learning_rate": 2.7106567257466854e-05,
      "loss": 0.0096,
      "step": 102600
    },
    {
      "epoch": 3.6678571428571427,
      "grad_norm": 0.04551427811384201,
      "learning_rate": 2.708446805660967e-05,
      "loss": 0.0099,
      "step": 102700
    },
    {
      "epoch": 3.6714285714285713,
      "grad_norm": 0.024043750017881393,
      "learning_rate": 2.7062145631501405e-05,
      "loss": 0.0104,
      "step": 102800
    },
    {
      "epoch": 3.675,
      "grad_norm": 0.036444585770368576,
      "learning_rate": 2.7039823206393145e-05,
      "loss": 0.0104,
      "step": 102900
    },
    {
      "epoch": 3.678571428571429,
      "grad_norm": 0.046986568719148636,
      "learning_rate": 2.701750078128488e-05,
      "loss": 0.0099,
      "step": 103000
    },
    {
      "epoch": 3.682142857142857,
      "grad_norm": 0.041720353066921234,
      "learning_rate": 2.6995178356176614e-05,
      "loss": 0.0098,
      "step": 103100
    },
    {
      "epoch": 3.685714285714286,
      "grad_norm": 0.07323494553565979,
      "learning_rate": 2.6972855931068354e-05,
      "loss": 0.0101,
      "step": 103200
    },
    {
      "epoch": 3.689285714285714,
      "grad_norm": 0.04700257629156113,
      "learning_rate": 2.695053350596009e-05,
      "loss": 0.0109,
      "step": 103300
    },
    {
      "epoch": 3.692857142857143,
      "grad_norm": 0.056387655436992645,
      "learning_rate": 2.6928211080851823e-05,
      "loss": 0.0107,
      "step": 103400
    },
    {
      "epoch": 3.696428571428571,
      "grad_norm": 0.07482808828353882,
      "learning_rate": 2.690588865574356e-05,
      "loss": 0.0101,
      "step": 103500
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.03857598081231117,
      "learning_rate": 2.68835662306353e-05,
      "loss": 0.0096,
      "step": 103600
    },
    {
      "epoch": 3.7035714285714287,
      "grad_norm": 0.029359042644500732,
      "learning_rate": 2.6861243805527032e-05,
      "loss": 0.0097,
      "step": 103700
    },
    {
      "epoch": 3.7071428571428573,
      "grad_norm": 0.027327902615070343,
      "learning_rate": 2.683892138041877e-05,
      "loss": 0.0099,
      "step": 103800
    },
    {
      "epoch": 3.710714285714286,
      "grad_norm": 0.047737814486026764,
      "learning_rate": 2.681659895531051e-05,
      "loss": 0.0102,
      "step": 103900
    },
    {
      "epoch": 3.7142857142857144,
      "grad_norm": 0.050271548330783844,
      "learning_rate": 2.6794276530202245e-05,
      "loss": 0.0104,
      "step": 104000
    },
    {
      "epoch": 3.717857142857143,
      "grad_norm": 0.027176784351468086,
      "learning_rate": 2.6771954105093978e-05,
      "loss": 0.0097,
      "step": 104100
    },
    {
      "epoch": 3.7214285714285715,
      "grad_norm": 0.05938052386045456,
      "learning_rate": 2.6749631679985714e-05,
      "loss": 0.0102,
      "step": 104200
    },
    {
      "epoch": 3.725,
      "grad_norm": 0.038551971316337585,
      "learning_rate": 2.6727309254877454e-05,
      "loss": 0.0105,
      "step": 104300
    },
    {
      "epoch": 3.7285714285714286,
      "grad_norm": 0.05713499337434769,
      "learning_rate": 2.6704986829769184e-05,
      "loss": 0.0103,
      "step": 104400
    },
    {
      "epoch": 3.732142857142857,
      "grad_norm": 0.08684655278921127,
      "learning_rate": 2.6682664404660923e-05,
      "loss": 0.0102,
      "step": 104500
    },
    {
      "epoch": 3.7357142857142858,
      "grad_norm": 0.02787739410996437,
      "learning_rate": 2.666034197955266e-05,
      "loss": 0.0098,
      "step": 104600
    },
    {
      "epoch": 3.7392857142857143,
      "grad_norm": 0.04860455170273781,
      "learning_rate": 2.6638019554444393e-05,
      "loss": 0.0097,
      "step": 104700
    },
    {
      "epoch": 3.742857142857143,
      "grad_norm": 0.05256122350692749,
      "learning_rate": 2.6615697129336132e-05,
      "loss": 0.0096,
      "step": 104800
    },
    {
      "epoch": 3.7464285714285714,
      "grad_norm": 0.02799948677420616,
      "learning_rate": 2.659337470422787e-05,
      "loss": 0.0103,
      "step": 104900
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.07491563260555267,
      "learning_rate": 2.657105227911961e-05,
      "loss": 0.0102,
      "step": 105000
    },
    {
      "epoch": 3.7535714285714286,
      "grad_norm": 0.029908936470746994,
      "learning_rate": 2.6548953078262423e-05,
      "loss": 0.0096,
      "step": 105100
    },
    {
      "epoch": 3.757142857142857,
      "grad_norm": 0.04753784462809563,
      "learning_rate": 2.652663065315416e-05,
      "loss": 0.0099,
      "step": 105200
    },
    {
      "epoch": 3.7607142857142857,
      "grad_norm": 0.06636213511228561,
      "learning_rate": 2.65043082280459e-05,
      "loss": 0.0105,
      "step": 105300
    },
    {
      "epoch": 3.7642857142857142,
      "grad_norm": 0.06348232924938202,
      "learning_rate": 2.6481985802937632e-05,
      "loss": 0.0104,
      "step": 105400
    },
    {
      "epoch": 3.767857142857143,
      "grad_norm": 0.05286683142185211,
      "learning_rate": 2.645966337782937e-05,
      "loss": 0.0096,
      "step": 105500
    },
    {
      "epoch": 3.7714285714285714,
      "grad_norm": 0.046108976006507874,
      "learning_rate": 2.643734095272111e-05,
      "loss": 0.0099,
      "step": 105600
    },
    {
      "epoch": 3.775,
      "grad_norm": 0.03354115039110184,
      "learning_rate": 2.6415018527612838e-05,
      "loss": 0.0096,
      "step": 105700
    },
    {
      "epoch": 3.7785714285714285,
      "grad_norm": 0.06609498709440231,
      "learning_rate": 2.6392696102504578e-05,
      "loss": 0.0104,
      "step": 105800
    },
    {
      "epoch": 3.782142857142857,
      "grad_norm": 0.041108231991529465,
      "learning_rate": 2.6370373677396314e-05,
      "loss": 0.0102,
      "step": 105900
    },
    {
      "epoch": 3.7857142857142856,
      "grad_norm": 0.044469378888607025,
      "learning_rate": 2.6348051252288047e-05,
      "loss": 0.0097,
      "step": 106000
    },
    {
      "epoch": 3.789285714285714,
      "grad_norm": 0.025775978341698647,
      "learning_rate": 2.6325728827179787e-05,
      "loss": 0.0095,
      "step": 106100
    },
    {
      "epoch": 3.7928571428571427,
      "grad_norm": 0.045134998857975006,
      "learning_rate": 2.6303406402071523e-05,
      "loss": 0.0096,
      "step": 106200
    },
    {
      "epoch": 3.7964285714285713,
      "grad_norm": 0.043832987546920776,
      "learning_rate": 2.628108397696326e-05,
      "loss": 0.0097,
      "step": 106300
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.06499321013689041,
      "learning_rate": 2.6258761551854993e-05,
      "loss": 0.0097,
      "step": 106400
    },
    {
      "epoch": 3.803571428571429,
      "grad_norm": 0.04858361929655075,
      "learning_rate": 2.6236439126746732e-05,
      "loss": 0.0105,
      "step": 106500
    },
    {
      "epoch": 3.807142857142857,
      "grad_norm": 0.07378211617469788,
      "learning_rate": 2.621411670163847e-05,
      "loss": 0.0103,
      "step": 106600
    },
    {
      "epoch": 3.810714285714286,
      "grad_norm": 0.05047541856765747,
      "learning_rate": 2.61917942765302e-05,
      "loss": 0.0095,
      "step": 106700
    },
    {
      "epoch": 3.814285714285714,
      "grad_norm": 0.06094362214207649,
      "learning_rate": 2.6169471851421938e-05,
      "loss": 0.0099,
      "step": 106800
    },
    {
      "epoch": 3.817857142857143,
      "grad_norm": 0.02946621924638748,
      "learning_rate": 2.6147149426313678e-05,
      "loss": 0.0104,
      "step": 106900
    },
    {
      "epoch": 3.821428571428571,
      "grad_norm": 0.024452952668070793,
      "learning_rate": 2.612482700120541e-05,
      "loss": 0.0102,
      "step": 107000
    },
    {
      "epoch": 3.825,
      "grad_norm": 0.042118337005376816,
      "learning_rate": 2.6102727800348232e-05,
      "loss": 0.0097,
      "step": 107100
    },
    {
      "epoch": 3.8285714285714287,
      "grad_norm": 0.038761597126722336,
      "learning_rate": 2.608040537523997e-05,
      "loss": 0.0097,
      "step": 107200
    },
    {
      "epoch": 3.8321428571428573,
      "grad_norm": 0.09557346254587173,
      "learning_rate": 2.60580829501317e-05,
      "loss": 0.0092,
      "step": 107300
    },
    {
      "epoch": 3.835714285714286,
      "grad_norm": 0.050303179770708084,
      "learning_rate": 2.6035760525023438e-05,
      "loss": 0.0098,
      "step": 107400
    },
    {
      "epoch": 3.8392857142857144,
      "grad_norm": 0.11343511193990707,
      "learning_rate": 2.6013438099915178e-05,
      "loss": 0.0106,
      "step": 107500
    },
    {
      "epoch": 3.842857142857143,
      "grad_norm": 0.051547348499298096,
      "learning_rate": 2.599111567480691e-05,
      "loss": 0.0098,
      "step": 107600
    },
    {
      "epoch": 3.8464285714285715,
      "grad_norm": 0.035856541246175766,
      "learning_rate": 2.5968793249698647e-05,
      "loss": 0.0098,
      "step": 107700
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.03553632274270058,
      "learning_rate": 2.5946470824590387e-05,
      "loss": 0.0106,
      "step": 107800
    },
    {
      "epoch": 3.8535714285714286,
      "grad_norm": 0.10367503017187119,
      "learning_rate": 2.5924148399482123e-05,
      "loss": 0.0102,
      "step": 107900
    },
    {
      "epoch": 3.857142857142857,
      "grad_norm": 0.04462672397494316,
      "learning_rate": 2.5901825974373856e-05,
      "loss": 0.0089,
      "step": 108000
    },
    {
      "epoch": 3.8607142857142858,
      "grad_norm": 0.030550211668014526,
      "learning_rate": 2.5879503549265592e-05,
      "loss": 0.0091,
      "step": 108100
    },
    {
      "epoch": 3.8642857142857143,
      "grad_norm": 0.026435941457748413,
      "learning_rate": 2.5857181124157332e-05,
      "loss": 0.0096,
      "step": 108200
    },
    {
      "epoch": 3.867857142857143,
      "grad_norm": 0.03919077664613724,
      "learning_rate": 2.5834858699049065e-05,
      "loss": 0.0093,
      "step": 108300
    },
    {
      "epoch": 3.8714285714285714,
      "grad_norm": 0.04309159517288208,
      "learning_rate": 2.58125362739408e-05,
      "loss": 0.01,
      "step": 108400
    },
    {
      "epoch": 3.875,
      "grad_norm": 0.0646461769938469,
      "learning_rate": 2.5790213848832538e-05,
      "loss": 0.0107,
      "step": 108500
    },
    {
      "epoch": 3.8785714285714286,
      "grad_norm": 0.03607024624943733,
      "learning_rate": 2.576789142372427e-05,
      "loss": 0.0106,
      "step": 108600
    },
    {
      "epoch": 3.882142857142857,
      "grad_norm": 0.04917498305439949,
      "learning_rate": 2.574556899861601e-05,
      "loss": 0.0104,
      "step": 108700
    },
    {
      "epoch": 3.8857142857142857,
      "grad_norm": 0.03024950437247753,
      "learning_rate": 2.5723246573507747e-05,
      "loss": 0.0103,
      "step": 108800
    },
    {
      "epoch": 3.8892857142857142,
      "grad_norm": 0.06231901794672012,
      "learning_rate": 2.5700924148399487e-05,
      "loss": 0.01,
      "step": 108900
    },
    {
      "epoch": 3.892857142857143,
      "grad_norm": 0.058096956461668015,
      "learning_rate": 2.5678601723291216e-05,
      "loss": 0.0102,
      "step": 109000
    },
    {
      "epoch": 3.8964285714285714,
      "grad_norm": 0.02054511569440365,
      "learning_rate": 2.5656279298182956e-05,
      "loss": 0.01,
      "step": 109100
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.0664389431476593,
      "learning_rate": 2.5633956873074692e-05,
      "loss": 0.0099,
      "step": 109200
    },
    {
      "epoch": 3.9035714285714285,
      "grad_norm": 0.10172245651483536,
      "learning_rate": 2.561185767221751e-05,
      "loss": 0.0095,
      "step": 109300
    },
    {
      "epoch": 3.907142857142857,
      "grad_norm": 0.061090387403964996,
      "learning_rate": 2.5589535247109247e-05,
      "loss": 0.0097,
      "step": 109400
    },
    {
      "epoch": 3.9107142857142856,
      "grad_norm": 0.027876023203134537,
      "learning_rate": 2.5567212822000987e-05,
      "loss": 0.0092,
      "step": 109500
    },
    {
      "epoch": 3.914285714285714,
      "grad_norm": 0.03905610367655754,
      "learning_rate": 2.5544890396892716e-05,
      "loss": 0.0093,
      "step": 109600
    },
    {
      "epoch": 3.9178571428571427,
      "grad_norm": 0.046984970569610596,
      "learning_rate": 2.5522567971784456e-05,
      "loss": 0.0102,
      "step": 109700
    },
    {
      "epoch": 3.9214285714285713,
      "grad_norm": 0.05254204571247101,
      "learning_rate": 2.5500245546676192e-05,
      "loss": 0.0101,
      "step": 109800
    },
    {
      "epoch": 3.925,
      "grad_norm": 0.03279993683099747,
      "learning_rate": 2.5477923121567925e-05,
      "loss": 0.0108,
      "step": 109900
    },
    {
      "epoch": 3.928571428571429,
      "grad_norm": 0.05518471822142601,
      "learning_rate": 2.5455600696459665e-05,
      "loss": 0.0098,
      "step": 110000
    },
    {
      "epoch": 3.932142857142857,
      "grad_norm": 0.03793434053659439,
      "learning_rate": 2.54332782713514e-05,
      "loss": 0.0104,
      "step": 110100
    },
    {
      "epoch": 3.935714285714286,
      "grad_norm": 0.06368990987539291,
      "learning_rate": 2.541095584624314e-05,
      "loss": 0.0098,
      "step": 110200
    },
    {
      "epoch": 3.939285714285714,
      "grad_norm": 0.06493161618709564,
      "learning_rate": 2.538863342113487e-05,
      "loss": 0.009,
      "step": 110300
    },
    {
      "epoch": 3.942857142857143,
      "grad_norm": 0.1286703646183014,
      "learning_rate": 2.536631099602661e-05,
      "loss": 0.0103,
      "step": 110400
    },
    {
      "epoch": 3.946428571428571,
      "grad_norm": 0.03538554161787033,
      "learning_rate": 2.5343988570918347e-05,
      "loss": 0.0094,
      "step": 110500
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.049271196126937866,
      "learning_rate": 2.532166614581008e-05,
      "loss": 0.0097,
      "step": 110600
    },
    {
      "epoch": 3.9535714285714287,
      "grad_norm": 0.06400778889656067,
      "learning_rate": 2.529934372070182e-05,
      "loss": 0.0105,
      "step": 110700
    },
    {
      "epoch": 3.9571428571428573,
      "grad_norm": 0.03635508194565773,
      "learning_rate": 2.5277021295593556e-05,
      "loss": 0.0097,
      "step": 110800
    },
    {
      "epoch": 3.960714285714286,
      "grad_norm": 0.03547044098377228,
      "learning_rate": 2.525469887048529e-05,
      "loss": 0.0098,
      "step": 110900
    },
    {
      "epoch": 3.9642857142857144,
      "grad_norm": 0.02726071886718273,
      "learning_rate": 2.5232376445377025e-05,
      "loss": 0.0098,
      "step": 111000
    },
    {
      "epoch": 3.967857142857143,
      "grad_norm": 0.05335747450590134,
      "learning_rate": 2.5210054020268765e-05,
      "loss": 0.0096,
      "step": 111100
    },
    {
      "epoch": 3.9714285714285715,
      "grad_norm": 0.0459882989525795,
      "learning_rate": 2.51877315951605e-05,
      "loss": 0.0097,
      "step": 111200
    },
    {
      "epoch": 3.975,
      "grad_norm": 0.06436264514923096,
      "learning_rate": 2.5165632394303316e-05,
      "loss": 0.0098,
      "step": 111300
    },
    {
      "epoch": 3.9785714285714286,
      "grad_norm": 0.06470226496458054,
      "learning_rate": 2.5143309969195056e-05,
      "loss": 0.0101,
      "step": 111400
    },
    {
      "epoch": 3.982142857142857,
      "grad_norm": 0.03160713240504265,
      "learning_rate": 2.512098754408679e-05,
      "loss": 0.0099,
      "step": 111500
    },
    {
      "epoch": 3.9857142857142858,
      "grad_norm": 0.03384706750512123,
      "learning_rate": 2.5098665118978525e-05,
      "loss": 0.0094,
      "step": 111600
    },
    {
      "epoch": 3.9892857142857143,
      "grad_norm": 0.027628356590867043,
      "learning_rate": 2.5076342693870265e-05,
      "loss": 0.0099,
      "step": 111700
    },
    {
      "epoch": 3.992857142857143,
      "grad_norm": 0.06805048882961273,
      "learning_rate": 2.5054020268762e-05,
      "loss": 0.0098,
      "step": 111800
    },
    {
      "epoch": 3.9964285714285714,
      "grad_norm": 0.05880660191178322,
      "learning_rate": 2.5031697843653734e-05,
      "loss": 0.0094,
      "step": 111900
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.03118807263672352,
      "learning_rate": 2.500937541854547e-05,
      "loss": 0.0096,
      "step": 112000
    },
    {
      "epoch": 4.0,
      "eval_accuracy_macro_0.5": 0.9964197278022766,
      "eval_accuracy_micro_0.5": 0.9964196085929871,
      "eval_accuracy_weighted_0.5": 0.9921014308929443,
      "eval_aucroc_macro": 0.8118174076080322,
      "eval_aucroc_micro": 0.8705670833587646,
      "eval_aucroc_weighted": 0.8689566254615784,
      "eval_f1_macro_0.5": 0.4029046595096588,
      "eval_f1_macro_0.6": 0.3261716365814209,
      "eval_f1_macro_0.7": 0.2500915825366974,
      "eval_f1_macro_0.8": 0.08836128562688828,
      "eval_f1_micro_0.5": 0.6096317768096924,
      "eval_f1_micro_0.6": 0.5436211824417114,
      "eval_f1_micro_0.7": 0.4475298821926117,
      "eval_f1_micro_0.8": 0.3219946324825287,
      "eval_f1_micro_0.9": 0.16015952825546265,
      "eval_f1_weighted_0.5": 0.5391151905059814,
      "eval_f1_weighted_0.6": 0.4660380184650421,
      "eval_f1_weighted_0.7": 0.3700760304927826,
      "eval_f1_weighted_0.8": 0.12676939368247986,
      "eval_loss": 0.008516516536474228,
      "eval_runtime": 1364.1416,
      "eval_samples_per_second": 40.802,
      "eval_steps_per_second": 5.101,
      "step": 112000
    },
    {
      "epoch": 4.003571428571429,
      "grad_norm": 0.06723148375749588,
      "learning_rate": 2.4987052993437207e-05,
      "loss": 0.0104,
      "step": 112100
    },
    {
      "epoch": 4.007142857142857,
      "grad_norm": 0.07080238312482834,
      "learning_rate": 2.4964730568328944e-05,
      "loss": 0.0098,
      "step": 112200
    },
    {
      "epoch": 4.010714285714286,
      "grad_norm": 0.07312701642513275,
      "learning_rate": 2.494240814322068e-05,
      "loss": 0.0105,
      "step": 112300
    },
    {
      "epoch": 4.014285714285714,
      "grad_norm": 0.04975730553269386,
      "learning_rate": 2.492008571811242e-05,
      "loss": 0.0099,
      "step": 112400
    },
    {
      "epoch": 4.017857142857143,
      "grad_norm": 0.05123278498649597,
      "learning_rate": 2.4897763293004153e-05,
      "loss": 0.0095,
      "step": 112500
    },
    {
      "epoch": 4.021428571428571,
      "grad_norm": 0.045373111963272095,
      "learning_rate": 2.487544086789589e-05,
      "loss": 0.0098,
      "step": 112600
    },
    {
      "epoch": 4.025,
      "grad_norm": 0.047131624072790146,
      "learning_rate": 2.4853118442787625e-05,
      "loss": 0.0101,
      "step": 112700
    },
    {
      "epoch": 4.0285714285714285,
      "grad_norm": 0.027870578691363335,
      "learning_rate": 2.4830796017679362e-05,
      "loss": 0.0096,
      "step": 112800
    },
    {
      "epoch": 4.0321428571428575,
      "grad_norm": 0.038947004824876785,
      "learning_rate": 2.4808473592571098e-05,
      "loss": 0.0097,
      "step": 112900
    },
    {
      "epoch": 4.035714285714286,
      "grad_norm": 0.036331385374069214,
      "learning_rate": 2.4786151167462834e-05,
      "loss": 0.0101,
      "step": 113000
    },
    {
      "epoch": 4.039285714285715,
      "grad_norm": 0.11985372006893158,
      "learning_rate": 2.476382874235457e-05,
      "loss": 0.0095,
      "step": 113100
    },
    {
      "epoch": 4.042857142857143,
      "grad_norm": 0.10122080892324448,
      "learning_rate": 2.4741506317246307e-05,
      "loss": 0.01,
      "step": 113200
    },
    {
      "epoch": 4.046428571428572,
      "grad_norm": 0.048883482813835144,
      "learning_rate": 2.4719183892138044e-05,
      "loss": 0.0105,
      "step": 113300
    },
    {
      "epoch": 4.05,
      "grad_norm": 0.03719573840498924,
      "learning_rate": 2.469708469128086e-05,
      "loss": 0.0101,
      "step": 113400
    },
    {
      "epoch": 4.053571428571429,
      "grad_norm": 0.07452650368213654,
      "learning_rate": 2.4674762266172598e-05,
      "loss": 0.0097,
      "step": 113500
    },
    {
      "epoch": 4.057142857142857,
      "grad_norm": 0.042123422026634216,
      "learning_rate": 2.4652439841064334e-05,
      "loss": 0.0097,
      "step": 113600
    },
    {
      "epoch": 4.060714285714286,
      "grad_norm": 0.07283414155244827,
      "learning_rate": 2.463011741595607e-05,
      "loss": 0.0097,
      "step": 113700
    },
    {
      "epoch": 4.064285714285714,
      "grad_norm": 0.03774291276931763,
      "learning_rate": 2.4607794990847807e-05,
      "loss": 0.0104,
      "step": 113800
    },
    {
      "epoch": 4.067857142857143,
      "grad_norm": 0.025758469477295876,
      "learning_rate": 2.4585472565739543e-05,
      "loss": 0.0103,
      "step": 113900
    },
    {
      "epoch": 4.071428571428571,
      "grad_norm": 0.07598964869976044,
      "learning_rate": 2.456315014063128e-05,
      "loss": 0.0105,
      "step": 114000
    },
    {
      "epoch": 4.075,
      "grad_norm": 0.04775256663560867,
      "learning_rate": 2.4540827715523016e-05,
      "loss": 0.0099,
      "step": 114100
    },
    {
      "epoch": 4.078571428571428,
      "grad_norm": 0.08733104914426804,
      "learning_rate": 2.451850529041475e-05,
      "loss": 0.0102,
      "step": 114200
    },
    {
      "epoch": 4.082142857142857,
      "grad_norm": 0.06289996951818466,
      "learning_rate": 2.449618286530649e-05,
      "loss": 0.0091,
      "step": 114300
    },
    {
      "epoch": 4.085714285714285,
      "grad_norm": 0.03839415684342384,
      "learning_rate": 2.4473860440198222e-05,
      "loss": 0.0091,
      "step": 114400
    },
    {
      "epoch": 4.089285714285714,
      "grad_norm": 0.049875881522893906,
      "learning_rate": 2.445153801508996e-05,
      "loss": 0.0104,
      "step": 114500
    },
    {
      "epoch": 4.0928571428571425,
      "grad_norm": 0.03454394266009331,
      "learning_rate": 2.4429215589981698e-05,
      "loss": 0.0098,
      "step": 114600
    },
    {
      "epoch": 4.0964285714285715,
      "grad_norm": 0.05250317603349686,
      "learning_rate": 2.440689316487343e-05,
      "loss": 0.0102,
      "step": 114700
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.04601826146245003,
      "learning_rate": 2.438457073976517e-05,
      "loss": 0.0098,
      "step": 114800
    },
    {
      "epoch": 4.103571428571429,
      "grad_norm": 0.08184933662414551,
      "learning_rate": 2.4362248314656904e-05,
      "loss": 0.0093,
      "step": 114900
    },
    {
      "epoch": 4.107142857142857,
      "grad_norm": 0.048675786703825,
      "learning_rate": 2.4339925889548643e-05,
      "loss": 0.0088,
      "step": 115000
    },
    {
      "epoch": 4.110714285714286,
      "grad_norm": 0.029768185690045357,
      "learning_rate": 2.4317603464440376e-05,
      "loss": 0.0096,
      "step": 115100
    },
    {
      "epoch": 4.114285714285714,
      "grad_norm": 0.046362683176994324,
      "learning_rate": 2.4295281039332113e-05,
      "loss": 0.0096,
      "step": 115200
    },
    {
      "epoch": 4.117857142857143,
      "grad_norm": 0.027244463562965393,
      "learning_rate": 2.427295861422385e-05,
      "loss": 0.0093,
      "step": 115300
    },
    {
      "epoch": 4.121428571428571,
      "grad_norm": 0.053145334124565125,
      "learning_rate": 2.4250636189115586e-05,
      "loss": 0.0098,
      "step": 115400
    },
    {
      "epoch": 4.125,
      "grad_norm": 0.03682558611035347,
      "learning_rate": 2.4228313764007325e-05,
      "loss": 0.0094,
      "step": 115500
    },
    {
      "epoch": 4.128571428571428,
      "grad_norm": 0.04638458415865898,
      "learning_rate": 2.4205991338899058e-05,
      "loss": 0.0095,
      "step": 115600
    },
    {
      "epoch": 4.132142857142857,
      "grad_norm": 0.034347984939813614,
      "learning_rate": 2.4183668913790795e-05,
      "loss": 0.01,
      "step": 115700
    },
    {
      "epoch": 4.135714285714286,
      "grad_norm": 0.04665824770927429,
      "learning_rate": 2.416134648868253e-05,
      "loss": 0.0095,
      "step": 115800
    },
    {
      "epoch": 4.139285714285714,
      "grad_norm": 0.05949734151363373,
      "learning_rate": 2.4139024063574267e-05,
      "loss": 0.0093,
      "step": 115900
    },
    {
      "epoch": 4.142857142857143,
      "grad_norm": 0.04316523298621178,
      "learning_rate": 2.4116701638466004e-05,
      "loss": 0.0094,
      "step": 116000
    },
    {
      "epoch": 4.146428571428571,
      "grad_norm": 0.05955630540847778,
      "learning_rate": 2.409437921335774e-05,
      "loss": 0.0094,
      "step": 116100
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.05413543060421944,
      "learning_rate": 2.4072056788249476e-05,
      "loss": 0.0094,
      "step": 116200
    },
    {
      "epoch": 4.1535714285714285,
      "grad_norm": 0.026707494631409645,
      "learning_rate": 2.4049734363141213e-05,
      "loss": 0.0098,
      "step": 116300
    },
    {
      "epoch": 4.1571428571428575,
      "grad_norm": 0.0571405328810215,
      "learning_rate": 2.402741193803295e-05,
      "loss": 0.0098,
      "step": 116400
    },
    {
      "epoch": 4.160714285714286,
      "grad_norm": 0.03355353698134422,
      "learning_rate": 2.4005089512924686e-05,
      "loss": 0.0097,
      "step": 116500
    },
    {
      "epoch": 4.164285714285715,
      "grad_norm": 0.07405636459589005,
      "learning_rate": 2.3982767087816422e-05,
      "loss": 0.0098,
      "step": 116600
    },
    {
      "epoch": 4.167857142857143,
      "grad_norm": 0.061500683426856995,
      "learning_rate": 2.396066788695924e-05,
      "loss": 0.0089,
      "step": 116700
    },
    {
      "epoch": 4.171428571428572,
      "grad_norm": 0.03791862353682518,
      "learning_rate": 2.3938345461850976e-05,
      "loss": 0.009,
      "step": 116800
    },
    {
      "epoch": 4.175,
      "grad_norm": 0.05219385772943497,
      "learning_rate": 2.3916023036742713e-05,
      "loss": 0.0102,
      "step": 116900
    },
    {
      "epoch": 4.178571428571429,
      "grad_norm": 0.0648776963353157,
      "learning_rate": 2.389370061163445e-05,
      "loss": 0.0093,
      "step": 117000
    },
    {
      "epoch": 4.182142857142857,
      "grad_norm": 0.047028057277202606,
      "learning_rate": 2.3871378186526185e-05,
      "loss": 0.0097,
      "step": 117100
    },
    {
      "epoch": 4.185714285714286,
      "grad_norm": 0.03886760398745537,
      "learning_rate": 2.3849055761417922e-05,
      "loss": 0.0093,
      "step": 117200
    },
    {
      "epoch": 4.189285714285714,
      "grad_norm": 0.033210258930921555,
      "learning_rate": 2.3826733336309658e-05,
      "loss": 0.0099,
      "step": 117300
    },
    {
      "epoch": 4.192857142857143,
      "grad_norm": 0.051129985600709915,
      "learning_rate": 2.3804410911201395e-05,
      "loss": 0.0095,
      "step": 117400
    },
    {
      "epoch": 4.196428571428571,
      "grad_norm": 0.0385076180100441,
      "learning_rate": 2.378208848609313e-05,
      "loss": 0.0092,
      "step": 117500
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.05835776776075363,
      "learning_rate": 2.3759766060984867e-05,
      "loss": 0.0102,
      "step": 117600
    },
    {
      "epoch": 4.203571428571428,
      "grad_norm": 0.037214457988739014,
      "learning_rate": 2.3737443635876604e-05,
      "loss": 0.0093,
      "step": 117700
    },
    {
      "epoch": 4.207142857142857,
      "grad_norm": 0.07712335884571075,
      "learning_rate": 2.371512121076834e-05,
      "loss": 0.0098,
      "step": 117800
    },
    {
      "epoch": 4.210714285714285,
      "grad_norm": 0.06368005275726318,
      "learning_rate": 2.3692798785660076e-05,
      "loss": 0.0094,
      "step": 117900
    },
    {
      "epoch": 4.214285714285714,
      "grad_norm": 0.05486639589071274,
      "learning_rate": 2.367047636055181e-05,
      "loss": 0.0101,
      "step": 118000
    },
    {
      "epoch": 4.2178571428571425,
      "grad_norm": 0.038479797542095184,
      "learning_rate": 2.364815393544355e-05,
      "loss": 0.0093,
      "step": 118100
    },
    {
      "epoch": 4.2214285714285715,
      "grad_norm": 0.028163935989141464,
      "learning_rate": 2.3625831510335282e-05,
      "loss": 0.0095,
      "step": 118200
    },
    {
      "epoch": 4.225,
      "grad_norm": 0.07560153305530548,
      "learning_rate": 2.3603509085227022e-05,
      "loss": 0.0083,
      "step": 118300
    },
    {
      "epoch": 4.228571428571429,
      "grad_norm": 0.07359336316585541,
      "learning_rate": 2.3581186660118755e-05,
      "loss": 0.0093,
      "step": 118400
    },
    {
      "epoch": 4.232142857142857,
      "grad_norm": 0.07355109602212906,
      "learning_rate": 2.355886423501049e-05,
      "loss": 0.0093,
      "step": 118500
    },
    {
      "epoch": 4.235714285714286,
      "grad_norm": 0.03746038302779198,
      "learning_rate": 2.353654180990223e-05,
      "loss": 0.0097,
      "step": 118600
    },
    {
      "epoch": 4.239285714285714,
      "grad_norm": 0.06486384570598602,
      "learning_rate": 2.3514219384793964e-05,
      "loss": 0.009,
      "step": 118700
    },
    {
      "epoch": 4.242857142857143,
      "grad_norm": Infinity,
      "learning_rate": 2.3492120183936782e-05,
      "loss": 0.009,
      "step": 118800
    },
    {
      "epoch": 4.246428571428572,
      "grad_norm": 0.07860399037599564,
      "learning_rate": 2.3469797758828522e-05,
      "loss": 0.0098,
      "step": 118900
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.051287129521369934,
      "learning_rate": 2.3447475333720255e-05,
      "loss": 0.0096,
      "step": 119000
    },
    {
      "epoch": 4.253571428571428,
      "grad_norm": 0.04215075075626373,
      "learning_rate": 2.342515290861199e-05,
      "loss": 0.0102,
      "step": 119100
    },
    {
      "epoch": 4.257142857142857,
      "grad_norm": 0.0402703657746315,
      "learning_rate": 2.340283048350373e-05,
      "loss": 0.0104,
      "step": 119200
    },
    {
      "epoch": 4.260714285714286,
      "grad_norm": 0.03472338616847992,
      "learning_rate": 2.3380508058395464e-05,
      "loss": 0.0095,
      "step": 119300
    },
    {
      "epoch": 4.264285714285714,
      "grad_norm": 0.046968746930360794,
      "learning_rate": 2.3358185633287204e-05,
      "loss": 0.009,
      "step": 119400
    },
    {
      "epoch": 4.267857142857143,
      "grad_norm": 0.018123775720596313,
      "learning_rate": 2.3335863208178937e-05,
      "loss": 0.0094,
      "step": 119500
    },
    {
      "epoch": 4.271428571428571,
      "grad_norm": 0.04626588523387909,
      "learning_rate": 2.3313540783070673e-05,
      "loss": 0.0096,
      "step": 119600
    },
    {
      "epoch": 4.275,
      "grad_norm": 0.031501322984695435,
      "learning_rate": 2.329121835796241e-05,
      "loss": 0.0099,
      "step": 119700
    },
    {
      "epoch": 4.2785714285714285,
      "grad_norm": 0.034997161477804184,
      "learning_rate": 2.3268895932854146e-05,
      "loss": 0.0091,
      "step": 119800
    },
    {
      "epoch": 4.2821428571428575,
      "grad_norm": 0.049201857298612595,
      "learning_rate": 2.3246573507745882e-05,
      "loss": 0.0095,
      "step": 119900
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.039732906967401505,
      "learning_rate": 2.322425108263762e-05,
      "loss": 0.0102,
      "step": 120000
    },
    {
      "epoch": 4.289285714285715,
      "grad_norm": 0.023056890815496445,
      "learning_rate": 2.3201928657529355e-05,
      "loss": 0.0095,
      "step": 120100
    },
    {
      "epoch": 4.292857142857143,
      "grad_norm": 0.050617873668670654,
      "learning_rate": 2.317960623242109e-05,
      "loss": 0.0103,
      "step": 120200
    },
    {
      "epoch": 4.296428571428572,
      "grad_norm": 0.042390126734972,
      "learning_rate": 2.3157283807312827e-05,
      "loss": 0.0094,
      "step": 120300
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.04097111150622368,
      "learning_rate": 2.3134961382204564e-05,
      "loss": 0.0094,
      "step": 120400
    },
    {
      "epoch": 4.303571428571429,
      "grad_norm": 0.07292564958333969,
      "learning_rate": 2.31126389570963e-05,
      "loss": 0.0092,
      "step": 120500
    },
    {
      "epoch": 4.307142857142857,
      "grad_norm": 0.026316698640584946,
      "learning_rate": 2.3090316531988037e-05,
      "loss": 0.009,
      "step": 120600
    },
    {
      "epoch": 4.310714285714286,
      "grad_norm": 0.04982367157936096,
      "learning_rate": 2.3067994106879773e-05,
      "loss": 0.0091,
      "step": 120700
    },
    {
      "epoch": 4.314285714285714,
      "grad_norm": 0.04135698452591896,
      "learning_rate": 2.304567168177151e-05,
      "loss": 0.0089,
      "step": 120800
    },
    {
      "epoch": 4.317857142857143,
      "grad_norm": 0.062448062002658844,
      "learning_rate": 2.3023349256663246e-05,
      "loss": 0.0102,
      "step": 120900
    },
    {
      "epoch": 4.321428571428571,
      "grad_norm": 0.06110735610127449,
      "learning_rate": 2.3001026831554982e-05,
      "loss": 0.0094,
      "step": 121000
    },
    {
      "epoch": 4.325,
      "grad_norm": 0.023576917126774788,
      "learning_rate": 2.297870440644672e-05,
      "loss": 0.0093,
      "step": 121100
    },
    {
      "epoch": 4.328571428571428,
      "grad_norm": 0.03737756609916687,
      "learning_rate": 2.2956381981338455e-05,
      "loss": 0.0094,
      "step": 121200
    },
    {
      "epoch": 4.332142857142857,
      "grad_norm": 0.03901967406272888,
      "learning_rate": 2.2934059556230188e-05,
      "loss": 0.0098,
      "step": 121300
    },
    {
      "epoch": 4.335714285714285,
      "grad_norm": 0.034858934581279755,
      "learning_rate": 2.2911737131121927e-05,
      "loss": 0.0098,
      "step": 121400
    },
    {
      "epoch": 4.339285714285714,
      "grad_norm": 0.035638485103845596,
      "learning_rate": 2.288941470601366e-05,
      "loss": 0.0093,
      "step": 121500
    },
    {
      "epoch": 4.3428571428571425,
      "grad_norm": 0.08576782047748566,
      "learning_rate": 2.2867315505156482e-05,
      "loss": 0.0095,
      "step": 121600
    },
    {
      "epoch": 4.3464285714285715,
      "grad_norm": 0.029654450714588165,
      "learning_rate": 2.284499308004822e-05,
      "loss": 0.0086,
      "step": 121700
    },
    {
      "epoch": 4.35,
      "grad_norm": 0.05931493267416954,
      "learning_rate": 2.2822670654939955e-05,
      "loss": 0.0089,
      "step": 121800
    },
    {
      "epoch": 4.353571428571429,
      "grad_norm": 0.038864221423864365,
      "learning_rate": 2.2800348229831688e-05,
      "loss": 0.0095,
      "step": 121900
    },
    {
      "epoch": 4.357142857142857,
      "grad_norm": 0.03665197640657425,
      "learning_rate": 2.2778025804723427e-05,
      "loss": 0.0104,
      "step": 122000
    },
    {
      "epoch": 4.360714285714286,
      "grad_norm": 0.040895212441682816,
      "learning_rate": 2.275570337961516e-05,
      "loss": 0.0095,
      "step": 122100
    },
    {
      "epoch": 4.364285714285714,
      "grad_norm": 0.060807302594184875,
      "learning_rate": 2.27333809545069e-05,
      "loss": 0.0091,
      "step": 122200
    },
    {
      "epoch": 4.367857142857143,
      "grad_norm": 0.14853380620479584,
      "learning_rate": 2.2711058529398637e-05,
      "loss": 0.0096,
      "step": 122300
    },
    {
      "epoch": 4.371428571428572,
      "grad_norm": 0.06496690958738327,
      "learning_rate": 2.268873610429037e-05,
      "loss": 0.0095,
      "step": 122400
    },
    {
      "epoch": 4.375,
      "grad_norm": 0.03703945875167847,
      "learning_rate": 2.266641367918211e-05,
      "loss": 0.0099,
      "step": 122500
    },
    {
      "epoch": 4.378571428571428,
      "grad_norm": 0.03297525644302368,
      "learning_rate": 2.2644091254073842e-05,
      "loss": 0.0096,
      "step": 122600
    },
    {
      "epoch": 4.382142857142857,
      "grad_norm": 0.05009325221180916,
      "learning_rate": 2.2621768828965582e-05,
      "loss": 0.0095,
      "step": 122700
    },
    {
      "epoch": 4.385714285714286,
      "grad_norm": 0.03861571103334427,
      "learning_rate": 2.2599446403857315e-05,
      "loss": 0.0093,
      "step": 122800
    },
    {
      "epoch": 4.389285714285714,
      "grad_norm": 0.03975943475961685,
      "learning_rate": 2.257712397874905e-05,
      "loss": 0.0091,
      "step": 122900
    },
    {
      "epoch": 4.392857142857143,
      "grad_norm": 0.05900800973176956,
      "learning_rate": 2.2554801553640788e-05,
      "loss": 0.0096,
      "step": 123000
    },
    {
      "epoch": 4.396428571428571,
      "grad_norm": 0.0659441202878952,
      "learning_rate": 2.2532479128532524e-05,
      "loss": 0.0092,
      "step": 123100
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.03244421258568764,
      "learning_rate": 2.2510156703424264e-05,
      "loss": 0.0096,
      "step": 123200
    },
    {
      "epoch": 4.4035714285714285,
      "grad_norm": 0.0447111539542675,
      "learning_rate": 2.2487834278315997e-05,
      "loss": 0.0101,
      "step": 123300
    },
    {
      "epoch": 4.4071428571428575,
      "grad_norm": 0.037847649306058884,
      "learning_rate": 2.2465511853207733e-05,
      "loss": 0.0091,
      "step": 123400
    },
    {
      "epoch": 4.410714285714286,
      "grad_norm": 0.03273982182145119,
      "learning_rate": 2.244318942809947e-05,
      "loss": 0.0101,
      "step": 123500
    },
    {
      "epoch": 4.414285714285715,
      "grad_norm": 0.022717125713825226,
      "learning_rate": 2.2420867002991206e-05,
      "loss": 0.0094,
      "step": 123600
    },
    {
      "epoch": 4.417857142857143,
      "grad_norm": 0.029240520671010017,
      "learning_rate": 2.2398544577882942e-05,
      "loss": 0.0097,
      "step": 123700
    },
    {
      "epoch": 4.421428571428572,
      "grad_norm": 0.08427172154188156,
      "learning_rate": 2.237622215277468e-05,
      "loss": 0.0087,
      "step": 123800
    },
    {
      "epoch": 4.425,
      "grad_norm": 0.041358139365911484,
      "learning_rate": 2.2354122951917497e-05,
      "loss": 0.0094,
      "step": 123900
    },
    {
      "epoch": 4.428571428571429,
      "grad_norm": 0.09400195628404617,
      "learning_rate": 2.2331800526809233e-05,
      "loss": 0.0091,
      "step": 124000
    },
    {
      "epoch": 4.432142857142857,
      "grad_norm": 0.08260633051395416,
      "learning_rate": 2.230947810170097e-05,
      "loss": 0.0093,
      "step": 124100
    },
    {
      "epoch": 4.435714285714286,
      "grad_norm": 0.03155757486820221,
      "learning_rate": 2.2287155676592706e-05,
      "loss": 0.009,
      "step": 124200
    },
    {
      "epoch": 4.439285714285714,
      "grad_norm": 0.07870730757713318,
      "learning_rate": 2.2264833251484442e-05,
      "loss": 0.0098,
      "step": 124300
    },
    {
      "epoch": 4.442857142857143,
      "grad_norm": 0.04591815173625946,
      "learning_rate": 2.224251082637618e-05,
      "loss": 0.0096,
      "step": 124400
    },
    {
      "epoch": 4.446428571428571,
      "grad_norm": 0.05304944887757301,
      "learning_rate": 2.2220188401267915e-05,
      "loss": 0.0089,
      "step": 124500
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.05528000742197037,
      "learning_rate": 2.219786597615965e-05,
      "loss": 0.0089,
      "step": 124600
    },
    {
      "epoch": 4.453571428571428,
      "grad_norm": 0.04438240826129913,
      "learning_rate": 2.2175543551051388e-05,
      "loss": 0.0092,
      "step": 124700
    },
    {
      "epoch": 4.457142857142857,
      "grad_norm": 0.03511805832386017,
      "learning_rate": 2.2153221125943124e-05,
      "loss": 0.0088,
      "step": 124800
    },
    {
      "epoch": 4.460714285714285,
      "grad_norm": 0.06265319138765335,
      "learning_rate": 2.213089870083486e-05,
      "loss": 0.0096,
      "step": 124900
    },
    {
      "epoch": 4.464285714285714,
      "grad_norm": 0.03271867334842682,
      "learning_rate": 2.2108576275726593e-05,
      "loss": 0.0092,
      "step": 125000
    },
    {
      "epoch": 4.4678571428571425,
      "grad_norm": 0.036140911281108856,
      "learning_rate": 2.2086253850618333e-05,
      "loss": 0.0087,
      "step": 125100
    },
    {
      "epoch": 4.4714285714285715,
      "grad_norm": 0.05847083032131195,
      "learning_rate": 2.2063931425510066e-05,
      "loss": 0.0095,
      "step": 125200
    },
    {
      "epoch": 4.475,
      "grad_norm": 0.0453355498611927,
      "learning_rate": 2.2041609000401806e-05,
      "loss": 0.0091,
      "step": 125300
    },
    {
      "epoch": 4.478571428571429,
      "grad_norm": 0.038154423236846924,
      "learning_rate": 2.2019286575293542e-05,
      "loss": 0.009,
      "step": 125400
    },
    {
      "epoch": 4.482142857142857,
      "grad_norm": 0.06318318843841553,
      "learning_rate": 2.199696415018528e-05,
      "loss": 0.0102,
      "step": 125500
    },
    {
      "epoch": 4.485714285714286,
      "grad_norm": 0.03747617453336716,
      "learning_rate": 2.1974641725077015e-05,
      "loss": 0.0096,
      "step": 125600
    },
    {
      "epoch": 4.489285714285714,
      "grad_norm": 0.043797217309474945,
      "learning_rate": 2.1952319299968748e-05,
      "loss": 0.0084,
      "step": 125700
    },
    {
      "epoch": 4.492857142857143,
      "grad_norm": 0.0451044961810112,
      "learning_rate": 2.1929996874860488e-05,
      "loss": 0.0095,
      "step": 125800
    },
    {
      "epoch": 4.496428571428572,
      "grad_norm": 0.06341379135847092,
      "learning_rate": 2.190767444975222e-05,
      "loss": 0.0094,
      "step": 125900
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.056663092225790024,
      "learning_rate": 2.1885575248895042e-05,
      "loss": 0.0092,
      "step": 126000
    },
    {
      "epoch": 4.503571428571428,
      "grad_norm": 0.031535569578409195,
      "learning_rate": 2.186325282378678e-05,
      "loss": 0.0097,
      "step": 126100
    },
    {
      "epoch": 4.507142857142857,
      "grad_norm": 0.052947599440813065,
      "learning_rate": 2.1840930398678515e-05,
      "loss": 0.0093,
      "step": 126200
    },
    {
      "epoch": 4.510714285714286,
      "grad_norm": 0.02337418869137764,
      "learning_rate": 2.1818607973570248e-05,
      "loss": 0.0094,
      "step": 126300
    },
    {
      "epoch": 4.514285714285714,
      "grad_norm": 0.04706718027591705,
      "learning_rate": 2.1796285548461988e-05,
      "loss": 0.0096,
      "step": 126400
    },
    {
      "epoch": 4.517857142857143,
      "grad_norm": 0.03662478178739548,
      "learning_rate": 2.177396312335372e-05,
      "loss": 0.0087,
      "step": 126500
    },
    {
      "epoch": 4.521428571428571,
      "grad_norm": 0.04590865969657898,
      "learning_rate": 2.175164069824546e-05,
      "loss": 0.0092,
      "step": 126600
    },
    {
      "epoch": 4.525,
      "grad_norm": 0.036001287400722504,
      "learning_rate": 2.1729318273137193e-05,
      "loss": 0.009,
      "step": 126700
    },
    {
      "epoch": 4.5285714285714285,
      "grad_norm": 0.036927927285432816,
      "learning_rate": 2.170699584802893e-05,
      "loss": 0.009,
      "step": 126800
    },
    {
      "epoch": 4.5321428571428575,
      "grad_norm": 0.04781877249479294,
      "learning_rate": 2.168467342292067e-05,
      "loss": 0.0088,
      "step": 126900
    },
    {
      "epoch": 4.535714285714286,
      "grad_norm": 0.04972226545214653,
      "learning_rate": 2.1662350997812402e-05,
      "loss": 0.0101,
      "step": 127000
    },
    {
      "epoch": 4.539285714285715,
      "grad_norm": 0.0293650534003973,
      "learning_rate": 2.1640028572704142e-05,
      "loss": 0.0101,
      "step": 127100
    },
    {
      "epoch": 4.542857142857143,
      "grad_norm": 0.05065211281180382,
      "learning_rate": 2.1617706147595875e-05,
      "loss": 0.0097,
      "step": 127200
    },
    {
      "epoch": 4.546428571428572,
      "grad_norm": 0.06627467274665833,
      "learning_rate": 2.159538372248761e-05,
      "loss": 0.0101,
      "step": 127300
    },
    {
      "epoch": 4.55,
      "grad_norm": 0.022824792191386223,
      "learning_rate": 2.1573061297379348e-05,
      "loss": 0.0099,
      "step": 127400
    },
    {
      "epoch": 4.553571428571429,
      "grad_norm": 0.028228914365172386,
      "learning_rate": 2.1550738872271084e-05,
      "loss": 0.0087,
      "step": 127500
    },
    {
      "epoch": 4.557142857142857,
      "grad_norm": 0.035516440868377686,
      "learning_rate": 2.152841644716282e-05,
      "loss": 0.0091,
      "step": 127600
    },
    {
      "epoch": 4.560714285714286,
      "grad_norm": 0.053697261959314346,
      "learning_rate": 2.1506094022054557e-05,
      "loss": 0.0095,
      "step": 127700
    },
    {
      "epoch": 4.564285714285714,
      "grad_norm": 0.04801231622695923,
      "learning_rate": 2.1483771596946293e-05,
      "loss": 0.0092,
      "step": 127800
    },
    {
      "epoch": 4.567857142857143,
      "grad_norm": 0.06443752348423004,
      "learning_rate": 2.146144917183803e-05,
      "loss": 0.0091,
      "step": 127900
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 0.04513094201683998,
      "learning_rate": 2.1439126746729766e-05,
      "loss": 0.0092,
      "step": 128000
    },
    {
      "epoch": 4.575,
      "grad_norm": 0.04280024766921997,
      "learning_rate": 2.1416804321621502e-05,
      "loss": 0.0096,
      "step": 128100
    },
    {
      "epoch": 4.578571428571428,
      "grad_norm": 0.04195557162165642,
      "learning_rate": 2.139448189651324e-05,
      "loss": 0.0091,
      "step": 128200
    },
    {
      "epoch": 4.582142857142857,
      "grad_norm": 0.018039196729660034,
      "learning_rate": 2.1372159471404972e-05,
      "loss": 0.0094,
      "step": 128300
    },
    {
      "epoch": 4.585714285714285,
      "grad_norm": 0.03907046839594841,
      "learning_rate": 2.134983704629671e-05,
      "loss": 0.0097,
      "step": 128400
    },
    {
      "epoch": 4.589285714285714,
      "grad_norm": 0.08848419785499573,
      "learning_rate": 2.1327514621188448e-05,
      "loss": 0.0089,
      "step": 128500
    },
    {
      "epoch": 4.5928571428571425,
      "grad_norm": 0.05424267426133156,
      "learning_rate": 2.1305415420331266e-05,
      "loss": 0.0096,
      "step": 128600
    },
    {
      "epoch": 4.5964285714285715,
      "grad_norm": 0.04087440297007561,
      "learning_rate": 2.1283092995223002e-05,
      "loss": 0.0095,
      "step": 128700
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.045951154083013535,
      "learning_rate": 2.126077057011474e-05,
      "loss": 0.0092,
      "step": 128800
    },
    {
      "epoch": 4.603571428571429,
      "grad_norm": 0.0638037621974945,
      "learning_rate": 2.123844814500647e-05,
      "loss": 0.0089,
      "step": 128900
    },
    {
      "epoch": 4.607142857142857,
      "grad_norm": 0.08694040030241013,
      "learning_rate": 2.121612571989821e-05,
      "loss": 0.0095,
      "step": 129000
    },
    {
      "epoch": 4.610714285714286,
      "grad_norm": 0.04523724690079689,
      "learning_rate": 2.1193803294789948e-05,
      "loss": 0.01,
      "step": 129100
    },
    {
      "epoch": 4.614285714285714,
      "grad_norm": 0.05043169856071472,
      "learning_rate": 2.1171480869681684e-05,
      "loss": 0.0089,
      "step": 129200
    },
    {
      "epoch": 4.617857142857143,
      "grad_norm": 0.04777491092681885,
      "learning_rate": 2.114915844457342e-05,
      "loss": 0.0093,
      "step": 129300
    },
    {
      "epoch": 4.621428571428572,
      "grad_norm": 0.07243377715349197,
      "learning_rate": 2.1126836019465153e-05,
      "loss": 0.0099,
      "step": 129400
    },
    {
      "epoch": 4.625,
      "grad_norm": 0.04966035112738609,
      "learning_rate": 2.1104513594356893e-05,
      "loss": 0.0091,
      "step": 129500
    },
    {
      "epoch": 4.628571428571428,
      "grad_norm": 0.08554460108280182,
      "learning_rate": 2.1082191169248626e-05,
      "loss": 0.0105,
      "step": 129600
    },
    {
      "epoch": 4.632142857142857,
      "grad_norm": 0.04439549520611763,
      "learning_rate": 2.1059868744140366e-05,
      "loss": 0.0092,
      "step": 129700
    },
    {
      "epoch": 4.635714285714286,
      "grad_norm": 0.04475290700793266,
      "learning_rate": 2.10375463190321e-05,
      "loss": 0.0094,
      "step": 129800
    },
    {
      "epoch": 4.639285714285714,
      "grad_norm": 0.056194107979536057,
      "learning_rate": 2.101544711817492e-05,
      "loss": 0.0091,
      "step": 129900
    },
    {
      "epoch": 4.642857142857143,
      "grad_norm": 0.05563715845346451,
      "learning_rate": 2.0993124693066657e-05,
      "loss": 0.0091,
      "step": 130000
    },
    {
      "epoch": 4.646428571428571,
      "grad_norm": 0.032537493854761124,
      "learning_rate": 2.0970802267958393e-05,
      "loss": 0.0092,
      "step": 130100
    },
    {
      "epoch": 4.65,
      "grad_norm": 0.034892741590738297,
      "learning_rate": 2.0948479842850126e-05,
      "loss": 0.0086,
      "step": 130200
    },
    {
      "epoch": 4.6535714285714285,
      "grad_norm": 0.056159742176532745,
      "learning_rate": 2.0926157417741866e-05,
      "loss": 0.0093,
      "step": 130300
    },
    {
      "epoch": 4.6571428571428575,
      "grad_norm": 0.04384377971291542,
      "learning_rate": 2.09038349926336e-05,
      "loss": 0.0098,
      "step": 130400
    },
    {
      "epoch": 4.660714285714286,
      "grad_norm": 0.04692019894719124,
      "learning_rate": 2.088151256752534e-05,
      "loss": 0.0098,
      "step": 130500
    },
    {
      "epoch": 4.664285714285715,
      "grad_norm": 0.059713639318943024,
      "learning_rate": 2.0859190142417075e-05,
      "loss": 0.0093,
      "step": 130600
    },
    {
      "epoch": 4.667857142857143,
      "grad_norm": 0.03965867683291435,
      "learning_rate": 2.0836867717308808e-05,
      "loss": 0.009,
      "step": 130700
    },
    {
      "epoch": 4.671428571428572,
      "grad_norm": 0.039841409772634506,
      "learning_rate": 2.0814545292200548e-05,
      "loss": 0.0092,
      "step": 130800
    },
    {
      "epoch": 4.675,
      "grad_norm": 0.05177033320069313,
      "learning_rate": 2.079222286709228e-05,
      "loss": 0.0093,
      "step": 130900
    },
    {
      "epoch": 4.678571428571429,
      "grad_norm": 0.02630198746919632,
      "learning_rate": 2.076990044198402e-05,
      "loss": 0.0096,
      "step": 131000
    },
    {
      "epoch": 4.682142857142857,
      "grad_norm": 0.04170823469758034,
      "learning_rate": 2.0747578016875753e-05,
      "loss": 0.0098,
      "step": 131100
    },
    {
      "epoch": 4.685714285714286,
      "grad_norm": 0.026971224695444107,
      "learning_rate": 2.072525559176749e-05,
      "loss": 0.0092,
      "step": 131200
    },
    {
      "epoch": 4.689285714285714,
      "grad_norm": 0.043192651122808456,
      "learning_rate": 2.0702933166659226e-05,
      "loss": 0.0092,
      "step": 131300
    },
    {
      "epoch": 4.692857142857143,
      "grad_norm": 0.05103975161910057,
      "learning_rate": 2.0680610741550962e-05,
      "loss": 0.0089,
      "step": 131400
    },
    {
      "epoch": 4.696428571428571,
      "grad_norm": 0.04625682160258293,
      "learning_rate": 2.06582883164427e-05,
      "loss": 0.0097,
      "step": 131500
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.04304824769496918,
      "learning_rate": 2.0635965891334435e-05,
      "loss": 0.009,
      "step": 131600
    },
    {
      "epoch": 4.703571428571428,
      "grad_norm": 0.03903314843773842,
      "learning_rate": 2.061364346622617e-05,
      "loss": 0.0098,
      "step": 131700
    },
    {
      "epoch": 4.707142857142857,
      "grad_norm": 0.05468221381306648,
      "learning_rate": 2.0591321041117908e-05,
      "loss": 0.0092,
      "step": 131800
    },
    {
      "epoch": 4.710714285714285,
      "grad_norm": 0.039701901376247406,
      "learning_rate": 2.0568998616009644e-05,
      "loss": 0.0101,
      "step": 131900
    },
    {
      "epoch": 4.714285714285714,
      "grad_norm": 0.031722523272037506,
      "learning_rate": 2.054667619090138e-05,
      "loss": 0.0093,
      "step": 132000
    },
    {
      "epoch": 4.7178571428571425,
      "grad_norm": 0.06642355769872665,
      "learning_rate": 2.0524353765793117e-05,
      "loss": 0.009,
      "step": 132100
    },
    {
      "epoch": 4.7214285714285715,
      "grad_norm": 0.048836711794137955,
      "learning_rate": 2.0502031340684853e-05,
      "loss": 0.0101,
      "step": 132200
    },
    {
      "epoch": 4.725,
      "grad_norm": 0.027131343260407448,
      "learning_rate": 2.047970891557659e-05,
      "loss": 0.0091,
      "step": 132300
    },
    {
      "epoch": 4.728571428571429,
      "grad_norm": 0.06197066605091095,
      "learning_rate": 2.0457386490468326e-05,
      "loss": 0.0101,
      "step": 132400
    },
    {
      "epoch": 4.732142857142857,
      "grad_norm": 0.0439617894589901,
      "learning_rate": 2.0435064065360062e-05,
      "loss": 0.0086,
      "step": 132500
    },
    {
      "epoch": 4.735714285714286,
      "grad_norm": 0.04609838128089905,
      "learning_rate": 2.04127416402518e-05,
      "loss": 0.0093,
      "step": 132600
    },
    {
      "epoch": 4.739285714285714,
      "grad_norm": 0.04840259999036789,
      "learning_rate": 2.0390419215143532e-05,
      "loss": 0.0096,
      "step": 132700
    },
    {
      "epoch": 4.742857142857143,
      "grad_norm": 0.033306483179330826,
      "learning_rate": 2.036809679003527e-05,
      "loss": 0.0086,
      "step": 132800
    },
    {
      "epoch": 4.746428571428572,
      "grad_norm": 0.04387444257736206,
      "learning_rate": 2.0345774364927005e-05,
      "loss": 0.0098,
      "step": 132900
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.04414323344826698,
      "learning_rate": 2.0323451939818744e-05,
      "loss": 0.0098,
      "step": 133000
    },
    {
      "epoch": 4.753571428571428,
      "grad_norm": 0.042866695672273636,
      "learning_rate": 2.030112951471048e-05,
      "loss": 0.0089,
      "step": 133100
    },
    {
      "epoch": 4.757142857142857,
      "grad_norm": 0.044204823672771454,
      "learning_rate": 2.0278807089602214e-05,
      "loss": 0.0089,
      "step": 133200
    },
    {
      "epoch": 4.760714285714286,
      "grad_norm": 0.04951709508895874,
      "learning_rate": 2.0256484664493953e-05,
      "loss": 0.0089,
      "step": 133300
    },
    {
      "epoch": 4.764285714285714,
      "grad_norm": 0.0380827933549881,
      "learning_rate": 2.0234162239385686e-05,
      "loss": 0.0095,
      "step": 133400
    },
    {
      "epoch": 4.767857142857143,
      "grad_norm": 0.025617683306336403,
      "learning_rate": 2.0211839814277426e-05,
      "loss": 0.0091,
      "step": 133500
    },
    {
      "epoch": 4.771428571428571,
      "grad_norm": 0.03659337759017944,
      "learning_rate": 2.018951738916916e-05,
      "loss": 0.008,
      "step": 133600
    },
    {
      "epoch": 4.775,
      "grad_norm": 0.04290534928441048,
      "learning_rate": 2.0167194964060895e-05,
      "loss": 0.0085,
      "step": 133700
    },
    {
      "epoch": 4.7785714285714285,
      "grad_norm": 0.07209691405296326,
      "learning_rate": 2.0144872538952632e-05,
      "loss": 0.0096,
      "step": 133800
    },
    {
      "epoch": 4.7821428571428575,
      "grad_norm": 0.05297110229730606,
      "learning_rate": 2.0122550113844368e-05,
      "loss": 0.0084,
      "step": 133900
    },
    {
      "epoch": 4.785714285714286,
      "grad_norm": 0.04723932221531868,
      "learning_rate": 2.0100227688736108e-05,
      "loss": 0.0096,
      "step": 134000
    },
    {
      "epoch": 4.789285714285715,
      "grad_norm": 0.03344087302684784,
      "learning_rate": 2.007790526362784e-05,
      "loss": 0.009,
      "step": 134100
    },
    {
      "epoch": 4.792857142857143,
      "grad_norm": 0.05356580391526222,
      "learning_rate": 2.0055582838519577e-05,
      "loss": 0.0099,
      "step": 134200
    },
    {
      "epoch": 4.796428571428572,
      "grad_norm": 0.042737387120723724,
      "learning_rate": 2.0033260413411314e-05,
      "loss": 0.0093,
      "step": 134300
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.03561196103692055,
      "learning_rate": 2.001093798830305e-05,
      "loss": 0.0097,
      "step": 134400
    },
    {
      "epoch": 4.803571428571429,
      "grad_norm": 0.03978953883051872,
      "learning_rate": 1.9988838787445868e-05,
      "loss": 0.0094,
      "step": 134500
    },
    {
      "epoch": 4.807142857142857,
      "grad_norm": 0.05888774245977402,
      "learning_rate": 1.9966516362337604e-05,
      "loss": 0.0095,
      "step": 134600
    },
    {
      "epoch": 4.810714285714286,
      "grad_norm": 0.02447325736284256,
      "learning_rate": 1.994419393722934e-05,
      "loss": 0.0086,
      "step": 134700
    },
    {
      "epoch": 4.814285714285714,
      "grad_norm": 0.054036565124988556,
      "learning_rate": 1.992187151212108e-05,
      "loss": 0.0091,
      "step": 134800
    },
    {
      "epoch": 4.817857142857143,
      "grad_norm": 0.04144490510225296,
      "learning_rate": 1.9899549087012814e-05,
      "loss": 0.0087,
      "step": 134900
    },
    {
      "epoch": 4.821428571428571,
      "grad_norm": 0.044084567576646805,
      "learning_rate": 1.987722666190455e-05,
      "loss": 0.009,
      "step": 135000
    },
    {
      "epoch": 4.825,
      "grad_norm": 0.04050574451684952,
      "learning_rate": 1.9854904236796286e-05,
      "loss": 0.009,
      "step": 135100
    },
    {
      "epoch": 4.828571428571428,
      "grad_norm": 0.041478388011455536,
      "learning_rate": 1.9832581811688023e-05,
      "loss": 0.0084,
      "step": 135200
    },
    {
      "epoch": 4.832142857142857,
      "grad_norm": 0.06181642785668373,
      "learning_rate": 1.981025938657976e-05,
      "loss": 0.0093,
      "step": 135300
    },
    {
      "epoch": 4.835714285714285,
      "grad_norm": 0.04200276732444763,
      "learning_rate": 1.9787936961471495e-05,
      "loss": 0.0089,
      "step": 135400
    },
    {
      "epoch": 4.839285714285714,
      "grad_norm": 0.03373954817652702,
      "learning_rate": 1.9765614536363232e-05,
      "loss": 0.0089,
      "step": 135500
    },
    {
      "epoch": 4.8428571428571425,
      "grad_norm": 0.055632032454013824,
      "learning_rate": 1.9743292111254968e-05,
      "loss": 0.0091,
      "step": 135600
    },
    {
      "epoch": 4.8464285714285715,
      "grad_norm": 0.03553342819213867,
      "learning_rate": 1.9720969686146705e-05,
      "loss": 0.0093,
      "step": 135700
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.0491938591003418,
      "learning_rate": 1.969864726103844e-05,
      "loss": 0.0106,
      "step": 135800
    },
    {
      "epoch": 4.853571428571429,
      "grad_norm": 0.03155864030122757,
      "learning_rate": 1.9676324835930177e-05,
      "loss": 0.0083,
      "step": 135900
    },
    {
      "epoch": 4.857142857142857,
      "grad_norm": 0.055489327758550644,
      "learning_rate": 1.965400241082191e-05,
      "loss": 0.0092,
      "step": 136000
    },
    {
      "epoch": 4.860714285714286,
      "grad_norm": 0.057012297213077545,
      "learning_rate": 1.963167998571365e-05,
      "loss": 0.0094,
      "step": 136100
    },
    {
      "epoch": 4.864285714285714,
      "grad_norm": 0.04934137314558029,
      "learning_rate": 1.9609357560605386e-05,
      "loss": 0.0091,
      "step": 136200
    },
    {
      "epoch": 4.867857142857143,
      "grad_norm": 0.049568064510822296,
      "learning_rate": 1.9587035135497123e-05,
      "loss": 0.0091,
      "step": 136300
    },
    {
      "epoch": 4.871428571428572,
      "grad_norm": 0.0751975029706955,
      "learning_rate": 1.956471271038886e-05,
      "loss": 0.0089,
      "step": 136400
    },
    {
      "epoch": 4.875,
      "grad_norm": 0.030460229143500328,
      "learning_rate": 1.9542390285280592e-05,
      "loss": 0.0094,
      "step": 136500
    },
    {
      "epoch": 4.878571428571428,
      "grad_norm": 0.05326502397656441,
      "learning_rate": 1.952029108442341e-05,
      "loss": 0.0091,
      "step": 136600
    },
    {
      "epoch": 4.882142857142857,
      "grad_norm": 0.05786534398794174,
      "learning_rate": 1.949796865931515e-05,
      "loss": 0.0091,
      "step": 136700
    },
    {
      "epoch": 4.885714285714286,
      "grad_norm": 0.04863574728369713,
      "learning_rate": 1.9475646234206886e-05,
      "loss": 0.0095,
      "step": 136800
    },
    {
      "epoch": 4.889285714285714,
      "grad_norm": 0.022226087749004364,
      "learning_rate": 1.9453323809098623e-05,
      "loss": 0.0092,
      "step": 136900
    },
    {
      "epoch": 4.892857142857143,
      "grad_norm": 0.052755214273929596,
      "learning_rate": 1.943100138399036e-05,
      "loss": 0.0087,
      "step": 137000
    },
    {
      "epoch": 4.896428571428571,
      "grad_norm": 0.04934399574995041,
      "learning_rate": 1.9408678958882092e-05,
      "loss": 0.0091,
      "step": 137100
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.033964596688747406,
      "learning_rate": 1.9386356533773832e-05,
      "loss": 0.0084,
      "step": 137200
    },
    {
      "epoch": 4.9035714285714285,
      "grad_norm": 0.043002400547266006,
      "learning_rate": 1.9364034108665565e-05,
      "loss": 0.0083,
      "step": 137300
    },
    {
      "epoch": 4.9071428571428575,
      "grad_norm": 0.05825543776154518,
      "learning_rate": 1.9341711683557304e-05,
      "loss": 0.0096,
      "step": 137400
    },
    {
      "epoch": 4.910714285714286,
      "grad_norm": 0.03688294440507889,
      "learning_rate": 1.9319389258449037e-05,
      "loss": 0.0093,
      "step": 137500
    },
    {
      "epoch": 4.914285714285715,
      "grad_norm": 0.03803833946585655,
      "learning_rate": 1.9297066833340774e-05,
      "loss": 0.0097,
      "step": 137600
    },
    {
      "epoch": 4.917857142857143,
      "grad_norm": 0.07193988561630249,
      "learning_rate": 1.927474440823251e-05,
      "loss": 0.0091,
      "step": 137700
    },
    {
      "epoch": 4.921428571428572,
      "grad_norm": 0.07764877378940582,
      "learning_rate": 1.9252421983124247e-05,
      "loss": 0.0086,
      "step": 137800
    },
    {
      "epoch": 4.925,
      "grad_norm": 0.06879759579896927,
      "learning_rate": 1.9230099558015986e-05,
      "loss": 0.0093,
      "step": 137900
    },
    {
      "epoch": 4.928571428571429,
      "grad_norm": 0.07166603952646255,
      "learning_rate": 1.920777713290772e-05,
      "loss": 0.0092,
      "step": 138000
    },
    {
      "epoch": 4.932142857142857,
      "grad_norm": 0.05536596104502678,
      "learning_rate": 1.9185454707799456e-05,
      "loss": 0.0095,
      "step": 138100
    },
    {
      "epoch": 4.935714285714286,
      "grad_norm": 0.07621131837368011,
      "learning_rate": 1.9163132282691192e-05,
      "loss": 0.0094,
      "step": 138200
    },
    {
      "epoch": 4.939285714285714,
      "grad_norm": 0.048355583101511,
      "learning_rate": 1.914080985758293e-05,
      "loss": 0.0091,
      "step": 138300
    },
    {
      "epoch": 4.942857142857143,
      "grad_norm": 0.05285156890749931,
      "learning_rate": 1.9118487432474665e-05,
      "loss": 0.009,
      "step": 138400
    },
    {
      "epoch": 4.946428571428571,
      "grad_norm": 0.06525752693414688,
      "learning_rate": 1.90961650073664e-05,
      "loss": 0.0093,
      "step": 138500
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.03740627318620682,
      "learning_rate": 1.9073842582258137e-05,
      "loss": 0.009,
      "step": 138600
    },
    {
      "epoch": 4.953571428571428,
      "grad_norm": 0.03117406740784645,
      "learning_rate": 1.9051520157149874e-05,
      "loss": 0.0095,
      "step": 138700
    },
    {
      "epoch": 4.957142857142857,
      "grad_norm": 0.04616665467619896,
      "learning_rate": 1.902919773204161e-05,
      "loss": 0.0094,
      "step": 138800
    },
    {
      "epoch": 4.960714285714285,
      "grad_norm": 0.043186284601688385,
      "learning_rate": 1.9006875306933347e-05,
      "loss": 0.0089,
      "step": 138900
    },
    {
      "epoch": 4.964285714285714,
      "grad_norm": 0.06735117733478546,
      "learning_rate": 1.8984552881825083e-05,
      "loss": 0.009,
      "step": 139000
    },
    {
      "epoch": 4.9678571428571425,
      "grad_norm": 0.052152909338474274,
      "learning_rate": 1.89624536809679e-05,
      "loss": 0.0096,
      "step": 139100
    },
    {
      "epoch": 4.9714285714285715,
      "grad_norm": 0.07776317000389099,
      "learning_rate": 1.8940131255859637e-05,
      "loss": 0.0099,
      "step": 139200
    },
    {
      "epoch": 4.975,
      "grad_norm": 0.07602345943450928,
      "learning_rate": 1.8917808830751374e-05,
      "loss": 0.0093,
      "step": 139300
    },
    {
      "epoch": 4.978571428571429,
      "grad_norm": 0.10116582363843918,
      "learning_rate": 1.889548640564311e-05,
      "loss": 0.0091,
      "step": 139400
    },
    {
      "epoch": 4.982142857142857,
      "grad_norm": 0.041539546102285385,
      "learning_rate": 1.8873163980534846e-05,
      "loss": 0.01,
      "step": 139500
    },
    {
      "epoch": 4.985714285714286,
      "grad_norm": 0.05378333851695061,
      "learning_rate": 1.8850841555426583e-05,
      "loss": 0.0093,
      "step": 139600
    },
    {
      "epoch": 4.989285714285714,
      "grad_norm": 0.046678368002176285,
      "learning_rate": 1.882851913031832e-05,
      "loss": 0.0092,
      "step": 139700
    },
    {
      "epoch": 4.992857142857143,
      "grad_norm": 0.042232196778059006,
      "learning_rate": 1.8806196705210056e-05,
      "loss": 0.0086,
      "step": 139800
    },
    {
      "epoch": 4.996428571428572,
      "grad_norm": 0.04658464714884758,
      "learning_rate": 1.8783874280101792e-05,
      "loss": 0.0092,
      "step": 139900
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.045922886580228806,
      "learning_rate": 1.8761551854993528e-05,
      "loss": 0.0097,
      "step": 140000
    },
    {
      "epoch": 5.0,
      "eval_accuracy_macro_0.5": 0.9966867566108704,
      "eval_accuracy_micro_0.5": 0.9966867566108704,
      "eval_accuracy_weighted_0.5": 0.9927047491073608,
      "eval_aucroc_macro": 0.8385359644889832,
      "eval_aucroc_micro": 0.8892092704772949,
      "eval_aucroc_weighted": 0.8877576589584351,
      "eval_f1_macro_0.5": 0.47257909178733826,
      "eval_f1_macro_0.6": 0.38797107338905334,
      "eval_f1_macro_0.7": 0.30113059282302856,
      "eval_f1_macro_0.8": 0.11627963185310364,
      "eval_f1_micro_0.5": 0.6498023867607117,
      "eval_f1_micro_0.6": 0.589738130569458,
      "eval_f1_micro_0.7": 0.4981320798397064,
      "eval_f1_micro_0.8": 0.3758956491947174,
      "eval_f1_micro_0.9": 0.2076910436153412,
      "eval_f1_weighted_0.5": 0.5938537120819092,
      "eval_f1_weighted_0.6": 0.521509051322937,
      "eval_f1_weighted_0.7": 0.4241359531879425,
      "eval_f1_weighted_0.8": 0.16494615375995636,
      "eval_loss": 0.007899136282503605,
      "eval_runtime": 1343.1542,
      "eval_samples_per_second": 41.44,
      "eval_steps_per_second": 5.18,
      "step": 140000
    },
    {
      "epoch": 5.003571428571429,
      "grad_norm": 0.03536677360534668,
      "learning_rate": 1.8739229429885265e-05,
      "loss": 0.0093,
      "step": 140100
    },
    {
      "epoch": 5.007142857142857,
      "grad_norm": 0.038306932896375656,
      "learning_rate": 1.8716907004777e-05,
      "loss": 0.009,
      "step": 140200
    },
    {
      "epoch": 5.010714285714286,
      "grad_norm": 0.04840536788105965,
      "learning_rate": 1.8694584579668737e-05,
      "loss": 0.009,
      "step": 140300
    },
    {
      "epoch": 5.014285714285714,
      "grad_norm": 0.04988725483417511,
      "learning_rate": 1.867226215456047e-05,
      "loss": 0.0096,
      "step": 140400
    },
    {
      "epoch": 5.017857142857143,
      "grad_norm": 0.036887411028146744,
      "learning_rate": 1.864993972945221e-05,
      "loss": 0.0094,
      "step": 140500
    },
    {
      "epoch": 5.021428571428571,
      "grad_norm": 0.07336657494306564,
      "learning_rate": 1.8627617304343943e-05,
      "loss": 0.0088,
      "step": 140600
    },
    {
      "epoch": 5.025,
      "grad_norm": 0.04501909390091896,
      "learning_rate": 1.8605294879235683e-05,
      "loss": 0.0092,
      "step": 140700
    },
    {
      "epoch": 5.0285714285714285,
      "grad_norm": 0.04017364978790283,
      "learning_rate": 1.8582972454127416e-05,
      "loss": 0.0091,
      "step": 140800
    },
    {
      "epoch": 5.0321428571428575,
      "grad_norm": 0.040900394320487976,
      "learning_rate": 1.8560650029019152e-05,
      "loss": 0.009,
      "step": 140900
    },
    {
      "epoch": 5.035714285714286,
      "grad_norm": 0.05153121426701546,
      "learning_rate": 1.8538327603910892e-05,
      "loss": 0.0097,
      "step": 141000
    },
    {
      "epoch": 5.039285714285715,
      "grad_norm": 0.07637661695480347,
      "learning_rate": 1.851622840305371e-05,
      "loss": 0.0099,
      "step": 141100
    },
    {
      "epoch": 5.042857142857143,
      "grad_norm": 0.04678220674395561,
      "learning_rate": 1.8493905977945443e-05,
      "loss": 0.0087,
      "step": 141200
    },
    {
      "epoch": 5.046428571428572,
      "grad_norm": 0.06094030290842056,
      "learning_rate": 1.8471583552837183e-05,
      "loss": 0.0086,
      "step": 141300
    },
    {
      "epoch": 5.05,
      "grad_norm": 0.04770508408546448,
      "learning_rate": 1.8449261127728916e-05,
      "loss": 0.0093,
      "step": 141400
    },
    {
      "epoch": 5.053571428571429,
      "grad_norm": 0.044702187180519104,
      "learning_rate": 1.8426938702620652e-05,
      "loss": 0.0098,
      "step": 141500
    },
    {
      "epoch": 5.057142857142857,
      "grad_norm": 0.08723841607570648,
      "learning_rate": 1.8404616277512392e-05,
      "loss": 0.0098,
      "step": 141600
    },
    {
      "epoch": 5.060714285714286,
      "grad_norm": 0.024032708257436752,
      "learning_rate": 1.8382293852404125e-05,
      "loss": 0.009,
      "step": 141700
    },
    {
      "epoch": 5.064285714285714,
      "grad_norm": 0.04057665541768074,
      "learning_rate": 1.8359971427295865e-05,
      "loss": 0.0095,
      "step": 141800
    },
    {
      "epoch": 5.067857142857143,
      "grad_norm": 0.0376264713704586,
      "learning_rate": 1.8337649002187598e-05,
      "loss": 0.0089,
      "step": 141900
    },
    {
      "epoch": 5.071428571428571,
      "grad_norm": 0.07188239693641663,
      "learning_rate": 1.8315326577079334e-05,
      "loss": 0.0095,
      "step": 142000
    },
    {
      "epoch": 5.075,
      "grad_norm": 0.06342890858650208,
      "learning_rate": 1.829300415197107e-05,
      "loss": 0.0088,
      "step": 142100
    },
    {
      "epoch": 5.078571428571428,
      "grad_norm": 0.0723673403263092,
      "learning_rate": 1.8270681726862807e-05,
      "loss": 0.0095,
      "step": 142200
    },
    {
      "epoch": 5.082142857142857,
      "grad_norm": 0.042607709765434265,
      "learning_rate": 1.8248359301754543e-05,
      "loss": 0.009,
      "step": 142300
    },
    {
      "epoch": 5.085714285714285,
      "grad_norm": 0.026103977113962173,
      "learning_rate": 1.822603687664628e-05,
      "loss": 0.0088,
      "step": 142400
    },
    {
      "epoch": 5.089285714285714,
      "grad_norm": 0.05923955887556076,
      "learning_rate": 1.8203714451538016e-05,
      "loss": 0.0093,
      "step": 142500
    },
    {
      "epoch": 5.0928571428571425,
      "grad_norm": 0.029921749606728554,
      "learning_rate": 1.8181392026429752e-05,
      "loss": 0.009,
      "step": 142600
    },
    {
      "epoch": 5.0964285714285715,
      "grad_norm": 0.058356933295726776,
      "learning_rate": 1.815906960132149e-05,
      "loss": 0.0087,
      "step": 142700
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.023181263357400894,
      "learning_rate": 1.8136747176213225e-05,
      "loss": 0.0091,
      "step": 142800
    },
    {
      "epoch": 5.103571428571429,
      "grad_norm": 0.030860427767038345,
      "learning_rate": 1.811442475110496e-05,
      "loss": 0.0089,
      "step": 142900
    },
    {
      "epoch": 5.107142857142857,
      "grad_norm": 0.04751095920801163,
      "learning_rate": 1.8092102325996698e-05,
      "loss": 0.0096,
      "step": 143000
    },
    {
      "epoch": 5.110714285714286,
      "grad_norm": 0.02245081588625908,
      "learning_rate": 1.8069779900888434e-05,
      "loss": 0.0083,
      "step": 143100
    },
    {
      "epoch": 5.114285714285714,
      "grad_norm": 0.045239079743623734,
      "learning_rate": 1.8047680700031252e-05,
      "loss": 0.0097,
      "step": 143200
    },
    {
      "epoch": 5.117857142857143,
      "grad_norm": 0.05181805044412613,
      "learning_rate": 1.802535827492299e-05,
      "loss": 0.0089,
      "step": 143300
    },
    {
      "epoch": 5.121428571428571,
      "grad_norm": 0.03161041811108589,
      "learning_rate": 1.8003035849814725e-05,
      "loss": 0.0092,
      "step": 143400
    },
    {
      "epoch": 5.125,
      "grad_norm": 0.03561227023601532,
      "learning_rate": 1.798071342470646e-05,
      "loss": 0.0089,
      "step": 143500
    },
    {
      "epoch": 5.128571428571428,
      "grad_norm": 0.03319674730300903,
      "learning_rate": 1.7958390999598197e-05,
      "loss": 0.0095,
      "step": 143600
    },
    {
      "epoch": 5.132142857142857,
      "grad_norm": 0.04228946566581726,
      "learning_rate": 1.7936068574489934e-05,
      "loss": 0.0089,
      "step": 143700
    },
    {
      "epoch": 5.135714285714286,
      "grad_norm": 0.051790837198495865,
      "learning_rate": 1.791374614938167e-05,
      "loss": 0.0097,
      "step": 143800
    },
    {
      "epoch": 5.139285714285714,
      "grad_norm": 0.0735366940498352,
      "learning_rate": 1.7891646948524488e-05,
      "loss": 0.0092,
      "step": 143900
    },
    {
      "epoch": 5.142857142857143,
      "grad_norm": 0.05372263118624687,
      "learning_rate": 1.7869324523416225e-05,
      "loss": 0.0085,
      "step": 144000
    },
    {
      "epoch": 5.146428571428571,
      "grad_norm": 0.03886852413415909,
      "learning_rate": 1.784700209830796e-05,
      "loss": 0.0094,
      "step": 144100
    },
    {
      "epoch": 5.15,
      "grad_norm": 0.05421501770615578,
      "learning_rate": 1.7824679673199697e-05,
      "loss": 0.0089,
      "step": 144200
    },
    {
      "epoch": 5.1535714285714285,
      "grad_norm": 0.08838672190904617,
      "learning_rate": 1.7802357248091434e-05,
      "loss": 0.009,
      "step": 144300
    },
    {
      "epoch": 5.1571428571428575,
      "grad_norm": 0.02808406390249729,
      "learning_rate": 1.778003482298317e-05,
      "loss": 0.0092,
      "step": 144400
    },
    {
      "epoch": 5.160714285714286,
      "grad_norm": 0.04417997971177101,
      "learning_rate": 1.7757712397874906e-05,
      "loss": 0.0089,
      "step": 144500
    },
    {
      "epoch": 5.164285714285715,
      "grad_norm": 0.05056041479110718,
      "learning_rate": 1.7735389972766643e-05,
      "loss": 0.0089,
      "step": 144600
    },
    {
      "epoch": 5.167857142857143,
      "grad_norm": 0.040466681122779846,
      "learning_rate": 1.771306754765838e-05,
      "loss": 0.0085,
      "step": 144700
    },
    {
      "epoch": 5.171428571428572,
      "grad_norm": 0.08942301571369171,
      "learning_rate": 1.7690745122550116e-05,
      "loss": 0.0094,
      "step": 144800
    },
    {
      "epoch": 5.175,
      "grad_norm": 0.04772280901670456,
      "learning_rate": 1.766842269744185e-05,
      "loss": 0.0089,
      "step": 144900
    },
    {
      "epoch": 5.178571428571429,
      "grad_norm": 0.03986231982707977,
      "learning_rate": 1.764610027233359e-05,
      "loss": 0.0089,
      "step": 145000
    },
    {
      "epoch": 5.182142857142857,
      "grad_norm": 0.03322238847613335,
      "learning_rate": 1.762377784722532e-05,
      "loss": 0.0092,
      "step": 145100
    },
    {
      "epoch": 5.185714285714286,
      "grad_norm": 0.04302319139242172,
      "learning_rate": 1.760145542211706e-05,
      "loss": 0.0096,
      "step": 145200
    },
    {
      "epoch": 5.189285714285714,
      "grad_norm": 0.05294103920459747,
      "learning_rate": 1.7579132997008797e-05,
      "loss": 0.0087,
      "step": 145300
    },
    {
      "epoch": 5.192857142857143,
      "grad_norm": 0.04712384566664696,
      "learning_rate": 1.755681057190053e-05,
      "loss": 0.0089,
      "step": 145400
    },
    {
      "epoch": 5.196428571428571,
      "grad_norm": 0.022383548319339752,
      "learning_rate": 1.753448814679227e-05,
      "loss": 0.0092,
      "step": 145500
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.03778938949108124,
      "learning_rate": 1.7512165721684003e-05,
      "loss": 0.0087,
      "step": 145600
    },
    {
      "epoch": 5.203571428571428,
      "grad_norm": 0.046970997005701065,
      "learning_rate": 1.7489843296575743e-05,
      "loss": 0.0091,
      "step": 145700
    },
    {
      "epoch": 5.207142857142857,
      "grad_norm": 0.07386553287506104,
      "learning_rate": 1.7467520871467476e-05,
      "loss": 0.0091,
      "step": 145800
    },
    {
      "epoch": 5.210714285714285,
      "grad_norm": 0.06941905617713928,
      "learning_rate": 1.7445198446359212e-05,
      "loss": 0.0089,
      "step": 145900
    },
    {
      "epoch": 5.214285714285714,
      "grad_norm": 0.05384860560297966,
      "learning_rate": 1.742287602125095e-05,
      "loss": 0.0085,
      "step": 146000
    },
    {
      "epoch": 5.2178571428571425,
      "grad_norm": 0.06365992873907089,
      "learning_rate": 1.7400553596142685e-05,
      "loss": 0.0095,
      "step": 146100
    },
    {
      "epoch": 5.2214285714285715,
      "grad_norm": 0.03929666802287102,
      "learning_rate": 1.7378231171034425e-05,
      "loss": 0.0088,
      "step": 146200
    },
    {
      "epoch": 5.225,
      "grad_norm": 0.05519690737128258,
      "learning_rate": 1.7355908745926158e-05,
      "loss": 0.0089,
      "step": 146300
    },
    {
      "epoch": 5.228571428571429,
      "grad_norm": 0.04610143601894379,
      "learning_rate": 1.7333586320817894e-05,
      "loss": 0.0094,
      "step": 146400
    },
    {
      "epoch": 5.232142857142857,
      "grad_norm": 0.04417509585618973,
      "learning_rate": 1.731126389570963e-05,
      "loss": 0.0086,
      "step": 146500
    },
    {
      "epoch": 5.235714285714286,
      "grad_norm": 0.04001395404338837,
      "learning_rate": 1.7288941470601367e-05,
      "loss": 0.0095,
      "step": 146600
    },
    {
      "epoch": 5.239285714285714,
      "grad_norm": 0.034417539834976196,
      "learning_rate": 1.7266619045493103e-05,
      "loss": 0.0092,
      "step": 146700
    },
    {
      "epoch": 5.242857142857143,
      "grad_norm": 0.05054965242743492,
      "learning_rate": 1.724429662038484e-05,
      "loss": 0.0089,
      "step": 146800
    },
    {
      "epoch": 5.246428571428572,
      "grad_norm": 0.06648187339305878,
      "learning_rate": 1.7221974195276576e-05,
      "loss": 0.0091,
      "step": 146900
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.03913126140832901,
      "learning_rate": 1.7199651770168312e-05,
      "loss": 0.0087,
      "step": 147000
    },
    {
      "epoch": 5.253571428571428,
      "grad_norm": 0.02381335385143757,
      "learning_rate": 1.717732934506005e-05,
      "loss": 0.0089,
      "step": 147100
    },
    {
      "epoch": 5.257142857142857,
      "grad_norm": 0.05027903988957405,
      "learning_rate": 1.7155006919951785e-05,
      "loss": 0.0091,
      "step": 147200
    },
    {
      "epoch": 5.260714285714286,
      "grad_norm": 0.037455055862665176,
      "learning_rate": 1.713268449484352e-05,
      "loss": 0.0081,
      "step": 147300
    },
    {
      "epoch": 5.264285714285714,
      "grad_norm": 0.06410769373178482,
      "learning_rate": 1.7110362069735254e-05,
      "loss": 0.0087,
      "step": 147400
    },
    {
      "epoch": 5.267857142857143,
      "grad_norm": 0.041749004274606705,
      "learning_rate": 1.7088039644626994e-05,
      "loss": 0.0091,
      "step": 147500
    },
    {
      "epoch": 5.271428571428571,
      "grad_norm": 0.042094919830560684,
      "learning_rate": 1.7065717219518727e-05,
      "loss": 0.0086,
      "step": 147600
    },
    {
      "epoch": 5.275,
      "grad_norm": 0.11337500065565109,
      "learning_rate": 1.7043394794410467e-05,
      "loss": 0.009,
      "step": 147700
    },
    {
      "epoch": 5.2785714285714285,
      "grad_norm": 0.054960016161203384,
      "learning_rate": 1.7021072369302203e-05,
      "loss": 0.0092,
      "step": 147800
    },
    {
      "epoch": 5.2821428571428575,
      "grad_norm": 0.037310704588890076,
      "learning_rate": 1.6998749944193936e-05,
      "loss": 0.0091,
      "step": 147900
    },
    {
      "epoch": 5.285714285714286,
      "grad_norm": 0.04259877651929855,
      "learning_rate": 1.6976427519085676e-05,
      "loss": 0.009,
      "step": 148000
    },
    {
      "epoch": 5.289285714285715,
      "grad_norm": 0.05821585655212402,
      "learning_rate": 1.695410509397741e-05,
      "loss": 0.0093,
      "step": 148100
    },
    {
      "epoch": 5.292857142857143,
      "grad_norm": 0.022702964022755623,
      "learning_rate": 1.693178266886915e-05,
      "loss": 0.0086,
      "step": 148200
    },
    {
      "epoch": 5.296428571428572,
      "grad_norm": 0.038101278245449066,
      "learning_rate": 1.690946024376088e-05,
      "loss": 0.0089,
      "step": 148300
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.05240816995501518,
      "learning_rate": 1.6887361042903703e-05,
      "loss": 0.0091,
      "step": 148400
    },
    {
      "epoch": 5.303571428571429,
      "grad_norm": 0.030755529180169106,
      "learning_rate": 1.686503861779544e-05,
      "loss": 0.0089,
      "step": 148500
    },
    {
      "epoch": 5.307142857142857,
      "grad_norm": 0.054876673966646194,
      "learning_rate": 1.6842716192687176e-05,
      "loss": 0.0081,
      "step": 148600
    },
    {
      "epoch": 5.310714285714286,
      "grad_norm": 0.03423256054520607,
      "learning_rate": 1.682039376757891e-05,
      "loss": 0.0086,
      "step": 148700
    },
    {
      "epoch": 5.314285714285714,
      "grad_norm": 0.05316345766186714,
      "learning_rate": 1.679807134247065e-05,
      "loss": 0.0088,
      "step": 148800
    },
    {
      "epoch": 5.317857142857143,
      "grad_norm": 0.046890269964933395,
      "learning_rate": 1.677574891736238e-05,
      "loss": 0.0086,
      "step": 148900
    },
    {
      "epoch": 5.321428571428571,
      "grad_norm": 0.044793080538511276,
      "learning_rate": 1.675342649225412e-05,
      "loss": 0.0086,
      "step": 149000
    },
    {
      "epoch": 5.325,
      "grad_norm": 0.052084244787693024,
      "learning_rate": 1.6731104067145854e-05,
      "loss": 0.0087,
      "step": 149100
    },
    {
      "epoch": 5.328571428571428,
      "grad_norm": 0.047286372631788254,
      "learning_rate": 1.670878164203759e-05,
      "loss": 0.009,
      "step": 149200
    },
    {
      "epoch": 5.332142857142857,
      "grad_norm": 0.05732147395610809,
      "learning_rate": 1.668645921692933e-05,
      "loss": 0.0092,
      "step": 149300
    },
    {
      "epoch": 5.335714285714285,
      "grad_norm": 0.034746576100587845,
      "learning_rate": 1.6664136791821063e-05,
      "loss": 0.0087,
      "step": 149400
    },
    {
      "epoch": 5.339285714285714,
      "grad_norm": 0.029243994504213333,
      "learning_rate": 1.6641814366712803e-05,
      "loss": 0.0089,
      "step": 149500
    },
    {
      "epoch": 5.3428571428571425,
      "grad_norm": 0.024325720965862274,
      "learning_rate": 1.6619491941604536e-05,
      "loss": 0.0091,
      "step": 149600
    },
    {
      "epoch": 5.3464285714285715,
      "grad_norm": 0.053383149206638336,
      "learning_rate": 1.6597169516496272e-05,
      "loss": 0.0092,
      "step": 149700
    },
    {
      "epoch": 5.35,
      "grad_norm": 0.027689378708600998,
      "learning_rate": 1.657484709138801e-05,
      "loss": 0.0085,
      "step": 149800
    },
    {
      "epoch": 5.353571428571429,
      "grad_norm": 0.03647799417376518,
      "learning_rate": 1.6552524666279745e-05,
      "loss": 0.0088,
      "step": 149900
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 0.06395961344242096,
      "learning_rate": 1.653020224117148e-05,
      "loss": 0.009,
      "step": 150000
    },
    {
      "epoch": 5.360714285714286,
      "grad_norm": 0.07061544060707092,
      "learning_rate": 1.6507879816063218e-05,
      "loss": 0.0086,
      "step": 150100
    },
    {
      "epoch": 5.364285714285714,
      "grad_norm": 0.058406416326761246,
      "learning_rate": 1.6485557390954954e-05,
      "loss": 0.0091,
      "step": 150200
    },
    {
      "epoch": 5.367857142857143,
      "grad_norm": 0.061682216823101044,
      "learning_rate": 1.646323496584669e-05,
      "loss": 0.009,
      "step": 150300
    },
    {
      "epoch": 5.371428571428572,
      "grad_norm": 0.0407225638628006,
      "learning_rate": 1.6440912540738427e-05,
      "loss": 0.0089,
      "step": 150400
    },
    {
      "epoch": 5.375,
      "grad_norm": 0.057047534734010696,
      "learning_rate": 1.6418813339881245e-05,
      "loss": 0.0085,
      "step": 150500
    },
    {
      "epoch": 5.378571428571428,
      "grad_norm": 0.024779843166470528,
      "learning_rate": 1.639649091477298e-05,
      "loss": 0.0101,
      "step": 150600
    },
    {
      "epoch": 5.382142857142857,
      "grad_norm": 0.10097267478704453,
      "learning_rate": 1.6374168489664718e-05,
      "loss": 0.0091,
      "step": 150700
    },
    {
      "epoch": 5.385714285714286,
      "grad_norm": 0.019680192694067955,
      "learning_rate": 1.6351846064556454e-05,
      "loss": 0.0087,
      "step": 150800
    },
    {
      "epoch": 5.389285714285714,
      "grad_norm": 0.08281094580888748,
      "learning_rate": 1.632952363944819e-05,
      "loss": 0.0091,
      "step": 150900
    },
    {
      "epoch": 5.392857142857143,
      "grad_norm": 0.06374958157539368,
      "learning_rate": 1.6307201214339927e-05,
      "loss": 0.0089,
      "step": 151000
    },
    {
      "epoch": 5.396428571428571,
      "grad_norm": 0.04047883674502373,
      "learning_rate": 1.6284878789231663e-05,
      "loss": 0.009,
      "step": 151100
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.04763752967119217,
      "learning_rate": 1.62625563641234e-05,
      "loss": 0.008,
      "step": 151200
    },
    {
      "epoch": 5.4035714285714285,
      "grad_norm": 0.057277143001556396,
      "learning_rate": 1.6240233939015133e-05,
      "loss": 0.0093,
      "step": 151300
    },
    {
      "epoch": 5.4071428571428575,
      "grad_norm": 0.04514322057366371,
      "learning_rate": 1.6217911513906872e-05,
      "loss": 0.0085,
      "step": 151400
    },
    {
      "epoch": 5.410714285714286,
      "grad_norm": 0.031103314831852913,
      "learning_rate": 1.619558908879861e-05,
      "loss": 0.0089,
      "step": 151500
    },
    {
      "epoch": 5.414285714285715,
      "grad_norm": 0.04934392869472504,
      "learning_rate": 1.6173266663690345e-05,
      "loss": 0.0095,
      "step": 151600
    },
    {
      "epoch": 5.417857142857143,
      "grad_norm": 0.07497324049472809,
      "learning_rate": 1.615094423858208e-05,
      "loss": 0.009,
      "step": 151700
    },
    {
      "epoch": 5.421428571428572,
      "grad_norm": 0.039188724011182785,
      "learning_rate": 1.6128621813473814e-05,
      "loss": 0.0087,
      "step": 151800
    },
    {
      "epoch": 5.425,
      "grad_norm": 0.03934143856167793,
      "learning_rate": 1.6106299388365554e-05,
      "loss": 0.0082,
      "step": 151900
    },
    {
      "epoch": 5.428571428571429,
      "grad_norm": 0.0518965981900692,
      "learning_rate": 1.6083976963257287e-05,
      "loss": 0.009,
      "step": 152000
    },
    {
      "epoch": 5.432142857142857,
      "grad_norm": 0.04682203754782677,
      "learning_rate": 1.6061654538149027e-05,
      "loss": 0.0088,
      "step": 152100
    },
    {
      "epoch": 5.435714285714286,
      "grad_norm": 0.029513753950595856,
      "learning_rate": 1.603933211304076e-05,
      "loss": 0.0091,
      "step": 152200
    },
    {
      "epoch": 5.439285714285714,
      "grad_norm": 0.05362983047962189,
      "learning_rate": 1.6017009687932496e-05,
      "loss": 0.0084,
      "step": 152300
    },
    {
      "epoch": 5.442857142857143,
      "grad_norm": 0.06347626447677612,
      "learning_rate": 1.5994687262824236e-05,
      "loss": 0.0094,
      "step": 152400
    },
    {
      "epoch": 5.446428571428571,
      "grad_norm": 0.030783943831920624,
      "learning_rate": 1.597236483771597e-05,
      "loss": 0.0101,
      "step": 152500
    },
    {
      "epoch": 5.45,
      "grad_norm": 0.021178919821977615,
      "learning_rate": 1.595004241260771e-05,
      "loss": 0.0084,
      "step": 152600
    },
    {
      "epoch": 5.453571428571428,
      "grad_norm": 0.03438526764512062,
      "learning_rate": 1.5927719987499442e-05,
      "loss": 0.009,
      "step": 152700
    },
    {
      "epoch": 5.457142857142857,
      "grad_norm": 0.06406107544898987,
      "learning_rate": 1.590562078664226e-05,
      "loss": 0.0097,
      "step": 152800
    },
    {
      "epoch": 5.460714285714285,
      "grad_norm": 0.045457594096660614,
      "learning_rate": 1.5883298361534e-05,
      "loss": 0.0087,
      "step": 152900
    },
    {
      "epoch": 5.464285714285714,
      "grad_norm": 0.05960671976208687,
      "learning_rate": 1.5860975936425736e-05,
      "loss": 0.0091,
      "step": 153000
    },
    {
      "epoch": 5.4678571428571425,
      "grad_norm": 0.02608374133706093,
      "learning_rate": 1.583865351131747e-05,
      "loss": 0.0091,
      "step": 153100
    },
    {
      "epoch": 5.4714285714285715,
      "grad_norm": 0.0970003679394722,
      "learning_rate": 1.581633108620921e-05,
      "loss": 0.0089,
      "step": 153200
    },
    {
      "epoch": 5.475,
      "grad_norm": 0.059867013245821,
      "learning_rate": 1.579400866110094e-05,
      "loss": 0.0089,
      "step": 153300
    },
    {
      "epoch": 5.478571428571429,
      "grad_norm": 0.05633082985877991,
      "learning_rate": 1.577168623599268e-05,
      "loss": 0.0082,
      "step": 153400
    },
    {
      "epoch": 5.482142857142857,
      "grad_norm": 0.10412884503602982,
      "learning_rate": 1.5749363810884414e-05,
      "loss": 0.0091,
      "step": 153500
    },
    {
      "epoch": 5.485714285714286,
      "grad_norm": 0.03391644358634949,
      "learning_rate": 1.572704138577615e-05,
      "loss": 0.0089,
      "step": 153600
    },
    {
      "epoch": 5.489285714285714,
      "grad_norm": 0.04401319846510887,
      "learning_rate": 1.5704718960667887e-05,
      "loss": 0.0085,
      "step": 153700
    },
    {
      "epoch": 5.492857142857143,
      "grad_norm": 0.06155373901128769,
      "learning_rate": 1.5682396535559623e-05,
      "loss": 0.0084,
      "step": 153800
    },
    {
      "epoch": 5.496428571428572,
      "grad_norm": 0.02941339835524559,
      "learning_rate": 1.5660074110451363e-05,
      "loss": 0.0091,
      "step": 153900
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.07264042645692825,
      "learning_rate": 1.5637751685343096e-05,
      "loss": 0.009,
      "step": 154000
    },
    {
      "epoch": 5.503571428571428,
      "grad_norm": 0.03290768712759018,
      "learning_rate": 1.5615429260234833e-05,
      "loss": 0.0083,
      "step": 154100
    },
    {
      "epoch": 5.507142857142857,
      "grad_norm": 0.029761217534542084,
      "learning_rate": 1.559310683512657e-05,
      "loss": 0.0091,
      "step": 154200
    },
    {
      "epoch": 5.510714285714286,
      "grad_norm": 0.03978782147169113,
      "learning_rate": 1.5570784410018305e-05,
      "loss": 0.0088,
      "step": 154300
    },
    {
      "epoch": 5.514285714285714,
      "grad_norm": 0.05679576098918915,
      "learning_rate": 1.554846198491004e-05,
      "loss": 0.0085,
      "step": 154400
    },
    {
      "epoch": 5.517857142857143,
      "grad_norm": 0.05867605283856392,
      "learning_rate": 1.5526139559801778e-05,
      "loss": 0.0094,
      "step": 154500
    },
    {
      "epoch": 5.521428571428571,
      "grad_norm": 0.04040507599711418,
      "learning_rate": 1.5503817134693514e-05,
      "loss": 0.0086,
      "step": 154600
    },
    {
      "epoch": 5.525,
      "grad_norm": 0.08300844579935074,
      "learning_rate": 1.548149470958525e-05,
      "loss": 0.0087,
      "step": 154700
    },
    {
      "epoch": 5.5285714285714285,
      "grad_norm": 0.05857829749584198,
      "learning_rate": 1.5459172284476987e-05,
      "loss": 0.0093,
      "step": 154800
    },
    {
      "epoch": 5.5321428571428575,
      "grad_norm": 0.054686881601810455,
      "learning_rate": 1.5436849859368723e-05,
      "loss": 0.0088,
      "step": 154900
    },
    {
      "epoch": 5.535714285714286,
      "grad_norm": 0.057315096259117126,
      "learning_rate": 1.541452743426046e-05,
      "loss": 0.0093,
      "step": 155000
    },
    {
      "epoch": 5.539285714285715,
      "grad_norm": 0.07364948093891144,
      "learning_rate": 1.5392428233403278e-05,
      "loss": 0.0086,
      "step": 155100
    },
    {
      "epoch": 5.542857142857143,
      "grad_norm": 0.04340183734893799,
      "learning_rate": 1.5370105808295014e-05,
      "loss": 0.0086,
      "step": 155200
    },
    {
      "epoch": 5.546428571428572,
      "grad_norm": 0.048076797276735306,
      "learning_rate": 1.534778338318675e-05,
      "loss": 0.0089,
      "step": 155300
    },
    {
      "epoch": 5.55,
      "grad_norm": 0.056005410850048065,
      "learning_rate": 1.5325460958078487e-05,
      "loss": 0.0096,
      "step": 155400
    },
    {
      "epoch": 5.553571428571429,
      "grad_norm": 0.05031292513012886,
      "learning_rate": 1.5303138532970223e-05,
      "loss": 0.009,
      "step": 155500
    },
    {
      "epoch": 5.557142857142857,
      "grad_norm": 0.03243862837553024,
      "learning_rate": 1.528081610786196e-05,
      "loss": 0.0087,
      "step": 155600
    },
    {
      "epoch": 5.560714285714286,
      "grad_norm": 0.038955554366111755,
      "learning_rate": 1.5258493682753694e-05,
      "loss": 0.0091,
      "step": 155700
    },
    {
      "epoch": 5.564285714285714,
      "grad_norm": 0.023072155192494392,
      "learning_rate": 1.5236171257645432e-05,
      "loss": 0.0094,
      "step": 155800
    },
    {
      "epoch": 5.567857142857143,
      "grad_norm": 0.05071311444044113,
      "learning_rate": 1.5213848832537167e-05,
      "loss": 0.0081,
      "step": 155900
    },
    {
      "epoch": 5.571428571428571,
      "grad_norm": 0.03647409379482269,
      "learning_rate": 1.5191526407428905e-05,
      "loss": 0.0089,
      "step": 156000
    },
    {
      "epoch": 5.575,
      "grad_norm": 0.054076556116342545,
      "learning_rate": 1.516920398232064e-05,
      "loss": 0.0082,
      "step": 156100
    },
    {
      "epoch": 5.578571428571428,
      "grad_norm": 0.034834232181310654,
      "learning_rate": 1.5146881557212375e-05,
      "loss": 0.0088,
      "step": 156200
    },
    {
      "epoch": 5.582142857142857,
      "grad_norm": 0.045613691210746765,
      "learning_rate": 1.5124559132104113e-05,
      "loss": 0.0086,
      "step": 156300
    },
    {
      "epoch": 5.585714285714285,
      "grad_norm": 0.03487677127122879,
      "learning_rate": 1.5102459931246932e-05,
      "loss": 0.0084,
      "step": 156400
    },
    {
      "epoch": 5.589285714285714,
      "grad_norm": 0.053237318992614746,
      "learning_rate": 1.5080137506138667e-05,
      "loss": 0.0089,
      "step": 156500
    },
    {
      "epoch": 5.5928571428571425,
      "grad_norm": 0.03625420108437538,
      "learning_rate": 1.5057815081030405e-05,
      "loss": 0.0086,
      "step": 156600
    },
    {
      "epoch": 5.5964285714285715,
      "grad_norm": 0.027481243014335632,
      "learning_rate": 1.503549265592214e-05,
      "loss": 0.0086,
      "step": 156700
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.04240730404853821,
      "learning_rate": 1.5013170230813874e-05,
      "loss": 0.0079,
      "step": 156800
    },
    {
      "epoch": 5.603571428571429,
      "grad_norm": 0.05160662531852722,
      "learning_rate": 1.4990847805705613e-05,
      "loss": 0.0089,
      "step": 156900
    },
    {
      "epoch": 5.607142857142857,
      "grad_norm": 0.029650148004293442,
      "learning_rate": 1.4968525380597347e-05,
      "loss": 0.0086,
      "step": 157000
    },
    {
      "epoch": 5.610714285714286,
      "grad_norm": 0.06193174049258232,
      "learning_rate": 1.4946202955489085e-05,
      "loss": 0.0084,
      "step": 157100
    },
    {
      "epoch": 5.614285714285714,
      "grad_norm": 0.03774842619895935,
      "learning_rate": 1.4923880530380822e-05,
      "loss": 0.0087,
      "step": 157200
    },
    {
      "epoch": 5.617857142857143,
      "grad_norm": 0.045266054570674896,
      "learning_rate": 1.490155810527256e-05,
      "loss": 0.0081,
      "step": 157300
    },
    {
      "epoch": 5.621428571428572,
      "grad_norm": 0.05135621130466461,
      "learning_rate": 1.4879235680164294e-05,
      "loss": 0.0088,
      "step": 157400
    },
    {
      "epoch": 5.625,
      "grad_norm": 0.03552493453025818,
      "learning_rate": 1.4856913255056029e-05,
      "loss": 0.0086,
      "step": 157500
    },
    {
      "epoch": 5.628571428571428,
      "grad_norm": 0.040106143802404404,
      "learning_rate": 1.4834590829947767e-05,
      "loss": 0.009,
      "step": 157600
    },
    {
      "epoch": 5.632142857142857,
      "grad_norm": 0.05387972667813301,
      "learning_rate": 1.4812268404839502e-05,
      "loss": 0.009,
      "step": 157700
    },
    {
      "epoch": 5.635714285714286,
      "grad_norm": 0.06570889800786972,
      "learning_rate": 1.478994597973124e-05,
      "loss": 0.0089,
      "step": 157800
    },
    {
      "epoch": 5.639285714285714,
      "grad_norm": 0.03082187846302986,
      "learning_rate": 1.4767623554622974e-05,
      "loss": 0.0088,
      "step": 157900
    },
    {
      "epoch": 5.642857142857143,
      "grad_norm": 0.04581797122955322,
      "learning_rate": 1.4745301129514711e-05,
      "loss": 0.0093,
      "step": 158000
    },
    {
      "epoch": 5.646428571428571,
      "grad_norm": 0.06323795765638351,
      "learning_rate": 1.4722978704406449e-05,
      "loss": 0.0091,
      "step": 158100
    },
    {
      "epoch": 5.65,
      "grad_norm": 0.04608919098973274,
      "learning_rate": 1.4700656279298184e-05,
      "loss": 0.0087,
      "step": 158200
    },
    {
      "epoch": 5.6535714285714285,
      "grad_norm": 0.09222785383462906,
      "learning_rate": 1.4678333854189922e-05,
      "loss": 0.0093,
      "step": 158300
    },
    {
      "epoch": 5.6571428571428575,
      "grad_norm": 0.03500482812523842,
      "learning_rate": 1.4656011429081656e-05,
      "loss": 0.0093,
      "step": 158400
    },
    {
      "epoch": 5.660714285714286,
      "grad_norm": 0.03234710916876793,
      "learning_rate": 1.4633689003973391e-05,
      "loss": 0.0084,
      "step": 158500
    },
    {
      "epoch": 5.664285714285715,
      "grad_norm": 0.06618033349514008,
      "learning_rate": 1.4611366578865129e-05,
      "loss": 0.009,
      "step": 158600
    },
    {
      "epoch": 5.667857142857143,
      "grad_norm": 0.05319932475686073,
      "learning_rate": 1.4589044153756864e-05,
      "loss": 0.0084,
      "step": 158700
    },
    {
      "epoch": 5.671428571428572,
      "grad_norm": 0.03650285303592682,
      "learning_rate": 1.4566721728648602e-05,
      "loss": 0.0085,
      "step": 158800
    },
    {
      "epoch": 5.675,
      "grad_norm": 0.053219929337501526,
      "learning_rate": 1.4544399303540338e-05,
      "loss": 0.0088,
      "step": 158900
    },
    {
      "epoch": 5.678571428571429,
      "grad_norm": 0.043385449796915054,
      "learning_rate": 1.4522076878432073e-05,
      "loss": 0.0083,
      "step": 159000
    },
    {
      "epoch": 5.682142857142857,
      "grad_norm": 0.04675501585006714,
      "learning_rate": 1.4499754453323811e-05,
      "loss": 0.0087,
      "step": 159100
    },
    {
      "epoch": 5.685714285714286,
      "grad_norm": 0.042375560849905014,
      "learning_rate": 1.4477432028215546e-05,
      "loss": 0.0088,
      "step": 159200
    },
    {
      "epoch": 5.689285714285714,
      "grad_norm": 0.032323937863111496,
      "learning_rate": 1.4455109603107284e-05,
      "loss": 0.0085,
      "step": 159300
    },
    {
      "epoch": 5.692857142857143,
      "grad_norm": 0.03084549680352211,
      "learning_rate": 1.4432787177999018e-05,
      "loss": 0.0094,
      "step": 159400
    },
    {
      "epoch": 5.696428571428571,
      "grad_norm": 0.0452866330742836,
      "learning_rate": 1.4410464752890755e-05,
      "loss": 0.0095,
      "step": 159500
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.04737747088074684,
      "learning_rate": 1.4388142327782491e-05,
      "loss": 0.0083,
      "step": 159600
    },
    {
      "epoch": 5.703571428571428,
      "grad_norm": 0.036780327558517456,
      "learning_rate": 1.4365819902674227e-05,
      "loss": 0.0088,
      "step": 159700
    },
    {
      "epoch": 5.707142857142857,
      "grad_norm": 0.05075385794043541,
      "learning_rate": 1.4343497477565965e-05,
      "loss": 0.0085,
      "step": 159800
    },
    {
      "epoch": 5.710714285714285,
      "grad_norm": 0.0456366240978241,
      "learning_rate": 1.43211750524577e-05,
      "loss": 0.0082,
      "step": 159900
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.04427321255207062,
      "learning_rate": 1.4298852627349435e-05,
      "loss": 0.009,
      "step": 160000
    },
    {
      "epoch": 5.7178571428571425,
      "grad_norm": 0.024614613503217697,
      "learning_rate": 1.4276530202241173e-05,
      "loss": 0.0087,
      "step": 160100
    },
    {
      "epoch": 5.7214285714285715,
      "grad_norm": 0.04987208545207977,
      "learning_rate": 1.4254207777132907e-05,
      "loss": 0.0086,
      "step": 160200
    },
    {
      "epoch": 5.725,
      "grad_norm": 0.04890087619423866,
      "learning_rate": 1.4231885352024646e-05,
      "loss": 0.0085,
      "step": 160300
    },
    {
      "epoch": 5.728571428571429,
      "grad_norm": 0.07705625891685486,
      "learning_rate": 1.420956292691638e-05,
      "loss": 0.0081,
      "step": 160400
    },
    {
      "epoch": 5.732142857142857,
      "grad_norm": 0.055398084223270416,
      "learning_rate": 1.4187240501808117e-05,
      "loss": 0.0088,
      "step": 160500
    },
    {
      "epoch": 5.735714285714286,
      "grad_norm": 0.04557914286851883,
      "learning_rate": 1.4164918076699855e-05,
      "loss": 0.0087,
      "step": 160600
    },
    {
      "epoch": 5.739285714285714,
      "grad_norm": 0.03785179555416107,
      "learning_rate": 1.414259565159159e-05,
      "loss": 0.0086,
      "step": 160700
    },
    {
      "epoch": 5.742857142857143,
      "grad_norm": 0.05646280571818352,
      "learning_rate": 1.4120273226483327e-05,
      "loss": 0.0087,
      "step": 160800
    },
    {
      "epoch": 5.746428571428572,
      "grad_norm": 0.02632896415889263,
      "learning_rate": 1.4097950801375062e-05,
      "loss": 0.0086,
      "step": 160900
    },
    {
      "epoch": 5.75,
      "grad_norm": 0.04907098039984703,
      "learning_rate": 1.4075628376266797e-05,
      "loss": 0.009,
      "step": 161000
    },
    {
      "epoch": 5.753571428571428,
      "grad_norm": 0.026843832805752754,
      "learning_rate": 1.4053529175409617e-05,
      "loss": 0.0092,
      "step": 161100
    },
    {
      "epoch": 5.757142857142857,
      "grad_norm": 0.0692606046795845,
      "learning_rate": 1.4031206750301355e-05,
      "loss": 0.0085,
      "step": 161200
    },
    {
      "epoch": 5.760714285714286,
      "grad_norm": 0.04191307723522186,
      "learning_rate": 1.400888432519309e-05,
      "loss": 0.0098,
      "step": 161300
    },
    {
      "epoch": 5.764285714285714,
      "grad_norm": 0.04162391647696495,
      "learning_rate": 1.3986561900084827e-05,
      "loss": 0.0086,
      "step": 161400
    },
    {
      "epoch": 5.767857142857143,
      "grad_norm": 0.04167449474334717,
      "learning_rate": 1.3964239474976562e-05,
      "loss": 0.0085,
      "step": 161500
    },
    {
      "epoch": 5.771428571428571,
      "grad_norm": 0.06792038679122925,
      "learning_rate": 1.3941917049868297e-05,
      "loss": 0.0091,
      "step": 161600
    },
    {
      "epoch": 5.775,
      "grad_norm": 0.0276828333735466,
      "learning_rate": 1.3919594624760035e-05,
      "loss": 0.0088,
      "step": 161700
    },
    {
      "epoch": 5.7785714285714285,
      "grad_norm": 0.04321635141968727,
      "learning_rate": 1.389727219965177e-05,
      "loss": 0.0093,
      "step": 161800
    },
    {
      "epoch": 5.7821428571428575,
      "grad_norm": 0.06722431629896164,
      "learning_rate": 1.3874949774543507e-05,
      "loss": 0.0088,
      "step": 161900
    },
    {
      "epoch": 5.785714285714286,
      "grad_norm": 0.040689896792173386,
      "learning_rate": 1.3852627349435244e-05,
      "loss": 0.0086,
      "step": 162000
    },
    {
      "epoch": 5.789285714285715,
      "grad_norm": 0.07236243784427643,
      "learning_rate": 1.3830304924326978e-05,
      "loss": 0.0087,
      "step": 162100
    },
    {
      "epoch": 5.792857142857143,
      "grad_norm": 0.021927790716290474,
      "learning_rate": 1.3807982499218717e-05,
      "loss": 0.0088,
      "step": 162200
    },
    {
      "epoch": 5.796428571428572,
      "grad_norm": 0.04488956183195114,
      "learning_rate": 1.3785660074110451e-05,
      "loss": 0.0084,
      "step": 162300
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.05006566271185875,
      "learning_rate": 1.376333764900219e-05,
      "loss": 0.008,
      "step": 162400
    },
    {
      "epoch": 5.803571428571429,
      "grad_norm": 0.06251458078622818,
      "learning_rate": 1.3741015223893924e-05,
      "loss": 0.0087,
      "step": 162500
    },
    {
      "epoch": 5.807142857142857,
      "grad_norm": 0.061718426644802094,
      "learning_rate": 1.371869279878566e-05,
      "loss": 0.0083,
      "step": 162600
    },
    {
      "epoch": 5.810714285714286,
      "grad_norm": 0.023425202816724777,
      "learning_rate": 1.3696370373677397e-05,
      "loss": 0.0084,
      "step": 162700
    },
    {
      "epoch": 5.814285714285714,
      "grad_norm": 0.03788551688194275,
      "learning_rate": 1.3674047948569133e-05,
      "loss": 0.0087,
      "step": 162800
    },
    {
      "epoch": 5.817857142857143,
      "grad_norm": 0.05413936451077461,
      "learning_rate": 1.3651725523460871e-05,
      "loss": 0.0084,
      "step": 162900
    },
    {
      "epoch": 5.821428571428571,
      "grad_norm": 0.05162413790822029,
      "learning_rate": 1.3629403098352606e-05,
      "loss": 0.0083,
      "step": 163000
    },
    {
      "epoch": 5.825,
      "grad_norm": 0.03770574927330017,
      "learning_rate": 1.360708067324434e-05,
      "loss": 0.0089,
      "step": 163100
    },
    {
      "epoch": 5.828571428571428,
      "grad_norm": 0.05808555334806442,
      "learning_rate": 1.3584758248136078e-05,
      "loss": 0.009,
      "step": 163200
    },
    {
      "epoch": 5.832142857142857,
      "grad_norm": 0.03201422840356827,
      "learning_rate": 1.3562435823027813e-05,
      "loss": 0.0084,
      "step": 163300
    },
    {
      "epoch": 5.835714285714285,
      "grad_norm": 0.07983813434839249,
      "learning_rate": 1.3540113397919551e-05,
      "loss": 0.0082,
      "step": 163400
    },
    {
      "epoch": 5.839285714285714,
      "grad_norm": 0.08695356547832489,
      "learning_rate": 1.3517790972811286e-05,
      "loss": 0.0092,
      "step": 163500
    },
    {
      "epoch": 5.8428571428571425,
      "grad_norm": 0.0275800209492445,
      "learning_rate": 1.3495468547703022e-05,
      "loss": 0.0087,
      "step": 163600
    },
    {
      "epoch": 5.8464285714285715,
      "grad_norm": 0.0810936838388443,
      "learning_rate": 1.347314612259476e-05,
      "loss": 0.0094,
      "step": 163700
    },
    {
      "epoch": 5.85,
      "grad_norm": 0.06271282583475113,
      "learning_rate": 1.3450823697486495e-05,
      "loss": 0.0092,
      "step": 163800
    },
    {
      "epoch": 5.853571428571429,
      "grad_norm": 0.016995131969451904,
      "learning_rate": 1.3428724496629313e-05,
      "loss": 0.0094,
      "step": 163900
    },
    {
      "epoch": 5.857142857142857,
      "grad_norm": 0.0475090928375721,
      "learning_rate": 1.3406402071521051e-05,
      "loss": 0.009,
      "step": 164000
    },
    {
      "epoch": 5.860714285714286,
      "grad_norm": 0.06998120993375778,
      "learning_rate": 1.3384079646412786e-05,
      "loss": 0.0093,
      "step": 164100
    },
    {
      "epoch": 5.864285714285714,
      "grad_norm": 0.043992780148983,
      "learning_rate": 1.3361757221304524e-05,
      "loss": 0.0086,
      "step": 164200
    },
    {
      "epoch": 5.867857142857143,
      "grad_norm": 0.05428457260131836,
      "learning_rate": 1.333943479619626e-05,
      "loss": 0.0084,
      "step": 164300
    },
    {
      "epoch": 5.871428571428572,
      "grad_norm": 0.05214196443557739,
      "learning_rate": 1.3317112371087995e-05,
      "loss": 0.0089,
      "step": 164400
    },
    {
      "epoch": 5.875,
      "grad_norm": 0.034669436514377594,
      "learning_rate": 1.3294789945979733e-05,
      "loss": 0.0089,
      "step": 164500
    },
    {
      "epoch": 5.878571428571428,
      "grad_norm": 0.026972921565175056,
      "learning_rate": 1.3272467520871468e-05,
      "loss": 0.0087,
      "step": 164600
    },
    {
      "epoch": 5.882142857142857,
      "grad_norm": 0.06877966970205307,
      "learning_rate": 1.3250145095763206e-05,
      "loss": 0.0084,
      "step": 164700
    },
    {
      "epoch": 5.885714285714286,
      "grad_norm": 0.03601847216486931,
      "learning_rate": 1.322782267065494e-05,
      "loss": 0.0092,
      "step": 164800
    },
    {
      "epoch": 5.889285714285714,
      "grad_norm": 0.055133555084466934,
      "learning_rate": 1.3205500245546675e-05,
      "loss": 0.0082,
      "step": 164900
    },
    {
      "epoch": 5.892857142857143,
      "grad_norm": 0.05683906376361847,
      "learning_rate": 1.3183177820438413e-05,
      "loss": 0.0092,
      "step": 165000
    },
    {
      "epoch": 5.896428571428571,
      "grad_norm": 0.03136276453733444,
      "learning_rate": 1.316085539533015e-05,
      "loss": 0.0088,
      "step": 165100
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.06078759580850601,
      "learning_rate": 1.3138532970221888e-05,
      "loss": 0.0084,
      "step": 165200
    },
    {
      "epoch": 5.9035714285714285,
      "grad_norm": 0.06523212790489197,
      "learning_rate": 1.3116210545113622e-05,
      "loss": 0.0088,
      "step": 165300
    },
    {
      "epoch": 5.9071428571428575,
      "grad_norm": 0.02942798286676407,
      "learning_rate": 1.3093888120005357e-05,
      "loss": 0.0087,
      "step": 165400
    },
    {
      "epoch": 5.910714285714286,
      "grad_norm": 0.06399744749069214,
      "learning_rate": 1.3071565694897095e-05,
      "loss": 0.0088,
      "step": 165500
    },
    {
      "epoch": 5.914285714285715,
      "grad_norm": 0.06602662056684494,
      "learning_rate": 1.304924326978883e-05,
      "loss": 0.0091,
      "step": 165600
    },
    {
      "epoch": 5.917857142857143,
      "grad_norm": 0.03955431282520294,
      "learning_rate": 1.3026920844680568e-05,
      "loss": 0.0093,
      "step": 165700
    },
    {
      "epoch": 5.921428571428572,
      "grad_norm": 0.06807864457368851,
      "learning_rate": 1.3004598419572302e-05,
      "loss": 0.0088,
      "step": 165800
    },
    {
      "epoch": 5.925,
      "grad_norm": 0.08123648911714554,
      "learning_rate": 1.2982275994464039e-05,
      "loss": 0.0085,
      "step": 165900
    },
    {
      "epoch": 5.928571428571429,
      "grad_norm": 0.05583569407463074,
      "learning_rate": 1.2959953569355777e-05,
      "loss": 0.0087,
      "step": 166000
    },
    {
      "epoch": 5.932142857142857,
      "grad_norm": 0.0262803602963686,
      "learning_rate": 1.2937854368498595e-05,
      "loss": 0.0087,
      "step": 166100
    },
    {
      "epoch": 5.935714285714286,
      "grad_norm": 0.0777801126241684,
      "learning_rate": 1.291553194339033e-05,
      "loss": 0.0084,
      "step": 166200
    },
    {
      "epoch": 5.939285714285714,
      "grad_norm": 0.055850863456726074,
      "learning_rate": 1.2893209518282068e-05,
      "loss": 0.0085,
      "step": 166300
    },
    {
      "epoch": 5.942857142857143,
      "grad_norm": 0.05176910012960434,
      "learning_rate": 1.2870887093173802e-05,
      "loss": 0.0081,
      "step": 166400
    },
    {
      "epoch": 5.946428571428571,
      "grad_norm": 0.03655564785003662,
      "learning_rate": 1.2848564668065539e-05,
      "loss": 0.009,
      "step": 166500
    },
    {
      "epoch": 5.95,
      "grad_norm": 0.02096063457429409,
      "learning_rate": 1.2826242242957277e-05,
      "loss": 0.0085,
      "step": 166600
    },
    {
      "epoch": 5.953571428571428,
      "grad_norm": 0.047083280980587006,
      "learning_rate": 1.2803919817849011e-05,
      "loss": 0.009,
      "step": 166700
    },
    {
      "epoch": 5.957142857142857,
      "grad_norm": 0.04363773763179779,
      "learning_rate": 1.278159739274075e-05,
      "loss": 0.0089,
      "step": 166800
    },
    {
      "epoch": 5.960714285714285,
      "grad_norm": 0.021331988275051117,
      "learning_rate": 1.2759274967632484e-05,
      "loss": 0.0088,
      "step": 166900
    },
    {
      "epoch": 5.964285714285714,
      "grad_norm": 0.039054419845342636,
      "learning_rate": 1.2736952542524219e-05,
      "loss": 0.0083,
      "step": 167000
    },
    {
      "epoch": 5.9678571428571425,
      "grad_norm": 0.05145467817783356,
      "learning_rate": 1.2714630117415957e-05,
      "loss": 0.0086,
      "step": 167100
    },
    {
      "epoch": 5.9714285714285715,
      "grad_norm": 0.04096526280045509,
      "learning_rate": 1.2692307692307691e-05,
      "loss": 0.0083,
      "step": 167200
    },
    {
      "epoch": 5.975,
      "grad_norm": 0.031433798372745514,
      "learning_rate": 1.266998526719943e-05,
      "loss": 0.0085,
      "step": 167300
    },
    {
      "epoch": 5.978571428571429,
      "grad_norm": 0.07247087359428406,
      "learning_rate": 1.2647662842091166e-05,
      "loss": 0.0087,
      "step": 167400
    },
    {
      "epoch": 5.982142857142857,
      "grad_norm": 0.04296521469950676,
      "learning_rate": 1.26253404169829e-05,
      "loss": 0.0092,
      "step": 167500
    },
    {
      "epoch": 5.985714285714286,
      "grad_norm": 0.04534933343529701,
      "learning_rate": 1.2603017991874639e-05,
      "loss": 0.0084,
      "step": 167600
    },
    {
      "epoch": 5.989285714285714,
      "grad_norm": 0.03185418248176575,
      "learning_rate": 1.2580695566766373e-05,
      "loss": 0.0086,
      "step": 167700
    },
    {
      "epoch": 5.992857142857143,
      "grad_norm": 0.15715020895004272,
      "learning_rate": 1.2558373141658111e-05,
      "loss": 0.0086,
      "step": 167800
    },
    {
      "epoch": 5.996428571428572,
      "grad_norm": 0.05571667477488518,
      "learning_rate": 1.2536050716549846e-05,
      "loss": 0.0086,
      "step": 167900
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.1388157308101654,
      "learning_rate": 1.2513728291441582e-05,
      "loss": 0.0086,
      "step": 168000
    },
    {
      "epoch": 6.0,
      "eval_accuracy_macro_0.5": 0.9968944191932678,
      "eval_accuracy_micro_0.5": 0.9968944787979126,
      "eval_accuracy_weighted_0.5": 0.9931644201278687,
      "eval_aucroc_macro": 0.8611253499984741,
      "eval_aucroc_micro": 0.9024308323860168,
      "eval_aucroc_weighted": 0.901071310043335,
      "eval_f1_macro_0.5": 0.5309708118438721,
      "eval_f1_macro_0.6": 0.45073202252388,
      "eval_f1_macro_0.7": 0.35498470067977905,
      "eval_f1_macro_0.8": 0.14475567638874054,
      "eval_f1_micro_0.5": 0.6819025278091431,
      "eval_f1_micro_0.6": 0.6301236748695374,
      "eval_f1_micro_0.7": 0.5460224151611328,
      "eval_f1_micro_0.8": 0.4215230345726013,
      "eval_f1_micro_0.9": 0.24827350676059723,
      "eval_f1_weighted_0.5": 0.6350528001785278,
      "eval_f1_weighted_0.6": 0.5716562271118164,
      "eval_f1_weighted_0.7": 0.47805386781692505,
      "eval_f1_weighted_0.8": 0.1972665935754776,
      "eval_loss": 0.007512271869927645,
      "eval_runtime": 1386.0527,
      "eval_samples_per_second": 40.157,
      "eval_steps_per_second": 5.02,
      "step": 168000
    },
    {
      "epoch": 6.003571428571429,
      "grad_norm": 0.0457930862903595,
      "learning_rate": 1.2491405866333319e-05,
      "loss": 0.0092,
      "step": 168100
    },
    {
      "epoch": 6.007142857142857,
      "grad_norm": 0.048303160816431046,
      "learning_rate": 1.2469083441225055e-05,
      "loss": 0.0082,
      "step": 168200
    },
    {
      "epoch": 6.010714285714286,
      "grad_norm": 0.049883753061294556,
      "learning_rate": 1.2446984240367875e-05,
      "loss": 0.0088,
      "step": 168300
    },
    {
      "epoch": 6.014285714285714,
      "grad_norm": 0.0662502720952034,
      "learning_rate": 1.242466181525961e-05,
      "loss": 0.0087,
      "step": 168400
    },
    {
      "epoch": 6.017857142857143,
      "grad_norm": 0.050278179347515106,
      "learning_rate": 1.2402339390151346e-05,
      "loss": 0.0089,
      "step": 168500
    },
    {
      "epoch": 6.021428571428571,
      "grad_norm": 0.07565034180879593,
      "learning_rate": 1.2380016965043082e-05,
      "loss": 0.0085,
      "step": 168600
    },
    {
      "epoch": 6.025,
      "grad_norm": 0.0980180874466896,
      "learning_rate": 1.2357694539934819e-05,
      "loss": 0.0086,
      "step": 168700
    },
    {
      "epoch": 6.0285714285714285,
      "grad_norm": 0.073919877409935,
      "learning_rate": 1.2335372114826555e-05,
      "loss": 0.0085,
      "step": 168800
    },
    {
      "epoch": 6.0321428571428575,
      "grad_norm": 0.04494438320398331,
      "learning_rate": 1.2313049689718291e-05,
      "loss": 0.0086,
      "step": 168900
    },
    {
      "epoch": 6.035714285714286,
      "grad_norm": 0.046312592923641205,
      "learning_rate": 1.2290727264610028e-05,
      "loss": 0.0091,
      "step": 169000
    },
    {
      "epoch": 6.039285714285715,
      "grad_norm": 0.05205162242054939,
      "learning_rate": 1.2268404839501764e-05,
      "loss": 0.0089,
      "step": 169100
    },
    {
      "epoch": 6.042857142857143,
      "grad_norm": 0.034519847482442856,
      "learning_rate": 1.22460824143935e-05,
      "loss": 0.0086,
      "step": 169200
    },
    {
      "epoch": 6.046428571428572,
      "grad_norm": 0.032041896134614944,
      "learning_rate": 1.2223759989285237e-05,
      "loss": 0.0086,
      "step": 169300
    },
    {
      "epoch": 6.05,
      "grad_norm": 0.04309863969683647,
      "learning_rate": 1.2201437564176972e-05,
      "loss": 0.0085,
      "step": 169400
    },
    {
      "epoch": 6.053571428571429,
      "grad_norm": 0.04838008061051369,
      "learning_rate": 1.2179115139068708e-05,
      "loss": 0.0081,
      "step": 169500
    },
    {
      "epoch": 6.057142857142857,
      "grad_norm": 0.04187948256731033,
      "learning_rate": 1.2156792713960446e-05,
      "loss": 0.0084,
      "step": 169600
    },
    {
      "epoch": 6.060714285714286,
      "grad_norm": 0.044014181941747665,
      "learning_rate": 1.2134470288852182e-05,
      "loss": 0.0082,
      "step": 169700
    },
    {
      "epoch": 6.064285714285714,
      "grad_norm": 0.0732635110616684,
      "learning_rate": 1.2112147863743919e-05,
      "loss": 0.0084,
      "step": 169800
    },
    {
      "epoch": 6.067857142857143,
      "grad_norm": 0.027988260611891747,
      "learning_rate": 1.2089825438635655e-05,
      "loss": 0.0083,
      "step": 169900
    },
    {
      "epoch": 6.071428571428571,
      "grad_norm": 0.030693773180246353,
      "learning_rate": 1.206750301352739e-05,
      "loss": 0.0088,
      "step": 170000
    },
    {
      "epoch": 6.075,
      "grad_norm": 0.0592527762055397,
      "learning_rate": 1.2045180588419126e-05,
      "loss": 0.0081,
      "step": 170100
    },
    {
      "epoch": 6.078571428571428,
      "grad_norm": 0.04565208777785301,
      "learning_rate": 1.2022858163310862e-05,
      "loss": 0.008,
      "step": 170200
    },
    {
      "epoch": 6.082142857142857,
      "grad_norm": 0.041075699031353,
      "learning_rate": 1.2000758962453682e-05,
      "loss": 0.0087,
      "step": 170300
    },
    {
      "epoch": 6.085714285714285,
      "grad_norm": 0.06322669982910156,
      "learning_rate": 1.1978436537345419e-05,
      "loss": 0.0089,
      "step": 170400
    },
    {
      "epoch": 6.089285714285714,
      "grad_norm": 0.05800805613398552,
      "learning_rate": 1.1956114112237155e-05,
      "loss": 0.0081,
      "step": 170500
    },
    {
      "epoch": 6.0928571428571425,
      "grad_norm": 0.04294397309422493,
      "learning_rate": 1.193379168712889e-05,
      "loss": 0.0086,
      "step": 170600
    },
    {
      "epoch": 6.0964285714285715,
      "grad_norm": 0.035097621381282806,
      "learning_rate": 1.1911469262020626e-05,
      "loss": 0.0087,
      "step": 170700
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.039462316781282425,
      "learning_rate": 1.1889146836912362e-05,
      "loss": 0.0088,
      "step": 170800
    },
    {
      "epoch": 6.103571428571429,
      "grad_norm": 0.04550919681787491,
      "learning_rate": 1.1866824411804099e-05,
      "loss": 0.0083,
      "step": 170900
    },
    {
      "epoch": 6.107142857142857,
      "grad_norm": 0.06639734655618668,
      "learning_rate": 1.1844501986695835e-05,
      "loss": 0.0083,
      "step": 171000
    },
    {
      "epoch": 6.110714285714286,
      "grad_norm": 0.03171660751104355,
      "learning_rate": 1.1822179561587571e-05,
      "loss": 0.009,
      "step": 171100
    },
    {
      "epoch": 6.114285714285714,
      "grad_norm": 0.07697364687919617,
      "learning_rate": 1.1799857136479308e-05,
      "loss": 0.0083,
      "step": 171200
    },
    {
      "epoch": 6.117857142857143,
      "grad_norm": 0.0349130779504776,
      "learning_rate": 1.1777534711371044e-05,
      "loss": 0.0087,
      "step": 171300
    },
    {
      "epoch": 6.121428571428571,
      "grad_norm": 0.05820784717798233,
      "learning_rate": 1.175521228626278e-05,
      "loss": 0.0083,
      "step": 171400
    },
    {
      "epoch": 6.125,
      "grad_norm": 0.039328135550022125,
      "learning_rate": 1.1732889861154517e-05,
      "loss": 0.0083,
      "step": 171500
    },
    {
      "epoch": 6.128571428571428,
      "grad_norm": 0.0735105574131012,
      "learning_rate": 1.1710567436046252e-05,
      "loss": 0.008,
      "step": 171600
    },
    {
      "epoch": 6.132142857142857,
      "grad_norm": 0.05404581502079964,
      "learning_rate": 1.1688245010937988e-05,
      "loss": 0.0087,
      "step": 171700
    },
    {
      "epoch": 6.135714285714286,
      "grad_norm": 0.046451594680547714,
      "learning_rate": 1.1665922585829724e-05,
      "loss": 0.0086,
      "step": 171800
    },
    {
      "epoch": 6.139285714285714,
      "grad_norm": 0.06553304195404053,
      "learning_rate": 1.164360016072146e-05,
      "loss": 0.0085,
      "step": 171900
    },
    {
      "epoch": 6.142857142857143,
      "grad_norm": 0.03929701820015907,
      "learning_rate": 1.1621277735613199e-05,
      "loss": 0.0085,
      "step": 172000
    },
    {
      "epoch": 6.146428571428571,
      "grad_norm": 0.08137200027704239,
      "learning_rate": 1.1598955310504935e-05,
      "loss": 0.0084,
      "step": 172100
    },
    {
      "epoch": 6.15,
      "grad_norm": 0.0499906949698925,
      "learning_rate": 1.157663288539667e-05,
      "loss": 0.0088,
      "step": 172200
    },
    {
      "epoch": 6.1535714285714285,
      "grad_norm": 0.04649890586733818,
      "learning_rate": 1.1554310460288406e-05,
      "loss": 0.0087,
      "step": 172300
    },
    {
      "epoch": 6.1571428571428575,
      "grad_norm": 0.03547245264053345,
      "learning_rate": 1.1531988035180143e-05,
      "loss": 0.0085,
      "step": 172400
    },
    {
      "epoch": 6.160714285714286,
      "grad_norm": 0.03535451367497444,
      "learning_rate": 1.1509665610071879e-05,
      "loss": 0.0082,
      "step": 172500
    },
    {
      "epoch": 6.164285714285715,
      "grad_norm": 0.03443151339888573,
      "learning_rate": 1.1487343184963615e-05,
      "loss": 0.0088,
      "step": 172600
    },
    {
      "epoch": 6.167857142857143,
      "grad_norm": 0.03470320999622345,
      "learning_rate": 1.1465020759855352e-05,
      "loss": 0.0085,
      "step": 172700
    },
    {
      "epoch": 6.171428571428572,
      "grad_norm": 0.04504266753792763,
      "learning_rate": 1.1442698334747088e-05,
      "loss": 0.0088,
      "step": 172800
    },
    {
      "epoch": 6.175,
      "grad_norm": 0.03991220146417618,
      "learning_rate": 1.1420599133889906e-05,
      "loss": 0.0085,
      "step": 172900
    },
    {
      "epoch": 6.178571428571429,
      "grad_norm": 0.023012863472104073,
      "learning_rate": 1.1398276708781642e-05,
      "loss": 0.0085,
      "step": 173000
    },
    {
      "epoch": 6.182142857142857,
      "grad_norm": 0.026590753346681595,
      "learning_rate": 1.1375954283673379e-05,
      "loss": 0.0089,
      "step": 173100
    },
    {
      "epoch": 6.185714285714286,
      "grad_norm": 0.04500013589859009,
      "learning_rate": 1.1353631858565115e-05,
      "loss": 0.0084,
      "step": 173200
    },
    {
      "epoch": 6.189285714285714,
      "grad_norm": 0.04374498128890991,
      "learning_rate": 1.133130943345685e-05,
      "loss": 0.0085,
      "step": 173300
    },
    {
      "epoch": 6.192857142857143,
      "grad_norm": 0.04278423264622688,
      "learning_rate": 1.1308987008348588e-05,
      "loss": 0.0085,
      "step": 173400
    },
    {
      "epoch": 6.196428571428571,
      "grad_norm": 0.04527612030506134,
      "learning_rate": 1.1286664583240324e-05,
      "loss": 0.0083,
      "step": 173500
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.028340646997094154,
      "learning_rate": 1.126434215813206e-05,
      "loss": 0.0083,
      "step": 173600
    },
    {
      "epoch": 6.203571428571428,
      "grad_norm": 0.032326165586709976,
      "learning_rate": 1.1242019733023797e-05,
      "loss": 0.0092,
      "step": 173700
    },
    {
      "epoch": 6.207142857142857,
      "grad_norm": 0.03947135806083679,
      "learning_rate": 1.1219697307915532e-05,
      "loss": 0.0079,
      "step": 173800
    },
    {
      "epoch": 6.210714285714285,
      "grad_norm": 0.04489367455244064,
      "learning_rate": 1.1197374882807268e-05,
      "loss": 0.0083,
      "step": 173900
    },
    {
      "epoch": 6.214285714285714,
      "grad_norm": 0.024541011080145836,
      "learning_rate": 1.1175052457699004e-05,
      "loss": 0.0083,
      "step": 174000
    },
    {
      "epoch": 6.2178571428571425,
      "grad_norm": 0.05338968709111214,
      "learning_rate": 1.115273003259074e-05,
      "loss": 0.009,
      "step": 174100
    },
    {
      "epoch": 6.2214285714285715,
      "grad_norm": 0.04072367772459984,
      "learning_rate": 1.1130407607482477e-05,
      "loss": 0.0083,
      "step": 174200
    },
    {
      "epoch": 6.225,
      "grad_norm": 0.041314445436000824,
      "learning_rate": 1.1108085182374213e-05,
      "loss": 0.0081,
      "step": 174300
    },
    {
      "epoch": 6.228571428571429,
      "grad_norm": 0.032598596066236496,
      "learning_rate": 1.108576275726595e-05,
      "loss": 0.0086,
      "step": 174400
    },
    {
      "epoch": 6.232142857142857,
      "grad_norm": 0.07410287111997604,
      "learning_rate": 1.1063440332157686e-05,
      "loss": 0.0084,
      "step": 174500
    },
    {
      "epoch": 6.235714285714286,
      "grad_norm": 0.026459045708179474,
      "learning_rate": 1.1041117907049423e-05,
      "loss": 0.0087,
      "step": 174600
    },
    {
      "epoch": 6.239285714285714,
      "grad_norm": 0.04586486890912056,
      "learning_rate": 1.1018795481941159e-05,
      "loss": 0.009,
      "step": 174700
    },
    {
      "epoch": 6.242857142857143,
      "grad_norm": 0.05614430829882622,
      "learning_rate": 1.0996473056832895e-05,
      "loss": 0.0096,
      "step": 174800
    },
    {
      "epoch": 6.246428571428572,
      "grad_norm": 0.0537826344370842,
      "learning_rate": 1.097415063172463e-05,
      "loss": 0.0084,
      "step": 174900
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.03523792326450348,
      "learning_rate": 1.0951828206616366e-05,
      "loss": 0.0088,
      "step": 175000
    },
    {
      "epoch": 6.253571428571428,
      "grad_norm": 0.03708760812878609,
      "learning_rate": 1.0929505781508104e-05,
      "loss": 0.0082,
      "step": 175100
    },
    {
      "epoch": 6.257142857142857,
      "grad_norm": 0.05513859912753105,
      "learning_rate": 1.090718335639984e-05,
      "loss": 0.0082,
      "step": 175200
    },
    {
      "epoch": 6.260714285714286,
      "grad_norm": 0.034813880920410156,
      "learning_rate": 1.0885084155542659e-05,
      "loss": 0.0089,
      "step": 175300
    },
    {
      "epoch": 6.264285714285714,
      "grad_norm": 0.047083862125873566,
      "learning_rate": 1.0862761730434395e-05,
      "loss": 0.0087,
      "step": 175400
    },
    {
      "epoch": 6.267857142857143,
      "grad_norm": 0.06588512659072876,
      "learning_rate": 1.084043930532613e-05,
      "loss": 0.0083,
      "step": 175500
    },
    {
      "epoch": 6.271428571428571,
      "grad_norm": 0.02836182899773121,
      "learning_rate": 1.0818116880217866e-05,
      "loss": 0.0085,
      "step": 175600
    },
    {
      "epoch": 6.275,
      "grad_norm": 0.03254695236682892,
      "learning_rate": 1.0795794455109604e-05,
      "loss": 0.0086,
      "step": 175700
    },
    {
      "epoch": 6.2785714285714285,
      "grad_norm": 0.06478266417980194,
      "learning_rate": 1.077347203000134e-05,
      "loss": 0.0081,
      "step": 175800
    },
    {
      "epoch": 6.2821428571428575,
      "grad_norm": 0.02384396269917488,
      "learning_rate": 1.0751149604893077e-05,
      "loss": 0.0087,
      "step": 175900
    },
    {
      "epoch": 6.285714285714286,
      "grad_norm": 0.04326880723237991,
      "learning_rate": 1.0728827179784812e-05,
      "loss": 0.0081,
      "step": 176000
    },
    {
      "epoch": 6.289285714285715,
      "grad_norm": 0.047862887382507324,
      "learning_rate": 1.0706504754676548e-05,
      "loss": 0.0086,
      "step": 176100
    },
    {
      "epoch": 6.292857142857143,
      "grad_norm": 0.026947224512696266,
      "learning_rate": 1.0684182329568284e-05,
      "loss": 0.0081,
      "step": 176200
    },
    {
      "epoch": 6.296428571428572,
      "grad_norm": 0.056674856692552567,
      "learning_rate": 1.066185990446002e-05,
      "loss": 0.0084,
      "step": 176300
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.04589968919754028,
      "learning_rate": 1.0639537479351757e-05,
      "loss": 0.0094,
      "step": 176400
    },
    {
      "epoch": 6.303571428571429,
      "grad_norm": 0.05831833556294441,
      "learning_rate": 1.0617215054243494e-05,
      "loss": 0.0088,
      "step": 176500
    },
    {
      "epoch": 6.307142857142857,
      "grad_norm": 0.032475121319293976,
      "learning_rate": 1.059489262913523e-05,
      "loss": 0.0086,
      "step": 176600
    },
    {
      "epoch": 6.310714285714286,
      "grad_norm": 0.040337394922971725,
      "learning_rate": 1.0572570204026966e-05,
      "loss": 0.0085,
      "step": 176700
    },
    {
      "epoch": 6.314285714285714,
      "grad_norm": 0.027397451922297478,
      "learning_rate": 1.0550247778918703e-05,
      "loss": 0.0089,
      "step": 176800
    },
    {
      "epoch": 6.317857142857143,
      "grad_norm": 0.06427227705717087,
      "learning_rate": 1.0527925353810439e-05,
      "loss": 0.0084,
      "step": 176900
    },
    {
      "epoch": 6.321428571428571,
      "grad_norm": 0.04693065583705902,
      "learning_rate": 1.0505602928702175e-05,
      "loss": 0.0091,
      "step": 177000
    },
    {
      "epoch": 6.325,
      "grad_norm": 0.057685159146785736,
      "learning_rate": 1.048328050359391e-05,
      "loss": 0.0079,
      "step": 177100
    },
    {
      "epoch": 6.328571428571428,
      "grad_norm": 0.0425313338637352,
      "learning_rate": 1.0460958078485646e-05,
      "loss": 0.009,
      "step": 177200
    },
    {
      "epoch": 6.332142857142857,
      "grad_norm": 0.06145547702908516,
      "learning_rate": 1.0438635653377383e-05,
      "loss": 0.0085,
      "step": 177300
    },
    {
      "epoch": 6.335714285714285,
      "grad_norm": 0.03178687021136284,
      "learning_rate": 1.041631322826912e-05,
      "loss": 0.0082,
      "step": 177400
    },
    {
      "epoch": 6.339285714285714,
      "grad_norm": 0.08246299624443054,
      "learning_rate": 1.0393990803160857e-05,
      "loss": 0.0088,
      "step": 177500
    },
    {
      "epoch": 6.3428571428571425,
      "grad_norm": 0.053052037954330444,
      "learning_rate": 1.0371668378052592e-05,
      "loss": 0.0086,
      "step": 177600
    },
    {
      "epoch": 6.3464285714285715,
      "grad_norm": 0.036427974700927734,
      "learning_rate": 1.0349345952944328e-05,
      "loss": 0.0087,
      "step": 177700
    },
    {
      "epoch": 6.35,
      "grad_norm": 0.035019367933273315,
      "learning_rate": 1.0327023527836065e-05,
      "loss": 0.008,
      "step": 177800
    },
    {
      "epoch": 6.353571428571429,
      "grad_norm": 0.05945773795247078,
      "learning_rate": 1.0304701102727801e-05,
      "loss": 0.0084,
      "step": 177900
    },
    {
      "epoch": 6.357142857142857,
      "grad_norm": 0.025660056620836258,
      "learning_rate": 1.0282378677619537e-05,
      "loss": 0.0084,
      "step": 178000
    },
    {
      "epoch": 6.360714285714286,
      "grad_norm": 0.039968665689229965,
      "learning_rate": 1.0260056252511272e-05,
      "loss": 0.0081,
      "step": 178100
    },
    {
      "epoch": 6.364285714285714,
      "grad_norm": 0.03264041617512703,
      "learning_rate": 1.023773382740301e-05,
      "loss": 0.008,
      "step": 178200
    },
    {
      "epoch": 6.367857142857143,
      "grad_norm": 0.06423169374465942,
      "learning_rate": 1.0215411402294746e-05,
      "loss": 0.0089,
      "step": 178300
    },
    {
      "epoch": 6.371428571428572,
      "grad_norm": 0.03185657784342766,
      "learning_rate": 1.0193088977186483e-05,
      "loss": 0.0088,
      "step": 178400
    },
    {
      "epoch": 6.375,
      "grad_norm": 0.04372071847319603,
      "learning_rate": 1.0170766552078219e-05,
      "loss": 0.0085,
      "step": 178500
    },
    {
      "epoch": 6.378571428571428,
      "grad_norm": 0.028436746448278427,
      "learning_rate": 1.0148444126969954e-05,
      "loss": 0.0087,
      "step": 178600
    },
    {
      "epoch": 6.382142857142857,
      "grad_norm": 0.026618462055921555,
      "learning_rate": 1.0126344926112772e-05,
      "loss": 0.0089,
      "step": 178700
    },
    {
      "epoch": 6.385714285714286,
      "grad_norm": 0.046987179666757584,
      "learning_rate": 1.010402250100451e-05,
      "loss": 0.008,
      "step": 178800
    },
    {
      "epoch": 6.389285714285714,
      "grad_norm": 0.03585740923881531,
      "learning_rate": 1.0081700075896246e-05,
      "loss": 0.0086,
      "step": 178900
    },
    {
      "epoch": 6.392857142857143,
      "grad_norm": 0.026167219504714012,
      "learning_rate": 1.0059377650787983e-05,
      "loss": 0.0084,
      "step": 179000
    },
    {
      "epoch": 6.396428571428571,
      "grad_norm": 0.024743780493736267,
      "learning_rate": 1.0037055225679719e-05,
      "loss": 0.0084,
      "step": 179100
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.029195968061685562,
      "learning_rate": 1.0014732800571455e-05,
      "loss": 0.0087,
      "step": 179200
    },
    {
      "epoch": 6.4035714285714285,
      "grad_norm": 0.03773271292448044,
      "learning_rate": 9.99241037546319e-06,
      "loss": 0.0085,
      "step": 179300
    },
    {
      "epoch": 6.4071428571428575,
      "grad_norm": 0.04730984568595886,
      "learning_rate": 9.970087950354926e-06,
      "loss": 0.0082,
      "step": 179400
    },
    {
      "epoch": 6.410714285714286,
      "grad_norm": 0.03648793324828148,
      "learning_rate": 9.947765525246663e-06,
      "loss": 0.009,
      "step": 179500
    },
    {
      "epoch": 6.414285714285715,
      "grad_norm": 0.04922836646437645,
      "learning_rate": 9.9254431001384e-06,
      "loss": 0.0083,
      "step": 179600
    },
    {
      "epoch": 6.417857142857143,
      "grad_norm": 0.05202621966600418,
      "learning_rate": 9.903120675030137e-06,
      "loss": 0.0083,
      "step": 179700
    },
    {
      "epoch": 6.421428571428572,
      "grad_norm": 0.039480775594711304,
      "learning_rate": 9.880798249921872e-06,
      "loss": 0.0089,
      "step": 179800
    },
    {
      "epoch": 6.425,
      "grad_norm": 0.019754759967327118,
      "learning_rate": 9.858475824813608e-06,
      "loss": 0.0093,
      "step": 179900
    },
    {
      "epoch": 6.428571428571429,
      "grad_norm": 0.03892972692847252,
      "learning_rate": 9.836153399705345e-06,
      "loss": 0.0085,
      "step": 180000
    },
    {
      "epoch": 6.432142857142857,
      "grad_norm": 0.08263552933931351,
      "learning_rate": 9.813830974597081e-06,
      "loss": 0.0083,
      "step": 180100
    },
    {
      "epoch": 6.435714285714286,
      "grad_norm": 0.037656087428331375,
      "learning_rate": 9.791508549488817e-06,
      "loss": 0.0086,
      "step": 180200
    },
    {
      "epoch": 6.439285714285714,
      "grad_norm": 0.026939598843455315,
      "learning_rate": 9.769186124380552e-06,
      "loss": 0.0088,
      "step": 180300
    },
    {
      "epoch": 6.442857142857143,
      "grad_norm": 0.04022641479969025,
      "learning_rate": 9.746863699272288e-06,
      "loss": 0.0092,
      "step": 180400
    },
    {
      "epoch": 6.446428571428571,
      "grad_norm": 0.02991349622607231,
      "learning_rate": 9.724541274164026e-06,
      "loss": 0.0092,
      "step": 180500
    },
    {
      "epoch": 6.45,
      "grad_norm": 0.06497934460639954,
      "learning_rate": 9.702218849055763e-06,
      "loss": 0.0079,
      "step": 180600
    },
    {
      "epoch": 6.453571428571428,
      "grad_norm": 0.048321425914764404,
      "learning_rate": 9.6798964239475e-06,
      "loss": 0.0084,
      "step": 180700
    },
    {
      "epoch": 6.457142857142857,
      "grad_norm": 0.02060551755130291,
      "learning_rate": 9.657573998839234e-06,
      "loss": 0.009,
      "step": 180800
    },
    {
      "epoch": 6.460714285714285,
      "grad_norm": 0.03318610042333603,
      "learning_rate": 9.63525157373097e-06,
      "loss": 0.0085,
      "step": 180900
    },
    {
      "epoch": 6.464285714285714,
      "grad_norm": 0.061087001115083694,
      "learning_rate": 9.612929148622707e-06,
      "loss": 0.0087,
      "step": 181000
    },
    {
      "epoch": 6.4678571428571425,
      "grad_norm": 0.05397341400384903,
      "learning_rate": 9.590606723514443e-06,
      "loss": 0.0086,
      "step": 181100
    },
    {
      "epoch": 6.4714285714285715,
      "grad_norm": 0.047175437211990356,
      "learning_rate": 9.56828429840618e-06,
      "loss": 0.0087,
      "step": 181200
    },
    {
      "epoch": 6.475,
      "grad_norm": 0.04273553565144539,
      "learning_rate": 9.545961873297916e-06,
      "loss": 0.0084,
      "step": 181300
    },
    {
      "epoch": 6.478571428571429,
      "grad_norm": 0.05652014538645744,
      "learning_rate": 9.523639448189652e-06,
      "loss": 0.009,
      "step": 181400
    },
    {
      "epoch": 6.482142857142857,
      "grad_norm": 0.0311975609511137,
      "learning_rate": 9.501317023081388e-06,
      "loss": 0.0083,
      "step": 181500
    },
    {
      "epoch": 6.485714285714286,
      "grad_norm": 0.0648205429315567,
      "learning_rate": 9.478994597973125e-06,
      "loss": 0.0079,
      "step": 181600
    },
    {
      "epoch": 6.489285714285714,
      "grad_norm": 0.061780668795108795,
      "learning_rate": 9.456672172864861e-06,
      "loss": 0.0088,
      "step": 181700
    },
    {
      "epoch": 6.492857142857143,
      "grad_norm": 0.02756166085600853,
      "learning_rate": 9.434349747756596e-06,
      "loss": 0.0078,
      "step": 181800
    },
    {
      "epoch": 6.496428571428572,
      "grad_norm": 0.022622356191277504,
      "learning_rate": 9.412027322648332e-06,
      "loss": 0.009,
      "step": 181900
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.04009808972477913,
      "learning_rate": 9.389704897540069e-06,
      "loss": 0.0086,
      "step": 182000
    },
    {
      "epoch": 6.503571428571428,
      "grad_norm": 0.05832287669181824,
      "learning_rate": 9.367605696682888e-06,
      "loss": 0.0081,
      "step": 182100
    },
    {
      "epoch": 6.507142857142857,
      "grad_norm": 0.01742282696068287,
      "learning_rate": 9.345283271574625e-06,
      "loss": 0.0082,
      "step": 182200
    },
    {
      "epoch": 6.510714285714286,
      "grad_norm": 0.04217555746436119,
      "learning_rate": 9.322960846466361e-06,
      "loss": 0.0083,
      "step": 182300
    },
    {
      "epoch": 6.514285714285714,
      "grad_norm": 0.06185886263847351,
      "learning_rate": 9.300638421358097e-06,
      "loss": 0.0086,
      "step": 182400
    },
    {
      "epoch": 6.517857142857143,
      "grad_norm": 0.10874410718679428,
      "learning_rate": 9.278315996249832e-06,
      "loss": 0.009,
      "step": 182500
    },
    {
      "epoch": 6.521428571428571,
      "grad_norm": 0.03534005582332611,
      "learning_rate": 9.255993571141568e-06,
      "loss": 0.0081,
      "step": 182600
    },
    {
      "epoch": 6.525,
      "grad_norm": 0.030235739424824715,
      "learning_rate": 9.233671146033305e-06,
      "loss": 0.0076,
      "step": 182700
    },
    {
      "epoch": 6.5285714285714285,
      "grad_norm": 0.07675117999315262,
      "learning_rate": 9.211348720925043e-06,
      "loss": 0.0089,
      "step": 182800
    },
    {
      "epoch": 6.5321428571428575,
      "grad_norm": 0.047947391867637634,
      "learning_rate": 9.18902629581678e-06,
      "loss": 0.0093,
      "step": 182900
    },
    {
      "epoch": 6.535714285714286,
      "grad_norm": 0.021506858989596367,
      "learning_rate": 9.166703870708514e-06,
      "loss": 0.0087,
      "step": 183000
    },
    {
      "epoch": 6.539285714285715,
      "grad_norm": 0.029248863458633423,
      "learning_rate": 9.14438144560025e-06,
      "loss": 0.0092,
      "step": 183100
    },
    {
      "epoch": 6.542857142857143,
      "grad_norm": 0.061249785125255585,
      "learning_rate": 9.122059020491987e-06,
      "loss": 0.0085,
      "step": 183200
    },
    {
      "epoch": 6.546428571428572,
      "grad_norm": 0.0315733477473259,
      "learning_rate": 9.099736595383723e-06,
      "loss": 0.0089,
      "step": 183300
    },
    {
      "epoch": 6.55,
      "grad_norm": 0.06575667858123779,
      "learning_rate": 9.07741417027546e-06,
      "loss": 0.0085,
      "step": 183400
    },
    {
      "epoch": 6.553571428571429,
      "grad_norm": 0.03571348637342453,
      "learning_rate": 9.055091745167194e-06,
      "loss": 0.0095,
      "step": 183500
    },
    {
      "epoch": 6.557142857142857,
      "grad_norm": 0.06834164261817932,
      "learning_rate": 9.032769320058932e-06,
      "loss": 0.0084,
      "step": 183600
    },
    {
      "epoch": 6.560714285714286,
      "grad_norm": 0.08932613581418991,
      "learning_rate": 9.010446894950669e-06,
      "loss": 0.0084,
      "step": 183700
    },
    {
      "epoch": 6.564285714285714,
      "grad_norm": 0.053305238485336304,
      "learning_rate": 8.988124469842405e-06,
      "loss": 0.0084,
      "step": 183800
    },
    {
      "epoch": 6.567857142857143,
      "grad_norm": 0.023952435702085495,
      "learning_rate": 8.965802044734141e-06,
      "loss": 0.0085,
      "step": 183900
    },
    {
      "epoch": 6.571428571428571,
      "grad_norm": 0.0427575409412384,
      "learning_rate": 8.943479619625876e-06,
      "loss": 0.0085,
      "step": 184000
    },
    {
      "epoch": 6.575,
      "grad_norm": 0.041270315647125244,
      "learning_rate": 8.921157194517612e-06,
      "loss": 0.0084,
      "step": 184100
    },
    {
      "epoch": 6.578571428571428,
      "grad_norm": 0.025979647412896156,
      "learning_rate": 8.899057993660432e-06,
      "loss": 0.0083,
      "step": 184200
    },
    {
      "epoch": 6.582142857142857,
      "grad_norm": 0.022297769784927368,
      "learning_rate": 8.876735568552168e-06,
      "loss": 0.0085,
      "step": 184300
    },
    {
      "epoch": 6.585714285714285,
      "grad_norm": 0.03468135744333267,
      "learning_rate": 8.854413143443905e-06,
      "loss": 0.0081,
      "step": 184400
    },
    {
      "epoch": 6.589285714285714,
      "grad_norm": 0.047879353165626526,
      "learning_rate": 8.832090718335641e-06,
      "loss": 0.0079,
      "step": 184500
    },
    {
      "epoch": 6.5928571428571425,
      "grad_norm": 0.0421239472925663,
      "learning_rate": 8.809768293227378e-06,
      "loss": 0.0084,
      "step": 184600
    },
    {
      "epoch": 6.5964285714285715,
      "grad_norm": 0.05993920564651489,
      "learning_rate": 8.787445868119112e-06,
      "loss": 0.0076,
      "step": 184700
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.10756566375494003,
      "learning_rate": 8.765123443010849e-06,
      "loss": 0.009,
      "step": 184800
    },
    {
      "epoch": 6.603571428571429,
      "grad_norm": 0.04736423119902611,
      "learning_rate": 8.742801017902585e-06,
      "loss": 0.0079,
      "step": 184900
    },
    {
      "epoch": 6.607142857142857,
      "grad_norm": 0.04139593988656998,
      "learning_rate": 8.720478592794321e-06,
      "loss": 0.0083,
      "step": 185000
    },
    {
      "epoch": 6.610714285714286,
      "grad_norm": 0.043458160012960434,
      "learning_rate": 8.698156167686058e-06,
      "loss": 0.008,
      "step": 185100
    },
    {
      "epoch": 6.614285714285714,
      "grad_norm": 0.058378301560878754,
      "learning_rate": 8.675833742577794e-06,
      "loss": 0.0087,
      "step": 185200
    },
    {
      "epoch": 6.617857142857143,
      "grad_norm": 0.037461232393980026,
      "learning_rate": 8.65351131746953e-06,
      "loss": 0.0085,
      "step": 185300
    },
    {
      "epoch": 6.621428571428572,
      "grad_norm": 0.02654118277132511,
      "learning_rate": 8.631188892361267e-06,
      "loss": 0.0087,
      "step": 185400
    },
    {
      "epoch": 6.625,
      "grad_norm": 0.0953872874379158,
      "learning_rate": 8.608866467253003e-06,
      "loss": 0.0084,
      "step": 185500
    },
    {
      "epoch": 6.628571428571428,
      "grad_norm": 0.040108613669872284,
      "learning_rate": 8.58654404214474e-06,
      "loss": 0.0084,
      "step": 185600
    },
    {
      "epoch": 6.632142857142857,
      "grad_norm": 0.053883086889982224,
      "learning_rate": 8.564221617036474e-06,
      "loss": 0.0081,
      "step": 185700
    },
    {
      "epoch": 6.635714285714286,
      "grad_norm": 0.06125140190124512,
      "learning_rate": 8.54189919192821e-06,
      "loss": 0.0087,
      "step": 185800
    },
    {
      "epoch": 6.639285714285714,
      "grad_norm": 0.05415961891412735,
      "learning_rate": 8.519576766819949e-06,
      "loss": 0.0086,
      "step": 185900
    },
    {
      "epoch": 6.642857142857143,
      "grad_norm": 0.0371391698718071,
      "learning_rate": 8.497254341711685e-06,
      "loss": 0.0089,
      "step": 186000
    },
    {
      "epoch": 6.646428571428571,
      "grad_norm": 0.03649431839585304,
      "learning_rate": 8.474931916603421e-06,
      "loss": 0.0085,
      "step": 186100
    },
    {
      "epoch": 6.65,
      "grad_norm": 0.034502893686294556,
      "learning_rate": 8.452609491495156e-06,
      "loss": 0.0087,
      "step": 186200
    },
    {
      "epoch": 6.6535714285714285,
      "grad_norm": 0.03543940186500549,
      "learning_rate": 8.430287066386892e-06,
      "loss": 0.0084,
      "step": 186300
    },
    {
      "epoch": 6.6571428571428575,
      "grad_norm": 0.07326441258192062,
      "learning_rate": 8.407964641278629e-06,
      "loss": 0.0081,
      "step": 186400
    },
    {
      "epoch": 6.660714285714286,
      "grad_norm": 0.03206676244735718,
      "learning_rate": 8.385642216170365e-06,
      "loss": 0.0087,
      "step": 186500
    },
    {
      "epoch": 6.664285714285715,
      "grad_norm": 0.04419304057955742,
      "learning_rate": 8.363319791062101e-06,
      "loss": 0.008,
      "step": 186600
    },
    {
      "epoch": 6.667857142857143,
      "grad_norm": 0.028364073485136032,
      "learning_rate": 8.340997365953838e-06,
      "loss": 0.0091,
      "step": 186700
    },
    {
      "epoch": 6.671428571428572,
      "grad_norm": 0.059164125472307205,
      "learning_rate": 8.318674940845574e-06,
      "loss": 0.0081,
      "step": 186800
    },
    {
      "epoch": 6.675,
      "grad_norm": 0.04526049271225929,
      "learning_rate": 8.29635251573731e-06,
      "loss": 0.0081,
      "step": 186900
    },
    {
      "epoch": 6.678571428571429,
      "grad_norm": 0.020229853689670563,
      "learning_rate": 8.274030090629047e-06,
      "loss": 0.0084,
      "step": 187000
    },
    {
      "epoch": 6.682142857142857,
      "grad_norm": 0.047605711966753006,
      "learning_rate": 8.251707665520783e-06,
      "loss": 0.0087,
      "step": 187100
    },
    {
      "epoch": 6.685714285714286,
      "grad_norm": 0.035794101655483246,
      "learning_rate": 8.229608464663601e-06,
      "loss": 0.0082,
      "step": 187200
    },
    {
      "epoch": 6.689285714285714,
      "grad_norm": 0.06500924378633499,
      "learning_rate": 8.207286039555338e-06,
      "loss": 0.0091,
      "step": 187300
    },
    {
      "epoch": 6.692857142857143,
      "grad_norm": 0.035968977957963943,
      "learning_rate": 8.184963614447074e-06,
      "loss": 0.0084,
      "step": 187400
    },
    {
      "epoch": 6.696428571428571,
      "grad_norm": 0.029738277196884155,
      "learning_rate": 8.16264118933881e-06,
      "loss": 0.0081,
      "step": 187500
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.02934105508029461,
      "learning_rate": 8.140318764230547e-06,
      "loss": 0.0088,
      "step": 187600
    },
    {
      "epoch": 6.703571428571428,
      "grad_norm": 0.03649086877703667,
      "learning_rate": 8.117996339122283e-06,
      "loss": 0.0084,
      "step": 187700
    },
    {
      "epoch": 6.707142857142857,
      "grad_norm": 0.06836839020252228,
      "learning_rate": 8.09567391401402e-06,
      "loss": 0.0088,
      "step": 187800
    },
    {
      "epoch": 6.710714285714285,
      "grad_norm": 0.05224008113145828,
      "learning_rate": 8.073351488905754e-06,
      "loss": 0.008,
      "step": 187900
    },
    {
      "epoch": 6.714285714285714,
      "grad_norm": 0.05851536989212036,
      "learning_rate": 8.05102906379749e-06,
      "loss": 0.0079,
      "step": 188000
    },
    {
      "epoch": 6.7178571428571425,
      "grad_norm": 0.07220473885536194,
      "learning_rate": 8.028706638689227e-06,
      "loss": 0.0084,
      "step": 188100
    },
    {
      "epoch": 6.7214285714285715,
      "grad_norm": 0.05487988516688347,
      "learning_rate": 8.006384213580963e-06,
      "loss": 0.0089,
      "step": 188200
    },
    {
      "epoch": 6.725,
      "grad_norm": 0.03481535241007805,
      "learning_rate": 7.984285012723783e-06,
      "loss": 0.0083,
      "step": 188300
    },
    {
      "epoch": 6.728571428571429,
      "grad_norm": 0.04176040366292,
      "learning_rate": 7.96196258761552e-06,
      "loss": 0.009,
      "step": 188400
    },
    {
      "epoch": 6.732142857142857,
      "grad_norm": 0.0391232855618,
      "learning_rate": 7.939640162507256e-06,
      "loss": 0.0083,
      "step": 188500
    },
    {
      "epoch": 6.735714285714286,
      "grad_norm": 0.0545017346739769,
      "learning_rate": 7.91731773739899e-06,
      "loss": 0.0089,
      "step": 188600
    },
    {
      "epoch": 6.739285714285714,
      "grad_norm": 0.03514612838625908,
      "learning_rate": 7.894995312290727e-06,
      "loss": 0.0089,
      "step": 188700
    },
    {
      "epoch": 6.742857142857143,
      "grad_norm": 0.04177582636475563,
      "learning_rate": 7.872672887182463e-06,
      "loss": 0.008,
      "step": 188800
    },
    {
      "epoch": 6.746428571428572,
      "grad_norm": 0.06371476501226425,
      "learning_rate": 7.850350462074201e-06,
      "loss": 0.0074,
      "step": 188900
    },
    {
      "epoch": 6.75,
      "grad_norm": 0.05313792824745178,
      "learning_rate": 7.828028036965938e-06,
      "loss": 0.0088,
      "step": 189000
    },
    {
      "epoch": 6.753571428571428,
      "grad_norm": 0.06428703665733337,
      "learning_rate": 7.805705611857672e-06,
      "loss": 0.0083,
      "step": 189100
    },
    {
      "epoch": 6.757142857142857,
      "grad_norm": 0.033226314932107925,
      "learning_rate": 7.783383186749409e-06,
      "loss": 0.0085,
      "step": 189200
    },
    {
      "epoch": 6.760714285714286,
      "grad_norm": 0.03132010996341705,
      "learning_rate": 7.761060761641145e-06,
      "loss": 0.0084,
      "step": 189300
    },
    {
      "epoch": 6.764285714285714,
      "grad_norm": 0.052932437509298325,
      "learning_rate": 7.738738336532881e-06,
      "loss": 0.0093,
      "step": 189400
    },
    {
      "epoch": 6.767857142857143,
      "grad_norm": 0.029906587675213814,
      "learning_rate": 7.716415911424618e-06,
      "loss": 0.0086,
      "step": 189500
    },
    {
      "epoch": 6.771428571428571,
      "grad_norm": 0.027976620942354202,
      "learning_rate": 7.694093486316354e-06,
      "loss": 0.0088,
      "step": 189600
    },
    {
      "epoch": 6.775,
      "grad_norm": 0.02234223112463951,
      "learning_rate": 7.67177106120809e-06,
      "loss": 0.0084,
      "step": 189700
    },
    {
      "epoch": 6.7785714285714285,
      "grad_norm": 0.048272814601659775,
      "learning_rate": 7.649448636099827e-06,
      "loss": 0.009,
      "step": 189800
    },
    {
      "epoch": 6.7821428571428575,
      "grad_norm": 0.03429451212286949,
      "learning_rate": 7.627126210991563e-06,
      "loss": 0.0085,
      "step": 189900
    },
    {
      "epoch": 6.785714285714286,
      "grad_norm": 0.07428042590618134,
      "learning_rate": 7.6048037858833e-06,
      "loss": 0.0085,
      "step": 190000
    },
    {
      "epoch": 6.789285714285715,
      "grad_norm": 0.03366008773446083,
      "learning_rate": 7.582481360775034e-06,
      "loss": 0.0085,
      "step": 190100
    },
    {
      "epoch": 6.792857142857143,
      "grad_norm": 0.042516354471445084,
      "learning_rate": 7.560158935666771e-06,
      "loss": 0.0082,
      "step": 190200
    },
    {
      "epoch": 6.796428571428572,
      "grad_norm": 0.05313694477081299,
      "learning_rate": 7.537836510558508e-06,
      "loss": 0.008,
      "step": 190300
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.014398284256458282,
      "learning_rate": 7.515514085450244e-06,
      "loss": 0.0085,
      "step": 190400
    },
    {
      "epoch": 6.803571428571429,
      "grad_norm": 0.04071148857474327,
      "learning_rate": 7.493191660341981e-06,
      "loss": 0.0086,
      "step": 190500
    },
    {
      "epoch": 6.807142857142857,
      "grad_norm": 0.047338493168354034,
      "learning_rate": 7.470869235233715e-06,
      "loss": 0.0087,
      "step": 190600
    },
    {
      "epoch": 6.810714285714286,
      "grad_norm": 0.03438102826476097,
      "learning_rate": 7.4485468101254525e-06,
      "loss": 0.0087,
      "step": 190700
    },
    {
      "epoch": 6.814285714285714,
      "grad_norm": 0.03524141013622284,
      "learning_rate": 7.426224385017189e-06,
      "loss": 0.0091,
      "step": 190800
    },
    {
      "epoch": 6.817857142857143,
      "grad_norm": 0.044042836874723434,
      "learning_rate": 7.403901959908925e-06,
      "loss": 0.0086,
      "step": 190900
    },
    {
      "epoch": 6.821428571428571,
      "grad_norm": 0.030925489962100983,
      "learning_rate": 7.3815795348006616e-06,
      "loss": 0.0086,
      "step": 191000
    },
    {
      "epoch": 6.825,
      "grad_norm": 0.04130902886390686,
      "learning_rate": 7.359257109692397e-06,
      "loss": 0.0082,
      "step": 191100
    },
    {
      "epoch": 6.828571428571428,
      "grad_norm": 0.04978133738040924,
      "learning_rate": 7.3369346845841334e-06,
      "loss": 0.0084,
      "step": 191200
    },
    {
      "epoch": 6.832142857142857,
      "grad_norm": 0.037988677620887756,
      "learning_rate": 7.31461225947587e-06,
      "loss": 0.0086,
      "step": 191300
    },
    {
      "epoch": 6.835714285714285,
      "grad_norm": 0.03533549606800079,
      "learning_rate": 7.292289834367606e-06,
      "loss": 0.009,
      "step": 191400
    },
    {
      "epoch": 6.839285714285714,
      "grad_norm": 0.07983517646789551,
      "learning_rate": 7.2699674092593425e-06,
      "loss": 0.0087,
      "step": 191500
    },
    {
      "epoch": 6.8428571428571425,
      "grad_norm": 0.07423660159111023,
      "learning_rate": 7.247644984151078e-06,
      "loss": 0.0085,
      "step": 191600
    },
    {
      "epoch": 6.8464285714285715,
      "grad_norm": 0.025268783792853355,
      "learning_rate": 7.225322559042814e-06,
      "loss": 0.0078,
      "step": 191700
    },
    {
      "epoch": 6.85,
      "grad_norm": 0.06214192882180214,
      "learning_rate": 7.203000133934551e-06,
      "loss": 0.0088,
      "step": 191800
    },
    {
      "epoch": 6.853571428571429,
      "grad_norm": 0.05680011957883835,
      "learning_rate": 7.180677708826287e-06,
      "loss": 0.0083,
      "step": 191900
    },
    {
      "epoch": 6.857142857142857,
      "grad_norm": 0.07289568334817886,
      "learning_rate": 7.158355283718024e-06,
      "loss": 0.0086,
      "step": 192000
    },
    {
      "epoch": 6.860714285714286,
      "grad_norm": 0.0808182805776596,
      "learning_rate": 7.136032858609759e-06,
      "loss": 0.0075,
      "step": 192100
    },
    {
      "epoch": 6.864285714285714,
      "grad_norm": 0.02810276299715042,
      "learning_rate": 7.113710433501495e-06,
      "loss": 0.008,
      "step": 192200
    },
    {
      "epoch": 6.867857142857143,
      "grad_norm": 0.08396600186824799,
      "learning_rate": 7.091388008393232e-06,
      "loss": 0.0085,
      "step": 192300
    },
    {
      "epoch": 6.871428571428572,
      "grad_norm": 0.05964134261012077,
      "learning_rate": 7.069065583284969e-06,
      "loss": 0.0081,
      "step": 192400
    },
    {
      "epoch": 6.875,
      "grad_norm": 0.05598371848464012,
      "learning_rate": 7.046966382427787e-06,
      "loss": 0.0084,
      "step": 192500
    },
    {
      "epoch": 6.878571428571428,
      "grad_norm": 0.03332720324397087,
      "learning_rate": 7.0246439573195234e-06,
      "loss": 0.0085,
      "step": 192600
    },
    {
      "epoch": 6.882142857142857,
      "grad_norm": 0.04711234197020531,
      "learning_rate": 7.002321532211261e-06,
      "loss": 0.0081,
      "step": 192700
    },
    {
      "epoch": 6.885714285714286,
      "grad_norm": 0.07746259868144989,
      "learning_rate": 6.979999107102995e-06,
      "loss": 0.0079,
      "step": 192800
    },
    {
      "epoch": 6.889285714285714,
      "grad_norm": 0.07336588948965073,
      "learning_rate": 6.957676681994732e-06,
      "loss": 0.0081,
      "step": 192900
    },
    {
      "epoch": 6.892857142857143,
      "grad_norm": 0.05939967557787895,
      "learning_rate": 6.935354256886469e-06,
      "loss": 0.0087,
      "step": 193000
    },
    {
      "epoch": 6.896428571428571,
      "grad_norm": 0.03613201156258583,
      "learning_rate": 6.913031831778205e-06,
      "loss": 0.0086,
      "step": 193100
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.03522363305091858,
      "learning_rate": 6.890709406669942e-06,
      "loss": 0.0083,
      "step": 193200
    },
    {
      "epoch": 6.9035714285714285,
      "grad_norm": 0.03724880889058113,
      "learning_rate": 6.868386981561676e-06,
      "loss": 0.0084,
      "step": 193300
    },
    {
      "epoch": 6.9071428571428575,
      "grad_norm": 0.07660070061683655,
      "learning_rate": 6.8460645564534135e-06,
      "loss": 0.0091,
      "step": 193400
    },
    {
      "epoch": 6.910714285714286,
      "grad_norm": 0.09942857921123505,
      "learning_rate": 6.82374213134515e-06,
      "loss": 0.0091,
      "step": 193500
    },
    {
      "epoch": 6.914285714285715,
      "grad_norm": 0.06939928978681564,
      "learning_rate": 6.801419706236886e-06,
      "loss": 0.0088,
      "step": 193600
    },
    {
      "epoch": 6.917857142857143,
      "grad_norm": 0.048735711723566055,
      "learning_rate": 6.779097281128623e-06,
      "loss": 0.0087,
      "step": 193700
    },
    {
      "epoch": 6.921428571428572,
      "grad_norm": 0.03235375136137009,
      "learning_rate": 6.756774856020358e-06,
      "loss": 0.0089,
      "step": 193800
    },
    {
      "epoch": 6.925,
      "grad_norm": 0.03873879462480545,
      "learning_rate": 6.7344524309120945e-06,
      "loss": 0.0084,
      "step": 193900
    },
    {
      "epoch": 6.928571428571429,
      "grad_norm": 0.02622007206082344,
      "learning_rate": 6.712130005803831e-06,
      "loss": 0.0084,
      "step": 194000
    },
    {
      "epoch": 6.932142857142857,
      "grad_norm": 0.05218997225165367,
      "learning_rate": 6.689807580695567e-06,
      "loss": 0.009,
      "step": 194100
    },
    {
      "epoch": 6.935714285714286,
      "grad_norm": 0.05924098938703537,
      "learning_rate": 6.667485155587304e-06,
      "loss": 0.0087,
      "step": 194200
    },
    {
      "epoch": 6.939285714285714,
      "grad_norm": 0.029170896857976913,
      "learning_rate": 6.645162730479039e-06,
      "loss": 0.0088,
      "step": 194300
    },
    {
      "epoch": 6.942857142857143,
      "grad_norm": 0.042124103754758835,
      "learning_rate": 6.6228403053707755e-06,
      "loss": 0.0084,
      "step": 194400
    },
    {
      "epoch": 6.946428571428571,
      "grad_norm": 0.0472627729177475,
      "learning_rate": 6.600517880262512e-06,
      "loss": 0.0088,
      "step": 194500
    },
    {
      "epoch": 6.95,
      "grad_norm": 0.0891457200050354,
      "learning_rate": 6.578195455154248e-06,
      "loss": 0.0087,
      "step": 194600
    },
    {
      "epoch": 6.953571428571428,
      "grad_norm": 0.05628795549273491,
      "learning_rate": 6.555873030045985e-06,
      "loss": 0.0089,
      "step": 194700
    },
    {
      "epoch": 6.957142857142857,
      "grad_norm": 0.029711218550801277,
      "learning_rate": 6.53355060493772e-06,
      "loss": 0.0083,
      "step": 194800
    },
    {
      "epoch": 6.960714285714285,
      "grad_norm": 0.04068025201559067,
      "learning_rate": 6.5112281798294564e-06,
      "loss": 0.0088,
      "step": 194900
    },
    {
      "epoch": 6.964285714285714,
      "grad_norm": 0.06575522571802139,
      "learning_rate": 6.489128978972275e-06,
      "loss": 0.0086,
      "step": 195000
    },
    {
      "epoch": 6.9678571428571425,
      "grad_norm": 0.027253221720457077,
      "learning_rate": 6.466806553864012e-06,
      "loss": 0.0095,
      "step": 195100
    },
    {
      "epoch": 6.9714285714285715,
      "grad_norm": 0.03490246459841728,
      "learning_rate": 6.444484128755748e-06,
      "loss": 0.0089,
      "step": 195200
    },
    {
      "epoch": 6.975,
      "grad_norm": 0.037983085960149765,
      "learning_rate": 6.4221617036474845e-06,
      "loss": 0.0089,
      "step": 195300
    },
    {
      "epoch": 6.978571428571429,
      "grad_norm": 0.04450606927275658,
      "learning_rate": 6.399839278539222e-06,
      "loss": 0.0082,
      "step": 195400
    },
    {
      "epoch": 6.982142857142857,
      "grad_norm": 0.04647433012723923,
      "learning_rate": 6.377516853430956e-06,
      "loss": 0.0094,
      "step": 195500
    },
    {
      "epoch": 6.985714285714286,
      "grad_norm": 0.05042248219251633,
      "learning_rate": 6.355194428322693e-06,
      "loss": 0.0088,
      "step": 195600
    },
    {
      "epoch": 6.989285714285714,
      "grad_norm": 0.03660226985812187,
      "learning_rate": 6.33287200321443e-06,
      "loss": 0.0083,
      "step": 195700
    },
    {
      "epoch": 6.992857142857143,
      "grad_norm": 0.03230855241417885,
      "learning_rate": 6.310549578106166e-06,
      "loss": 0.008,
      "step": 195800
    },
    {
      "epoch": 6.996428571428572,
      "grad_norm": 0.03879596292972565,
      "learning_rate": 6.288227152997903e-06,
      "loss": 0.0084,
      "step": 195900
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.07159564644098282,
      "learning_rate": 6.265904727889637e-06,
      "loss": 0.0087,
      "step": 196000
    },
    {
      "epoch": 7.0,
      "eval_accuracy_macro_0.5": 0.996941864490509,
      "eval_accuracy_micro_0.5": 0.9969418048858643,
      "eval_accuracy_weighted_0.5": 0.9932885766029358,
      "eval_aucroc_macro": 0.8596566319465637,
      "eval_aucroc_micro": 0.9026721119880676,
      "eval_aucroc_weighted": 0.9013595581054688,
      "eval_f1_macro_0.5": 0.5350632071495056,
      "eval_f1_macro_0.6": 0.4560379087924957,
      "eval_f1_macro_0.7": 0.36609023809432983,
      "eval_f1_macro_0.8": 0.1547846496105194,
      "eval_f1_micro_0.5": 0.6873721480369568,
      "eval_f1_micro_0.6": 0.6393948793411255,
      "eval_f1_micro_0.7": 0.560388445854187,
      "eval_f1_micro_0.8": 0.4358796775341034,
      "eval_f1_micro_0.9": 0.2596377432346344,
      "eval_f1_weighted_0.5": 0.6410492658615112,
      "eval_f1_weighted_0.6": 0.580713152885437,
      "eval_f1_weighted_0.7": 0.4944854974746704,
      "eval_f1_weighted_0.8": 0.20792299509048462,
      "eval_loss": 0.0072485520504415035,
      "eval_runtime": 1367.6838,
      "eval_samples_per_second": 40.697,
      "eval_steps_per_second": 5.087,
      "step": 196000
    }
  ],
  "logging_steps": 100,
  "max_steps": 224000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7930394421905536e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
