{
  "best_metric": 0.7207556366920471,
  "best_model_checkpoint": "alexander_cointegrated_rubert-tiny2/model bert lora level 1/checkpoint-199696",
  "epoch": 14.0,
  "eval_steps": 500,
  "global_step": 199696,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007010656197420078,
      "grad_norm": 0.6755964159965515,
      "learning_rate": 4.998028166545436e-05,
      "loss": 0.7344,
      "step": 100
    },
    {
      "epoch": 0.014021312394840156,
      "grad_norm": 0.3453054428100586,
      "learning_rate": 4.995837240484809e-05,
      "loss": 0.2644,
      "step": 200
    },
    {
      "epoch": 0.021031968592260235,
      "grad_norm": 0.29062730073928833,
      "learning_rate": 4.9936463144241814e-05,
      "loss": 0.1578,
      "step": 300
    },
    {
      "epoch": 0.028042624789680313,
      "grad_norm": 0.25448307394981384,
      "learning_rate": 4.991455388363554e-05,
      "loss": 0.1457,
      "step": 400
    },
    {
      "epoch": 0.035053280987100394,
      "grad_norm": 0.2199939340353012,
      "learning_rate": 4.989264462302927e-05,
      "loss": 0.137,
      "step": 500
    },
    {
      "epoch": 0.04206393718452047,
      "grad_norm": 0.22721679508686066,
      "learning_rate": 4.9870735362422995e-05,
      "loss": 0.1433,
      "step": 600
    },
    {
      "epoch": 0.04907459338194055,
      "grad_norm": 0.16419006884098053,
      "learning_rate": 4.984882610181672e-05,
      "loss": 0.1403,
      "step": 700
    },
    {
      "epoch": 0.056085249579360626,
      "grad_norm": 0.18388502299785614,
      "learning_rate": 4.982691684121045e-05,
      "loss": 0.1384,
      "step": 800
    },
    {
      "epoch": 0.0630959057767807,
      "grad_norm": 0.21838268637657166,
      "learning_rate": 4.9805007580604176e-05,
      "loss": 0.1388,
      "step": 900
    },
    {
      "epoch": 0.07010656197420079,
      "grad_norm": 0.19862528145313263,
      "learning_rate": 4.97830983199979e-05,
      "loss": 0.1476,
      "step": 1000
    },
    {
      "epoch": 0.07711721817162086,
      "grad_norm": 0.3261980712413788,
      "learning_rate": 4.976118905939163e-05,
      "loss": 0.1431,
      "step": 1100
    },
    {
      "epoch": 0.08412787436904094,
      "grad_norm": 0.18772070109844208,
      "learning_rate": 4.973927979878536e-05,
      "loss": 0.1325,
      "step": 1200
    },
    {
      "epoch": 0.09113853056646103,
      "grad_norm": 0.18837960064411163,
      "learning_rate": 4.9717370538179084e-05,
      "loss": 0.1402,
      "step": 1300
    },
    {
      "epoch": 0.0981491867638811,
      "grad_norm": 0.23567108809947968,
      "learning_rate": 4.969546127757281e-05,
      "loss": 0.1299,
      "step": 1400
    },
    {
      "epoch": 0.10515984296130118,
      "grad_norm": 0.20482736825942993,
      "learning_rate": 4.967355201696654e-05,
      "loss": 0.1361,
      "step": 1500
    },
    {
      "epoch": 0.11217049915872125,
      "grad_norm": 0.22088056802749634,
      "learning_rate": 4.9651642756360265e-05,
      "loss": 0.1387,
      "step": 1600
    },
    {
      "epoch": 0.11918115535614134,
      "grad_norm": 0.21087069809436798,
      "learning_rate": 4.962973349575399e-05,
      "loss": 0.1367,
      "step": 1700
    },
    {
      "epoch": 0.1261918115535614,
      "grad_norm": 0.16674640774726868,
      "learning_rate": 4.960782423514771e-05,
      "loss": 0.1335,
      "step": 1800
    },
    {
      "epoch": 0.1332024677509815,
      "grad_norm": 0.41808322072029114,
      "learning_rate": 4.958591497454144e-05,
      "loss": 0.1317,
      "step": 1900
    },
    {
      "epoch": 0.14021312394840157,
      "grad_norm": 0.21009398996829987,
      "learning_rate": 4.9564005713935166e-05,
      "loss": 0.1231,
      "step": 2000
    },
    {
      "epoch": 0.14722378014582166,
      "grad_norm": 0.20857825875282288,
      "learning_rate": 4.954209645332889e-05,
      "loss": 0.1314,
      "step": 2100
    },
    {
      "epoch": 0.15423443634324172,
      "grad_norm": 0.2254655510187149,
      "learning_rate": 4.952018719272262e-05,
      "loss": 0.1259,
      "step": 2200
    },
    {
      "epoch": 0.1612450925406618,
      "grad_norm": 0.2035609632730484,
      "learning_rate": 4.949827793211635e-05,
      "loss": 0.12,
      "step": 2300
    },
    {
      "epoch": 0.16825574873808188,
      "grad_norm": 0.18725056946277618,
      "learning_rate": 4.9476368671510074e-05,
      "loss": 0.1213,
      "step": 2400
    },
    {
      "epoch": 0.17526640493550197,
      "grad_norm": 0.17993250489234924,
      "learning_rate": 4.94544594109038e-05,
      "loss": 0.1226,
      "step": 2500
    },
    {
      "epoch": 0.18227706113292205,
      "grad_norm": 0.22616297006607056,
      "learning_rate": 4.943255015029753e-05,
      "loss": 0.1167,
      "step": 2600
    },
    {
      "epoch": 0.1892877173303421,
      "grad_norm": 0.20390120148658752,
      "learning_rate": 4.9410640889691255e-05,
      "loss": 0.1185,
      "step": 2700
    },
    {
      "epoch": 0.1962983735277622,
      "grad_norm": 0.23263634741306305,
      "learning_rate": 4.938873162908498e-05,
      "loss": 0.1188,
      "step": 2800
    },
    {
      "epoch": 0.20330902972518228,
      "grad_norm": 0.24182049930095673,
      "learning_rate": 4.936682236847871e-05,
      "loss": 0.1144,
      "step": 2900
    },
    {
      "epoch": 0.21031968592260236,
      "grad_norm": 0.16580551862716675,
      "learning_rate": 4.9344913107872436e-05,
      "loss": 0.1119,
      "step": 3000
    },
    {
      "epoch": 0.21733034212002245,
      "grad_norm": 0.1380140334367752,
      "learning_rate": 4.932300384726616e-05,
      "loss": 0.1137,
      "step": 3100
    },
    {
      "epoch": 0.2243409983174425,
      "grad_norm": 0.19028957188129425,
      "learning_rate": 4.930109458665989e-05,
      "loss": 0.1071,
      "step": 3200
    },
    {
      "epoch": 0.2313516545148626,
      "grad_norm": 0.21771879494190216,
      "learning_rate": 4.9279185326053617e-05,
      "loss": 0.1008,
      "step": 3300
    },
    {
      "epoch": 0.23836231071228267,
      "grad_norm": 0.19294555485248566,
      "learning_rate": 4.9257276065447344e-05,
      "loss": 0.1029,
      "step": 3400
    },
    {
      "epoch": 0.24537296690970276,
      "grad_norm": 0.2017790526151657,
      "learning_rate": 4.923536680484107e-05,
      "loss": 0.1089,
      "step": 3500
    },
    {
      "epoch": 0.2523836231071228,
      "grad_norm": 0.21667319536209106,
      "learning_rate": 4.92134575442348e-05,
      "loss": 0.1057,
      "step": 3600
    },
    {
      "epoch": 0.2593942793045429,
      "grad_norm": 0.19323445856571198,
      "learning_rate": 4.9191548283628525e-05,
      "loss": 0.1048,
      "step": 3700
    },
    {
      "epoch": 0.266404935501963,
      "grad_norm": 0.22235196828842163,
      "learning_rate": 4.916963902302225e-05,
      "loss": 0.1044,
      "step": 3800
    },
    {
      "epoch": 0.27341559169938306,
      "grad_norm": 0.15084771811962128,
      "learning_rate": 4.914772976241598e-05,
      "loss": 0.099,
      "step": 3900
    },
    {
      "epoch": 0.28042624789680315,
      "grad_norm": 0.2852044999599457,
      "learning_rate": 4.9125820501809705e-05,
      "loss": 0.0985,
      "step": 4000
    },
    {
      "epoch": 0.28743690409422323,
      "grad_norm": 0.13057053089141846,
      "learning_rate": 4.910391124120343e-05,
      "loss": 0.0945,
      "step": 4100
    },
    {
      "epoch": 0.2944475602916433,
      "grad_norm": 0.18323417007923126,
      "learning_rate": 4.908200198059716e-05,
      "loss": 0.0927,
      "step": 4200
    },
    {
      "epoch": 0.3014582164890634,
      "grad_norm": 0.1782911717891693,
      "learning_rate": 4.9060092719990886e-05,
      "loss": 0.0941,
      "step": 4300
    },
    {
      "epoch": 0.30846887268648343,
      "grad_norm": 0.24204188585281372,
      "learning_rate": 4.903818345938461e-05,
      "loss": 0.0935,
      "step": 4400
    },
    {
      "epoch": 0.3154795288839035,
      "grad_norm": 0.23444826900959015,
      "learning_rate": 4.901627419877835e-05,
      "loss": 0.0909,
      "step": 4500
    },
    {
      "epoch": 0.3224901850813236,
      "grad_norm": 0.275689035654068,
      "learning_rate": 4.8994364938172074e-05,
      "loss": 0.0939,
      "step": 4600
    },
    {
      "epoch": 0.3295008412787437,
      "grad_norm": 0.22424080967903137,
      "learning_rate": 4.89724556775658e-05,
      "loss": 0.0937,
      "step": 4700
    },
    {
      "epoch": 0.33651149747616377,
      "grad_norm": 0.20098885893821716,
      "learning_rate": 4.895054641695953e-05,
      "loss": 0.0939,
      "step": 4800
    },
    {
      "epoch": 0.34352215367358385,
      "grad_norm": 0.2899671494960785,
      "learning_rate": 4.8928637156353255e-05,
      "loss": 0.0959,
      "step": 4900
    },
    {
      "epoch": 0.35053280987100394,
      "grad_norm": 0.2780851423740387,
      "learning_rate": 4.890672789574698e-05,
      "loss": 0.0922,
      "step": 5000
    },
    {
      "epoch": 0.357543466068424,
      "grad_norm": 0.216263085603714,
      "learning_rate": 4.88848186351407e-05,
      "loss": 0.0907,
      "step": 5100
    },
    {
      "epoch": 0.3645541222658441,
      "grad_norm": 0.14709463715553284,
      "learning_rate": 4.886290937453443e-05,
      "loss": 0.0899,
      "step": 5200
    },
    {
      "epoch": 0.3715647784632642,
      "grad_norm": 0.31511953473091125,
      "learning_rate": 4.8841000113928156e-05,
      "loss": 0.0851,
      "step": 5300
    },
    {
      "epoch": 0.3785754346606842,
      "grad_norm": 0.1443542242050171,
      "learning_rate": 4.881909085332188e-05,
      "loss": 0.0888,
      "step": 5400
    },
    {
      "epoch": 0.3855860908581043,
      "grad_norm": 0.2730540931224823,
      "learning_rate": 4.879718159271561e-05,
      "loss": 0.0903,
      "step": 5500
    },
    {
      "epoch": 0.3925967470555244,
      "grad_norm": 0.1708865463733673,
      "learning_rate": 4.877527233210934e-05,
      "loss": 0.084,
      "step": 5600
    },
    {
      "epoch": 0.39960740325294447,
      "grad_norm": 0.25297680497169495,
      "learning_rate": 4.8753363071503064e-05,
      "loss": 0.0817,
      "step": 5700
    },
    {
      "epoch": 0.40661805945036456,
      "grad_norm": 0.19005738198757172,
      "learning_rate": 4.873145381089679e-05,
      "loss": 0.0835,
      "step": 5800
    },
    {
      "epoch": 0.41362871564778464,
      "grad_norm": 0.2508423924446106,
      "learning_rate": 4.870954455029052e-05,
      "loss": 0.088,
      "step": 5900
    },
    {
      "epoch": 0.4206393718452047,
      "grad_norm": 0.27224209904670715,
      "learning_rate": 4.8687635289684245e-05,
      "loss": 0.0793,
      "step": 6000
    },
    {
      "epoch": 0.4276500280426248,
      "grad_norm": 0.2642786204814911,
      "learning_rate": 4.866572602907797e-05,
      "loss": 0.0851,
      "step": 6100
    },
    {
      "epoch": 0.4346606842400449,
      "grad_norm": 0.28678494691848755,
      "learning_rate": 4.86438167684717e-05,
      "loss": 0.0856,
      "step": 6200
    },
    {
      "epoch": 0.4416713404374649,
      "grad_norm": 0.1719186156988144,
      "learning_rate": 4.8621907507865426e-05,
      "loss": 0.0805,
      "step": 6300
    },
    {
      "epoch": 0.448681996634885,
      "grad_norm": 0.13189449906349182,
      "learning_rate": 4.859999824725915e-05,
      "loss": 0.081,
      "step": 6400
    },
    {
      "epoch": 0.4556926528323051,
      "grad_norm": 0.17339055240154266,
      "learning_rate": 4.857808898665288e-05,
      "loss": 0.0872,
      "step": 6500
    },
    {
      "epoch": 0.4627033090297252,
      "grad_norm": 0.3254707157611847,
      "learning_rate": 4.855617972604661e-05,
      "loss": 0.0864,
      "step": 6600
    },
    {
      "epoch": 0.46971396522714526,
      "grad_norm": 0.3309250771999359,
      "learning_rate": 4.8534270465440334e-05,
      "loss": 0.0852,
      "step": 6700
    },
    {
      "epoch": 0.47672462142456534,
      "grad_norm": 0.262061208486557,
      "learning_rate": 4.851236120483406e-05,
      "loss": 0.0832,
      "step": 6800
    },
    {
      "epoch": 0.4837352776219854,
      "grad_norm": 0.2065291553735733,
      "learning_rate": 4.849045194422779e-05,
      "loss": 0.0838,
      "step": 6900
    },
    {
      "epoch": 0.4907459338194055,
      "grad_norm": 0.1743497997522354,
      "learning_rate": 4.8468542683621515e-05,
      "loss": 0.0808,
      "step": 7000
    },
    {
      "epoch": 0.4977565900168256,
      "grad_norm": 0.18083594739437103,
      "learning_rate": 4.844663342301524e-05,
      "loss": 0.0797,
      "step": 7100
    },
    {
      "epoch": 0.5047672462142456,
      "grad_norm": 0.1058853417634964,
      "learning_rate": 4.842472416240897e-05,
      "loss": 0.0838,
      "step": 7200
    },
    {
      "epoch": 0.5117779024116658,
      "grad_norm": 0.2869972288608551,
      "learning_rate": 4.8402814901802696e-05,
      "loss": 0.0842,
      "step": 7300
    },
    {
      "epoch": 0.5187885586090858,
      "grad_norm": 0.3260858356952667,
      "learning_rate": 4.838090564119642e-05,
      "loss": 0.079,
      "step": 7400
    },
    {
      "epoch": 0.5257992148065059,
      "grad_norm": 0.21569278836250305,
      "learning_rate": 4.835899638059015e-05,
      "loss": 0.079,
      "step": 7500
    },
    {
      "epoch": 0.532809871003926,
      "grad_norm": 0.1799796223640442,
      "learning_rate": 4.833708711998388e-05,
      "loss": 0.0825,
      "step": 7600
    },
    {
      "epoch": 0.5398205272013461,
      "grad_norm": 0.27823305130004883,
      "learning_rate": 4.8315177859377604e-05,
      "loss": 0.078,
      "step": 7700
    },
    {
      "epoch": 0.5468311833987661,
      "grad_norm": 0.22963902354240417,
      "learning_rate": 4.829326859877133e-05,
      "loss": 0.0713,
      "step": 7800
    },
    {
      "epoch": 0.5538418395961862,
      "grad_norm": 0.23733077943325043,
      "learning_rate": 4.827135933816506e-05,
      "loss": 0.0756,
      "step": 7900
    },
    {
      "epoch": 0.5608524957936063,
      "grad_norm": 0.24216847121715546,
      "learning_rate": 4.8249450077558785e-05,
      "loss": 0.0804,
      "step": 8000
    },
    {
      "epoch": 0.5678631519910263,
      "grad_norm": 0.2648751735687256,
      "learning_rate": 4.822754081695251e-05,
      "loss": 0.0821,
      "step": 8100
    },
    {
      "epoch": 0.5748738081884465,
      "grad_norm": 0.16625827550888062,
      "learning_rate": 4.820563155634624e-05,
      "loss": 0.0752,
      "step": 8200
    },
    {
      "epoch": 0.5818844643858665,
      "grad_norm": 0.17712099850177765,
      "learning_rate": 4.8183722295739966e-05,
      "loss": 0.0747,
      "step": 8300
    },
    {
      "epoch": 0.5888951205832866,
      "grad_norm": 0.14334967732429504,
      "learning_rate": 4.816181303513369e-05,
      "loss": 0.0772,
      "step": 8400
    },
    {
      "epoch": 0.5959057767807067,
      "grad_norm": 0.1815708726644516,
      "learning_rate": 4.813990377452742e-05,
      "loss": 0.0737,
      "step": 8500
    },
    {
      "epoch": 0.6029164329781268,
      "grad_norm": 0.21250298619270325,
      "learning_rate": 4.8117994513921146e-05,
      "loss": 0.0726,
      "step": 8600
    },
    {
      "epoch": 0.6099270891755468,
      "grad_norm": 0.2607995867729187,
      "learning_rate": 4.8096085253314873e-05,
      "loss": 0.0772,
      "step": 8700
    },
    {
      "epoch": 0.6169377453729669,
      "grad_norm": 0.1477578580379486,
      "learning_rate": 4.80741759927086e-05,
      "loss": 0.0774,
      "step": 8800
    },
    {
      "epoch": 0.623948401570387,
      "grad_norm": 0.22850164771080017,
      "learning_rate": 4.805226673210233e-05,
      "loss": 0.0773,
      "step": 8900
    },
    {
      "epoch": 0.630959057767807,
      "grad_norm": 0.1706344038248062,
      "learning_rate": 4.8030357471496054e-05,
      "loss": 0.0738,
      "step": 9000
    },
    {
      "epoch": 0.6379697139652272,
      "grad_norm": 0.353028804063797,
      "learning_rate": 4.800844821088978e-05,
      "loss": 0.0811,
      "step": 9100
    },
    {
      "epoch": 0.6449803701626472,
      "grad_norm": 0.1720205843448639,
      "learning_rate": 4.798653895028351e-05,
      "loss": 0.0731,
      "step": 9200
    },
    {
      "epoch": 0.6519910263600673,
      "grad_norm": 0.1811838448047638,
      "learning_rate": 4.7964629689677235e-05,
      "loss": 0.0775,
      "step": 9300
    },
    {
      "epoch": 0.6590016825574874,
      "grad_norm": 0.23969727754592896,
      "learning_rate": 4.794272042907096e-05,
      "loss": 0.0735,
      "step": 9400
    },
    {
      "epoch": 0.6660123387549075,
      "grad_norm": 0.17392337322235107,
      "learning_rate": 4.792081116846469e-05,
      "loss": 0.0837,
      "step": 9500
    },
    {
      "epoch": 0.6730229949523275,
      "grad_norm": 0.19066603481769562,
      "learning_rate": 4.7898901907858416e-05,
      "loss": 0.077,
      "step": 9600
    },
    {
      "epoch": 0.6800336511497476,
      "grad_norm": 0.1666703224182129,
      "learning_rate": 4.787699264725214e-05,
      "loss": 0.0751,
      "step": 9700
    },
    {
      "epoch": 0.6870443073471677,
      "grad_norm": 0.17526577413082123,
      "learning_rate": 4.785508338664587e-05,
      "loss": 0.0789,
      "step": 9800
    },
    {
      "epoch": 0.6940549635445877,
      "grad_norm": 0.08965291827917099,
      "learning_rate": 4.78331741260396e-05,
      "loss": 0.0721,
      "step": 9900
    },
    {
      "epoch": 0.7010656197420079,
      "grad_norm": 0.13079434633255005,
      "learning_rate": 4.7811264865433324e-05,
      "loss": 0.0704,
      "step": 10000
    },
    {
      "epoch": 0.7080762759394279,
      "grad_norm": 0.21829856932163239,
      "learning_rate": 4.778935560482705e-05,
      "loss": 0.0728,
      "step": 10100
    },
    {
      "epoch": 0.715086932136848,
      "grad_norm": 0.2615979015827179,
      "learning_rate": 4.776744634422078e-05,
      "loss": 0.0735,
      "step": 10200
    },
    {
      "epoch": 0.7220975883342681,
      "grad_norm": 0.12267456948757172,
      "learning_rate": 4.7745537083614505e-05,
      "loss": 0.0733,
      "step": 10300
    },
    {
      "epoch": 0.7291082445316882,
      "grad_norm": 0.2134794145822525,
      "learning_rate": 4.772362782300823e-05,
      "loss": 0.0753,
      "step": 10400
    },
    {
      "epoch": 0.7361189007291082,
      "grad_norm": 0.37417373061180115,
      "learning_rate": 4.770193765500802e-05,
      "loss": 0.0729,
      "step": 10500
    },
    {
      "epoch": 0.7431295569265284,
      "grad_norm": 0.2531581521034241,
      "learning_rate": 4.768002839440175e-05,
      "loss": 0.0722,
      "step": 10600
    },
    {
      "epoch": 0.7501402131239484,
      "grad_norm": 0.2107086330652237,
      "learning_rate": 4.765811913379548e-05,
      "loss": 0.0725,
      "step": 10700
    },
    {
      "epoch": 0.7571508693213684,
      "grad_norm": 0.3481792211532593,
      "learning_rate": 4.7636209873189204e-05,
      "loss": 0.0706,
      "step": 10800
    },
    {
      "epoch": 0.7641615255187886,
      "grad_norm": 0.19364386796951294,
      "learning_rate": 4.761430061258293e-05,
      "loss": 0.0749,
      "step": 10900
    },
    {
      "epoch": 0.7711721817162086,
      "grad_norm": 0.24325475096702576,
      "learning_rate": 4.759239135197666e-05,
      "loss": 0.0704,
      "step": 11000
    },
    {
      "epoch": 0.7781828379136287,
      "grad_norm": 0.19051963090896606,
      "learning_rate": 4.7570482091370385e-05,
      "loss": 0.07,
      "step": 11100
    },
    {
      "epoch": 0.7851934941110488,
      "grad_norm": 0.19926099479198456,
      "learning_rate": 4.754857283076411e-05,
      "loss": 0.0727,
      "step": 11200
    },
    {
      "epoch": 0.7922041503084689,
      "grad_norm": 0.1444036364555359,
      "learning_rate": 4.752666357015784e-05,
      "loss": 0.0725,
      "step": 11300
    },
    {
      "epoch": 0.7992148065058889,
      "grad_norm": 0.13709139823913574,
      "learning_rate": 4.7504754309551566e-05,
      "loss": 0.0712,
      "step": 11400
    },
    {
      "epoch": 0.8062254627033091,
      "grad_norm": 0.1600741595029831,
      "learning_rate": 4.748284504894529e-05,
      "loss": 0.0748,
      "step": 11500
    },
    {
      "epoch": 0.8132361189007291,
      "grad_norm": 0.20052267611026764,
      "learning_rate": 4.746093578833902e-05,
      "loss": 0.0716,
      "step": 11600
    },
    {
      "epoch": 0.8202467750981491,
      "grad_norm": 0.2951289415359497,
      "learning_rate": 4.7439026527732747e-05,
      "loss": 0.0732,
      "step": 11700
    },
    {
      "epoch": 0.8272574312955693,
      "grad_norm": 0.2811987102031708,
      "learning_rate": 4.7417117267126474e-05,
      "loss": 0.0695,
      "step": 11800
    },
    {
      "epoch": 0.8342680874929893,
      "grad_norm": 0.21940109133720398,
      "learning_rate": 4.73952080065202e-05,
      "loss": 0.0746,
      "step": 11900
    },
    {
      "epoch": 0.8412787436904094,
      "grad_norm": 0.22191046178340912,
      "learning_rate": 4.737329874591393e-05,
      "loss": 0.0733,
      "step": 12000
    },
    {
      "epoch": 0.8482893998878295,
      "grad_norm": 0.2432464361190796,
      "learning_rate": 4.7351389485307654e-05,
      "loss": 0.0735,
      "step": 12100
    },
    {
      "epoch": 0.8553000560852496,
      "grad_norm": 0.3043438792228699,
      "learning_rate": 4.7329480224701375e-05,
      "loss": 0.0775,
      "step": 12200
    },
    {
      "epoch": 0.8623107122826696,
      "grad_norm": 0.14095793664455414,
      "learning_rate": 4.73075709640951e-05,
      "loss": 0.0681,
      "step": 12300
    },
    {
      "epoch": 0.8693213684800898,
      "grad_norm": 0.23873476684093475,
      "learning_rate": 4.728566170348883e-05,
      "loss": 0.0728,
      "step": 12400
    },
    {
      "epoch": 0.8763320246775098,
      "grad_norm": 0.09830799698829651,
      "learning_rate": 4.7263752442882556e-05,
      "loss": 0.072,
      "step": 12500
    },
    {
      "epoch": 0.8833426808749298,
      "grad_norm": 0.1174599677324295,
      "learning_rate": 4.724184318227628e-05,
      "loss": 0.0686,
      "step": 12600
    },
    {
      "epoch": 0.89035333707235,
      "grad_norm": 0.1414819210767746,
      "learning_rate": 4.721993392167001e-05,
      "loss": 0.0695,
      "step": 12700
    },
    {
      "epoch": 0.89736399326977,
      "grad_norm": 0.2803860306739807,
      "learning_rate": 4.7198024661063737e-05,
      "loss": 0.0707,
      "step": 12800
    },
    {
      "epoch": 0.9043746494671902,
      "grad_norm": 0.3023838400840759,
      "learning_rate": 4.7176115400457463e-05,
      "loss": 0.0737,
      "step": 12900
    },
    {
      "epoch": 0.9113853056646102,
      "grad_norm": 0.131661519408226,
      "learning_rate": 4.715420613985119e-05,
      "loss": 0.07,
      "step": 13000
    },
    {
      "epoch": 0.9183959618620303,
      "grad_norm": 0.18368445336818695,
      "learning_rate": 4.713229687924492e-05,
      "loss": 0.0723,
      "step": 13100
    },
    {
      "epoch": 0.9254066180594503,
      "grad_norm": 0.3322727680206299,
      "learning_rate": 4.7110387618638644e-05,
      "loss": 0.0692,
      "step": 13200
    },
    {
      "epoch": 0.9324172742568705,
      "grad_norm": 0.19834484159946442,
      "learning_rate": 4.708847835803237e-05,
      "loss": 0.071,
      "step": 13300
    },
    {
      "epoch": 0.9394279304542905,
      "grad_norm": 0.23660875856876373,
      "learning_rate": 4.70665690974261e-05,
      "loss": 0.0704,
      "step": 13400
    },
    {
      "epoch": 0.9464385866517105,
      "grad_norm": 0.2779746949672699,
      "learning_rate": 4.7044659836819825e-05,
      "loss": 0.0728,
      "step": 13500
    },
    {
      "epoch": 0.9534492428491307,
      "grad_norm": 0.12202122062444687,
      "learning_rate": 4.702275057621356e-05,
      "loss": 0.0735,
      "step": 13600
    },
    {
      "epoch": 0.9604598990465507,
      "grad_norm": 0.24315661191940308,
      "learning_rate": 4.7000841315607286e-05,
      "loss": 0.0691,
      "step": 13700
    },
    {
      "epoch": 0.9674705552439709,
      "grad_norm": 0.14268812537193298,
      "learning_rate": 4.697893205500101e-05,
      "loss": 0.0693,
      "step": 13800
    },
    {
      "epoch": 0.9744812114413909,
      "grad_norm": 0.1732271909713745,
      "learning_rate": 4.6957241887000804e-05,
      "loss": 0.0691,
      "step": 13900
    },
    {
      "epoch": 0.981491867638811,
      "grad_norm": 0.17850349843502045,
      "learning_rate": 4.693533262639453e-05,
      "loss": 0.0709,
      "step": 14000
    },
    {
      "epoch": 0.988502523836231,
      "grad_norm": 0.17729130387306213,
      "learning_rate": 4.691342336578826e-05,
      "loss": 0.0684,
      "step": 14100
    },
    {
      "epoch": 0.9955131800336512,
      "grad_norm": 0.20495839416980743,
      "learning_rate": 4.6891514105181985e-05,
      "loss": 0.0703,
      "step": 14200
    },
    {
      "epoch": 1.0,
      "eval_accuracy_macro_0.5": 0.9719842672348022,
      "eval_accuracy_micro_0.5": 0.971984326839447,
      "eval_accuracy_weighted_0.5": 0.9575849771499634,
      "eval_aucroc_macro": 0.8170337080955505,
      "eval_aucroc_micro": 0.8479738235473633,
      "eval_aucroc_weighted": 0.8407884240150452,
      "eval_f1_macro_0.5": 0.47991910576820374,
      "eval_f1_macro_0.6": 0.39632970094680786,
      "eval_f1_macro_0.7": 0.3062737286090851,
      "eval_f1_macro_0.8": 0.07338273525238037,
      "eval_f1_micro_0.5": 0.5770664811134338,
      "eval_f1_micro_0.6": 0.5127269625663757,
      "eval_f1_micro_0.7": 0.42877113819122314,
      "eval_f1_micro_0.8": 0.3162069320678711,
      "eval_f1_micro_0.9": 0.11579161882400513,
      "eval_f1_weighted_0.5": 0.5407246947288513,
      "eval_f1_weighted_0.6": 0.4598159193992615,
      "eval_f1_weighted_0.7": 0.3700644075870514,
      "eval_f1_weighted_0.8": 0.10520044714212418,
      "eval_loss": 0.06720340251922607,
      "eval_runtime": 68.7869,
      "eval_samples_per_second": 413.945,
      "eval_steps_per_second": 51.754,
      "step": 14264
    },
    {
      "epoch": 1.0025238362310713,
      "grad_norm": 0.1228146031498909,
      "learning_rate": 4.686960484457571e-05,
      "loss": 0.0688,
      "step": 14300
    },
    {
      "epoch": 1.0095344924284912,
      "grad_norm": 0.31037095189094543,
      "learning_rate": 4.684769558396944e-05,
      "loss": 0.0678,
      "step": 14400
    },
    {
      "epoch": 1.0165451486259114,
      "grad_norm": 0.22109638154506683,
      "learning_rate": 4.6825786323363166e-05,
      "loss": 0.0698,
      "step": 14500
    },
    {
      "epoch": 1.0235558048233315,
      "grad_norm": 0.27506762742996216,
      "learning_rate": 4.680387706275689e-05,
      "loss": 0.0733,
      "step": 14600
    },
    {
      "epoch": 1.0305664610207514,
      "grad_norm": 0.21687553822994232,
      "learning_rate": 4.678196780215062e-05,
      "loss": 0.0676,
      "step": 14700
    },
    {
      "epoch": 1.0375771172181716,
      "grad_norm": 0.20049051940441132,
      "learning_rate": 4.6760058541544347e-05,
      "loss": 0.0685,
      "step": 14800
    },
    {
      "epoch": 1.0445877734155917,
      "grad_norm": 0.20734909176826477,
      "learning_rate": 4.6738149280938074e-05,
      "loss": 0.0755,
      "step": 14900
    },
    {
      "epoch": 1.0515984296130119,
      "grad_norm": 0.19364218413829803,
      "learning_rate": 4.67162400203318e-05,
      "loss": 0.0671,
      "step": 15000
    },
    {
      "epoch": 1.0586090858104318,
      "grad_norm": 0.15234458446502686,
      "learning_rate": 4.669433075972553e-05,
      "loss": 0.0736,
      "step": 15100
    },
    {
      "epoch": 1.065619742007852,
      "grad_norm": 0.244174987077713,
      "learning_rate": 4.667242149911925e-05,
      "loss": 0.0661,
      "step": 15200
    },
    {
      "epoch": 1.072630398205272,
      "grad_norm": 0.23320496082305908,
      "learning_rate": 4.6650512238512975e-05,
      "loss": 0.0704,
      "step": 15300
    },
    {
      "epoch": 1.0796410544026922,
      "grad_norm": 0.25091323256492615,
      "learning_rate": 4.66286029779067e-05,
      "loss": 0.066,
      "step": 15400
    },
    {
      "epoch": 1.0866517106001121,
      "grad_norm": 0.11504325270652771,
      "learning_rate": 4.660669371730043e-05,
      "loss": 0.0696,
      "step": 15500
    },
    {
      "epoch": 1.0936623667975323,
      "grad_norm": 0.17561353743076324,
      "learning_rate": 4.6584784456694156e-05,
      "loss": 0.067,
      "step": 15600
    },
    {
      "epoch": 1.1006730229949524,
      "grad_norm": 0.13007311522960663,
      "learning_rate": 4.656287519608788e-05,
      "loss": 0.0684,
      "step": 15700
    },
    {
      "epoch": 1.1076836791923723,
      "grad_norm": 0.16145087778568268,
      "learning_rate": 4.654096593548161e-05,
      "loss": 0.0702,
      "step": 15800
    },
    {
      "epoch": 1.1146943353897925,
      "grad_norm": 0.14013944566249847,
      "learning_rate": 4.6519056674875337e-05,
      "loss": 0.0698,
      "step": 15900
    },
    {
      "epoch": 1.1217049915872126,
      "grad_norm": 0.31390050053596497,
      "learning_rate": 4.6497147414269064e-05,
      "loss": 0.0648,
      "step": 16000
    },
    {
      "epoch": 1.1287156477846327,
      "grad_norm": 0.2558261454105377,
      "learning_rate": 4.647523815366279e-05,
      "loss": 0.0649,
      "step": 16100
    },
    {
      "epoch": 1.1357263039820527,
      "grad_norm": 0.15272484719753265,
      "learning_rate": 4.645332889305652e-05,
      "loss": 0.0658,
      "step": 16200
    },
    {
      "epoch": 1.1427369601794728,
      "grad_norm": 0.23128017783164978,
      "learning_rate": 4.6431419632450244e-05,
      "loss": 0.0674,
      "step": 16300
    },
    {
      "epoch": 1.149747616376893,
      "grad_norm": 0.15083378553390503,
      "learning_rate": 4.640951037184397e-05,
      "loss": 0.0629,
      "step": 16400
    },
    {
      "epoch": 1.1567582725743129,
      "grad_norm": 0.21423715353012085,
      "learning_rate": 4.63876011112377e-05,
      "loss": 0.0672,
      "step": 16500
    },
    {
      "epoch": 1.163768928771733,
      "grad_norm": 0.13445936143398285,
      "learning_rate": 4.6365691850631425e-05,
      "loss": 0.0651,
      "step": 16600
    },
    {
      "epoch": 1.1707795849691531,
      "grad_norm": 0.20047533512115479,
      "learning_rate": 4.634378259002515e-05,
      "loss": 0.0712,
      "step": 16700
    },
    {
      "epoch": 1.1777902411665733,
      "grad_norm": 0.1590646654367447,
      "learning_rate": 4.632209242202494e-05,
      "loss": 0.0685,
      "step": 16800
    },
    {
      "epoch": 1.1848008973639932,
      "grad_norm": 0.42199307680130005,
      "learning_rate": 4.630018316141867e-05,
      "loss": 0.0675,
      "step": 16900
    },
    {
      "epoch": 1.1918115535614133,
      "grad_norm": 0.3138735890388489,
      "learning_rate": 4.62782739008124e-05,
      "loss": 0.0663,
      "step": 17000
    },
    {
      "epoch": 1.1988222097588335,
      "grad_norm": 0.1283852756023407,
      "learning_rate": 4.6256364640206124e-05,
      "loss": 0.0656,
      "step": 17100
    },
    {
      "epoch": 1.2058328659562534,
      "grad_norm": 0.17349563539028168,
      "learning_rate": 4.623445537959985e-05,
      "loss": 0.063,
      "step": 17200
    },
    {
      "epoch": 1.2128435221536735,
      "grad_norm": 0.3443151116371155,
      "learning_rate": 4.621254611899358e-05,
      "loss": 0.0639,
      "step": 17300
    },
    {
      "epoch": 1.2198541783510937,
      "grad_norm": 0.2792016863822937,
      "learning_rate": 4.6190636858387305e-05,
      "loss": 0.0647,
      "step": 17400
    },
    {
      "epoch": 1.2268648345485138,
      "grad_norm": 0.5175113081932068,
      "learning_rate": 4.616872759778103e-05,
      "loss": 0.068,
      "step": 17500
    },
    {
      "epoch": 1.2338754907459337,
      "grad_norm": 0.11417476087808609,
      "learning_rate": 4.614681833717476e-05,
      "loss": 0.0666,
      "step": 17600
    },
    {
      "epoch": 1.2408861469433539,
      "grad_norm": 0.2673485577106476,
      "learning_rate": 4.6124909076568486e-05,
      "loss": 0.0617,
      "step": 17700
    },
    {
      "epoch": 1.247896803140774,
      "grad_norm": 0.2845017611980438,
      "learning_rate": 4.610299981596221e-05,
      "loss": 0.066,
      "step": 17800
    },
    {
      "epoch": 1.254907459338194,
      "grad_norm": 0.30250784754753113,
      "learning_rate": 4.608109055535594e-05,
      "loss": 0.0668,
      "step": 17900
    },
    {
      "epoch": 1.261918115535614,
      "grad_norm": 0.3155618906021118,
      "learning_rate": 4.605918129474967e-05,
      "loss": 0.0652,
      "step": 18000
    },
    {
      "epoch": 1.2689287717330342,
      "grad_norm": 0.172611802816391,
      "learning_rate": 4.6037272034143394e-05,
      "loss": 0.0652,
      "step": 18100
    },
    {
      "epoch": 1.2759394279304543,
      "grad_norm": 0.14582614600658417,
      "learning_rate": 4.601536277353712e-05,
      "loss": 0.0641,
      "step": 18200
    },
    {
      "epoch": 1.2829500841278745,
      "grad_norm": 0.1390463411808014,
      "learning_rate": 4.599345351293085e-05,
      "loss": 0.0664,
      "step": 18300
    },
    {
      "epoch": 1.2899607403252944,
      "grad_norm": 0.13929970562458038,
      "learning_rate": 4.5971544252324575e-05,
      "loss": 0.0668,
      "step": 18400
    },
    {
      "epoch": 1.2969713965227145,
      "grad_norm": 0.1571340709924698,
      "learning_rate": 4.59496349917183e-05,
      "loss": 0.0656,
      "step": 18500
    },
    {
      "epoch": 1.3039820527201347,
      "grad_norm": 0.1392408162355423,
      "learning_rate": 4.592772573111203e-05,
      "loss": 0.0682,
      "step": 18600
    },
    {
      "epoch": 1.3109927089175546,
      "grad_norm": 0.16026461124420166,
      "learning_rate": 4.5905816470505756e-05,
      "loss": 0.0675,
      "step": 18700
    },
    {
      "epoch": 1.3180033651149747,
      "grad_norm": 0.1360011249780655,
      "learning_rate": 4.5884126302505546e-05,
      "loss": 0.067,
      "step": 18800
    },
    {
      "epoch": 1.3250140213123949,
      "grad_norm": 0.2540449798107147,
      "learning_rate": 4.5862217041899273e-05,
      "loss": 0.0678,
      "step": 18900
    },
    {
      "epoch": 1.332024677509815,
      "grad_norm": 0.14984296262264252,
      "learning_rate": 4.5840307781293e-05,
      "loss": 0.0659,
      "step": 19000
    },
    {
      "epoch": 1.339035333707235,
      "grad_norm": 0.2548186480998993,
      "learning_rate": 4.581839852068673e-05,
      "loss": 0.0663,
      "step": 19100
    },
    {
      "epoch": 1.346045989904655,
      "grad_norm": 0.17378784716129303,
      "learning_rate": 4.5796489260080454e-05,
      "loss": 0.0648,
      "step": 19200
    },
    {
      "epoch": 1.3530566461020752,
      "grad_norm": 0.32657110691070557,
      "learning_rate": 4.577457999947418e-05,
      "loss": 0.0666,
      "step": 19300
    },
    {
      "epoch": 1.3600673022994951,
      "grad_norm": 0.13366125524044037,
      "learning_rate": 4.575267073886791e-05,
      "loss": 0.0689,
      "step": 19400
    },
    {
      "epoch": 1.3670779584969153,
      "grad_norm": 0.21773113310337067,
      "learning_rate": 4.5730761478261635e-05,
      "loss": 0.0664,
      "step": 19500
    },
    {
      "epoch": 1.3740886146943354,
      "grad_norm": 0.1180102527141571,
      "learning_rate": 4.570885221765536e-05,
      "loss": 0.0654,
      "step": 19600
    },
    {
      "epoch": 1.3810992708917555,
      "grad_norm": 0.3025512397289276,
      "learning_rate": 4.568694295704909e-05,
      "loss": 0.0637,
      "step": 19700
    },
    {
      "epoch": 1.3881099270891755,
      "grad_norm": 0.11673542112112045,
      "learning_rate": 4.5665033696442816e-05,
      "loss": 0.0663,
      "step": 19800
    },
    {
      "epoch": 1.3951205832865956,
      "grad_norm": 0.17666563391685486,
      "learning_rate": 4.564312443583654e-05,
      "loss": 0.0678,
      "step": 19900
    },
    {
      "epoch": 1.4021312394840157,
      "grad_norm": 0.25837016105651855,
      "learning_rate": 4.562121517523027e-05,
      "loss": 0.0677,
      "step": 20000
    },
    {
      "epoch": 1.4091418956814357,
      "grad_norm": 0.3044212758541107,
      "learning_rate": 4.5599305914624e-05,
      "loss": 0.0662,
      "step": 20100
    },
    {
      "epoch": 1.4161525518788558,
      "grad_norm": 0.39468997716903687,
      "learning_rate": 4.5577396654017724e-05,
      "loss": 0.0667,
      "step": 20200
    },
    {
      "epoch": 1.423163208076276,
      "grad_norm": 0.22100889682769775,
      "learning_rate": 4.555548739341145e-05,
      "loss": 0.0647,
      "step": 20300
    },
    {
      "epoch": 1.430173864273696,
      "grad_norm": 0.17798620462417603,
      "learning_rate": 4.553357813280518e-05,
      "loss": 0.0639,
      "step": 20400
    },
    {
      "epoch": 1.4371845204711162,
      "grad_norm": 0.2404893934726715,
      "learning_rate": 4.5511668872198905e-05,
      "loss": 0.0669,
      "step": 20500
    },
    {
      "epoch": 1.4441951766685361,
      "grad_norm": 0.18083490431308746,
      "learning_rate": 4.548975961159263e-05,
      "loss": 0.0685,
      "step": 20600
    },
    {
      "epoch": 1.4512058328659563,
      "grad_norm": 0.22802981734275818,
      "learning_rate": 4.546785035098636e-05,
      "loss": 0.073,
      "step": 20700
    },
    {
      "epoch": 1.4582164890633762,
      "grad_norm": 0.16422434151172638,
      "learning_rate": 4.544616018298615e-05,
      "loss": 0.0629,
      "step": 20800
    },
    {
      "epoch": 1.4652271452607963,
      "grad_norm": 0.25585484504699707,
      "learning_rate": 4.542425092237988e-05,
      "loss": 0.066,
      "step": 20900
    },
    {
      "epoch": 1.4722378014582165,
      "grad_norm": 0.21957029402256012,
      "learning_rate": 4.5402341661773604e-05,
      "loss": 0.0701,
      "step": 21000
    },
    {
      "epoch": 1.4792484576556366,
      "grad_norm": 0.19291236996650696,
      "learning_rate": 4.538043240116733e-05,
      "loss": 0.0643,
      "step": 21100
    },
    {
      "epoch": 1.4862591138530568,
      "grad_norm": 0.1433984786272049,
      "learning_rate": 4.535852314056106e-05,
      "loss": 0.0621,
      "step": 21200
    },
    {
      "epoch": 1.4932697700504767,
      "grad_norm": 0.19429795444011688,
      "learning_rate": 4.533661387995478e-05,
      "loss": 0.0625,
      "step": 21300
    },
    {
      "epoch": 1.5002804262478968,
      "grad_norm": 0.21588853001594543,
      "learning_rate": 4.5314704619348505e-05,
      "loss": 0.0695,
      "step": 21400
    },
    {
      "epoch": 1.5072910824453167,
      "grad_norm": 0.145250603556633,
      "learning_rate": 4.529279535874223e-05,
      "loss": 0.0648,
      "step": 21500
    },
    {
      "epoch": 1.5143017386427369,
      "grad_norm": 0.40225517749786377,
      "learning_rate": 4.527088609813596e-05,
      "loss": 0.0676,
      "step": 21600
    },
    {
      "epoch": 1.521312394840157,
      "grad_norm": 0.23894107341766357,
      "learning_rate": 4.5248976837529686e-05,
      "loss": 0.0651,
      "step": 21700
    },
    {
      "epoch": 1.5283230510375772,
      "grad_norm": 0.12841247022151947,
      "learning_rate": 4.522706757692341e-05,
      "loss": 0.0609,
      "step": 21800
    },
    {
      "epoch": 1.5353337072349973,
      "grad_norm": 0.3091534376144409,
      "learning_rate": 4.520515831631714e-05,
      "loss": 0.064,
      "step": 21900
    },
    {
      "epoch": 1.5423443634324174,
      "grad_norm": 0.18999740481376648,
      "learning_rate": 4.518324905571087e-05,
      "loss": 0.0681,
      "step": 22000
    },
    {
      "epoch": 1.5493550196298373,
      "grad_norm": 0.2511945962905884,
      "learning_rate": 4.5161339795104594e-05,
      "loss": 0.0606,
      "step": 22100
    },
    {
      "epoch": 1.5563656758272573,
      "grad_norm": 0.2973499596118927,
      "learning_rate": 4.513943053449832e-05,
      "loss": 0.0637,
      "step": 22200
    },
    {
      "epoch": 1.5633763320246774,
      "grad_norm": 0.288154274225235,
      "learning_rate": 4.511752127389205e-05,
      "loss": 0.0655,
      "step": 22300
    },
    {
      "epoch": 1.5703869882220975,
      "grad_norm": 0.11797027289867401,
      "learning_rate": 4.5095612013285775e-05,
      "loss": 0.0639,
      "step": 22400
    },
    {
      "epoch": 1.5773976444195177,
      "grad_norm": 0.20087094604969025,
      "learning_rate": 4.50737027526795e-05,
      "loss": 0.066,
      "step": 22500
    },
    {
      "epoch": 1.5844083006169378,
      "grad_norm": 0.3146664798259735,
      "learning_rate": 4.505179349207323e-05,
      "loss": 0.064,
      "step": 22600
    },
    {
      "epoch": 1.591418956814358,
      "grad_norm": 0.20561714470386505,
      "learning_rate": 4.5029884231466956e-05,
      "loss": 0.0658,
      "step": 22700
    },
    {
      "epoch": 1.5984296130117779,
      "grad_norm": 0.18732605874538422,
      "learning_rate": 4.500797497086068e-05,
      "loss": 0.0676,
      "step": 22800
    },
    {
      "epoch": 1.605440269209198,
      "grad_norm": 0.5375792980194092,
      "learning_rate": 4.498606571025441e-05,
      "loss": 0.066,
      "step": 22900
    },
    {
      "epoch": 1.612450925406618,
      "grad_norm": 0.1388208568096161,
      "learning_rate": 4.4964156449648137e-05,
      "loss": 0.063,
      "step": 23000
    },
    {
      "epoch": 1.619461581604038,
      "grad_norm": 0.24707502126693726,
      "learning_rate": 4.494246628164793e-05,
      "loss": 0.0666,
      "step": 23100
    },
    {
      "epoch": 1.6264722378014582,
      "grad_norm": 0.23035648465156555,
      "learning_rate": 4.4920557021041654e-05,
      "loss": 0.0658,
      "step": 23200
    },
    {
      "epoch": 1.6334828939988784,
      "grad_norm": 0.24109163880348206,
      "learning_rate": 4.489864776043538e-05,
      "loss": 0.0649,
      "step": 23300
    },
    {
      "epoch": 1.6404935501962985,
      "grad_norm": 0.3560764789581299,
      "learning_rate": 4.487673849982911e-05,
      "loss": 0.065,
      "step": 23400
    },
    {
      "epoch": 1.6475042063937184,
      "grad_norm": 0.33078888058662415,
      "learning_rate": 4.4854829239222835e-05,
      "loss": 0.0605,
      "step": 23500
    },
    {
      "epoch": 1.6545148625911386,
      "grad_norm": 0.23574133217334747,
      "learning_rate": 4.483291997861657e-05,
      "loss": 0.0607,
      "step": 23600
    },
    {
      "epoch": 1.6615255187885585,
      "grad_norm": 0.25887438654899597,
      "learning_rate": 4.4811010718010296e-05,
      "loss": 0.0612,
      "step": 23700
    },
    {
      "epoch": 1.6685361749859786,
      "grad_norm": 0.15192338824272156,
      "learning_rate": 4.478910145740402e-05,
      "loss": 0.0666,
      "step": 23800
    },
    {
      "epoch": 1.6755468311833988,
      "grad_norm": 0.2610563039779663,
      "learning_rate": 4.476719219679775e-05,
      "loss": 0.0646,
      "step": 23900
    },
    {
      "epoch": 1.682557487380819,
      "grad_norm": 0.18580779433250427,
      "learning_rate": 4.474528293619148e-05,
      "loss": 0.0654,
      "step": 24000
    },
    {
      "epoch": 1.689568143578239,
      "grad_norm": 0.17776530981063843,
      "learning_rate": 4.4723373675585204e-05,
      "loss": 0.0622,
      "step": 24100
    },
    {
      "epoch": 1.696578799775659,
      "grad_norm": 0.17883867025375366,
      "learning_rate": 4.470146441497893e-05,
      "loss": 0.0651,
      "step": 24200
    },
    {
      "epoch": 1.703589455973079,
      "grad_norm": 0.2897249460220337,
      "learning_rate": 4.467955515437265e-05,
      "loss": 0.0646,
      "step": 24300
    },
    {
      "epoch": 1.710600112170499,
      "grad_norm": 0.22367976605892181,
      "learning_rate": 4.465764589376638e-05,
      "loss": 0.0665,
      "step": 24400
    },
    {
      "epoch": 1.7176107683679191,
      "grad_norm": 0.20298485457897186,
      "learning_rate": 4.4635736633160105e-05,
      "loss": 0.0635,
      "step": 24500
    },
    {
      "epoch": 1.7246214245653393,
      "grad_norm": 0.1948724091053009,
      "learning_rate": 4.461382737255383e-05,
      "loss": 0.0632,
      "step": 24600
    },
    {
      "epoch": 1.7316320807627594,
      "grad_norm": 0.1653999388217926,
      "learning_rate": 4.459191811194756e-05,
      "loss": 0.0674,
      "step": 24700
    },
    {
      "epoch": 1.7386427369601796,
      "grad_norm": 0.3373504877090454,
      "learning_rate": 4.4570008851341286e-05,
      "loss": 0.0629,
      "step": 24800
    },
    {
      "epoch": 1.7456533931575997,
      "grad_norm": 0.12852540612220764,
      "learning_rate": 4.454809959073501e-05,
      "loss": 0.0696,
      "step": 24900
    },
    {
      "epoch": 1.7526640493550196,
      "grad_norm": 0.23073400557041168,
      "learning_rate": 4.452619033012874e-05,
      "loss": 0.0631,
      "step": 25000
    },
    {
      "epoch": 1.7596747055524395,
      "grad_norm": 0.1486859768629074,
      "learning_rate": 4.450450016212853e-05,
      "loss": 0.0623,
      "step": 25100
    },
    {
      "epoch": 1.7666853617498597,
      "grad_norm": 0.28642556071281433,
      "learning_rate": 4.448259090152226e-05,
      "loss": 0.0639,
      "step": 25200
    },
    {
      "epoch": 1.7736960179472798,
      "grad_norm": 0.27397483587265015,
      "learning_rate": 4.4460681640915985e-05,
      "loss": 0.0651,
      "step": 25300
    },
    {
      "epoch": 1.7807066741447,
      "grad_norm": 0.17743688821792603,
      "learning_rate": 4.443877238030971e-05,
      "loss": 0.0637,
      "step": 25400
    },
    {
      "epoch": 1.78771733034212,
      "grad_norm": 0.374388724565506,
      "learning_rate": 4.441686311970344e-05,
      "loss": 0.0649,
      "step": 25500
    },
    {
      "epoch": 1.7947279865395402,
      "grad_norm": 0.3582910895347595,
      "learning_rate": 4.4394953859097165e-05,
      "loss": 0.0574,
      "step": 25600
    },
    {
      "epoch": 1.8017386427369602,
      "grad_norm": 0.20555032789707184,
      "learning_rate": 4.437304459849089e-05,
      "loss": 0.0618,
      "step": 25700
    },
    {
      "epoch": 1.8087492989343803,
      "grad_norm": 0.29444584250450134,
      "learning_rate": 4.435113533788462e-05,
      "loss": 0.0612,
      "step": 25800
    },
    {
      "epoch": 1.8157599551318002,
      "grad_norm": 0.19384333491325378,
      "learning_rate": 4.4329226077278346e-05,
      "loss": 0.0641,
      "step": 25900
    },
    {
      "epoch": 1.8227706113292204,
      "grad_norm": 0.3149314522743225,
      "learning_rate": 4.430731681667207e-05,
      "loss": 0.0641,
      "step": 26000
    },
    {
      "epoch": 1.8297812675266405,
      "grad_norm": 0.16902655363082886,
      "learning_rate": 4.42854075560658e-05,
      "loss": 0.0664,
      "step": 26100
    },
    {
      "epoch": 1.8367919237240606,
      "grad_norm": 0.24609480798244476,
      "learning_rate": 4.426349829545953e-05,
      "loss": 0.0617,
      "step": 26200
    },
    {
      "epoch": 1.8438025799214808,
      "grad_norm": 0.2404988408088684,
      "learning_rate": 4.4241589034853254e-05,
      "loss": 0.0651,
      "step": 26300
    },
    {
      "epoch": 1.8508132361189007,
      "grad_norm": 0.23386900126934052,
      "learning_rate": 4.421967977424698e-05,
      "loss": 0.0615,
      "step": 26400
    },
    {
      "epoch": 1.8578238923163208,
      "grad_norm": 0.3340047299861908,
      "learning_rate": 4.419777051364071e-05,
      "loss": 0.0645,
      "step": 26500
    },
    {
      "epoch": 1.8648345485137408,
      "grad_norm": 0.3749440014362335,
      "learning_rate": 4.4175861253034435e-05,
      "loss": 0.0595,
      "step": 26600
    },
    {
      "epoch": 1.871845204711161,
      "grad_norm": 0.11420271545648575,
      "learning_rate": 4.415395199242816e-05,
      "loss": 0.063,
      "step": 26700
    },
    {
      "epoch": 1.878855860908581,
      "grad_norm": 0.19288231432437897,
      "learning_rate": 4.413204273182189e-05,
      "loss": 0.0651,
      "step": 26800
    },
    {
      "epoch": 1.8858665171060012,
      "grad_norm": 0.2922552824020386,
      "learning_rate": 4.4110133471215616e-05,
      "loss": 0.0676,
      "step": 26900
    },
    {
      "epoch": 1.8928771733034213,
      "grad_norm": 0.2459855079650879,
      "learning_rate": 4.408822421060934e-05,
      "loss": 0.0628,
      "step": 27000
    },
    {
      "epoch": 1.8998878295008412,
      "grad_norm": 0.10723865032196045,
      "learning_rate": 4.406631495000307e-05,
      "loss": 0.0614,
      "step": 27100
    },
    {
      "epoch": 1.9068984856982614,
      "grad_norm": 0.09763406962156296,
      "learning_rate": 4.40444056893968e-05,
      "loss": 0.0586,
      "step": 27200
    },
    {
      "epoch": 1.9139091418956813,
      "grad_norm": 0.17684021592140198,
      "learning_rate": 4.402271552139659e-05,
      "loss": 0.0663,
      "step": 27300
    },
    {
      "epoch": 1.9209197980931014,
      "grad_norm": 0.13499987125396729,
      "learning_rate": 4.4000806260790315e-05,
      "loss": 0.0591,
      "step": 27400
    },
    {
      "epoch": 1.9279304542905216,
      "grad_norm": 0.42453479766845703,
      "learning_rate": 4.3978897000184035e-05,
      "loss": 0.0601,
      "step": 27500
    },
    {
      "epoch": 1.9349411104879417,
      "grad_norm": 0.45649951696395874,
      "learning_rate": 4.395698773957776e-05,
      "loss": 0.0635,
      "step": 27600
    },
    {
      "epoch": 1.9419517666853618,
      "grad_norm": 0.16652683913707733,
      "learning_rate": 4.393507847897149e-05,
      "loss": 0.0619,
      "step": 27700
    },
    {
      "epoch": 1.948962422882782,
      "grad_norm": 0.17387022078037262,
      "learning_rate": 4.3913169218365216e-05,
      "loss": 0.063,
      "step": 27800
    },
    {
      "epoch": 1.955973079080202,
      "grad_norm": 0.3548898696899414,
      "learning_rate": 4.389125995775894e-05,
      "loss": 0.0616,
      "step": 27900
    },
    {
      "epoch": 1.9629837352776218,
      "grad_norm": 0.20311833918094635,
      "learning_rate": 4.386935069715267e-05,
      "loss": 0.0623,
      "step": 28000
    },
    {
      "epoch": 1.969994391475042,
      "grad_norm": 0.21439120173454285,
      "learning_rate": 4.38474414365464e-05,
      "loss": 0.0628,
      "step": 28100
    },
    {
      "epoch": 1.977005047672462,
      "grad_norm": 0.3090226948261261,
      "learning_rate": 4.3825532175940124e-05,
      "loss": 0.0606,
      "step": 28200
    },
    {
      "epoch": 1.9840157038698822,
      "grad_norm": 0.2914068102836609,
      "learning_rate": 4.380362291533385e-05,
      "loss": 0.065,
      "step": 28300
    },
    {
      "epoch": 1.9910263600673024,
      "grad_norm": 0.15740221738815308,
      "learning_rate": 4.378171365472758e-05,
      "loss": 0.0676,
      "step": 28400
    },
    {
      "epoch": 1.9980370162647225,
      "grad_norm": 0.11616947501897812,
      "learning_rate": 4.375980439412131e-05,
      "loss": 0.0613,
      "step": 28500
    },
    {
      "epoch": 2.0,
      "eval_accuracy_macro_0.5": 0.9743691682815552,
      "eval_accuracy_micro_0.5": 0.9743691682815552,
      "eval_accuracy_weighted_0.5": 0.961340069770813,
      "eval_aucroc_macro": 0.8506792783737183,
      "eval_aucroc_micro": 0.8691287636756897,
      "eval_aucroc_weighted": 0.863491952419281,
      "eval_f1_macro_0.5": 0.5737296938896179,
      "eval_f1_macro_0.6": 0.5195332765579224,
      "eval_f1_macro_0.7": 0.44225022196769714,
      "eval_f1_macro_0.8": 0.20261043310165405,
      "eval_f1_micro_0.5": 0.6346598863601685,
      "eval_f1_micro_0.6": 0.5903498530387878,
      "eval_f1_micro_0.7": 0.5220340490341187,
      "eval_f1_micro_0.8": 0.41830992698669434,
      "eval_f1_micro_0.9": 0.23891916871070862,
      "eval_f1_weighted_0.5": 0.6154757738113403,
      "eval_f1_weighted_0.6": 0.5580736994743347,
      "eval_f1_weighted_0.7": 0.47606292366981506,
      "eval_f1_weighted_0.8": 0.21012412011623383,
      "eval_loss": 0.06051059067249298,
      "eval_runtime": 70.3455,
      "eval_samples_per_second": 404.774,
      "eval_steps_per_second": 50.607,
      "step": 28528
    },
    {
      "epoch": 2.0050476724621427,
      "grad_norm": 0.10434098541736603,
      "learning_rate": 4.373789513351504e-05,
      "loss": 0.0616,
      "step": 28600
    },
    {
      "epoch": 2.0120583286595624,
      "grad_norm": 0.34615060687065125,
      "learning_rate": 4.3715985872908766e-05,
      "loss": 0.0623,
      "step": 28700
    },
    {
      "epoch": 2.0190689848569825,
      "grad_norm": 0.16321660578250885,
      "learning_rate": 4.369407661230249e-05,
      "loss": 0.0643,
      "step": 28800
    },
    {
      "epoch": 2.0260796410544026,
      "grad_norm": 0.22904613614082336,
      "learning_rate": 4.367216735169622e-05,
      "loss": 0.0596,
      "step": 28900
    },
    {
      "epoch": 2.0330902972518228,
      "grad_norm": 0.10142834484577179,
      "learning_rate": 4.3650258091089946e-05,
      "loss": 0.0653,
      "step": 29000
    },
    {
      "epoch": 2.040100953449243,
      "grad_norm": 0.286190390586853,
      "learning_rate": 4.3628348830483673e-05,
      "loss": 0.0624,
      "step": 29100
    },
    {
      "epoch": 2.047111609646663,
      "grad_norm": 0.22098994255065918,
      "learning_rate": 4.36064395698774e-05,
      "loss": 0.0654,
      "step": 29200
    },
    {
      "epoch": 2.054122265844083,
      "grad_norm": 0.12795855104923248,
      "learning_rate": 4.358453030927113e-05,
      "loss": 0.061,
      "step": 29300
    },
    {
      "epoch": 2.061132922041503,
      "grad_norm": 0.17885062098503113,
      "learning_rate": 4.3562621048664854e-05,
      "loss": 0.0599,
      "step": 29400
    },
    {
      "epoch": 2.068143578238923,
      "grad_norm": 0.09875986725091934,
      "learning_rate": 4.3540930880664645e-05,
      "loss": 0.0605,
      "step": 29500
    },
    {
      "epoch": 2.075154234436343,
      "grad_norm": 0.12817324697971344,
      "learning_rate": 4.351902162005837e-05,
      "loss": 0.0631,
      "step": 29600
    },
    {
      "epoch": 2.0821648906337633,
      "grad_norm": 0.17106415331363678,
      "learning_rate": 4.34971123594521e-05,
      "loss": 0.063,
      "step": 29700
    },
    {
      "epoch": 2.0891755468311834,
      "grad_norm": 0.29430603981018066,
      "learning_rate": 4.3475203098845826e-05,
      "loss": 0.0608,
      "step": 29800
    },
    {
      "epoch": 2.0961862030286036,
      "grad_norm": 0.2765905261039734,
      "learning_rate": 4.345329383823955e-05,
      "loss": 0.0636,
      "step": 29900
    },
    {
      "epoch": 2.1031968592260237,
      "grad_norm": 0.13832898437976837,
      "learning_rate": 4.343138457763328e-05,
      "loss": 0.0594,
      "step": 30000
    },
    {
      "epoch": 2.1102075154234434,
      "grad_norm": 0.1414773315191269,
      "learning_rate": 4.340947531702701e-05,
      "loss": 0.0574,
      "step": 30100
    },
    {
      "epoch": 2.1172181716208636,
      "grad_norm": 0.33014950156211853,
      "learning_rate": 4.3387566056420734e-05,
      "loss": 0.0638,
      "step": 30200
    },
    {
      "epoch": 2.1242288278182837,
      "grad_norm": 0.16271401941776276,
      "learning_rate": 4.336565679581446e-05,
      "loss": 0.0625,
      "step": 30300
    },
    {
      "epoch": 2.131239484015704,
      "grad_norm": 0.27628418803215027,
      "learning_rate": 4.334374753520819e-05,
      "loss": 0.0612,
      "step": 30400
    },
    {
      "epoch": 2.138250140213124,
      "grad_norm": 0.1612592488527298,
      "learning_rate": 4.332183827460191e-05,
      "loss": 0.0649,
      "step": 30500
    },
    {
      "epoch": 2.145260796410544,
      "grad_norm": 0.21105970442295074,
      "learning_rate": 4.3299929013995635e-05,
      "loss": 0.0581,
      "step": 30600
    },
    {
      "epoch": 2.1522714526079643,
      "grad_norm": 0.24366970360279083,
      "learning_rate": 4.327801975338936e-05,
      "loss": 0.0586,
      "step": 30700
    },
    {
      "epoch": 2.1592821088053844,
      "grad_norm": 0.1647125780582428,
      "learning_rate": 4.325611049278309e-05,
      "loss": 0.0629,
      "step": 30800
    },
    {
      "epoch": 2.166292765002804,
      "grad_norm": 0.2696535885334015,
      "learning_rate": 4.3234201232176816e-05,
      "loss": 0.0626,
      "step": 30900
    },
    {
      "epoch": 2.1733034212002242,
      "grad_norm": 0.2469741553068161,
      "learning_rate": 4.321229197157054e-05,
      "loss": 0.0614,
      "step": 31000
    },
    {
      "epoch": 2.1803140773976444,
      "grad_norm": 0.3083643913269043,
      "learning_rate": 4.319038271096427e-05,
      "loss": 0.0616,
      "step": 31100
    },
    {
      "epoch": 2.1873247335950645,
      "grad_norm": 0.12201447784900665,
      "learning_rate": 4.3168473450358e-05,
      "loss": 0.0585,
      "step": 31200
    },
    {
      "epoch": 2.1943353897924847,
      "grad_norm": 0.3430769741535187,
      "learning_rate": 4.3146564189751724e-05,
      "loss": 0.0641,
      "step": 31300
    },
    {
      "epoch": 2.201346045989905,
      "grad_norm": 0.43909749388694763,
      "learning_rate": 4.312465492914545e-05,
      "loss": 0.064,
      "step": 31400
    },
    {
      "epoch": 2.208356702187325,
      "grad_norm": 0.11941496282815933,
      "learning_rate": 4.310274566853918e-05,
      "loss": 0.0655,
      "step": 31500
    },
    {
      "epoch": 2.2153673583847446,
      "grad_norm": 0.172354057431221,
      "learning_rate": 4.3080836407932905e-05,
      "loss": 0.0647,
      "step": 31600
    },
    {
      "epoch": 2.2223780145821648,
      "grad_norm": 0.1344146877527237,
      "learning_rate": 4.305892714732663e-05,
      "loss": 0.0616,
      "step": 31700
    },
    {
      "epoch": 2.229388670779585,
      "grad_norm": 0.13101190328598022,
      "learning_rate": 4.303723697932642e-05,
      "loss": 0.0607,
      "step": 31800
    },
    {
      "epoch": 2.236399326977005,
      "grad_norm": 0.24980849027633667,
      "learning_rate": 4.301532771872015e-05,
      "loss": 0.0609,
      "step": 31900
    },
    {
      "epoch": 2.243409983174425,
      "grad_norm": 0.14689511060714722,
      "learning_rate": 4.2993418458113877e-05,
      "loss": 0.0624,
      "step": 32000
    },
    {
      "epoch": 2.2504206393718453,
      "grad_norm": 0.1011972650885582,
      "learning_rate": 4.2971509197507603e-05,
      "loss": 0.0606,
      "step": 32100
    },
    {
      "epoch": 2.2574312955692655,
      "grad_norm": 0.17617198824882507,
      "learning_rate": 4.294959993690133e-05,
      "loss": 0.0601,
      "step": 32200
    },
    {
      "epoch": 2.264441951766685,
      "grad_norm": 0.325395405292511,
      "learning_rate": 4.292769067629506e-05,
      "loss": 0.0618,
      "step": 32300
    },
    {
      "epoch": 2.2714526079641053,
      "grad_norm": 0.211805522441864,
      "learning_rate": 4.2905781415688784e-05,
      "loss": 0.0629,
      "step": 32400
    },
    {
      "epoch": 2.2784632641615254,
      "grad_norm": 0.18281513452529907,
      "learning_rate": 4.288387215508251e-05,
      "loss": 0.0594,
      "step": 32500
    },
    {
      "epoch": 2.2854739203589456,
      "grad_norm": 0.1457575410604477,
      "learning_rate": 4.286196289447624e-05,
      "loss": 0.0619,
      "step": 32600
    },
    {
      "epoch": 2.2924845765563657,
      "grad_norm": 0.1382841169834137,
      "learning_rate": 4.2840053633869965e-05,
      "loss": 0.0627,
      "step": 32700
    },
    {
      "epoch": 2.299495232753786,
      "grad_norm": 0.28852686285972595,
      "learning_rate": 4.281814437326369e-05,
      "loss": 0.0608,
      "step": 32800
    },
    {
      "epoch": 2.306505888951206,
      "grad_norm": 0.19286951422691345,
      "learning_rate": 4.279623511265742e-05,
      "loss": 0.0601,
      "step": 32900
    },
    {
      "epoch": 2.3135165451486257,
      "grad_norm": 0.13951142132282257,
      "learning_rate": 4.2774325852051146e-05,
      "loss": 0.0585,
      "step": 33000
    },
    {
      "epoch": 2.320527201346046,
      "grad_norm": 0.27918583154678345,
      "learning_rate": 4.275241659144487e-05,
      "loss": 0.0626,
      "step": 33100
    },
    {
      "epoch": 2.327537857543466,
      "grad_norm": 0.2427269071340561,
      "learning_rate": 4.27305073308386e-05,
      "loss": 0.057,
      "step": 33200
    },
    {
      "epoch": 2.334548513740886,
      "grad_norm": 0.2034759372472763,
      "learning_rate": 4.270859807023233e-05,
      "loss": 0.0622,
      "step": 33300
    },
    {
      "epoch": 2.3415591699383063,
      "grad_norm": 0.2590298354625702,
      "learning_rate": 4.2686688809626054e-05,
      "loss": 0.0546,
      "step": 33400
    },
    {
      "epoch": 2.3485698261357264,
      "grad_norm": 0.260651558637619,
      "learning_rate": 4.266477954901978e-05,
      "loss": 0.0632,
      "step": 33500
    },
    {
      "epoch": 2.3555804823331465,
      "grad_norm": 0.21633806824684143,
      "learning_rate": 4.264287028841351e-05,
      "loss": 0.0649,
      "step": 33600
    },
    {
      "epoch": 2.3625911385305667,
      "grad_norm": 0.17889904975891113,
      "learning_rate": 4.2620961027807235e-05,
      "loss": 0.0593,
      "step": 33700
    },
    {
      "epoch": 2.3696017947279864,
      "grad_norm": 0.19076310098171234,
      "learning_rate": 4.2599270859807026e-05,
      "loss": 0.0632,
      "step": 33800
    },
    {
      "epoch": 2.3766124509254065,
      "grad_norm": 0.1324322670698166,
      "learning_rate": 4.257736159920075e-05,
      "loss": 0.0583,
      "step": 33900
    },
    {
      "epoch": 2.3836231071228267,
      "grad_norm": 0.13720867037773132,
      "learning_rate": 4.2555671431200544e-05,
      "loss": 0.0609,
      "step": 34000
    },
    {
      "epoch": 2.390633763320247,
      "grad_norm": 0.09136578440666199,
      "learning_rate": 4.253376217059427e-05,
      "loss": 0.0622,
      "step": 34100
    },
    {
      "epoch": 2.397644419517667,
      "grad_norm": 0.26984962821006775,
      "learning_rate": 4.2511852909988e-05,
      "loss": 0.0607,
      "step": 34200
    },
    {
      "epoch": 2.404655075715087,
      "grad_norm": 0.19362905621528625,
      "learning_rate": 4.2489943649381725e-05,
      "loss": 0.0581,
      "step": 34300
    },
    {
      "epoch": 2.4116657319125068,
      "grad_norm": 0.10617423057556152,
      "learning_rate": 4.246803438877545e-05,
      "loss": 0.0579,
      "step": 34400
    },
    {
      "epoch": 2.418676388109927,
      "grad_norm": 0.27116715908050537,
      "learning_rate": 4.244612512816918e-05,
      "loss": 0.0575,
      "step": 34500
    },
    {
      "epoch": 2.425687044307347,
      "grad_norm": 0.26776352524757385,
      "learning_rate": 4.2424215867562905e-05,
      "loss": 0.0604,
      "step": 34600
    },
    {
      "epoch": 2.432697700504767,
      "grad_norm": 0.28089243173599243,
      "learning_rate": 4.240230660695663e-05,
      "loss": 0.0572,
      "step": 34700
    },
    {
      "epoch": 2.4397083567021873,
      "grad_norm": 0.14750322699546814,
      "learning_rate": 4.238039734635036e-05,
      "loss": 0.0596,
      "step": 34800
    },
    {
      "epoch": 2.4467190128996075,
      "grad_norm": 0.11156760901212692,
      "learning_rate": 4.2358488085744086e-05,
      "loss": 0.06,
      "step": 34900
    },
    {
      "epoch": 2.4537296690970276,
      "grad_norm": 0.23026281595230103,
      "learning_rate": 4.233657882513781e-05,
      "loss": 0.0622,
      "step": 35000
    },
    {
      "epoch": 2.4607403252944478,
      "grad_norm": 0.523938000202179,
      "learning_rate": 4.231466956453154e-05,
      "loss": 0.0601,
      "step": 35100
    },
    {
      "epoch": 2.4677509814918674,
      "grad_norm": 0.25057271122932434,
      "learning_rate": 4.229276030392527e-05,
      "loss": 0.0594,
      "step": 35200
    },
    {
      "epoch": 2.4747616376892876,
      "grad_norm": 0.25285831093788147,
      "learning_rate": 4.2270851043318994e-05,
      "loss": 0.0597,
      "step": 35300
    },
    {
      "epoch": 2.4817722938867077,
      "grad_norm": 0.2898856997489929,
      "learning_rate": 4.224894178271272e-05,
      "loss": 0.0657,
      "step": 35400
    },
    {
      "epoch": 2.488782950084128,
      "grad_norm": 0.10278639197349548,
      "learning_rate": 4.222703252210645e-05,
      "loss": 0.0638,
      "step": 35500
    },
    {
      "epoch": 2.495793606281548,
      "grad_norm": 0.23030602931976318,
      "learning_rate": 4.2205123261500175e-05,
      "loss": 0.0585,
      "step": 35600
    },
    {
      "epoch": 2.502804262478968,
      "grad_norm": 0.2559761703014374,
      "learning_rate": 4.21832140008939e-05,
      "loss": 0.0623,
      "step": 35700
    },
    {
      "epoch": 2.509814918676388,
      "grad_norm": 0.1444714069366455,
      "learning_rate": 4.216130474028763e-05,
      "loss": 0.0539,
      "step": 35800
    },
    {
      "epoch": 2.516825574873808,
      "grad_norm": 0.17451111972332,
      "learning_rate": 4.2139395479681356e-05,
      "loss": 0.0625,
      "step": 35900
    },
    {
      "epoch": 2.523836231071228,
      "grad_norm": 0.18807026743888855,
      "learning_rate": 4.211748621907508e-05,
      "loss": 0.0601,
      "step": 36000
    },
    {
      "epoch": 2.5308468872686483,
      "grad_norm": 0.1258591115474701,
      "learning_rate": 4.209557695846881e-05,
      "loss": 0.063,
      "step": 36100
    },
    {
      "epoch": 2.5378575434660684,
      "grad_norm": 0.2645997405052185,
      "learning_rate": 4.207366769786254e-05,
      "loss": 0.0555,
      "step": 36200
    },
    {
      "epoch": 2.5448681996634885,
      "grad_norm": 0.23238828778266907,
      "learning_rate": 4.2051758437256264e-05,
      "loss": 0.0585,
      "step": 36300
    },
    {
      "epoch": 2.5518788558609087,
      "grad_norm": 0.11887515336275101,
      "learning_rate": 4.202984917664999e-05,
      "loss": 0.0596,
      "step": 36400
    },
    {
      "epoch": 2.558889512058329,
      "grad_norm": 0.19122135639190674,
      "learning_rate": 4.200793991604372e-05,
      "loss": 0.0622,
      "step": 36500
    },
    {
      "epoch": 2.565900168255749,
      "grad_norm": 0.07314256578683853,
      "learning_rate": 4.1986030655437445e-05,
      "loss": 0.0638,
      "step": 36600
    },
    {
      "epoch": 2.5729108244531687,
      "grad_norm": 0.12142977863550186,
      "learning_rate": 4.1964121394831165e-05,
      "loss": 0.0582,
      "step": 36700
    },
    {
      "epoch": 2.579921480650589,
      "grad_norm": 0.27486205101013184,
      "learning_rate": 4.194221213422489e-05,
      "loss": 0.0634,
      "step": 36800
    },
    {
      "epoch": 2.586932136848009,
      "grad_norm": 0.17684800922870636,
      "learning_rate": 4.192030287361862e-05,
      "loss": 0.0564,
      "step": 36900
    },
    {
      "epoch": 2.593942793045429,
      "grad_norm": 0.1973460167646408,
      "learning_rate": 4.1898393613012346e-05,
      "loss": 0.0588,
      "step": 37000
    },
    {
      "epoch": 2.600953449242849,
      "grad_norm": 0.19458326697349548,
      "learning_rate": 4.187648435240607e-05,
      "loss": 0.0587,
      "step": 37100
    },
    {
      "epoch": 2.6079641054402694,
      "grad_norm": 0.18891243636608124,
      "learning_rate": 4.18545750917998e-05,
      "loss": 0.0609,
      "step": 37200
    },
    {
      "epoch": 2.614974761637689,
      "grad_norm": 0.26712465286254883,
      "learning_rate": 4.183266583119353e-05,
      "loss": 0.0598,
      "step": 37300
    },
    {
      "epoch": 2.621985417835109,
      "grad_norm": 0.17593230307102203,
      "learning_rate": 4.1810756570587254e-05,
      "loss": 0.0582,
      "step": 37400
    },
    {
      "epoch": 2.6289960740325293,
      "grad_norm": 0.30900731682777405,
      "learning_rate": 4.178884730998098e-05,
      "loss": 0.0604,
      "step": 37500
    },
    {
      "epoch": 2.6360067302299495,
      "grad_norm": 0.20675109326839447,
      "learning_rate": 4.176693804937471e-05,
      "loss": 0.0602,
      "step": 37600
    },
    {
      "epoch": 2.6430173864273696,
      "grad_norm": 0.23809997737407684,
      "learning_rate": 4.1745028788768435e-05,
      "loss": 0.0619,
      "step": 37700
    },
    {
      "epoch": 2.6500280426247897,
      "grad_norm": 0.16366225481033325,
      "learning_rate": 4.172311952816216e-05,
      "loss": 0.0537,
      "step": 37800
    },
    {
      "epoch": 2.65703869882221,
      "grad_norm": 0.4377981424331665,
      "learning_rate": 4.170121026755589e-05,
      "loss": 0.0644,
      "step": 37900
    },
    {
      "epoch": 2.66404935501963,
      "grad_norm": 0.20526987314224243,
      "learning_rate": 4.1679301006949616e-05,
      "loss": 0.0576,
      "step": 38000
    },
    {
      "epoch": 2.67106001121705,
      "grad_norm": 0.2386654168367386,
      "learning_rate": 4.165739174634334e-05,
      "loss": 0.0632,
      "step": 38100
    },
    {
      "epoch": 2.67807066741447,
      "grad_norm": 0.15893715620040894,
      "learning_rate": 4.163548248573707e-05,
      "loss": 0.0578,
      "step": 38200
    },
    {
      "epoch": 2.68508132361189,
      "grad_norm": 0.29450488090515137,
      "learning_rate": 4.1613573225130804e-05,
      "loss": 0.0595,
      "step": 38300
    },
    {
      "epoch": 2.69209197980931,
      "grad_norm": 0.10226929932832718,
      "learning_rate": 4.159166396452453e-05,
      "loss": 0.0617,
      "step": 38400
    },
    {
      "epoch": 2.6991026360067303,
      "grad_norm": 0.18414828181266785,
      "learning_rate": 4.1569973796524315e-05,
      "loss": 0.0615,
      "step": 38500
    },
    {
      "epoch": 2.7061132922041504,
      "grad_norm": 0.1513606756925583,
      "learning_rate": 4.154806453591805e-05,
      "loss": 0.0602,
      "step": 38600
    },
    {
      "epoch": 2.71312394840157,
      "grad_norm": 0.2863662838935852,
      "learning_rate": 4.1526155275311775e-05,
      "loss": 0.0576,
      "step": 38700
    },
    {
      "epoch": 2.7201346045989903,
      "grad_norm": 0.12399947643280029,
      "learning_rate": 4.15042460147055e-05,
      "loss": 0.0605,
      "step": 38800
    },
    {
      "epoch": 2.7271452607964104,
      "grad_norm": 0.16131265461444855,
      "learning_rate": 4.148233675409923e-05,
      "loss": 0.0572,
      "step": 38900
    },
    {
      "epoch": 2.7341559169938305,
      "grad_norm": 0.18435202538967133,
      "learning_rate": 4.1460427493492956e-05,
      "loss": 0.0627,
      "step": 39000
    },
    {
      "epoch": 2.7411665731912507,
      "grad_norm": 0.19433575868606567,
      "learning_rate": 4.143851823288668e-05,
      "loss": 0.0603,
      "step": 39100
    },
    {
      "epoch": 2.748177229388671,
      "grad_norm": 0.37743014097213745,
      "learning_rate": 4.141660897228041e-05,
      "loss": 0.0606,
      "step": 39200
    },
    {
      "epoch": 2.755187885586091,
      "grad_norm": 0.27626287937164307,
      "learning_rate": 4.139469971167414e-05,
      "loss": 0.0572,
      "step": 39300
    },
    {
      "epoch": 2.762198541783511,
      "grad_norm": 0.3154674470424652,
      "learning_rate": 4.1372790451067864e-05,
      "loss": 0.0631,
      "step": 39400
    },
    {
      "epoch": 2.7692091979809312,
      "grad_norm": 0.1300133615732193,
      "learning_rate": 4.135088119046159e-05,
      "loss": 0.0654,
      "step": 39500
    },
    {
      "epoch": 2.776219854178351,
      "grad_norm": 0.2790549099445343,
      "learning_rate": 4.132897192985531e-05,
      "loss": 0.0607,
      "step": 39600
    },
    {
      "epoch": 2.783230510375771,
      "grad_norm": 0.12053172290325165,
      "learning_rate": 4.130706266924904e-05,
      "loss": 0.0642,
      "step": 39700
    },
    {
      "epoch": 2.790241166573191,
      "grad_norm": 0.2483772188425064,
      "learning_rate": 4.1285153408642765e-05,
      "loss": 0.0574,
      "step": 39800
    },
    {
      "epoch": 2.7972518227706114,
      "grad_norm": 0.2732001841068268,
      "learning_rate": 4.126324414803649e-05,
      "loss": 0.0609,
      "step": 39900
    },
    {
      "epoch": 2.8042624789680315,
      "grad_norm": 0.10074896365404129,
      "learning_rate": 4.124133488743022e-05,
      "loss": 0.0567,
      "step": 40000
    },
    {
      "epoch": 2.8112731351654516,
      "grad_norm": 0.1508931964635849,
      "learning_rate": 4.1219425626823946e-05,
      "loss": 0.0629,
      "step": 40100
    },
    {
      "epoch": 2.8182837913628713,
      "grad_norm": 0.18354637920856476,
      "learning_rate": 4.119751636621767e-05,
      "loss": 0.0607,
      "step": 40200
    },
    {
      "epoch": 2.8252944475602915,
      "grad_norm": 0.17952050268650055,
      "learning_rate": 4.11756071056114e-05,
      "loss": 0.06,
      "step": 40300
    },
    {
      "epoch": 2.8323051037577116,
      "grad_norm": 0.1200840100646019,
      "learning_rate": 4.115369784500513e-05,
      "loss": 0.0605,
      "step": 40400
    },
    {
      "epoch": 2.8393157599551317,
      "grad_norm": 0.19705231487751007,
      "learning_rate": 4.113200767700492e-05,
      "loss": 0.0569,
      "step": 40500
    },
    {
      "epoch": 2.846326416152552,
      "grad_norm": 0.18363407254219055,
      "learning_rate": 4.1110098416398645e-05,
      "loss": 0.0625,
      "step": 40600
    },
    {
      "epoch": 2.853337072349972,
      "grad_norm": 0.19732870161533356,
      "learning_rate": 4.108818915579237e-05,
      "loss": 0.061,
      "step": 40700
    },
    {
      "epoch": 2.860347728547392,
      "grad_norm": 0.12482213228940964,
      "learning_rate": 4.10662798951861e-05,
      "loss": 0.0562,
      "step": 40800
    },
    {
      "epoch": 2.8673583847448123,
      "grad_norm": 0.34327492117881775,
      "learning_rate": 4.1044370634579826e-05,
      "loss": 0.0546,
      "step": 40900
    },
    {
      "epoch": 2.8743690409422324,
      "grad_norm": 0.12083089351654053,
      "learning_rate": 4.102246137397355e-05,
      "loss": 0.0589,
      "step": 41000
    },
    {
      "epoch": 2.881379697139652,
      "grad_norm": 0.1398622989654541,
      "learning_rate": 4.100055211336728e-05,
      "loss": 0.0637,
      "step": 41100
    },
    {
      "epoch": 2.8883903533370723,
      "grad_norm": 0.290763795375824,
      "learning_rate": 4.097864285276101e-05,
      "loss": 0.0583,
      "step": 41200
    },
    {
      "epoch": 2.8954010095344924,
      "grad_norm": 0.22840258479118347,
      "learning_rate": 4.0956733592154734e-05,
      "loss": 0.0619,
      "step": 41300
    },
    {
      "epoch": 2.9024116657319126,
      "grad_norm": 0.3683217465877533,
      "learning_rate": 4.093482433154846e-05,
      "loss": 0.0613,
      "step": 41400
    },
    {
      "epoch": 2.9094223219293327,
      "grad_norm": 0.14116770029067993,
      "learning_rate": 4.091291507094219e-05,
      "loss": 0.0561,
      "step": 41500
    },
    {
      "epoch": 2.9164329781267524,
      "grad_norm": 0.1900770217180252,
      "learning_rate": 4.0891005810335915e-05,
      "loss": 0.0598,
      "step": 41600
    },
    {
      "epoch": 2.9234436343241725,
      "grad_norm": 0.16276101768016815,
      "learning_rate": 4.086909654972964e-05,
      "loss": 0.06,
      "step": 41700
    },
    {
      "epoch": 2.9304542905215927,
      "grad_norm": 0.15272490680217743,
      "learning_rate": 4.084718728912337e-05,
      "loss": 0.056,
      "step": 41800
    },
    {
      "epoch": 2.937464946719013,
      "grad_norm": 0.22885406017303467,
      "learning_rate": 4.0825278028517096e-05,
      "loss": 0.059,
      "step": 41900
    },
    {
      "epoch": 2.944475602916433,
      "grad_norm": 0.3463992774486542,
      "learning_rate": 4.080336876791082e-05,
      "loss": 0.0603,
      "step": 42000
    },
    {
      "epoch": 2.951486259113853,
      "grad_norm": 0.25555306673049927,
      "learning_rate": 4.078145950730455e-05,
      "loss": 0.0583,
      "step": 42100
    },
    {
      "epoch": 2.9584969153112732,
      "grad_norm": 0.09811845421791077,
      "learning_rate": 4.0759550246698277e-05,
      "loss": 0.0649,
      "step": 42200
    },
    {
      "epoch": 2.9655075715086934,
      "grad_norm": 0.16406084597110748,
      "learning_rate": 4.0737640986092004e-05,
      "loss": 0.0574,
      "step": 42300
    },
    {
      "epoch": 2.9725182277061135,
      "grad_norm": 0.19637785851955414,
      "learning_rate": 4.071573172548573e-05,
      "loss": 0.0614,
      "step": 42400
    },
    {
      "epoch": 2.979528883903533,
      "grad_norm": 0.20338930189609528,
      "learning_rate": 4.069382246487946e-05,
      "loss": 0.0607,
      "step": 42500
    },
    {
      "epoch": 2.9865395401009533,
      "grad_norm": 0.46412989497184753,
      "learning_rate": 4.0671913204273184e-05,
      "loss": 0.0621,
      "step": 42600
    },
    {
      "epoch": 2.9935501962983735,
      "grad_norm": 0.20380418002605438,
      "learning_rate": 4.065000394366691e-05,
      "loss": 0.0558,
      "step": 42700
    },
    {
      "epoch": 3.0,
      "eval_accuracy_macro_0.5": 0.9758375883102417,
      "eval_accuracy_micro_0.5": 0.9758375883102417,
      "eval_accuracy_weighted_0.5": 0.963620126247406,
      "eval_aucroc_macro": 0.8561246991157532,
      "eval_aucroc_micro": 0.8742164373397827,
      "eval_aucroc_weighted": 0.8692593574523926,
      "eval_f1_macro_0.5": 0.6046281456947327,
      "eval_f1_macro_0.6": 0.5554835200309753,
      "eval_f1_macro_0.7": 0.48334959149360657,
      "eval_f1_macro_0.8": 0.24817223846912384,
      "eval_f1_micro_0.5": 0.6592899560928345,
      "eval_f1_micro_0.6": 0.6206977963447571,
      "eval_f1_micro_0.7": 0.5586046576499939,
      "eval_f1_micro_0.8": 0.46519333124160767,
      "eval_f1_micro_0.9": 0.29889053106307983,
      "eval_f1_weighted_0.5": 0.6425912976264954,
      "eval_f1_weighted_0.6": 0.5927693247795105,
      "eval_f1_weighted_0.7": 0.5184040069580078,
      "eval_f1_weighted_0.8": 0.2641582787036896,
      "eval_loss": 0.056230831891298294,
      "eval_runtime": 68.3868,
      "eval_samples_per_second": 416.367,
      "eval_steps_per_second": 52.057,
      "step": 42792
    },
    {
      "epoch": 3.0005608524957936,
      "grad_norm": 0.2771446704864502,
      "learning_rate": 4.062809468306064e-05,
      "loss": 0.0583,
      "step": 42800
    },
    {
      "epoch": 3.0075715086932138,
      "grad_norm": 0.49865955114364624,
      "learning_rate": 4.060640451506042e-05,
      "loss": 0.0606,
      "step": 42900
    },
    {
      "epoch": 3.014582164890634,
      "grad_norm": 0.10352131724357605,
      "learning_rate": 4.058449525445415e-05,
      "loss": 0.0554,
      "step": 43000
    },
    {
      "epoch": 3.021592821088054,
      "grad_norm": 0.19499273598194122,
      "learning_rate": 4.0562585993847876e-05,
      "loss": 0.0589,
      "step": 43100
    },
    {
      "epoch": 3.0286034772854737,
      "grad_norm": 0.1120377704501152,
      "learning_rate": 4.05406767332416e-05,
      "loss": 0.057,
      "step": 43200
    },
    {
      "epoch": 3.035614133482894,
      "grad_norm": 0.21922504901885986,
      "learning_rate": 4.051876747263533e-05,
      "loss": 0.057,
      "step": 43300
    },
    {
      "epoch": 3.042624789680314,
      "grad_norm": 0.27700769901275635,
      "learning_rate": 4.0496858212029064e-05,
      "loss": 0.0575,
      "step": 43400
    },
    {
      "epoch": 3.049635445877734,
      "grad_norm": 0.1277015060186386,
      "learning_rate": 4.047494895142279e-05,
      "loss": 0.0556,
      "step": 43500
    },
    {
      "epoch": 3.0566461020751543,
      "grad_norm": 0.19702625274658203,
      "learning_rate": 4.045303969081652e-05,
      "loss": 0.057,
      "step": 43600
    },
    {
      "epoch": 3.0636567582725744,
      "grad_norm": 0.17678315937519073,
      "learning_rate": 4.0431130430210245e-05,
      "loss": 0.0594,
      "step": 43700
    },
    {
      "epoch": 3.0706674144699946,
      "grad_norm": 0.2226795256137848,
      "learning_rate": 4.040922116960397e-05,
      "loss": 0.06,
      "step": 43800
    },
    {
      "epoch": 3.0776780706674143,
      "grad_norm": 0.12730644643306732,
      "learning_rate": 4.03873119089977e-05,
      "loss": 0.0621,
      "step": 43900
    },
    {
      "epoch": 3.0846887268648344,
      "grad_norm": 0.4450834393501282,
      "learning_rate": 4.0365402648391426e-05,
      "loss": 0.0555,
      "step": 44000
    },
    {
      "epoch": 3.0916993830622546,
      "grad_norm": 0.10699060559272766,
      "learning_rate": 4.034349338778515e-05,
      "loss": 0.0565,
      "step": 44100
    },
    {
      "epoch": 3.0987100392596747,
      "grad_norm": 0.20629476010799408,
      "learning_rate": 4.032158412717888e-05,
      "loss": 0.0566,
      "step": 44200
    },
    {
      "epoch": 3.105720695457095,
      "grad_norm": 0.11524117738008499,
      "learning_rate": 4.029967486657261e-05,
      "loss": 0.0597,
      "step": 44300
    },
    {
      "epoch": 3.112731351654515,
      "grad_norm": 0.07742676138877869,
      "learning_rate": 4.0277765605966334e-05,
      "loss": 0.0594,
      "step": 44400
    },
    {
      "epoch": 3.119742007851935,
      "grad_norm": 0.10240235924720764,
      "learning_rate": 4.025585634536006e-05,
      "loss": 0.0597,
      "step": 44500
    },
    {
      "epoch": 3.126752664049355,
      "grad_norm": 0.19928047060966492,
      "learning_rate": 4.023394708475379e-05,
      "loss": 0.0567,
      "step": 44600
    },
    {
      "epoch": 3.133763320246775,
      "grad_norm": 0.12262806296348572,
      "learning_rate": 4.0212037824147515e-05,
      "loss": 0.0578,
      "step": 44700
    },
    {
      "epoch": 3.140773976444195,
      "grad_norm": 0.11071835458278656,
      "learning_rate": 4.019012856354124e-05,
      "loss": 0.0616,
      "step": 44800
    },
    {
      "epoch": 3.1477846326416152,
      "grad_norm": 0.18277737498283386,
      "learning_rate": 4.016821930293497e-05,
      "loss": 0.0595,
      "step": 44900
    },
    {
      "epoch": 3.1547952888390354,
      "grad_norm": 0.20427177846431732,
      "learning_rate": 4.0146310042328696e-05,
      "loss": 0.0581,
      "step": 45000
    },
    {
      "epoch": 3.1618059450364555,
      "grad_norm": 0.10122904181480408,
      "learning_rate": 4.012440078172242e-05,
      "loss": 0.0574,
      "step": 45100
    },
    {
      "epoch": 3.1688166012338757,
      "grad_norm": 0.12295526266098022,
      "learning_rate": 4.010271061372221e-05,
      "loss": 0.0567,
      "step": 45200
    },
    {
      "epoch": 3.175827257431296,
      "grad_norm": 0.14736874401569366,
      "learning_rate": 4.008080135311594e-05,
      "loss": 0.0603,
      "step": 45300
    },
    {
      "epoch": 3.1828379136287155,
      "grad_norm": 0.06519626826047897,
      "learning_rate": 4.005889209250967e-05,
      "loss": 0.0568,
      "step": 45400
    },
    {
      "epoch": 3.1898485698261356,
      "grad_norm": 0.2457120716571808,
      "learning_rate": 4.0036982831903394e-05,
      "loss": 0.0567,
      "step": 45500
    },
    {
      "epoch": 3.1968592260235558,
      "grad_norm": 0.19215023517608643,
      "learning_rate": 4.001507357129712e-05,
      "loss": 0.0594,
      "step": 45600
    },
    {
      "epoch": 3.203869882220976,
      "grad_norm": 0.10106004774570465,
      "learning_rate": 3.999316431069085e-05,
      "loss": 0.0603,
      "step": 45700
    },
    {
      "epoch": 3.210880538418396,
      "grad_norm": 0.1625237762928009,
      "learning_rate": 3.997125505008457e-05,
      "loss": 0.0594,
      "step": 45800
    },
    {
      "epoch": 3.217891194615816,
      "grad_norm": 0.12296714633703232,
      "learning_rate": 3.9949345789478295e-05,
      "loss": 0.061,
      "step": 45900
    },
    {
      "epoch": 3.2249018508132363,
      "grad_norm": 0.14383895695209503,
      "learning_rate": 3.992743652887202e-05,
      "loss": 0.0518,
      "step": 46000
    },
    {
      "epoch": 3.231912507010656,
      "grad_norm": 0.1512138545513153,
      "learning_rate": 3.990552726826575e-05,
      "loss": 0.0578,
      "step": 46100
    },
    {
      "epoch": 3.238923163208076,
      "grad_norm": 0.08391812443733215,
      "learning_rate": 3.9883618007659476e-05,
      "loss": 0.0581,
      "step": 46200
    },
    {
      "epoch": 3.2459338194054963,
      "grad_norm": 0.13441631197929382,
      "learning_rate": 3.98617087470532e-05,
      "loss": 0.0556,
      "step": 46300
    },
    {
      "epoch": 3.2529444756029164,
      "grad_norm": 0.4059368073940277,
      "learning_rate": 3.983979948644693e-05,
      "loss": 0.054,
      "step": 46400
    },
    {
      "epoch": 3.2599551318003366,
      "grad_norm": 0.1716296225786209,
      "learning_rate": 3.981789022584066e-05,
      "loss": 0.0573,
      "step": 46500
    },
    {
      "epoch": 3.2669657879977567,
      "grad_norm": 0.10393571853637695,
      "learning_rate": 3.9795980965234384e-05,
      "loss": 0.059,
      "step": 46600
    },
    {
      "epoch": 3.273976444195177,
      "grad_norm": 0.08744914084672928,
      "learning_rate": 3.977407170462811e-05,
      "loss": 0.0572,
      "step": 46700
    },
    {
      "epoch": 3.2809871003925966,
      "grad_norm": 0.12305720150470734,
      "learning_rate": 3.975216244402184e-05,
      "loss": 0.0577,
      "step": 46800
    },
    {
      "epoch": 3.2879977565900167,
      "grad_norm": 0.2167169749736786,
      "learning_rate": 3.9730253183415565e-05,
      "loss": 0.0565,
      "step": 46900
    },
    {
      "epoch": 3.295008412787437,
      "grad_norm": 0.2689177691936493,
      "learning_rate": 3.970834392280929e-05,
      "loss": 0.0572,
      "step": 47000
    },
    {
      "epoch": 3.302019068984857,
      "grad_norm": 0.09935880452394485,
      "learning_rate": 3.968643466220302e-05,
      "loss": 0.0551,
      "step": 47100
    },
    {
      "epoch": 3.309029725182277,
      "grad_norm": 0.22731447219848633,
      "learning_rate": 3.966474449420281e-05,
      "loss": 0.0617,
      "step": 47200
    },
    {
      "epoch": 3.3160403813796973,
      "grad_norm": 0.19619087874889374,
      "learning_rate": 3.964283523359654e-05,
      "loss": 0.0557,
      "step": 47300
    },
    {
      "epoch": 3.3230510375771174,
      "grad_norm": 0.34368962049484253,
      "learning_rate": 3.9620925972990264e-05,
      "loss": 0.0569,
      "step": 47400
    },
    {
      "epoch": 3.330061693774537,
      "grad_norm": 0.0886669009923935,
      "learning_rate": 3.959901671238399e-05,
      "loss": 0.0585,
      "step": 47500
    },
    {
      "epoch": 3.3370723499719572,
      "grad_norm": 0.11465040594339371,
      "learning_rate": 3.957710745177772e-05,
      "loss": 0.0593,
      "step": 47600
    },
    {
      "epoch": 3.3440830061693774,
      "grad_norm": 0.16835805773735046,
      "learning_rate": 3.9555198191171445e-05,
      "loss": 0.055,
      "step": 47700
    },
    {
      "epoch": 3.3510936623667975,
      "grad_norm": 0.11120281368494034,
      "learning_rate": 3.953328893056517e-05,
      "loss": 0.0624,
      "step": 47800
    },
    {
      "epoch": 3.3581043185642176,
      "grad_norm": 0.23750221729278564,
      "learning_rate": 3.95113796699589e-05,
      "loss": 0.0565,
      "step": 47900
    },
    {
      "epoch": 3.365114974761638,
      "grad_norm": 0.13147488236427307,
      "learning_rate": 3.9489470409352626e-05,
      "loss": 0.0576,
      "step": 48000
    },
    {
      "epoch": 3.372125630959058,
      "grad_norm": 0.2503918707370758,
      "learning_rate": 3.946756114874635e-05,
      "loss": 0.0592,
      "step": 48100
    },
    {
      "epoch": 3.379136287156478,
      "grad_norm": 0.13588891923427582,
      "learning_rate": 3.944565188814008e-05,
      "loss": 0.0602,
      "step": 48200
    },
    {
      "epoch": 3.3861469433538978,
      "grad_norm": 0.08689554035663605,
      "learning_rate": 3.9423742627533813e-05,
      "loss": 0.059,
      "step": 48300
    },
    {
      "epoch": 3.393157599551318,
      "grad_norm": 0.33326706290245056,
      "learning_rate": 3.940183336692754e-05,
      "loss": 0.058,
      "step": 48400
    },
    {
      "epoch": 3.400168255748738,
      "grad_norm": 0.250118613243103,
      "learning_rate": 3.937992410632127e-05,
      "loss": 0.0576,
      "step": 48500
    },
    {
      "epoch": 3.407178911946158,
      "grad_norm": 0.29422393441200256,
      "learning_rate": 3.9358014845714994e-05,
      "loss": 0.0605,
      "step": 48600
    },
    {
      "epoch": 3.4141895681435783,
      "grad_norm": 0.20475365221500397,
      "learning_rate": 3.9336105585108715e-05,
      "loss": 0.055,
      "step": 48700
    },
    {
      "epoch": 3.4212002243409985,
      "grad_norm": 0.155851811170578,
      "learning_rate": 3.931419632450244e-05,
      "loss": 0.0594,
      "step": 48800
    },
    {
      "epoch": 3.428210880538418,
      "grad_norm": 0.13596086204051971,
      "learning_rate": 3.929228706389617e-05,
      "loss": 0.0606,
      "step": 48900
    },
    {
      "epoch": 3.4352215367358383,
      "grad_norm": 0.3161126971244812,
      "learning_rate": 3.9270377803289896e-05,
      "loss": 0.0596,
      "step": 49000
    },
    {
      "epoch": 3.4422321929332584,
      "grad_norm": 0.1252441108226776,
      "learning_rate": 3.924846854268362e-05,
      "loss": 0.0539,
      "step": 49100
    },
    {
      "epoch": 3.4492428491306786,
      "grad_norm": 0.1049141138792038,
      "learning_rate": 3.922655928207735e-05,
      "loss": 0.0528,
      "step": 49200
    },
    {
      "epoch": 3.4562535053280987,
      "grad_norm": 0.30953893065452576,
      "learning_rate": 3.920486911407714e-05,
      "loss": 0.0604,
      "step": 49300
    },
    {
      "epoch": 3.463264161525519,
      "grad_norm": 0.15983964502811432,
      "learning_rate": 3.918295985347087e-05,
      "loss": 0.0525,
      "step": 49400
    },
    {
      "epoch": 3.470274817722939,
      "grad_norm": 0.11156252771615982,
      "learning_rate": 3.9161050592864594e-05,
      "loss": 0.0514,
      "step": 49500
    },
    {
      "epoch": 3.477285473920359,
      "grad_norm": 0.15310826897621155,
      "learning_rate": 3.913914133225832e-05,
      "loss": 0.0563,
      "step": 49600
    },
    {
      "epoch": 3.484296130117779,
      "grad_norm": 0.20235666632652283,
      "learning_rate": 3.911723207165205e-05,
      "loss": 0.0616,
      "step": 49700
    },
    {
      "epoch": 3.491306786315199,
      "grad_norm": 0.11153598129749298,
      "learning_rate": 3.9095322811045775e-05,
      "loss": 0.0541,
      "step": 49800
    },
    {
      "epoch": 3.498317442512619,
      "grad_norm": 0.1451909840106964,
      "learning_rate": 3.90734135504395e-05,
      "loss": 0.0578,
      "step": 49900
    },
    {
      "epoch": 3.5053280987100393,
      "grad_norm": 0.08215808123350143,
      "learning_rate": 3.905150428983323e-05,
      "loss": 0.0569,
      "step": 50000
    },
    {
      "epoch": 3.5123387549074594,
      "grad_norm": 0.1837303340435028,
      "learning_rate": 3.9029595029226956e-05,
      "loss": 0.0567,
      "step": 50100
    },
    {
      "epoch": 3.5193494111048795,
      "grad_norm": 0.28358447551727295,
      "learning_rate": 3.900768576862068e-05,
      "loss": 0.0588,
      "step": 50200
    },
    {
      "epoch": 3.5263600673022992,
      "grad_norm": 0.08789914101362228,
      "learning_rate": 3.898577650801441e-05,
      "loss": 0.0586,
      "step": 50300
    },
    {
      "epoch": 3.5333707234997194,
      "grad_norm": 0.34839507937431335,
      "learning_rate": 3.896386724740814e-05,
      "loss": 0.0565,
      "step": 50400
    },
    {
      "epoch": 3.5403813796971395,
      "grad_norm": 0.18200132250785828,
      "learning_rate": 3.8941957986801864e-05,
      "loss": 0.0557,
      "step": 50500
    },
    {
      "epoch": 3.5473920358945596,
      "grad_norm": 0.085356205701828,
      "learning_rate": 3.892004872619559e-05,
      "loss": 0.0564,
      "step": 50600
    },
    {
      "epoch": 3.55440269209198,
      "grad_norm": 0.17349453270435333,
      "learning_rate": 3.889835855819538e-05,
      "loss": 0.0577,
      "step": 50700
    },
    {
      "epoch": 3.5614133482894,
      "grad_norm": 0.13094405829906464,
      "learning_rate": 3.887644929758911e-05,
      "loss": 0.0617,
      "step": 50800
    },
    {
      "epoch": 3.56842400448682,
      "grad_norm": 0.35342860221862793,
      "learning_rate": 3.8854540036982836e-05,
      "loss": 0.061,
      "step": 50900
    },
    {
      "epoch": 3.57543466068424,
      "grad_norm": 0.07529386132955551,
      "learning_rate": 3.883263077637656e-05,
      "loss": 0.0562,
      "step": 51000
    },
    {
      "epoch": 3.5824453168816603,
      "grad_norm": 0.08694437146186829,
      "learning_rate": 3.881072151577029e-05,
      "loss": 0.0577,
      "step": 51100
    },
    {
      "epoch": 3.58945597307908,
      "grad_norm": 0.10850398987531662,
      "learning_rate": 3.8788812255164017e-05,
      "loss": 0.061,
      "step": 51200
    },
    {
      "epoch": 3.5964666292765,
      "grad_norm": 0.1304047703742981,
      "learning_rate": 3.8766902994557744e-05,
      "loss": 0.0562,
      "step": 51300
    },
    {
      "epoch": 3.6034772854739203,
      "grad_norm": 0.09350820630788803,
      "learning_rate": 3.874499373395147e-05,
      "loss": 0.0545,
      "step": 51400
    },
    {
      "epoch": 3.6104879416713405,
      "grad_norm": 0.16411660611629486,
      "learning_rate": 3.87230844733452e-05,
      "loss": 0.0585,
      "step": 51500
    },
    {
      "epoch": 3.6174985978687606,
      "grad_norm": 0.14366908371448517,
      "learning_rate": 3.8701175212738924e-05,
      "loss": 0.0622,
      "step": 51600
    },
    {
      "epoch": 3.6245092540661807,
      "grad_norm": 0.3397189974784851,
      "learning_rate": 3.867926595213265e-05,
      "loss": 0.0578,
      "step": 51700
    },
    {
      "epoch": 3.6315199102636004,
      "grad_norm": 0.1651410460472107,
      "learning_rate": 3.865735669152638e-05,
      "loss": 0.0582,
      "step": 51800
    },
    {
      "epoch": 3.6385305664610206,
      "grad_norm": 0.21744345128536224,
      "learning_rate": 3.8635447430920105e-05,
      "loss": 0.0557,
      "step": 51900
    },
    {
      "epoch": 3.6455412226584407,
      "grad_norm": 0.08456974476575851,
      "learning_rate": 3.8613538170313826e-05,
      "loss": 0.0585,
      "step": 52000
    },
    {
      "epoch": 3.652551878855861,
      "grad_norm": 0.07045655697584152,
      "learning_rate": 3.859162890970755e-05,
      "loss": 0.0565,
      "step": 52100
    },
    {
      "epoch": 3.659562535053281,
      "grad_norm": 0.2582741379737854,
      "learning_rate": 3.856971964910128e-05,
      "loss": 0.055,
      "step": 52200
    },
    {
      "epoch": 3.666573191250701,
      "grad_norm": 0.1089576929807663,
      "learning_rate": 3.8547810388495007e-05,
      "loss": 0.0544,
      "step": 52300
    },
    {
      "epoch": 3.6735838474481213,
      "grad_norm": 0.16609227657318115,
      "learning_rate": 3.8525901127888733e-05,
      "loss": 0.0592,
      "step": 52400
    },
    {
      "epoch": 3.6805945036455414,
      "grad_norm": 0.13988956809043884,
      "learning_rate": 3.850399186728246e-05,
      "loss": 0.0566,
      "step": 52500
    },
    {
      "epoch": 3.6876051598429616,
      "grad_norm": 0.19138073921203613,
      "learning_rate": 3.848208260667619e-05,
      "loss": 0.0536,
      "step": 52600
    },
    {
      "epoch": 3.6946158160403813,
      "grad_norm": 0.4151051640510559,
      "learning_rate": 3.8460173346069914e-05,
      "loss": 0.0569,
      "step": 52700
    },
    {
      "epoch": 3.7016264722378014,
      "grad_norm": 0.22594238817691803,
      "learning_rate": 3.843826408546364e-05,
      "loss": 0.057,
      "step": 52800
    },
    {
      "epoch": 3.7086371284352215,
      "grad_norm": 0.19382697343826294,
      "learning_rate": 3.841635482485737e-05,
      "loss": 0.059,
      "step": 52900
    },
    {
      "epoch": 3.7156477846326417,
      "grad_norm": 0.39045384526252747,
      "learning_rate": 3.8394445564251095e-05,
      "loss": 0.0577,
      "step": 53000
    },
    {
      "epoch": 3.722658440830062,
      "grad_norm": 0.1560102105140686,
      "learning_rate": 3.837253630364482e-05,
      "loss": 0.0601,
      "step": 53100
    },
    {
      "epoch": 3.7296690970274815,
      "grad_norm": 0.18015384674072266,
      "learning_rate": 3.8350627043038556e-05,
      "loss": 0.0559,
      "step": 53200
    },
    {
      "epoch": 3.7366797532249016,
      "grad_norm": 0.2215510904788971,
      "learning_rate": 3.832871778243228e-05,
      "loss": 0.0525,
      "step": 53300
    },
    {
      "epoch": 3.743690409422322,
      "grad_norm": 0.16958166658878326,
      "learning_rate": 3.830680852182601e-05,
      "loss": 0.0549,
      "step": 53400
    },
    {
      "epoch": 3.750701065619742,
      "grad_norm": 0.0814628154039383,
      "learning_rate": 3.828489926121974e-05,
      "loss": 0.0535,
      "step": 53500
    },
    {
      "epoch": 3.757711721817162,
      "grad_norm": 0.06598909199237823,
      "learning_rate": 3.8262990000613464e-05,
      "loss": 0.0572,
      "step": 53600
    },
    {
      "epoch": 3.764722378014582,
      "grad_norm": 0.16130776703357697,
      "learning_rate": 3.824108074000719e-05,
      "loss": 0.056,
      "step": 53700
    },
    {
      "epoch": 3.7717330342120023,
      "grad_norm": 0.07469846308231354,
      "learning_rate": 3.821917147940092e-05,
      "loss": 0.0571,
      "step": 53800
    },
    {
      "epoch": 3.7787436904094225,
      "grad_norm": 0.11759624630212784,
      "learning_rate": 3.8197262218794645e-05,
      "loss": 0.0555,
      "step": 53900
    },
    {
      "epoch": 3.7857543466068426,
      "grad_norm": 0.10259528458118439,
      "learning_rate": 3.817535295818837e-05,
      "loss": 0.061,
      "step": 54000
    },
    {
      "epoch": 3.7927650028042623,
      "grad_norm": 0.2338281273841858,
      "learning_rate": 3.81534436975821e-05,
      "loss": 0.0565,
      "step": 54100
    },
    {
      "epoch": 3.7997756590016825,
      "grad_norm": 0.1092030331492424,
      "learning_rate": 3.8131534436975826e-05,
      "loss": 0.0629,
      "step": 54200
    },
    {
      "epoch": 3.8067863151991026,
      "grad_norm": 0.26787132024765015,
      "learning_rate": 3.810962517636955e-05,
      "loss": 0.0579,
      "step": 54300
    },
    {
      "epoch": 3.8137969713965227,
      "grad_norm": 0.1516529619693756,
      "learning_rate": 3.808771591576328e-05,
      "loss": 0.056,
      "step": 54400
    },
    {
      "epoch": 3.820807627593943,
      "grad_norm": 0.07732678204774857,
      "learning_rate": 3.806580665515701e-05,
      "loss": 0.0586,
      "step": 54500
    },
    {
      "epoch": 3.827818283791363,
      "grad_norm": 0.16998973488807678,
      "learning_rate": 3.8043897394550734e-05,
      "loss": 0.0565,
      "step": 54600
    },
    {
      "epoch": 3.8348289399887827,
      "grad_norm": 0.24099990725517273,
      "learning_rate": 3.8022207226550525e-05,
      "loss": 0.0562,
      "step": 54700
    },
    {
      "epoch": 3.841839596186203,
      "grad_norm": 0.16053105890750885,
      "learning_rate": 3.800029796594425e-05,
      "loss": 0.0643,
      "step": 54800
    },
    {
      "epoch": 3.848850252383623,
      "grad_norm": 0.25720399618148804,
      "learning_rate": 3.797838870533797e-05,
      "loss": 0.0578,
      "step": 54900
    },
    {
      "epoch": 3.855860908581043,
      "grad_norm": 0.04497790336608887,
      "learning_rate": 3.79564794447317e-05,
      "loss": 0.0556,
      "step": 55000
    },
    {
      "epoch": 3.8628715647784633,
      "grad_norm": 0.1083318442106247,
      "learning_rate": 3.7934570184125426e-05,
      "loss": 0.0553,
      "step": 55100
    },
    {
      "epoch": 3.8698822209758834,
      "grad_norm": 0.20142921805381775,
      "learning_rate": 3.791266092351915e-05,
      "loss": 0.051,
      "step": 55200
    },
    {
      "epoch": 3.8768928771733036,
      "grad_norm": 0.28905943036079407,
      "learning_rate": 3.789075166291288e-05,
      "loss": 0.0603,
      "step": 55300
    },
    {
      "epoch": 3.8839035333707237,
      "grad_norm": 0.27112793922424316,
      "learning_rate": 3.7868842402306607e-05,
      "loss": 0.0587,
      "step": 55400
    },
    {
      "epoch": 3.890914189568144,
      "grad_norm": 0.08858868479728699,
      "learning_rate": 3.7846933141700334e-05,
      "loss": 0.0608,
      "step": 55500
    },
    {
      "epoch": 3.8979248457655635,
      "grad_norm": 0.14468401670455933,
      "learning_rate": 3.782502388109406e-05,
      "loss": 0.0539,
      "step": 55600
    },
    {
      "epoch": 3.9049355019629837,
      "grad_norm": 0.06692372262477875,
      "learning_rate": 3.780311462048779e-05,
      "loss": 0.0529,
      "step": 55700
    },
    {
      "epoch": 3.911946158160404,
      "grad_norm": 0.0797315314412117,
      "learning_rate": 3.7781205359881515e-05,
      "loss": 0.0584,
      "step": 55800
    },
    {
      "epoch": 3.918956814357824,
      "grad_norm": 0.1182025596499443,
      "learning_rate": 3.775929609927524e-05,
      "loss": 0.0598,
      "step": 55900
    },
    {
      "epoch": 3.925967470555244,
      "grad_norm": 0.15235093235969543,
      "learning_rate": 3.773738683866897e-05,
      "loss": 0.0581,
      "step": 56000
    },
    {
      "epoch": 3.932978126752664,
      "grad_norm": 0.21596002578735352,
      "learning_rate": 3.7715477578062695e-05,
      "loss": 0.0568,
      "step": 56100
    },
    {
      "epoch": 3.939988782950084,
      "grad_norm": 0.05045852065086365,
      "learning_rate": 3.769356831745642e-05,
      "loss": 0.0543,
      "step": 56200
    },
    {
      "epoch": 3.946999439147504,
      "grad_norm": 0.25036513805389404,
      "learning_rate": 3.767165905685015e-05,
      "loss": 0.0599,
      "step": 56300
    },
    {
      "epoch": 3.954010095344924,
      "grad_norm": 0.21042369306087494,
      "learning_rate": 3.7649749796243876e-05,
      "loss": 0.0611,
      "step": 56400
    },
    {
      "epoch": 3.9610207515423443,
      "grad_norm": 0.11744469404220581,
      "learning_rate": 3.76278405356376e-05,
      "loss": 0.0589,
      "step": 56500
    },
    {
      "epoch": 3.9680314077397645,
      "grad_norm": 0.07056255638599396,
      "learning_rate": 3.760593127503133e-05,
      "loss": 0.0584,
      "step": 56600
    },
    {
      "epoch": 3.9750420639371846,
      "grad_norm": 0.1901358962059021,
      "learning_rate": 3.758402201442506e-05,
      "loss": 0.0547,
      "step": 56700
    },
    {
      "epoch": 3.9820527201346048,
      "grad_norm": 0.06890847533941269,
      "learning_rate": 3.7562112753818784e-05,
      "loss": 0.06,
      "step": 56800
    },
    {
      "epoch": 3.989063376332025,
      "grad_norm": 0.1767577975988388,
      "learning_rate": 3.7540422585818575e-05,
      "loss": 0.0607,
      "step": 56900
    },
    {
      "epoch": 3.9960740325294446,
      "grad_norm": 0.14782559871673584,
      "learning_rate": 3.75185133252123e-05,
      "loss": 0.059,
      "step": 57000
    },
    {
      "epoch": 4.0,
      "eval_accuracy_macro_0.5": 0.9768067002296448,
      "eval_accuracy_micro_0.5": 0.9768067002296448,
      "eval_accuracy_weighted_0.5": 0.9651027917861938,
      "eval_aucroc_macro": 0.8621019124984741,
      "eval_aucroc_micro": 0.8804017305374146,
      "eval_aucroc_weighted": 0.8757092952728271,
      "eval_f1_macro_0.5": 0.6229098439216614,
      "eval_f1_macro_0.6": 0.577242910861969,
      "eval_f1_macro_0.7": 0.5171089172363281,
      "eval_f1_macro_0.8": 0.28917908668518066,
      "eval_f1_micro_0.5": 0.6780616641044617,
      "eval_f1_micro_0.6": 0.6438440084457397,
      "eval_f1_micro_0.7": 0.5930759906768799,
      "eval_f1_micro_0.8": 0.5082368850708008,
      "eval_f1_micro_0.9": 0.34795716404914856,
      "eval_f1_weighted_0.5": 0.6609740853309631,
      "eval_f1_weighted_0.6": 0.6163976192474365,
      "eval_f1_weighted_0.7": 0.5557799339294434,
      "eval_f1_weighted_0.8": 0.3101920485496521,
      "eval_loss": 0.053615644574165344,
      "eval_runtime": 70.3898,
      "eval_samples_per_second": 404.519,
      "eval_steps_per_second": 50.575,
      "step": 57056
    },
    {
      "epoch": 4.003084688726865,
      "grad_norm": 0.2137378603219986,
      "learning_rate": 3.749660406460603e-05,
      "loss": 0.0538,
      "step": 57100
    },
    {
      "epoch": 4.010095344924285,
      "grad_norm": 0.273391991853714,
      "learning_rate": 3.7474694803999756e-05,
      "loss": 0.0555,
      "step": 57200
    },
    {
      "epoch": 4.017106001121705,
      "grad_norm": 0.14665892720222473,
      "learning_rate": 3.745278554339348e-05,
      "loss": 0.0574,
      "step": 57300
    },
    {
      "epoch": 4.024116657319125,
      "grad_norm": 0.17170138657093048,
      "learning_rate": 3.743087628278721e-05,
      "loss": 0.0563,
      "step": 57400
    },
    {
      "epoch": 4.031127313516545,
      "grad_norm": 0.29752394556999207,
      "learning_rate": 3.740896702218094e-05,
      "loss": 0.0574,
      "step": 57500
    },
    {
      "epoch": 4.038137969713965,
      "grad_norm": 0.11642741411924362,
      "learning_rate": 3.7387057761574664e-05,
      "loss": 0.0584,
      "step": 57600
    },
    {
      "epoch": 4.045148625911385,
      "grad_norm": 0.15278902649879456,
      "learning_rate": 3.736514850096839e-05,
      "loss": 0.0564,
      "step": 57700
    },
    {
      "epoch": 4.052159282108805,
      "grad_norm": 0.1489650309085846,
      "learning_rate": 3.734323924036212e-05,
      "loss": 0.0569,
      "step": 57800
    },
    {
      "epoch": 4.059169938306225,
      "grad_norm": 0.27995944023132324,
      "learning_rate": 3.7321329979755845e-05,
      "loss": 0.0587,
      "step": 57900
    },
    {
      "epoch": 4.0661805945036456,
      "grad_norm": 0.1641954779624939,
      "learning_rate": 3.729942071914957e-05,
      "loss": 0.0602,
      "step": 58000
    },
    {
      "epoch": 4.073191250701066,
      "grad_norm": 0.21663261950016022,
      "learning_rate": 3.72775114585433e-05,
      "loss": 0.0579,
      "step": 58100
    },
    {
      "epoch": 4.080201906898486,
      "grad_norm": 0.3038509488105774,
      "learning_rate": 3.7255602197937026e-05,
      "loss": 0.0579,
      "step": 58200
    },
    {
      "epoch": 4.087212563095906,
      "grad_norm": 0.15437379479408264,
      "learning_rate": 3.723369293733075e-05,
      "loss": 0.0615,
      "step": 58300
    },
    {
      "epoch": 4.094223219293326,
      "grad_norm": 0.329902321100235,
      "learning_rate": 3.721178367672448e-05,
      "loss": 0.0568,
      "step": 58400
    },
    {
      "epoch": 4.101233875490746,
      "grad_norm": 0.1459605097770691,
      "learning_rate": 3.718987441611821e-05,
      "loss": 0.0507,
      "step": 58500
    },
    {
      "epoch": 4.108244531688166,
      "grad_norm": 0.26437386870384216,
      "learning_rate": 3.7167965155511934e-05,
      "loss": 0.0546,
      "step": 58600
    },
    {
      "epoch": 4.115255187885586,
      "grad_norm": 0.3787556290626526,
      "learning_rate": 3.714605589490566e-05,
      "loss": 0.0489,
      "step": 58700
    },
    {
      "epoch": 4.122265844083006,
      "grad_norm": 0.30110323429107666,
      "learning_rate": 3.712414663429939e-05,
      "loss": 0.0593,
      "step": 58800
    },
    {
      "epoch": 4.129276500280426,
      "grad_norm": 0.12452197074890137,
      "learning_rate": 3.710245646629918e-05,
      "loss": 0.0569,
      "step": 58900
    },
    {
      "epoch": 4.136287156477846,
      "grad_norm": 0.18666419386863708,
      "learning_rate": 3.7080547205692905e-05,
      "loss": 0.0545,
      "step": 59000
    },
    {
      "epoch": 4.143297812675266,
      "grad_norm": 0.2811215817928314,
      "learning_rate": 3.705863794508663e-05,
      "loss": 0.0575,
      "step": 59100
    },
    {
      "epoch": 4.150308468872686,
      "grad_norm": 0.13534171879291534,
      "learning_rate": 3.703672868448036e-05,
      "loss": 0.0534,
      "step": 59200
    },
    {
      "epoch": 4.1573191250701065,
      "grad_norm": 0.12644921243190765,
      "learning_rate": 3.7014819423874086e-05,
      "loss": 0.0556,
      "step": 59300
    },
    {
      "epoch": 4.164329781267527,
      "grad_norm": 0.23379004001617432,
      "learning_rate": 3.699291016326781e-05,
      "loss": 0.0534,
      "step": 59400
    },
    {
      "epoch": 4.171340437464947,
      "grad_norm": 0.18604926764965057,
      "learning_rate": 3.697100090266154e-05,
      "loss": 0.06,
      "step": 59500
    },
    {
      "epoch": 4.178351093662367,
      "grad_norm": 0.18041816353797913,
      "learning_rate": 3.694909164205527e-05,
      "loss": 0.0591,
      "step": 59600
    },
    {
      "epoch": 4.185361749859787,
      "grad_norm": 0.2862129509449005,
      "learning_rate": 3.6927182381448994e-05,
      "loss": 0.0568,
      "step": 59700
    },
    {
      "epoch": 4.192372406057207,
      "grad_norm": 0.15841612219810486,
      "learning_rate": 3.690527312084272e-05,
      "loss": 0.0537,
      "step": 59800
    },
    {
      "epoch": 4.199383062254627,
      "grad_norm": 0.26922526955604553,
      "learning_rate": 3.688336386023645e-05,
      "loss": 0.0546,
      "step": 59900
    },
    {
      "epoch": 4.2063937184520475,
      "grad_norm": 0.23618319630622864,
      "learning_rate": 3.6861454599630175e-05,
      "loss": 0.0585,
      "step": 60000
    },
    {
      "epoch": 4.213404374649468,
      "grad_norm": 0.27069294452667236,
      "learning_rate": 3.68395453390239e-05,
      "loss": 0.057,
      "step": 60100
    },
    {
      "epoch": 4.220415030846887,
      "grad_norm": 0.20591484010219574,
      "learning_rate": 3.681763607841763e-05,
      "loss": 0.0544,
      "step": 60200
    },
    {
      "epoch": 4.227425687044307,
      "grad_norm": 0.15122810006141663,
      "learning_rate": 3.6795726817811356e-05,
      "loss": 0.0569,
      "step": 60300
    },
    {
      "epoch": 4.234436343241727,
      "grad_norm": 0.20779576897621155,
      "learning_rate": 3.677381755720508e-05,
      "loss": 0.0518,
      "step": 60400
    },
    {
      "epoch": 4.241446999439147,
      "grad_norm": 0.2507022023200989,
      "learning_rate": 3.675190829659881e-05,
      "loss": 0.0559,
      "step": 60500
    },
    {
      "epoch": 4.248457655636567,
      "grad_norm": 0.29555755853652954,
      "learning_rate": 3.672999903599254e-05,
      "loss": 0.0582,
      "step": 60600
    },
    {
      "epoch": 4.2554683118339875,
      "grad_norm": 0.38388392329216003,
      "learning_rate": 3.6708089775386264e-05,
      "loss": 0.0538,
      "step": 60700
    },
    {
      "epoch": 4.262478968031408,
      "grad_norm": 0.2324589490890503,
      "learning_rate": 3.668618051477999e-05,
      "loss": 0.0588,
      "step": 60800
    },
    {
      "epoch": 4.269489624228828,
      "grad_norm": 0.11498788744211197,
      "learning_rate": 3.666449034677978e-05,
      "loss": 0.0556,
      "step": 60900
    },
    {
      "epoch": 4.276500280426248,
      "grad_norm": 0.2825174033641815,
      "learning_rate": 3.664258108617351e-05,
      "loss": 0.0535,
      "step": 61000
    },
    {
      "epoch": 4.283510936623668,
      "grad_norm": 0.1274956464767456,
      "learning_rate": 3.662067182556723e-05,
      "loss": 0.0592,
      "step": 61100
    },
    {
      "epoch": 4.290521592821088,
      "grad_norm": 0.23344692587852478,
      "learning_rate": 3.659898165756702e-05,
      "loss": 0.0567,
      "step": 61200
    },
    {
      "epoch": 4.297532249018508,
      "grad_norm": 0.2352210134267807,
      "learning_rate": 3.6577072396960747e-05,
      "loss": 0.0544,
      "step": 61300
    },
    {
      "epoch": 4.3045429052159285,
      "grad_norm": 0.25535115599632263,
      "learning_rate": 3.6555163136354474e-05,
      "loss": 0.0565,
      "step": 61400
    },
    {
      "epoch": 4.311553561413349,
      "grad_norm": 0.4743390381336212,
      "learning_rate": 3.65332538757482e-05,
      "loss": 0.0559,
      "step": 61500
    },
    {
      "epoch": 4.318564217610769,
      "grad_norm": 0.16813963651657104,
      "learning_rate": 3.651134461514193e-05,
      "loss": 0.0522,
      "step": 61600
    },
    {
      "epoch": 4.325574873808188,
      "grad_norm": 0.1742819994688034,
      "learning_rate": 3.6489435354535654e-05,
      "loss": 0.0541,
      "step": 61700
    },
    {
      "epoch": 4.332585530005608,
      "grad_norm": 0.3791571855545044,
      "learning_rate": 3.646752609392938e-05,
      "loss": 0.0534,
      "step": 61800
    },
    {
      "epoch": 4.339596186203028,
      "grad_norm": 0.1724761724472046,
      "learning_rate": 3.644561683332311e-05,
      "loss": 0.0552,
      "step": 61900
    },
    {
      "epoch": 4.3466068424004485,
      "grad_norm": 0.22667160630226135,
      "learning_rate": 3.6423707572716835e-05,
      "loss": 0.0544,
      "step": 62000
    },
    {
      "epoch": 4.353617498597869,
      "grad_norm": 0.1805383265018463,
      "learning_rate": 3.640179831211056e-05,
      "loss": 0.0584,
      "step": 62100
    },
    {
      "epoch": 4.360628154795289,
      "grad_norm": 0.21851931512355804,
      "learning_rate": 3.637988905150429e-05,
      "loss": 0.0566,
      "step": 62200
    },
    {
      "epoch": 4.367638810992709,
      "grad_norm": 0.19309449195861816,
      "learning_rate": 3.6357979790898016e-05,
      "loss": 0.0554,
      "step": 62300
    },
    {
      "epoch": 4.374649467190129,
      "grad_norm": 0.3718472421169281,
      "learning_rate": 3.633607053029174e-05,
      "loss": 0.0602,
      "step": 62400
    },
    {
      "epoch": 4.381660123387549,
      "grad_norm": 0.2573171854019165,
      "learning_rate": 3.631416126968547e-05,
      "loss": 0.0506,
      "step": 62500
    },
    {
      "epoch": 4.388670779584969,
      "grad_norm": 0.3545839786529541,
      "learning_rate": 3.62922520090792e-05,
      "loss": 0.0548,
      "step": 62600
    },
    {
      "epoch": 4.3956814357823895,
      "grad_norm": 0.10253970324993134,
      "learning_rate": 3.6270342748472924e-05,
      "loss": 0.0566,
      "step": 62700
    },
    {
      "epoch": 4.40269209197981,
      "grad_norm": 0.3448050320148468,
      "learning_rate": 3.624843348786665e-05,
      "loss": 0.0588,
      "step": 62800
    },
    {
      "epoch": 4.40970274817723,
      "grad_norm": 0.249285027384758,
      "learning_rate": 3.622652422726038e-05,
      "loss": 0.0554,
      "step": 62900
    },
    {
      "epoch": 4.41671340437465,
      "grad_norm": 0.1832311600446701,
      "learning_rate": 3.6204614966654105e-05,
      "loss": 0.0566,
      "step": 63000
    },
    {
      "epoch": 4.42372406057207,
      "grad_norm": 0.17319516837596893,
      "learning_rate": 3.618270570604783e-05,
      "loss": 0.054,
      "step": 63100
    },
    {
      "epoch": 4.430734716769489,
      "grad_norm": 0.27284467220306396,
      "learning_rate": 3.616079644544156e-05,
      "loss": 0.0553,
      "step": 63200
    },
    {
      "epoch": 4.437745372966909,
      "grad_norm": 0.14091825485229492,
      "learning_rate": 3.613888718483529e-05,
      "loss": 0.0596,
      "step": 63300
    },
    {
      "epoch": 4.4447560291643295,
      "grad_norm": 0.13772127032279968,
      "learning_rate": 3.611697792422902e-05,
      "loss": 0.0574,
      "step": 63400
    },
    {
      "epoch": 4.45176668536175,
      "grad_norm": 0.13242566585540771,
      "learning_rate": 3.609506866362275e-05,
      "loss": 0.0531,
      "step": 63500
    },
    {
      "epoch": 4.45877734155917,
      "grad_norm": 0.40180882811546326,
      "learning_rate": 3.607337849562253e-05,
      "loss": 0.056,
      "step": 63600
    },
    {
      "epoch": 4.46578799775659,
      "grad_norm": 0.24181388318538666,
      "learning_rate": 3.605146923501626e-05,
      "loss": 0.0594,
      "step": 63700
    },
    {
      "epoch": 4.47279865395401,
      "grad_norm": 0.26239994168281555,
      "learning_rate": 3.6029559974409985e-05,
      "loss": 0.0599,
      "step": 63800
    },
    {
      "epoch": 4.47980931015143,
      "grad_norm": 0.2784709930419922,
      "learning_rate": 3.600765071380371e-05,
      "loss": 0.0488,
      "step": 63900
    },
    {
      "epoch": 4.48681996634885,
      "grad_norm": 0.42379552125930786,
      "learning_rate": 3.598574145319744e-05,
      "loss": 0.0556,
      "step": 64000
    },
    {
      "epoch": 4.4938306225462705,
      "grad_norm": 0.10020376741886139,
      "learning_rate": 3.5963832192591166e-05,
      "loss": 0.0548,
      "step": 64100
    },
    {
      "epoch": 4.500841278743691,
      "grad_norm": 0.31787025928497314,
      "learning_rate": 3.594192293198489e-05,
      "loss": 0.0527,
      "step": 64200
    },
    {
      "epoch": 4.507851934941111,
      "grad_norm": 0.13473093509674072,
      "learning_rate": 3.592001367137862e-05,
      "loss": 0.0543,
      "step": 64300
    },
    {
      "epoch": 4.514862591138531,
      "grad_norm": 0.2554580569267273,
      "learning_rate": 3.5898104410772347e-05,
      "loss": 0.0571,
      "step": 64400
    },
    {
      "epoch": 4.52187324733595,
      "grad_norm": 0.24750983715057373,
      "learning_rate": 3.5876195150166074e-05,
      "loss": 0.0584,
      "step": 64500
    },
    {
      "epoch": 4.52888390353337,
      "grad_norm": 0.25426414608955383,
      "learning_rate": 3.58542858895598e-05,
      "loss": 0.0535,
      "step": 64600
    },
    {
      "epoch": 4.5358945597307905,
      "grad_norm": 0.21674299240112305,
      "learning_rate": 3.583237662895353e-05,
      "loss": 0.0581,
      "step": 64700
    },
    {
      "epoch": 4.542905215928211,
      "grad_norm": 0.23255519568920135,
      "learning_rate": 3.5810467368347255e-05,
      "loss": 0.0536,
      "step": 64800
    },
    {
      "epoch": 4.549915872125631,
      "grad_norm": 0.1605433225631714,
      "learning_rate": 3.578855810774098e-05,
      "loss": 0.0544,
      "step": 64900
    },
    {
      "epoch": 4.556926528323051,
      "grad_norm": 0.19427303969860077,
      "learning_rate": 3.576664884713471e-05,
      "loss": 0.057,
      "step": 65000
    },
    {
      "epoch": 4.563937184520471,
      "grad_norm": 0.2922213673591614,
      "learning_rate": 3.5744739586528435e-05,
      "loss": 0.0546,
      "step": 65100
    },
    {
      "epoch": 4.570947840717891,
      "grad_norm": 0.23631852865219116,
      "learning_rate": 3.572283032592216e-05,
      "loss": 0.0557,
      "step": 65200
    },
    {
      "epoch": 4.577958496915311,
      "grad_norm": 0.23405569791793823,
      "learning_rate": 3.570092106531589e-05,
      "loss": 0.0573,
      "step": 65300
    },
    {
      "epoch": 4.5849691531127315,
      "grad_norm": 0.12119360268115997,
      "learning_rate": 3.5679011804709616e-05,
      "loss": 0.0577,
      "step": 65400
    },
    {
      "epoch": 4.591979809310152,
      "grad_norm": 0.24737904965877533,
      "learning_rate": 3.565710254410334e-05,
      "loss": 0.0565,
      "step": 65500
    },
    {
      "epoch": 4.598990465507572,
      "grad_norm": 0.2549014389514923,
      "learning_rate": 3.563519328349707e-05,
      "loss": 0.0572,
      "step": 65600
    },
    {
      "epoch": 4.606001121704992,
      "grad_norm": 0.13774342834949493,
      "learning_rate": 3.56132840228908e-05,
      "loss": 0.056,
      "step": 65700
    },
    {
      "epoch": 4.613011777902412,
      "grad_norm": 0.445497989654541,
      "learning_rate": 3.5591374762284524e-05,
      "loss": 0.0536,
      "step": 65800
    },
    {
      "epoch": 4.620022434099832,
      "grad_norm": 0.14628364145755768,
      "learning_rate": 3.556946550167825e-05,
      "loss": 0.0524,
      "step": 65900
    },
    {
      "epoch": 4.627033090297251,
      "grad_norm": 0.30202072858810425,
      "learning_rate": 3.554777533367804e-05,
      "loss": 0.0599,
      "step": 66000
    },
    {
      "epoch": 4.6340437464946715,
      "grad_norm": 0.14348596334457397,
      "learning_rate": 3.552586607307177e-05,
      "loss": 0.0576,
      "step": 66100
    },
    {
      "epoch": 4.641054402692092,
      "grad_norm": 0.20000876486301422,
      "learning_rate": 3.5503956812465496e-05,
      "loss": 0.0574,
      "step": 66200
    },
    {
      "epoch": 4.648065058889512,
      "grad_norm": 0.3204403519630432,
      "learning_rate": 3.548204755185922e-05,
      "loss": 0.051,
      "step": 66300
    },
    {
      "epoch": 4.655075715086932,
      "grad_norm": 0.26836031675338745,
      "learning_rate": 3.546013829125295e-05,
      "loss": 0.0535,
      "step": 66400
    },
    {
      "epoch": 4.662086371284352,
      "grad_norm": 0.12528857588768005,
      "learning_rate": 3.543822903064668e-05,
      "loss": 0.0553,
      "step": 66500
    },
    {
      "epoch": 4.669097027481772,
      "grad_norm": 0.12140785157680511,
      "learning_rate": 3.5416319770040404e-05,
      "loss": 0.0566,
      "step": 66600
    },
    {
      "epoch": 4.676107683679192,
      "grad_norm": 0.1237797960639,
      "learning_rate": 3.539441050943413e-05,
      "loss": 0.05,
      "step": 66700
    },
    {
      "epoch": 4.6831183398766125,
      "grad_norm": 0.16052523255348206,
      "learning_rate": 3.537250124882786e-05,
      "loss": 0.0551,
      "step": 66800
    },
    {
      "epoch": 4.690128996074033,
      "grad_norm": 0.2107870727777481,
      "learning_rate": 3.5350591988221585e-05,
      "loss": 0.0591,
      "step": 66900
    },
    {
      "epoch": 4.697139652271453,
      "grad_norm": 0.20107652246952057,
      "learning_rate": 3.532868272761531e-05,
      "loss": 0.0564,
      "step": 67000
    },
    {
      "epoch": 4.704150308468873,
      "grad_norm": 0.16867822408676147,
      "learning_rate": 3.530677346700904e-05,
      "loss": 0.0542,
      "step": 67100
    },
    {
      "epoch": 4.711160964666293,
      "grad_norm": 0.22886183857917786,
      "learning_rate": 3.5284864206402766e-05,
      "loss": 0.0567,
      "step": 67200
    },
    {
      "epoch": 4.718171620863713,
      "grad_norm": 0.10684856027364731,
      "learning_rate": 3.5262954945796486e-05,
      "loss": 0.0561,
      "step": 67300
    },
    {
      "epoch": 4.725182277061133,
      "grad_norm": 0.15452267229557037,
      "learning_rate": 3.524104568519021e-05,
      "loss": 0.0584,
      "step": 67400
    },
    {
      "epoch": 4.732192933258553,
      "grad_norm": 0.14390933513641357,
      "learning_rate": 3.521913642458394e-05,
      "loss": 0.0561,
      "step": 67500
    },
    {
      "epoch": 4.739203589455973,
      "grad_norm": 0.17660535871982574,
      "learning_rate": 3.519722716397767e-05,
      "loss": 0.0559,
      "step": 67600
    },
    {
      "epoch": 4.746214245653393,
      "grad_norm": 0.22070176899433136,
      "learning_rate": 3.5175317903371394e-05,
      "loss": 0.0577,
      "step": 67700
    },
    {
      "epoch": 4.753224901850813,
      "grad_norm": 0.3034038841724396,
      "learning_rate": 3.515340864276512e-05,
      "loss": 0.0546,
      "step": 67800
    },
    {
      "epoch": 4.760235558048233,
      "grad_norm": 0.3073863387107849,
      "learning_rate": 3.513149938215885e-05,
      "loss": 0.0591,
      "step": 67900
    },
    {
      "epoch": 4.767246214245653,
      "grad_norm": 0.2890804409980774,
      "learning_rate": 3.5109590121552575e-05,
      "loss": 0.0517,
      "step": 68000
    },
    {
      "epoch": 4.7742568704430735,
      "grad_norm": 0.1306304782629013,
      "learning_rate": 3.508768086094631e-05,
      "loss": 0.0522,
      "step": 68100
    },
    {
      "epoch": 4.781267526640494,
      "grad_norm": 0.13251851499080658,
      "learning_rate": 3.5065771600340036e-05,
      "loss": 0.0552,
      "step": 68200
    },
    {
      "epoch": 4.788278182837914,
      "grad_norm": 0.11494236439466476,
      "learning_rate": 3.504386233973376e-05,
      "loss": 0.0549,
      "step": 68300
    },
    {
      "epoch": 4.795288839035334,
      "grad_norm": 0.43525683879852295,
      "learning_rate": 3.502195307912749e-05,
      "loss": 0.0554,
      "step": 68400
    },
    {
      "epoch": 4.802299495232754,
      "grad_norm": 0.16414964199066162,
      "learning_rate": 3.5000043818521216e-05,
      "loss": 0.055,
      "step": 68500
    },
    {
      "epoch": 4.809310151430174,
      "grad_norm": 0.21930797398090363,
      "learning_rate": 3.4978134557914943e-05,
      "loss": 0.0564,
      "step": 68600
    },
    {
      "epoch": 4.816320807627594,
      "grad_norm": 0.3022051751613617,
      "learning_rate": 3.495622529730867e-05,
      "loss": 0.053,
      "step": 68700
    },
    {
      "epoch": 4.8233314638250135,
      "grad_norm": 0.4054211974143982,
      "learning_rate": 3.49343160367024e-05,
      "loss": 0.0542,
      "step": 68800
    },
    {
      "epoch": 4.830342120022435,
      "grad_norm": 0.14317728579044342,
      "learning_rate": 3.4912406776096124e-05,
      "loss": 0.0613,
      "step": 68900
    },
    {
      "epoch": 4.837352776219854,
      "grad_norm": 0.13308317959308624,
      "learning_rate": 3.489049751548985e-05,
      "loss": 0.0557,
      "step": 69000
    },
    {
      "epoch": 4.844363432417274,
      "grad_norm": 0.45398998260498047,
      "learning_rate": 3.486858825488358e-05,
      "loss": 0.0552,
      "step": 69100
    },
    {
      "epoch": 4.851374088614694,
      "grad_norm": 0.3429974615573883,
      "learning_rate": 3.4846678994277305e-05,
      "loss": 0.0532,
      "step": 69200
    },
    {
      "epoch": 4.858384744812114,
      "grad_norm": 0.23004047572612762,
      "learning_rate": 3.482476973367103e-05,
      "loss": 0.0542,
      "step": 69300
    },
    {
      "epoch": 4.865395401009534,
      "grad_norm": 0.2074085772037506,
      "learning_rate": 3.480286047306476e-05,
      "loss": 0.0592,
      "step": 69400
    },
    {
      "epoch": 4.8724060572069545,
      "grad_norm": 0.3102392256259918,
      "learning_rate": 3.4780951212458486e-05,
      "loss": 0.0505,
      "step": 69500
    },
    {
      "epoch": 4.879416713404375,
      "grad_norm": 0.18312129378318787,
      "learning_rate": 3.475904195185221e-05,
      "loss": 0.0547,
      "step": 69600
    },
    {
      "epoch": 4.886427369601795,
      "grad_norm": 0.39104214310646057,
      "learning_rate": 3.473713269124594e-05,
      "loss": 0.0565,
      "step": 69700
    },
    {
      "epoch": 4.893438025799215,
      "grad_norm": 0.15661786496639252,
      "learning_rate": 3.471522343063967e-05,
      "loss": 0.0545,
      "step": 69800
    },
    {
      "epoch": 4.900448681996635,
      "grad_norm": 0.12567219138145447,
      "learning_rate": 3.4693314170033394e-05,
      "loss": 0.0515,
      "step": 69900
    },
    {
      "epoch": 4.907459338194055,
      "grad_norm": 0.15280479192733765,
      "learning_rate": 3.4671624002033185e-05,
      "loss": 0.0562,
      "step": 70000
    },
    {
      "epoch": 4.914469994391475,
      "grad_norm": 0.18100713193416595,
      "learning_rate": 3.464971474142691e-05,
      "loss": 0.0562,
      "step": 70100
    },
    {
      "epoch": 4.9214806505888955,
      "grad_norm": 0.17980016767978668,
      "learning_rate": 3.462780548082063e-05,
      "loss": 0.0552,
      "step": 70200
    },
    {
      "epoch": 4.928491306786315,
      "grad_norm": 0.28189682960510254,
      "learning_rate": 3.460589622021436e-05,
      "loss": 0.0554,
      "step": 70300
    },
    {
      "epoch": 4.935501962983735,
      "grad_norm": 0.2854168117046356,
      "learning_rate": 3.4583986959608086e-05,
      "loss": 0.0588,
      "step": 70400
    },
    {
      "epoch": 4.942512619181155,
      "grad_norm": 0.2335536926984787,
      "learning_rate": 3.456207769900181e-05,
      "loss": 0.0521,
      "step": 70500
    },
    {
      "epoch": 4.949523275378575,
      "grad_norm": 0.20709815621376038,
      "learning_rate": 3.454016843839554e-05,
      "loss": 0.052,
      "step": 70600
    },
    {
      "epoch": 4.956533931575995,
      "grad_norm": 0.21462947130203247,
      "learning_rate": 3.451825917778927e-05,
      "loss": 0.0573,
      "step": 70700
    },
    {
      "epoch": 4.9635445877734155,
      "grad_norm": 0.4369697570800781,
      "learning_rate": 3.4496349917182994e-05,
      "loss": 0.0556,
      "step": 70800
    },
    {
      "epoch": 4.970555243970836,
      "grad_norm": 0.10195190459489822,
      "learning_rate": 3.447444065657672e-05,
      "loss": 0.0545,
      "step": 70900
    },
    {
      "epoch": 4.977565900168256,
      "grad_norm": 0.12362033873796463,
      "learning_rate": 3.445253139597045e-05,
      "loss": 0.0557,
      "step": 71000
    },
    {
      "epoch": 4.984576556365676,
      "grad_norm": 0.19002090394496918,
      "learning_rate": 3.4430622135364175e-05,
      "loss": 0.0535,
      "step": 71100
    },
    {
      "epoch": 4.991587212563096,
      "grad_norm": 0.32290831208229065,
      "learning_rate": 3.44087128747579e-05,
      "loss": 0.0587,
      "step": 71200
    },
    {
      "epoch": 4.998597868760516,
      "grad_norm": 0.3119599223136902,
      "learning_rate": 3.438680361415163e-05,
      "loss": 0.0549,
      "step": 71300
    },
    {
      "epoch": 5.0,
      "eval_accuracy_macro_0.5": 0.9773971438407898,
      "eval_accuracy_micro_0.5": 0.9773971438407898,
      "eval_accuracy_weighted_0.5": 0.9660882949829102,
      "eval_aucroc_macro": 0.8725775480270386,
      "eval_aucroc_micro": 0.8884881734848022,
      "eval_aucroc_weighted": 0.8840071558952332,
      "eval_f1_macro_0.5": 0.6447301506996155,
      "eval_f1_macro_0.6": 0.6093552708625793,
      "eval_f1_macro_0.7": 0.5482768416404724,
      "eval_f1_macro_0.8": 0.32927459478378296,
      "eval_f1_micro_0.5": 0.6920097470283508,
      "eval_f1_micro_0.6": 0.6652525663375854,
      "eval_f1_micro_0.7": 0.6154899597167969,
      "eval_f1_micro_0.8": 0.5377874970436096,
      "eval_f1_micro_0.9": 0.3891882598400116,
      "eval_f1_weighted_0.5": 0.6788135170936584,
      "eval_f1_weighted_0.6": 0.6437330842018127,
      "eval_f1_weighted_0.7": 0.5830687880516052,
      "eval_f1_weighted_0.8": 0.34525689482688904,
      "eval_loss": 0.052377570420503616,
      "eval_runtime": 69.1251,
      "eval_samples_per_second": 411.92,
      "eval_steps_per_second": 51.501,
      "step": 71320
    },
    {
      "epoch": 5.005608524957936,
      "grad_norm": 0.15955939888954163,
      "learning_rate": 3.4364894353545356e-05,
      "loss": 0.0531,
      "step": 71400
    },
    {
      "epoch": 5.012619181155356,
      "grad_norm": 0.20506301522254944,
      "learning_rate": 3.434298509293908e-05,
      "loss": 0.0576,
      "step": 71500
    },
    {
      "epoch": 5.019629837352777,
      "grad_norm": 0.17017458379268646,
      "learning_rate": 3.432107583233281e-05,
      "loss": 0.0551,
      "step": 71600
    },
    {
      "epoch": 5.026640493550197,
      "grad_norm": 0.3968525826931,
      "learning_rate": 3.429916657172654e-05,
      "loss": 0.0556,
      "step": 71700
    },
    {
      "epoch": 5.033651149747616,
      "grad_norm": 0.11543748527765274,
      "learning_rate": 3.4277257311120264e-05,
      "loss": 0.0552,
      "step": 71800
    },
    {
      "epoch": 5.040661805945036,
      "grad_norm": 0.24862278997898102,
      "learning_rate": 3.425534805051399e-05,
      "loss": 0.0574,
      "step": 71900
    },
    {
      "epoch": 5.047672462142456,
      "grad_norm": 0.1744813621044159,
      "learning_rate": 3.423365788251378e-05,
      "loss": 0.0566,
      "step": 72000
    },
    {
      "epoch": 5.054683118339876,
      "grad_norm": 0.10518179833889008,
      "learning_rate": 3.421174862190751e-05,
      "loss": 0.0544,
      "step": 72100
    },
    {
      "epoch": 5.0616937745372965,
      "grad_norm": 0.24728694558143616,
      "learning_rate": 3.4189839361301235e-05,
      "loss": 0.0561,
      "step": 72200
    },
    {
      "epoch": 5.068704430734717,
      "grad_norm": 0.13492277264595032,
      "learning_rate": 3.416793010069496e-05,
      "loss": 0.0551,
      "step": 72300
    },
    {
      "epoch": 5.075715086932137,
      "grad_norm": 0.18343088030815125,
      "learning_rate": 3.414602084008869e-05,
      "loss": 0.0502,
      "step": 72400
    },
    {
      "epoch": 5.082725743129557,
      "grad_norm": 0.31115758419036865,
      "learning_rate": 3.4124111579482416e-05,
      "loss": 0.0564,
      "step": 72500
    },
    {
      "epoch": 5.089736399326977,
      "grad_norm": 0.3932080566883087,
      "learning_rate": 3.410220231887614e-05,
      "loss": 0.0513,
      "step": 72600
    },
    {
      "epoch": 5.096747055524397,
      "grad_norm": 0.38653260469436646,
      "learning_rate": 3.408029305826987e-05,
      "loss": 0.0553,
      "step": 72700
    },
    {
      "epoch": 5.103757711721817,
      "grad_norm": 0.34569740295410156,
      "learning_rate": 3.40583837976636e-05,
      "loss": 0.059,
      "step": 72800
    },
    {
      "epoch": 5.1107683679192375,
      "grad_norm": 0.2295159548521042,
      "learning_rate": 3.4036474537057324e-05,
      "loss": 0.0555,
      "step": 72900
    },
    {
      "epoch": 5.117779024116658,
      "grad_norm": 0.11429750919342041,
      "learning_rate": 3.401456527645106e-05,
      "loss": 0.0542,
      "step": 73000
    },
    {
      "epoch": 5.124789680314078,
      "grad_norm": 0.36765149235725403,
      "learning_rate": 3.399265601584478e-05,
      "loss": 0.0581,
      "step": 73100
    },
    {
      "epoch": 5.131800336511498,
      "grad_norm": 0.23344074189662933,
      "learning_rate": 3.3970746755238505e-05,
      "loss": 0.0555,
      "step": 73200
    },
    {
      "epoch": 5.138810992708917,
      "grad_norm": 0.2436835765838623,
      "learning_rate": 3.394883749463223e-05,
      "loss": 0.0519,
      "step": 73300
    },
    {
      "epoch": 5.145821648906337,
      "grad_norm": 0.1457759588956833,
      "learning_rate": 3.392692823402596e-05,
      "loss": 0.054,
      "step": 73400
    },
    {
      "epoch": 5.1528323051037574,
      "grad_norm": 0.3015698790550232,
      "learning_rate": 3.3905018973419686e-05,
      "loss": 0.0553,
      "step": 73500
    },
    {
      "epoch": 5.159842961301178,
      "grad_norm": 0.23080679774284363,
      "learning_rate": 3.388310971281341e-05,
      "loss": 0.054,
      "step": 73600
    },
    {
      "epoch": 5.166853617498598,
      "grad_norm": 0.22883926331996918,
      "learning_rate": 3.386120045220714e-05,
      "loss": 0.056,
      "step": 73700
    },
    {
      "epoch": 5.173864273696018,
      "grad_norm": 0.20201115310192108,
      "learning_rate": 3.383929119160087e-05,
      "loss": 0.0539,
      "step": 73800
    },
    {
      "epoch": 5.180874929893438,
      "grad_norm": 0.11509948968887329,
      "learning_rate": 3.3817381930994594e-05,
      "loss": 0.0516,
      "step": 73900
    },
    {
      "epoch": 5.187885586090858,
      "grad_norm": 0.1874399334192276,
      "learning_rate": 3.379547267038832e-05,
      "loss": 0.0563,
      "step": 74000
    },
    {
      "epoch": 5.194896242288278,
      "grad_norm": 0.38104137778282166,
      "learning_rate": 3.377378250238811e-05,
      "loss": 0.0576,
      "step": 74100
    },
    {
      "epoch": 5.201906898485698,
      "grad_norm": 0.14578433334827423,
      "learning_rate": 3.375187324178184e-05,
      "loss": 0.0539,
      "step": 74200
    },
    {
      "epoch": 5.208917554683119,
      "grad_norm": 0.12510687112808228,
      "learning_rate": 3.3729963981175566e-05,
      "loss": 0.0615,
      "step": 74300
    },
    {
      "epoch": 5.215928210880539,
      "grad_norm": 0.26828089356422424,
      "learning_rate": 3.370805472056929e-05,
      "loss": 0.0518,
      "step": 74400
    },
    {
      "epoch": 5.222938867077959,
      "grad_norm": 0.3409702479839325,
      "learning_rate": 3.368614545996302e-05,
      "loss": 0.0566,
      "step": 74500
    },
    {
      "epoch": 5.229949523275379,
      "grad_norm": 0.2064044028520584,
      "learning_rate": 3.3664236199356747e-05,
      "loss": 0.0494,
      "step": 74600
    },
    {
      "epoch": 5.236960179472798,
      "grad_norm": 0.08568134158849716,
      "learning_rate": 3.3642326938750474e-05,
      "loss": 0.0543,
      "step": 74700
    },
    {
      "epoch": 5.243970835670218,
      "grad_norm": 0.2807651162147522,
      "learning_rate": 3.36204176781442e-05,
      "loss": 0.0551,
      "step": 74800
    },
    {
      "epoch": 5.2509814918676385,
      "grad_norm": 0.3067392408847809,
      "learning_rate": 3.359850841753793e-05,
      "loss": 0.0514,
      "step": 74900
    },
    {
      "epoch": 5.257992148065059,
      "grad_norm": 0.2032470703125,
      "learning_rate": 3.3576599156931655e-05,
      "loss": 0.0565,
      "step": 75000
    },
    {
      "epoch": 5.265002804262479,
      "grad_norm": 0.15402548015117645,
      "learning_rate": 3.355468989632538e-05,
      "loss": 0.0546,
      "step": 75100
    },
    {
      "epoch": 5.272013460459899,
      "grad_norm": 0.11579222977161407,
      "learning_rate": 3.353278063571911e-05,
      "loss": 0.0555,
      "step": 75200
    },
    {
      "epoch": 5.279024116657319,
      "grad_norm": 0.16696658730506897,
      "learning_rate": 3.3510871375112835e-05,
      "loss": 0.054,
      "step": 75300
    },
    {
      "epoch": 5.286034772854739,
      "grad_norm": 0.2855457663536072,
      "learning_rate": 3.348896211450656e-05,
      "loss": 0.0577,
      "step": 75400
    },
    {
      "epoch": 5.293045429052159,
      "grad_norm": 0.16576239466667175,
      "learning_rate": 3.346705285390029e-05,
      "loss": 0.0546,
      "step": 75500
    },
    {
      "epoch": 5.3000560852495795,
      "grad_norm": 0.2104901373386383,
      "learning_rate": 3.3445143593294016e-05,
      "loss": 0.0562,
      "step": 75600
    },
    {
      "epoch": 5.307066741447,
      "grad_norm": 0.16086098551750183,
      "learning_rate": 3.342323433268774e-05,
      "loss": 0.0539,
      "step": 75700
    },
    {
      "epoch": 5.31407739764442,
      "grad_norm": 0.24387283623218536,
      "learning_rate": 3.340132507208147e-05,
      "loss": 0.0517,
      "step": 75800
    },
    {
      "epoch": 5.32108805384184,
      "grad_norm": 0.3368324637413025,
      "learning_rate": 3.33794158114752e-05,
      "loss": 0.0547,
      "step": 75900
    },
    {
      "epoch": 5.32809871003926,
      "grad_norm": 0.16639311611652374,
      "learning_rate": 3.3357506550868924e-05,
      "loss": 0.0557,
      "step": 76000
    },
    {
      "epoch": 5.335109366236679,
      "grad_norm": 0.2969302833080292,
      "learning_rate": 3.3335816382868715e-05,
      "loss": 0.0529,
      "step": 76100
    },
    {
      "epoch": 5.3421200224340994,
      "grad_norm": 0.2637937664985657,
      "learning_rate": 3.331390712226244e-05,
      "loss": 0.0572,
      "step": 76200
    },
    {
      "epoch": 5.34913067863152,
      "grad_norm": 0.20847757160663605,
      "learning_rate": 3.329199786165617e-05,
      "loss": 0.0628,
      "step": 76300
    },
    {
      "epoch": 5.35614133482894,
      "grad_norm": 0.28523439168930054,
      "learning_rate": 3.327008860104989e-05,
      "loss": 0.0609,
      "step": 76400
    },
    {
      "epoch": 5.36315199102636,
      "grad_norm": 0.24445930123329163,
      "learning_rate": 3.3248179340443616e-05,
      "loss": 0.0512,
      "step": 76500
    },
    {
      "epoch": 5.37016264722378,
      "grad_norm": 0.391156405210495,
      "learning_rate": 3.322627007983734e-05,
      "loss": 0.0524,
      "step": 76600
    },
    {
      "epoch": 5.3771733034212,
      "grad_norm": 0.26606905460357666,
      "learning_rate": 3.320436081923107e-05,
      "loss": 0.0519,
      "step": 76700
    },
    {
      "epoch": 5.38418395961862,
      "grad_norm": 0.1783038079738617,
      "learning_rate": 3.31824515586248e-05,
      "loss": 0.0507,
      "step": 76800
    },
    {
      "epoch": 5.39119461581604,
      "grad_norm": 0.14606274664402008,
      "learning_rate": 3.3160542298018524e-05,
      "loss": 0.0551,
      "step": 76900
    },
    {
      "epoch": 5.398205272013461,
      "grad_norm": 0.1684163510799408,
      "learning_rate": 3.313863303741225e-05,
      "loss": 0.0521,
      "step": 77000
    },
    {
      "epoch": 5.405215928210881,
      "grad_norm": 0.17111003398895264,
      "learning_rate": 3.311672377680598e-05,
      "loss": 0.0585,
      "step": 77100
    },
    {
      "epoch": 5.412226584408301,
      "grad_norm": 0.4748641550540924,
      "learning_rate": 3.3094814516199705e-05,
      "loss": 0.0575,
      "step": 77200
    },
    {
      "epoch": 5.419237240605721,
      "grad_norm": 0.3097997307777405,
      "learning_rate": 3.307290525559343e-05,
      "loss": 0.0579,
      "step": 77300
    },
    {
      "epoch": 5.426247896803141,
      "grad_norm": 0.1316932886838913,
      "learning_rate": 3.305099599498716e-05,
      "loss": 0.0512,
      "step": 77400
    },
    {
      "epoch": 5.433258553000561,
      "grad_norm": 0.18333697319030762,
      "learning_rate": 3.3029086734380886e-05,
      "loss": 0.0536,
      "step": 77500
    },
    {
      "epoch": 5.4402692091979805,
      "grad_norm": 0.31166839599609375,
      "learning_rate": 3.300717747377461e-05,
      "loss": 0.05,
      "step": 77600
    },
    {
      "epoch": 5.447279865395401,
      "grad_norm": 0.389934241771698,
      "learning_rate": 3.298526821316834e-05,
      "loss": 0.0559,
      "step": 77700
    },
    {
      "epoch": 5.454290521592821,
      "grad_norm": 0.38289347290992737,
      "learning_rate": 3.296335895256207e-05,
      "loss": 0.0544,
      "step": 77800
    },
    {
      "epoch": 5.461301177790241,
      "grad_norm": 0.10727599263191223,
      "learning_rate": 3.29414496919558e-05,
      "loss": 0.0556,
      "step": 77900
    },
    {
      "epoch": 5.468311833987661,
      "grad_norm": 0.15260088443756104,
      "learning_rate": 3.291954043134953e-05,
      "loss": 0.0554,
      "step": 78000
    },
    {
      "epoch": 5.475322490185081,
      "grad_norm": 0.13704313337802887,
      "learning_rate": 3.2897631170743255e-05,
      "loss": 0.0518,
      "step": 78100
    },
    {
      "epoch": 5.482333146382501,
      "grad_norm": 0.2622644901275635,
      "learning_rate": 3.2875941002743045e-05,
      "loss": 0.0553,
      "step": 78200
    },
    {
      "epoch": 5.4893438025799215,
      "grad_norm": 0.22346031665802002,
      "learning_rate": 3.285403174213677e-05,
      "loss": 0.0553,
      "step": 78300
    },
    {
      "epoch": 5.496354458777342,
      "grad_norm": 0.3231492042541504,
      "learning_rate": 3.28321224815305e-05,
      "loss": 0.0536,
      "step": 78400
    },
    {
      "epoch": 5.503365114974762,
      "grad_norm": 0.1643165647983551,
      "learning_rate": 3.2810213220924226e-05,
      "loss": 0.0553,
      "step": 78500
    },
    {
      "epoch": 5.510375771172182,
      "grad_norm": 0.2578725516796112,
      "learning_rate": 3.278830396031795e-05,
      "loss": 0.0544,
      "step": 78600
    },
    {
      "epoch": 5.517386427369602,
      "grad_norm": 0.1276824176311493,
      "learning_rate": 3.276639469971168e-05,
      "loss": 0.0517,
      "step": 78700
    },
    {
      "epoch": 5.524397083567022,
      "grad_norm": 0.24834555387496948,
      "learning_rate": 3.274448543910541e-05,
      "loss": 0.0541,
      "step": 78800
    },
    {
      "epoch": 5.531407739764442,
      "grad_norm": 0.1725378781557083,
      "learning_rate": 3.2722576178499134e-05,
      "loss": 0.0549,
      "step": 78900
    },
    {
      "epoch": 5.5384183959618625,
      "grad_norm": 0.20014412701129913,
      "learning_rate": 3.270066691789286e-05,
      "loss": 0.0529,
      "step": 79000
    },
    {
      "epoch": 5.545429052159282,
      "grad_norm": 0.34729504585266113,
      "learning_rate": 3.267875765728659e-05,
      "loss": 0.0514,
      "step": 79100
    },
    {
      "epoch": 5.552439708356702,
      "grad_norm": 0.3117455244064331,
      "learning_rate": 3.2656848396680315e-05,
      "loss": 0.0525,
      "step": 79200
    },
    {
      "epoch": 5.559450364554122,
      "grad_norm": 0.2536616027355194,
      "learning_rate": 3.2634939136074035e-05,
      "loss": 0.055,
      "step": 79300
    },
    {
      "epoch": 5.566461020751542,
      "grad_norm": 0.18702352046966553,
      "learning_rate": 3.261302987546776e-05,
      "loss": 0.0543,
      "step": 79400
    },
    {
      "epoch": 5.573471676948962,
      "grad_norm": 0.37137168645858765,
      "learning_rate": 3.259112061486149e-05,
      "loss": 0.0541,
      "step": 79500
    },
    {
      "epoch": 5.580482333146382,
      "grad_norm": 0.17599257826805115,
      "learning_rate": 3.2569211354255216e-05,
      "loss": 0.0572,
      "step": 79600
    },
    {
      "epoch": 5.587492989343803,
      "grad_norm": 0.25371742248535156,
      "learning_rate": 3.254730209364894e-05,
      "loss": 0.0541,
      "step": 79700
    },
    {
      "epoch": 5.594503645541223,
      "grad_norm": 0.5246630311012268,
      "learning_rate": 3.2525611925648734e-05,
      "loss": 0.0533,
      "step": 79800
    },
    {
      "epoch": 5.601514301738643,
      "grad_norm": 0.28857553005218506,
      "learning_rate": 3.250370266504246e-05,
      "loss": 0.0569,
      "step": 79900
    },
    {
      "epoch": 5.608524957936063,
      "grad_norm": 0.16680477559566498,
      "learning_rate": 3.248179340443619e-05,
      "loss": 0.0536,
      "step": 80000
    },
    {
      "epoch": 5.615535614133483,
      "grad_norm": 0.2468394637107849,
      "learning_rate": 3.2459884143829915e-05,
      "loss": 0.0518,
      "step": 80100
    },
    {
      "epoch": 5.622546270330903,
      "grad_norm": 0.36367958784103394,
      "learning_rate": 3.243797488322364e-05,
      "loss": 0.0545,
      "step": 80200
    },
    {
      "epoch": 5.629556926528323,
      "grad_norm": 0.1431587189435959,
      "learning_rate": 3.241606562261737e-05,
      "loss": 0.0514,
      "step": 80300
    },
    {
      "epoch": 5.636567582725743,
      "grad_norm": 0.11875086277723312,
      "learning_rate": 3.2394156362011096e-05,
      "loss": 0.0579,
      "step": 80400
    },
    {
      "epoch": 5.643578238923164,
      "grad_norm": 0.1473150998353958,
      "learning_rate": 3.237224710140482e-05,
      "loss": 0.0532,
      "step": 80500
    },
    {
      "epoch": 5.650588895120583,
      "grad_norm": 0.09514573961496353,
      "learning_rate": 3.235033784079855e-05,
      "loss": 0.0562,
      "step": 80600
    },
    {
      "epoch": 5.657599551318003,
      "grad_norm": 0.090520478785038,
      "learning_rate": 3.232842858019228e-05,
      "loss": 0.0541,
      "step": 80700
    },
    {
      "epoch": 5.664610207515423,
      "grad_norm": 0.22881105542182922,
      "learning_rate": 3.2306519319586004e-05,
      "loss": 0.0571,
      "step": 80800
    },
    {
      "epoch": 5.671620863712843,
      "grad_norm": 0.12992624938488007,
      "learning_rate": 3.228461005897973e-05,
      "loss": 0.0532,
      "step": 80900
    },
    {
      "epoch": 5.6786315199102635,
      "grad_norm": 0.0795176774263382,
      "learning_rate": 3.226270079837346e-05,
      "loss": 0.0559,
      "step": 81000
    },
    {
      "epoch": 5.685642176107684,
      "grad_norm": 0.2661750912666321,
      "learning_rate": 3.2240791537767185e-05,
      "loss": 0.0479,
      "step": 81100
    },
    {
      "epoch": 5.692652832305104,
      "grad_norm": 0.1686573475599289,
      "learning_rate": 3.221888227716091e-05,
      "loss": 0.0555,
      "step": 81200
    },
    {
      "epoch": 5.699663488502524,
      "grad_norm": 0.29726094007492065,
      "learning_rate": 3.219697301655464e-05,
      "loss": 0.0508,
      "step": 81300
    },
    {
      "epoch": 5.706674144699944,
      "grad_norm": 0.2953922152519226,
      "learning_rate": 3.2175063755948366e-05,
      "loss": 0.055,
      "step": 81400
    },
    {
      "epoch": 5.713684800897364,
      "grad_norm": 0.17739994823932648,
      "learning_rate": 3.215315449534209e-05,
      "loss": 0.0523,
      "step": 81500
    },
    {
      "epoch": 5.720695457094784,
      "grad_norm": 0.3499204218387604,
      "learning_rate": 3.213124523473582e-05,
      "loss": 0.0518,
      "step": 81600
    },
    {
      "epoch": 5.7277061132922045,
      "grad_norm": 0.1827254593372345,
      "learning_rate": 3.2109335974129547e-05,
      "loss": 0.0515,
      "step": 81700
    },
    {
      "epoch": 5.734716769489625,
      "grad_norm": 0.3928684592247009,
      "learning_rate": 3.2087426713523274e-05,
      "loss": 0.0555,
      "step": 81800
    },
    {
      "epoch": 5.741727425687044,
      "grad_norm": 0.24970053136348724,
      "learning_rate": 3.2065517452917e-05,
      "loss": 0.0539,
      "step": 81900
    },
    {
      "epoch": 5.748738081884464,
      "grad_norm": 0.2923446297645569,
      "learning_rate": 3.204360819231073e-05,
      "loss": 0.0578,
      "step": 82000
    },
    {
      "epoch": 5.755748738081884,
      "grad_norm": 0.15781845152378082,
      "learning_rate": 3.2021698931704454e-05,
      "loss": 0.055,
      "step": 82100
    },
    {
      "epoch": 5.762759394279304,
      "grad_norm": 0.14455169439315796,
      "learning_rate": 3.199978967109818e-05,
      "loss": 0.0526,
      "step": 82200
    },
    {
      "epoch": 5.769770050476724,
      "grad_norm": 0.16220998764038086,
      "learning_rate": 3.197788041049191e-05,
      "loss": 0.0536,
      "step": 82300
    },
    {
      "epoch": 5.776780706674145,
      "grad_norm": 0.23038294911384583,
      "learning_rate": 3.1955971149885635e-05,
      "loss": 0.0531,
      "step": 82400
    },
    {
      "epoch": 5.783791362871565,
      "grad_norm": 0.20619571208953857,
      "learning_rate": 3.193406188927936e-05,
      "loss": 0.0527,
      "step": 82500
    },
    {
      "epoch": 5.790802019068985,
      "grad_norm": 0.1956602782011032,
      "learning_rate": 3.191215262867309e-05,
      "loss": 0.0544,
      "step": 82600
    },
    {
      "epoch": 5.797812675266405,
      "grad_norm": 0.2985267639160156,
      "learning_rate": 3.1890243368066816e-05,
      "loss": 0.0548,
      "step": 82700
    },
    {
      "epoch": 5.804823331463825,
      "grad_norm": 0.26112258434295654,
      "learning_rate": 3.186833410746054e-05,
      "loss": 0.0525,
      "step": 82800
    },
    {
      "epoch": 5.811833987661245,
      "grad_norm": 0.20980334281921387,
      "learning_rate": 3.184642484685427e-05,
      "loss": 0.0587,
      "step": 82900
    },
    {
      "epoch": 5.818844643858665,
      "grad_norm": 0.27147722244262695,
      "learning_rate": 3.1824515586248e-05,
      "loss": 0.0515,
      "step": 83000
    },
    {
      "epoch": 5.8258553000560855,
      "grad_norm": 0.25788798928260803,
      "learning_rate": 3.1802606325641724e-05,
      "loss": 0.0565,
      "step": 83100
    },
    {
      "epoch": 5.832865956253506,
      "grad_norm": 0.3181745409965515,
      "learning_rate": 3.178069706503545e-05,
      "loss": 0.0519,
      "step": 83200
    },
    {
      "epoch": 5.839876612450926,
      "grad_norm": 0.20778408646583557,
      "learning_rate": 3.175878780442918e-05,
      "loss": 0.0542,
      "step": 83300
    },
    {
      "epoch": 5.846887268648345,
      "grad_norm": 0.16099612414836884,
      "learning_rate": 3.1736878543822905e-05,
      "loss": 0.0604,
      "step": 83400
    },
    {
      "epoch": 5.853897924845765,
      "grad_norm": 0.11621669679880142,
      "learning_rate": 3.171496928321663e-05,
      "loss": 0.0499,
      "step": 83500
    },
    {
      "epoch": 5.860908581043185,
      "grad_norm": 0.17601236701011658,
      "learning_rate": 3.169306002261036e-05,
      "loss": 0.0546,
      "step": 83600
    },
    {
      "epoch": 5.8679192372406055,
      "grad_norm": 0.17055368423461914,
      "learning_rate": 3.1671150762004086e-05,
      "loss": 0.0517,
      "step": 83700
    },
    {
      "epoch": 5.874929893438026,
      "grad_norm": 0.1423911154270172,
      "learning_rate": 3.164924150139781e-05,
      "loss": 0.0592,
      "step": 83800
    },
    {
      "epoch": 5.881940549635446,
      "grad_norm": 0.24108262360095978,
      "learning_rate": 3.1627551333397604e-05,
      "loss": 0.0567,
      "step": 83900
    },
    {
      "epoch": 5.888951205832866,
      "grad_norm": 0.42962324619293213,
      "learning_rate": 3.160564207279133e-05,
      "loss": 0.0544,
      "step": 84000
    },
    {
      "epoch": 5.895961862030286,
      "grad_norm": 0.17606687545776367,
      "learning_rate": 3.158373281218506e-05,
      "loss": 0.051,
      "step": 84100
    },
    {
      "epoch": 5.902972518227706,
      "grad_norm": 0.22367946803569794,
      "learning_rate": 3.1561823551578785e-05,
      "loss": 0.0517,
      "step": 84200
    },
    {
      "epoch": 5.909983174425126,
      "grad_norm": 0.18878434598445892,
      "learning_rate": 3.153991429097251e-05,
      "loss": 0.0538,
      "step": 84300
    },
    {
      "epoch": 5.9169938306225465,
      "grad_norm": 0.19155558943748474,
      "learning_rate": 3.151800503036624e-05,
      "loss": 0.0496,
      "step": 84400
    },
    {
      "epoch": 5.924004486819967,
      "grad_norm": 0.25086167454719543,
      "learning_rate": 3.1496095769759966e-05,
      "loss": 0.0541,
      "step": 84500
    },
    {
      "epoch": 5.931015143017387,
      "grad_norm": 0.11985330283641815,
      "learning_rate": 3.147418650915369e-05,
      "loss": 0.0569,
      "step": 84600
    },
    {
      "epoch": 5.938025799214807,
      "grad_norm": 0.15069085359573364,
      "learning_rate": 3.145227724854742e-05,
      "loss": 0.0541,
      "step": 84700
    },
    {
      "epoch": 5.945036455412227,
      "grad_norm": 0.14381656050682068,
      "learning_rate": 3.1430367987941147e-05,
      "loss": 0.0499,
      "step": 84800
    },
    {
      "epoch": 5.952047111609646,
      "grad_norm": 0.3280869722366333,
      "learning_rate": 3.1408458727334874e-05,
      "loss": 0.0516,
      "step": 84900
    },
    {
      "epoch": 5.959057767807066,
      "grad_norm": 0.5489071011543274,
      "learning_rate": 3.13865494667286e-05,
      "loss": 0.0529,
      "step": 85000
    },
    {
      "epoch": 5.966068424004487,
      "grad_norm": 0.17329321801662445,
      "learning_rate": 3.136464020612233e-05,
      "loss": 0.0516,
      "step": 85100
    },
    {
      "epoch": 5.973079080201907,
      "grad_norm": 0.24282774329185486,
      "learning_rate": 3.1342730945516055e-05,
      "loss": 0.0529,
      "step": 85200
    },
    {
      "epoch": 5.980089736399327,
      "grad_norm": 0.16311831772327423,
      "learning_rate": 3.132082168490978e-05,
      "loss": 0.0534,
      "step": 85300
    },
    {
      "epoch": 5.987100392596747,
      "grad_norm": 0.10848086327314377,
      "learning_rate": 3.129891242430351e-05,
      "loss": 0.0543,
      "step": 85400
    },
    {
      "epoch": 5.994111048794167,
      "grad_norm": 0.16914474964141846,
      "learning_rate": 3.1277003163697235e-05,
      "loss": 0.0489,
      "step": 85500
    },
    {
      "epoch": 6.0,
      "eval_accuracy_macro_0.5": 0.9782038331031799,
      "eval_accuracy_micro_0.5": 0.9782037734985352,
      "eval_accuracy_weighted_0.5": 0.967218816280365,
      "eval_aucroc_macro": 0.8661083579063416,
      "eval_aucroc_micro": 0.8858474493026733,
      "eval_aucroc_weighted": 0.8815516829490662,
      "eval_f1_macro_0.5": 0.6494053602218628,
      "eval_f1_macro_0.6": 0.6075440645217896,
      "eval_f1_macro_0.7": 0.5492530465126038,
      "eval_f1_macro_0.8": 0.32753539085388184,
      "eval_f1_micro_0.5": 0.699327826499939,
      "eval_f1_micro_0.6": 0.6686882376670837,
      "eval_f1_micro_0.7": 0.6207308769226074,
      "eval_f1_micro_0.8": 0.542054295539856,
      "eval_f1_micro_0.9": 0.39536333084106445,
      "eval_f1_weighted_0.5": 0.6852959394454956,
      "eval_f1_weighted_0.6": 0.6467229723930359,
      "eval_f1_weighted_0.7": 0.5884165167808533,
      "eval_f1_weighted_0.8": 0.35162174701690674,
      "eval_loss": 0.050132282078266144,
      "eval_runtime": 69.7976,
      "eval_samples_per_second": 407.951,
      "eval_steps_per_second": 51.005,
      "step": 85584
    },
    {
      "epoch": 6.001121704991587,
      "grad_norm": 0.1917044073343277,
      "learning_rate": 3.125509390309096e-05,
      "loss": 0.0504,
      "step": 85600
    },
    {
      "epoch": 6.008132361189007,
      "grad_norm": 0.0882156491279602,
      "learning_rate": 3.123318464248469e-05,
      "loss": 0.0504,
      "step": 85700
    },
    {
      "epoch": 6.0151430173864275,
      "grad_norm": 0.17711834609508514,
      "learning_rate": 3.1211275381878416e-05,
      "loss": 0.0534,
      "step": 85800
    },
    {
      "epoch": 6.022153673583848,
      "grad_norm": 0.22322848439216614,
      "learning_rate": 3.1189366121272137e-05,
      "loss": 0.0515,
      "step": 85900
    },
    {
      "epoch": 6.029164329781268,
      "grad_norm": 0.10697068274021149,
      "learning_rate": 3.1167456860665864e-05,
      "loss": 0.0516,
      "step": 86000
    },
    {
      "epoch": 6.036174985978688,
      "grad_norm": 0.10191003978252411,
      "learning_rate": 3.114554760005959e-05,
      "loss": 0.053,
      "step": 86100
    },
    {
      "epoch": 6.043185642176108,
      "grad_norm": 0.34838342666625977,
      "learning_rate": 3.112363833945332e-05,
      "loss": 0.0511,
      "step": 86200
    },
    {
      "epoch": 6.050196298373527,
      "grad_norm": 0.20083624124526978,
      "learning_rate": 3.110194817145311e-05,
      "loss": 0.0545,
      "step": 86300
    },
    {
      "epoch": 6.0572069545709475,
      "grad_norm": 0.10595286637544632,
      "learning_rate": 3.1080038910846835e-05,
      "loss": 0.0571,
      "step": 86400
    },
    {
      "epoch": 6.064217610768368,
      "grad_norm": 0.19195696711540222,
      "learning_rate": 3.105812965024056e-05,
      "loss": 0.048,
      "step": 86500
    },
    {
      "epoch": 6.071228266965788,
      "grad_norm": 0.1427905112504959,
      "learning_rate": 3.103622038963429e-05,
      "loss": 0.0512,
      "step": 86600
    },
    {
      "epoch": 6.078238923163208,
      "grad_norm": 0.2893253266811371,
      "learning_rate": 3.1014311129028016e-05,
      "loss": 0.0555,
      "step": 86700
    },
    {
      "epoch": 6.085249579360628,
      "grad_norm": 0.1418745368719101,
      "learning_rate": 3.099240186842174e-05,
      "loss": 0.0584,
      "step": 86800
    },
    {
      "epoch": 6.092260235558048,
      "grad_norm": 0.17347338795661926,
      "learning_rate": 3.097049260781547e-05,
      "loss": 0.0552,
      "step": 86900
    },
    {
      "epoch": 6.099270891755468,
      "grad_norm": 0.20346203446388245,
      "learning_rate": 3.09485833472092e-05,
      "loss": 0.0577,
      "step": 87000
    },
    {
      "epoch": 6.1062815479528885,
      "grad_norm": 0.1162736713886261,
      "learning_rate": 3.0926674086602924e-05,
      "loss": 0.0524,
      "step": 87100
    },
    {
      "epoch": 6.113292204150309,
      "grad_norm": 0.12489009648561478,
      "learning_rate": 3.090476482599665e-05,
      "loss": 0.0504,
      "step": 87200
    },
    {
      "epoch": 6.120302860347729,
      "grad_norm": 0.2198287844657898,
      "learning_rate": 3.088285556539038e-05,
      "loss": 0.0538,
      "step": 87300
    },
    {
      "epoch": 6.127313516545149,
      "grad_norm": 0.08917570859193802,
      "learning_rate": 3.0860946304784105e-05,
      "loss": 0.0545,
      "step": 87400
    },
    {
      "epoch": 6.134324172742569,
      "grad_norm": 0.1081552729010582,
      "learning_rate": 3.083903704417783e-05,
      "loss": 0.0472,
      "step": 87500
    },
    {
      "epoch": 6.141334828939989,
      "grad_norm": 0.09517046064138412,
      "learning_rate": 3.081712778357156e-05,
      "loss": 0.0536,
      "step": 87600
    },
    {
      "epoch": 6.148345485137408,
      "grad_norm": 0.3533194363117218,
      "learning_rate": 3.079521852296529e-05,
      "loss": 0.0621,
      "step": 87700
    },
    {
      "epoch": 6.155356141334829,
      "grad_norm": 0.1551789939403534,
      "learning_rate": 3.077330926235902e-05,
      "loss": 0.0539,
      "step": 87800
    },
    {
      "epoch": 6.162366797532249,
      "grad_norm": 0.25205981731414795,
      "learning_rate": 3.075140000175275e-05,
      "loss": 0.0525,
      "step": 87900
    },
    {
      "epoch": 6.169377453729669,
      "grad_norm": 0.20265354216098785,
      "learning_rate": 3.0729490741146474e-05,
      "loss": 0.0527,
      "step": 88000
    },
    {
      "epoch": 6.176388109927089,
      "grad_norm": 0.20437031984329224,
      "learning_rate": 3.07075814805402e-05,
      "loss": 0.0535,
      "step": 88100
    },
    {
      "epoch": 6.183398766124509,
      "grad_norm": 0.23817960917949677,
      "learning_rate": 3.068567221993393e-05,
      "loss": 0.054,
      "step": 88200
    },
    {
      "epoch": 6.190409422321929,
      "grad_norm": 0.2296718806028366,
      "learning_rate": 3.066398205193372e-05,
      "loss": 0.0564,
      "step": 88300
    },
    {
      "epoch": 6.197420078519349,
      "grad_norm": 0.13884998857975006,
      "learning_rate": 3.064207279132744e-05,
      "loss": 0.0522,
      "step": 88400
    },
    {
      "epoch": 6.2044307347167695,
      "grad_norm": 0.12225507199764252,
      "learning_rate": 3.0620163530721166e-05,
      "loss": 0.0508,
      "step": 88500
    },
    {
      "epoch": 6.21144139091419,
      "grad_norm": 0.12423858046531677,
      "learning_rate": 3.059825427011489e-05,
      "loss": 0.0556,
      "step": 88600
    },
    {
      "epoch": 6.21845204711161,
      "grad_norm": 0.16490116715431213,
      "learning_rate": 3.057634500950862e-05,
      "loss": 0.0551,
      "step": 88700
    },
    {
      "epoch": 6.22546270330903,
      "grad_norm": 0.13519111275672913,
      "learning_rate": 3.0554435748902346e-05,
      "loss": 0.0576,
      "step": 88800
    },
    {
      "epoch": 6.23247335950645,
      "grad_norm": 0.16787004470825195,
      "learning_rate": 3.0532526488296073e-05,
      "loss": 0.0511,
      "step": 88900
    },
    {
      "epoch": 6.23948401570387,
      "grad_norm": 0.14409634470939636,
      "learning_rate": 3.0510617227689804e-05,
      "loss": 0.0531,
      "step": 89000
    },
    {
      "epoch": 6.24649467190129,
      "grad_norm": 0.342620849609375,
      "learning_rate": 3.048870796708353e-05,
      "loss": 0.0495,
      "step": 89100
    },
    {
      "epoch": 6.25350532809871,
      "grad_norm": 0.1215643361210823,
      "learning_rate": 3.0466798706477258e-05,
      "loss": 0.0517,
      "step": 89200
    },
    {
      "epoch": 6.26051598429613,
      "grad_norm": 0.2367437332868576,
      "learning_rate": 3.0444889445870985e-05,
      "loss": 0.0512,
      "step": 89300
    },
    {
      "epoch": 6.26752664049355,
      "grad_norm": 0.12368964403867722,
      "learning_rate": 3.0422980185264712e-05,
      "loss": 0.0521,
      "step": 89400
    },
    {
      "epoch": 6.27453729669097,
      "grad_norm": 0.19356045126914978,
      "learning_rate": 3.0401070924658435e-05,
      "loss": 0.0541,
      "step": 89500
    },
    {
      "epoch": 6.28154795288839,
      "grad_norm": 0.15642724931240082,
      "learning_rate": 3.0379161664052162e-05,
      "loss": 0.0508,
      "step": 89600
    },
    {
      "epoch": 6.28855860908581,
      "grad_norm": 0.3359186053276062,
      "learning_rate": 3.035725240344589e-05,
      "loss": 0.0503,
      "step": 89700
    },
    {
      "epoch": 6.2955692652832305,
      "grad_norm": 0.14048032462596893,
      "learning_rate": 3.0335343142839616e-05,
      "loss": 0.054,
      "step": 89800
    },
    {
      "epoch": 6.302579921480651,
      "grad_norm": 0.3024374544620514,
      "learning_rate": 3.0313433882233343e-05,
      "loss": 0.0538,
      "step": 89900
    },
    {
      "epoch": 6.309590577678071,
      "grad_norm": 0.14009171724319458,
      "learning_rate": 3.029152462162707e-05,
      "loss": 0.0509,
      "step": 90000
    },
    {
      "epoch": 6.316601233875491,
      "grad_norm": 0.13893510401248932,
      "learning_rate": 3.0269615361020797e-05,
      "loss": 0.054,
      "step": 90100
    },
    {
      "epoch": 6.323611890072911,
      "grad_norm": 0.1680191606283188,
      "learning_rate": 3.0247706100414524e-05,
      "loss": 0.0536,
      "step": 90200
    },
    {
      "epoch": 6.330622546270331,
      "grad_norm": 0.5453340411186218,
      "learning_rate": 3.022579683980825e-05,
      "loss": 0.052,
      "step": 90300
    },
    {
      "epoch": 6.337633202467751,
      "grad_norm": 0.07441530376672745,
      "learning_rate": 3.0203887579201978e-05,
      "loss": 0.0509,
      "step": 90400
    },
    {
      "epoch": 6.344643858665171,
      "grad_norm": 0.17410942912101746,
      "learning_rate": 3.018219741120177e-05,
      "loss": 0.0534,
      "step": 90500
    },
    {
      "epoch": 6.351654514862592,
      "grad_norm": 0.2969922423362732,
      "learning_rate": 3.0160288150595496e-05,
      "loss": 0.0521,
      "step": 90600
    },
    {
      "epoch": 6.358665171060011,
      "grad_norm": 0.1996006965637207,
      "learning_rate": 3.0138378889989223e-05,
      "loss": 0.0522,
      "step": 90700
    },
    {
      "epoch": 6.365675827257431,
      "grad_norm": 0.09310472756624222,
      "learning_rate": 3.011646962938295e-05,
      "loss": 0.0557,
      "step": 90800
    },
    {
      "epoch": 6.372686483454851,
      "grad_norm": 0.18537287414073944,
      "learning_rate": 3.0094560368776677e-05,
      "loss": 0.0525,
      "step": 90900
    },
    {
      "epoch": 6.379697139652271,
      "grad_norm": 0.44994208216667175,
      "learning_rate": 3.0072651108170404e-05,
      "loss": 0.0512,
      "step": 91000
    },
    {
      "epoch": 6.386707795849691,
      "grad_norm": 0.11702637374401093,
      "learning_rate": 3.0050741847564127e-05,
      "loss": 0.0522,
      "step": 91100
    },
    {
      "epoch": 6.3937184520471115,
      "grad_norm": 0.12222754955291748,
      "learning_rate": 3.0028832586957854e-05,
      "loss": 0.0537,
      "step": 91200
    },
    {
      "epoch": 6.400729108244532,
      "grad_norm": 0.18112732470035553,
      "learning_rate": 3.000692332635158e-05,
      "loss": 0.0553,
      "step": 91300
    },
    {
      "epoch": 6.407739764441952,
      "grad_norm": 0.6642672419548035,
      "learning_rate": 2.9985014065745308e-05,
      "loss": 0.0531,
      "step": 91400
    },
    {
      "epoch": 6.414750420639372,
      "grad_norm": 0.11189260333776474,
      "learning_rate": 2.9963104805139035e-05,
      "loss": 0.0566,
      "step": 91500
    },
    {
      "epoch": 6.421761076836792,
      "grad_norm": 0.1390606313943863,
      "learning_rate": 2.9941195544532762e-05,
      "loss": 0.0535,
      "step": 91600
    },
    {
      "epoch": 6.428771733034212,
      "grad_norm": 0.15074244141578674,
      "learning_rate": 2.991928628392649e-05,
      "loss": 0.0514,
      "step": 91700
    },
    {
      "epoch": 6.435782389231632,
      "grad_norm": 0.33546334505081177,
      "learning_rate": 2.9897377023320216e-05,
      "loss": 0.0507,
      "step": 91800
    },
    {
      "epoch": 6.4427930454290525,
      "grad_norm": 0.2585238218307495,
      "learning_rate": 2.9875686855320007e-05,
      "loss": 0.0527,
      "step": 91900
    },
    {
      "epoch": 6.449803701626473,
      "grad_norm": 0.1535404473543167,
      "learning_rate": 2.9853777594713734e-05,
      "loss": 0.0548,
      "step": 92000
    },
    {
      "epoch": 6.456814357823892,
      "grad_norm": 0.30096206068992615,
      "learning_rate": 2.983186833410746e-05,
      "loss": 0.0557,
      "step": 92100
    },
    {
      "epoch": 6.463825014021312,
      "grad_norm": 0.1863749474287033,
      "learning_rate": 2.9809959073501188e-05,
      "loss": 0.0562,
      "step": 92200
    },
    {
      "epoch": 6.470835670218732,
      "grad_norm": 0.13239607214927673,
      "learning_rate": 2.9788049812894915e-05,
      "loss": 0.0491,
      "step": 92300
    },
    {
      "epoch": 6.477846326416152,
      "grad_norm": 0.15984848141670227,
      "learning_rate": 2.9766140552288642e-05,
      "loss": 0.0563,
      "step": 92400
    },
    {
      "epoch": 6.4848569826135725,
      "grad_norm": 0.18459364771842957,
      "learning_rate": 2.974423129168237e-05,
      "loss": 0.0548,
      "step": 92500
    },
    {
      "epoch": 6.491867638810993,
      "grad_norm": 0.10501746833324432,
      "learning_rate": 2.9722322031076096e-05,
      "loss": 0.0549,
      "step": 92600
    },
    {
      "epoch": 6.498878295008413,
      "grad_norm": 0.1408473700284958,
      "learning_rate": 2.970041277046982e-05,
      "loss": 0.0526,
      "step": 92700
    },
    {
      "epoch": 6.505888951205833,
      "grad_norm": 0.1997329145669937,
      "learning_rate": 2.9678503509863546e-05,
      "loss": 0.0505,
      "step": 92800
    },
    {
      "epoch": 6.512899607403253,
      "grad_norm": 0.1436382234096527,
      "learning_rate": 2.965659424925728e-05,
      "loss": 0.0511,
      "step": 92900
    },
    {
      "epoch": 6.519910263600673,
      "grad_norm": 0.05089496821165085,
      "learning_rate": 2.9634684988651007e-05,
      "loss": 0.0526,
      "step": 93000
    },
    {
      "epoch": 6.526920919798093,
      "grad_norm": 0.15475553274154663,
      "learning_rate": 2.9612775728044734e-05,
      "loss": 0.0487,
      "step": 93100
    },
    {
      "epoch": 6.533931575995513,
      "grad_norm": 0.28241318464279175,
      "learning_rate": 2.959086646743846e-05,
      "loss": 0.0555,
      "step": 93200
    },
    {
      "epoch": 6.540942232192934,
      "grad_norm": 0.44960522651672363,
      "learning_rate": 2.9568957206832188e-05,
      "loss": 0.0512,
      "step": 93300
    },
    {
      "epoch": 6.547952888390354,
      "grad_norm": 0.3814832866191864,
      "learning_rate": 2.9547047946225915e-05,
      "loss": 0.0525,
      "step": 93400
    },
    {
      "epoch": 6.554963544587773,
      "grad_norm": 0.2977047562599182,
      "learning_rate": 2.9525138685619642e-05,
      "loss": 0.059,
      "step": 93500
    },
    {
      "epoch": 6.561974200785193,
      "grad_norm": 0.327213853597641,
      "learning_rate": 2.950322942501337e-05,
      "loss": 0.057,
      "step": 93600
    },
    {
      "epoch": 6.568984856982613,
      "grad_norm": 0.20766755938529968,
      "learning_rate": 2.9481320164407096e-05,
      "loss": 0.0526,
      "step": 93700
    },
    {
      "epoch": 6.575995513180033,
      "grad_norm": 0.1290265917778015,
      "learning_rate": 2.9459410903800823e-05,
      "loss": 0.0523,
      "step": 93800
    },
    {
      "epoch": 6.5830061693774535,
      "grad_norm": 0.16752798855304718,
      "learning_rate": 2.943750164319455e-05,
      "loss": 0.0531,
      "step": 93900
    },
    {
      "epoch": 6.590016825574874,
      "grad_norm": 0.24400795996189117,
      "learning_rate": 2.9415592382588273e-05,
      "loss": 0.055,
      "step": 94000
    },
    {
      "epoch": 6.597027481772294,
      "grad_norm": 0.12573033571243286,
      "learning_rate": 2.9393683121982e-05,
      "loss": 0.0534,
      "step": 94100
    },
    {
      "epoch": 6.604038137969714,
      "grad_norm": 0.18260644376277924,
      "learning_rate": 2.9371773861375727e-05,
      "loss": 0.0563,
      "step": 94200
    },
    {
      "epoch": 6.611048794167134,
      "grad_norm": 0.22490093111991882,
      "learning_rate": 2.9349864600769454e-05,
      "loss": 0.0501,
      "step": 94300
    },
    {
      "epoch": 6.618059450364554,
      "grad_norm": 0.11770300567150116,
      "learning_rate": 2.932795534016318e-05,
      "loss": 0.0578,
      "step": 94400
    },
    {
      "epoch": 6.625070106561974,
      "grad_norm": 0.2974731922149658,
      "learning_rate": 2.930604607955691e-05,
      "loss": 0.0546,
      "step": 94500
    },
    {
      "epoch": 6.6320807627593945,
      "grad_norm": 0.5088627934455872,
      "learning_rate": 2.9284136818950635e-05,
      "loss": 0.0563,
      "step": 94600
    },
    {
      "epoch": 6.639091418956815,
      "grad_norm": 0.2880569398403168,
      "learning_rate": 2.9262227558344362e-05,
      "loss": 0.0503,
      "step": 94700
    },
    {
      "epoch": 6.646102075154235,
      "grad_norm": 0.11990490555763245,
      "learning_rate": 2.924031829773809e-05,
      "loss": 0.0555,
      "step": 94800
    },
    {
      "epoch": 6.653112731351655,
      "grad_norm": 0.3432314097881317,
      "learning_rate": 2.9218409037131816e-05,
      "loss": 0.0547,
      "step": 94900
    },
    {
      "epoch": 6.660123387549074,
      "grad_norm": 0.29744744300842285,
      "learning_rate": 2.9196499776525543e-05,
      "loss": 0.0516,
      "step": 95000
    },
    {
      "epoch": 6.667134043746494,
      "grad_norm": 0.17231011390686035,
      "learning_rate": 2.917459051591927e-05,
      "loss": 0.0545,
      "step": 95100
    },
    {
      "epoch": 6.6741446999439145,
      "grad_norm": 0.090521901845932,
      "learning_rate": 2.9152681255312997e-05,
      "loss": 0.0526,
      "step": 95200
    },
    {
      "epoch": 6.681155356141335,
      "grad_norm": 0.31786322593688965,
      "learning_rate": 2.9130771994706724e-05,
      "loss": 0.0564,
      "step": 95300
    },
    {
      "epoch": 6.688166012338755,
      "grad_norm": 0.10324081778526306,
      "learning_rate": 2.910886273410045e-05,
      "loss": 0.0528,
      "step": 95400
    },
    {
      "epoch": 6.695176668536175,
      "grad_norm": 0.5959085822105408,
      "learning_rate": 2.9086953473494178e-05,
      "loss": 0.0484,
      "step": 95500
    },
    {
      "epoch": 6.702187324733595,
      "grad_norm": 0.33059757947921753,
      "learning_rate": 2.906526330549397e-05,
      "loss": 0.0541,
      "step": 95600
    },
    {
      "epoch": 6.709197980931015,
      "grad_norm": 0.6247040033340454,
      "learning_rate": 2.9043354044887692e-05,
      "loss": 0.0556,
      "step": 95700
    },
    {
      "epoch": 6.716208637128435,
      "grad_norm": 0.23239091038703918,
      "learning_rate": 2.902144478428142e-05,
      "loss": 0.0558,
      "step": 95800
    },
    {
      "epoch": 6.723219293325855,
      "grad_norm": 0.3839839994907379,
      "learning_rate": 2.8999535523675146e-05,
      "loss": 0.0532,
      "step": 95900
    },
    {
      "epoch": 6.730229949523276,
      "grad_norm": 0.186754047870636,
      "learning_rate": 2.8977626263068873e-05,
      "loss": 0.0446,
      "step": 96000
    },
    {
      "epoch": 6.737240605720696,
      "grad_norm": 0.23838838934898376,
      "learning_rate": 2.89557170024626e-05,
      "loss": 0.0488,
      "step": 96100
    },
    {
      "epoch": 6.744251261918116,
      "grad_norm": 0.31025391817092896,
      "learning_rate": 2.8933807741856327e-05,
      "loss": 0.0513,
      "step": 96200
    },
    {
      "epoch": 6.751261918115536,
      "grad_norm": 0.18865184485912323,
      "learning_rate": 2.8911898481250054e-05,
      "loss": 0.0505,
      "step": 96300
    },
    {
      "epoch": 6.758272574312956,
      "grad_norm": 0.30681389570236206,
      "learning_rate": 2.888998922064378e-05,
      "loss": 0.051,
      "step": 96400
    },
    {
      "epoch": 6.765283230510375,
      "grad_norm": 0.27288222312927246,
      "learning_rate": 2.8868079960037508e-05,
      "loss": 0.0526,
      "step": 96500
    },
    {
      "epoch": 6.7722938867077955,
      "grad_norm": 0.15199454128742218,
      "learning_rate": 2.8846170699431235e-05,
      "loss": 0.0516,
      "step": 96600
    },
    {
      "epoch": 6.779304542905216,
      "grad_norm": 0.18872174620628357,
      "learning_rate": 2.8824261438824962e-05,
      "loss": 0.048,
      "step": 96700
    },
    {
      "epoch": 6.786315199102636,
      "grad_norm": 0.1859089434146881,
      "learning_rate": 2.880235217821869e-05,
      "loss": 0.0509,
      "step": 96800
    },
    {
      "epoch": 6.793325855300056,
      "grad_norm": 0.10242009907960892,
      "learning_rate": 2.8780442917612416e-05,
      "loss": 0.0539,
      "step": 96900
    },
    {
      "epoch": 6.800336511497476,
      "grad_norm": 0.14684559404850006,
      "learning_rate": 2.8758533657006143e-05,
      "loss": 0.0518,
      "step": 97000
    },
    {
      "epoch": 6.807347167694896,
      "grad_norm": 0.2044874131679535,
      "learning_rate": 2.873662439639987e-05,
      "loss": 0.0517,
      "step": 97100
    },
    {
      "epoch": 6.814357823892316,
      "grad_norm": 0.26809170842170715,
      "learning_rate": 2.8714715135793597e-05,
      "loss": 0.054,
      "step": 97200
    },
    {
      "epoch": 6.8213684800897365,
      "grad_norm": 0.10917969793081284,
      "learning_rate": 2.8692805875187324e-05,
      "loss": 0.0505,
      "step": 97300
    },
    {
      "epoch": 6.828379136287157,
      "grad_norm": 0.46369674801826477,
      "learning_rate": 2.867089661458105e-05,
      "loss": 0.0579,
      "step": 97400
    },
    {
      "epoch": 6.835389792484577,
      "grad_norm": 0.2981395423412323,
      "learning_rate": 2.864898735397478e-05,
      "loss": 0.0541,
      "step": 97500
    },
    {
      "epoch": 6.842400448681997,
      "grad_norm": 0.15443265438079834,
      "learning_rate": 2.862707809336851e-05,
      "loss": 0.0504,
      "step": 97600
    },
    {
      "epoch": 6.849411104879417,
      "grad_norm": 0.15370754897594452,
      "learning_rate": 2.8605168832762235e-05,
      "loss": 0.0513,
      "step": 97700
    },
    {
      "epoch": 6.856421761076836,
      "grad_norm": 0.15545836091041565,
      "learning_rate": 2.8583259572155962e-05,
      "loss": 0.0488,
      "step": 97800
    },
    {
      "epoch": 6.863432417274257,
      "grad_norm": 0.22103361785411835,
      "learning_rate": 2.856135031154969e-05,
      "loss": 0.0481,
      "step": 97900
    },
    {
      "epoch": 6.870443073471677,
      "grad_norm": 0.5901679992675781,
      "learning_rate": 2.8539441050943416e-05,
      "loss": 0.0573,
      "step": 98000
    },
    {
      "epoch": 6.877453729669097,
      "grad_norm": 0.08956322073936462,
      "learning_rate": 2.8517531790337143e-05,
      "loss": 0.0499,
      "step": 98100
    },
    {
      "epoch": 6.884464385866517,
      "grad_norm": 0.2834324836730957,
      "learning_rate": 2.849562252973087e-05,
      "loss": 0.0533,
      "step": 98200
    },
    {
      "epoch": 6.891475042063937,
      "grad_norm": 0.25387632846832275,
      "learning_rate": 2.8473713269124597e-05,
      "loss": 0.0528,
      "step": 98300
    },
    {
      "epoch": 6.898485698261357,
      "grad_norm": 0.27408531308174133,
      "learning_rate": 2.8451804008518324e-05,
      "loss": 0.055,
      "step": 98400
    },
    {
      "epoch": 6.905496354458777,
      "grad_norm": 0.16954252123832703,
      "learning_rate": 2.842989474791205e-05,
      "loss": 0.0551,
      "step": 98500
    },
    {
      "epoch": 6.912507010656197,
      "grad_norm": 0.41323745250701904,
      "learning_rate": 2.8407985487305778e-05,
      "loss": 0.0545,
      "step": 98600
    },
    {
      "epoch": 6.919517666853618,
      "grad_norm": 0.30921584367752075,
      "learning_rate": 2.8386076226699505e-05,
      "loss": 0.0513,
      "step": 98700
    },
    {
      "epoch": 6.926528323051038,
      "grad_norm": 0.13047902286052704,
      "learning_rate": 2.8364166966093232e-05,
      "loss": 0.053,
      "step": 98800
    },
    {
      "epoch": 6.933538979248458,
      "grad_norm": 0.12485955655574799,
      "learning_rate": 2.834225770548696e-05,
      "loss": 0.0498,
      "step": 98900
    },
    {
      "epoch": 6.940549635445878,
      "grad_norm": 0.14698068797588348,
      "learning_rate": 2.8320348444880683e-05,
      "loss": 0.0524,
      "step": 99000
    },
    {
      "epoch": 6.947560291643298,
      "grad_norm": 0.18138740956783295,
      "learning_rate": 2.829843918427441e-05,
      "loss": 0.0513,
      "step": 99100
    },
    {
      "epoch": 6.954570947840718,
      "grad_norm": 0.1730731576681137,
      "learning_rate": 2.8276529923668137e-05,
      "loss": 0.0531,
      "step": 99200
    },
    {
      "epoch": 6.9615816040381375,
      "grad_norm": 0.14498238265514374,
      "learning_rate": 2.8254620663061864e-05,
      "loss": 0.0525,
      "step": 99300
    },
    {
      "epoch": 6.968592260235558,
      "grad_norm": 0.19731822609901428,
      "learning_rate": 2.823271140245559e-05,
      "loss": 0.0555,
      "step": 99400
    },
    {
      "epoch": 6.975602916432978,
      "grad_norm": 0.10784030705690384,
      "learning_rate": 2.8210802141849318e-05,
      "loss": 0.0491,
      "step": 99500
    },
    {
      "epoch": 6.982613572630398,
      "grad_norm": 0.14580576121807098,
      "learning_rate": 2.8188892881243045e-05,
      "loss": 0.0582,
      "step": 99600
    },
    {
      "epoch": 6.989624228827818,
      "grad_norm": 0.09896691143512726,
      "learning_rate": 2.816698362063677e-05,
      "loss": 0.0539,
      "step": 99700
    },
    {
      "epoch": 6.996634885025238,
      "grad_norm": 0.18535113334655762,
      "learning_rate": 2.8145512545242626e-05,
      "loss": 0.054,
      "step": 99800
    },
    {
      "epoch": 7.0,
      "eval_accuracy_macro_0.5": 0.9785714149475098,
      "eval_accuracy_micro_0.5": 0.9785714745521545,
      "eval_accuracy_weighted_0.5": 0.9678898453712463,
      "eval_aucroc_macro": 0.8788628578186035,
      "eval_aucroc_micro": 0.8935030102729797,
      "eval_aucroc_weighted": 0.8893794417381287,
      "eval_f1_macro_0.5": 0.6667041778564453,
      "eval_f1_macro_0.6": 0.6330805420875549,
      "eval_f1_macro_0.7": 0.5770260691642761,
      "eval_f1_macro_0.8": 0.36383020877838135,
      "eval_f1_micro_0.5": 0.7100836038589478,
      "eval_f1_micro_0.6": 0.6856914758682251,
      "eval_f1_micro_0.7": 0.6406271457672119,
      "eval_f1_micro_0.8": 0.5701293349266052,
      "eval_f1_micro_0.9": 0.4275946319103241,
      "eval_f1_weighted_0.5": 0.6978585720062256,
      "eval_f1_weighted_0.6": 0.6659014821052551,
      "eval_f1_weighted_0.7": 0.6111389994621277,
      "eval_f1_weighted_0.8": 0.38533321022987366,
      "eval_loss": 0.049539998173713684,
      "eval_runtime": 69.0362,
      "eval_samples_per_second": 412.45,
      "eval_steps_per_second": 51.567,
      "step": 99848
    },
    {
      "epoch": 7.003645541222658,
      "grad_norm": 0.12346141040325165,
      "learning_rate": 2.8123603284636353e-05,
      "loss": 0.0556,
      "step": 99900
    },
    {
      "epoch": 7.0106561974200785,
      "grad_norm": 0.18141241371631622,
      "learning_rate": 2.810169402403008e-05,
      "loss": 0.0498,
      "step": 100000
    },
    {
      "epoch": 7.017666853617499,
      "grad_norm": 0.17655004560947418,
      "learning_rate": 2.8079784763423807e-05,
      "loss": 0.052,
      "step": 100100
    },
    {
      "epoch": 7.024677509814919,
      "grad_norm": 0.12896759808063507,
      "learning_rate": 2.805787550281753e-05,
      "loss": 0.0554,
      "step": 100200
    },
    {
      "epoch": 7.031688166012339,
      "grad_norm": 0.06764408200979233,
      "learning_rate": 2.8035966242211258e-05,
      "loss": 0.0494,
      "step": 100300
    },
    {
      "epoch": 7.038698822209759,
      "grad_norm": 0.1414017528295517,
      "learning_rate": 2.8014056981604985e-05,
      "loss": 0.0486,
      "step": 100400
    },
    {
      "epoch": 7.045709478407179,
      "grad_norm": 0.1456819623708725,
      "learning_rate": 2.799214772099871e-05,
      "loss": 0.0553,
      "step": 100500
    },
    {
      "epoch": 7.052720134604599,
      "grad_norm": 0.1616184264421463,
      "learning_rate": 2.797023846039244e-05,
      "loss": 0.0517,
      "step": 100600
    },
    {
      "epoch": 7.0597307908020195,
      "grad_norm": 0.46890613436698914,
      "learning_rate": 2.7948329199786165e-05,
      "loss": 0.054,
      "step": 100700
    },
    {
      "epoch": 7.066741446999439,
      "grad_norm": 0.20732669532299042,
      "learning_rate": 2.7926419939179892e-05,
      "loss": 0.0579,
      "step": 100800
    },
    {
      "epoch": 7.073752103196859,
      "grad_norm": 0.16706660389900208,
      "learning_rate": 2.790451067857362e-05,
      "loss": 0.0492,
      "step": 100900
    },
    {
      "epoch": 7.080762759394279,
      "grad_norm": 0.32727134227752686,
      "learning_rate": 2.7882601417967346e-05,
      "loss": 0.0587,
      "step": 101000
    },
    {
      "epoch": 7.087773415591699,
      "grad_norm": 0.1681305319070816,
      "learning_rate": 2.7860692157361073e-05,
      "loss": 0.0532,
      "step": 101100
    },
    {
      "epoch": 7.094784071789119,
      "grad_norm": 0.19643454253673553,
      "learning_rate": 2.78387828967548e-05,
      "loss": 0.0535,
      "step": 101200
    },
    {
      "epoch": 7.101794727986539,
      "grad_norm": 0.24849551916122437,
      "learning_rate": 2.7816873636148527e-05,
      "loss": 0.0531,
      "step": 101300
    },
    {
      "epoch": 7.10880538418396,
      "grad_norm": 0.16624361276626587,
      "learning_rate": 2.7794964375542254e-05,
      "loss": 0.0515,
      "step": 101400
    },
    {
      "epoch": 7.11581604038138,
      "grad_norm": 0.1533520221710205,
      "learning_rate": 2.777305511493598e-05,
      "loss": 0.0467,
      "step": 101500
    },
    {
      "epoch": 7.1228266965788,
      "grad_norm": 0.11903682351112366,
      "learning_rate": 2.7751145854329708e-05,
      "loss": 0.0525,
      "step": 101600
    },
    {
      "epoch": 7.12983735277622,
      "grad_norm": 0.18376311659812927,
      "learning_rate": 2.7729236593723435e-05,
      "loss": 0.0548,
      "step": 101700
    },
    {
      "epoch": 7.13684800897364,
      "grad_norm": 0.20410168170928955,
      "learning_rate": 2.7707327333117162e-05,
      "loss": 0.0534,
      "step": 101800
    },
    {
      "epoch": 7.14385866517106,
      "grad_norm": 0.26249268651008606,
      "learning_rate": 2.768541807251089e-05,
      "loss": 0.0533,
      "step": 101900
    },
    {
      "epoch": 7.15086932136848,
      "grad_norm": 0.304230272769928,
      "learning_rate": 2.7663508811904616e-05,
      "loss": 0.049,
      "step": 102000
    },
    {
      "epoch": 7.1578799775659006,
      "grad_norm": 0.2731930911540985,
      "learning_rate": 2.7641599551298343e-05,
      "loss": 0.0546,
      "step": 102100
    },
    {
      "epoch": 7.164890633763321,
      "grad_norm": 0.07460496574640274,
      "learning_rate": 2.761969029069207e-05,
      "loss": 0.0512,
      "step": 102200
    },
    {
      "epoch": 7.17190128996074,
      "grad_norm": 0.13993611931800842,
      "learning_rate": 2.7597781030085794e-05,
      "loss": 0.0512,
      "step": 102300
    },
    {
      "epoch": 7.17891194615816,
      "grad_norm": 0.24346433579921722,
      "learning_rate": 2.7575871769479527e-05,
      "loss": 0.052,
      "step": 102400
    },
    {
      "epoch": 7.18592260235558,
      "grad_norm": 0.13867342472076416,
      "learning_rate": 2.7553962508873254e-05,
      "loss": 0.0493,
      "step": 102500
    },
    {
      "epoch": 7.192933258553,
      "grad_norm": 0.08354847133159637,
      "learning_rate": 2.753205324826698e-05,
      "loss": 0.0536,
      "step": 102600
    },
    {
      "epoch": 7.1999439147504205,
      "grad_norm": 0.22569537162780762,
      "learning_rate": 2.751014398766071e-05,
      "loss": 0.0561,
      "step": 102700
    },
    {
      "epoch": 7.206954570947841,
      "grad_norm": 0.17021942138671875,
      "learning_rate": 2.7488234727054435e-05,
      "loss": 0.0526,
      "step": 102800
    },
    {
      "epoch": 7.213965227145261,
      "grad_norm": 0.2231254279613495,
      "learning_rate": 2.7466325466448162e-05,
      "loss": 0.0569,
      "step": 102900
    },
    {
      "epoch": 7.220975883342681,
      "grad_norm": 0.1378651261329651,
      "learning_rate": 2.744441620584189e-05,
      "loss": 0.053,
      "step": 103000
    },
    {
      "epoch": 7.227986539540101,
      "grad_norm": 0.1842857301235199,
      "learning_rate": 2.7422506945235616e-05,
      "loss": 0.055,
      "step": 103100
    },
    {
      "epoch": 7.234997195737521,
      "grad_norm": 0.1414804458618164,
      "learning_rate": 2.7400597684629343e-05,
      "loss": 0.053,
      "step": 103200
    },
    {
      "epoch": 7.242007851934941,
      "grad_norm": 0.11502468585968018,
      "learning_rate": 2.737868842402307e-05,
      "loss": 0.0524,
      "step": 103300
    },
    {
      "epoch": 7.2490185081323615,
      "grad_norm": 0.14188726246356964,
      "learning_rate": 2.7356779163416797e-05,
      "loss": 0.0514,
      "step": 103400
    },
    {
      "epoch": 7.256029164329782,
      "grad_norm": 0.16747967898845673,
      "learning_rate": 2.7334869902810524e-05,
      "loss": 0.0483,
      "step": 103500
    },
    {
      "epoch": 7.263039820527202,
      "grad_norm": 0.23562587797641754,
      "learning_rate": 2.7312960642204248e-05,
      "loss": 0.0501,
      "step": 103600
    },
    {
      "epoch": 7.270050476724621,
      "grad_norm": 0.07172372192144394,
      "learning_rate": 2.7291051381597975e-05,
      "loss": 0.0522,
      "step": 103700
    },
    {
      "epoch": 7.277061132922041,
      "grad_norm": 0.1225118413567543,
      "learning_rate": 2.7269142120991702e-05,
      "loss": 0.0524,
      "step": 103800
    },
    {
      "epoch": 7.284071789119461,
      "grad_norm": 0.20899027585983276,
      "learning_rate": 2.7247451952991493e-05,
      "loss": 0.0474,
      "step": 103900
    },
    {
      "epoch": 7.291082445316881,
      "grad_norm": 0.1827852874994278,
      "learning_rate": 2.722554269238522e-05,
      "loss": 0.054,
      "step": 104000
    },
    {
      "epoch": 7.298093101514302,
      "grad_norm": 0.17703241109848022,
      "learning_rate": 2.7203633431778946e-05,
      "loss": 0.0561,
      "step": 104100
    },
    {
      "epoch": 7.305103757711722,
      "grad_norm": 0.07474925369024277,
      "learning_rate": 2.7181724171172673e-05,
      "loss": 0.0548,
      "step": 104200
    },
    {
      "epoch": 7.312114413909142,
      "grad_norm": 0.150098517537117,
      "learning_rate": 2.71598149105664e-05,
      "loss": 0.0508,
      "step": 104300
    },
    {
      "epoch": 7.319125070106562,
      "grad_norm": 0.11664813756942749,
      "learning_rate": 2.7137905649960127e-05,
      "loss": 0.0532,
      "step": 104400
    },
    {
      "epoch": 7.326135726303982,
      "grad_norm": 0.17416693270206451,
      "learning_rate": 2.7115996389353854e-05,
      "loss": 0.0532,
      "step": 104500
    },
    {
      "epoch": 7.333146382501402,
      "grad_norm": 0.11710096150636673,
      "learning_rate": 2.709408712874758e-05,
      "loss": 0.0486,
      "step": 104600
    },
    {
      "epoch": 7.340157038698822,
      "grad_norm": 0.11821003258228302,
      "learning_rate": 2.707217786814131e-05,
      "loss": 0.0525,
      "step": 104700
    },
    {
      "epoch": 7.3471676948962426,
      "grad_norm": 0.165858656167984,
      "learning_rate": 2.7050268607535035e-05,
      "loss": 0.054,
      "step": 104800
    },
    {
      "epoch": 7.354178351093663,
      "grad_norm": 0.12166833877563477,
      "learning_rate": 2.7028359346928762e-05,
      "loss": 0.0497,
      "step": 104900
    },
    {
      "epoch": 7.361189007291083,
      "grad_norm": 0.12708963453769684,
      "learning_rate": 2.700645008632249e-05,
      "loss": 0.0552,
      "step": 105000
    },
    {
      "epoch": 7.368199663488502,
      "grad_norm": 0.3330715596675873,
      "learning_rate": 2.6984540825716216e-05,
      "loss": 0.0544,
      "step": 105100
    },
    {
      "epoch": 7.375210319685922,
      "grad_norm": 0.22034922242164612,
      "learning_rate": 2.696263156510994e-05,
      "loss": 0.0497,
      "step": 105200
    },
    {
      "epoch": 7.382220975883342,
      "grad_norm": 0.13460688292980194,
      "learning_rate": 2.6940722304503667e-05,
      "loss": 0.0543,
      "step": 105300
    },
    {
      "epoch": 7.3892316320807625,
      "grad_norm": 0.22548671066761017,
      "learning_rate": 2.6918813043897394e-05,
      "loss": 0.0484,
      "step": 105400
    },
    {
      "epoch": 7.396242288278183,
      "grad_norm": 0.08835619688034058,
      "learning_rate": 2.689690378329112e-05,
      "loss": 0.0496,
      "step": 105500
    },
    {
      "epoch": 7.403252944475603,
      "grad_norm": 0.16049085557460785,
      "learning_rate": 2.6874994522684848e-05,
      "loss": 0.0516,
      "step": 105600
    },
    {
      "epoch": 7.410263600673023,
      "grad_norm": 0.27086907625198364,
      "learning_rate": 2.6853085262078575e-05,
      "loss": 0.0497,
      "step": 105700
    },
    {
      "epoch": 7.417274256870443,
      "grad_norm": 0.1284562200307846,
      "learning_rate": 2.6831395094078365e-05,
      "loss": 0.0539,
      "step": 105800
    },
    {
      "epoch": 7.424284913067863,
      "grad_norm": 0.17431701719760895,
      "learning_rate": 2.6809485833472092e-05,
      "loss": 0.0548,
      "step": 105900
    },
    {
      "epoch": 7.431295569265283,
      "grad_norm": 0.18924959003925323,
      "learning_rate": 2.678757657286582e-05,
      "loss": 0.0533,
      "step": 106000
    },
    {
      "epoch": 7.4383062254627035,
      "grad_norm": 0.08015646785497665,
      "learning_rate": 2.6765667312259546e-05,
      "loss": 0.0518,
      "step": 106100
    },
    {
      "epoch": 7.445316881660124,
      "grad_norm": 0.1969958394765854,
      "learning_rate": 2.6743758051653273e-05,
      "loss": 0.0556,
      "step": 106200
    },
    {
      "epoch": 7.452327537857544,
      "grad_norm": 0.329860121011734,
      "learning_rate": 2.6721848791047e-05,
      "loss": 0.054,
      "step": 106300
    },
    {
      "epoch": 7.459338194054964,
      "grad_norm": 0.20337338745594025,
      "learning_rate": 2.6699939530440727e-05,
      "loss": 0.0445,
      "step": 106400
    },
    {
      "epoch": 7.466348850252384,
      "grad_norm": 0.17757390439510345,
      "learning_rate": 2.6678030269834454e-05,
      "loss": 0.0521,
      "step": 106500
    },
    {
      "epoch": 7.473359506449803,
      "grad_norm": 0.1761433482170105,
      "learning_rate": 2.665612100922818e-05,
      "loss": 0.0534,
      "step": 106600
    },
    {
      "epoch": 7.480370162647223,
      "grad_norm": 0.15926681458950043,
      "learning_rate": 2.6634211748621908e-05,
      "loss": 0.0509,
      "step": 106700
    },
    {
      "epoch": 7.487380818844644,
      "grad_norm": 0.12190404534339905,
      "learning_rate": 2.6612302488015632e-05,
      "loss": 0.0516,
      "step": 106800
    },
    {
      "epoch": 7.494391475042064,
      "grad_norm": 0.10003605484962463,
      "learning_rate": 2.659039322740936e-05,
      "loss": 0.0517,
      "step": 106900
    },
    {
      "epoch": 7.501402131239484,
      "grad_norm": 0.3918862044811249,
      "learning_rate": 2.6568483966803086e-05,
      "loss": 0.0491,
      "step": 107000
    },
    {
      "epoch": 7.508412787436904,
      "grad_norm": 0.11786915361881256,
      "learning_rate": 2.6546574706196813e-05,
      "loss": 0.0574,
      "step": 107100
    },
    {
      "epoch": 7.515423443634324,
      "grad_norm": 0.24363236129283905,
      "learning_rate": 2.652466544559054e-05,
      "loss": 0.0519,
      "step": 107200
    },
    {
      "epoch": 7.522434099831744,
      "grad_norm": 0.14306522905826569,
      "learning_rate": 2.6502756184984274e-05,
      "loss": 0.0511,
      "step": 107300
    },
    {
      "epoch": 7.529444756029164,
      "grad_norm": 0.07265578210353851,
      "learning_rate": 2.6480846924378e-05,
      "loss": 0.0509,
      "step": 107400
    },
    {
      "epoch": 7.5364554122265845,
      "grad_norm": 0.17891241610050201,
      "learning_rate": 2.6458937663771727e-05,
      "loss": 0.0523,
      "step": 107500
    },
    {
      "epoch": 7.543466068424005,
      "grad_norm": 0.12420148402452469,
      "learning_rate": 2.6437028403165454e-05,
      "loss": 0.0527,
      "step": 107600
    },
    {
      "epoch": 7.550476724621425,
      "grad_norm": 0.055088598281145096,
      "learning_rate": 2.641511914255918e-05,
      "loss": 0.0533,
      "step": 107700
    },
    {
      "epoch": 7.557487380818845,
      "grad_norm": 0.14988785982131958,
      "learning_rate": 2.639320988195291e-05,
      "loss": 0.0533,
      "step": 107800
    },
    {
      "epoch": 7.564498037016265,
      "grad_norm": 0.3002856373786926,
      "learning_rate": 2.6371300621346635e-05,
      "loss": 0.054,
      "step": 107900
    },
    {
      "epoch": 7.571508693213685,
      "grad_norm": 0.2962796092033386,
      "learning_rate": 2.6349391360740362e-05,
      "loss": 0.0514,
      "step": 108000
    },
    {
      "epoch": 7.5785193494111045,
      "grad_norm": 0.10574883967638016,
      "learning_rate": 2.632748210013409e-05,
      "loss": 0.0497,
      "step": 108100
    },
    {
      "epoch": 7.585530005608525,
      "grad_norm": 0.1083981916308403,
      "learning_rate": 2.6305572839527813e-05,
      "loss": 0.0488,
      "step": 108200
    },
    {
      "epoch": 7.592540661805945,
      "grad_norm": 0.35442060232162476,
      "learning_rate": 2.628366357892154e-05,
      "loss": 0.0539,
      "step": 108300
    },
    {
      "epoch": 7.599551318003365,
      "grad_norm": 0.15136075019836426,
      "learning_rate": 2.6261754318315267e-05,
      "loss": 0.0505,
      "step": 108400
    },
    {
      "epoch": 7.606561974200785,
      "grad_norm": 0.1261788010597229,
      "learning_rate": 2.6239845057708994e-05,
      "loss": 0.0503,
      "step": 108500
    },
    {
      "epoch": 7.613572630398205,
      "grad_norm": 0.3022693991661072,
      "learning_rate": 2.621793579710272e-05,
      "loss": 0.0538,
      "step": 108600
    },
    {
      "epoch": 7.620583286595625,
      "grad_norm": 0.3305271863937378,
      "learning_rate": 2.6196026536496448e-05,
      "loss": 0.049,
      "step": 108700
    },
    {
      "epoch": 7.6275939427930455,
      "grad_norm": 0.19803284108638763,
      "learning_rate": 2.6174117275890175e-05,
      "loss": 0.0507,
      "step": 108800
    },
    {
      "epoch": 7.634604598990466,
      "grad_norm": 0.08295145630836487,
      "learning_rate": 2.6152208015283902e-05,
      "loss": 0.0525,
      "step": 108900
    },
    {
      "epoch": 7.641615255187886,
      "grad_norm": 0.1252274364233017,
      "learning_rate": 2.613029875467763e-05,
      "loss": 0.0488,
      "step": 109000
    },
    {
      "epoch": 7.648625911385306,
      "grad_norm": 0.1283065378665924,
      "learning_rate": 2.6108389494071356e-05,
      "loss": 0.0513,
      "step": 109100
    },
    {
      "epoch": 7.655636567582726,
      "grad_norm": 0.17484433948993683,
      "learning_rate": 2.6086480233465083e-05,
      "loss": 0.0568,
      "step": 109200
    },
    {
      "epoch": 7.662647223780146,
      "grad_norm": 0.1641448736190796,
      "learning_rate": 2.606457097285881e-05,
      "loss": 0.0527,
      "step": 109300
    },
    {
      "epoch": 7.669657879977565,
      "grad_norm": 0.11374417692422867,
      "learning_rate": 2.6042661712252537e-05,
      "loss": 0.0514,
      "step": 109400
    },
    {
      "epoch": 7.6766685361749865,
      "grad_norm": 0.23553533852100372,
      "learning_rate": 2.6020752451646264e-05,
      "loss": 0.0521,
      "step": 109500
    },
    {
      "epoch": 7.683679192372406,
      "grad_norm": 0.15501031279563904,
      "learning_rate": 2.599884319103999e-05,
      "loss": 0.0515,
      "step": 109600
    },
    {
      "epoch": 7.690689848569826,
      "grad_norm": 0.1358402669429779,
      "learning_rate": 2.5976933930433718e-05,
      "loss": 0.0503,
      "step": 109700
    },
    {
      "epoch": 7.697700504767246,
      "grad_norm": 0.16762150824069977,
      "learning_rate": 2.5955243762433505e-05,
      "loss": 0.0535,
      "step": 109800
    },
    {
      "epoch": 7.704711160964666,
      "grad_norm": 0.34228619933128357,
      "learning_rate": 2.5933334501827232e-05,
      "loss": 0.0541,
      "step": 109900
    },
    {
      "epoch": 7.711721817162086,
      "grad_norm": 0.16068464517593384,
      "learning_rate": 2.591142524122096e-05,
      "loss": 0.0547,
      "step": 110000
    },
    {
      "epoch": 7.718732473359506,
      "grad_norm": 0.1397082656621933,
      "learning_rate": 2.5889515980614686e-05,
      "loss": 0.0508,
      "step": 110100
    },
    {
      "epoch": 7.7257431295569265,
      "grad_norm": 0.07926397770643234,
      "learning_rate": 2.5867606720008413e-05,
      "loss": 0.0558,
      "step": 110200
    },
    {
      "epoch": 7.732753785754347,
      "grad_norm": 0.1729537546634674,
      "learning_rate": 2.584569745940214e-05,
      "loss": 0.0502,
      "step": 110300
    },
    {
      "epoch": 7.739764441951767,
      "grad_norm": 0.14133669435977936,
      "learning_rate": 2.5823788198795867e-05,
      "loss": 0.0539,
      "step": 110400
    },
    {
      "epoch": 7.746775098149187,
      "grad_norm": 0.18677988648414612,
      "learning_rate": 2.5801878938189594e-05,
      "loss": 0.0511,
      "step": 110500
    },
    {
      "epoch": 7.753785754346607,
      "grad_norm": 0.20409728586673737,
      "learning_rate": 2.577996967758332e-05,
      "loss": 0.0513,
      "step": 110600
    },
    {
      "epoch": 7.760796410544027,
      "grad_norm": 0.20266757905483246,
      "learning_rate": 2.5758060416977048e-05,
      "loss": 0.0502,
      "step": 110700
    },
    {
      "epoch": 7.767807066741447,
      "grad_norm": 0.09305105358362198,
      "learning_rate": 2.5736151156370775e-05,
      "loss": 0.053,
      "step": 110800
    },
    {
      "epoch": 7.774817722938867,
      "grad_norm": 0.1590430736541748,
      "learning_rate": 2.5714241895764502e-05,
      "loss": 0.049,
      "step": 110900
    },
    {
      "epoch": 7.781828379136287,
      "grad_norm": 0.16558748483657837,
      "learning_rate": 2.569233263515823e-05,
      "loss": 0.0506,
      "step": 111000
    },
    {
      "epoch": 7.788839035333707,
      "grad_norm": 0.27908188104629517,
      "learning_rate": 2.5670423374551956e-05,
      "loss": 0.0492,
      "step": 111100
    },
    {
      "epoch": 7.795849691531127,
      "grad_norm": 0.18097957968711853,
      "learning_rate": 2.5648514113945683e-05,
      "loss": 0.0531,
      "step": 111200
    },
    {
      "epoch": 7.802860347728547,
      "grad_norm": 0.1799725592136383,
      "learning_rate": 2.562660485333941e-05,
      "loss": 0.0534,
      "step": 111300
    },
    {
      "epoch": 7.809871003925967,
      "grad_norm": 0.23001696169376373,
      "learning_rate": 2.5604695592733137e-05,
      "loss": 0.0513,
      "step": 111400
    },
    {
      "epoch": 7.8168816601233875,
      "grad_norm": 0.12267474830150604,
      "learning_rate": 2.5582786332126864e-05,
      "loss": 0.0542,
      "step": 111500
    },
    {
      "epoch": 7.823892316320808,
      "grad_norm": 0.1996004283428192,
      "learning_rate": 2.556087707152059e-05,
      "loss": 0.0542,
      "step": 111600
    },
    {
      "epoch": 7.830902972518228,
      "grad_norm": 0.2514938414096832,
      "learning_rate": 2.5538967810914318e-05,
      "loss": 0.0523,
      "step": 111700
    },
    {
      "epoch": 7.837913628715648,
      "grad_norm": 0.352517306804657,
      "learning_rate": 2.5517277642914105e-05,
      "loss": 0.0532,
      "step": 111800
    },
    {
      "epoch": 7.844924284913068,
      "grad_norm": 0.10304547101259232,
      "learning_rate": 2.5495368382307832e-05,
      "loss": 0.0492,
      "step": 111900
    },
    {
      "epoch": 7.851934941110488,
      "grad_norm": 0.15916889905929565,
      "learning_rate": 2.547345912170156e-05,
      "loss": 0.0483,
      "step": 112000
    },
    {
      "epoch": 7.858945597307908,
      "grad_norm": 0.3202473819255829,
      "learning_rate": 2.5451549861095286e-05,
      "loss": 0.0531,
      "step": 112100
    },
    {
      "epoch": 7.8659562535053285,
      "grad_norm": 0.3818967640399933,
      "learning_rate": 2.542964060048902e-05,
      "loss": 0.0508,
      "step": 112200
    },
    {
      "epoch": 7.872966909702749,
      "grad_norm": 0.22352871298789978,
      "learning_rate": 2.5407731339882747e-05,
      "loss": 0.0524,
      "step": 112300
    },
    {
      "epoch": 7.879977565900168,
      "grad_norm": 0.18883724510669708,
      "learning_rate": 2.5385822079276474e-05,
      "loss": 0.0486,
      "step": 112400
    },
    {
      "epoch": 7.886988222097588,
      "grad_norm": 0.1549595296382904,
      "learning_rate": 2.53639128186702e-05,
      "loss": 0.0539,
      "step": 112500
    },
    {
      "epoch": 7.893998878295008,
      "grad_norm": 0.12527067959308624,
      "learning_rate": 2.5342003558063927e-05,
      "loss": 0.0515,
      "step": 112600
    },
    {
      "epoch": 7.901009534492428,
      "grad_norm": 0.17880122363567352,
      "learning_rate": 2.532009429745765e-05,
      "loss": 0.0544,
      "step": 112700
    },
    {
      "epoch": 7.908020190689848,
      "grad_norm": 0.2756365239620209,
      "learning_rate": 2.5298185036851378e-05,
      "loss": 0.0528,
      "step": 112800
    },
    {
      "epoch": 7.9150308468872685,
      "grad_norm": 0.20616458356380463,
      "learning_rate": 2.5276275776245105e-05,
      "loss": 0.0497,
      "step": 112900
    },
    {
      "epoch": 7.922041503084689,
      "grad_norm": 0.06486742943525314,
      "learning_rate": 2.5254366515638832e-05,
      "loss": 0.0504,
      "step": 113000
    },
    {
      "epoch": 7.929052159282109,
      "grad_norm": 0.1902388334274292,
      "learning_rate": 2.523245725503256e-05,
      "loss": 0.053,
      "step": 113100
    },
    {
      "epoch": 7.936062815479529,
      "grad_norm": 0.2752077281475067,
      "learning_rate": 2.5210547994426286e-05,
      "loss": 0.0547,
      "step": 113200
    },
    {
      "epoch": 7.943073471676949,
      "grad_norm": 0.1494876742362976,
      "learning_rate": 2.5188638733820013e-05,
      "loss": 0.053,
      "step": 113300
    },
    {
      "epoch": 7.950084127874369,
      "grad_norm": 0.19286882877349854,
      "learning_rate": 2.516672947321374e-05,
      "loss": 0.0519,
      "step": 113400
    },
    {
      "epoch": 7.957094784071789,
      "grad_norm": 0.1386723667383194,
      "learning_rate": 2.5144820212607467e-05,
      "loss": 0.0475,
      "step": 113500
    },
    {
      "epoch": 7.9641054402692095,
      "grad_norm": 0.06131845712661743,
      "learning_rate": 2.5122910952001194e-05,
      "loss": 0.0544,
      "step": 113600
    },
    {
      "epoch": 7.97111609646663,
      "grad_norm": 0.3461475968360901,
      "learning_rate": 2.510100169139492e-05,
      "loss": 0.0516,
      "step": 113700
    },
    {
      "epoch": 7.97812675266405,
      "grad_norm": 0.1950383484363556,
      "learning_rate": 2.5079092430788648e-05,
      "loss": 0.0511,
      "step": 113800
    },
    {
      "epoch": 7.985137408861469,
      "grad_norm": 0.09204570949077606,
      "learning_rate": 2.505740226278844e-05,
      "loss": 0.0532,
      "step": 113900
    },
    {
      "epoch": 7.992148065058889,
      "grad_norm": 0.245087131857872,
      "learning_rate": 2.5035493002182166e-05,
      "loss": 0.0543,
      "step": 114000
    },
    {
      "epoch": 7.999158721256309,
      "grad_norm": 0.22798965871334076,
      "learning_rate": 2.5013583741575893e-05,
      "loss": 0.0504,
      "step": 114100
    },
    {
      "epoch": 8.0,
      "eval_accuracy_macro_0.5": 0.9789445996284485,
      "eval_accuracy_micro_0.5": 0.9789445996284485,
      "eval_accuracy_weighted_0.5": 0.9685022234916687,
      "eval_aucroc_macro": 0.8813766241073608,
      "eval_aucroc_micro": 0.8938611149787903,
      "eval_aucroc_weighted": 0.8900349140167236,
      "eval_f1_macro_0.5": 0.6746484041213989,
      "eval_f1_macro_0.6": 0.6407485604286194,
      "eval_f1_macro_0.7": 0.5860205888748169,
      "eval_f1_macro_0.8": 0.37356820702552795,
      "eval_f1_micro_0.5": 0.7134043574333191,
      "eval_f1_micro_0.6": 0.6872371435165405,
      "eval_f1_micro_0.7": 0.6428115367889404,
      "eval_f1_micro_0.8": 0.5704013109207153,
      "eval_f1_micro_0.9": 0.429616242647171,
      "eval_f1_weighted_0.5": 0.7022451162338257,
      "eval_f1_weighted_0.6": 0.6685727834701538,
      "eval_f1_weighted_0.7": 0.6143329739570618,
      "eval_f1_weighted_0.8": 0.387400358915329,
      "eval_loss": 0.04876510426402092,
      "eval_runtime": 69.044,
      "eval_samples_per_second": 412.403,
      "eval_steps_per_second": 51.561,
      "step": 114112
    },
    {
      "epoch": 8.00616937745373,
      "grad_norm": 0.2287532538175583,
      "learning_rate": 2.499167448096962e-05,
      "loss": 0.051,
      "step": 114200
    },
    {
      "epoch": 8.01318003365115,
      "grad_norm": 0.35655176639556885,
      "learning_rate": 2.4969765220363343e-05,
      "loss": 0.0522,
      "step": 114300
    },
    {
      "epoch": 8.02019068984857,
      "grad_norm": 0.2895797789096832,
      "learning_rate": 2.494785595975707e-05,
      "loss": 0.0513,
      "step": 114400
    },
    {
      "epoch": 8.02720134604599,
      "grad_norm": 0.16048136353492737,
      "learning_rate": 2.4925946699150797e-05,
      "loss": 0.0503,
      "step": 114500
    },
    {
      "epoch": 8.03421200224341,
      "grad_norm": 0.15860265493392944,
      "learning_rate": 2.4904037438544524e-05,
      "loss": 0.0501,
      "step": 114600
    },
    {
      "epoch": 8.04122265844083,
      "grad_norm": 0.36295369267463684,
      "learning_rate": 2.488212817793825e-05,
      "loss": 0.0528,
      "step": 114700
    },
    {
      "epoch": 8.04823331463825,
      "grad_norm": 0.13629338145256042,
      "learning_rate": 2.4860218917331978e-05,
      "loss": 0.0527,
      "step": 114800
    },
    {
      "epoch": 8.05524397083567,
      "grad_norm": 0.3565431535243988,
      "learning_rate": 2.4838309656725705e-05,
      "loss": 0.0476,
      "step": 114900
    },
    {
      "epoch": 8.06225462703309,
      "grad_norm": 0.22474493086338043,
      "learning_rate": 2.4816400396119432e-05,
      "loss": 0.0512,
      "step": 115000
    },
    {
      "epoch": 8.06926528323051,
      "grad_norm": 0.35347509384155273,
      "learning_rate": 2.479449113551316e-05,
      "loss": 0.0531,
      "step": 115100
    },
    {
      "epoch": 8.07627593942793,
      "grad_norm": 0.174810990691185,
      "learning_rate": 2.4772581874906886e-05,
      "loss": 0.0482,
      "step": 115200
    },
    {
      "epoch": 8.083286595625351,
      "grad_norm": 0.17901648581027985,
      "learning_rate": 2.4750891706906677e-05,
      "loss": 0.0499,
      "step": 115300
    },
    {
      "epoch": 8.09029725182277,
      "grad_norm": 0.2713775634765625,
      "learning_rate": 2.4728982446300404e-05,
      "loss": 0.0513,
      "step": 115400
    },
    {
      "epoch": 8.097307908020191,
      "grad_norm": 0.22204504907131195,
      "learning_rate": 2.470707318569413e-05,
      "loss": 0.0513,
      "step": 115500
    },
    {
      "epoch": 8.10431856421761,
      "grad_norm": 0.1461426317691803,
      "learning_rate": 2.4685163925087858e-05,
      "loss": 0.0537,
      "step": 115600
    },
    {
      "epoch": 8.111329220415032,
      "grad_norm": 0.25928062200546265,
      "learning_rate": 2.4663254664481585e-05,
      "loss": 0.0557,
      "step": 115700
    },
    {
      "epoch": 8.11833987661245,
      "grad_norm": 0.22674083709716797,
      "learning_rate": 2.464134540387531e-05,
      "loss": 0.0514,
      "step": 115800
    },
    {
      "epoch": 8.125350532809872,
      "grad_norm": 0.36681780219078064,
      "learning_rate": 2.461943614326904e-05,
      "loss": 0.0494,
      "step": 115900
    },
    {
      "epoch": 8.132361189007291,
      "grad_norm": 0.3436838984489441,
      "learning_rate": 2.4597526882662765e-05,
      "loss": 0.0497,
      "step": 116000
    },
    {
      "epoch": 8.13937184520471,
      "grad_norm": 0.15587589144706726,
      "learning_rate": 2.4575617622056492e-05,
      "loss": 0.0503,
      "step": 116100
    },
    {
      "epoch": 8.146382501402131,
      "grad_norm": 0.31828317046165466,
      "learning_rate": 2.455370836145022e-05,
      "loss": 0.0538,
      "step": 116200
    },
    {
      "epoch": 8.15339315759955,
      "grad_norm": 0.20194163918495178,
      "learning_rate": 2.4531799100843946e-05,
      "loss": 0.0524,
      "step": 116300
    },
    {
      "epoch": 8.160403813796972,
      "grad_norm": 0.26901575922966003,
      "learning_rate": 2.4509889840237673e-05,
      "loss": 0.0537,
      "step": 116400
    },
    {
      "epoch": 8.167414469994391,
      "grad_norm": 0.29119202494621277,
      "learning_rate": 2.44879805796314e-05,
      "loss": 0.0497,
      "step": 116500
    },
    {
      "epoch": 8.174425126191812,
      "grad_norm": 0.20812420547008514,
      "learning_rate": 2.4466071319025127e-05,
      "loss": 0.0543,
      "step": 116600
    },
    {
      "epoch": 8.181435782389231,
      "grad_norm": 0.1639799326658249,
      "learning_rate": 2.4444162058418854e-05,
      "loss": 0.049,
      "step": 116700
    },
    {
      "epoch": 8.188446438586652,
      "grad_norm": 0.2262367159128189,
      "learning_rate": 2.442225279781258e-05,
      "loss": 0.0521,
      "step": 116800
    },
    {
      "epoch": 8.195457094784071,
      "grad_norm": 0.3356115520000458,
      "learning_rate": 2.4400343537206308e-05,
      "loss": 0.0494,
      "step": 116900
    },
    {
      "epoch": 8.202467750981493,
      "grad_norm": 0.155498668551445,
      "learning_rate": 2.4378434276600035e-05,
      "loss": 0.0539,
      "step": 117000
    },
    {
      "epoch": 8.209478407178912,
      "grad_norm": 0.14715714752674103,
      "learning_rate": 2.4356525015993762e-05,
      "loss": 0.0493,
      "step": 117100
    },
    {
      "epoch": 8.216489063376333,
      "grad_norm": 0.3049304187297821,
      "learning_rate": 2.433461575538749e-05,
      "loss": 0.0545,
      "step": 117200
    },
    {
      "epoch": 8.223499719573752,
      "grad_norm": 0.19907395541667938,
      "learning_rate": 2.4312706494781216e-05,
      "loss": 0.0501,
      "step": 117300
    },
    {
      "epoch": 8.230510375771171,
      "grad_norm": 0.5492250323295593,
      "learning_rate": 2.4290797234174943e-05,
      "loss": 0.05,
      "step": 117400
    },
    {
      "epoch": 8.237521031968592,
      "grad_norm": 0.37285134196281433,
      "learning_rate": 2.426910706617473e-05,
      "loss": 0.0509,
      "step": 117500
    },
    {
      "epoch": 8.244531688166012,
      "grad_norm": 0.23705163598060608,
      "learning_rate": 2.4247197805568457e-05,
      "loss": 0.0557,
      "step": 117600
    },
    {
      "epoch": 8.251542344363433,
      "grad_norm": 0.236234650015831,
      "learning_rate": 2.4225288544962184e-05,
      "loss": 0.0501,
      "step": 117700
    },
    {
      "epoch": 8.258553000560852,
      "grad_norm": 0.28014588356018066,
      "learning_rate": 2.420337928435591e-05,
      "loss": 0.0523,
      "step": 117800
    },
    {
      "epoch": 8.265563656758273,
      "grad_norm": 0.3025255799293518,
      "learning_rate": 2.418147002374964e-05,
      "loss": 0.0506,
      "step": 117900
    },
    {
      "epoch": 8.272574312955692,
      "grad_norm": 0.1832984983921051,
      "learning_rate": 2.4159560763143365e-05,
      "loss": 0.0527,
      "step": 118000
    },
    {
      "epoch": 8.279584969153113,
      "grad_norm": 0.2650495171546936,
      "learning_rate": 2.4137651502537092e-05,
      "loss": 0.051,
      "step": 118100
    },
    {
      "epoch": 8.286595625350532,
      "grad_norm": 0.5525243878364563,
      "learning_rate": 2.411574224193082e-05,
      "loss": 0.0563,
      "step": 118200
    },
    {
      "epoch": 8.293606281547953,
      "grad_norm": 0.34233298897743225,
      "learning_rate": 2.4093832981324546e-05,
      "loss": 0.0519,
      "step": 118300
    },
    {
      "epoch": 8.300616937745373,
      "grad_norm": 0.3667818009853363,
      "learning_rate": 2.4071923720718277e-05,
      "loss": 0.0519,
      "step": 118400
    },
    {
      "epoch": 8.307627593942794,
      "grad_norm": 0.383905291557312,
      "learning_rate": 2.4050014460112004e-05,
      "loss": 0.0533,
      "step": 118500
    },
    {
      "epoch": 8.314638250140213,
      "grad_norm": 0.3146478533744812,
      "learning_rate": 2.402810519950573e-05,
      "loss": 0.0517,
      "step": 118600
    },
    {
      "epoch": 8.321648906337634,
      "grad_norm": 0.28352707624435425,
      "learning_rate": 2.4006195938899458e-05,
      "loss": 0.0539,
      "step": 118700
    },
    {
      "epoch": 8.328659562535053,
      "grad_norm": 0.20637668669223785,
      "learning_rate": 2.3984286678293185e-05,
      "loss": 0.0506,
      "step": 118800
    },
    {
      "epoch": 8.335670218732474,
      "grad_norm": 0.14432114362716675,
      "learning_rate": 2.3962377417686908e-05,
      "loss": 0.0523,
      "step": 118900
    },
    {
      "epoch": 8.342680874929894,
      "grad_norm": 0.29573455452919006,
      "learning_rate": 2.3940468157080635e-05,
      "loss": 0.0516,
      "step": 119000
    },
    {
      "epoch": 8.349691531127313,
      "grad_norm": 0.1906556785106659,
      "learning_rate": 2.3918558896474362e-05,
      "loss": 0.0494,
      "step": 119100
    },
    {
      "epoch": 8.356702187324734,
      "grad_norm": 0.2635960578918457,
      "learning_rate": 2.389664963586809e-05,
      "loss": 0.0527,
      "step": 119200
    },
    {
      "epoch": 8.363712843522153,
      "grad_norm": 0.17668665945529938,
      "learning_rate": 2.3874740375261816e-05,
      "loss": 0.0546,
      "step": 119300
    },
    {
      "epoch": 8.370723499719574,
      "grad_norm": 0.14113162457942963,
      "learning_rate": 2.3852831114655543e-05,
      "loss": 0.0513,
      "step": 119400
    },
    {
      "epoch": 8.377734155916993,
      "grad_norm": 0.19053064286708832,
      "learning_rate": 2.383092185404927e-05,
      "loss": 0.0507,
      "step": 119500
    },
    {
      "epoch": 8.384744812114414,
      "grad_norm": 0.1768670231103897,
      "learning_rate": 2.3809012593442997e-05,
      "loss": 0.0481,
      "step": 119600
    },
    {
      "epoch": 8.391755468311834,
      "grad_norm": 0.43394535779953003,
      "learning_rate": 2.3787103332836724e-05,
      "loss": 0.0511,
      "step": 119700
    },
    {
      "epoch": 8.398766124509255,
      "grad_norm": 0.17798246443271637,
      "learning_rate": 2.376519407223045e-05,
      "loss": 0.0509,
      "step": 119800
    },
    {
      "epoch": 8.405776780706674,
      "grad_norm": 0.23189455270767212,
      "learning_rate": 2.3743284811624178e-05,
      "loss": 0.0563,
      "step": 119900
    },
    {
      "epoch": 8.412787436904095,
      "grad_norm": 0.20669598877429962,
      "learning_rate": 2.3721375551017905e-05,
      "loss": 0.0542,
      "step": 120000
    },
    {
      "epoch": 8.419798093101514,
      "grad_norm": 0.23807241022586823,
      "learning_rate": 2.3699466290411632e-05,
      "loss": 0.0478,
      "step": 120100
    },
    {
      "epoch": 8.426808749298935,
      "grad_norm": 0.24777305126190186,
      "learning_rate": 2.367755702980536e-05,
      "loss": 0.0513,
      "step": 120200
    },
    {
      "epoch": 8.433819405496354,
      "grad_norm": 0.23241981863975525,
      "learning_rate": 2.3655647769199086e-05,
      "loss": 0.0501,
      "step": 120300
    },
    {
      "epoch": 8.440830061693774,
      "grad_norm": 0.22101646661758423,
      "learning_rate": 2.3633738508592813e-05,
      "loss": 0.0513,
      "step": 120400
    },
    {
      "epoch": 8.447840717891195,
      "grad_norm": 0.06399644166231155,
      "learning_rate": 2.361182924798654e-05,
      "loss": 0.0473,
      "step": 120500
    },
    {
      "epoch": 8.454851374088614,
      "grad_norm": 0.1098209023475647,
      "learning_rate": 2.3589919987380267e-05,
      "loss": 0.0501,
      "step": 120600
    },
    {
      "epoch": 8.461862030286035,
      "grad_norm": 0.3747127652168274,
      "learning_rate": 2.3568010726773994e-05,
      "loss": 0.0499,
      "step": 120700
    },
    {
      "epoch": 8.468872686483454,
      "grad_norm": 0.09229843318462372,
      "learning_rate": 2.354610146616772e-05,
      "loss": 0.0515,
      "step": 120800
    },
    {
      "epoch": 8.475883342680875,
      "grad_norm": 0.24905647337436676,
      "learning_rate": 2.3524192205561448e-05,
      "loss": 0.0466,
      "step": 120900
    },
    {
      "epoch": 8.482893998878295,
      "grad_norm": 0.19458246231079102,
      "learning_rate": 2.3502282944955175e-05,
      "loss": 0.0505,
      "step": 121000
    },
    {
      "epoch": 8.489904655075716,
      "grad_norm": 0.21325092017650604,
      "learning_rate": 2.3480373684348902e-05,
      "loss": 0.0518,
      "step": 121100
    },
    {
      "epoch": 8.496915311273135,
      "grad_norm": 0.156839057803154,
      "learning_rate": 2.345846442374263e-05,
      "loss": 0.0552,
      "step": 121200
    },
    {
      "epoch": 8.503925967470556,
      "grad_norm": 0.2995513081550598,
      "learning_rate": 2.3436555163136356e-05,
      "loss": 0.0534,
      "step": 121300
    },
    {
      "epoch": 8.510936623667975,
      "grad_norm": 0.40370434522628784,
      "learning_rate": 2.3414645902530083e-05,
      "loss": 0.0504,
      "step": 121400
    },
    {
      "epoch": 8.517947279865396,
      "grad_norm": 0.1851864904165268,
      "learning_rate": 2.339273664192381e-05,
      "loss": 0.0525,
      "step": 121500
    },
    {
      "epoch": 8.524957936062815,
      "grad_norm": 0.17961165308952332,
      "learning_rate": 2.3371265566529664e-05,
      "loss": 0.0535,
      "step": 121600
    },
    {
      "epoch": 8.531968592260235,
      "grad_norm": 0.20648892223834991,
      "learning_rate": 2.334935630592339e-05,
      "loss": 0.053,
      "step": 121700
    },
    {
      "epoch": 8.538979248457656,
      "grad_norm": 0.24694320559501648,
      "learning_rate": 2.3327447045317115e-05,
      "loss": 0.0535,
      "step": 121800
    },
    {
      "epoch": 8.545989904655075,
      "grad_norm": 0.13328473269939423,
      "learning_rate": 2.330553778471084e-05,
      "loss": 0.049,
      "step": 121900
    },
    {
      "epoch": 8.553000560852496,
      "grad_norm": 0.14410847425460815,
      "learning_rate": 2.328362852410457e-05,
      "loss": 0.0488,
      "step": 122000
    },
    {
      "epoch": 8.560011217049915,
      "grad_norm": 0.1802033632993698,
      "learning_rate": 2.3261719263498296e-05,
      "loss": 0.048,
      "step": 122100
    },
    {
      "epoch": 8.567021873247336,
      "grad_norm": 0.34025707840919495,
      "learning_rate": 2.3239810002892023e-05,
      "loss": 0.0513,
      "step": 122200
    },
    {
      "epoch": 8.574032529444755,
      "grad_norm": 0.1921686977148056,
      "learning_rate": 2.321790074228575e-05,
      "loss": 0.0504,
      "step": 122300
    },
    {
      "epoch": 8.581043185642176,
      "grad_norm": 0.24069173634052277,
      "learning_rate": 2.3195991481679477e-05,
      "loss": 0.0484,
      "step": 122400
    },
    {
      "epoch": 8.588053841839596,
      "grad_norm": 0.12530608475208282,
      "learning_rate": 2.3174082221073204e-05,
      "loss": 0.0495,
      "step": 122500
    },
    {
      "epoch": 8.595064498037017,
      "grad_norm": 0.1265818476676941,
      "learning_rate": 2.315217296046693e-05,
      "loss": 0.0516,
      "step": 122600
    },
    {
      "epoch": 8.602075154234436,
      "grad_norm": 0.3419656753540039,
      "learning_rate": 2.3130263699860657e-05,
      "loss": 0.0515,
      "step": 122700
    },
    {
      "epoch": 8.609085810431857,
      "grad_norm": 0.3234710395336151,
      "learning_rate": 2.3108354439254384e-05,
      "loss": 0.0541,
      "step": 122800
    },
    {
      "epoch": 8.616096466629276,
      "grad_norm": 0.2864623963832855,
      "learning_rate": 2.308644517864811e-05,
      "loss": 0.051,
      "step": 122900
    },
    {
      "epoch": 8.623107122826697,
      "grad_norm": 0.2546202540397644,
      "learning_rate": 2.306453591804184e-05,
      "loss": 0.0521,
      "step": 123000
    },
    {
      "epoch": 8.630117779024117,
      "grad_norm": 0.16994915902614594,
      "learning_rate": 2.3042626657435565e-05,
      "loss": 0.0503,
      "step": 123100
    },
    {
      "epoch": 8.637128435221538,
      "grad_norm": 0.29910460114479065,
      "learning_rate": 2.3020717396829292e-05,
      "loss": 0.0503,
      "step": 123200
    },
    {
      "epoch": 8.644139091418957,
      "grad_norm": 0.1820032298564911,
      "learning_rate": 2.2998808136223023e-05,
      "loss": 0.0467,
      "step": 123300
    },
    {
      "epoch": 8.651149747616376,
      "grad_norm": 0.2573532462120056,
      "learning_rate": 2.297689887561675e-05,
      "loss": 0.055,
      "step": 123400
    },
    {
      "epoch": 8.658160403813797,
      "grad_norm": 0.21282148361206055,
      "learning_rate": 2.2954989615010473e-05,
      "loss": 0.0515,
      "step": 123500
    },
    {
      "epoch": 8.665171060011216,
      "grad_norm": 0.33509889245033264,
      "learning_rate": 2.29330803544042e-05,
      "loss": 0.0511,
      "step": 123600
    },
    {
      "epoch": 8.672181716208637,
      "grad_norm": 0.14155343174934387,
      "learning_rate": 2.2911171093797927e-05,
      "loss": 0.054,
      "step": 123700
    },
    {
      "epoch": 8.679192372406057,
      "grad_norm": 0.18160030245780945,
      "learning_rate": 2.2889261833191654e-05,
      "loss": 0.0539,
      "step": 123800
    },
    {
      "epoch": 8.686203028603478,
      "grad_norm": 0.28065118193626404,
      "learning_rate": 2.286735257258538e-05,
      "loss": 0.0533,
      "step": 123900
    },
    {
      "epoch": 8.693213684800897,
      "grad_norm": 0.2574155330657959,
      "learning_rate": 2.2845443311979108e-05,
      "loss": 0.0529,
      "step": 124000
    },
    {
      "epoch": 8.700224340998318,
      "grad_norm": 0.1578568071126938,
      "learning_rate": 2.2823534051372835e-05,
      "loss": 0.0545,
      "step": 124100
    },
    {
      "epoch": 8.707234997195737,
      "grad_norm": 0.22693608701229095,
      "learning_rate": 2.2801624790766562e-05,
      "loss": 0.052,
      "step": 124200
    },
    {
      "epoch": 8.714245653393158,
      "grad_norm": 0.27616778016090393,
      "learning_rate": 2.277971553016029e-05,
      "loss": 0.0503,
      "step": 124300
    },
    {
      "epoch": 8.721256309590578,
      "grad_norm": 0.2658858597278595,
      "learning_rate": 2.2757806269554016e-05,
      "loss": 0.0463,
      "step": 124400
    },
    {
      "epoch": 8.728266965787999,
      "grad_norm": 0.25490236282348633,
      "learning_rate": 2.2736116101553807e-05,
      "loss": 0.0535,
      "step": 124500
    },
    {
      "epoch": 8.735277621985418,
      "grad_norm": 0.4334064722061157,
      "learning_rate": 2.2714206840947534e-05,
      "loss": 0.0502,
      "step": 124600
    },
    {
      "epoch": 8.742288278182837,
      "grad_norm": 0.16292886435985565,
      "learning_rate": 2.269229758034126e-05,
      "loss": 0.0529,
      "step": 124700
    },
    {
      "epoch": 8.749298934380258,
      "grad_norm": 0.3216364085674286,
      "learning_rate": 2.2670388319734988e-05,
      "loss": 0.0506,
      "step": 124800
    },
    {
      "epoch": 8.756309590577677,
      "grad_norm": 0.17222729325294495,
      "learning_rate": 2.2648479059128715e-05,
      "loss": 0.0527,
      "step": 124900
    },
    {
      "epoch": 8.763320246775098,
      "grad_norm": 0.1963011771440506,
      "learning_rate": 2.2626569798522442e-05,
      "loss": 0.0514,
      "step": 125000
    },
    {
      "epoch": 8.770330902972518,
      "grad_norm": 0.38051989674568176,
      "learning_rate": 2.2604660537916165e-05,
      "loss": 0.0506,
      "step": 125100
    },
    {
      "epoch": 8.777341559169939,
      "grad_norm": 0.16198576986789703,
      "learning_rate": 2.2582751277309892e-05,
      "loss": 0.0525,
      "step": 125200
    },
    {
      "epoch": 8.784352215367358,
      "grad_norm": 0.28011488914489746,
      "learning_rate": 2.256084201670362e-05,
      "loss": 0.0497,
      "step": 125300
    },
    {
      "epoch": 8.791362871564779,
      "grad_norm": 0.2404913455247879,
      "learning_rate": 2.2538932756097346e-05,
      "loss": 0.0518,
      "step": 125400
    },
    {
      "epoch": 8.798373527762198,
      "grad_norm": 0.14129988849163055,
      "learning_rate": 2.2517023495491073e-05,
      "loss": 0.0531,
      "step": 125500
    },
    {
      "epoch": 8.80538418395962,
      "grad_norm": 0.2743588984012604,
      "learning_rate": 2.24951142348848e-05,
      "loss": 0.0474,
      "step": 125600
    },
    {
      "epoch": 8.812394840157038,
      "grad_norm": 0.1650862991809845,
      "learning_rate": 2.2473204974278527e-05,
      "loss": 0.0533,
      "step": 125700
    },
    {
      "epoch": 8.81940549635446,
      "grad_norm": 0.13263848423957825,
      "learning_rate": 2.2451295713672258e-05,
      "loss": 0.0541,
      "step": 125800
    },
    {
      "epoch": 8.826416152551879,
      "grad_norm": 0.27305588126182556,
      "learning_rate": 2.2429386453065985e-05,
      "loss": 0.0523,
      "step": 125900
    },
    {
      "epoch": 8.8334268087493,
      "grad_norm": 0.15819843113422394,
      "learning_rate": 2.240747719245971e-05,
      "loss": 0.0534,
      "step": 126000
    },
    {
      "epoch": 8.840437464946719,
      "grad_norm": 0.2045813351869583,
      "learning_rate": 2.238556793185344e-05,
      "loss": 0.0545,
      "step": 126100
    },
    {
      "epoch": 8.84744812114414,
      "grad_norm": 0.2712583839893341,
      "learning_rate": 2.2363658671247165e-05,
      "loss": 0.0488,
      "step": 126200
    },
    {
      "epoch": 8.85445877734156,
      "grad_norm": 0.3209379315376282,
      "learning_rate": 2.2341749410640892e-05,
      "loss": 0.0475,
      "step": 126300
    },
    {
      "epoch": 8.861469433538979,
      "grad_norm": 0.1092708557844162,
      "learning_rate": 2.231984015003462e-05,
      "loss": 0.0524,
      "step": 126400
    },
    {
      "epoch": 8.8684800897364,
      "grad_norm": 0.23439720273017883,
      "learning_rate": 2.2297930889428346e-05,
      "loss": 0.0507,
      "step": 126500
    },
    {
      "epoch": 8.875490745933819,
      "grad_norm": 0.22159619629383087,
      "learning_rate": 2.2276021628822073e-05,
      "loss": 0.0541,
      "step": 126600
    },
    {
      "epoch": 8.88250140213124,
      "grad_norm": 0.42268723249435425,
      "learning_rate": 2.22541123682158e-05,
      "loss": 0.0549,
      "step": 126700
    },
    {
      "epoch": 8.889512058328659,
      "grad_norm": 0.17224536836147308,
      "learning_rate": 2.2232203107609524e-05,
      "loss": 0.0496,
      "step": 126800
    },
    {
      "epoch": 8.89652271452608,
      "grad_norm": 0.5462920665740967,
      "learning_rate": 2.221029384700325e-05,
      "loss": 0.0508,
      "step": 126900
    },
    {
      "epoch": 8.9035333707235,
      "grad_norm": 0.29542243480682373,
      "learning_rate": 2.2188384586396978e-05,
      "loss": 0.0554,
      "step": 127000
    },
    {
      "epoch": 8.91054402692092,
      "grad_norm": 0.15128400921821594,
      "learning_rate": 2.2166475325790705e-05,
      "loss": 0.0492,
      "step": 127100
    },
    {
      "epoch": 8.91755468311834,
      "grad_norm": 0.11597088724374771,
      "learning_rate": 2.2144566065184432e-05,
      "loss": 0.0511,
      "step": 127200
    },
    {
      "epoch": 8.92456533931576,
      "grad_norm": 0.35340049862861633,
      "learning_rate": 2.2122875897184223e-05,
      "loss": 0.0538,
      "step": 127300
    },
    {
      "epoch": 8.93157599551318,
      "grad_norm": 0.45226356387138367,
      "learning_rate": 2.210096663657795e-05,
      "loss": 0.0512,
      "step": 127400
    },
    {
      "epoch": 8.938586651710601,
      "grad_norm": 0.3664572238922119,
      "learning_rate": 2.2079057375971677e-05,
      "loss": 0.0504,
      "step": 127500
    },
    {
      "epoch": 8.94559730790802,
      "grad_norm": 0.20614327490329742,
      "learning_rate": 2.2057148115365404e-05,
      "loss": 0.0521,
      "step": 127600
    },
    {
      "epoch": 8.95260796410544,
      "grad_norm": 0.12181957811117172,
      "learning_rate": 2.203523885475913e-05,
      "loss": 0.0516,
      "step": 127700
    },
    {
      "epoch": 8.95961862030286,
      "grad_norm": 0.21879422664642334,
      "learning_rate": 2.2013329594152857e-05,
      "loss": 0.0483,
      "step": 127800
    },
    {
      "epoch": 8.96662927650028,
      "grad_norm": 0.29810088872909546,
      "learning_rate": 2.1991420333546584e-05,
      "loss": 0.0489,
      "step": 127900
    },
    {
      "epoch": 8.9736399326977,
      "grad_norm": 0.20758101344108582,
      "learning_rate": 2.196951107294031e-05,
      "loss": 0.0517,
      "step": 128000
    },
    {
      "epoch": 8.98065058889512,
      "grad_norm": 0.31555166840553284,
      "learning_rate": 2.194760181233404e-05,
      "loss": 0.0551,
      "step": 128100
    },
    {
      "epoch": 8.987661245092541,
      "grad_norm": 0.14557194709777832,
      "learning_rate": 2.1925692551727765e-05,
      "loss": 0.0548,
      "step": 128200
    },
    {
      "epoch": 8.99467190128996,
      "grad_norm": 0.18135777115821838,
      "learning_rate": 2.1903783291121492e-05,
      "loss": 0.0511,
      "step": 128300
    },
    {
      "epoch": 9.0,
      "eval_accuracy_macro_0.5": 0.9791300892829895,
      "eval_accuracy_micro_0.5": 0.9791300892829895,
      "eval_accuracy_weighted_0.5": 0.968757688999176,
      "eval_aucroc_macro": 0.8807744383811951,
      "eval_aucroc_micro": 0.8952708840370178,
      "eval_aucroc_weighted": 0.891381561756134,
      "eval_f1_macro_0.5": 0.6777517199516296,
      "eval_f1_macro_0.6": 0.6445661187171936,
      "eval_f1_macro_0.7": 0.5939624309539795,
      "eval_f1_macro_0.8": 0.38069456815719604,
      "eval_f1_micro_0.5": 0.7175198197364807,
      "eval_f1_micro_0.6": 0.6924046277999878,
      "eval_f1_micro_0.7": 0.6495577096939087,
      "eval_f1_micro_0.8": 0.5788905620574951,
      "eval_f1_micro_0.9": 0.43792203068733215,
      "eval_f1_weighted_0.5": 0.7074134349822998,
      "eval_f1_weighted_0.6": 0.6753079891204834,
      "eval_f1_weighted_0.7": 0.6244914531707764,
      "eval_f1_weighted_0.8": 0.3958813548088074,
      "eval_loss": 0.047883033752441406,
      "eval_runtime": 68.3806,
      "eval_samples_per_second": 416.405,
      "eval_steps_per_second": 52.062,
      "step": 128376
    },
    {
      "epoch": 9.001682557487381,
      "grad_norm": 0.608613133430481,
      "learning_rate": 2.188187403051522e-05,
      "loss": 0.05,
      "step": 128400
    },
    {
      "epoch": 9.0086932136848,
      "grad_norm": 0.2949915826320648,
      "learning_rate": 2.1859964769908946e-05,
      "loss": 0.053,
      "step": 128500
    },
    {
      "epoch": 9.015703869882222,
      "grad_norm": 0.11129768937826157,
      "learning_rate": 2.1838055509302673e-05,
      "loss": 0.0474,
      "step": 128600
    },
    {
      "epoch": 9.02271452607964,
      "grad_norm": 0.20647740364074707,
      "learning_rate": 2.18161462486964e-05,
      "loss": 0.0463,
      "step": 128700
    },
    {
      "epoch": 9.029725182277062,
      "grad_norm": 0.18823237717151642,
      "learning_rate": 2.1794236988090127e-05,
      "loss": 0.0511,
      "step": 128800
    },
    {
      "epoch": 9.036735838474481,
      "grad_norm": 0.1296764612197876,
      "learning_rate": 2.1772327727483854e-05,
      "loss": 0.053,
      "step": 128900
    },
    {
      "epoch": 9.043746494671902,
      "grad_norm": 0.3502441346645355,
      "learning_rate": 2.175041846687758e-05,
      "loss": 0.0543,
      "step": 129000
    },
    {
      "epoch": 9.050757150869321,
      "grad_norm": 0.27705249190330505,
      "learning_rate": 2.1728509206271308e-05,
      "loss": 0.0468,
      "step": 129100
    },
    {
      "epoch": 9.05776780706674,
      "grad_norm": 0.14574086666107178,
      "learning_rate": 2.1706599945665035e-05,
      "loss": 0.0518,
      "step": 129200
    },
    {
      "epoch": 9.064778463264162,
      "grad_norm": 0.3630327880382538,
      "learning_rate": 2.1684690685058762e-05,
      "loss": 0.0479,
      "step": 129300
    },
    {
      "epoch": 9.071789119461581,
      "grad_norm": 0.1708013266324997,
      "learning_rate": 2.166278142445249e-05,
      "loss": 0.0489,
      "step": 129400
    },
    {
      "epoch": 9.078799775659002,
      "grad_norm": 0.35246148705482483,
      "learning_rate": 2.1640872163846216e-05,
      "loss": 0.054,
      "step": 129500
    },
    {
      "epoch": 9.085810431856421,
      "grad_norm": 0.18748807907104492,
      "learning_rate": 2.1618962903239943e-05,
      "loss": 0.0521,
      "step": 129600
    },
    {
      "epoch": 9.092821088053842,
      "grad_norm": 0.22953999042510986,
      "learning_rate": 2.159705364263367e-05,
      "loss": 0.0484,
      "step": 129700
    },
    {
      "epoch": 9.099831744251262,
      "grad_norm": 0.35329538583755493,
      "learning_rate": 2.1575144382027397e-05,
      "loss": 0.0541,
      "step": 129800
    },
    {
      "epoch": 9.106842400448683,
      "grad_norm": 0.15287041664123535,
      "learning_rate": 2.1553235121421124e-05,
      "loss": 0.0484,
      "step": 129900
    },
    {
      "epoch": 9.113853056646102,
      "grad_norm": 0.1858995258808136,
      "learning_rate": 2.153132586081485e-05,
      "loss": 0.0469,
      "step": 130000
    },
    {
      "epoch": 9.120863712843523,
      "grad_norm": 0.3144398331642151,
      "learning_rate": 2.1509416600208575e-05,
      "loss": 0.0518,
      "step": 130100
    },
    {
      "epoch": 9.127874369040942,
      "grad_norm": 0.13016806542873383,
      "learning_rate": 2.14875073396023e-05,
      "loss": 0.0511,
      "step": 130200
    },
    {
      "epoch": 9.134885025238363,
      "grad_norm": 0.23635315895080566,
      "learning_rate": 2.146559807899603e-05,
      "loss": 0.0483,
      "step": 130300
    },
    {
      "epoch": 9.141895681435782,
      "grad_norm": 0.11895651370286942,
      "learning_rate": 2.1443688818389756e-05,
      "loss": 0.0545,
      "step": 130400
    },
    {
      "epoch": 9.148906337633202,
      "grad_norm": 0.18189752101898193,
      "learning_rate": 2.1421779557783486e-05,
      "loss": 0.0506,
      "step": 130500
    },
    {
      "epoch": 9.155916993830623,
      "grad_norm": 0.10032311826944351,
      "learning_rate": 2.1399870297177213e-05,
      "loss": 0.0512,
      "step": 130600
    },
    {
      "epoch": 9.162927650028042,
      "grad_norm": 0.23611249029636383,
      "learning_rate": 2.137796103657094e-05,
      "loss": 0.0517,
      "step": 130700
    },
    {
      "epoch": 9.169938306225463,
      "grad_norm": 0.1963052749633789,
      "learning_rate": 2.1356051775964667e-05,
      "loss": 0.0516,
      "step": 130800
    },
    {
      "epoch": 9.176948962422882,
      "grad_norm": 0.11236964166164398,
      "learning_rate": 2.1334142515358394e-05,
      "loss": 0.0542,
      "step": 130900
    },
    {
      "epoch": 9.183959618620303,
      "grad_norm": 0.11887829750776291,
      "learning_rate": 2.131223325475212e-05,
      "loss": 0.0502,
      "step": 131000
    },
    {
      "epoch": 9.190970274817722,
      "grad_norm": 0.17336492240428925,
      "learning_rate": 2.1290323994145848e-05,
      "loss": 0.0522,
      "step": 131100
    },
    {
      "epoch": 9.197980931015143,
      "grad_norm": 0.15561866760253906,
      "learning_rate": 2.1268414733539575e-05,
      "loss": 0.052,
      "step": 131200
    },
    {
      "epoch": 9.204991587212563,
      "grad_norm": 0.1449926495552063,
      "learning_rate": 2.1246724565539362e-05,
      "loss": 0.0504,
      "step": 131300
    },
    {
      "epoch": 9.212002243409984,
      "grad_norm": 0.1223813071846962,
      "learning_rate": 2.122481530493309e-05,
      "loss": 0.0534,
      "step": 131400
    },
    {
      "epoch": 9.219012899607403,
      "grad_norm": 0.2799915373325348,
      "learning_rate": 2.1202906044326816e-05,
      "loss": 0.0505,
      "step": 131500
    },
    {
      "epoch": 9.226023555804824,
      "grad_norm": 0.19781120121479034,
      "learning_rate": 2.1180996783720543e-05,
      "loss": 0.0511,
      "step": 131600
    },
    {
      "epoch": 9.233034212002243,
      "grad_norm": 0.15095698833465576,
      "learning_rate": 2.115908752311427e-05,
      "loss": 0.0492,
      "step": 131700
    },
    {
      "epoch": 9.240044868199664,
      "grad_norm": 0.14958152174949646,
      "learning_rate": 2.1137178262507997e-05,
      "loss": 0.0468,
      "step": 131800
    },
    {
      "epoch": 9.247055524397084,
      "grad_norm": 0.169059619307518,
      "learning_rate": 2.1115269001901724e-05,
      "loss": 0.0503,
      "step": 131900
    },
    {
      "epoch": 9.254066180594503,
      "grad_norm": 0.13312000036239624,
      "learning_rate": 2.109335974129545e-05,
      "loss": 0.0513,
      "step": 132000
    },
    {
      "epoch": 9.261076836791924,
      "grad_norm": 0.12760469317436218,
      "learning_rate": 2.107166957329524e-05,
      "loss": 0.0486,
      "step": 132100
    },
    {
      "epoch": 9.268087492989343,
      "grad_norm": 0.16016815602779388,
      "learning_rate": 2.104976031268897e-05,
      "loss": 0.0497,
      "step": 132200
    },
    {
      "epoch": 9.275098149186764,
      "grad_norm": 0.12272972613573074,
      "learning_rate": 2.1027851052082696e-05,
      "loss": 0.0515,
      "step": 132300
    },
    {
      "epoch": 9.282108805384183,
      "grad_norm": 0.1306292861700058,
      "learning_rate": 2.1005941791476423e-05,
      "loss": 0.0484,
      "step": 132400
    },
    {
      "epoch": 9.289119461581604,
      "grad_norm": 0.13734671473503113,
      "learning_rate": 2.098403253087015e-05,
      "loss": 0.0528,
      "step": 132500
    },
    {
      "epoch": 9.296130117779024,
      "grad_norm": 0.29483771324157715,
      "learning_rate": 2.0962123270263877e-05,
      "loss": 0.048,
      "step": 132600
    },
    {
      "epoch": 9.303140773976445,
      "grad_norm": 0.2831973433494568,
      "learning_rate": 2.0940214009657604e-05,
      "loss": 0.0482,
      "step": 132700
    },
    {
      "epoch": 9.310151430173864,
      "grad_norm": 0.18645615875720978,
      "learning_rate": 2.091830474905133e-05,
      "loss": 0.0503,
      "step": 132800
    },
    {
      "epoch": 9.317162086371285,
      "grad_norm": 0.27905720472335815,
      "learning_rate": 2.0896395488445057e-05,
      "loss": 0.0514,
      "step": 132900
    },
    {
      "epoch": 9.324172742568704,
      "grad_norm": 0.2792516052722931,
      "learning_rate": 2.087448622783878e-05,
      "loss": 0.0512,
      "step": 133000
    },
    {
      "epoch": 9.331183398766125,
      "grad_norm": 0.2338738590478897,
      "learning_rate": 2.085257696723251e-05,
      "loss": 0.0504,
      "step": 133100
    },
    {
      "epoch": 9.338194054963544,
      "grad_norm": 0.2496734857559204,
      "learning_rate": 2.083066770662624e-05,
      "loss": 0.0533,
      "step": 133200
    },
    {
      "epoch": 9.345204711160966,
      "grad_norm": 0.2531905174255371,
      "learning_rate": 2.0808758446019965e-05,
      "loss": 0.0558,
      "step": 133300
    },
    {
      "epoch": 9.352215367358385,
      "grad_norm": 0.22618049383163452,
      "learning_rate": 2.0786849185413692e-05,
      "loss": 0.0515,
      "step": 133400
    },
    {
      "epoch": 9.359226023555804,
      "grad_norm": 0.15496142208576202,
      "learning_rate": 2.076493992480742e-05,
      "loss": 0.0554,
      "step": 133500
    },
    {
      "epoch": 9.366236679753225,
      "grad_norm": 0.11395695805549622,
      "learning_rate": 2.0743030664201146e-05,
      "loss": 0.0481,
      "step": 133600
    },
    {
      "epoch": 9.373247335950644,
      "grad_norm": 0.14560191333293915,
      "learning_rate": 2.0721121403594873e-05,
      "loss": 0.0565,
      "step": 133700
    },
    {
      "epoch": 9.380257992148065,
      "grad_norm": 0.11142601072788239,
      "learning_rate": 2.06992121429886e-05,
      "loss": 0.0492,
      "step": 133800
    },
    {
      "epoch": 9.387268648345485,
      "grad_norm": 0.13194462656974792,
      "learning_rate": 2.0677302882382327e-05,
      "loss": 0.053,
      "step": 133900
    },
    {
      "epoch": 9.394279304542906,
      "grad_norm": 0.3490765690803528,
      "learning_rate": 2.0655393621776054e-05,
      "loss": 0.0508,
      "step": 134000
    },
    {
      "epoch": 9.401289960740325,
      "grad_norm": 0.13278353214263916,
      "learning_rate": 2.063348436116978e-05,
      "loss": 0.0489,
      "step": 134100
    },
    {
      "epoch": 9.408300616937746,
      "grad_norm": 0.22084449231624603,
      "learning_rate": 2.0611575100563508e-05,
      "loss": 0.0545,
      "step": 134200
    },
    {
      "epoch": 9.415311273135165,
      "grad_norm": 0.3239245116710663,
      "learning_rate": 2.0589665839957235e-05,
      "loss": 0.0501,
      "step": 134300
    },
    {
      "epoch": 9.422321929332586,
      "grad_norm": 0.26725465059280396,
      "learning_rate": 2.0567975671957023e-05,
      "loss": 0.0491,
      "step": 134400
    },
    {
      "epoch": 9.429332585530005,
      "grad_norm": 0.11804357171058655,
      "learning_rate": 2.054606641135075e-05,
      "loss": 0.0494,
      "step": 134500
    },
    {
      "epoch": 9.436343241727426,
      "grad_norm": 0.1278924196958542,
      "learning_rate": 2.0524157150744476e-05,
      "loss": 0.0525,
      "step": 134600
    },
    {
      "epoch": 9.443353897924846,
      "grad_norm": 0.2529580891132355,
      "learning_rate": 2.0502247890138203e-05,
      "loss": 0.0491,
      "step": 134700
    },
    {
      "epoch": 9.450364554122267,
      "grad_norm": 0.12364175915718079,
      "learning_rate": 2.048033862953193e-05,
      "loss": 0.052,
      "step": 134800
    },
    {
      "epoch": 9.457375210319686,
      "grad_norm": 0.208517387509346,
      "learning_rate": 2.0458429368925657e-05,
      "loss": 0.0536,
      "step": 134900
    },
    {
      "epoch": 9.464385866517105,
      "grad_norm": 0.11070796847343445,
      "learning_rate": 2.0436520108319384e-05,
      "loss": 0.05,
      "step": 135000
    },
    {
      "epoch": 9.471396522714526,
      "grad_norm": 0.29148155450820923,
      "learning_rate": 2.041461084771311e-05,
      "loss": 0.0516,
      "step": 135100
    },
    {
      "epoch": 9.478407178911946,
      "grad_norm": 0.2001677006483078,
      "learning_rate": 2.039270158710684e-05,
      "loss": 0.0483,
      "step": 135200
    },
    {
      "epoch": 9.485417835109367,
      "grad_norm": 0.15810340642929077,
      "learning_rate": 2.0370792326500565e-05,
      "loss": 0.0492,
      "step": 135300
    },
    {
      "epoch": 9.492428491306786,
      "grad_norm": 0.15343452990055084,
      "learning_rate": 2.0348883065894292e-05,
      "loss": 0.0488,
      "step": 135400
    },
    {
      "epoch": 9.499439147504207,
      "grad_norm": 0.1404789388179779,
      "learning_rate": 2.032697380528802e-05,
      "loss": 0.052,
      "step": 135500
    },
    {
      "epoch": 9.506449803701626,
      "grad_norm": 0.3051661252975464,
      "learning_rate": 2.030506454468175e-05,
      "loss": 0.0545,
      "step": 135600
    },
    {
      "epoch": 9.513460459899047,
      "grad_norm": 0.1267901360988617,
      "learning_rate": 2.0283155284075477e-05,
      "loss": 0.0514,
      "step": 135700
    },
    {
      "epoch": 9.520471116096466,
      "grad_norm": 0.2075389176607132,
      "learning_rate": 2.0261246023469204e-05,
      "loss": 0.0506,
      "step": 135800
    },
    {
      "epoch": 9.527481772293887,
      "grad_norm": 0.17603540420532227,
      "learning_rate": 2.0239336762862927e-05,
      "loss": 0.0499,
      "step": 135900
    },
    {
      "epoch": 9.534492428491307,
      "grad_norm": 0.10878588259220123,
      "learning_rate": 2.0217427502256654e-05,
      "loss": 0.0491,
      "step": 136000
    },
    {
      "epoch": 9.541503084688728,
      "grad_norm": 0.3047960102558136,
      "learning_rate": 2.019551824165038e-05,
      "loss": 0.0503,
      "step": 136100
    },
    {
      "epoch": 9.548513740886147,
      "grad_norm": 0.3330989480018616,
      "learning_rate": 2.0173608981044108e-05,
      "loss": 0.0517,
      "step": 136200
    },
    {
      "epoch": 9.555524397083566,
      "grad_norm": 0.11321958899497986,
      "learning_rate": 2.0151699720437835e-05,
      "loss": 0.0505,
      "step": 136300
    },
    {
      "epoch": 9.562535053280987,
      "grad_norm": 0.20159517228603363,
      "learning_rate": 2.0129790459831562e-05,
      "loss": 0.0497,
      "step": 136400
    },
    {
      "epoch": 9.569545709478406,
      "grad_norm": 0.17643170058727264,
      "learning_rate": 2.010788119922529e-05,
      "loss": 0.0517,
      "step": 136500
    },
    {
      "epoch": 9.576556365675827,
      "grad_norm": 0.1142800971865654,
      "learning_rate": 2.0085971938619016e-05,
      "loss": 0.0514,
      "step": 136600
    },
    {
      "epoch": 9.583567021873247,
      "grad_norm": 0.18161870539188385,
      "learning_rate": 2.0064062678012743e-05,
      "loss": 0.0484,
      "step": 136700
    },
    {
      "epoch": 9.590577678070668,
      "grad_norm": 0.14162534475326538,
      "learning_rate": 2.004215341740647e-05,
      "loss": 0.0489,
      "step": 136800
    },
    {
      "epoch": 9.597588334268087,
      "grad_norm": 0.44907206296920776,
      "learning_rate": 2.0020244156800197e-05,
      "loss": 0.0542,
      "step": 136900
    },
    {
      "epoch": 9.604598990465508,
      "grad_norm": 0.1385239064693451,
      "learning_rate": 1.9998334896193924e-05,
      "loss": 0.0488,
      "step": 137000
    },
    {
      "epoch": 9.611609646662927,
      "grad_norm": 0.273161917924881,
      "learning_rate": 1.997642563558765e-05,
      "loss": 0.0526,
      "step": 137100
    },
    {
      "epoch": 9.618620302860348,
      "grad_norm": 0.12169201672077179,
      "learning_rate": 1.995473546758744e-05,
      "loss": 0.0527,
      "step": 137200
    },
    {
      "epoch": 9.625630959057768,
      "grad_norm": 0.12210971117019653,
      "learning_rate": 1.993282620698117e-05,
      "loss": 0.0494,
      "step": 137300
    },
    {
      "epoch": 9.632641615255189,
      "grad_norm": 0.12321604788303375,
      "learning_rate": 1.9910916946374896e-05,
      "loss": 0.0521,
      "step": 137400
    },
    {
      "epoch": 9.639652271452608,
      "grad_norm": 0.18662473559379578,
      "learning_rate": 1.988900768576862e-05,
      "loss": 0.0476,
      "step": 137500
    },
    {
      "epoch": 9.646662927650029,
      "grad_norm": 0.19041867554187775,
      "learning_rate": 1.9867098425162346e-05,
      "loss": 0.0524,
      "step": 137600
    },
    {
      "epoch": 9.653673583847448,
      "grad_norm": 0.36331817507743835,
      "learning_rate": 1.9845189164556073e-05,
      "loss": 0.0512,
      "step": 137700
    },
    {
      "epoch": 9.66068424004487,
      "grad_norm": 0.09453285485506058,
      "learning_rate": 1.98232799039498e-05,
      "loss": 0.0465,
      "step": 137800
    },
    {
      "epoch": 9.667694896242288,
      "grad_norm": 0.23273733258247375,
      "learning_rate": 1.9801370643343527e-05,
      "loss": 0.0486,
      "step": 137900
    },
    {
      "epoch": 9.674705552439708,
      "grad_norm": 0.31508150696754456,
      "learning_rate": 1.9779461382737257e-05,
      "loss": 0.0493,
      "step": 138000
    },
    {
      "epoch": 9.681716208637129,
      "grad_norm": 0.4212336838245392,
      "learning_rate": 1.9757552122130984e-05,
      "loss": 0.0509,
      "step": 138100
    },
    {
      "epoch": 9.688726864834548,
      "grad_norm": 0.17674218118190765,
      "learning_rate": 1.973564286152471e-05,
      "loss": 0.054,
      "step": 138200
    },
    {
      "epoch": 9.695737521031969,
      "grad_norm": 0.1900932341814041,
      "learning_rate": 1.971373360091844e-05,
      "loss": 0.0505,
      "step": 138300
    },
    {
      "epoch": 9.702748177229388,
      "grad_norm": 0.07898952811956406,
      "learning_rate": 1.9691824340312165e-05,
      "loss": 0.0488,
      "step": 138400
    },
    {
      "epoch": 9.70975883342681,
      "grad_norm": 0.09946240484714508,
      "learning_rate": 1.9669915079705892e-05,
      "loss": 0.0519,
      "step": 138500
    },
    {
      "epoch": 9.716769489624228,
      "grad_norm": 0.34323850274086,
      "learning_rate": 1.964800581909962e-05,
      "loss": 0.0492,
      "step": 138600
    },
    {
      "epoch": 9.72378014582165,
      "grad_norm": 0.2529846429824829,
      "learning_rate": 1.9626096558493346e-05,
      "loss": 0.0535,
      "step": 138700
    },
    {
      "epoch": 9.730790802019069,
      "grad_norm": 0.39957624673843384,
      "learning_rate": 1.9604187297887073e-05,
      "loss": 0.0532,
      "step": 138800
    },
    {
      "epoch": 9.73780145821649,
      "grad_norm": 0.24218115210533142,
      "learning_rate": 1.95822780372808e-05,
      "loss": 0.0534,
      "step": 138900
    },
    {
      "epoch": 9.744812114413909,
      "grad_norm": 0.11424512416124344,
      "learning_rate": 1.9560368776674527e-05,
      "loss": 0.0531,
      "step": 139000
    },
    {
      "epoch": 9.75182277061133,
      "grad_norm": 0.13547523319721222,
      "learning_rate": 1.9538459516068254e-05,
      "loss": 0.0491,
      "step": 139100
    },
    {
      "epoch": 9.75883342680875,
      "grad_norm": 0.35968828201293945,
      "learning_rate": 1.9516550255461978e-05,
      "loss": 0.0526,
      "step": 139200
    },
    {
      "epoch": 9.765844083006169,
      "grad_norm": 0.20019498467445374,
      "learning_rate": 1.9494640994855705e-05,
      "loss": 0.0493,
      "step": 139300
    },
    {
      "epoch": 9.77285473920359,
      "grad_norm": 0.3100810647010803,
      "learning_rate": 1.9472731734249432e-05,
      "loss": 0.0493,
      "step": 139400
    },
    {
      "epoch": 9.779865395401009,
      "grad_norm": 0.22865842282772064,
      "learning_rate": 1.9451041566249223e-05,
      "loss": 0.0531,
      "step": 139500
    },
    {
      "epoch": 9.78687605159843,
      "grad_norm": 0.15088868141174316,
      "learning_rate": 1.942913230564295e-05,
      "loss": 0.0517,
      "step": 139600
    },
    {
      "epoch": 9.79388670779585,
      "grad_norm": 0.3814363479614258,
      "learning_rate": 1.9407223045036676e-05,
      "loss": 0.0553,
      "step": 139700
    },
    {
      "epoch": 9.80089736399327,
      "grad_norm": 0.23060216009616852,
      "learning_rate": 1.9385313784430403e-05,
      "loss": 0.0517,
      "step": 139800
    },
    {
      "epoch": 9.80790802019069,
      "grad_norm": 0.22303321957588196,
      "learning_rate": 1.936340452382413e-05,
      "loss": 0.0516,
      "step": 139900
    },
    {
      "epoch": 9.81491867638811,
      "grad_norm": 0.38893112540245056,
      "learning_rate": 1.9341495263217857e-05,
      "loss": 0.0501,
      "step": 140000
    },
    {
      "epoch": 9.82192933258553,
      "grad_norm": 0.2104201763868332,
      "learning_rate": 1.9319586002611584e-05,
      "loss": 0.0507,
      "step": 140100
    },
    {
      "epoch": 9.82893998878295,
      "grad_norm": 0.24381564557552338,
      "learning_rate": 1.929767674200531e-05,
      "loss": 0.0513,
      "step": 140200
    },
    {
      "epoch": 9.83595064498037,
      "grad_norm": 0.35427871346473694,
      "learning_rate": 1.927576748139904e-05,
      "loss": 0.0457,
      "step": 140300
    },
    {
      "epoch": 9.842961301177791,
      "grad_norm": 0.1252831667661667,
      "learning_rate": 1.9253858220792765e-05,
      "loss": 0.0574,
      "step": 140400
    },
    {
      "epoch": 9.84997195737521,
      "grad_norm": 0.37612995505332947,
      "learning_rate": 1.9231948960186492e-05,
      "loss": 0.0485,
      "step": 140500
    },
    {
      "epoch": 9.85698261357263,
      "grad_norm": 0.3257729411125183,
      "learning_rate": 1.921003969958022e-05,
      "loss": 0.0505,
      "step": 140600
    },
    {
      "epoch": 9.86399326977005,
      "grad_norm": 0.45024433732032776,
      "learning_rate": 1.9188130438973946e-05,
      "loss": 0.0522,
      "step": 140700
    },
    {
      "epoch": 9.87100392596747,
      "grad_norm": 0.07871343940496445,
      "learning_rate": 1.9166221178367673e-05,
      "loss": 0.0512,
      "step": 140800
    },
    {
      "epoch": 9.87801458216489,
      "grad_norm": 0.35138657689094543,
      "learning_rate": 1.91443119177614e-05,
      "loss": 0.0519,
      "step": 140900
    },
    {
      "epoch": 9.88502523836231,
      "grad_norm": 0.26153069734573364,
      "learning_rate": 1.9122402657155127e-05,
      "loss": 0.0503,
      "step": 141000
    },
    {
      "epoch": 9.892035894559731,
      "grad_norm": 0.2466588020324707,
      "learning_rate": 1.9100493396548854e-05,
      "loss": 0.0495,
      "step": 141100
    },
    {
      "epoch": 9.89904655075715,
      "grad_norm": 0.39014381170272827,
      "learning_rate": 1.907858413594258e-05,
      "loss": 0.0497,
      "step": 141200
    },
    {
      "epoch": 9.906057206954571,
      "grad_norm": 0.10074817389249802,
      "learning_rate": 1.9056674875336308e-05,
      "loss": 0.0538,
      "step": 141300
    },
    {
      "epoch": 9.91306786315199,
      "grad_norm": 0.35865601897239685,
      "learning_rate": 1.9034765614730035e-05,
      "loss": 0.0498,
      "step": 141400
    },
    {
      "epoch": 9.920078519349412,
      "grad_norm": 0.2641459107398987,
      "learning_rate": 1.9012856354123762e-05,
      "loss": 0.0495,
      "step": 141500
    },
    {
      "epoch": 9.927089175546831,
      "grad_norm": 0.3342165946960449,
      "learning_rate": 1.899094709351749e-05,
      "loss": 0.0518,
      "step": 141600
    },
    {
      "epoch": 9.934099831744252,
      "grad_norm": 0.5330343246459961,
      "learning_rate": 1.8969037832911216e-05,
      "loss": 0.0512,
      "step": 141700
    },
    {
      "epoch": 9.941110487941671,
      "grad_norm": 0.31447896361351013,
      "learning_rate": 1.8947128572304943e-05,
      "loss": 0.0459,
      "step": 141800
    },
    {
      "epoch": 9.948121144139092,
      "grad_norm": 0.14072345197200775,
      "learning_rate": 1.892521931169867e-05,
      "loss": 0.0531,
      "step": 141900
    },
    {
      "epoch": 9.955131800336511,
      "grad_norm": 0.1278282105922699,
      "learning_rate": 1.890352914369846e-05,
      "loss": 0.0527,
      "step": 142000
    },
    {
      "epoch": 9.962142456533932,
      "grad_norm": 0.1241849884390831,
      "learning_rate": 1.8881619883092184e-05,
      "loss": 0.0476,
      "step": 142100
    },
    {
      "epoch": 9.969153112731352,
      "grad_norm": 0.1513136774301529,
      "learning_rate": 1.885971062248591e-05,
      "loss": 0.0539,
      "step": 142200
    },
    {
      "epoch": 9.976163768928771,
      "grad_norm": 0.10742651671171188,
      "learning_rate": 1.8837801361879638e-05,
      "loss": 0.0526,
      "step": 142300
    },
    {
      "epoch": 9.983174425126192,
      "grad_norm": 0.2506067454814911,
      "learning_rate": 1.8815892101273365e-05,
      "loss": 0.0486,
      "step": 142400
    },
    {
      "epoch": 9.990185081323611,
      "grad_norm": 0.1628342866897583,
      "learning_rate": 1.8793982840667092e-05,
      "loss": 0.0476,
      "step": 142500
    },
    {
      "epoch": 9.997195737521032,
      "grad_norm": 0.10701599717140198,
      "learning_rate": 1.877207358006082e-05,
      "loss": 0.051,
      "step": 142600
    },
    {
      "epoch": 10.0,
      "eval_accuracy_macro_0.5": 0.9793045520782471,
      "eval_accuracy_micro_0.5": 0.9793046116828918,
      "eval_accuracy_weighted_0.5": 0.9690721035003662,
      "eval_aucroc_macro": 0.8823859691619873,
      "eval_aucroc_micro": 0.8959404230117798,
      "eval_aucroc_weighted": 0.892228901386261,
      "eval_f1_macro_0.5": 0.6804360151290894,
      "eval_f1_macro_0.6": 0.6489860415458679,
      "eval_f1_macro_0.7": 0.5979596376419067,
      "eval_f1_macro_0.8": 0.3927852213382721,
      "eval_f1_micro_0.5": 0.7201021313667297,
      "eval_f1_micro_0.6": 0.6962630152702332,
      "eval_f1_micro_0.7": 0.6523314714431763,
      "eval_f1_micro_0.8": 0.5840252041816711,
      "eval_f1_micro_0.9": 0.44688719511032104,
      "eval_f1_weighted_0.5": 0.7089741230010986,
      "eval_f1_weighted_0.6": 0.6779472231864929,
      "eval_f1_weighted_0.7": 0.6254539489746094,
      "eval_f1_weighted_0.8": 0.4048660695552826,
      "eval_loss": 0.047621212899684906,
      "eval_runtime": 69.0226,
      "eval_samples_per_second": 412.531,
      "eval_steps_per_second": 51.577,
      "step": 142640
    },
    {
      "epoch": 10.004206393718452,
      "grad_norm": 0.12430377304553986,
      "learning_rate": 1.8750164319454546e-05,
      "loss": 0.0537,
      "step": 142700
    },
    {
      "epoch": 10.011217049915873,
      "grad_norm": 0.1685769408941269,
      "learning_rate": 1.8728255058848273e-05,
      "loss": 0.0536,
      "step": 142800
    },
    {
      "epoch": 10.018227706113292,
      "grad_norm": 0.11231350898742676,
      "learning_rate": 1.8706345798242004e-05,
      "loss": 0.0525,
      "step": 142900
    },
    {
      "epoch": 10.025238362310713,
      "grad_norm": 0.17426802217960358,
      "learning_rate": 1.868443653763573e-05,
      "loss": 0.0492,
      "step": 143000
    },
    {
      "epoch": 10.032249018508132,
      "grad_norm": 0.2534538805484772,
      "learning_rate": 1.8662527277029457e-05,
      "loss": 0.0543,
      "step": 143100
    },
    {
      "epoch": 10.039259674705553,
      "grad_norm": 0.10926375538110733,
      "learning_rate": 1.8640618016423184e-05,
      "loss": 0.0493,
      "step": 143200
    },
    {
      "epoch": 10.046270330902972,
      "grad_norm": 0.22537460923194885,
      "learning_rate": 1.861870875581691e-05,
      "loss": 0.046,
      "step": 143300
    },
    {
      "epoch": 10.053280987100393,
      "grad_norm": 0.13500486314296722,
      "learning_rate": 1.859679949521064e-05,
      "loss": 0.0517,
      "step": 143400
    },
    {
      "epoch": 10.060291643297813,
      "grad_norm": 0.13835930824279785,
      "learning_rate": 1.8574890234604365e-05,
      "loss": 0.05,
      "step": 143500
    },
    {
      "epoch": 10.067302299495232,
      "grad_norm": 0.12746909260749817,
      "learning_rate": 1.8552980973998092e-05,
      "loss": 0.0507,
      "step": 143600
    },
    {
      "epoch": 10.074312955692653,
      "grad_norm": 0.17046624422073364,
      "learning_rate": 1.853107171339182e-05,
      "loss": 0.0489,
      "step": 143700
    },
    {
      "epoch": 10.081323611890072,
      "grad_norm": 0.1345798224210739,
      "learning_rate": 1.8509162452785543e-05,
      "loss": 0.0556,
      "step": 143800
    },
    {
      "epoch": 10.088334268087493,
      "grad_norm": 0.13030241429805756,
      "learning_rate": 1.848725319217927e-05,
      "loss": 0.0526,
      "step": 143900
    },
    {
      "epoch": 10.095344924284912,
      "grad_norm": 0.10945460200309753,
      "learning_rate": 1.8465343931572997e-05,
      "loss": 0.0512,
      "step": 144000
    },
    {
      "epoch": 10.102355580482334,
      "grad_norm": 0.3024250268936157,
      "learning_rate": 1.8443434670966724e-05,
      "loss": 0.0523,
      "step": 144100
    },
    {
      "epoch": 10.109366236679753,
      "grad_norm": 0.3255472183227539,
      "learning_rate": 1.842152541036045e-05,
      "loss": 0.0487,
      "step": 144200
    },
    {
      "epoch": 10.116376892877174,
      "grad_norm": 0.18184344470500946,
      "learning_rate": 1.8399616149754178e-05,
      "loss": 0.0536,
      "step": 144300
    },
    {
      "epoch": 10.123387549074593,
      "grad_norm": 0.26003530621528625,
      "learning_rate": 1.8377706889147905e-05,
      "loss": 0.0483,
      "step": 144400
    },
    {
      "epoch": 10.130398205272014,
      "grad_norm": 0.30251821875572205,
      "learning_rate": 1.8355797628541632e-05,
      "loss": 0.0502,
      "step": 144500
    },
    {
      "epoch": 10.137408861469433,
      "grad_norm": 0.13543742895126343,
      "learning_rate": 1.833388836793536e-05,
      "loss": 0.0502,
      "step": 144600
    },
    {
      "epoch": 10.144419517666854,
      "grad_norm": 0.07592275738716125,
      "learning_rate": 1.8311979107329086e-05,
      "loss": 0.0498,
      "step": 144700
    },
    {
      "epoch": 10.151430173864274,
      "grad_norm": 0.2222221940755844,
      "learning_rate": 1.8290069846722813e-05,
      "loss": 0.0505,
      "step": 144800
    },
    {
      "epoch": 10.158440830061695,
      "grad_norm": 0.12621770799160004,
      "learning_rate": 1.826816058611654e-05,
      "loss": 0.0574,
      "step": 144900
    },
    {
      "epoch": 10.165451486259114,
      "grad_norm": 0.19393488764762878,
      "learning_rate": 1.8246251325510267e-05,
      "loss": 0.0506,
      "step": 145000
    },
    {
      "epoch": 10.172462142456533,
      "grad_norm": 0.21958057582378387,
      "learning_rate": 1.8224342064903997e-05,
      "loss": 0.0489,
      "step": 145100
    },
    {
      "epoch": 10.179472798653954,
      "grad_norm": 0.17850597202777863,
      "learning_rate": 1.8202432804297724e-05,
      "loss": 0.0584,
      "step": 145200
    },
    {
      "epoch": 10.186483454851373,
      "grad_norm": 0.3565959334373474,
      "learning_rate": 1.818052354369145e-05,
      "loss": 0.0498,
      "step": 145300
    },
    {
      "epoch": 10.193494111048794,
      "grad_norm": 0.40274885296821594,
      "learning_rate": 1.815883337569124e-05,
      "loss": 0.0557,
      "step": 145400
    },
    {
      "epoch": 10.200504767246214,
      "grad_norm": 0.13894256949424744,
      "learning_rate": 1.8136924115084965e-05,
      "loss": 0.0513,
      "step": 145500
    },
    {
      "epoch": 10.207515423443635,
      "grad_norm": 0.2456284761428833,
      "learning_rate": 1.8115014854478692e-05,
      "loss": 0.0526,
      "step": 145600
    },
    {
      "epoch": 10.214526079641054,
      "grad_norm": 0.17272399365901947,
      "learning_rate": 1.809310559387242e-05,
      "loss": 0.0508,
      "step": 145700
    },
    {
      "epoch": 10.221536735838475,
      "grad_norm": 0.1853167712688446,
      "learning_rate": 1.8071196333266146e-05,
      "loss": 0.0508,
      "step": 145800
    },
    {
      "epoch": 10.228547392035894,
      "grad_norm": 0.12204147130250931,
      "learning_rate": 1.8049287072659873e-05,
      "loss": 0.049,
      "step": 145900
    },
    {
      "epoch": 10.235558048233315,
      "grad_norm": 0.14089073240756989,
      "learning_rate": 1.80273778120536e-05,
      "loss": 0.0503,
      "step": 146000
    },
    {
      "epoch": 10.242568704430735,
      "grad_norm": 0.07765181362628937,
      "learning_rate": 1.8005468551447327e-05,
      "loss": 0.053,
      "step": 146100
    },
    {
      "epoch": 10.249579360628156,
      "grad_norm": 0.5069056749343872,
      "learning_rate": 1.7983559290841054e-05,
      "loss": 0.0514,
      "step": 146200
    },
    {
      "epoch": 10.256590016825575,
      "grad_norm": 0.125843346118927,
      "learning_rate": 1.796165003023478e-05,
      "loss": 0.0476,
      "step": 146300
    },
    {
      "epoch": 10.263600673022996,
      "grad_norm": 0.1058940514922142,
      "learning_rate": 1.7939740769628508e-05,
      "loss": 0.053,
      "step": 146400
    },
    {
      "epoch": 10.270611329220415,
      "grad_norm": 0.21134421229362488,
      "learning_rate": 1.7917831509022235e-05,
      "loss": 0.0471,
      "step": 146500
    },
    {
      "epoch": 10.277621985417834,
      "grad_norm": 0.05546253174543381,
      "learning_rate": 1.7895922248415962e-05,
      "loss": 0.0502,
      "step": 146600
    },
    {
      "epoch": 10.284632641615255,
      "grad_norm": 0.10245470702648163,
      "learning_rate": 1.787401298780969e-05,
      "loss": 0.0474,
      "step": 146700
    },
    {
      "epoch": 10.291643297812675,
      "grad_norm": 0.21244099736213684,
      "learning_rate": 1.7852103727203416e-05,
      "loss": 0.0483,
      "step": 146800
    },
    {
      "epoch": 10.298653954010096,
      "grad_norm": 0.1365429162979126,
      "learning_rate": 1.7830194466597143e-05,
      "loss": 0.05,
      "step": 146900
    },
    {
      "epoch": 10.305664610207515,
      "grad_norm": 0.49740031361579895,
      "learning_rate": 1.780828520599087e-05,
      "loss": 0.0493,
      "step": 147000
    },
    {
      "epoch": 10.312675266404936,
      "grad_norm": 0.20428521931171417,
      "learning_rate": 1.7786375945384594e-05,
      "loss": 0.0525,
      "step": 147100
    },
    {
      "epoch": 10.319685922602355,
      "grad_norm": 0.15748587250709534,
      "learning_rate": 1.776446668477832e-05,
      "loss": 0.0471,
      "step": 147200
    },
    {
      "epoch": 10.326696578799776,
      "grad_norm": 0.273700088262558,
      "learning_rate": 1.7742557424172048e-05,
      "loss": 0.05,
      "step": 147300
    },
    {
      "epoch": 10.333707234997195,
      "grad_norm": 0.07976701110601425,
      "learning_rate": 1.7720648163565775e-05,
      "loss": 0.0495,
      "step": 147400
    },
    {
      "epoch": 10.340717891194616,
      "grad_norm": 0.23263294994831085,
      "learning_rate": 1.76987389029595e-05,
      "loss": 0.0501,
      "step": 147500
    },
    {
      "epoch": 10.347728547392036,
      "grad_norm": 0.16988055408000946,
      "learning_rate": 1.7676829642353232e-05,
      "loss": 0.0458,
      "step": 147600
    },
    {
      "epoch": 10.354739203589457,
      "grad_norm": 0.07754649221897125,
      "learning_rate": 1.765492038174696e-05,
      "loss": 0.0476,
      "step": 147700
    },
    {
      "epoch": 10.361749859786876,
      "grad_norm": 0.1866319626569748,
      "learning_rate": 1.7633011121140686e-05,
      "loss": 0.0524,
      "step": 147800
    },
    {
      "epoch": 10.368760515984295,
      "grad_norm": 0.142245352268219,
      "learning_rate": 1.7611101860534413e-05,
      "loss": 0.0489,
      "step": 147900
    },
    {
      "epoch": 10.375771172181716,
      "grad_norm": 0.1308128833770752,
      "learning_rate": 1.758919259992814e-05,
      "loss": 0.0544,
      "step": 148000
    },
    {
      "epoch": 10.382781828379136,
      "grad_norm": 0.14877118170261383,
      "learning_rate": 1.7567283339321867e-05,
      "loss": 0.0508,
      "step": 148100
    },
    {
      "epoch": 10.389792484576557,
      "grad_norm": 0.2694500684738159,
      "learning_rate": 1.7545593171321657e-05,
      "loss": 0.0519,
      "step": 148200
    },
    {
      "epoch": 10.396803140773976,
      "grad_norm": 0.3276940882205963,
      "learning_rate": 1.752368391071538e-05,
      "loss": 0.0524,
      "step": 148300
    },
    {
      "epoch": 10.403813796971397,
      "grad_norm": 0.2334766834974289,
      "learning_rate": 1.7501774650109108e-05,
      "loss": 0.0483,
      "step": 148400
    },
    {
      "epoch": 10.410824453168816,
      "grad_norm": 0.12980866432189941,
      "learning_rate": 1.7479865389502835e-05,
      "loss": 0.0505,
      "step": 148500
    },
    {
      "epoch": 10.417835109366237,
      "grad_norm": 0.2102874517440796,
      "learning_rate": 1.7457956128896562e-05,
      "loss": 0.051,
      "step": 148600
    },
    {
      "epoch": 10.424845765563656,
      "grad_norm": 0.12110693752765656,
      "learning_rate": 1.743604686829029e-05,
      "loss": 0.0494,
      "step": 148700
    },
    {
      "epoch": 10.431856421761077,
      "grad_norm": 0.14532878994941711,
      "learning_rate": 1.7414137607684016e-05,
      "loss": 0.0516,
      "step": 148800
    },
    {
      "epoch": 10.438867077958497,
      "grad_norm": 0.15406638383865356,
      "learning_rate": 1.7392228347077743e-05,
      "loss": 0.052,
      "step": 148900
    },
    {
      "epoch": 10.445877734155918,
      "grad_norm": 0.14616909623146057,
      "learning_rate": 1.737031908647147e-05,
      "loss": 0.0475,
      "step": 149000
    },
    {
      "epoch": 10.452888390353337,
      "grad_norm": 0.2498803734779358,
      "learning_rate": 1.7348409825865197e-05,
      "loss": 0.0523,
      "step": 149100
    },
    {
      "epoch": 10.459899046550758,
      "grad_norm": 0.11460375785827637,
      "learning_rate": 1.7326500565258924e-05,
      "loss": 0.0472,
      "step": 149200
    },
    {
      "epoch": 10.466909702748177,
      "grad_norm": 0.15636275708675385,
      "learning_rate": 1.730459130465265e-05,
      "loss": 0.0481,
      "step": 149300
    },
    {
      "epoch": 10.473920358945596,
      "grad_norm": 0.3431411683559418,
      "learning_rate": 1.7282682044046378e-05,
      "loss": 0.0481,
      "step": 149400
    },
    {
      "epoch": 10.480931015143018,
      "grad_norm": 0.18700014054775238,
      "learning_rate": 1.7260772783440105e-05,
      "loss": 0.0516,
      "step": 149500
    },
    {
      "epoch": 10.487941671340437,
      "grad_norm": 0.2758222818374634,
      "learning_rate": 1.7238863522833832e-05,
      "loss": 0.0553,
      "step": 149600
    },
    {
      "epoch": 10.494952327537858,
      "grad_norm": 0.22281764447689056,
      "learning_rate": 1.721695426222756e-05,
      "loss": 0.0482,
      "step": 149700
    },
    {
      "epoch": 10.501962983735277,
      "grad_norm": 0.1711960732936859,
      "learning_rate": 1.7195045001621286e-05,
      "loss": 0.0498,
      "step": 149800
    },
    {
      "epoch": 10.508973639932698,
      "grad_norm": 0.1264336258172989,
      "learning_rate": 1.7173135741015013e-05,
      "loss": 0.0493,
      "step": 149900
    },
    {
      "epoch": 10.515984296130117,
      "grad_norm": 0.3013201951980591,
      "learning_rate": 1.715122648040874e-05,
      "loss": 0.049,
      "step": 150000
    },
    {
      "epoch": 10.522994952327538,
      "grad_norm": 0.4237980544567108,
      "learning_rate": 1.7129317219802467e-05,
      "loss": 0.0496,
      "step": 150100
    },
    {
      "epoch": 10.530005608524958,
      "grad_norm": 0.2470666766166687,
      "learning_rate": 1.7107407959196194e-05,
      "loss": 0.0476,
      "step": 150200
    },
    {
      "epoch": 10.537016264722379,
      "grad_norm": 0.12841911613941193,
      "learning_rate": 1.708549869858992e-05,
      "loss": 0.0523,
      "step": 150300
    },
    {
      "epoch": 10.544026920919798,
      "grad_norm": 0.07262196391820908,
      "learning_rate": 1.7063589437983648e-05,
      "loss": 0.0497,
      "step": 150400
    },
    {
      "epoch": 10.551037577117219,
      "grad_norm": 0.1328614354133606,
      "learning_rate": 1.7041680177377375e-05,
      "loss": 0.0475,
      "step": 150500
    },
    {
      "epoch": 10.558048233314638,
      "grad_norm": 0.28586438298225403,
      "learning_rate": 1.70197709167711e-05,
      "loss": 0.0502,
      "step": 150600
    },
    {
      "epoch": 10.56505888951206,
      "grad_norm": 0.16182707250118256,
      "learning_rate": 1.699786165616483e-05,
      "loss": 0.0526,
      "step": 150700
    },
    {
      "epoch": 10.572069545709478,
      "grad_norm": 0.08834170550107956,
      "learning_rate": 1.6975952395558556e-05,
      "loss": 0.0488,
      "step": 150800
    },
    {
      "epoch": 10.579080201906898,
      "grad_norm": 0.2384345829486847,
      "learning_rate": 1.6954043134952282e-05,
      "loss": 0.0528,
      "step": 150900
    },
    {
      "epoch": 10.586090858104319,
      "grad_norm": 0.22455497086048126,
      "learning_rate": 1.693213387434601e-05,
      "loss": 0.0476,
      "step": 151000
    },
    {
      "epoch": 10.593101514301738,
      "grad_norm": 0.1924581080675125,
      "learning_rate": 1.6910224613739736e-05,
      "loss": 0.0498,
      "step": 151100
    },
    {
      "epoch": 10.600112170499159,
      "grad_norm": 0.1615006923675537,
      "learning_rate": 1.6888315353133463e-05,
      "loss": 0.0471,
      "step": 151200
    },
    {
      "epoch": 10.607122826696578,
      "grad_norm": 0.20729435980319977,
      "learning_rate": 1.6866625185133254e-05,
      "loss": 0.0511,
      "step": 151300
    },
    {
      "epoch": 10.614133482894,
      "grad_norm": 0.12513628602027893,
      "learning_rate": 1.684471592452698e-05,
      "loss": 0.0499,
      "step": 151400
    },
    {
      "epoch": 10.621144139091419,
      "grad_norm": 0.12908494472503662,
      "learning_rate": 1.6822806663920708e-05,
      "loss": 0.052,
      "step": 151500
    },
    {
      "epoch": 10.62815479528884,
      "grad_norm": 0.2868376076221466,
      "learning_rate": 1.6800897403314435e-05,
      "loss": 0.0492,
      "step": 151600
    },
    {
      "epoch": 10.635165451486259,
      "grad_norm": 0.28453925251960754,
      "learning_rate": 1.677898814270816e-05,
      "loss": 0.0532,
      "step": 151700
    },
    {
      "epoch": 10.64217610768368,
      "grad_norm": 0.15462589263916016,
      "learning_rate": 1.6757078882101886e-05,
      "loss": 0.0496,
      "step": 151800
    },
    {
      "epoch": 10.649186763881099,
      "grad_norm": 0.14297769963741302,
      "learning_rate": 1.6735169621495613e-05,
      "loss": 0.049,
      "step": 151900
    },
    {
      "epoch": 10.65619742007852,
      "grad_norm": 0.17325983941555023,
      "learning_rate": 1.671326036088934e-05,
      "loss": 0.0498,
      "step": 152000
    },
    {
      "epoch": 10.66320807627594,
      "grad_norm": 0.1255238652229309,
      "learning_rate": 1.6691351100283067e-05,
      "loss": 0.0541,
      "step": 152100
    },
    {
      "epoch": 10.670218732473359,
      "grad_norm": 0.13962922990322113,
      "learning_rate": 1.6669441839676794e-05,
      "loss": 0.055,
      "step": 152200
    },
    {
      "epoch": 10.67722938867078,
      "grad_norm": 0.1580040007829666,
      "learning_rate": 1.664753257907052e-05,
      "loss": 0.0492,
      "step": 152300
    },
    {
      "epoch": 10.684240044868199,
      "grad_norm": 0.09514777362346649,
      "learning_rate": 1.6625623318464248e-05,
      "loss": 0.0471,
      "step": 152400
    },
    {
      "epoch": 10.69125070106562,
      "grad_norm": 0.13795481622219086,
      "learning_rate": 1.6603714057857978e-05,
      "loss": 0.0533,
      "step": 152500
    },
    {
      "epoch": 10.69826135726304,
      "grad_norm": 0.1415194869041443,
      "learning_rate": 1.6581804797251705e-05,
      "loss": 0.0502,
      "step": 152600
    },
    {
      "epoch": 10.70527201346046,
      "grad_norm": 0.08012549579143524,
      "learning_rate": 1.6559895536645432e-05,
      "loss": 0.0553,
      "step": 152700
    },
    {
      "epoch": 10.71228266965788,
      "grad_norm": 0.3187532126903534,
      "learning_rate": 1.653798627603916e-05,
      "loss": 0.0503,
      "step": 152800
    },
    {
      "epoch": 10.7192933258553,
      "grad_norm": 0.18824166059494019,
      "learning_rate": 1.6516077015432886e-05,
      "loss": 0.0499,
      "step": 152900
    },
    {
      "epoch": 10.72630398205272,
      "grad_norm": 0.1092715635895729,
      "learning_rate": 1.6494167754826613e-05,
      "loss": 0.0459,
      "step": 153000
    },
    {
      "epoch": 10.73331463825014,
      "grad_norm": 0.11959243565797806,
      "learning_rate": 1.647225849422034e-05,
      "loss": 0.0498,
      "step": 153100
    },
    {
      "epoch": 10.74032529444756,
      "grad_norm": 0.12468905001878738,
      "learning_rate": 1.6450349233614067e-05,
      "loss": 0.0442,
      "step": 153200
    },
    {
      "epoch": 10.747335950644981,
      "grad_norm": 0.13245441019535065,
      "learning_rate": 1.642843997300779e-05,
      "loss": 0.0477,
      "step": 153300
    },
    {
      "epoch": 10.7543466068424,
      "grad_norm": 0.16407494246959686,
      "learning_rate": 1.6406530712401517e-05,
      "loss": 0.0449,
      "step": 153400
    },
    {
      "epoch": 10.761357263039821,
      "grad_norm": 0.07065732032060623,
      "learning_rate": 1.6384621451795244e-05,
      "loss": 0.0511,
      "step": 153500
    },
    {
      "epoch": 10.76836791923724,
      "grad_norm": 0.14884960651397705,
      "learning_rate": 1.636271219118897e-05,
      "loss": 0.048,
      "step": 153600
    },
    {
      "epoch": 10.775378575434662,
      "grad_norm": 0.16474854946136475,
      "learning_rate": 1.6341022023188762e-05,
      "loss": 0.0518,
      "step": 153700
    },
    {
      "epoch": 10.78238923163208,
      "grad_norm": 0.23832333087921143,
      "learning_rate": 1.631911276258249e-05,
      "loss": 0.0536,
      "step": 153800
    },
    {
      "epoch": 10.7893998878295,
      "grad_norm": 0.08353990316390991,
      "learning_rate": 1.6297203501976216e-05,
      "loss": 0.0484,
      "step": 153900
    },
    {
      "epoch": 10.796410544026921,
      "grad_norm": 0.5838049650192261,
      "learning_rate": 1.6275294241369943e-05,
      "loss": 0.0504,
      "step": 154000
    },
    {
      "epoch": 10.80342120022434,
      "grad_norm": 0.14301876723766327,
      "learning_rate": 1.625338498076367e-05,
      "loss": 0.051,
      "step": 154100
    },
    {
      "epoch": 10.810431856421761,
      "grad_norm": 0.16415229439735413,
      "learning_rate": 1.6231475720157397e-05,
      "loss": 0.049,
      "step": 154200
    },
    {
      "epoch": 10.81744251261918,
      "grad_norm": 0.2600835859775543,
      "learning_rate": 1.6209566459551124e-05,
      "loss": 0.0478,
      "step": 154300
    },
    {
      "epoch": 10.824453168816602,
      "grad_norm": 0.17349807918071747,
      "learning_rate": 1.618765719894485e-05,
      "loss": 0.048,
      "step": 154400
    },
    {
      "epoch": 10.831463825014021,
      "grad_norm": 0.18455232679843903,
      "learning_rate": 1.6165747938338578e-05,
      "loss": 0.0517,
      "step": 154500
    },
    {
      "epoch": 10.838474481211442,
      "grad_norm": 0.24223418533802032,
      "learning_rate": 1.6143838677732305e-05,
      "loss": 0.0498,
      "step": 154600
    },
    {
      "epoch": 10.845485137408861,
      "grad_norm": 0.2838876247406006,
      "learning_rate": 1.6121929417126032e-05,
      "loss": 0.055,
      "step": 154700
    },
    {
      "epoch": 10.852495793606282,
      "grad_norm": 0.32587504386901855,
      "learning_rate": 1.610002015651976e-05,
      "loss": 0.0491,
      "step": 154800
    },
    {
      "epoch": 10.859506449803701,
      "grad_norm": 0.2182506024837494,
      "learning_rate": 1.6078110895913486e-05,
      "loss": 0.0463,
      "step": 154900
    },
    {
      "epoch": 10.866517106001123,
      "grad_norm": 0.2543961703777313,
      "learning_rate": 1.6056201635307213e-05,
      "loss": 0.0488,
      "step": 155000
    },
    {
      "epoch": 10.873527762198542,
      "grad_norm": 0.07987191528081894,
      "learning_rate": 1.603429237470094e-05,
      "loss": 0.051,
      "step": 155100
    },
    {
      "epoch": 10.880538418395961,
      "grad_norm": 0.16839416325092316,
      "learning_rate": 1.6012383114094667e-05,
      "loss": 0.0508,
      "step": 155200
    },
    {
      "epoch": 10.887549074593382,
      "grad_norm": 0.23010994493961334,
      "learning_rate": 1.5990473853488394e-05,
      "loss": 0.0543,
      "step": 155300
    },
    {
      "epoch": 10.894559730790801,
      "grad_norm": 0.1154017224907875,
      "learning_rate": 1.596856459288212e-05,
      "loss": 0.0508,
      "step": 155400
    },
    {
      "epoch": 10.901570386988222,
      "grad_norm": 0.32069337368011475,
      "learning_rate": 1.5946655332275848e-05,
      "loss": 0.0513,
      "step": 155500
    },
    {
      "epoch": 10.908581043185642,
      "grad_norm": 0.12393254041671753,
      "learning_rate": 1.5924746071669575e-05,
      "loss": 0.0528,
      "step": 155600
    },
    {
      "epoch": 10.915591699383063,
      "grad_norm": 0.27422118186950684,
      "learning_rate": 1.59028368110633e-05,
      "loss": 0.0484,
      "step": 155700
    },
    {
      "epoch": 10.922602355580482,
      "grad_norm": 0.3162519931793213,
      "learning_rate": 1.588092755045703e-05,
      "loss": 0.0495,
      "step": 155800
    },
    {
      "epoch": 10.929613011777903,
      "grad_norm": 0.1414678990840912,
      "learning_rate": 1.5859018289850756e-05,
      "loss": 0.0527,
      "step": 155900
    },
    {
      "epoch": 10.936623667975322,
      "grad_norm": 0.16562102735042572,
      "learning_rate": 1.5837109029244482e-05,
      "loss": 0.0485,
      "step": 156000
    },
    {
      "epoch": 10.943634324172743,
      "grad_norm": 0.4251196086406708,
      "learning_rate": 1.5815418861244273e-05,
      "loss": 0.055,
      "step": 156100
    },
    {
      "epoch": 10.950644980370162,
      "grad_norm": 0.29151859879493713,
      "learning_rate": 1.5793509600637997e-05,
      "loss": 0.0528,
      "step": 156200
    },
    {
      "epoch": 10.957655636567583,
      "grad_norm": 0.12955036759376526,
      "learning_rate": 1.5771600340031724e-05,
      "loss": 0.0476,
      "step": 156300
    },
    {
      "epoch": 10.964666292765003,
      "grad_norm": 0.07743263989686966,
      "learning_rate": 1.574969107942545e-05,
      "loss": 0.0493,
      "step": 156400
    },
    {
      "epoch": 10.971676948962422,
      "grad_norm": 0.15693813562393188,
      "learning_rate": 1.5727781818819178e-05,
      "loss": 0.0537,
      "step": 156500
    },
    {
      "epoch": 10.978687605159843,
      "grad_norm": 0.2483588010072708,
      "learning_rate": 1.5705872558212905e-05,
      "loss": 0.0545,
      "step": 156600
    },
    {
      "epoch": 10.985698261357262,
      "grad_norm": 0.3040864169597626,
      "learning_rate": 1.5683963297606632e-05,
      "loss": 0.0493,
      "step": 156700
    },
    {
      "epoch": 10.992708917554683,
      "grad_norm": 0.20515236258506775,
      "learning_rate": 1.566205403700036e-05,
      "loss": 0.0508,
      "step": 156800
    },
    {
      "epoch": 10.999719573752103,
      "grad_norm": 0.33354049921035767,
      "learning_rate": 1.5640144776394086e-05,
      "loss": 0.0518,
      "step": 156900
    },
    {
      "epoch": 11.0,
      "eval_accuracy_macro_0.5": 0.9794889092445374,
      "eval_accuracy_micro_0.5": 0.9794889688491821,
      "eval_accuracy_weighted_0.5": 0.9693759679794312,
      "eval_aucroc_macro": 0.8847792148590088,
      "eval_aucroc_micro": 0.8981564044952393,
      "eval_aucroc_weighted": 0.8943503499031067,
      "eval_f1_macro_0.5": 0.6862162351608276,
      "eval_f1_macro_0.6": 0.6532518267631531,
      "eval_f1_macro_0.7": 0.603870153427124,
      "eval_f1_macro_0.8": 0.3970087468624115,
      "eval_f1_micro_0.5": 0.7241679430007935,
      "eval_f1_micro_0.6": 0.7001267075538635,
      "eval_f1_micro_0.7": 0.6589106321334839,
      "eval_f1_micro_0.8": 0.5922478437423706,
      "eval_f1_micro_0.9": 0.45733141899108887,
      "eval_f1_weighted_0.5": 0.7145492434501648,
      "eval_f1_weighted_0.6": 0.6833252906799316,
      "eval_f1_weighted_0.7": 0.6332796216011047,
      "eval_f1_weighted_0.8": 0.41400668025016785,
      "eval_loss": 0.04736492782831192,
      "eval_runtime": 69.1954,
      "eval_samples_per_second": 411.501,
      "eval_steps_per_second": 51.449,
      "step": 156904
    },
    {
      "epoch": 11.006730229949524,
      "grad_norm": 0.18077614903450012,
      "learning_rate": 1.5618235515787813e-05,
      "loss": 0.0518,
      "step": 157000
    },
    {
      "epoch": 11.013740886146943,
      "grad_norm": 0.20062269270420074,
      "learning_rate": 1.559632625518154e-05,
      "loss": 0.0516,
      "step": 157100
    },
    {
      "epoch": 11.020751542344364,
      "grad_norm": 0.35468029975891113,
      "learning_rate": 1.5574416994575267e-05,
      "loss": 0.0462,
      "step": 157200
    },
    {
      "epoch": 11.027762198541783,
      "grad_norm": 0.17997559905052185,
      "learning_rate": 1.5552507733968994e-05,
      "loss": 0.0487,
      "step": 157300
    },
    {
      "epoch": 11.034772854739204,
      "grad_norm": 0.3823409080505371,
      "learning_rate": 1.5530598473362724e-05,
      "loss": 0.0493,
      "step": 157400
    },
    {
      "epoch": 11.041783510936623,
      "grad_norm": 0.20611277222633362,
      "learning_rate": 1.550868921275645e-05,
      "loss": 0.0493,
      "step": 157500
    },
    {
      "epoch": 11.048794167134044,
      "grad_norm": 0.10075504332780838,
      "learning_rate": 1.5486779952150178e-05,
      "loss": 0.0489,
      "step": 157600
    },
    {
      "epoch": 11.055804823331464,
      "grad_norm": 0.1993204951286316,
      "learning_rate": 1.5464870691543905e-05,
      "loss": 0.0488,
      "step": 157700
    },
    {
      "epoch": 11.062815479528885,
      "grad_norm": 0.1373680680990219,
      "learning_rate": 1.5442961430937632e-05,
      "loss": 0.0509,
      "step": 157800
    },
    {
      "epoch": 11.069826135726304,
      "grad_norm": 0.12391095608472824,
      "learning_rate": 1.5421052170331355e-05,
      "loss": 0.0468,
      "step": 157900
    },
    {
      "epoch": 11.076836791923725,
      "grad_norm": 0.22064338624477386,
      "learning_rate": 1.5399142909725082e-05,
      "loss": 0.0522,
      "step": 158000
    },
    {
      "epoch": 11.083847448121144,
      "grad_norm": 0.23881694674491882,
      "learning_rate": 1.5377452741724873e-05,
      "loss": 0.0514,
      "step": 158100
    },
    {
      "epoch": 11.090858104318563,
      "grad_norm": 0.267720490694046,
      "learning_rate": 1.53555434811186e-05,
      "loss": 0.0483,
      "step": 158200
    },
    {
      "epoch": 11.097868760515984,
      "grad_norm": 0.2848581075668335,
      "learning_rate": 1.5333634220512327e-05,
      "loss": 0.0505,
      "step": 158300
    },
    {
      "epoch": 11.104879416713404,
      "grad_norm": 0.5049683451652527,
      "learning_rate": 1.5311724959906054e-05,
      "loss": 0.0522,
      "step": 158400
    },
    {
      "epoch": 11.111890072910825,
      "grad_norm": 0.16729463636875153,
      "learning_rate": 1.528981569929978e-05,
      "loss": 0.0525,
      "step": 158500
    },
    {
      "epoch": 11.118900729108244,
      "grad_norm": 0.2426833212375641,
      "learning_rate": 1.5267906438693508e-05,
      "loss": 0.0511,
      "step": 158600
    },
    {
      "epoch": 11.125911385305665,
      "grad_norm": 0.3125816583633423,
      "learning_rate": 1.5245997178087235e-05,
      "loss": 0.048,
      "step": 158700
    },
    {
      "epoch": 11.132922041503084,
      "grad_norm": 0.26212432980537415,
      "learning_rate": 1.5224087917480962e-05,
      "loss": 0.0498,
      "step": 158800
    },
    {
      "epoch": 11.139932697700505,
      "grad_norm": 0.2910465896129608,
      "learning_rate": 1.5202178656874689e-05,
      "loss": 0.0503,
      "step": 158900
    },
    {
      "epoch": 11.146943353897925,
      "grad_norm": 0.15761803090572357,
      "learning_rate": 1.5180269396268414e-05,
      "loss": 0.0469,
      "step": 159000
    },
    {
      "epoch": 11.153954010095346,
      "grad_norm": 0.36189574003219604,
      "learning_rate": 1.5158360135662141e-05,
      "loss": 0.0505,
      "step": 159100
    },
    {
      "epoch": 11.160964666292765,
      "grad_norm": 0.1122061237692833,
      "learning_rate": 1.5136450875055868e-05,
      "loss": 0.0469,
      "step": 159200
    },
    {
      "epoch": 11.167975322490186,
      "grad_norm": 0.17954713106155396,
      "learning_rate": 1.5114541614449595e-05,
      "loss": 0.0478,
      "step": 159300
    },
    {
      "epoch": 11.174985978687605,
      "grad_norm": 0.24875813722610474,
      "learning_rate": 1.5092632353843322e-05,
      "loss": 0.0511,
      "step": 159400
    },
    {
      "epoch": 11.181996634885024,
      "grad_norm": 0.10946548730134964,
      "learning_rate": 1.5070723093237049e-05,
      "loss": 0.057,
      "step": 159500
    },
    {
      "epoch": 11.189007291082445,
      "grad_norm": 0.22699713706970215,
      "learning_rate": 1.5048813832630776e-05,
      "loss": 0.0532,
      "step": 159600
    },
    {
      "epoch": 11.196017947279865,
      "grad_norm": 0.23353277146816254,
      "learning_rate": 1.5026904572024503e-05,
      "loss": 0.048,
      "step": 159700
    },
    {
      "epoch": 11.203028603477286,
      "grad_norm": 0.12423399090766907,
      "learning_rate": 1.5004995311418232e-05,
      "loss": 0.0519,
      "step": 159800
    },
    {
      "epoch": 11.210039259674705,
      "grad_norm": 0.2523818910121918,
      "learning_rate": 1.4983086050811959e-05,
      "loss": 0.0485,
      "step": 159900
    },
    {
      "epoch": 11.217049915872126,
      "grad_norm": 0.18090654909610748,
      "learning_rate": 1.4961176790205686e-05,
      "loss": 0.0507,
      "step": 160000
    },
    {
      "epoch": 11.224060572069545,
      "grad_norm": 0.1459473818540573,
      "learning_rate": 1.4939267529599413e-05,
      "loss": 0.0526,
      "step": 160100
    },
    {
      "epoch": 11.231071228266966,
      "grad_norm": 0.30545976758003235,
      "learning_rate": 1.491735826899314e-05,
      "loss": 0.0506,
      "step": 160200
    },
    {
      "epoch": 11.238081884464385,
      "grad_norm": 0.12568043172359467,
      "learning_rate": 1.4895449008386867e-05,
      "loss": 0.0484,
      "step": 160300
    },
    {
      "epoch": 11.245092540661807,
      "grad_norm": 0.20526298880577087,
      "learning_rate": 1.4873539747780594e-05,
      "loss": 0.0487,
      "step": 160400
    },
    {
      "epoch": 11.252103196859226,
      "grad_norm": 0.33185285329818726,
      "learning_rate": 1.485163048717432e-05,
      "loss": 0.0491,
      "step": 160500
    },
    {
      "epoch": 11.259113853056647,
      "grad_norm": 0.32518213987350464,
      "learning_rate": 1.4829721226568048e-05,
      "loss": 0.0451,
      "step": 160600
    },
    {
      "epoch": 11.266124509254066,
      "grad_norm": 0.3444221615791321,
      "learning_rate": 1.4807811965961773e-05,
      "loss": 0.0489,
      "step": 160700
    },
    {
      "epoch": 11.273135165451487,
      "grad_norm": 0.0837179645895958,
      "learning_rate": 1.47859027053555e-05,
      "loss": 0.0467,
      "step": 160800
    },
    {
      "epoch": 11.280145821648906,
      "grad_norm": 0.19583961367607117,
      "learning_rate": 1.4763993444749227e-05,
      "loss": 0.0483,
      "step": 160900
    },
    {
      "epoch": 11.287156477846326,
      "grad_norm": 0.3939351439476013,
      "learning_rate": 1.4742084184142954e-05,
      "loss": 0.0462,
      "step": 161000
    },
    {
      "epoch": 11.294167134043747,
      "grad_norm": 0.5379726886749268,
      "learning_rate": 1.472017492353668e-05,
      "loss": 0.0494,
      "step": 161100
    },
    {
      "epoch": 11.301177790241166,
      "grad_norm": 0.18057851493358612,
      "learning_rate": 1.4698484755536472e-05,
      "loss": 0.0496,
      "step": 161200
    },
    {
      "epoch": 11.308188446438587,
      "grad_norm": 0.1443236619234085,
      "learning_rate": 1.4676575494930197e-05,
      "loss": 0.0482,
      "step": 161300
    },
    {
      "epoch": 11.315199102636006,
      "grad_norm": 0.2007833868265152,
      "learning_rate": 1.4654666234323924e-05,
      "loss": 0.0493,
      "step": 161400
    },
    {
      "epoch": 11.322209758833427,
      "grad_norm": 0.5396485924720764,
      "learning_rate": 1.463275697371765e-05,
      "loss": 0.0493,
      "step": 161500
    },
    {
      "epoch": 11.329220415030846,
      "grad_norm": 0.14601989090442657,
      "learning_rate": 1.4610847713111378e-05,
      "loss": 0.0476,
      "step": 161600
    },
    {
      "epoch": 11.336231071228267,
      "grad_norm": 0.17568959295749664,
      "learning_rate": 1.4588938452505105e-05,
      "loss": 0.0479,
      "step": 161700
    },
    {
      "epoch": 11.343241727425687,
      "grad_norm": 0.33284348249435425,
      "learning_rate": 1.4567029191898832e-05,
      "loss": 0.0511,
      "step": 161800
    },
    {
      "epoch": 11.350252383623108,
      "grad_norm": 0.1606249064207077,
      "learning_rate": 1.4545119931292559e-05,
      "loss": 0.0532,
      "step": 161900
    },
    {
      "epoch": 11.357263039820527,
      "grad_norm": 0.19663986563682556,
      "learning_rate": 1.4523210670686286e-05,
      "loss": 0.0521,
      "step": 162000
    },
    {
      "epoch": 11.364273696017948,
      "grad_norm": 0.25120747089385986,
      "learning_rate": 1.4501301410080013e-05,
      "loss": 0.05,
      "step": 162100
    },
    {
      "epoch": 11.371284352215367,
      "grad_norm": 0.210302472114563,
      "learning_rate": 1.447939214947374e-05,
      "loss": 0.0483,
      "step": 162200
    },
    {
      "epoch": 11.378295008412788,
      "grad_norm": 0.16500955820083618,
      "learning_rate": 1.4457482888867468e-05,
      "loss": 0.0461,
      "step": 162300
    },
    {
      "epoch": 11.385305664610208,
      "grad_norm": 0.20315316319465637,
      "learning_rate": 1.4435573628261195e-05,
      "loss": 0.0471,
      "step": 162400
    },
    {
      "epoch": 11.392316320807627,
      "grad_norm": 0.15121659636497498,
      "learning_rate": 1.4413664367654922e-05,
      "loss": 0.0533,
      "step": 162500
    },
    {
      "epoch": 11.399326977005048,
      "grad_norm": 0.17063237726688385,
      "learning_rate": 1.439175510704865e-05,
      "loss": 0.0569,
      "step": 162600
    },
    {
      "epoch": 11.406337633202467,
      "grad_norm": 0.17924688756465912,
      "learning_rate": 1.4369845846442376e-05,
      "loss": 0.0469,
      "step": 162700
    },
    {
      "epoch": 11.413348289399888,
      "grad_norm": 0.37574318051338196,
      "learning_rate": 1.4347936585836103e-05,
      "loss": 0.0513,
      "step": 162800
    },
    {
      "epoch": 11.420358945597307,
      "grad_norm": 0.16331128776073456,
      "learning_rate": 1.432602732522983e-05,
      "loss": 0.0487,
      "step": 162900
    },
    {
      "epoch": 11.427369601794728,
      "grad_norm": 0.3555014431476593,
      "learning_rate": 1.4304118064623555e-05,
      "loss": 0.0502,
      "step": 163000
    },
    {
      "epoch": 11.434380257992148,
      "grad_norm": 0.46140256524086,
      "learning_rate": 1.4282208804017282e-05,
      "loss": 0.0517,
      "step": 163100
    },
    {
      "epoch": 11.441390914189569,
      "grad_norm": 0.18057718873023987,
      "learning_rate": 1.426029954341101e-05,
      "loss": 0.0494,
      "step": 163200
    },
    {
      "epoch": 11.448401570386988,
      "grad_norm": 0.2391262799501419,
      "learning_rate": 1.4238390282804736e-05,
      "loss": 0.0483,
      "step": 163300
    },
    {
      "epoch": 11.455412226584409,
      "grad_norm": 0.25019699335098267,
      "learning_rate": 1.4216481022198463e-05,
      "loss": 0.0498,
      "step": 163400
    },
    {
      "epoch": 11.462422882781828,
      "grad_norm": 0.17032484710216522,
      "learning_rate": 1.419457176159219e-05,
      "loss": 0.0523,
      "step": 163500
    },
    {
      "epoch": 11.46943353897925,
      "grad_norm": 0.23774828016757965,
      "learning_rate": 1.4172662500985917e-05,
      "loss": 0.0495,
      "step": 163600
    },
    {
      "epoch": 11.476444195176668,
      "grad_norm": 0.15869419276714325,
      "learning_rate": 1.4150753240379644e-05,
      "loss": 0.0502,
      "step": 163700
    },
    {
      "epoch": 11.483454851374088,
      "grad_norm": 0.13192495703697205,
      "learning_rate": 1.4128843979773371e-05,
      "loss": 0.0499,
      "step": 163800
    },
    {
      "epoch": 11.490465507571509,
      "grad_norm": 0.22691889107227325,
      "learning_rate": 1.4106934719167098e-05,
      "loss": 0.0518,
      "step": 163900
    },
    {
      "epoch": 11.497476163768928,
      "grad_norm": 0.29731935262680054,
      "learning_rate": 1.4085025458560824e-05,
      "loss": 0.0508,
      "step": 164000
    },
    {
      "epoch": 11.504486819966349,
      "grad_norm": 0.39559581875801086,
      "learning_rate": 1.406311619795455e-05,
      "loss": 0.0506,
      "step": 164100
    },
    {
      "epoch": 11.511497476163768,
      "grad_norm": 0.17703020572662354,
      "learning_rate": 1.4041206937348277e-05,
      "loss": 0.0465,
      "step": 164200
    },
    {
      "epoch": 11.51850813236119,
      "grad_norm": 0.21062462031841278,
      "learning_rate": 1.4019297676742004e-05,
      "loss": 0.0523,
      "step": 164300
    },
    {
      "epoch": 11.525518788558609,
      "grad_norm": 0.1671494096517563,
      "learning_rate": 1.3997388416135731e-05,
      "loss": 0.051,
      "step": 164400
    },
    {
      "epoch": 11.53252944475603,
      "grad_norm": 0.28388282656669617,
      "learning_rate": 1.3975479155529462e-05,
      "loss": 0.0517,
      "step": 164500
    },
    {
      "epoch": 11.539540100953449,
      "grad_norm": 0.3859158456325531,
      "learning_rate": 1.3953569894923189e-05,
      "loss": 0.0439,
      "step": 164600
    },
    {
      "epoch": 11.54655075715087,
      "grad_norm": 0.5318363308906555,
      "learning_rate": 1.3931879726922978e-05,
      "loss": 0.0546,
      "step": 164700
    },
    {
      "epoch": 11.55356141334829,
      "grad_norm": 0.1786670684814453,
      "learning_rate": 1.3909970466316705e-05,
      "loss": 0.0471,
      "step": 164800
    },
    {
      "epoch": 11.56057206954571,
      "grad_norm": 0.14360812306404114,
      "learning_rate": 1.3888061205710432e-05,
      "loss": 0.0465,
      "step": 164900
    },
    {
      "epoch": 11.56758272574313,
      "grad_norm": 0.3569633960723877,
      "learning_rate": 1.3866151945104159e-05,
      "loss": 0.0505,
      "step": 165000
    },
    {
      "epoch": 11.57459338194055,
      "grad_norm": 0.37447670102119446,
      "learning_rate": 1.3844242684497886e-05,
      "loss": 0.0477,
      "step": 165100
    },
    {
      "epoch": 11.58160403813797,
      "grad_norm": 0.1766682267189026,
      "learning_rate": 1.3822333423891613e-05,
      "loss": 0.0499,
      "step": 165200
    },
    {
      "epoch": 11.58861469433539,
      "grad_norm": 0.3325306177139282,
      "learning_rate": 1.3800424163285338e-05,
      "loss": 0.0508,
      "step": 165300
    },
    {
      "epoch": 11.59562535053281,
      "grad_norm": 0.18527857959270477,
      "learning_rate": 1.3778514902679065e-05,
      "loss": 0.0495,
      "step": 165400
    },
    {
      "epoch": 11.60263600673023,
      "grad_norm": 0.19316385686397552,
      "learning_rate": 1.3756605642072792e-05,
      "loss": 0.0527,
      "step": 165500
    },
    {
      "epoch": 11.60964666292765,
      "grad_norm": 0.24968202412128448,
      "learning_rate": 1.3734696381466519e-05,
      "loss": 0.0499,
      "step": 165600
    },
    {
      "epoch": 11.61665731912507,
      "grad_norm": 0.2750684916973114,
      "learning_rate": 1.3712787120860246e-05,
      "loss": 0.0517,
      "step": 165700
    },
    {
      "epoch": 11.62366797532249,
      "grad_norm": 0.17916443943977356,
      "learning_rate": 1.3690877860253973e-05,
      "loss": 0.0528,
      "step": 165800
    },
    {
      "epoch": 11.63067863151991,
      "grad_norm": 0.18056842684745789,
      "learning_rate": 1.36689685996477e-05,
      "loss": 0.0527,
      "step": 165900
    },
    {
      "epoch": 11.63768928771733,
      "grad_norm": 0.3851051330566406,
      "learning_rate": 1.3647059339041427e-05,
      "loss": 0.0474,
      "step": 166000
    },
    {
      "epoch": 11.64469994391475,
      "grad_norm": 0.16403886675834656,
      "learning_rate": 1.3625150078435154e-05,
      "loss": 0.0464,
      "step": 166100
    },
    {
      "epoch": 11.651710600112171,
      "grad_norm": 0.18645122647285461,
      "learning_rate": 1.360324081782888e-05,
      "loss": 0.051,
      "step": 166200
    },
    {
      "epoch": 11.65872125630959,
      "grad_norm": 0.12098164111375809,
      "learning_rate": 1.3581331557222606e-05,
      "loss": 0.0498,
      "step": 166300
    },
    {
      "epoch": 11.665731912507011,
      "grad_norm": 0.12247315794229507,
      "learning_rate": 1.3559422296616333e-05,
      "loss": 0.053,
      "step": 166400
    },
    {
      "epoch": 11.67274256870443,
      "grad_norm": 0.2735775113105774,
      "learning_rate": 1.353751303601006e-05,
      "loss": 0.0482,
      "step": 166500
    },
    {
      "epoch": 11.679753224901852,
      "grad_norm": 0.30159032344818115,
      "learning_rate": 1.3515603775403787e-05,
      "loss": 0.0503,
      "step": 166600
    },
    {
      "epoch": 11.686763881099271,
      "grad_norm": 0.10386846959590912,
      "learning_rate": 1.3493694514797514e-05,
      "loss": 0.0496,
      "step": 166700
    },
    {
      "epoch": 11.69377453729669,
      "grad_norm": 0.21375742554664612,
      "learning_rate": 1.3471785254191241e-05,
      "loss": 0.0487,
      "step": 166800
    },
    {
      "epoch": 11.700785193494111,
      "grad_norm": 0.3138982355594635,
      "learning_rate": 1.3449875993584971e-05,
      "loss": 0.0517,
      "step": 166900
    },
    {
      "epoch": 11.70779584969153,
      "grad_norm": 0.24710945785045624,
      "learning_rate": 1.3427966732978697e-05,
      "loss": 0.0512,
      "step": 167000
    },
    {
      "epoch": 11.714806505888951,
      "grad_norm": 0.536723256111145,
      "learning_rate": 1.3406057472372424e-05,
      "loss": 0.0525,
      "step": 167100
    },
    {
      "epoch": 11.72181716208637,
      "grad_norm": 0.2807404398918152,
      "learning_rate": 1.338414821176615e-05,
      "loss": 0.0502,
      "step": 167200
    },
    {
      "epoch": 11.728827818283792,
      "grad_norm": 0.27057966589927673,
      "learning_rate": 1.3362238951159878e-05,
      "loss": 0.0517,
      "step": 167300
    },
    {
      "epoch": 11.735838474481211,
      "grad_norm": 0.24192525446414948,
      "learning_rate": 1.3340329690553605e-05,
      "loss": 0.05,
      "step": 167400
    },
    {
      "epoch": 11.742849130678632,
      "grad_norm": 0.15681466460227966,
      "learning_rate": 1.3318420429947332e-05,
      "loss": 0.0517,
      "step": 167500
    },
    {
      "epoch": 11.749859786876051,
      "grad_norm": 0.1498350352048874,
      "learning_rate": 1.3296511169341059e-05,
      "loss": 0.0511,
      "step": 167600
    },
    {
      "epoch": 11.756870443073472,
      "grad_norm": 0.12891961634159088,
      "learning_rate": 1.3274601908734785e-05,
      "loss": 0.0484,
      "step": 167700
    },
    {
      "epoch": 11.763881099270892,
      "grad_norm": 0.1370072215795517,
      "learning_rate": 1.3252692648128512e-05,
      "loss": 0.0475,
      "step": 167800
    },
    {
      "epoch": 11.770891755468313,
      "grad_norm": 0.21346290409564972,
      "learning_rate": 1.323078338752224e-05,
      "loss": 0.0492,
      "step": 167900
    },
    {
      "epoch": 11.777902411665732,
      "grad_norm": 0.3989752233028412,
      "learning_rate": 1.3208874126915965e-05,
      "loss": 0.0539,
      "step": 168000
    },
    {
      "epoch": 11.784913067863151,
      "grad_norm": 0.07173718512058258,
      "learning_rate": 1.3186964866309692e-05,
      "loss": 0.05,
      "step": 168100
    },
    {
      "epoch": 11.791923724060572,
      "grad_norm": 0.2324981838464737,
      "learning_rate": 1.3165055605703419e-05,
      "loss": 0.0545,
      "step": 168200
    },
    {
      "epoch": 11.798934380257991,
      "grad_norm": 0.29233023524284363,
      "learning_rate": 1.3143146345097146e-05,
      "loss": 0.0517,
      "step": 168300
    },
    {
      "epoch": 11.805945036455412,
      "grad_norm": 0.4034939110279083,
      "learning_rate": 1.3121237084490873e-05,
      "loss": 0.0528,
      "step": 168400
    },
    {
      "epoch": 11.812955692652832,
      "grad_norm": 0.11028923839330673,
      "learning_rate": 1.30993278238846e-05,
      "loss": 0.0522,
      "step": 168500
    },
    {
      "epoch": 11.819966348850253,
      "grad_norm": 0.12182857096195221,
      "learning_rate": 1.3077418563278327e-05,
      "loss": 0.0483,
      "step": 168600
    },
    {
      "epoch": 11.826977005047672,
      "grad_norm": Infinity,
      "learning_rate": 1.3055728395278116e-05,
      "loss": 0.0513,
      "step": 168700
    },
    {
      "epoch": 11.833987661245093,
      "grad_norm": 0.13944968581199646,
      "learning_rate": 1.3033819134671843e-05,
      "loss": 0.0468,
      "step": 168800
    },
    {
      "epoch": 11.840998317442512,
      "grad_norm": 0.40407365560531616,
      "learning_rate": 1.301190987406557e-05,
      "loss": 0.0455,
      "step": 168900
    },
    {
      "epoch": 11.848008973639933,
      "grad_norm": 0.15041637420654297,
      "learning_rate": 1.2990000613459297e-05,
      "loss": 0.0477,
      "step": 169000
    },
    {
      "epoch": 11.855019629837352,
      "grad_norm": 0.20190361142158508,
      "learning_rate": 1.2968091352853024e-05,
      "loss": 0.0542,
      "step": 169100
    },
    {
      "epoch": 11.862030286034773,
      "grad_norm": 0.355154424905777,
      "learning_rate": 1.294618209224675e-05,
      "loss": 0.0513,
      "step": 169200
    },
    {
      "epoch": 11.869040942232193,
      "grad_norm": 0.14563938975334167,
      "learning_rate": 1.2924272831640477e-05,
      "loss": 0.0498,
      "step": 169300
    },
    {
      "epoch": 11.876051598429614,
      "grad_norm": 0.2551630735397339,
      "learning_rate": 1.2902363571034206e-05,
      "loss": 0.0476,
      "step": 169400
    },
    {
      "epoch": 11.883062254627033,
      "grad_norm": 0.2993044853210449,
      "learning_rate": 1.2880454310427933e-05,
      "loss": 0.0545,
      "step": 169500
    },
    {
      "epoch": 11.890072910824454,
      "grad_norm": 0.4110257923603058,
      "learning_rate": 1.285854504982166e-05,
      "loss": 0.049,
      "step": 169600
    },
    {
      "epoch": 11.897083567021873,
      "grad_norm": 0.1756848394870758,
      "learning_rate": 1.2836635789215387e-05,
      "loss": 0.0453,
      "step": 169700
    },
    {
      "epoch": 11.904094223219293,
      "grad_norm": 0.38566353917121887,
      "learning_rate": 1.2814726528609114e-05,
      "loss": 0.0526,
      "step": 169800
    },
    {
      "epoch": 11.911104879416714,
      "grad_norm": 0.36718061566352844,
      "learning_rate": 1.2792817268002841e-05,
      "loss": 0.0488,
      "step": 169900
    },
    {
      "epoch": 11.918115535614133,
      "grad_norm": 0.14772944152355194,
      "learning_rate": 1.2770908007396568e-05,
      "loss": 0.0478,
      "step": 170000
    },
    {
      "epoch": 11.925126191811554,
      "grad_norm": 0.14775168895721436,
      "learning_rate": 1.2748998746790295e-05,
      "loss": 0.0506,
      "step": 170100
    },
    {
      "epoch": 11.932136848008973,
      "grad_norm": 0.18880698084831238,
      "learning_rate": 1.2727089486184022e-05,
      "loss": 0.0462,
      "step": 170200
    },
    {
      "epoch": 11.939147504206394,
      "grad_norm": 0.22288280725479126,
      "learning_rate": 1.2705180225577747e-05,
      "loss": 0.0432,
      "step": 170300
    },
    {
      "epoch": 11.946158160403813,
      "grad_norm": 0.177951842546463,
      "learning_rate": 1.2683270964971474e-05,
      "loss": 0.0524,
      "step": 170400
    },
    {
      "epoch": 11.953168816601234,
      "grad_norm": 0.20000678300857544,
      "learning_rate": 1.2661361704365201e-05,
      "loss": 0.0489,
      "step": 170500
    },
    {
      "epoch": 11.960179472798654,
      "grad_norm": 0.19129003584384918,
      "learning_rate": 1.2639452443758928e-05,
      "loss": 0.0494,
      "step": 170600
    },
    {
      "epoch": 11.967190128996075,
      "grad_norm": 0.2460172027349472,
      "learning_rate": 1.2617543183152655e-05,
      "loss": 0.0464,
      "step": 170700
    },
    {
      "epoch": 11.974200785193494,
      "grad_norm": 0.10092587769031525,
      "learning_rate": 1.2595633922546382e-05,
      "loss": 0.05,
      "step": 170800
    },
    {
      "epoch": 11.981211441390915,
      "grad_norm": 0.11052108556032181,
      "learning_rate": 1.2573724661940109e-05,
      "loss": 0.0484,
      "step": 170900
    },
    {
      "epoch": 11.988222097588334,
      "grad_norm": 0.3750804662704468,
      "learning_rate": 1.2551815401333836e-05,
      "loss": 0.0479,
      "step": 171000
    },
    {
      "epoch": 11.995232753785753,
      "grad_norm": 0.2433130294084549,
      "learning_rate": 1.2530125233333625e-05,
      "loss": 0.0524,
      "step": 171100
    },
    {
      "epoch": 12.0,
      "eval_accuracy_macro_0.5": 0.9796514511108398,
      "eval_accuracy_micro_0.5": 0.9796513915061951,
      "eval_accuracy_weighted_0.5": 0.9696855545043945,
      "eval_aucroc_macro": 0.885488748550415,
      "eval_aucroc_micro": 0.8987337350845337,
      "eval_aucroc_weighted": 0.8949977159500122,
      "eval_f1_macro_0.5": 0.6884233951568604,
      "eval_f1_macro_0.6": 0.6558374166488647,
      "eval_f1_macro_0.7": 0.6073124408721924,
      "eval_f1_macro_0.8": 0.40326544642448425,
      "eval_f1_micro_0.5": 0.726449191570282,
      "eval_f1_micro_0.6": 0.7027009725570679,
      "eval_f1_micro_0.7": 0.6628620028495789,
      "eval_f1_micro_0.8": 0.5973169207572937,
      "eval_f1_micro_0.9": 0.46749791502952576,
      "eval_f1_weighted_0.5": 0.7167726755142212,
      "eval_f1_weighted_0.6": 0.6856294870376587,
      "eval_f1_weighted_0.7": 0.6372570991516113,
      "eval_f1_weighted_0.8": 0.42165306210517883,
      "eval_loss": 0.046860143542289734,
      "eval_runtime": 69.4335,
      "eval_samples_per_second": 410.09,
      "eval_steps_per_second": 51.272,
      "step": 171168
    },
    {
      "epoch": 12.002243409983175,
      "grad_norm": 0.18141105771064758,
      "learning_rate": 1.2508215972727352e-05,
      "loss": 0.048,
      "step": 171200
    },
    {
      "epoch": 12.009254066180594,
      "grad_norm": 0.27421894669532776,
      "learning_rate": 1.248630671212108e-05,
      "loss": 0.0489,
      "step": 171300
    },
    {
      "epoch": 12.016264722378015,
      "grad_norm": 0.16595898568630219,
      "learning_rate": 1.2464397451514808e-05,
      "loss": 0.0489,
      "step": 171400
    },
    {
      "epoch": 12.023275378575434,
      "grad_norm": 0.3963083326816559,
      "learning_rate": 1.2442488190908535e-05,
      "loss": 0.0498,
      "step": 171500
    },
    {
      "epoch": 12.030286034772855,
      "grad_norm": 0.13530059158802032,
      "learning_rate": 1.2420578930302262e-05,
      "loss": 0.0502,
      "step": 171600
    },
    {
      "epoch": 12.037296690970274,
      "grad_norm": 0.19123230874538422,
      "learning_rate": 1.2398669669695987e-05,
      "loss": 0.0526,
      "step": 171700
    },
    {
      "epoch": 12.044307347167695,
      "grad_norm": 0.13673222064971924,
      "learning_rate": 1.2376760409089714e-05,
      "loss": 0.0482,
      "step": 171800
    },
    {
      "epoch": 12.051318003365115,
      "grad_norm": 0.540690541267395,
      "learning_rate": 1.2354851148483441e-05,
      "loss": 0.0511,
      "step": 171900
    },
    {
      "epoch": 12.058328659562536,
      "grad_norm": 0.3179982006549835,
      "learning_rate": 1.2332941887877168e-05,
      "loss": 0.0534,
      "step": 172000
    },
    {
      "epoch": 12.065339315759955,
      "grad_norm": 0.352618008852005,
      "learning_rate": 1.2311032627270895e-05,
      "loss": 0.0479,
      "step": 172100
    },
    {
      "epoch": 12.072349971957376,
      "grad_norm": 0.23926478624343872,
      "learning_rate": 1.2289342459270686e-05,
      "loss": 0.0453,
      "step": 172200
    },
    {
      "epoch": 12.079360628154795,
      "grad_norm": 0.13571800291538239,
      "learning_rate": 1.2267433198664411e-05,
      "loss": 0.0507,
      "step": 172300
    },
    {
      "epoch": 12.086371284352216,
      "grad_norm": 0.20257414877414703,
      "learning_rate": 1.2245523938058138e-05,
      "loss": 0.0506,
      "step": 172400
    },
    {
      "epoch": 12.093381940549635,
      "grad_norm": 0.14548814296722412,
      "learning_rate": 1.2223614677451865e-05,
      "loss": 0.0492,
      "step": 172500
    },
    {
      "epoch": 12.100392596747055,
      "grad_norm": 0.1769225299358368,
      "learning_rate": 1.2201705416845594e-05,
      "loss": 0.0503,
      "step": 172600
    },
    {
      "epoch": 12.107403252944476,
      "grad_norm": 0.24556873738765717,
      "learning_rate": 1.217979615623932e-05,
      "loss": 0.0552,
      "step": 172700
    },
    {
      "epoch": 12.114413909141895,
      "grad_norm": 0.1647096872329712,
      "learning_rate": 1.2157886895633048e-05,
      "loss": 0.0488,
      "step": 172800
    },
    {
      "epoch": 12.121424565339316,
      "grad_norm": 0.2736209034919739,
      "learning_rate": 1.2135977635026775e-05,
      "loss": 0.0505,
      "step": 172900
    },
    {
      "epoch": 12.128435221536735,
      "grad_norm": 0.31183579564094543,
      "learning_rate": 1.2114068374420501e-05,
      "loss": 0.0491,
      "step": 173000
    },
    {
      "epoch": 12.135445877734156,
      "grad_norm": 0.23950353264808655,
      "learning_rate": 1.2092159113814227e-05,
      "loss": 0.0516,
      "step": 173100
    },
    {
      "epoch": 12.142456533931576,
      "grad_norm": 0.22356127202510834,
      "learning_rate": 1.2070249853207954e-05,
      "loss": 0.0474,
      "step": 173200
    },
    {
      "epoch": 12.149467190128997,
      "grad_norm": 0.17331580817699432,
      "learning_rate": 1.204834059260168e-05,
      "loss": 0.0554,
      "step": 173300
    },
    {
      "epoch": 12.156477846326416,
      "grad_norm": 0.2320610135793686,
      "learning_rate": 1.2026431331995408e-05,
      "loss": 0.0504,
      "step": 173400
    },
    {
      "epoch": 12.163488502523837,
      "grad_norm": 0.349130779504776,
      "learning_rate": 1.2004522071389135e-05,
      "loss": 0.0497,
      "step": 173500
    },
    {
      "epoch": 12.170499158721256,
      "grad_norm": 0.18497061729431152,
      "learning_rate": 1.1982612810782862e-05,
      "loss": 0.0505,
      "step": 173600
    },
    {
      "epoch": 12.177509814918677,
      "grad_norm": 0.18924608826637268,
      "learning_rate": 1.196070355017659e-05,
      "loss": 0.0492,
      "step": 173700
    },
    {
      "epoch": 12.184520471116096,
      "grad_norm": 0.1493000090122223,
      "learning_rate": 1.1938794289570317e-05,
      "loss": 0.0506,
      "step": 173800
    },
    {
      "epoch": 12.191531127313517,
      "grad_norm": 0.15054497122764587,
      "learning_rate": 1.1916885028964044e-05,
      "loss": 0.0506,
      "step": 173900
    },
    {
      "epoch": 12.198541783510937,
      "grad_norm": 0.17414282262325287,
      "learning_rate": 1.189497576835777e-05,
      "loss": 0.0539,
      "step": 174000
    },
    {
      "epoch": 12.205552439708356,
      "grad_norm": 0.08726497739553452,
      "learning_rate": 1.1873066507751497e-05,
      "loss": 0.0519,
      "step": 174100
    },
    {
      "epoch": 12.212563095905777,
      "grad_norm": 0.1481127142906189,
      "learning_rate": 1.1851157247145224e-05,
      "loss": 0.0477,
      "step": 174200
    },
    {
      "epoch": 12.219573752103196,
      "grad_norm": 0.14881885051727295,
      "learning_rate": 1.182924798653895e-05,
      "loss": 0.0485,
      "step": 174300
    },
    {
      "epoch": 12.226584408300617,
      "grad_norm": 0.1994106024503708,
      "learning_rate": 1.1807338725932677e-05,
      "loss": 0.0511,
      "step": 174400
    },
    {
      "epoch": 12.233595064498036,
      "grad_norm": 0.282500296831131,
      "learning_rate": 1.1785429465326404e-05,
      "loss": 0.0466,
      "step": 174500
    },
    {
      "epoch": 12.240605720695457,
      "grad_norm": 0.20376436412334442,
      "learning_rate": 1.1763520204720131e-05,
      "loss": 0.0504,
      "step": 174600
    },
    {
      "epoch": 12.247616376892877,
      "grad_norm": 0.3765961229801178,
      "learning_rate": 1.1741610944113858e-05,
      "loss": 0.0521,
      "step": 174700
    },
    {
      "epoch": 12.254627033090298,
      "grad_norm": 0.18322409689426422,
      "learning_rate": 1.1719701683507585e-05,
      "loss": 0.0503,
      "step": 174800
    },
    {
      "epoch": 12.261637689287717,
      "grad_norm": 0.21865898370742798,
      "learning_rate": 1.1697792422901312e-05,
      "loss": 0.0474,
      "step": 174900
    },
    {
      "epoch": 12.268648345485138,
      "grad_norm": 0.28950074315071106,
      "learning_rate": 1.167588316229504e-05,
      "loss": 0.0485,
      "step": 175000
    },
    {
      "epoch": 12.275659001682557,
      "grad_norm": 0.3277290463447571,
      "learning_rate": 1.1653973901688766e-05,
      "loss": 0.0503,
      "step": 175100
    },
    {
      "epoch": 12.282669657879978,
      "grad_norm": 0.3066187798976898,
      "learning_rate": 1.1632064641082493e-05,
      "loss": 0.0487,
      "step": 175200
    },
    {
      "epoch": 12.289680314077398,
      "grad_norm": 0.14198210835456848,
      "learning_rate": 1.161015538047622e-05,
      "loss": 0.0493,
      "step": 175300
    },
    {
      "epoch": 12.296690970274817,
      "grad_norm": 0.19441992044448853,
      "learning_rate": 1.1588246119869947e-05,
      "loss": 0.0495,
      "step": 175400
    },
    {
      "epoch": 12.303701626472238,
      "grad_norm": 0.23186498880386353,
      "learning_rate": 1.1566336859263674e-05,
      "loss": 0.0505,
      "step": 175500
    },
    {
      "epoch": 12.310712282669657,
      "grad_norm": 0.17455923557281494,
      "learning_rate": 1.1544646691263463e-05,
      "loss": 0.052,
      "step": 175600
    },
    {
      "epoch": 12.317722938867078,
      "grad_norm": 0.3489743769168854,
      "learning_rate": 1.152273743065719e-05,
      "loss": 0.0475,
      "step": 175700
    },
    {
      "epoch": 12.324733595064497,
      "grad_norm": 0.18098369240760803,
      "learning_rate": 1.1500828170050917e-05,
      "loss": 0.0539,
      "step": 175800
    },
    {
      "epoch": 12.331744251261918,
      "grad_norm": 0.15641285479068756,
      "learning_rate": 1.1478918909444644e-05,
      "loss": 0.0471,
      "step": 175900
    },
    {
      "epoch": 12.338754907459338,
      "grad_norm": 0.11724402010440826,
      "learning_rate": 1.1457009648838371e-05,
      "loss": 0.0508,
      "step": 176000
    },
    {
      "epoch": 12.345765563656759,
      "grad_norm": 0.14753234386444092,
      "learning_rate": 1.1435100388232098e-05,
      "loss": 0.0488,
      "step": 176100
    },
    {
      "epoch": 12.352776219854178,
      "grad_norm": 0.1988995373249054,
      "learning_rate": 1.1413191127625827e-05,
      "loss": 0.0471,
      "step": 176200
    },
    {
      "epoch": 12.359786876051599,
      "grad_norm": 0.13518649339675903,
      "learning_rate": 1.1391281867019552e-05,
      "loss": 0.0467,
      "step": 176300
    },
    {
      "epoch": 12.366797532249018,
      "grad_norm": 0.16262295842170715,
      "learning_rate": 1.1369372606413279e-05,
      "loss": 0.0513,
      "step": 176400
    },
    {
      "epoch": 12.37380818844644,
      "grad_norm": 0.2964203357696533,
      "learning_rate": 1.1347463345807006e-05,
      "loss": 0.0512,
      "step": 176500
    },
    {
      "epoch": 12.380818844643859,
      "grad_norm": 0.08659245073795319,
      "learning_rate": 1.1325554085200733e-05,
      "loss": 0.0512,
      "step": 176600
    },
    {
      "epoch": 12.38782950084128,
      "grad_norm": 0.19816739857196808,
      "learning_rate": 1.130364482459446e-05,
      "loss": 0.0531,
      "step": 176700
    },
    {
      "epoch": 12.394840157038699,
      "grad_norm": 0.20925374329090118,
      "learning_rate": 1.1281735563988187e-05,
      "loss": 0.0491,
      "step": 176800
    },
    {
      "epoch": 12.401850813236118,
      "grad_norm": 0.2443288266658783,
      "learning_rate": 1.1259826303381914e-05,
      "loss": 0.0522,
      "step": 176900
    },
    {
      "epoch": 12.408861469433539,
      "grad_norm": 0.12803228199481964,
      "learning_rate": 1.1237917042775641e-05,
      "loss": 0.0474,
      "step": 177000
    },
    {
      "epoch": 12.415872125630958,
      "grad_norm": 0.23705114424228668,
      "learning_rate": 1.1216007782169368e-05,
      "loss": 0.0507,
      "step": 177100
    },
    {
      "epoch": 12.42288278182838,
      "grad_norm": 0.36905741691589355,
      "learning_rate": 1.1194098521563095e-05,
      "loss": 0.0474,
      "step": 177200
    },
    {
      "epoch": 12.429893438025799,
      "grad_norm": 0.15170086920261383,
      "learning_rate": 1.1172189260956822e-05,
      "loss": 0.0505,
      "step": 177300
    },
    {
      "epoch": 12.43690409422322,
      "grad_norm": 0.24956661462783813,
      "learning_rate": 1.1150280000350549e-05,
      "loss": 0.0481,
      "step": 177400
    },
    {
      "epoch": 12.443914750420639,
      "grad_norm": 0.3987753391265869,
      "learning_rate": 1.1128370739744276e-05,
      "loss": 0.049,
      "step": 177500
    },
    {
      "epoch": 12.45092540661806,
      "grad_norm": 0.150630384683609,
      "learning_rate": 1.1106461479138003e-05,
      "loss": 0.0508,
      "step": 177600
    },
    {
      "epoch": 12.45793606281548,
      "grad_norm": 0.16683784127235413,
      "learning_rate": 1.108455221853173e-05,
      "loss": 0.0527,
      "step": 177700
    },
    {
      "epoch": 12.4649467190129,
      "grad_norm": 0.40357762575149536,
      "learning_rate": 1.1062642957925457e-05,
      "loss": 0.051,
      "step": 177800
    },
    {
      "epoch": 12.47195737521032,
      "grad_norm": 0.1883327215909958,
      "learning_rate": 1.1040733697319184e-05,
      "loss": 0.0444,
      "step": 177900
    },
    {
      "epoch": 12.47896803140774,
      "grad_norm": 0.17152683436870575,
      "learning_rate": 1.101882443671291e-05,
      "loss": 0.0493,
      "step": 178000
    },
    {
      "epoch": 12.48597868760516,
      "grad_norm": 0.13514477014541626,
      "learning_rate": 1.09971342687127e-05,
      "loss": 0.0517,
      "step": 178100
    },
    {
      "epoch": 12.49298934380258,
      "grad_norm": 0.1560344099998474,
      "learning_rate": 1.0975225008106427e-05,
      "loss": 0.0499,
      "step": 178200
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.2490169107913971,
      "learning_rate": 1.0953315747500154e-05,
      "loss": 0.0503,
      "step": 178300
    },
    {
      "epoch": 12.50701065619742,
      "grad_norm": 0.28881096839904785,
      "learning_rate": 1.093140648689388e-05,
      "loss": 0.05,
      "step": 178400
    },
    {
      "epoch": 12.51402131239484,
      "grad_norm": 0.15203098952770233,
      "learning_rate": 1.0909497226287608e-05,
      "loss": 0.0536,
      "step": 178500
    },
    {
      "epoch": 12.52103196859226,
      "grad_norm": 0.2211424559354782,
      "learning_rate": 1.0887587965681335e-05,
      "loss": 0.0471,
      "step": 178600
    },
    {
      "epoch": 12.52804262478968,
      "grad_norm": 0.4600842297077179,
      "learning_rate": 1.0865678705075062e-05,
      "loss": 0.0472,
      "step": 178700
    },
    {
      "epoch": 12.5350532809871,
      "grad_norm": 0.1555839627981186,
      "learning_rate": 1.0843769444468789e-05,
      "loss": 0.0452,
      "step": 178800
    },
    {
      "epoch": 12.54206393718452,
      "grad_norm": 0.14292310178279877,
      "learning_rate": 1.0821860183862516e-05,
      "loss": 0.0493,
      "step": 178900
    },
    {
      "epoch": 12.54907459338194,
      "grad_norm": 0.19507914781570435,
      "learning_rate": 1.0799950923256243e-05,
      "loss": 0.0518,
      "step": 179000
    },
    {
      "epoch": 12.556085249579361,
      "grad_norm": 0.15421713888645172,
      "learning_rate": 1.077804166264997e-05,
      "loss": 0.0528,
      "step": 179100
    },
    {
      "epoch": 12.56309590577678,
      "grad_norm": 0.25004318356513977,
      "learning_rate": 1.0756132402043697e-05,
      "loss": 0.0491,
      "step": 179200
    },
    {
      "epoch": 12.570106561974201,
      "grad_norm": 0.2879430651664734,
      "learning_rate": 1.0734223141437424e-05,
      "loss": 0.0491,
      "step": 179300
    },
    {
      "epoch": 12.57711721817162,
      "grad_norm": 0.2290397435426712,
      "learning_rate": 1.071231388083115e-05,
      "loss": 0.046,
      "step": 179400
    },
    {
      "epoch": 12.584127874369042,
      "grad_norm": 0.13264767825603485,
      "learning_rate": 1.0690404620224877e-05,
      "loss": 0.0502,
      "step": 179500
    },
    {
      "epoch": 12.591138530566461,
      "grad_norm": 0.2635006904602051,
      "learning_rate": 1.0668495359618603e-05,
      "loss": 0.045,
      "step": 179600
    },
    {
      "epoch": 12.59814918676388,
      "grad_norm": 0.12365391105413437,
      "learning_rate": 1.0646586099012331e-05,
      "loss": 0.0527,
      "step": 179700
    },
    {
      "epoch": 12.605159842961301,
      "grad_norm": 0.20363673567771912,
      "learning_rate": 1.0624676838406058e-05,
      "loss": 0.0518,
      "step": 179800
    },
    {
      "epoch": 12.61217049915872,
      "grad_norm": 0.337849885225296,
      "learning_rate": 1.0602986670405847e-05,
      "loss": 0.0493,
      "step": 179900
    },
    {
      "epoch": 12.619181155356141,
      "grad_norm": 0.11741603165864944,
      "learning_rate": 1.0581077409799574e-05,
      "loss": 0.053,
      "step": 180000
    },
    {
      "epoch": 12.62619181155356,
      "grad_norm": 0.19677826762199402,
      "learning_rate": 1.0559168149193301e-05,
      "loss": 0.0466,
      "step": 180100
    },
    {
      "epoch": 12.633202467750982,
      "grad_norm": 0.1617642194032669,
      "learning_rate": 1.0537258888587028e-05,
      "loss": 0.0469,
      "step": 180200
    },
    {
      "epoch": 12.640213123948401,
      "grad_norm": 0.1191582903265953,
      "learning_rate": 1.0515349627980755e-05,
      "loss": 0.0469,
      "step": 180300
    },
    {
      "epoch": 12.647223780145822,
      "grad_norm": 0.13131776452064514,
      "learning_rate": 1.0493440367374482e-05,
      "loss": 0.0536,
      "step": 180400
    },
    {
      "epoch": 12.654234436343241,
      "grad_norm": 0.2601131498813629,
      "learning_rate": 1.047153110676821e-05,
      "loss": 0.0501,
      "step": 180500
    },
    {
      "epoch": 12.661245092540662,
      "grad_norm": 0.310783714056015,
      "learning_rate": 1.0449621846161936e-05,
      "loss": 0.0475,
      "step": 180600
    },
    {
      "epoch": 12.668255748738082,
      "grad_norm": 0.10763368010520935,
      "learning_rate": 1.0427712585555663e-05,
      "loss": 0.0488,
      "step": 180700
    },
    {
      "epoch": 12.675266404935503,
      "grad_norm": 0.15351396799087524,
      "learning_rate": 1.040580332494939e-05,
      "loss": 0.0507,
      "step": 180800
    },
    {
      "epoch": 12.682277061132922,
      "grad_norm": 0.13076871633529663,
      "learning_rate": 1.0383894064343117e-05,
      "loss": 0.0481,
      "step": 180900
    },
    {
      "epoch": 12.689287717330343,
      "grad_norm": 0.34503835439682007,
      "learning_rate": 1.0361984803736843e-05,
      "loss": 0.049,
      "step": 181000
    },
    {
      "epoch": 12.696298373527762,
      "grad_norm": 0.39018112421035767,
      "learning_rate": 1.0340075543130571e-05,
      "loss": 0.0529,
      "step": 181100
    },
    {
      "epoch": 12.703309029725183,
      "grad_norm": 0.11002971231937408,
      "learning_rate": 1.0318166282524298e-05,
      "loss": 0.0524,
      "step": 181200
    },
    {
      "epoch": 12.710319685922602,
      "grad_norm": 0.22992509603500366,
      "learning_rate": 1.0296257021918025e-05,
      "loss": 0.0487,
      "step": 181300
    },
    {
      "epoch": 12.717330342120022,
      "grad_norm": 0.17969492077827454,
      "learning_rate": 1.0274347761311752e-05,
      "loss": 0.0512,
      "step": 181400
    },
    {
      "epoch": 12.724340998317443,
      "grad_norm": 0.16961687803268433,
      "learning_rate": 1.0252438500705479e-05,
      "loss": 0.0481,
      "step": 181500
    },
    {
      "epoch": 12.731351654514862,
      "grad_norm": 0.19455166161060333,
      "learning_rate": 1.0230529240099206e-05,
      "loss": 0.0506,
      "step": 181600
    },
    {
      "epoch": 12.738362310712283,
      "grad_norm": 0.295112282037735,
      "learning_rate": 1.0208619979492933e-05,
      "loss": 0.0488,
      "step": 181700
    },
    {
      "epoch": 12.745372966909702,
      "grad_norm": 0.13897916674613953,
      "learning_rate": 1.018671071888666e-05,
      "loss": 0.047,
      "step": 181800
    },
    {
      "epoch": 12.752383623107123,
      "grad_norm": 0.0970655232667923,
      "learning_rate": 1.0164801458280385e-05,
      "loss": 0.0465,
      "step": 181900
    },
    {
      "epoch": 12.759394279304543,
      "grad_norm": 0.21632829308509827,
      "learning_rate": 1.0142892197674112e-05,
      "loss": 0.0501,
      "step": 182000
    },
    {
      "epoch": 12.766404935501964,
      "grad_norm": 0.21264198422431946,
      "learning_rate": 1.012098293706784e-05,
      "loss": 0.048,
      "step": 182100
    },
    {
      "epoch": 12.773415591699383,
      "grad_norm": 0.360368549823761,
      "learning_rate": 1.0099073676461568e-05,
      "loss": 0.0506,
      "step": 182200
    },
    {
      "epoch": 12.780426247896804,
      "grad_norm": 0.12285670638084412,
      "learning_rate": 1.0077164415855295e-05,
      "loss": 0.0478,
      "step": 182300
    },
    {
      "epoch": 12.787436904094223,
      "grad_norm": 0.24450115859508514,
      "learning_rate": 1.0055255155249022e-05,
      "loss": 0.0514,
      "step": 182400
    },
    {
      "epoch": 12.794447560291644,
      "grad_norm": 0.20738837122917175,
      "learning_rate": 1.0033345894642749e-05,
      "loss": 0.049,
      "step": 182500
    },
    {
      "epoch": 12.801458216489063,
      "grad_norm": 0.1614075005054474,
      "learning_rate": 1.0011436634036476e-05,
      "loss": 0.0509,
      "step": 182600
    },
    {
      "epoch": 12.808468872686483,
      "grad_norm": 0.18303841352462769,
      "learning_rate": 9.989527373430201e-06,
      "loss": 0.0536,
      "step": 182700
    },
    {
      "epoch": 12.815479528883904,
      "grad_norm": 0.07922062277793884,
      "learning_rate": 9.967618112823928e-06,
      "loss": 0.0512,
      "step": 182800
    },
    {
      "epoch": 12.822490185081323,
      "grad_norm": 0.2575000524520874,
      "learning_rate": 9.945708852217655e-06,
      "loss": 0.0501,
      "step": 182900
    },
    {
      "epoch": 12.829500841278744,
      "grad_norm": 0.2539558708667755,
      "learning_rate": 9.923799591611382e-06,
      "loss": 0.0477,
      "step": 183000
    },
    {
      "epoch": 12.836511497476163,
      "grad_norm": 0.1971702128648758,
      "learning_rate": 9.901890331005109e-06,
      "loss": 0.0495,
      "step": 183100
    },
    {
      "epoch": 12.843522153673584,
      "grad_norm": 0.25398021936416626,
      "learning_rate": 9.879981070398836e-06,
      "loss": 0.0468,
      "step": 183200
    },
    {
      "epoch": 12.850532809871003,
      "grad_norm": 0.13670611381530762,
      "learning_rate": 9.858071809792565e-06,
      "loss": 0.0485,
      "step": 183300
    },
    {
      "epoch": 12.857543466068424,
      "grad_norm": 0.26444798707962036,
      "learning_rate": 9.836162549186292e-06,
      "loss": 0.0513,
      "step": 183400
    },
    {
      "epoch": 12.864554122265844,
      "grad_norm": 0.20435939729213715,
      "learning_rate": 9.814253288580019e-06,
      "loss": 0.0482,
      "step": 183500
    },
    {
      "epoch": 12.871564778463265,
      "grad_norm": 0.17308452725410461,
      "learning_rate": 9.792344027973744e-06,
      "loss": 0.0484,
      "step": 183600
    },
    {
      "epoch": 12.878575434660684,
      "grad_norm": 0.10831087827682495,
      "learning_rate": 9.770434767367471e-06,
      "loss": 0.0517,
      "step": 183700
    },
    {
      "epoch": 12.885586090858105,
      "grad_norm": 0.2297372967004776,
      "learning_rate": 9.748525506761198e-06,
      "loss": 0.0549,
      "step": 183800
    },
    {
      "epoch": 12.892596747055524,
      "grad_norm": 0.21546374261379242,
      "learning_rate": 9.726616246154925e-06,
      "loss": 0.0444,
      "step": 183900
    },
    {
      "epoch": 12.899607403252945,
      "grad_norm": 0.3727503716945648,
      "learning_rate": 9.704706985548652e-06,
      "loss": 0.0527,
      "step": 184000
    },
    {
      "epoch": 12.906618059450365,
      "grad_norm": 0.08048975467681885,
      "learning_rate": 9.682797724942379e-06,
      "loss": 0.0476,
      "step": 184100
    },
    {
      "epoch": 12.913628715647784,
      "grad_norm": 0.23626576364040375,
      "learning_rate": 9.660888464336106e-06,
      "loss": 0.0479,
      "step": 184200
    },
    {
      "epoch": 12.920639371845205,
      "grad_norm": 0.13045617938041687,
      "learning_rate": 9.638979203729833e-06,
      "loss": 0.0515,
      "step": 184300
    },
    {
      "epoch": 12.927650028042624,
      "grad_norm": 0.23353800177574158,
      "learning_rate": 9.61706994312356e-06,
      "loss": 0.0507,
      "step": 184400
    },
    {
      "epoch": 12.934660684240045,
      "grad_norm": 0.2133636325597763,
      "learning_rate": 9.595160682517287e-06,
      "loss": 0.0516,
      "step": 184500
    },
    {
      "epoch": 12.941671340437464,
      "grad_norm": 0.1178634762763977,
      "learning_rate": 9.573251421911014e-06,
      "loss": 0.0471,
      "step": 184600
    },
    {
      "epoch": 12.948681996634885,
      "grad_norm": 0.09889227896928787,
      "learning_rate": 9.55134216130474e-06,
      "loss": 0.0543,
      "step": 184700
    },
    {
      "epoch": 12.955692652832305,
      "grad_norm": 0.20783525705337524,
      "learning_rate": 9.529432900698468e-06,
      "loss": 0.0484,
      "step": 184800
    },
    {
      "epoch": 12.962703309029726,
      "grad_norm": 0.12057874351739883,
      "learning_rate": 9.507523640092195e-06,
      "loss": 0.05,
      "step": 184900
    },
    {
      "epoch": 12.969713965227145,
      "grad_norm": 0.13395442068576813,
      "learning_rate": 9.485614379485922e-06,
      "loss": 0.0513,
      "step": 185000
    },
    {
      "epoch": 12.976724621424566,
      "grad_norm": 0.12354043126106262,
      "learning_rate": 9.463705118879649e-06,
      "loss": 0.0473,
      "step": 185100
    },
    {
      "epoch": 12.983735277621985,
      "grad_norm": 0.21731150150299072,
      "learning_rate": 9.441795858273376e-06,
      "loss": 0.0452,
      "step": 185200
    },
    {
      "epoch": 12.990745933819406,
      "grad_norm": 0.11698029935359955,
      "learning_rate": 9.419886597667103e-06,
      "loss": 0.0483,
      "step": 185300
    },
    {
      "epoch": 12.997756590016825,
      "grad_norm": 0.26685988903045654,
      "learning_rate": 9.397977337060828e-06,
      "loss": 0.0484,
      "step": 185400
    },
    {
      "epoch": 13.0,
      "eval_accuracy_macro_0.5": 0.9797852039337158,
      "eval_accuracy_micro_0.5": 0.9797852635383606,
      "eval_accuracy_weighted_0.5": 0.9698570370674133,
      "eval_aucroc_macro": 0.8858851790428162,
      "eval_aucroc_micro": 0.8984791040420532,
      "eval_aucroc_weighted": 0.8948954343795776,
      "eval_f1_macro_0.5": 0.6904416680335999,
      "eval_f1_macro_0.6": 0.6585184931755066,
      "eval_f1_macro_0.7": 0.6104404330253601,
      "eval_f1_macro_0.8": 0.4059913158416748,
      "eval_f1_micro_0.5": 0.7269439101219177,
      "eval_f1_micro_0.6": 0.7025783658027649,
      "eval_f1_micro_0.7": 0.6620118021965027,
      "eval_f1_micro_0.8": 0.5938637852668762,
      "eval_f1_micro_0.9": 0.4604014456272125,
      "eval_f1_weighted_0.5": 0.7173606753349304,
      "eval_f1_weighted_0.6": 0.6859363913536072,
      "eval_f1_weighted_0.7": 0.6370930075645447,
      "eval_f1_weighted_0.8": 0.4177912175655365,
      "eval_loss": 0.04648469015955925,
      "eval_runtime": 69.7516,
      "eval_samples_per_second": 408.22,
      "eval_steps_per_second": 51.038,
      "step": 185432
    },
    {
      "epoch": 13.004767246214247,
      "grad_norm": 0.39141425490379333,
      "learning_rate": 9.376068076454557e-06,
      "loss": 0.0529,
      "step": 185500
    },
    {
      "epoch": 13.011777902411666,
      "grad_norm": 0.2584291100502014,
      "learning_rate": 9.354158815848284e-06,
      "loss": 0.0466,
      "step": 185600
    },
    {
      "epoch": 13.018788558609085,
      "grad_norm": 0.2869182527065277,
      "learning_rate": 9.33224955524201e-06,
      "loss": 0.0505,
      "step": 185700
    },
    {
      "epoch": 13.025799214806506,
      "grad_norm": 0.27271848917007446,
      "learning_rate": 9.310340294635737e-06,
      "loss": 0.0515,
      "step": 185800
    },
    {
      "epoch": 13.032809871003925,
      "grad_norm": 0.10385903716087341,
      "learning_rate": 9.288431034029464e-06,
      "loss": 0.0473,
      "step": 185900
    },
    {
      "epoch": 13.039820527201346,
      "grad_norm": 0.2201899141073227,
      "learning_rate": 9.266740866029253e-06,
      "loss": 0.0519,
      "step": 186000
    },
    {
      "epoch": 13.046831183398766,
      "grad_norm": 0.13123220205307007,
      "learning_rate": 9.24483160542298e-06,
      "loss": 0.0564,
      "step": 186100
    },
    {
      "epoch": 13.053841839596187,
      "grad_norm": 0.32849082350730896,
      "learning_rate": 9.222922344816707e-06,
      "loss": 0.0464,
      "step": 186200
    },
    {
      "epoch": 13.060852495793606,
      "grad_norm": 0.1887611299753189,
      "learning_rate": 9.201013084210434e-06,
      "loss": 0.0524,
      "step": 186300
    },
    {
      "epoch": 13.067863151991027,
      "grad_norm": 0.14073988795280457,
      "learning_rate": 9.179103823604161e-06,
      "loss": 0.0501,
      "step": 186400
    },
    {
      "epoch": 13.074873808188446,
      "grad_norm": 0.10244343429803848,
      "learning_rate": 9.157194562997888e-06,
      "loss": 0.0487,
      "step": 186500
    },
    {
      "epoch": 13.081884464385867,
      "grad_norm": 0.14234048128128052,
      "learning_rate": 9.135285302391615e-06,
      "loss": 0.0522,
      "step": 186600
    },
    {
      "epoch": 13.088895120583286,
      "grad_norm": 0.22975696623325348,
      "learning_rate": 9.113376041785342e-06,
      "loss": 0.046,
      "step": 186700
    },
    {
      "epoch": 13.095905776780707,
      "grad_norm": 0.17232844233512878,
      "learning_rate": 9.09146678117907e-06,
      "loss": 0.0468,
      "step": 186800
    },
    {
      "epoch": 13.102916432978127,
      "grad_norm": 0.34716323018074036,
      "learning_rate": 9.069557520572796e-06,
      "loss": 0.0464,
      "step": 186900
    },
    {
      "epoch": 13.109927089175546,
      "grad_norm": 0.16861800849437714,
      "learning_rate": 9.047648259966523e-06,
      "loss": 0.0498,
      "step": 187000
    },
    {
      "epoch": 13.116937745372967,
      "grad_norm": 0.17158350348472595,
      "learning_rate": 9.02573899936025e-06,
      "loss": 0.05,
      "step": 187100
    },
    {
      "epoch": 13.123948401570386,
      "grad_norm": 0.15646648406982422,
      "learning_rate": 9.003829738753977e-06,
      "loss": 0.0493,
      "step": 187200
    },
    {
      "epoch": 13.130959057767807,
      "grad_norm": 0.10218837112188339,
      "learning_rate": 8.981920478147704e-06,
      "loss": 0.0529,
      "step": 187300
    },
    {
      "epoch": 13.137969713965227,
      "grad_norm": 0.35047173500061035,
      "learning_rate": 8.960011217541431e-06,
      "loss": 0.0486,
      "step": 187400
    },
    {
      "epoch": 13.144980370162648,
      "grad_norm": 0.13153284788131714,
      "learning_rate": 8.938101956935158e-06,
      "loss": 0.0507,
      "step": 187500
    },
    {
      "epoch": 13.151991026360067,
      "grad_norm": 0.17614278197288513,
      "learning_rate": 8.916411788934947e-06,
      "loss": 0.0492,
      "step": 187600
    },
    {
      "epoch": 13.159001682557488,
      "grad_norm": 0.17261038720607758,
      "learning_rate": 8.894502528328674e-06,
      "loss": 0.0501,
      "step": 187700
    },
    {
      "epoch": 13.166012338754907,
      "grad_norm": 0.09936853498220444,
      "learning_rate": 8.872593267722401e-06,
      "loss": 0.0453,
      "step": 187800
    },
    {
      "epoch": 13.173022994952328,
      "grad_norm": 0.15585622191429138,
      "learning_rate": 8.850684007116128e-06,
      "loss": 0.0513,
      "step": 187900
    },
    {
      "epoch": 13.180033651149747,
      "grad_norm": 0.31918439269065857,
      "learning_rate": 8.828774746509855e-06,
      "loss": 0.0548,
      "step": 188000
    },
    {
      "epoch": 13.187044307347168,
      "grad_norm": 0.15145425498485565,
      "learning_rate": 8.806865485903582e-06,
      "loss": 0.053,
      "step": 188100
    },
    {
      "epoch": 13.194054963544588,
      "grad_norm": 0.13597504794597626,
      "learning_rate": 8.784956225297309e-06,
      "loss": 0.0471,
      "step": 188200
    },
    {
      "epoch": 13.201065619742009,
      "grad_norm": 0.12394046783447266,
      "learning_rate": 8.763046964691036e-06,
      "loss": 0.0501,
      "step": 188300
    },
    {
      "epoch": 13.208076275939428,
      "grad_norm": 0.0969388484954834,
      "learning_rate": 8.741137704084763e-06,
      "loss": 0.0479,
      "step": 188400
    },
    {
      "epoch": 13.215086932136847,
      "grad_norm": 0.1698625683784485,
      "learning_rate": 8.71922844347849e-06,
      "loss": 0.0495,
      "step": 188500
    },
    {
      "epoch": 13.222097588334268,
      "grad_norm": 0.23016062378883362,
      "learning_rate": 8.697319182872217e-06,
      "loss": 0.0501,
      "step": 188600
    },
    {
      "epoch": 13.229108244531687,
      "grad_norm": 0.14041617512702942,
      "learning_rate": 8.675409922265944e-06,
      "loss": 0.0503,
      "step": 188700
    },
    {
      "epoch": 13.236118900729108,
      "grad_norm": 0.2404697686433792,
      "learning_rate": 8.653500661659671e-06,
      "loss": 0.053,
      "step": 188800
    },
    {
      "epoch": 13.243129556926528,
      "grad_norm": 0.2510110139846802,
      "learning_rate": 8.631591401053398e-06,
      "loss": 0.0473,
      "step": 188900
    },
    {
      "epoch": 13.250140213123949,
      "grad_norm": 0.2683270275592804,
      "learning_rate": 8.609682140447125e-06,
      "loss": 0.046,
      "step": 189000
    },
    {
      "epoch": 13.257150869321368,
      "grad_norm": 0.3970464766025543,
      "learning_rate": 8.587772879840852e-06,
      "loss": 0.0525,
      "step": 189100
    },
    {
      "epoch": 13.264161525518789,
      "grad_norm": 0.13568073511123657,
      "learning_rate": 8.565863619234577e-06,
      "loss": 0.0485,
      "step": 189200
    },
    {
      "epoch": 13.271172181716208,
      "grad_norm": 0.2721889615058899,
      "learning_rate": 8.543954358628306e-06,
      "loss": 0.0467,
      "step": 189300
    },
    {
      "epoch": 13.27818283791363,
      "grad_norm": 0.30271708965301514,
      "learning_rate": 8.522045098022033e-06,
      "loss": 0.0469,
      "step": 189400
    },
    {
      "epoch": 13.285193494111049,
      "grad_norm": 0.20889294147491455,
      "learning_rate": 8.50013583741576e-06,
      "loss": 0.0515,
      "step": 189500
    },
    {
      "epoch": 13.29220415030847,
      "grad_norm": 0.1595102995634079,
      "learning_rate": 8.478226576809487e-06,
      "loss": 0.0514,
      "step": 189600
    },
    {
      "epoch": 13.299214806505889,
      "grad_norm": 0.2362813651561737,
      "learning_rate": 8.456317316203214e-06,
      "loss": 0.0493,
      "step": 189700
    },
    {
      "epoch": 13.30622546270331,
      "grad_norm": 0.19912999868392944,
      "learning_rate": 8.43440805559694e-06,
      "loss": 0.0487,
      "step": 189800
    },
    {
      "epoch": 13.313236118900729,
      "grad_norm": 0.06734614074230194,
      "learning_rate": 8.412498794990668e-06,
      "loss": 0.0563,
      "step": 189900
    },
    {
      "epoch": 13.320246775098148,
      "grad_norm": 0.15900875627994537,
      "learning_rate": 8.390589534384393e-06,
      "loss": 0.0514,
      "step": 190000
    },
    {
      "epoch": 13.32725743129557,
      "grad_norm": 0.2643444240093231,
      "learning_rate": 8.36868027377812e-06,
      "loss": 0.0523,
      "step": 190100
    },
    {
      "epoch": 13.334268087492989,
      "grad_norm": 0.18654397130012512,
      "learning_rate": 8.346771013171847e-06,
      "loss": 0.0467,
      "step": 190200
    },
    {
      "epoch": 13.34127874369041,
      "grad_norm": 0.25013983249664307,
      "learning_rate": 8.324861752565574e-06,
      "loss": 0.0502,
      "step": 190300
    },
    {
      "epoch": 13.348289399887829,
      "grad_norm": 0.12117615342140198,
      "learning_rate": 8.302952491959303e-06,
      "loss": 0.0477,
      "step": 190400
    },
    {
      "epoch": 13.35530005608525,
      "grad_norm": 0.23136445879936218,
      "learning_rate": 8.281262323959092e-06,
      "loss": 0.0478,
      "step": 190500
    },
    {
      "epoch": 13.36231071228267,
      "grad_norm": 0.18074412643909454,
      "learning_rate": 8.259353063352819e-06,
      "loss": 0.0499,
      "step": 190600
    },
    {
      "epoch": 13.36932136848009,
      "grad_norm": 0.14813736081123352,
      "learning_rate": 8.237443802746546e-06,
      "loss": 0.0527,
      "step": 190700
    },
    {
      "epoch": 13.37633202467751,
      "grad_norm": 0.16917084157466888,
      "learning_rate": 8.215534542140273e-06,
      "loss": 0.0469,
      "step": 190800
    },
    {
      "epoch": 13.38334268087493,
      "grad_norm": 0.14887867867946625,
      "learning_rate": 8.193625281534e-06,
      "loss": 0.0514,
      "step": 190900
    },
    {
      "epoch": 13.39035333707235,
      "grad_norm": 0.2835773229598999,
      "learning_rate": 8.171716020927727e-06,
      "loss": 0.048,
      "step": 191000
    },
    {
      "epoch": 13.39736399326977,
      "grad_norm": 0.1576717346906662,
      "learning_rate": 8.149806760321454e-06,
      "loss": 0.045,
      "step": 191100
    },
    {
      "epoch": 13.40437464946719,
      "grad_norm": 0.38534384965896606,
      "learning_rate": 8.12789749971518e-06,
      "loss": 0.0534,
      "step": 191200
    },
    {
      "epoch": 13.411385305664611,
      "grad_norm": 0.2960663437843323,
      "learning_rate": 8.105988239108907e-06,
      "loss": 0.0511,
      "step": 191300
    },
    {
      "epoch": 13.41839596186203,
      "grad_norm": 0.13400930166244507,
      "learning_rate": 8.084078978502633e-06,
      "loss": 0.0503,
      "step": 191400
    },
    {
      "epoch": 13.42540661805945,
      "grad_norm": 0.2118156999349594,
      "learning_rate": 8.06216971789636e-06,
      "loss": 0.0486,
      "step": 191500
    },
    {
      "epoch": 13.43241727425687,
      "grad_norm": 0.17653116583824158,
      "learning_rate": 8.040260457290087e-06,
      "loss": 0.0497,
      "step": 191600
    },
    {
      "epoch": 13.43942793045429,
      "grad_norm": 0.33398064970970154,
      "learning_rate": 8.018351196683814e-06,
      "loss": 0.0491,
      "step": 191700
    },
    {
      "epoch": 13.44643858665171,
      "grad_norm": 0.10857649892568588,
      "learning_rate": 7.996441936077542e-06,
      "loss": 0.0467,
      "step": 191800
    },
    {
      "epoch": 13.45344924284913,
      "grad_norm": 0.20441147685050964,
      "learning_rate": 7.97453267547127e-06,
      "loss": 0.0477,
      "step": 191900
    },
    {
      "epoch": 13.460459899046551,
      "grad_norm": 0.17893479764461517,
      "learning_rate": 7.952623414864996e-06,
      "loss": 0.0503,
      "step": 192000
    },
    {
      "epoch": 13.46747055524397,
      "grad_norm": 0.19538992643356323,
      "learning_rate": 7.930714154258723e-06,
      "loss": 0.0479,
      "step": 192100
    },
    {
      "epoch": 13.474481211441391,
      "grad_norm": 0.3196517527103424,
      "learning_rate": 7.90880489365245e-06,
      "loss": 0.0452,
      "step": 192200
    },
    {
      "epoch": 13.48149186763881,
      "grad_norm": 0.1583002507686615,
      "learning_rate": 7.886895633046176e-06,
      "loss": 0.0471,
      "step": 192300
    },
    {
      "epoch": 13.488502523836232,
      "grad_norm": 0.045253463089466095,
      "learning_rate": 7.864986372439903e-06,
      "loss": 0.0463,
      "step": 192400
    },
    {
      "epoch": 13.495513180033651,
      "grad_norm": 0.13910922408103943,
      "learning_rate": 7.84307711183363e-06,
      "loss": 0.0488,
      "step": 192500
    },
    {
      "epoch": 13.502523836231072,
      "grad_norm": 0.1664557009935379,
      "learning_rate": 7.821167851227356e-06,
      "loss": 0.0467,
      "step": 192600
    },
    {
      "epoch": 13.509534492428491,
      "grad_norm": 0.07337242364883423,
      "learning_rate": 7.799258590621083e-06,
      "loss": 0.0506,
      "step": 192700
    },
    {
      "epoch": 13.516545148625912,
      "grad_norm": 0.37085893750190735,
      "learning_rate": 7.77734933001481e-06,
      "loss": 0.049,
      "step": 192800
    },
    {
      "epoch": 13.523555804823332,
      "grad_norm": 0.0759512335062027,
      "learning_rate": 7.755440069408539e-06,
      "loss": 0.0538,
      "step": 192900
    },
    {
      "epoch": 13.53056646102075,
      "grad_norm": 0.14600825309753418,
      "learning_rate": 7.733530808802266e-06,
      "loss": 0.0465,
      "step": 193000
    },
    {
      "epoch": 13.537577117218172,
      "grad_norm": 0.15949079394340515,
      "learning_rate": 7.711840640802055e-06,
      "loss": 0.0524,
      "step": 193100
    },
    {
      "epoch": 13.544587773415591,
      "grad_norm": 0.12354330718517303,
      "learning_rate": 7.689931380195782e-06,
      "loss": 0.0478,
      "step": 193200
    },
    {
      "epoch": 13.551598429613012,
      "grad_norm": 0.17516711354255676,
      "learning_rate": 7.668022119589509e-06,
      "loss": 0.0489,
      "step": 193300
    },
    {
      "epoch": 13.558609085810431,
      "grad_norm": 0.07844232022762299,
      "learning_rate": 7.646112858983236e-06,
      "loss": 0.0521,
      "step": 193400
    },
    {
      "epoch": 13.565619742007852,
      "grad_norm": 0.24205808341503143,
      "learning_rate": 7.624203598376962e-06,
      "loss": 0.0471,
      "step": 193500
    },
    {
      "epoch": 13.572630398205272,
      "grad_norm": 0.15922266244888306,
      "learning_rate": 7.602294337770689e-06,
      "loss": 0.0478,
      "step": 193600
    },
    {
      "epoch": 13.579641054402693,
      "grad_norm": 0.24578455090522766,
      "learning_rate": 7.580385077164416e-06,
      "loss": 0.0473,
      "step": 193700
    },
    {
      "epoch": 13.586651710600112,
      "grad_norm": 0.1505800485610962,
      "learning_rate": 7.558475816558143e-06,
      "loss": 0.0449,
      "step": 193800
    },
    {
      "epoch": 13.593662366797533,
      "grad_norm": 0.23242810368537903,
      "learning_rate": 7.53656655595187e-06,
      "loss": 0.0506,
      "step": 193900
    },
    {
      "epoch": 13.600673022994952,
      "grad_norm": 0.13159312307834625,
      "learning_rate": 7.514657295345596e-06,
      "loss": 0.0482,
      "step": 194000
    },
    {
      "epoch": 13.607683679192373,
      "grad_norm": 0.15866178274154663,
      "learning_rate": 7.492748034739323e-06,
      "loss": 0.0458,
      "step": 194100
    },
    {
      "epoch": 13.614694335389792,
      "grad_norm": 0.37859418988227844,
      "learning_rate": 7.470838774133052e-06,
      "loss": 0.0472,
      "step": 194200
    },
    {
      "epoch": 13.621704991587212,
      "grad_norm": 0.36958983540534973,
      "learning_rate": 7.448929513526778e-06,
      "loss": 0.0515,
      "step": 194300
    },
    {
      "epoch": 13.628715647784633,
      "grad_norm": 0.22422266006469727,
      "learning_rate": 7.427020252920505e-06,
      "loss": 0.0468,
      "step": 194400
    },
    {
      "epoch": 13.635726303982052,
      "grad_norm": 0.1641244888305664,
      "learning_rate": 7.405110992314232e-06,
      "loss": 0.0462,
      "step": 194500
    },
    {
      "epoch": 13.642736960179473,
      "grad_norm": 0.1748901605606079,
      "learning_rate": 7.383201731707959e-06,
      "loss": 0.0497,
      "step": 194600
    },
    {
      "epoch": 13.649747616376892,
      "grad_norm": 0.211730495095253,
      "learning_rate": 7.361292471101686e-06,
      "loss": 0.0488,
      "step": 194700
    },
    {
      "epoch": 13.656758272574313,
      "grad_norm": 0.0906824916601181,
      "learning_rate": 7.339383210495412e-06,
      "loss": 0.0485,
      "step": 194800
    },
    {
      "epoch": 13.663768928771733,
      "grad_norm": 0.23049432039260864,
      "learning_rate": 7.317473949889139e-06,
      "loss": 0.0517,
      "step": 194900
    },
    {
      "epoch": 13.670779584969154,
      "grad_norm": 0.2710208594799042,
      "learning_rate": 7.295564689282866e-06,
      "loss": 0.0519,
      "step": 195000
    },
    {
      "epoch": 13.677790241166573,
      "grad_norm": Infinity,
      "learning_rate": 7.273874521282656e-06,
      "loss": 0.0477,
      "step": 195100
    },
    {
      "epoch": 13.684800897363994,
      "grad_norm": 0.13618367910385132,
      "learning_rate": 7.251965260676383e-06,
      "loss": 0.0455,
      "step": 195200
    },
    {
      "epoch": 13.691811553561413,
      "grad_norm": 0.28263920545578003,
      "learning_rate": 7.23005600007011e-06,
      "loss": 0.0513,
      "step": 195300
    },
    {
      "epoch": 13.698822209758834,
      "grad_norm": 0.18916994333267212,
      "learning_rate": 7.208146739463836e-06,
      "loss": 0.0529,
      "step": 195400
    },
    {
      "epoch": 13.705832865956253,
      "grad_norm": 0.0922689288854599,
      "learning_rate": 7.186237478857565e-06,
      "loss": 0.0483,
      "step": 195500
    },
    {
      "epoch": 13.712843522153674,
      "grad_norm": 0.3624502718448639,
      "learning_rate": 7.164328218251292e-06,
      "loss": 0.0503,
      "step": 195600
    },
    {
      "epoch": 13.719854178351094,
      "grad_norm": 0.23257550597190857,
      "learning_rate": 7.142418957645018e-06,
      "loss": 0.0501,
      "step": 195700
    },
    {
      "epoch": 13.726864834548513,
      "grad_norm": 0.15400433540344238,
      "learning_rate": 7.120509697038745e-06,
      "loss": 0.0527,
      "step": 195800
    },
    {
      "epoch": 13.733875490745934,
      "grad_norm": 0.11649874597787857,
      "learning_rate": 7.098600436432472e-06,
      "loss": 0.052,
      "step": 195900
    },
    {
      "epoch": 13.740886146943353,
      "grad_norm": 0.0993514284491539,
      "learning_rate": 7.076691175826199e-06,
      "loss": 0.0469,
      "step": 196000
    },
    {
      "epoch": 13.747896803140774,
      "grad_norm": 0.3357084393501282,
      "learning_rate": 7.054781915219926e-06,
      "loss": 0.0492,
      "step": 196100
    },
    {
      "epoch": 13.754907459338193,
      "grad_norm": 0.1964552104473114,
      "learning_rate": 7.032872654613653e-06,
      "loss": 0.0505,
      "step": 196200
    },
    {
      "epoch": 13.761918115535615,
      "grad_norm": 0.14757883548736572,
      "learning_rate": 7.010963394007379e-06,
      "loss": 0.0471,
      "step": 196300
    },
    {
      "epoch": 13.768928771733034,
      "grad_norm": 0.142971932888031,
      "learning_rate": 6.989054133401106e-06,
      "loss": 0.0489,
      "step": 196400
    },
    {
      "epoch": 13.775939427930455,
      "grad_norm": 0.2768007516860962,
      "learning_rate": 6.967144872794833e-06,
      "loss": 0.0538,
      "step": 196500
    },
    {
      "epoch": 13.782950084127874,
      "grad_norm": 0.11605502665042877,
      "learning_rate": 6.94523561218856e-06,
      "loss": 0.0493,
      "step": 196600
    },
    {
      "epoch": 13.789960740325295,
      "grad_norm": 0.15357649326324463,
      "learning_rate": 6.9233263515822875e-06,
      "loss": 0.0495,
      "step": 196700
    },
    {
      "epoch": 13.796971396522714,
      "grad_norm": 0.2539023458957672,
      "learning_rate": 6.9014170909760145e-06,
      "loss": 0.0502,
      "step": 196800
    },
    {
      "epoch": 13.803982052720135,
      "grad_norm": 0.0690602958202362,
      "learning_rate": 6.8795078303697415e-06,
      "loss": 0.0479,
      "step": 196900
    },
    {
      "epoch": 13.810992708917555,
      "grad_norm": 0.3887665867805481,
      "learning_rate": 6.8575985697634685e-06,
      "loss": 0.0482,
      "step": 197000
    },
    {
      "epoch": 13.818003365114976,
      "grad_norm": 0.19624227285385132,
      "learning_rate": 6.835689309157195e-06,
      "loss": 0.0457,
      "step": 197100
    },
    {
      "epoch": 13.825014021312395,
      "grad_norm": 0.5713229179382324,
      "learning_rate": 6.813780048550922e-06,
      "loss": 0.0514,
      "step": 197200
    },
    {
      "epoch": 13.832024677509814,
      "grad_norm": 0.2785390019416809,
      "learning_rate": 6.7918707879446486e-06,
      "loss": 0.0503,
      "step": 197300
    },
    {
      "epoch": 13.839035333707235,
      "grad_norm": 0.2308494597673416,
      "learning_rate": 6.7699615273383755e-06,
      "loss": 0.0465,
      "step": 197400
    },
    {
      "epoch": 13.846045989904654,
      "grad_norm": 0.20758488774299622,
      "learning_rate": 6.7480522667321025e-06,
      "loss": 0.0505,
      "step": 197500
    },
    {
      "epoch": 13.853056646102075,
      "grad_norm": 0.20303182303905487,
      "learning_rate": 6.726143006125829e-06,
      "loss": 0.0465,
      "step": 197600
    },
    {
      "epoch": 13.860067302299495,
      "grad_norm": 0.1727713793516159,
      "learning_rate": 6.704233745519556e-06,
      "loss": 0.0523,
      "step": 197700
    },
    {
      "epoch": 13.867077958496916,
      "grad_norm": 0.37109678983688354,
      "learning_rate": 6.682324484913284e-06,
      "loss": 0.0465,
      "step": 197800
    },
    {
      "epoch": 13.874088614694335,
      "grad_norm": 0.2263137549161911,
      "learning_rate": 6.660415224307011e-06,
      "loss": 0.05,
      "step": 197900
    },
    {
      "epoch": 13.881099270891756,
      "grad_norm": 0.1397319883108139,
      "learning_rate": 6.638505963700737e-06,
      "loss": 0.0477,
      "step": 198000
    },
    {
      "epoch": 13.888109927089175,
      "grad_norm": 0.1231321468949318,
      "learning_rate": 6.616596703094464e-06,
      "loss": 0.0518,
      "step": 198100
    },
    {
      "epoch": 13.895120583286596,
      "grad_norm": 0.12923763692378998,
      "learning_rate": 6.594687442488191e-06,
      "loss": 0.0477,
      "step": 198200
    },
    {
      "epoch": 13.902131239484016,
      "grad_norm": 0.4924907088279724,
      "learning_rate": 6.572997274487981e-06,
      "loss": 0.0498,
      "step": 198300
    },
    {
      "epoch": 13.909141895681437,
      "grad_norm": 0.16118265688419342,
      "learning_rate": 6.551088013881708e-06,
      "loss": 0.0518,
      "step": 198400
    },
    {
      "epoch": 13.916152551878856,
      "grad_norm": 0.2528820335865021,
      "learning_rate": 6.529178753275434e-06,
      "loss": 0.0496,
      "step": 198500
    },
    {
      "epoch": 13.923163208076275,
      "grad_norm": 0.17417427897453308,
      "learning_rate": 6.507269492669161e-06,
      "loss": 0.0502,
      "step": 198600
    },
    {
      "epoch": 13.930173864273696,
      "grad_norm": 0.1855926662683487,
      "learning_rate": 6.485360232062888e-06,
      "loss": 0.0487,
      "step": 198700
    },
    {
      "epoch": 13.937184520471115,
      "grad_norm": 0.2708994150161743,
      "learning_rate": 6.463450971456615e-06,
      "loss": 0.0484,
      "step": 198800
    },
    {
      "epoch": 13.944195176668536,
      "grad_norm": 0.388204962015152,
      "learning_rate": 6.441541710850342e-06,
      "loss": 0.0471,
      "step": 198900
    },
    {
      "epoch": 13.951205832865956,
      "grad_norm": 0.0761943832039833,
      "learning_rate": 6.419632450244069e-06,
      "loss": 0.0478,
      "step": 199000
    },
    {
      "epoch": 13.958216489063377,
      "grad_norm": 0.2372315376996994,
      "learning_rate": 6.397723189637797e-06,
      "loss": 0.0516,
      "step": 199100
    },
    {
      "epoch": 13.965227145260796,
      "grad_norm": 0.20958887040615082,
      "learning_rate": 6.375813929031524e-06,
      "loss": 0.0498,
      "step": 199200
    },
    {
      "epoch": 13.972237801458217,
      "grad_norm": 0.3648304343223572,
      "learning_rate": 6.353904668425251e-06,
      "loss": 0.0487,
      "step": 199300
    },
    {
      "epoch": 13.979248457655636,
      "grad_norm": 0.27895283699035645,
      "learning_rate": 6.331995407818977e-06,
      "loss": 0.0501,
      "step": 199400
    },
    {
      "epoch": 13.986259113853057,
      "grad_norm": 0.20626971125602722,
      "learning_rate": 6.310086147212704e-06,
      "loss": 0.0513,
      "step": 199500
    },
    {
      "epoch": 13.993269770050476,
      "grad_norm": 0.23091189563274384,
      "learning_rate": 6.288176886606431e-06,
      "loss": 0.0526,
      "step": 199600
    },
    {
      "epoch": 14.0,
      "eval_accuracy_macro_0.5": 0.9798807501792908,
      "eval_accuracy_micro_0.5": 0.9798807501792908,
      "eval_accuracy_weighted_0.5": 0.9699613451957703,
      "eval_aucroc_macro": 0.8873434662818909,
      "eval_aucroc_micro": 0.9000895023345947,
      "eval_aucroc_weighted": 0.8964175581932068,
      "eval_f1_macro_0.5": 0.6940516829490662,
      "eval_f1_macro_0.6": 0.6625502109527588,
      "eval_f1_macro_0.7": 0.6163719892501831,
      "eval_f1_macro_0.8": 0.4128677248954773,
      "eval_f1_micro_0.5": 0.7297520637512207,
      "eval_f1_micro_0.6": 0.7059974670410156,
      "eval_f1_micro_0.7": 0.666632890701294,
      "eval_f1_micro_0.8": 0.59928959608078,
      "eval_f1_micro_0.9": 0.466714471578598,
      "eval_f1_weighted_0.5": 0.7207556366920471,
      "eval_f1_weighted_0.6": 0.6902650594711304,
      "eval_f1_weighted_0.7": 0.6431678533554077,
      "eval_f1_weighted_0.8": 0.4251626133918762,
      "eval_loss": 0.046378836035728455,
      "eval_runtime": 69.2049,
      "eval_samples_per_second": 411.445,
      "eval_steps_per_second": 51.441,
      "step": 199696
    }
  ],
  "logging_steps": 100,
  "max_steps": 228224,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 16,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5056583297612160.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
