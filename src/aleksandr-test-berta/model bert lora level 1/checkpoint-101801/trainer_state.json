{
  "best_metric": 0.814548134803772,
  "best_model_checkpoint": "aleksandr-test-berta/model bert lora level 1/checkpoint-101801",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 101801,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00687616035205941,
      "grad_norm": 0.30092722177505493,
      "learning_rate": 4.996131827324772e-05,
      "loss": 0.3468,
      "step": 100
    },
    {
      "epoch": 0.01375232070411882,
      "grad_norm": 0.24770225584506989,
      "learning_rate": 4.9918338576856295e-05,
      "loss": 0.1481,
      "step": 200
    },
    {
      "epoch": 0.02062848105617823,
      "grad_norm": 0.20923106372356415,
      "learning_rate": 4.9875358880464876e-05,
      "loss": 0.1387,
      "step": 300
    },
    {
      "epoch": 0.02750464140823764,
      "grad_norm": 0.2593066990375519,
      "learning_rate": 4.983237918407345e-05,
      "loss": 0.1278,
      "step": 400
    },
    {
      "epoch": 0.03438080176029705,
      "grad_norm": 0.187103271484375,
      "learning_rate": 4.978939948768202e-05,
      "loss": 0.1209,
      "step": 500
    },
    {
      "epoch": 0.04125696211235646,
      "grad_norm": 0.26272523403167725,
      "learning_rate": 4.97464197912906e-05,
      "loss": 0.1189,
      "step": 600
    },
    {
      "epoch": 0.04813312246441587,
      "grad_norm": 0.20948486030101776,
      "learning_rate": 4.970344009489917e-05,
      "loss": 0.1086,
      "step": 700
    },
    {
      "epoch": 0.05500928281647528,
      "grad_norm": 0.21765850484371185,
      "learning_rate": 4.9660460398507745e-05,
      "loss": 0.0997,
      "step": 800
    },
    {
      "epoch": 0.06188544316853469,
      "grad_norm": 0.1578366458415985,
      "learning_rate": 4.961748070211632e-05,
      "loss": 0.094,
      "step": 900
    },
    {
      "epoch": 0.0687616035205941,
      "grad_norm": 0.15749506652355194,
      "learning_rate": 4.95745010057249e-05,
      "loss": 0.0874,
      "step": 1000
    },
    {
      "epoch": 0.07563776387265352,
      "grad_norm": 0.21348530054092407,
      "learning_rate": 4.9531521309333474e-05,
      "loss": 0.085,
      "step": 1100
    },
    {
      "epoch": 0.08251392422471292,
      "grad_norm": 0.24414557218551636,
      "learning_rate": 4.948854161294205e-05,
      "loss": 0.0788,
      "step": 1200
    },
    {
      "epoch": 0.08939008457677233,
      "grad_norm": 0.16495798528194427,
      "learning_rate": 4.944556191655063e-05,
      "loss": 0.0782,
      "step": 1300
    },
    {
      "epoch": 0.09626624492883173,
      "grad_norm": 0.16688282787799835,
      "learning_rate": 4.94025822201592e-05,
      "loss": 0.0736,
      "step": 1400
    },
    {
      "epoch": 0.10314240528089115,
      "grad_norm": 0.15375916659832,
      "learning_rate": 4.9359602523767776e-05,
      "loss": 0.0726,
      "step": 1500
    },
    {
      "epoch": 0.11001856563295057,
      "grad_norm": 0.20613963901996613,
      "learning_rate": 4.931662282737635e-05,
      "loss": 0.0684,
      "step": 1600
    },
    {
      "epoch": 0.11689472598500997,
      "grad_norm": 0.15705429017543793,
      "learning_rate": 4.9273643130984924e-05,
      "loss": 0.0694,
      "step": 1700
    },
    {
      "epoch": 0.12377088633706938,
      "grad_norm": 0.2128504067659378,
      "learning_rate": 4.92306634345935e-05,
      "loss": 0.067,
      "step": 1800
    },
    {
      "epoch": 0.1306470466891288,
      "grad_norm": 0.23770561814308167,
      "learning_rate": 4.918768373820208e-05,
      "loss": 0.0647,
      "step": 1900
    },
    {
      "epoch": 0.1375232070411882,
      "grad_norm": 0.16240869462490082,
      "learning_rate": 4.914470404181065e-05,
      "loss": 0.065,
      "step": 2000
    },
    {
      "epoch": 0.1443993673932476,
      "grad_norm": 0.27431342005729675,
      "learning_rate": 4.9101724345419226e-05,
      "loss": 0.0623,
      "step": 2100
    },
    {
      "epoch": 0.15127552774530703,
      "grad_norm": 0.17490911483764648,
      "learning_rate": 4.90587446490278e-05,
      "loss": 0.059,
      "step": 2200
    },
    {
      "epoch": 0.15815168809736643,
      "grad_norm": 0.19477123022079468,
      "learning_rate": 4.901576495263638e-05,
      "loss": 0.0635,
      "step": 2300
    },
    {
      "epoch": 0.16502784844942583,
      "grad_norm": 0.19840486347675323,
      "learning_rate": 4.8972785256244955e-05,
      "loss": 0.0614,
      "step": 2400
    },
    {
      "epoch": 0.17190400880148526,
      "grad_norm": 0.1744128167629242,
      "learning_rate": 4.892980555985353e-05,
      "loss": 0.0579,
      "step": 2500
    },
    {
      "epoch": 0.17878016915354467,
      "grad_norm": 0.22932390868663788,
      "learning_rate": 4.88868258634621e-05,
      "loss": 0.0615,
      "step": 2600
    },
    {
      "epoch": 0.18565632950560407,
      "grad_norm": 0.19861532747745514,
      "learning_rate": 4.8843846167070677e-05,
      "loss": 0.0604,
      "step": 2700
    },
    {
      "epoch": 0.19253248985766347,
      "grad_norm": 0.13746511936187744,
      "learning_rate": 4.880086647067925e-05,
      "loss": 0.0585,
      "step": 2800
    },
    {
      "epoch": 0.1994086502097229,
      "grad_norm": 0.2503070831298828,
      "learning_rate": 4.875788677428783e-05,
      "loss": 0.0577,
      "step": 2900
    },
    {
      "epoch": 0.2062848105617823,
      "grad_norm": 0.1423463672399521,
      "learning_rate": 4.8714907077896405e-05,
      "loss": 0.0591,
      "step": 3000
    },
    {
      "epoch": 0.2131609709138417,
      "grad_norm": 0.24653631448745728,
      "learning_rate": 4.867192738150498e-05,
      "loss": 0.059,
      "step": 3100
    },
    {
      "epoch": 0.22003713126590113,
      "grad_norm": 0.17719900608062744,
      "learning_rate": 4.862894768511356e-05,
      "loss": 0.0609,
      "step": 3200
    },
    {
      "epoch": 0.22691329161796053,
      "grad_norm": 0.14229488372802734,
      "learning_rate": 4.8585967988722134e-05,
      "loss": 0.0564,
      "step": 3300
    },
    {
      "epoch": 0.23378945197001993,
      "grad_norm": 0.24206799268722534,
      "learning_rate": 4.854298829233071e-05,
      "loss": 0.0579,
      "step": 3400
    },
    {
      "epoch": 0.24066561232207936,
      "grad_norm": 0.14873766899108887,
      "learning_rate": 4.850000859593928e-05,
      "loss": 0.0573,
      "step": 3500
    },
    {
      "epoch": 0.24754177267413877,
      "grad_norm": 0.1297047734260559,
      "learning_rate": 4.8457028899547855e-05,
      "loss": 0.0558,
      "step": 3600
    },
    {
      "epoch": 0.2544179330261982,
      "grad_norm": 0.18265873193740845,
      "learning_rate": 4.841404920315643e-05,
      "loss": 0.0539,
      "step": 3700
    },
    {
      "epoch": 0.2612940933782576,
      "grad_norm": 0.2094983011484146,
      "learning_rate": 4.8371069506765e-05,
      "loss": 0.057,
      "step": 3800
    },
    {
      "epoch": 0.268170253730317,
      "grad_norm": 0.20909862220287323,
      "learning_rate": 4.8328089810373584e-05,
      "loss": 0.0572,
      "step": 3900
    },
    {
      "epoch": 0.2750464140823764,
      "grad_norm": 0.18866996467113495,
      "learning_rate": 4.828511011398216e-05,
      "loss": 0.0553,
      "step": 4000
    },
    {
      "epoch": 0.2819225744344358,
      "grad_norm": 0.18081361055374146,
      "learning_rate": 4.824213041759073e-05,
      "loss": 0.0548,
      "step": 4100
    },
    {
      "epoch": 0.2887987347864952,
      "grad_norm": 0.20689181983470917,
      "learning_rate": 4.819915072119931e-05,
      "loss": 0.0528,
      "step": 4200
    },
    {
      "epoch": 0.2956748951385546,
      "grad_norm": 0.16727231442928314,
      "learning_rate": 4.8156171024807886e-05,
      "loss": 0.0535,
      "step": 4300
    },
    {
      "epoch": 0.30255105549061406,
      "grad_norm": 0.147002711892128,
      "learning_rate": 4.811319132841646e-05,
      "loss": 0.0516,
      "step": 4400
    },
    {
      "epoch": 0.30942721584267346,
      "grad_norm": 0.14130781590938568,
      "learning_rate": 4.8070211632025034e-05,
      "loss": 0.0527,
      "step": 4500
    },
    {
      "epoch": 0.31630337619473287,
      "grad_norm": 0.16992172598838806,
      "learning_rate": 4.802723193563361e-05,
      "loss": 0.0536,
      "step": 4600
    },
    {
      "epoch": 0.32317953654679227,
      "grad_norm": 0.19366934895515442,
      "learning_rate": 4.798425223924218e-05,
      "loss": 0.0509,
      "step": 4700
    },
    {
      "epoch": 0.33005569689885167,
      "grad_norm": 0.19381797313690186,
      "learning_rate": 4.7941272542850756e-05,
      "loss": 0.0542,
      "step": 4800
    },
    {
      "epoch": 0.33693185725091107,
      "grad_norm": 0.15164977312088013,
      "learning_rate": 4.7898292846459336e-05,
      "loss": 0.0539,
      "step": 4900
    },
    {
      "epoch": 0.34380801760297053,
      "grad_norm": 0.2075648456811905,
      "learning_rate": 4.785531315006791e-05,
      "loss": 0.051,
      "step": 5000
    },
    {
      "epoch": 0.35068417795502993,
      "grad_norm": 0.15858739614486694,
      "learning_rate": 4.7812333453676484e-05,
      "loss": 0.0507,
      "step": 5100
    },
    {
      "epoch": 0.35756033830708933,
      "grad_norm": 0.12365575134754181,
      "learning_rate": 4.7769353757285065e-05,
      "loss": 0.0512,
      "step": 5200
    },
    {
      "epoch": 0.36443649865914873,
      "grad_norm": 0.17980292439460754,
      "learning_rate": 4.772637406089364e-05,
      "loss": 0.0516,
      "step": 5300
    },
    {
      "epoch": 0.37131265901120813,
      "grad_norm": 0.13439737260341644,
      "learning_rate": 4.768339436450221e-05,
      "loss": 0.0525,
      "step": 5400
    },
    {
      "epoch": 0.37818881936326754,
      "grad_norm": 0.2690430283546448,
      "learning_rate": 4.764041466811079e-05,
      "loss": 0.05,
      "step": 5500
    },
    {
      "epoch": 0.38506497971532694,
      "grad_norm": 0.31408894062042236,
      "learning_rate": 4.759743497171936e-05,
      "loss": 0.0496,
      "step": 5600
    },
    {
      "epoch": 0.3919411400673864,
      "grad_norm": 0.17644144594669342,
      "learning_rate": 4.7554455275327935e-05,
      "loss": 0.0519,
      "step": 5700
    },
    {
      "epoch": 0.3988173004194458,
      "grad_norm": 0.19609381258487701,
      "learning_rate": 4.7511475578936515e-05,
      "loss": 0.0537,
      "step": 5800
    },
    {
      "epoch": 0.4056934607715052,
      "grad_norm": 0.134985089302063,
      "learning_rate": 4.746849588254509e-05,
      "loss": 0.0528,
      "step": 5900
    },
    {
      "epoch": 0.4125696211235646,
      "grad_norm": 0.16980887949466705,
      "learning_rate": 4.742551618615366e-05,
      "loss": 0.0512,
      "step": 6000
    },
    {
      "epoch": 0.419445781475624,
      "grad_norm": 0.16040010750293732,
      "learning_rate": 4.738253648976224e-05,
      "loss": 0.0482,
      "step": 6100
    },
    {
      "epoch": 0.4263219418276834,
      "grad_norm": 0.07654038816690445,
      "learning_rate": 4.733955679337082e-05,
      "loss": 0.0502,
      "step": 6200
    },
    {
      "epoch": 0.4331981021797428,
      "grad_norm": 0.17160287499427795,
      "learning_rate": 4.729657709697939e-05,
      "loss": 0.0467,
      "step": 6300
    },
    {
      "epoch": 0.44007426253180226,
      "grad_norm": 0.09655546396970749,
      "learning_rate": 4.7253597400587965e-05,
      "loss": 0.0501,
      "step": 6400
    },
    {
      "epoch": 0.44695042288386166,
      "grad_norm": 0.20460852980613708,
      "learning_rate": 4.721061770419654e-05,
      "loss": 0.0493,
      "step": 6500
    },
    {
      "epoch": 0.45382658323592107,
      "grad_norm": 0.17131181061267853,
      "learning_rate": 4.716763800780511e-05,
      "loss": 0.05,
      "step": 6600
    },
    {
      "epoch": 0.46070274358798047,
      "grad_norm": 0.11618433892726898,
      "learning_rate": 4.712465831141369e-05,
      "loss": 0.0491,
      "step": 6700
    },
    {
      "epoch": 0.46757890394003987,
      "grad_norm": 0.2851440906524658,
      "learning_rate": 4.708167861502227e-05,
      "loss": 0.0513,
      "step": 6800
    },
    {
      "epoch": 0.47445506429209927,
      "grad_norm": 0.18394480645656586,
      "learning_rate": 4.703869891863084e-05,
      "loss": 0.0475,
      "step": 6900
    },
    {
      "epoch": 0.48133122464415873,
      "grad_norm": 0.2271178513765335,
      "learning_rate": 4.6995719222239416e-05,
      "loss": 0.0492,
      "step": 7000
    },
    {
      "epoch": 0.48820738499621813,
      "grad_norm": 0.23462074995040894,
      "learning_rate": 4.6952739525847996e-05,
      "loss": 0.0479,
      "step": 7100
    },
    {
      "epoch": 0.49508354534827753,
      "grad_norm": 0.15596838295459747,
      "learning_rate": 4.690975982945657e-05,
      "loss": 0.0492,
      "step": 7200
    },
    {
      "epoch": 0.5019597057003369,
      "grad_norm": 0.13506004214286804,
      "learning_rate": 4.6866780133065144e-05,
      "loss": 0.047,
      "step": 7300
    },
    {
      "epoch": 0.5088358660523964,
      "grad_norm": 0.09999419003725052,
      "learning_rate": 4.682380043667372e-05,
      "loss": 0.0479,
      "step": 7400
    },
    {
      "epoch": 0.5157120264044558,
      "grad_norm": 0.2801929712295532,
      "learning_rate": 4.678082074028229e-05,
      "loss": 0.0454,
      "step": 7500
    },
    {
      "epoch": 0.5225881867565152,
      "grad_norm": 0.16510459780693054,
      "learning_rate": 4.6737841043890866e-05,
      "loss": 0.0498,
      "step": 7600
    },
    {
      "epoch": 0.5294643471085746,
      "grad_norm": 0.24624404311180115,
      "learning_rate": 4.669486134749944e-05,
      "loss": 0.0499,
      "step": 7700
    },
    {
      "epoch": 0.536340507460634,
      "grad_norm": 0.13571828603744507,
      "learning_rate": 4.665188165110802e-05,
      "loss": 0.0503,
      "step": 7800
    },
    {
      "epoch": 0.5432166678126934,
      "grad_norm": 0.20271217823028564,
      "learning_rate": 4.6608901954716594e-05,
      "loss": 0.0468,
      "step": 7900
    },
    {
      "epoch": 0.5500928281647528,
      "grad_norm": 0.1488831490278244,
      "learning_rate": 4.656592225832517e-05,
      "loss": 0.0457,
      "step": 8000
    },
    {
      "epoch": 0.5569689885168122,
      "grad_norm": 0.1745973378419876,
      "learning_rate": 4.652294256193375e-05,
      "loss": 0.0459,
      "step": 8100
    },
    {
      "epoch": 0.5638451488688716,
      "grad_norm": 0.27686598896980286,
      "learning_rate": 4.647996286554232e-05,
      "loss": 0.0503,
      "step": 8200
    },
    {
      "epoch": 0.570721309220931,
      "grad_norm": 0.14510418474674225,
      "learning_rate": 4.64369831691509e-05,
      "loss": 0.0488,
      "step": 8300
    },
    {
      "epoch": 0.5775974695729904,
      "grad_norm": 0.30423516035079956,
      "learning_rate": 4.6394433269723386e-05,
      "loss": 0.0487,
      "step": 8400
    },
    {
      "epoch": 0.5844736299250498,
      "grad_norm": 0.17414771020412445,
      "learning_rate": 4.635145357333196e-05,
      "loss": 0.0481,
      "step": 8500
    },
    {
      "epoch": 0.5913497902771092,
      "grad_norm": 0.17809025943279266,
      "learning_rate": 4.6308473876940534e-05,
      "loss": 0.0492,
      "step": 8600
    },
    {
      "epoch": 0.5982259506291687,
      "grad_norm": 0.14381840825080872,
      "learning_rate": 4.6265494180549114e-05,
      "loss": 0.048,
      "step": 8700
    },
    {
      "epoch": 0.6051021109812281,
      "grad_norm": 0.22336573898792267,
      "learning_rate": 4.622251448415769e-05,
      "loss": 0.0485,
      "step": 8800
    },
    {
      "epoch": 0.6119782713332875,
      "grad_norm": 0.19028978049755096,
      "learning_rate": 4.617953478776626e-05,
      "loss": 0.0488,
      "step": 8900
    },
    {
      "epoch": 0.6188544316853469,
      "grad_norm": 0.2384057492017746,
      "learning_rate": 4.6136555091374836e-05,
      "loss": 0.0461,
      "step": 9000
    },
    {
      "epoch": 0.6257305920374063,
      "grad_norm": 0.24688708782196045,
      "learning_rate": 4.609357539498341e-05,
      "loss": 0.0476,
      "step": 9100
    },
    {
      "epoch": 0.6326067523894657,
      "grad_norm": 0.19242005050182343,
      "learning_rate": 4.6050595698591984e-05,
      "loss": 0.0478,
      "step": 9200
    },
    {
      "epoch": 0.6394829127415251,
      "grad_norm": 0.15539692342281342,
      "learning_rate": 4.6007616002200565e-05,
      "loss": 0.0463,
      "step": 9300
    },
    {
      "epoch": 0.6463590730935845,
      "grad_norm": 0.17627686262130737,
      "learning_rate": 4.596463630580914e-05,
      "loss": 0.0439,
      "step": 9400
    },
    {
      "epoch": 0.6532352334456439,
      "grad_norm": 0.14807520806789398,
      "learning_rate": 4.592165660941771e-05,
      "loss": 0.0483,
      "step": 9500
    },
    {
      "epoch": 0.6601113937977033,
      "grad_norm": 0.1343754082918167,
      "learning_rate": 4.5878676913026286e-05,
      "loss": 0.0471,
      "step": 9600
    },
    {
      "epoch": 0.6669875541497627,
      "grad_norm": 0.14003334939479828,
      "learning_rate": 4.583569721663487e-05,
      "loss": 0.0462,
      "step": 9700
    },
    {
      "epoch": 0.6738637145018221,
      "grad_norm": 0.3958102762699127,
      "learning_rate": 4.579271752024344e-05,
      "loss": 0.0451,
      "step": 9800
    },
    {
      "epoch": 0.6807398748538815,
      "grad_norm": 0.31880754232406616,
      "learning_rate": 4.5749737823852015e-05,
      "loss": 0.0474,
      "step": 9900
    },
    {
      "epoch": 0.6876160352059411,
      "grad_norm": 0.23381301760673523,
      "learning_rate": 4.570675812746059e-05,
      "loss": 0.0462,
      "step": 10000
    },
    {
      "epoch": 0.6944921955580005,
      "grad_norm": 0.2467617243528366,
      "learning_rate": 4.566377843106916e-05,
      "loss": 0.0477,
      "step": 10100
    },
    {
      "epoch": 0.7013683559100599,
      "grad_norm": 0.2439810037612915,
      "learning_rate": 4.562079873467774e-05,
      "loss": 0.0472,
      "step": 10200
    },
    {
      "epoch": 0.7082445162621193,
      "grad_norm": 0.18601445853710175,
      "learning_rate": 4.557781903828632e-05,
      "loss": 0.0429,
      "step": 10300
    },
    {
      "epoch": 0.7151206766141787,
      "grad_norm": 0.17241644859313965,
      "learning_rate": 4.553483934189489e-05,
      "loss": 0.0441,
      "step": 10400
    },
    {
      "epoch": 0.7219968369662381,
      "grad_norm": 0.17888520658016205,
      "learning_rate": 4.5491859645503465e-05,
      "loss": 0.0458,
      "step": 10500
    },
    {
      "epoch": 0.7288729973182975,
      "grad_norm": 0.24131865799427032,
      "learning_rate": 4.5449309746075954e-05,
      "loss": 0.0469,
      "step": 10600
    },
    {
      "epoch": 0.7357491576703569,
      "grad_norm": 0.16368146240711212,
      "learning_rate": 4.540633004968453e-05,
      "loss": 0.0434,
      "step": 10700
    },
    {
      "epoch": 0.7426253180224163,
      "grad_norm": 0.1916743516921997,
      "learning_rate": 4.53633503532931e-05,
      "loss": 0.0473,
      "step": 10800
    },
    {
      "epoch": 0.7495014783744757,
      "grad_norm": 0.2182653844356537,
      "learning_rate": 4.532037065690168e-05,
      "loss": 0.045,
      "step": 10900
    },
    {
      "epoch": 0.7563776387265351,
      "grad_norm": 0.265152245759964,
      "learning_rate": 4.527739096051026e-05,
      "loss": 0.0443,
      "step": 11000
    },
    {
      "epoch": 0.7632537990785945,
      "grad_norm": 0.12183871865272522,
      "learning_rate": 4.523441126411883e-05,
      "loss": 0.043,
      "step": 11100
    },
    {
      "epoch": 0.7701299594306539,
      "grad_norm": 0.17935843765735626,
      "learning_rate": 4.519143156772741e-05,
      "loss": 0.0455,
      "step": 11200
    },
    {
      "epoch": 0.7770061197827133,
      "grad_norm": 0.19918185472488403,
      "learning_rate": 4.5148451871335985e-05,
      "loss": 0.0466,
      "step": 11300
    },
    {
      "epoch": 0.7838822801347728,
      "grad_norm": 0.21248219907283783,
      "learning_rate": 4.510547217494456e-05,
      "loss": 0.046,
      "step": 11400
    },
    {
      "epoch": 0.7907584404868322,
      "grad_norm": 0.168336421251297,
      "learning_rate": 4.506249247855313e-05,
      "loss": 0.0442,
      "step": 11500
    },
    {
      "epoch": 0.7976346008388916,
      "grad_norm": 0.11991831660270691,
      "learning_rate": 4.501951278216171e-05,
      "loss": 0.0464,
      "step": 11600
    },
    {
      "epoch": 0.804510761190951,
      "grad_norm": 0.2300414890050888,
      "learning_rate": 4.497653308577028e-05,
      "loss": 0.046,
      "step": 11700
    },
    {
      "epoch": 0.8113869215430104,
      "grad_norm": 0.11531306803226471,
      "learning_rate": 4.4933553389378855e-05,
      "loss": 0.0418,
      "step": 11800
    },
    {
      "epoch": 0.8182630818950698,
      "grad_norm": 0.14734797179698944,
      "learning_rate": 4.4890573692987435e-05,
      "loss": 0.0447,
      "step": 11900
    },
    {
      "epoch": 0.8251392422471292,
      "grad_norm": 0.2742595970630646,
      "learning_rate": 4.484759399659601e-05,
      "loss": 0.0443,
      "step": 12000
    },
    {
      "epoch": 0.8320154025991886,
      "grad_norm": 0.1306626945734024,
      "learning_rate": 4.480461430020458e-05,
      "loss": 0.0441,
      "step": 12100
    },
    {
      "epoch": 0.838891562951248,
      "grad_norm": 0.14745955169200897,
      "learning_rate": 4.4761634603813164e-05,
      "loss": 0.0429,
      "step": 12200
    },
    {
      "epoch": 0.8457677233033074,
      "grad_norm": 0.14239351451396942,
      "learning_rate": 4.471865490742174e-05,
      "loss": 0.0414,
      "step": 12300
    },
    {
      "epoch": 0.8526438836553668,
      "grad_norm": 0.1901470273733139,
      "learning_rate": 4.467567521103031e-05,
      "loss": 0.0414,
      "step": 12400
    },
    {
      "epoch": 0.8595200440074262,
      "grad_norm": 0.18940633535385132,
      "learning_rate": 4.463269551463889e-05,
      "loss": 0.0445,
      "step": 12500
    },
    {
      "epoch": 0.8663962043594856,
      "grad_norm": 0.22994399070739746,
      "learning_rate": 4.458971581824746e-05,
      "loss": 0.0436,
      "step": 12600
    },
    {
      "epoch": 0.8732723647115451,
      "grad_norm": 0.10630148649215698,
      "learning_rate": 4.4546736121856033e-05,
      "loss": 0.0434,
      "step": 12700
    },
    {
      "epoch": 0.8801485250636045,
      "grad_norm": 0.1540795862674713,
      "learning_rate": 4.450418622242853e-05,
      "loss": 0.0469,
      "step": 12800
    },
    {
      "epoch": 0.8870246854156639,
      "grad_norm": 0.27610936760902405,
      "learning_rate": 4.44612065260371e-05,
      "loss": 0.0455,
      "step": 12900
    },
    {
      "epoch": 0.8939008457677233,
      "grad_norm": 0.12622283399105072,
      "learning_rate": 4.441822682964568e-05,
      "loss": 0.0457,
      "step": 13000
    },
    {
      "epoch": 0.9007770061197827,
      "grad_norm": 0.2423715889453888,
      "learning_rate": 4.437524713325426e-05,
      "loss": 0.045,
      "step": 13100
    },
    {
      "epoch": 0.9076531664718421,
      "grad_norm": 0.24647992849349976,
      "learning_rate": 4.433226743686283e-05,
      "loss": 0.0456,
      "step": 13200
    },
    {
      "epoch": 0.9145293268239015,
      "grad_norm": 0.2768940329551697,
      "learning_rate": 4.4289717537435314e-05,
      "loss": 0.0448,
      "step": 13300
    },
    {
      "epoch": 0.9214054871759609,
      "grad_norm": 0.1465647965669632,
      "learning_rate": 4.4246737841043895e-05,
      "loss": 0.0391,
      "step": 13400
    },
    {
      "epoch": 0.9282816475280203,
      "grad_norm": 0.11972052603960037,
      "learning_rate": 4.420375814465247e-05,
      "loss": 0.0435,
      "step": 13500
    },
    {
      "epoch": 0.9351578078800797,
      "grad_norm": 0.2129807025194168,
      "learning_rate": 4.416077844826104e-05,
      "loss": 0.0446,
      "step": 13600
    },
    {
      "epoch": 0.9420339682321391,
      "grad_norm": 0.1456003487110138,
      "learning_rate": 4.411779875186962e-05,
      "loss": 0.0452,
      "step": 13700
    },
    {
      "epoch": 0.9489101285841985,
      "grad_norm": 0.16161401569843292,
      "learning_rate": 4.4075248852442105e-05,
      "loss": 0.0461,
      "step": 13800
    },
    {
      "epoch": 0.9557862889362579,
      "grad_norm": 0.2173955887556076,
      "learning_rate": 4.403226915605068e-05,
      "loss": 0.044,
      "step": 13900
    },
    {
      "epoch": 0.9626624492883175,
      "grad_norm": 0.12819966673851013,
      "learning_rate": 4.398928945965926e-05,
      "loss": 0.0426,
      "step": 14000
    },
    {
      "epoch": 0.9695386096403769,
      "grad_norm": 0.18715399503707886,
      "learning_rate": 4.3946309763267834e-05,
      "loss": 0.0436,
      "step": 14100
    },
    {
      "epoch": 0.9764147699924363,
      "grad_norm": 0.14649003744125366,
      "learning_rate": 4.390333006687641e-05,
      "loss": 0.0434,
      "step": 14200
    },
    {
      "epoch": 0.9832909303444957,
      "grad_norm": 0.20846058428287506,
      "learning_rate": 4.386035037048499e-05,
      "loss": 0.0411,
      "step": 14300
    },
    {
      "epoch": 0.9901670906965551,
      "grad_norm": 0.21367119252681732,
      "learning_rate": 4.381737067409356e-05,
      "loss": 0.0419,
      "step": 14400
    },
    {
      "epoch": 0.9970432510486145,
      "grad_norm": 0.20734888315200806,
      "learning_rate": 4.3774390977702136e-05,
      "loss": 0.0407,
      "step": 14500
    },
    {
      "epoch": 1.0,
      "eval_accuracy_macro_0.5": 0.980263352394104,
      "eval_accuracy_micro_0.5": 0.980263352394104,
      "eval_accuracy_weighted_0.5": 0.977776288986206,
      "eval_f1_macro_0.5": 0.7347238659858704,
      "eval_f1_macro_0.6": 0.7137305736541748,
      "eval_f1_macro_0.7": 0.6723474860191345,
      "eval_f1_macro_0.8": 0.4804520606994629,
      "eval_f1_micro_0.5": 0.7387867569923401,
      "eval_f1_micro_0.6": 0.721841037273407,
      "eval_f1_micro_0.7": 0.6866098046302795,
      "eval_f1_micro_0.8": 0.6300436854362488,
      "eval_f1_micro_0.9": 0.504455029964447,
      "eval_f1_weighted_0.5": 0.7317468523979187,
      "eval_f1_weighted_0.6": 0.7096604108810425,
      "eval_f1_weighted_0.7": 0.6671109199523926,
      "eval_f1_weighted_0.8": 0.46428346633911133,
      "eval_loss": 0.041081976145505905,
      "eval_runtime": 140.7568,
      "eval_samples_per_second": 206.292,
      "eval_steps_per_second": 25.789,
      "step": 14543
    },
    {
      "epoch": 1.0039194114006738,
      "grad_norm": 0.16393379867076874,
      "learning_rate": 4.373141128131071e-05,
      "loss": 0.0412,
      "step": 14600
    },
    {
      "epoch": 1.0107955717527333,
      "grad_norm": 0.1479579359292984,
      "learning_rate": 4.3688431584919284e-05,
      "loss": 0.0418,
      "step": 14700
    },
    {
      "epoch": 1.0176717321047928,
      "grad_norm": 0.15419478714466095,
      "learning_rate": 4.364545188852786e-05,
      "loss": 0.0423,
      "step": 14800
    },
    {
      "epoch": 1.024547892456852,
      "grad_norm": 0.1771877408027649,
      "learning_rate": 4.360247219213643e-05,
      "loss": 0.042,
      "step": 14900
    },
    {
      "epoch": 1.0314240528089116,
      "grad_norm": 0.3059571385383606,
      "learning_rate": 4.355949249574501e-05,
      "loss": 0.0427,
      "step": 15000
    },
    {
      "epoch": 1.0383002131609709,
      "grad_norm": 0.13812103867530823,
      "learning_rate": 4.351651279935359e-05,
      "loss": 0.0423,
      "step": 15100
    },
    {
      "epoch": 1.0451763735130304,
      "grad_norm": 0.16594885289669037,
      "learning_rate": 4.347353310296216e-05,
      "loss": 0.0381,
      "step": 15200
    },
    {
      "epoch": 1.0520525338650897,
      "grad_norm": 0.24075298011302948,
      "learning_rate": 4.343055340657074e-05,
      "loss": 0.0414,
      "step": 15300
    },
    {
      "epoch": 1.0589286942171492,
      "grad_norm": 0.1609702706336975,
      "learning_rate": 4.3387573710179315e-05,
      "loss": 0.045,
      "step": 15400
    },
    {
      "epoch": 1.0658048545692085,
      "grad_norm": 0.2088722288608551,
      "learning_rate": 4.334459401378789e-05,
      "loss": 0.0422,
      "step": 15500
    },
    {
      "epoch": 1.072681014921268,
      "grad_norm": 0.10145410150289536,
      "learning_rate": 4.330161431739646e-05,
      "loss": 0.0392,
      "step": 15600
    },
    {
      "epoch": 1.0795571752733273,
      "grad_norm": 0.19309672713279724,
      "learning_rate": 4.325863462100504e-05,
      "loss": 0.0421,
      "step": 15700
    },
    {
      "epoch": 1.0864333356253868,
      "grad_norm": 0.20450735092163086,
      "learning_rate": 4.321565492461361e-05,
      "loss": 0.0414,
      "step": 15800
    },
    {
      "epoch": 1.0933094959774463,
      "grad_norm": 0.10073333978652954,
      "learning_rate": 4.317267522822219e-05,
      "loss": 0.0431,
      "step": 15900
    },
    {
      "epoch": 1.1001856563295056,
      "grad_norm": 0.09804574400186539,
      "learning_rate": 4.3129695531830765e-05,
      "loss": 0.0396,
      "step": 16000
    },
    {
      "epoch": 1.1070618166815651,
      "grad_norm": 0.13886362314224243,
      "learning_rate": 4.308671583543934e-05,
      "loss": 0.0413,
      "step": 16100
    },
    {
      "epoch": 1.1139379770336244,
      "grad_norm": 0.15358993411064148,
      "learning_rate": 4.304373613904791e-05,
      "loss": 0.038,
      "step": 16200
    },
    {
      "epoch": 1.120814137385684,
      "grad_norm": 0.20450589060783386,
      "learning_rate": 4.3000756442656494e-05,
      "loss": 0.0401,
      "step": 16300
    },
    {
      "epoch": 1.1276902977377432,
      "grad_norm": 0.14706486463546753,
      "learning_rate": 4.295777674626507e-05,
      "loss": 0.0387,
      "step": 16400
    },
    {
      "epoch": 1.1345664580898027,
      "grad_norm": 0.2742457687854767,
      "learning_rate": 4.291479704987364e-05,
      "loss": 0.0413,
      "step": 16500
    },
    {
      "epoch": 1.141442618441862,
      "grad_norm": 0.1375122368335724,
      "learning_rate": 4.2871817353482216e-05,
      "loss": 0.0426,
      "step": 16600
    },
    {
      "epoch": 1.1483187787939215,
      "grad_norm": 0.18344172835350037,
      "learning_rate": 4.282883765709079e-05,
      "loss": 0.0403,
      "step": 16700
    },
    {
      "epoch": 1.1551949391459808,
      "grad_norm": 0.16344787180423737,
      "learning_rate": 4.2785857960699363e-05,
      "loss": 0.0417,
      "step": 16800
    },
    {
      "epoch": 1.1620710994980403,
      "grad_norm": 0.23293475806713104,
      "learning_rate": 4.2742878264307944e-05,
      "loss": 0.042,
      "step": 16900
    },
    {
      "epoch": 1.1689472598500996,
      "grad_norm": 0.15081071853637695,
      "learning_rate": 4.269989856791652e-05,
      "loss": 0.0414,
      "step": 17000
    },
    {
      "epoch": 1.1758234202021591,
      "grad_norm": 0.16061264276504517,
      "learning_rate": 4.265691887152509e-05,
      "loss": 0.0387,
      "step": 17100
    },
    {
      "epoch": 1.1826995805542184,
      "grad_norm": 0.17779693007469177,
      "learning_rate": 4.261393917513367e-05,
      "loss": 0.041,
      "step": 17200
    },
    {
      "epoch": 1.189575740906278,
      "grad_norm": 0.15605852007865906,
      "learning_rate": 4.2570959478742247e-05,
      "loss": 0.0438,
      "step": 17300
    },
    {
      "epoch": 1.1964519012583374,
      "grad_norm": 0.19072671234607697,
      "learning_rate": 4.252797978235082e-05,
      "loss": 0.0433,
      "step": 17400
    },
    {
      "epoch": 1.2033280616103967,
      "grad_norm": 0.13785220682621002,
      "learning_rate": 4.2485000085959394e-05,
      "loss": 0.0429,
      "step": 17500
    },
    {
      "epoch": 1.2102042219624563,
      "grad_norm": 0.10126055777072906,
      "learning_rate": 4.244202038956797e-05,
      "loss": 0.0415,
      "step": 17600
    },
    {
      "epoch": 1.2170803823145155,
      "grad_norm": 0.16859667003154755,
      "learning_rate": 4.239904069317654e-05,
      "loss": 0.0441,
      "step": 17700
    },
    {
      "epoch": 1.223956542666575,
      "grad_norm": 0.16099298000335693,
      "learning_rate": 4.2356060996785116e-05,
      "loss": 0.0406,
      "step": 17800
    },
    {
      "epoch": 1.2308327030186343,
      "grad_norm": 0.14551091194152832,
      "learning_rate": 4.23130813003937e-05,
      "loss": 0.0404,
      "step": 17900
    },
    {
      "epoch": 1.2377088633706939,
      "grad_norm": 0.2594376504421234,
      "learning_rate": 4.227010160400227e-05,
      "loss": 0.0408,
      "step": 18000
    },
    {
      "epoch": 1.2445850237227531,
      "grad_norm": 0.10484717041254044,
      "learning_rate": 4.2227121907610845e-05,
      "loss": 0.0408,
      "step": 18100
    },
    {
      "epoch": 1.2514611840748127,
      "grad_norm": 0.2838665843009949,
      "learning_rate": 4.2184142211219425e-05,
      "loss": 0.0406,
      "step": 18200
    },
    {
      "epoch": 1.258337344426872,
      "grad_norm": 0.12024357914924622,
      "learning_rate": 4.2141162514828e-05,
      "loss": 0.0412,
      "step": 18300
    },
    {
      "epoch": 1.2652135047789315,
      "grad_norm": 0.19449637830257416,
      "learning_rate": 4.209818281843657e-05,
      "loss": 0.0395,
      "step": 18400
    },
    {
      "epoch": 1.272089665130991,
      "grad_norm": 0.18937787413597107,
      "learning_rate": 4.205520312204515e-05,
      "loss": 0.0417,
      "step": 18500
    },
    {
      "epoch": 1.2789658254830503,
      "grad_norm": 0.1485014408826828,
      "learning_rate": 4.201222342565372e-05,
      "loss": 0.0392,
      "step": 18600
    },
    {
      "epoch": 1.2858419858351096,
      "grad_norm": 0.14968328177928925,
      "learning_rate": 4.1969243729262295e-05,
      "loss": 0.0375,
      "step": 18700
    },
    {
      "epoch": 1.292718146187169,
      "grad_norm": 0.1717120260000229,
      "learning_rate": 4.192626403287087e-05,
      "loss": 0.0418,
      "step": 18800
    },
    {
      "epoch": 1.2995943065392286,
      "grad_norm": 0.2713626027107239,
      "learning_rate": 4.188328433647945e-05,
      "loss": 0.0389,
      "step": 18900
    },
    {
      "epoch": 1.3064704668912879,
      "grad_norm": 0.11934405565261841,
      "learning_rate": 4.1840304640088023e-05,
      "loss": 0.0403,
      "step": 19000
    },
    {
      "epoch": 1.3133466272433474,
      "grad_norm": 0.08561644703149796,
      "learning_rate": 4.17973249436966e-05,
      "loss": 0.0396,
      "step": 19100
    },
    {
      "epoch": 1.3202227875954067,
      "grad_norm": 0.19226187467575073,
      "learning_rate": 4.175434524730518e-05,
      "loss": 0.042,
      "step": 19200
    },
    {
      "epoch": 1.3270989479474662,
      "grad_norm": 0.18531294167041779,
      "learning_rate": 4.171179534787766e-05,
      "loss": 0.0419,
      "step": 19300
    },
    {
      "epoch": 1.3339751082995255,
      "grad_norm": 0.19327080249786377,
      "learning_rate": 4.166881565148624e-05,
      "loss": 0.0389,
      "step": 19400
    },
    {
      "epoch": 1.340851268651585,
      "grad_norm": 0.19811172783374786,
      "learning_rate": 4.1625835955094815e-05,
      "loss": 0.0418,
      "step": 19500
    },
    {
      "epoch": 1.3477274290036443,
      "grad_norm": 0.09367195516824722,
      "learning_rate": 4.158285625870339e-05,
      "loss": 0.0385,
      "step": 19600
    },
    {
      "epoch": 1.3546035893557038,
      "grad_norm": 0.23713113367557526,
      "learning_rate": 4.153987656231196e-05,
      "loss": 0.0409,
      "step": 19700
    },
    {
      "epoch": 1.361479749707763,
      "grad_norm": 0.17490635812282562,
      "learning_rate": 4.1496896865920543e-05,
      "loss": 0.0408,
      "step": 19800
    },
    {
      "epoch": 1.3683559100598226,
      "grad_norm": 0.1696605682373047,
      "learning_rate": 4.145391716952912e-05,
      "loss": 0.0404,
      "step": 19900
    },
    {
      "epoch": 1.3752320704118821,
      "grad_norm": 0.12272512167692184,
      "learning_rate": 4.141093747313769e-05,
      "loss": 0.04,
      "step": 20000
    },
    {
      "epoch": 1.3821082307639414,
      "grad_norm": 0.19764406979084015,
      "learning_rate": 4.136795777674627e-05,
      "loss": 0.0388,
      "step": 20100
    },
    {
      "epoch": 1.3889843911160007,
      "grad_norm": 0.2129228562116623,
      "learning_rate": 4.1324978080354846e-05,
      "loss": 0.0392,
      "step": 20200
    },
    {
      "epoch": 1.3958605514680602,
      "grad_norm": 0.15772686898708344,
      "learning_rate": 4.128199838396341e-05,
      "loss": 0.0395,
      "step": 20300
    },
    {
      "epoch": 1.4027367118201197,
      "grad_norm": 0.12187208235263824,
      "learning_rate": 4.1239018687571994e-05,
      "loss": 0.0405,
      "step": 20400
    },
    {
      "epoch": 1.409612872172179,
      "grad_norm": 0.15442508459091187,
      "learning_rate": 4.119603899118057e-05,
      "loss": 0.0393,
      "step": 20500
    },
    {
      "epoch": 1.4164890325242385,
      "grad_norm": 0.15117092430591583,
      "learning_rate": 4.115305929478914e-05,
      "loss": 0.0382,
      "step": 20600
    },
    {
      "epoch": 1.4233651928762978,
      "grad_norm": 0.20422327518463135,
      "learning_rate": 4.111007959839772e-05,
      "loss": 0.0423,
      "step": 20700
    },
    {
      "epoch": 1.4302413532283573,
      "grad_norm": 0.1047637090086937,
      "learning_rate": 4.1067099902006296e-05,
      "loss": 0.0384,
      "step": 20800
    },
    {
      "epoch": 1.4371175135804166,
      "grad_norm": 0.2849200665950775,
      "learning_rate": 4.102412020561487e-05,
      "loss": 0.0402,
      "step": 20900
    },
    {
      "epoch": 1.4439936739324761,
      "grad_norm": 0.19893492758274078,
      "learning_rate": 4.0981140509223444e-05,
      "loss": 0.0421,
      "step": 21000
    },
    {
      "epoch": 1.4508698342845356,
      "grad_norm": 0.1530245691537857,
      "learning_rate": 4.0938160812832025e-05,
      "loss": 0.0408,
      "step": 21100
    },
    {
      "epoch": 1.457745994636595,
      "grad_norm": 0.2163059562444687,
      "learning_rate": 4.08951811164406e-05,
      "loss": 0.0413,
      "step": 21200
    },
    {
      "epoch": 1.4646221549886542,
      "grad_norm": 0.18884682655334473,
      "learning_rate": 4.0852201420049166e-05,
      "loss": 0.0404,
      "step": 21300
    },
    {
      "epoch": 1.4714983153407137,
      "grad_norm": 0.22511988878250122,
      "learning_rate": 4.0809221723657746e-05,
      "loss": 0.0373,
      "step": 21400
    },
    {
      "epoch": 1.4783744756927732,
      "grad_norm": 0.10896860063076019,
      "learning_rate": 4.076624202726632e-05,
      "loss": 0.0412,
      "step": 21500
    },
    {
      "epoch": 1.4852506360448325,
      "grad_norm": 0.1986120045185089,
      "learning_rate": 4.0723262330874894e-05,
      "loss": 0.039,
      "step": 21600
    },
    {
      "epoch": 1.492126796396892,
      "grad_norm": 0.14443565905094147,
      "learning_rate": 4.0680282634483475e-05,
      "loss": 0.0406,
      "step": 21700
    },
    {
      "epoch": 1.4990029567489513,
      "grad_norm": 0.18552888929843903,
      "learning_rate": 4.063730293809205e-05,
      "loss": 0.0399,
      "step": 21800
    },
    {
      "epoch": 1.5058791171010109,
      "grad_norm": 0.12456408143043518,
      "learning_rate": 4.059432324170062e-05,
      "loss": 0.039,
      "step": 21900
    },
    {
      "epoch": 1.5127552774530701,
      "grad_norm": 0.14551493525505066,
      "learning_rate": 4.055177334227311e-05,
      "loss": 0.0399,
      "step": 22000
    },
    {
      "epoch": 1.5196314378051297,
      "grad_norm": 0.12057439982891083,
      "learning_rate": 4.0508793645881686e-05,
      "loss": 0.0389,
      "step": 22100
    },
    {
      "epoch": 1.5265075981571892,
      "grad_norm": 0.17344509065151215,
      "learning_rate": 4.046581394949026e-05,
      "loss": 0.0376,
      "step": 22200
    },
    {
      "epoch": 1.5333837585092485,
      "grad_norm": 0.19922080636024475,
      "learning_rate": 4.042283425309884e-05,
      "loss": 0.0398,
      "step": 22300
    },
    {
      "epoch": 1.5402599188613078,
      "grad_norm": 0.260398268699646,
      "learning_rate": 4.0379854556707414e-05,
      "loss": 0.0429,
      "step": 22400
    },
    {
      "epoch": 1.5471360792133673,
      "grad_norm": 0.15679188072681427,
      "learning_rate": 4.033687486031599e-05,
      "loss": 0.0371,
      "step": 22500
    },
    {
      "epoch": 1.5540122395654268,
      "grad_norm": 0.16618941724300385,
      "learning_rate": 4.029389516392457e-05,
      "loss": 0.038,
      "step": 22600
    },
    {
      "epoch": 1.560888399917486,
      "grad_norm": 0.2784775495529175,
      "learning_rate": 4.025091546753314e-05,
      "loss": 0.039,
      "step": 22700
    },
    {
      "epoch": 1.5677645602695454,
      "grad_norm": 0.16193579137325287,
      "learning_rate": 4.0207935771141717e-05,
      "loss": 0.0403,
      "step": 22800
    },
    {
      "epoch": 1.5746407206216049,
      "grad_norm": 0.16121308505535126,
      "learning_rate": 4.016495607475029e-05,
      "loss": 0.0406,
      "step": 22900
    },
    {
      "epoch": 1.5815168809736644,
      "grad_norm": 0.18042242527008057,
      "learning_rate": 4.0121976378358864e-05,
      "loss": 0.0378,
      "step": 23000
    },
    {
      "epoch": 1.5883930413257237,
      "grad_norm": 0.14557428658008575,
      "learning_rate": 4.007899668196744e-05,
      "loss": 0.0372,
      "step": 23100
    },
    {
      "epoch": 1.595269201677783,
      "grad_norm": 0.15462273359298706,
      "learning_rate": 4.003601698557601e-05,
      "loss": 0.0359,
      "step": 23200
    },
    {
      "epoch": 1.6021453620298427,
      "grad_norm": 0.201985701918602,
      "learning_rate": 3.999303728918459e-05,
      "loss": 0.0397,
      "step": 23300
    },
    {
      "epoch": 1.609021522381902,
      "grad_norm": 0.14128921926021576,
      "learning_rate": 3.995005759279317e-05,
      "loss": 0.0377,
      "step": 23400
    },
    {
      "epoch": 1.6158976827339613,
      "grad_norm": 0.3011268973350525,
      "learning_rate": 3.990707789640174e-05,
      "loss": 0.0413,
      "step": 23500
    },
    {
      "epoch": 1.6227738430860208,
      "grad_norm": 0.1334739774465561,
      "learning_rate": 3.986409820001032e-05,
      "loss": 0.0403,
      "step": 23600
    },
    {
      "epoch": 1.6296500034380803,
      "grad_norm": 0.12927764654159546,
      "learning_rate": 3.9821118503618895e-05,
      "loss": 0.0392,
      "step": 23700
    },
    {
      "epoch": 1.6365261637901396,
      "grad_norm": 0.23249882459640503,
      "learning_rate": 3.977813880722747e-05,
      "loss": 0.0382,
      "step": 23800
    },
    {
      "epoch": 1.643402324142199,
      "grad_norm": 0.2407858967781067,
      "learning_rate": 3.973515911083604e-05,
      "loss": 0.0402,
      "step": 23900
    },
    {
      "epoch": 1.6502784844942584,
      "grad_norm": 0.18038104474544525,
      "learning_rate": 3.969217941444462e-05,
      "loss": 0.0398,
      "step": 24000
    },
    {
      "epoch": 1.657154644846318,
      "grad_norm": 0.2133415788412094,
      "learning_rate": 3.964919971805319e-05,
      "loss": 0.0404,
      "step": 24100
    },
    {
      "epoch": 1.6640308051983772,
      "grad_norm": 0.09787022322416306,
      "learning_rate": 3.9606220021661765e-05,
      "loss": 0.0381,
      "step": 24200
    },
    {
      "epoch": 1.6709069655504365,
      "grad_norm": 0.1529339849948883,
      "learning_rate": 3.9563240325270346e-05,
      "loss": 0.0369,
      "step": 24300
    },
    {
      "epoch": 1.677783125902496,
      "grad_norm": 0.16405659914016724,
      "learning_rate": 3.952026062887892e-05,
      "loss": 0.0391,
      "step": 24400
    },
    {
      "epoch": 1.6846592862545555,
      "grad_norm": 0.14603720605373383,
      "learning_rate": 3.947728093248749e-05,
      "loss": 0.0378,
      "step": 24500
    },
    {
      "epoch": 1.6915354466066148,
      "grad_norm": 0.1945798248052597,
      "learning_rate": 3.9434301236096074e-05,
      "loss": 0.0394,
      "step": 24600
    },
    {
      "epoch": 1.6984116069586743,
      "grad_norm": 0.24079561233520508,
      "learning_rate": 3.939132153970465e-05,
      "loss": 0.0388,
      "step": 24700
    },
    {
      "epoch": 1.7052877673107338,
      "grad_norm": 0.14912883937358856,
      "learning_rate": 3.934834184331322e-05,
      "loss": 0.039,
      "step": 24800
    },
    {
      "epoch": 1.7121639276627931,
      "grad_norm": 0.176955908536911,
      "learning_rate": 3.9305362146921796e-05,
      "loss": 0.0392,
      "step": 24900
    },
    {
      "epoch": 1.7190400880148524,
      "grad_norm": 0.09973493963479996,
      "learning_rate": 3.926238245053037e-05,
      "loss": 0.0385,
      "step": 25000
    },
    {
      "epoch": 1.725916248366912,
      "grad_norm": 0.21772778034210205,
      "learning_rate": 3.9219402754138944e-05,
      "loss": 0.0378,
      "step": 25100
    },
    {
      "epoch": 1.7327924087189714,
      "grad_norm": 0.3150186240673065,
      "learning_rate": 3.9176423057747524e-05,
      "loss": 0.0397,
      "step": 25200
    },
    {
      "epoch": 1.7396685690710307,
      "grad_norm": 0.15701735019683838,
      "learning_rate": 3.91334433613561e-05,
      "loss": 0.0361,
      "step": 25300
    },
    {
      "epoch": 1.74654472942309,
      "grad_norm": 0.1176733747124672,
      "learning_rate": 3.909046366496467e-05,
      "loss": 0.0378,
      "step": 25400
    },
    {
      "epoch": 1.7534208897751495,
      "grad_norm": 0.181890606880188,
      "learning_rate": 3.9047483968573246e-05,
      "loss": 0.037,
      "step": 25500
    },
    {
      "epoch": 1.760297050127209,
      "grad_norm": 0.15552105009555817,
      "learning_rate": 3.900450427218183e-05,
      "loss": 0.0394,
      "step": 25600
    },
    {
      "epoch": 1.7671732104792683,
      "grad_norm": 0.29997214674949646,
      "learning_rate": 3.89615245757904e-05,
      "loss": 0.0389,
      "step": 25700
    },
    {
      "epoch": 1.7740493708313276,
      "grad_norm": 0.12083961814641953,
      "learning_rate": 3.8918544879398975e-05,
      "loss": 0.0409,
      "step": 25800
    },
    {
      "epoch": 1.7809255311833871,
      "grad_norm": 0.18964296579360962,
      "learning_rate": 3.8875994979971464e-05,
      "loss": 0.0401,
      "step": 25900
    },
    {
      "epoch": 1.7878016915354467,
      "grad_norm": 0.13186733424663544,
      "learning_rate": 3.883301528358004e-05,
      "loss": 0.0381,
      "step": 26000
    },
    {
      "epoch": 1.794677851887506,
      "grad_norm": 0.17166045308113098,
      "learning_rate": 3.879003558718861e-05,
      "loss": 0.0371,
      "step": 26100
    },
    {
      "epoch": 1.8015540122395655,
      "grad_norm": 0.1321481168270111,
      "learning_rate": 3.874705589079719e-05,
      "loss": 0.0377,
      "step": 26200
    },
    {
      "epoch": 1.808430172591625,
      "grad_norm": 0.17481796443462372,
      "learning_rate": 3.8704076194405766e-05,
      "loss": 0.0375,
      "step": 26300
    },
    {
      "epoch": 1.8153063329436843,
      "grad_norm": 0.22114066779613495,
      "learning_rate": 3.866109649801434e-05,
      "loss": 0.039,
      "step": 26400
    },
    {
      "epoch": 1.8221824932957436,
      "grad_norm": 0.14967627823352814,
      "learning_rate": 3.8618116801622914e-05,
      "loss": 0.0426,
      "step": 26500
    },
    {
      "epoch": 1.829058653647803,
      "grad_norm": 0.12697012722492218,
      "learning_rate": 3.857513710523149e-05,
      "loss": 0.0398,
      "step": 26600
    },
    {
      "epoch": 1.8359348139998626,
      "grad_norm": 0.1328357458114624,
      "learning_rate": 3.853215740884006e-05,
      "loss": 0.0396,
      "step": 26700
    },
    {
      "epoch": 1.8428109743519219,
      "grad_norm": 0.16869495809078217,
      "learning_rate": 3.848917771244864e-05,
      "loss": 0.0374,
      "step": 26800
    },
    {
      "epoch": 1.8496871347039812,
      "grad_norm": 0.31577762961387634,
      "learning_rate": 3.8446198016057216e-05,
      "loss": 0.0384,
      "step": 26900
    },
    {
      "epoch": 1.8565632950560407,
      "grad_norm": 0.1659270077943802,
      "learning_rate": 3.840321831966579e-05,
      "loss": 0.0384,
      "step": 27000
    },
    {
      "epoch": 1.8634394554081002,
      "grad_norm": 0.1470019519329071,
      "learning_rate": 3.836023862327437e-05,
      "loss": 0.0375,
      "step": 27100
    },
    {
      "epoch": 1.8703156157601595,
      "grad_norm": 0.1529477834701538,
      "learning_rate": 3.8317258926882945e-05,
      "loss": 0.0382,
      "step": 27200
    },
    {
      "epoch": 1.877191776112219,
      "grad_norm": 0.16166745126247406,
      "learning_rate": 3.827427923049152e-05,
      "loss": 0.0382,
      "step": 27300
    },
    {
      "epoch": 1.8840679364642785,
      "grad_norm": 0.16655106842517853,
      "learning_rate": 3.823129953410009e-05,
      "loss": 0.0403,
      "step": 27400
    },
    {
      "epoch": 1.8909440968163378,
      "grad_norm": 0.1435336470603943,
      "learning_rate": 3.8188319837708667e-05,
      "loss": 0.0376,
      "step": 27500
    },
    {
      "epoch": 1.897820257168397,
      "grad_norm": 0.22228634357452393,
      "learning_rate": 3.814534014131724e-05,
      "loss": 0.0402,
      "step": 27600
    },
    {
      "epoch": 1.9046964175204566,
      "grad_norm": 0.20316992700099945,
      "learning_rate": 3.8102360444925814e-05,
      "loss": 0.0402,
      "step": 27700
    },
    {
      "epoch": 1.911572577872516,
      "grad_norm": 0.20680388808250427,
      "learning_rate": 3.8059380748534395e-05,
      "loss": 0.0391,
      "step": 27800
    },
    {
      "epoch": 1.9184487382245754,
      "grad_norm": 0.17100642621517181,
      "learning_rate": 3.801640105214297e-05,
      "loss": 0.0402,
      "step": 27900
    },
    {
      "epoch": 1.9253248985766347,
      "grad_norm": 0.20598509907722473,
      "learning_rate": 3.797342135575154e-05,
      "loss": 0.0374,
      "step": 28000
    },
    {
      "epoch": 1.9322010589286942,
      "grad_norm": 0.23628582060337067,
      "learning_rate": 3.793087145632403e-05,
      "loss": 0.0376,
      "step": 28100
    },
    {
      "epoch": 1.9390772192807537,
      "grad_norm": 0.1669132560491562,
      "learning_rate": 3.7887891759932606e-05,
      "loss": 0.0427,
      "step": 28200
    },
    {
      "epoch": 1.945953379632813,
      "grad_norm": 0.24811892211437225,
      "learning_rate": 3.784491206354118e-05,
      "loss": 0.0361,
      "step": 28300
    },
    {
      "epoch": 1.9528295399848723,
      "grad_norm": 0.18419420719146729,
      "learning_rate": 3.780193236714976e-05,
      "loss": 0.0385,
      "step": 28400
    },
    {
      "epoch": 1.9597057003369318,
      "grad_norm": 0.2646101713180542,
      "learning_rate": 3.7758952670758334e-05,
      "loss": 0.0372,
      "step": 28500
    },
    {
      "epoch": 1.9665818606889913,
      "grad_norm": 0.14227020740509033,
      "learning_rate": 3.771597297436691e-05,
      "loss": 0.038,
      "step": 28600
    },
    {
      "epoch": 1.9734580210410506,
      "grad_norm": 0.09418468177318573,
      "learning_rate": 3.767299327797549e-05,
      "loss": 0.0356,
      "step": 28700
    },
    {
      "epoch": 1.9803341813931101,
      "grad_norm": 0.19385381042957306,
      "learning_rate": 3.763001358158406e-05,
      "loss": 0.0405,
      "step": 28800
    },
    {
      "epoch": 1.9872103417451696,
      "grad_norm": 0.2689470052719116,
      "learning_rate": 3.758703388519264e-05,
      "loss": 0.039,
      "step": 28900
    },
    {
      "epoch": 1.994086502097229,
      "grad_norm": 0.13945001363754272,
      "learning_rate": 3.754405418880122e-05,
      "loss": 0.0392,
      "step": 29000
    },
    {
      "epoch": 2.0,
      "eval_accuracy_macro_0.5": 0.9825729131698608,
      "eval_accuracy_micro_0.5": 0.9825728535652161,
      "eval_accuracy_weighted_0.5": 0.9802182912826538,
      "eval_f1_macro_0.5": 0.7719457149505615,
      "eval_f1_macro_0.6": 0.7579287886619568,
      "eval_f1_macro_0.7": 0.7268080711364746,
      "eval_f1_macro_0.8": 0.5584608316421509,
      "eval_f1_micro_0.5": 0.7728732824325562,
      "eval_f1_micro_0.6": 0.7625841498374939,
      "eval_f1_micro_0.7": 0.7363860607147217,
      "eval_f1_micro_0.8": 0.688919186592102,
      "eval_f1_micro_0.9": 0.5833021402359009,
      "eval_f1_weighted_0.5": 0.7673465013504028,
      "eval_f1_weighted_0.6": 0.7531790137290955,
      "eval_f1_weighted_0.7": 0.7214981913566589,
      "eval_f1_weighted_0.8": 0.5478028059005737,
      "eval_loss": 0.03599632531404495,
      "eval_runtime": 133.378,
      "eval_samples_per_second": 217.705,
      "eval_steps_per_second": 27.216,
      "step": 29086
    },
    {
      "epoch": 2.000962662449288,
      "grad_norm": 0.18937243521213531,
      "learning_rate": 3.7501074492409785e-05,
      "loss": 0.0376,
      "step": 29100
    },
    {
      "epoch": 2.0078388228013475,
      "grad_norm": 0.17030157148838043,
      "learning_rate": 3.745809479601836e-05,
      "loss": 0.0358,
      "step": 29200
    },
    {
      "epoch": 2.0147149831534072,
      "grad_norm": 0.2222854346036911,
      "learning_rate": 3.741511509962694e-05,
      "loss": 0.0391,
      "step": 29300
    },
    {
      "epoch": 2.0215911435054665,
      "grad_norm": 0.11358349770307541,
      "learning_rate": 3.737213540323551e-05,
      "loss": 0.0399,
      "step": 29400
    },
    {
      "epoch": 2.028467303857526,
      "grad_norm": 0.3073960840702057,
      "learning_rate": 3.732915570684409e-05,
      "loss": 0.0381,
      "step": 29500
    },
    {
      "epoch": 2.0353434642095856,
      "grad_norm": 0.1548558920621872,
      "learning_rate": 3.728617601045266e-05,
      "loss": 0.0348,
      "step": 29600
    },
    {
      "epoch": 2.042219624561645,
      "grad_norm": 0.11491481959819794,
      "learning_rate": 3.724319631406124e-05,
      "loss": 0.0364,
      "step": 29700
    },
    {
      "epoch": 2.049095784913704,
      "grad_norm": 0.27478837966918945,
      "learning_rate": 3.7200216617669816e-05,
      "loss": 0.0356,
      "step": 29800
    },
    {
      "epoch": 2.0559719452657634,
      "grad_norm": 0.06377561390399933,
      "learning_rate": 3.715723692127839e-05,
      "loss": 0.0391,
      "step": 29900
    },
    {
      "epoch": 2.062848105617823,
      "grad_norm": 0.1814483255147934,
      "learning_rate": 3.711425722488697e-05,
      "loss": 0.0353,
      "step": 30000
    },
    {
      "epoch": 2.0697242659698825,
      "grad_norm": 0.18018390238285065,
      "learning_rate": 3.707127752849554e-05,
      "loss": 0.035,
      "step": 30100
    },
    {
      "epoch": 2.0766004263219418,
      "grad_norm": 0.09388755261898041,
      "learning_rate": 3.702829783210411e-05,
      "loss": 0.0381,
      "step": 30200
    },
    {
      "epoch": 2.083476586674001,
      "grad_norm": 0.22966742515563965,
      "learning_rate": 3.698531813571269e-05,
      "loss": 0.0347,
      "step": 30300
    },
    {
      "epoch": 2.0903527470260608,
      "grad_norm": 0.17637643218040466,
      "learning_rate": 3.6942338439321266e-05,
      "loss": 0.0364,
      "step": 30400
    },
    {
      "epoch": 2.09722890737812,
      "grad_norm": 0.15193413197994232,
      "learning_rate": 3.689935874292984e-05,
      "loss": 0.038,
      "step": 30500
    },
    {
      "epoch": 2.1041050677301794,
      "grad_norm": 0.28184744715690613,
      "learning_rate": 3.685637904653842e-05,
      "loss": 0.0371,
      "step": 30600
    },
    {
      "epoch": 2.110981228082239,
      "grad_norm": 0.12866859138011932,
      "learning_rate": 3.6813399350146994e-05,
      "loss": 0.0399,
      "step": 30700
    },
    {
      "epoch": 2.1178573884342984,
      "grad_norm": 0.15260550379753113,
      "learning_rate": 3.677041965375557e-05,
      "loss": 0.0381,
      "step": 30800
    },
    {
      "epoch": 2.1247335487863577,
      "grad_norm": 0.1781722605228424,
      "learning_rate": 3.672743995736414e-05,
      "loss": 0.036,
      "step": 30900
    },
    {
      "epoch": 2.131609709138417,
      "grad_norm": 0.1624794900417328,
      "learning_rate": 3.668446026097272e-05,
      "loss": 0.0359,
      "step": 31000
    },
    {
      "epoch": 2.1384858694904767,
      "grad_norm": 0.15179456770420074,
      "learning_rate": 3.6641910361545205e-05,
      "loss": 0.0388,
      "step": 31100
    },
    {
      "epoch": 2.145362029842536,
      "grad_norm": 0.11939429491758347,
      "learning_rate": 3.6598930665153786e-05,
      "loss": 0.0363,
      "step": 31200
    },
    {
      "epoch": 2.1522381901945953,
      "grad_norm": 0.16027605533599854,
      "learning_rate": 3.655595096876236e-05,
      "loss": 0.0368,
      "step": 31300
    },
    {
      "epoch": 2.1591143505466546,
      "grad_norm": 0.21358931064605713,
      "learning_rate": 3.6512971272370934e-05,
      "loss": 0.0365,
      "step": 31400
    },
    {
      "epoch": 2.1659905108987143,
      "grad_norm": 0.2372085601091385,
      "learning_rate": 3.646999157597951e-05,
      "loss": 0.0344,
      "step": 31500
    },
    {
      "epoch": 2.1728666712507736,
      "grad_norm": 0.16339914500713348,
      "learning_rate": 3.642701187958809e-05,
      "loss": 0.038,
      "step": 31600
    },
    {
      "epoch": 2.179742831602833,
      "grad_norm": 0.079653799533844,
      "learning_rate": 3.638403218319666e-05,
      "loss": 0.0368,
      "step": 31700
    },
    {
      "epoch": 2.1866189919548926,
      "grad_norm": 0.18060284852981567,
      "learning_rate": 3.6341052486805236e-05,
      "loss": 0.0315,
      "step": 31800
    },
    {
      "epoch": 2.193495152306952,
      "grad_norm": 0.1277589201927185,
      "learning_rate": 3.629807279041381e-05,
      "loss": 0.035,
      "step": 31900
    },
    {
      "epoch": 2.200371312659011,
      "grad_norm": 0.09172718971967697,
      "learning_rate": 3.6255093094022384e-05,
      "loss": 0.0358,
      "step": 32000
    },
    {
      "epoch": 2.2072474730110705,
      "grad_norm": 0.15263649821281433,
      "learning_rate": 3.621211339763096e-05,
      "loss": 0.036,
      "step": 32100
    },
    {
      "epoch": 2.2141236333631302,
      "grad_norm": 0.21005485951900482,
      "learning_rate": 3.616913370123954e-05,
      "loss": 0.0387,
      "step": 32200
    },
    {
      "epoch": 2.2209997937151895,
      "grad_norm": 0.16836026310920715,
      "learning_rate": 3.612615400484811e-05,
      "loss": 0.0355,
      "step": 32300
    },
    {
      "epoch": 2.227875954067249,
      "grad_norm": 0.19148428738117218,
      "learning_rate": 3.6083174308456686e-05,
      "loss": 0.0349,
      "step": 32400
    },
    {
      "epoch": 2.234752114419308,
      "grad_norm": 0.25155746936798096,
      "learning_rate": 3.604019461206527e-05,
      "loss": 0.0353,
      "step": 32500
    },
    {
      "epoch": 2.241628274771368,
      "grad_norm": 0.279098242521286,
      "learning_rate": 3.599721491567384e-05,
      "loss": 0.0344,
      "step": 32600
    },
    {
      "epoch": 2.248504435123427,
      "grad_norm": 0.2614203095436096,
      "learning_rate": 3.5954235219282415e-05,
      "loss": 0.036,
      "step": 32700
    },
    {
      "epoch": 2.2553805954754864,
      "grad_norm": 0.23915016651153564,
      "learning_rate": 3.591125552289099e-05,
      "loss": 0.0353,
      "step": 32800
    },
    {
      "epoch": 2.2622567558275457,
      "grad_norm": 0.17694878578186035,
      "learning_rate": 3.586827582649956e-05,
      "loss": 0.0356,
      "step": 32900
    },
    {
      "epoch": 2.2691329161796054,
      "grad_norm": 0.19064757227897644,
      "learning_rate": 3.5825296130108136e-05,
      "loss": 0.037,
      "step": 33000
    },
    {
      "epoch": 2.2760090765316647,
      "grad_norm": 0.21667703986167908,
      "learning_rate": 3.578231643371671e-05,
      "loss": 0.0342,
      "step": 33100
    },
    {
      "epoch": 2.282885236883724,
      "grad_norm": 0.13546216487884521,
      "learning_rate": 3.573933673732529e-05,
      "loss": 0.0397,
      "step": 33200
    },
    {
      "epoch": 2.2897613972357833,
      "grad_norm": 0.17806445062160492,
      "learning_rate": 3.5696357040933865e-05,
      "loss": 0.0368,
      "step": 33300
    },
    {
      "epoch": 2.296637557587843,
      "grad_norm": 0.18906360864639282,
      "learning_rate": 3.565337734454244e-05,
      "loss": 0.0383,
      "step": 33400
    },
    {
      "epoch": 2.3035137179399023,
      "grad_norm": 0.2130676805973053,
      "learning_rate": 3.561039764815102e-05,
      "loss": 0.0368,
      "step": 33500
    },
    {
      "epoch": 2.3103898782919616,
      "grad_norm": 0.13517144322395325,
      "learning_rate": 3.5567417951759593e-05,
      "loss": 0.0373,
      "step": 33600
    },
    {
      "epoch": 2.3172660386440214,
      "grad_norm": 0.21116693317890167,
      "learning_rate": 3.552443825536817e-05,
      "loss": 0.0371,
      "step": 33700
    },
    {
      "epoch": 2.3241421989960807,
      "grad_norm": 0.18508797883987427,
      "learning_rate": 3.548145855897674e-05,
      "loss": 0.0328,
      "step": 33800
    },
    {
      "epoch": 2.33101835934814,
      "grad_norm": 0.17658835649490356,
      "learning_rate": 3.5438478862585315e-05,
      "loss": 0.0366,
      "step": 33900
    },
    {
      "epoch": 2.3378945197001992,
      "grad_norm": 0.16734610497951508,
      "learning_rate": 3.539549916619389e-05,
      "loss": 0.0364,
      "step": 34000
    },
    {
      "epoch": 2.344770680052259,
      "grad_norm": 0.23558098077774048,
      "learning_rate": 3.535251946980247e-05,
      "loss": 0.0384,
      "step": 34100
    },
    {
      "epoch": 2.3516468404043183,
      "grad_norm": 0.17354059219360352,
      "learning_rate": 3.5309539773411044e-05,
      "loss": 0.039,
      "step": 34200
    },
    {
      "epoch": 2.3585230007563776,
      "grad_norm": 0.20092247426509857,
      "learning_rate": 3.526656007701962e-05,
      "loss": 0.0346,
      "step": 34300
    },
    {
      "epoch": 2.365399161108437,
      "grad_norm": 0.21847553551197052,
      "learning_rate": 3.522358038062819e-05,
      "loss": 0.034,
      "step": 34400
    },
    {
      "epoch": 2.3722753214604966,
      "grad_norm": 0.18523229658603668,
      "learning_rate": 3.518060068423677e-05,
      "loss": 0.0381,
      "step": 34500
    },
    {
      "epoch": 2.379151481812556,
      "grad_norm": 0.08949518203735352,
      "learning_rate": 3.5137620987845346e-05,
      "loss": 0.0352,
      "step": 34600
    },
    {
      "epoch": 2.386027642164615,
      "grad_norm": 0.1875215768814087,
      "learning_rate": 3.509464129145392e-05,
      "loss": 0.0372,
      "step": 34700
    },
    {
      "epoch": 2.392903802516675,
      "grad_norm": 0.05796864256262779,
      "learning_rate": 3.5051661595062494e-05,
      "loss": 0.0381,
      "step": 34800
    },
    {
      "epoch": 2.399779962868734,
      "grad_norm": 0.09247439354658127,
      "learning_rate": 3.500868189867107e-05,
      "loss": 0.0328,
      "step": 34900
    },
    {
      "epoch": 2.4066561232207935,
      "grad_norm": 0.231056809425354,
      "learning_rate": 3.496613199924356e-05,
      "loss": 0.0379,
      "step": 35000
    },
    {
      "epoch": 2.4135322835728528,
      "grad_norm": 0.12339279055595398,
      "learning_rate": 3.492315230285214e-05,
      "loss": 0.0352,
      "step": 35100
    },
    {
      "epoch": 2.4204084439249125,
      "grad_norm": 0.23171044886112213,
      "learning_rate": 3.488017260646071e-05,
      "loss": 0.0356,
      "step": 35200
    },
    {
      "epoch": 2.427284604276972,
      "grad_norm": 0.13032467663288116,
      "learning_rate": 3.4837192910069285e-05,
      "loss": 0.0372,
      "step": 35300
    },
    {
      "epoch": 2.434160764629031,
      "grad_norm": 0.13261130452156067,
      "learning_rate": 3.479421321367786e-05,
      "loss": 0.0345,
      "step": 35400
    },
    {
      "epoch": 2.4410369249810904,
      "grad_norm": 0.1923259198665619,
      "learning_rate": 3.475123351728643e-05,
      "loss": 0.039,
      "step": 35500
    },
    {
      "epoch": 2.44791308533315,
      "grad_norm": 0.1871739774942398,
      "learning_rate": 3.470825382089501e-05,
      "loss": 0.0399,
      "step": 35600
    },
    {
      "epoch": 2.4547892456852094,
      "grad_norm": 0.2186048924922943,
      "learning_rate": 3.466527412450359e-05,
      "loss": 0.0361,
      "step": 35700
    },
    {
      "epoch": 2.4616654060372687,
      "grad_norm": 0.24743467569351196,
      "learning_rate": 3.462229442811216e-05,
      "loss": 0.037,
      "step": 35800
    },
    {
      "epoch": 2.4685415663893284,
      "grad_norm": 0.13690920174121857,
      "learning_rate": 3.4579314731720736e-05,
      "loss": 0.036,
      "step": 35900
    },
    {
      "epoch": 2.4754177267413877,
      "grad_norm": 0.2651641368865967,
      "learning_rate": 3.4536335035329316e-05,
      "loss": 0.0337,
      "step": 36000
    },
    {
      "epoch": 2.482293887093447,
      "grad_norm": 0.0732768177986145,
      "learning_rate": 3.449335533893789e-05,
      "loss": 0.036,
      "step": 36100
    },
    {
      "epoch": 2.4891700474455063,
      "grad_norm": 0.15078105032444,
      "learning_rate": 3.4450375642546464e-05,
      "loss": 0.0382,
      "step": 36200
    },
    {
      "epoch": 2.496046207797566,
      "grad_norm": 0.15984447300434113,
      "learning_rate": 3.440739594615504e-05,
      "loss": 0.0353,
      "step": 36300
    },
    {
      "epoch": 2.5029223681496253,
      "grad_norm": 0.08285287767648697,
      "learning_rate": 3.436441624976361e-05,
      "loss": 0.0371,
      "step": 36400
    },
    {
      "epoch": 2.5097985285016846,
      "grad_norm": 0.19604246318340302,
      "learning_rate": 3.4321436553372186e-05,
      "loss": 0.0366,
      "step": 36500
    },
    {
      "epoch": 2.516674688853744,
      "grad_norm": 0.21133889257907867,
      "learning_rate": 3.427845685698076e-05,
      "loss": 0.0354,
      "step": 36600
    },
    {
      "epoch": 2.5235508492058036,
      "grad_norm": 0.13692407310009003,
      "learning_rate": 3.423547716058934e-05,
      "loss": 0.036,
      "step": 36700
    },
    {
      "epoch": 2.530427009557863,
      "grad_norm": 0.14427174627780914,
      "learning_rate": 3.4192497464197914e-05,
      "loss": 0.0374,
      "step": 36800
    },
    {
      "epoch": 2.537303169909922,
      "grad_norm": 0.08390074223279953,
      "learning_rate": 3.414951776780649e-05,
      "loss": 0.0369,
      "step": 36900
    },
    {
      "epoch": 2.544179330261982,
      "grad_norm": 0.11006210744380951,
      "learning_rate": 3.410653807141507e-05,
      "loss": 0.0342,
      "step": 37000
    },
    {
      "epoch": 2.5510554906140412,
      "grad_norm": 0.1633930802345276,
      "learning_rate": 3.406355837502364e-05,
      "loss": 0.0363,
      "step": 37100
    },
    {
      "epoch": 2.5579316509661005,
      "grad_norm": 0.16675882041454315,
      "learning_rate": 3.402057867863222e-05,
      "loss": 0.037,
      "step": 37200
    },
    {
      "epoch": 2.56480781131816,
      "grad_norm": 0.17660744488239288,
      "learning_rate": 3.397759898224079e-05,
      "loss": 0.0349,
      "step": 37300
    },
    {
      "epoch": 2.571683971670219,
      "grad_norm": 0.18592533469200134,
      "learning_rate": 3.3934619285849365e-05,
      "loss": 0.0346,
      "step": 37400
    },
    {
      "epoch": 2.578560132022279,
      "grad_norm": 0.20279398560523987,
      "learning_rate": 3.389163958945794e-05,
      "loss": 0.0373,
      "step": 37500
    },
    {
      "epoch": 2.585436292374338,
      "grad_norm": 0.19192670285701752,
      "learning_rate": 3.384865989306651e-05,
      "loss": 0.0355,
      "step": 37600
    },
    {
      "epoch": 2.5923124527263974,
      "grad_norm": 0.15298692882061005,
      "learning_rate": 3.380568019667509e-05,
      "loss": 0.0365,
      "step": 37700
    },
    {
      "epoch": 2.599188613078457,
      "grad_norm": 0.1488054394721985,
      "learning_rate": 3.376270050028367e-05,
      "loss": 0.0364,
      "step": 37800
    },
    {
      "epoch": 2.6060647734305165,
      "grad_norm": 0.16389915347099304,
      "learning_rate": 3.371972080389224e-05,
      "loss": 0.034,
      "step": 37900
    },
    {
      "epoch": 2.6129409337825757,
      "grad_norm": 0.250277578830719,
      "learning_rate": 3.367674110750082e-05,
      "loss": 0.0386,
      "step": 38000
    },
    {
      "epoch": 2.6198170941346355,
      "grad_norm": 0.20802666246891022,
      "learning_rate": 3.3633761411109396e-05,
      "loss": 0.037,
      "step": 38100
    },
    {
      "epoch": 2.6266932544866948,
      "grad_norm": 0.17302767932415009,
      "learning_rate": 3.359078171471797e-05,
      "loss": 0.0347,
      "step": 38200
    },
    {
      "epoch": 2.633569414838754,
      "grad_norm": 0.20201843976974487,
      "learning_rate": 3.3547802018326543e-05,
      "loss": 0.0373,
      "step": 38300
    },
    {
      "epoch": 2.6404455751908134,
      "grad_norm": 0.052721988409757614,
      "learning_rate": 3.350482232193512e-05,
      "loss": 0.0327,
      "step": 38400
    },
    {
      "epoch": 2.6473217355428726,
      "grad_norm": 0.1647724211215973,
      "learning_rate": 3.346184262554369e-05,
      "loss": 0.0364,
      "step": 38500
    },
    {
      "epoch": 2.6541978958949324,
      "grad_norm": 0.18488527834415436,
      "learning_rate": 3.341886292915227e-05,
      "loss": 0.0327,
      "step": 38600
    },
    {
      "epoch": 2.6610740562469917,
      "grad_norm": 0.22872252762317657,
      "learning_rate": 3.3375883232760846e-05,
      "loss": 0.037,
      "step": 38700
    },
    {
      "epoch": 2.667950216599051,
      "grad_norm": 0.2028205841779709,
      "learning_rate": 3.333290353636942e-05,
      "loss": 0.0389,
      "step": 38800
    },
    {
      "epoch": 2.6748263769511107,
      "grad_norm": 0.11881259828805923,
      "learning_rate": 3.3289923839977994e-05,
      "loss": 0.0334,
      "step": 38900
    },
    {
      "epoch": 2.68170253730317,
      "grad_norm": 0.282474160194397,
      "learning_rate": 3.324737394055048e-05,
      "loss": 0.0349,
      "step": 39000
    },
    {
      "epoch": 2.6885786976552293,
      "grad_norm": 0.22032155096530914,
      "learning_rate": 3.320439424415906e-05,
      "loss": 0.0341,
      "step": 39100
    },
    {
      "epoch": 2.6954548580072886,
      "grad_norm": 0.29456737637519836,
      "learning_rate": 3.316141454776764e-05,
      "loss": 0.0361,
      "step": 39200
    },
    {
      "epoch": 2.7023310183593483,
      "grad_norm": 0.22218795120716095,
      "learning_rate": 3.311843485137621e-05,
      "loss": 0.0358,
      "step": 39300
    },
    {
      "epoch": 2.7092071787114076,
      "grad_norm": 0.21918155252933502,
      "learning_rate": 3.3075455154984785e-05,
      "loss": 0.038,
      "step": 39400
    },
    {
      "epoch": 2.716083339063467,
      "grad_norm": 0.17316649854183197,
      "learning_rate": 3.303247545859336e-05,
      "loss": 0.0358,
      "step": 39500
    },
    {
      "epoch": 2.722959499415526,
      "grad_norm": 0.24231471121311188,
      "learning_rate": 3.298949576220194e-05,
      "loss": 0.0362,
      "step": 39600
    },
    {
      "epoch": 2.729835659767586,
      "grad_norm": 0.20220786333084106,
      "learning_rate": 3.2946516065810514e-05,
      "loss": 0.0357,
      "step": 39700
    },
    {
      "epoch": 2.736711820119645,
      "grad_norm": 0.11045411974191666,
      "learning_rate": 3.290353636941909e-05,
      "loss": 0.0371,
      "step": 39800
    },
    {
      "epoch": 2.7435879804717045,
      "grad_norm": 0.1314670890569687,
      "learning_rate": 3.286055667302766e-05,
      "loss": 0.0346,
      "step": 39900
    },
    {
      "epoch": 2.7504641408237642,
      "grad_norm": 0.21773503720760345,
      "learning_rate": 3.2817576976636235e-05,
      "loss": 0.0344,
      "step": 40000
    },
    {
      "epoch": 2.7573403011758235,
      "grad_norm": 0.1384189873933792,
      "learning_rate": 3.277459728024481e-05,
      "loss": 0.0362,
      "step": 40100
    },
    {
      "epoch": 2.764216461527883,
      "grad_norm": 0.17627952992916107,
      "learning_rate": 3.273161758385339e-05,
      "loss": 0.0317,
      "step": 40200
    },
    {
      "epoch": 2.771092621879942,
      "grad_norm": 0.17154154181480408,
      "learning_rate": 3.2688637887461964e-05,
      "loss": 0.0371,
      "step": 40300
    },
    {
      "epoch": 2.7779687822320014,
      "grad_norm": 0.1407514065504074,
      "learning_rate": 3.264565819107054e-05,
      "loss": 0.0359,
      "step": 40400
    },
    {
      "epoch": 2.784844942584061,
      "grad_norm": 0.19509582221508026,
      "learning_rate": 3.260267849467912e-05,
      "loss": 0.0372,
      "step": 40500
    },
    {
      "epoch": 2.7917211029361204,
      "grad_norm": 0.2614290714263916,
      "learning_rate": 3.255969879828769e-05,
      "loss": 0.04,
      "step": 40600
    },
    {
      "epoch": 2.7985972632881797,
      "grad_norm": 0.1412152349948883,
      "learning_rate": 3.2516719101896266e-05,
      "loss": 0.0361,
      "step": 40700
    },
    {
      "epoch": 2.8054734236402394,
      "grad_norm": 0.09165410697460175,
      "learning_rate": 3.247373940550485e-05,
      "loss": 0.035,
      "step": 40800
    },
    {
      "epoch": 2.8123495839922987,
      "grad_norm": 0.13163696229457855,
      "learning_rate": 3.243118950607733e-05,
      "loss": 0.0345,
      "step": 40900
    },
    {
      "epoch": 2.819225744344358,
      "grad_norm": 0.08784112334251404,
      "learning_rate": 3.23882098096859e-05,
      "loss": 0.0338,
      "step": 41000
    },
    {
      "epoch": 2.8261019046964178,
      "grad_norm": 0.18969474732875824,
      "learning_rate": 3.2345230113294484e-05,
      "loss": 0.0351,
      "step": 41100
    },
    {
      "epoch": 2.832978065048477,
      "grad_norm": 0.1966286599636078,
      "learning_rate": 3.230268021386697e-05,
      "loss": 0.0366,
      "step": 41200
    },
    {
      "epoch": 2.8398542254005363,
      "grad_norm": 0.20411130785942078,
      "learning_rate": 3.225970051747555e-05,
      "loss": 0.0341,
      "step": 41300
    },
    {
      "epoch": 2.8467303857525956,
      "grad_norm": 0.09314245730638504,
      "learning_rate": 3.221672082108412e-05,
      "loss": 0.0348,
      "step": 41400
    },
    {
      "epoch": 2.853606546104655,
      "grad_norm": 0.23904138803482056,
      "learning_rate": 3.2173741124692695e-05,
      "loss": 0.0332,
      "step": 41500
    },
    {
      "epoch": 2.8604827064567147,
      "grad_norm": 0.13605299592018127,
      "learning_rate": 3.213076142830127e-05,
      "loss": 0.0356,
      "step": 41600
    },
    {
      "epoch": 2.867358866808774,
      "grad_norm": 0.17558343708515167,
      "learning_rate": 3.208778173190985e-05,
      "loss": 0.0345,
      "step": 41700
    },
    {
      "epoch": 2.8742350271608332,
      "grad_norm": 0.253231942653656,
      "learning_rate": 3.204480203551842e-05,
      "loss": 0.0335,
      "step": 41800
    },
    {
      "epoch": 2.881111187512893,
      "grad_norm": 0.13470599055290222,
      "learning_rate": 3.2001822339127e-05,
      "loss": 0.0364,
      "step": 41900
    },
    {
      "epoch": 2.8879873478649523,
      "grad_norm": 0.22138077020645142,
      "learning_rate": 3.195884264273558e-05,
      "loss": 0.0364,
      "step": 42000
    },
    {
      "epoch": 2.8948635082170115,
      "grad_norm": 0.13921111822128296,
      "learning_rate": 3.191586294634415e-05,
      "loss": 0.0361,
      "step": 42100
    },
    {
      "epoch": 2.9017396685690713,
      "grad_norm": 0.14847373962402344,
      "learning_rate": 3.1872883249952726e-05,
      "loss": 0.0331,
      "step": 42200
    },
    {
      "epoch": 2.9086158289211306,
      "grad_norm": 0.20472879707813263,
      "learning_rate": 3.18299035535613e-05,
      "loss": 0.0322,
      "step": 42300
    },
    {
      "epoch": 2.91549198927319,
      "grad_norm": 0.13624197244644165,
      "learning_rate": 3.1786923857169873e-05,
      "loss": 0.0319,
      "step": 42400
    },
    {
      "epoch": 2.922368149625249,
      "grad_norm": 0.09072738885879517,
      "learning_rate": 3.174394416077845e-05,
      "loss": 0.0347,
      "step": 42500
    },
    {
      "epoch": 2.9292443099773084,
      "grad_norm": 0.13172096014022827,
      "learning_rate": 3.170096446438702e-05,
      "loss": 0.0358,
      "step": 42600
    },
    {
      "epoch": 2.936120470329368,
      "grad_norm": 0.13641642034053802,
      "learning_rate": 3.16579847679956e-05,
      "loss": 0.0363,
      "step": 42700
    },
    {
      "epoch": 2.9429966306814275,
      "grad_norm": 0.2813669443130493,
      "learning_rate": 3.1615005071604176e-05,
      "loss": 0.0341,
      "step": 42800
    },
    {
      "epoch": 2.9498727910334868,
      "grad_norm": 0.06970017403364182,
      "learning_rate": 3.157202537521275e-05,
      "loss": 0.0339,
      "step": 42900
    },
    {
      "epoch": 2.9567489513855465,
      "grad_norm": 0.15938153862953186,
      "learning_rate": 3.152904567882133e-05,
      "loss": 0.0365,
      "step": 43000
    },
    {
      "epoch": 2.963625111737606,
      "grad_norm": 0.16557005047798157,
      "learning_rate": 3.1486065982429904e-05,
      "loss": 0.0344,
      "step": 43100
    },
    {
      "epoch": 2.970501272089665,
      "grad_norm": 0.13395150005817413,
      "learning_rate": 3.144308628603848e-05,
      "loss": 0.0356,
      "step": 43200
    },
    {
      "epoch": 2.977377432441725,
      "grad_norm": 0.2615606486797333,
      "learning_rate": 3.140010658964705e-05,
      "loss": 0.0333,
      "step": 43300
    },
    {
      "epoch": 2.984253592793784,
      "grad_norm": 0.06008037552237511,
      "learning_rate": 3.1357126893255626e-05,
      "loss": 0.0347,
      "step": 43400
    },
    {
      "epoch": 2.9911297531458434,
      "grad_norm": 0.18624259531497955,
      "learning_rate": 3.13141471968642e-05,
      "loss": 0.0346,
      "step": 43500
    },
    {
      "epoch": 2.9980059134979027,
      "grad_norm": 0.1790689378976822,
      "learning_rate": 3.1271167500472774e-05,
      "loss": 0.0347,
      "step": 43600
    },
    {
      "epoch": 3.0,
      "eval_accuracy_macro_0.5": 0.9836609959602356,
      "eval_accuracy_micro_0.5": 0.9836609363555908,
      "eval_accuracy_weighted_0.5": 0.9814699292182922,
      "eval_f1_macro_0.5": 0.7890941500663757,
      "eval_f1_macro_0.6": 0.7782379388809204,
      "eval_f1_macro_0.7": 0.7523107528686523,
      "eval_f1_macro_0.8": 0.604189395904541,
      "eval_f1_micro_0.5": 0.7878957390785217,
      "eval_f1_micro_0.6": 0.7783516645431519,
      "eval_f1_micro_0.7": 0.7554161548614502,
      "eval_f1_micro_0.8": 0.7140163779258728,
      "eval_f1_micro_0.9": 0.6214997172355652,
      "eval_f1_weighted_0.5": 0.783107340335846,
      "eval_f1_weighted_0.6": 0.7698832750320435,
      "eval_f1_weighted_0.7": 0.7417212724685669,
      "eval_f1_weighted_0.8": 0.5861725807189941,
      "eval_loss": 0.03367091342806816,
      "eval_runtime": 133.6015,
      "eval_samples_per_second": 217.34,
      "eval_steps_per_second": 27.17,
      "step": 43629
    },
    {
      "epoch": 3.004882073849962,
      "grad_norm": 0.2050539255142212,
      "learning_rate": 3.1228187804081355e-05,
      "loss": 0.0351,
      "step": 43700
    },
    {
      "epoch": 3.0117582342020217,
      "grad_norm": 0.19516533613204956,
      "learning_rate": 3.118520810768993e-05,
      "loss": 0.0344,
      "step": 43800
    },
    {
      "epoch": 3.018634394554081,
      "grad_norm": 0.14582420885562897,
      "learning_rate": 3.11422284112985e-05,
      "loss": 0.0328,
      "step": 43900
    },
    {
      "epoch": 3.0255105549061403,
      "grad_norm": 0.21854016184806824,
      "learning_rate": 3.109924871490708e-05,
      "loss": 0.0374,
      "step": 44000
    },
    {
      "epoch": 3.0323867152582,
      "grad_norm": 0.08675000071525574,
      "learning_rate": 3.105626901851566e-05,
      "loss": 0.0324,
      "step": 44100
    },
    {
      "epoch": 3.0392628756102593,
      "grad_norm": 0.24591046571731567,
      "learning_rate": 3.101328932212423e-05,
      "loss": 0.0353,
      "step": 44200
    },
    {
      "epoch": 3.0461390359623186,
      "grad_norm": 0.06630472838878632,
      "learning_rate": 3.0970309625732805e-05,
      "loss": 0.0346,
      "step": 44300
    },
    {
      "epoch": 3.053015196314378,
      "grad_norm": 0.10485240817070007,
      "learning_rate": 3.092732992934138e-05,
      "loss": 0.0342,
      "step": 44400
    },
    {
      "epoch": 3.0598913566664376,
      "grad_norm": 0.16797085106372833,
      "learning_rate": 3.088435023294995e-05,
      "loss": 0.034,
      "step": 44500
    },
    {
      "epoch": 3.066767517018497,
      "grad_norm": 0.2924562692642212,
      "learning_rate": 3.084180033352245e-05,
      "loss": 0.0326,
      "step": 44600
    },
    {
      "epoch": 3.073643677370556,
      "grad_norm": 0.19350631535053253,
      "learning_rate": 3.079882063713102e-05,
      "loss": 0.036,
      "step": 44700
    },
    {
      "epoch": 3.0805198377226155,
      "grad_norm": 0.10648715496063232,
      "learning_rate": 3.0755840940739596e-05,
      "loss": 0.0339,
      "step": 44800
    },
    {
      "epoch": 3.0873959980746752,
      "grad_norm": 0.1367293894290924,
      "learning_rate": 3.071286124434817e-05,
      "loss": 0.0339,
      "step": 44900
    },
    {
      "epoch": 3.0942721584267345,
      "grad_norm": 0.14735819399356842,
      "learning_rate": 3.0669881547956744e-05,
      "loss": 0.0368,
      "step": 45000
    },
    {
      "epoch": 3.101148318778794,
      "grad_norm": 0.17947839200496674,
      "learning_rate": 3.062690185156532e-05,
      "loss": 0.0315,
      "step": 45100
    },
    {
      "epoch": 3.1080244791308536,
      "grad_norm": 0.12563051283359528,
      "learning_rate": 3.05839221551739e-05,
      "loss": 0.0343,
      "step": 45200
    },
    {
      "epoch": 3.114900639482913,
      "grad_norm": 0.32566389441490173,
      "learning_rate": 3.054094245878247e-05,
      "loss": 0.034,
      "step": 45300
    },
    {
      "epoch": 3.121776799834972,
      "grad_norm": 0.2966451644897461,
      "learning_rate": 3.0497962762391047e-05,
      "loss": 0.0356,
      "step": 45400
    },
    {
      "epoch": 3.1286529601870314,
      "grad_norm": 0.19359970092773438,
      "learning_rate": 3.045498306599962e-05,
      "loss": 0.0353,
      "step": 45500
    },
    {
      "epoch": 3.135529120539091,
      "grad_norm": 0.26040858030319214,
      "learning_rate": 3.04120033696082e-05,
      "loss": 0.0343,
      "step": 45600
    },
    {
      "epoch": 3.1424052808911505,
      "grad_norm": 0.08283662796020508,
      "learning_rate": 3.0369023673216772e-05,
      "loss": 0.0337,
      "step": 45700
    },
    {
      "epoch": 3.1492814412432097,
      "grad_norm": 0.15707723796367645,
      "learning_rate": 3.0326043976825346e-05,
      "loss": 0.0335,
      "step": 45800
    },
    {
      "epoch": 3.156157601595269,
      "grad_norm": 0.16529738903045654,
      "learning_rate": 3.0283064280433926e-05,
      "loss": 0.0352,
      "step": 45900
    },
    {
      "epoch": 3.1630337619473288,
      "grad_norm": 0.1801116168498993,
      "learning_rate": 3.02400845840425e-05,
      "loss": 0.0356,
      "step": 46000
    },
    {
      "epoch": 3.169909922299388,
      "grad_norm": 0.17906290292739868,
      "learning_rate": 3.0197104887651074e-05,
      "loss": 0.0339,
      "step": 46100
    },
    {
      "epoch": 3.1767860826514474,
      "grad_norm": 0.13177064061164856,
      "learning_rate": 3.015412519125965e-05,
      "loss": 0.032,
      "step": 46200
    },
    {
      "epoch": 3.1836622430035066,
      "grad_norm": 0.21368642151355743,
      "learning_rate": 3.0111145494868225e-05,
      "loss": 0.0342,
      "step": 46300
    },
    {
      "epoch": 3.1905384033555664,
      "grad_norm": 0.11936008185148239,
      "learning_rate": 3.00681657984768e-05,
      "loss": 0.0316,
      "step": 46400
    },
    {
      "epoch": 3.1974145637076257,
      "grad_norm": 0.28428614139556885,
      "learning_rate": 3.002518610208538e-05,
      "loss": 0.0359,
      "step": 46500
    },
    {
      "epoch": 3.204290724059685,
      "grad_norm": 0.10831739008426666,
      "learning_rate": 2.9982206405693954e-05,
      "loss": 0.0366,
      "step": 46600
    },
    {
      "epoch": 3.2111668844117442,
      "grad_norm": 0.18888375163078308,
      "learning_rate": 2.9939226709302524e-05,
      "loss": 0.0335,
      "step": 46700
    },
    {
      "epoch": 3.218043044763804,
      "grad_norm": 0.2429496943950653,
      "learning_rate": 2.9896247012911105e-05,
      "loss": 0.0351,
      "step": 46800
    },
    {
      "epoch": 3.2249192051158633,
      "grad_norm": 0.25524890422821045,
      "learning_rate": 2.985326731651968e-05,
      "loss": 0.0362,
      "step": 46900
    },
    {
      "epoch": 3.2317953654679226,
      "grad_norm": 0.2194514125585556,
      "learning_rate": 2.9810287620128253e-05,
      "loss": 0.0352,
      "step": 47000
    },
    {
      "epoch": 3.2386715258199823,
      "grad_norm": 0.16275273263454437,
      "learning_rate": 2.9767307923736827e-05,
      "loss": 0.033,
      "step": 47100
    },
    {
      "epoch": 3.2455476861720416,
      "grad_norm": 0.18165381252765656,
      "learning_rate": 2.9724328227345404e-05,
      "loss": 0.0346,
      "step": 47200
    },
    {
      "epoch": 3.252423846524101,
      "grad_norm": 0.30529308319091797,
      "learning_rate": 2.9681348530953978e-05,
      "loss": 0.035,
      "step": 47300
    },
    {
      "epoch": 3.25930000687616,
      "grad_norm": 0.48230960965156555,
      "learning_rate": 2.9638368834562552e-05,
      "loss": 0.0334,
      "step": 47400
    },
    {
      "epoch": 3.26617616722822,
      "grad_norm": 0.23234060406684875,
      "learning_rate": 2.9595389138171133e-05,
      "loss": 0.032,
      "step": 47500
    },
    {
      "epoch": 3.273052327580279,
      "grad_norm": 0.17804645001888275,
      "learning_rate": 2.9552409441779703e-05,
      "loss": 0.0342,
      "step": 47600
    },
    {
      "epoch": 3.2799284879323385,
      "grad_norm": 0.2597070634365082,
      "learning_rate": 2.9509429745388277e-05,
      "loss": 0.0327,
      "step": 47700
    },
    {
      "epoch": 3.286804648284398,
      "grad_norm": 0.1454324722290039,
      "learning_rate": 2.946687984596077e-05,
      "loss": 0.0327,
      "step": 47800
    },
    {
      "epoch": 3.2936808086364575,
      "grad_norm": 0.3204071521759033,
      "learning_rate": 2.9423900149569343e-05,
      "loss": 0.0343,
      "step": 47900
    },
    {
      "epoch": 3.300556968988517,
      "grad_norm": 0.19195491075515747,
      "learning_rate": 2.9380920453177917e-05,
      "loss": 0.0366,
      "step": 48000
    },
    {
      "epoch": 3.307433129340576,
      "grad_norm": 0.18658941984176636,
      "learning_rate": 2.9337940756786498e-05,
      "loss": 0.0365,
      "step": 48100
    },
    {
      "epoch": 3.314309289692636,
      "grad_norm": 0.08347003906965256,
      "learning_rate": 2.9294961060395072e-05,
      "loss": 0.0318,
      "step": 48200
    },
    {
      "epoch": 3.321185450044695,
      "grad_norm": 0.207497239112854,
      "learning_rate": 2.9251981364003646e-05,
      "loss": 0.0329,
      "step": 48300
    },
    {
      "epoch": 3.3280616103967544,
      "grad_norm": 0.1111302524805069,
      "learning_rate": 2.9209001667612223e-05,
      "loss": 0.0328,
      "step": 48400
    },
    {
      "epoch": 3.3349377707488137,
      "grad_norm": 0.14098462462425232,
      "learning_rate": 2.9166021971220797e-05,
      "loss": 0.0345,
      "step": 48500
    },
    {
      "epoch": 3.3418139311008734,
      "grad_norm": 0.20784178376197815,
      "learning_rate": 2.912304227482937e-05,
      "loss": 0.0345,
      "step": 48600
    },
    {
      "epoch": 3.3486900914529327,
      "grad_norm": 0.15819469094276428,
      "learning_rate": 2.9080062578437948e-05,
      "loss": 0.0363,
      "step": 48700
    },
    {
      "epoch": 3.355566251804992,
      "grad_norm": 0.13054120540618896,
      "learning_rate": 2.9037082882046522e-05,
      "loss": 0.0357,
      "step": 48800
    },
    {
      "epoch": 3.3624424121570513,
      "grad_norm": 0.11712495982646942,
      "learning_rate": 2.8994103185655096e-05,
      "loss": 0.033,
      "step": 48900
    },
    {
      "epoch": 3.369318572509111,
      "grad_norm": 0.2518578767776489,
      "learning_rate": 2.895112348926367e-05,
      "loss": 0.036,
      "step": 49000
    },
    {
      "epoch": 3.3761947328611703,
      "grad_norm": 0.1342002898454666,
      "learning_rate": 2.890814379287225e-05,
      "loss": 0.0335,
      "step": 49100
    },
    {
      "epoch": 3.3830708932132296,
      "grad_norm": 0.04149820655584335,
      "learning_rate": 2.8865164096480825e-05,
      "loss": 0.0306,
      "step": 49200
    },
    {
      "epoch": 3.3899470535652894,
      "grad_norm": 0.09488436579704285,
      "learning_rate": 2.88221844000894e-05,
      "loss": 0.0331,
      "step": 49300
    },
    {
      "epoch": 3.3968232139173486,
      "grad_norm": 0.13868045806884766,
      "learning_rate": 2.8779204703697976e-05,
      "loss": 0.0347,
      "step": 49400
    },
    {
      "epoch": 3.403699374269408,
      "grad_norm": 0.16492396593093872,
      "learning_rate": 2.873622500730655e-05,
      "loss": 0.0348,
      "step": 49500
    },
    {
      "epoch": 3.4105755346214672,
      "grad_norm": 0.20993733406066895,
      "learning_rate": 2.8693245310915124e-05,
      "loss": 0.0346,
      "step": 49600
    },
    {
      "epoch": 3.417451694973527,
      "grad_norm": 0.13912615180015564,
      "learning_rate": 2.86502656145237e-05,
      "loss": 0.0321,
      "step": 49700
    },
    {
      "epoch": 3.4243278553255863,
      "grad_norm": 0.18977487087249756,
      "learning_rate": 2.8607285918132275e-05,
      "loss": 0.034,
      "step": 49800
    },
    {
      "epoch": 3.4312040156776455,
      "grad_norm": 0.30875295400619507,
      "learning_rate": 2.856430622174085e-05,
      "loss": 0.0326,
      "step": 49900
    },
    {
      "epoch": 3.438080176029705,
      "grad_norm": 0.22121746838092804,
      "learning_rate": 2.852132652534943e-05,
      "loss": 0.0332,
      "step": 50000
    },
    {
      "epoch": 3.4449563363817646,
      "grad_norm": 0.11791609227657318,
      "learning_rate": 2.8478346828958003e-05,
      "loss": 0.032,
      "step": 50100
    },
    {
      "epoch": 3.451832496733824,
      "grad_norm": 0.23175665736198425,
      "learning_rate": 2.8435367132566577e-05,
      "loss": 0.0353,
      "step": 50200
    },
    {
      "epoch": 3.458708657085883,
      "grad_norm": 0.28321897983551025,
      "learning_rate": 2.839238743617515e-05,
      "loss": 0.0339,
      "step": 50300
    },
    {
      "epoch": 3.465584817437943,
      "grad_norm": 0.12028749287128448,
      "learning_rate": 2.834940773978373e-05,
      "loss": 0.0352,
      "step": 50400
    },
    {
      "epoch": 3.472460977790002,
      "grad_norm": 0.19881242513656616,
      "learning_rate": 2.8306428043392302e-05,
      "loss": 0.0336,
      "step": 50500
    },
    {
      "epoch": 3.4793371381420615,
      "grad_norm": 0.19974258542060852,
      "learning_rate": 2.8263448347000876e-05,
      "loss": 0.0333,
      "step": 50600
    },
    {
      "epoch": 3.4862132984941208,
      "grad_norm": 0.1930721402168274,
      "learning_rate": 2.8220468650609454e-05,
      "loss": 0.0381,
      "step": 50700
    },
    {
      "epoch": 3.49308945884618,
      "grad_norm": 0.24093952775001526,
      "learning_rate": 2.8177488954218028e-05,
      "loss": 0.0328,
      "step": 50800
    },
    {
      "epoch": 3.49996561919824,
      "grad_norm": 0.158257395029068,
      "learning_rate": 2.81345092578266e-05,
      "loss": 0.0342,
      "step": 50900
    },
    {
      "epoch": 3.506841779550299,
      "grad_norm": 0.25495007634162903,
      "learning_rate": 2.8091529561435182e-05,
      "loss": 0.0335,
      "step": 51000
    },
    {
      "epoch": 3.5137179399023584,
      "grad_norm": 0.20160387456417084,
      "learning_rate": 2.8048549865043756e-05,
      "loss": 0.0334,
      "step": 51100
    },
    {
      "epoch": 3.520594100254418,
      "grad_norm": 0.18260638415813446,
      "learning_rate": 2.800557016865233e-05,
      "loss": 0.034,
      "step": 51200
    },
    {
      "epoch": 3.5274702606064774,
      "grad_norm": 0.17156316339969635,
      "learning_rate": 2.7962590472260907e-05,
      "loss": 0.0353,
      "step": 51300
    },
    {
      "epoch": 3.5343464209585367,
      "grad_norm": 0.19961903989315033,
      "learning_rate": 2.791961077586948e-05,
      "loss": 0.0321,
      "step": 51400
    },
    {
      "epoch": 3.5412225813105964,
      "grad_norm": 0.2336777299642563,
      "learning_rate": 2.7876631079478055e-05,
      "loss": 0.0313,
      "step": 51500
    },
    {
      "epoch": 3.5480987416626557,
      "grad_norm": 0.14568471908569336,
      "learning_rate": 2.783365138308663e-05,
      "loss": 0.0346,
      "step": 51600
    },
    {
      "epoch": 3.554974902014715,
      "grad_norm": 0.13214895129203796,
      "learning_rate": 2.7790671686695206e-05,
      "loss": 0.0353,
      "step": 51700
    },
    {
      "epoch": 3.5618510623667743,
      "grad_norm": 0.14232872426509857,
      "learning_rate": 2.774769199030378e-05,
      "loss": 0.0334,
      "step": 51800
    },
    {
      "epoch": 3.5687272227188336,
      "grad_norm": 0.1936047226190567,
      "learning_rate": 2.7704712293912354e-05,
      "loss": 0.0344,
      "step": 51900
    },
    {
      "epoch": 3.5756033830708933,
      "grad_norm": 0.1509319692850113,
      "learning_rate": 2.7661732597520935e-05,
      "loss": 0.0338,
      "step": 52000
    },
    {
      "epoch": 3.5824795434229526,
      "grad_norm": 0.22262822091579437,
      "learning_rate": 2.761875290112951e-05,
      "loss": 0.0358,
      "step": 52100
    },
    {
      "epoch": 3.589355703775012,
      "grad_norm": 0.2536684274673462,
      "learning_rate": 2.7575773204738083e-05,
      "loss": 0.0359,
      "step": 52200
    },
    {
      "epoch": 3.5962318641270716,
      "grad_norm": 0.1524181216955185,
      "learning_rate": 2.753279350834666e-05,
      "loss": 0.0323,
      "step": 52300
    },
    {
      "epoch": 3.603108024479131,
      "grad_norm": 0.10925144702196121,
      "learning_rate": 2.7489813811955234e-05,
      "loss": 0.0348,
      "step": 52400
    },
    {
      "epoch": 3.60998418483119,
      "grad_norm": 0.17024947702884674,
      "learning_rate": 2.7446834115563808e-05,
      "loss": 0.0354,
      "step": 52500
    },
    {
      "epoch": 3.61686034518325,
      "grad_norm": 0.17796500027179718,
      "learning_rate": 2.74042842161363e-05,
      "loss": 0.0347,
      "step": 52600
    },
    {
      "epoch": 3.6237365055353092,
      "grad_norm": 0.2755741775035858,
      "learning_rate": 2.7361304519744874e-05,
      "loss": 0.0308,
      "step": 52700
    },
    {
      "epoch": 3.6306126658873685,
      "grad_norm": 0.1537674516439438,
      "learning_rate": 2.7318324823353448e-05,
      "loss": 0.034,
      "step": 52800
    },
    {
      "epoch": 3.637488826239428,
      "grad_norm": 0.09340813755989075,
      "learning_rate": 2.7275345126962025e-05,
      "loss": 0.0322,
      "step": 52900
    },
    {
      "epoch": 3.644364986591487,
      "grad_norm": 0.17084980010986328,
      "learning_rate": 2.7232795227534514e-05,
      "loss": 0.0346,
      "step": 53000
    },
    {
      "epoch": 3.651241146943547,
      "grad_norm": 0.14402812719345093,
      "learning_rate": 2.7189815531143088e-05,
      "loss": 0.0332,
      "step": 53100
    },
    {
      "epoch": 3.658117307295606,
      "grad_norm": 0.15994501113891602,
      "learning_rate": 2.7146835834751666e-05,
      "loss": 0.0308,
      "step": 53200
    },
    {
      "epoch": 3.6649934676476654,
      "grad_norm": 0.09235339611768723,
      "learning_rate": 2.710385613836024e-05,
      "loss": 0.0341,
      "step": 53300
    },
    {
      "epoch": 3.671869627999725,
      "grad_norm": 0.09953093528747559,
      "learning_rate": 2.7060876441968813e-05,
      "loss": 0.0329,
      "step": 53400
    },
    {
      "epoch": 3.6787457883517845,
      "grad_norm": 0.1534312218427658,
      "learning_rate": 2.7017896745577394e-05,
      "loss": 0.0336,
      "step": 53500
    },
    {
      "epoch": 3.6856219487038437,
      "grad_norm": 0.13799196481704712,
      "learning_rate": 2.6974917049185965e-05,
      "loss": 0.0329,
      "step": 53600
    },
    {
      "epoch": 3.692498109055903,
      "grad_norm": 0.20418395102024078,
      "learning_rate": 2.693193735279454e-05,
      "loss": 0.0331,
      "step": 53700
    },
    {
      "epoch": 3.6993742694079623,
      "grad_norm": 0.1963317096233368,
      "learning_rate": 2.688895765640312e-05,
      "loss": 0.0354,
      "step": 53800
    },
    {
      "epoch": 3.706250429760022,
      "grad_norm": 0.20533303916454315,
      "learning_rate": 2.6845977960011693e-05,
      "loss": 0.0335,
      "step": 53900
    },
    {
      "epoch": 3.7131265901120813,
      "grad_norm": 0.12814299762248993,
      "learning_rate": 2.6802998263620267e-05,
      "loss": 0.0353,
      "step": 54000
    },
    {
      "epoch": 3.7200027504641406,
      "grad_norm": 0.1343746930360794,
      "learning_rate": 2.6760018567228844e-05,
      "loss": 0.0335,
      "step": 54100
    },
    {
      "epoch": 3.7268789108162004,
      "grad_norm": 0.16962246596813202,
      "learning_rate": 2.6717038870837418e-05,
      "loss": 0.0328,
      "step": 54200
    },
    {
      "epoch": 3.7337550711682597,
      "grad_norm": 0.12264805287122726,
      "learning_rate": 2.6674059174445992e-05,
      "loss": 0.0336,
      "step": 54300
    },
    {
      "epoch": 3.740631231520319,
      "grad_norm": 0.2578887939453125,
      "learning_rate": 2.6631079478054566e-05,
      "loss": 0.0329,
      "step": 54400
    },
    {
      "epoch": 3.7475073918723787,
      "grad_norm": 0.09973683208227158,
      "learning_rate": 2.6588099781663143e-05,
      "loss": 0.0349,
      "step": 54500
    },
    {
      "epoch": 3.754383552224438,
      "grad_norm": 0.11853247880935669,
      "learning_rate": 2.6545120085271717e-05,
      "loss": 0.0327,
      "step": 54600
    },
    {
      "epoch": 3.7612597125764973,
      "grad_norm": 0.2760680913925171,
      "learning_rate": 2.650214038888029e-05,
      "loss": 0.0346,
      "step": 54700
    },
    {
      "epoch": 3.7681358729285566,
      "grad_norm": 0.1119990348815918,
      "learning_rate": 2.6459160692488872e-05,
      "loss": 0.0335,
      "step": 54800
    },
    {
      "epoch": 3.775012033280616,
      "grad_norm": 0.16489893198013306,
      "learning_rate": 2.6416180996097446e-05,
      "loss": 0.032,
      "step": 54900
    },
    {
      "epoch": 3.7818881936326756,
      "grad_norm": 0.18874290585517883,
      "learning_rate": 2.637320129970602e-05,
      "loss": 0.0327,
      "step": 55000
    },
    {
      "epoch": 3.788764353984735,
      "grad_norm": 0.04551622271537781,
      "learning_rate": 2.6330221603314597e-05,
      "loss": 0.0328,
      "step": 55100
    },
    {
      "epoch": 3.795640514336794,
      "grad_norm": 0.0925525650382042,
      "learning_rate": 2.628724190692317e-05,
      "loss": 0.0344,
      "step": 55200
    },
    {
      "epoch": 3.802516674688854,
      "grad_norm": 0.11274314671754837,
      "learning_rate": 2.6244262210531745e-05,
      "loss": 0.0323,
      "step": 55300
    },
    {
      "epoch": 3.809392835040913,
      "grad_norm": 0.3321414887905121,
      "learning_rate": 2.6201282514140325e-05,
      "loss": 0.0345,
      "step": 55400
    },
    {
      "epoch": 3.8162689953929725,
      "grad_norm": 0.22235046327114105,
      "learning_rate": 2.6158302817748896e-05,
      "loss": 0.0342,
      "step": 55500
    },
    {
      "epoch": 3.823145155745032,
      "grad_norm": 0.17358210682868958,
      "learning_rate": 2.611532312135747e-05,
      "loss": 0.0355,
      "step": 55600
    },
    {
      "epoch": 3.8300213160970915,
      "grad_norm": 0.21653014421463013,
      "learning_rate": 2.6072343424966044e-05,
      "loss": 0.0329,
      "step": 55700
    },
    {
      "epoch": 3.836897476449151,
      "grad_norm": 0.17715266346931458,
      "learning_rate": 2.6029363728574625e-05,
      "loss": 0.0296,
      "step": 55800
    },
    {
      "epoch": 3.84377363680121,
      "grad_norm": 0.1198173463344574,
      "learning_rate": 2.59863840321832e-05,
      "loss": 0.0302,
      "step": 55900
    },
    {
      "epoch": 3.8506497971532694,
      "grad_norm": 0.11721007525920868,
      "learning_rate": 2.5943404335791772e-05,
      "loss": 0.0332,
      "step": 56000
    },
    {
      "epoch": 3.857525957505329,
      "grad_norm": 0.20645132660865784,
      "learning_rate": 2.590042463940035e-05,
      "loss": 0.0342,
      "step": 56100
    },
    {
      "epoch": 3.8644021178573884,
      "grad_norm": 0.13241557776927948,
      "learning_rate": 2.5857444943008924e-05,
      "loss": 0.0347,
      "step": 56200
    },
    {
      "epoch": 3.8712782782094477,
      "grad_norm": 0.0909356102347374,
      "learning_rate": 2.5814465246617497e-05,
      "loss": 0.0339,
      "step": 56300
    },
    {
      "epoch": 3.8781544385615074,
      "grad_norm": 0.15040192008018494,
      "learning_rate": 2.5771485550226078e-05,
      "loss": 0.0335,
      "step": 56400
    },
    {
      "epoch": 3.8850305989135667,
      "grad_norm": 0.18237432837486267,
      "learning_rate": 2.572850585383465e-05,
      "loss": 0.0309,
      "step": 56500
    },
    {
      "epoch": 3.891906759265626,
      "grad_norm": 0.2291446030139923,
      "learning_rate": 2.5685526157443223e-05,
      "loss": 0.035,
      "step": 56600
    },
    {
      "epoch": 3.8987829196176857,
      "grad_norm": 0.09460467845201492,
      "learning_rate": 2.5642546461051803e-05,
      "loss": 0.0331,
      "step": 56700
    },
    {
      "epoch": 3.905659079969745,
      "grad_norm": 0.17648616433143616,
      "learning_rate": 2.5599566764660377e-05,
      "loss": 0.0364,
      "step": 56800
    },
    {
      "epoch": 3.9125352403218043,
      "grad_norm": 0.28806379437446594,
      "learning_rate": 2.555658706826895e-05,
      "loss": 0.0369,
      "step": 56900
    },
    {
      "epoch": 3.9194114006738636,
      "grad_norm": 0.16839194297790527,
      "learning_rate": 2.5513607371877525e-05,
      "loss": 0.0305,
      "step": 57000
    },
    {
      "epoch": 3.926287561025923,
      "grad_norm": 0.21627989411354065,
      "learning_rate": 2.5470627675486102e-05,
      "loss": 0.0317,
      "step": 57100
    },
    {
      "epoch": 3.9331637213779826,
      "grad_norm": 0.16954584419727325,
      "learning_rate": 2.5427647979094676e-05,
      "loss": 0.0334,
      "step": 57200
    },
    {
      "epoch": 3.940039881730042,
      "grad_norm": 0.26476389169692993,
      "learning_rate": 2.538466828270325e-05,
      "loss": 0.0315,
      "step": 57300
    },
    {
      "epoch": 3.9469160420821012,
      "grad_norm": 0.08419839292764664,
      "learning_rate": 2.534168858631183e-05,
      "loss": 0.0318,
      "step": 57400
    },
    {
      "epoch": 3.953792202434161,
      "grad_norm": 0.23860418796539307,
      "learning_rate": 2.52987088899204e-05,
      "loss": 0.0325,
      "step": 57500
    },
    {
      "epoch": 3.9606683627862203,
      "grad_norm": 0.21625007688999176,
      "learning_rate": 2.5255729193528975e-05,
      "loss": 0.0321,
      "step": 57600
    },
    {
      "epoch": 3.9675445231382795,
      "grad_norm": 0.17238615453243256,
      "learning_rate": 2.5212749497137556e-05,
      "loss": 0.0322,
      "step": 57700
    },
    {
      "epoch": 3.974420683490339,
      "grad_norm": 0.2726643979549408,
      "learning_rate": 2.516976980074613e-05,
      "loss": 0.0348,
      "step": 57800
    },
    {
      "epoch": 3.9812968438423986,
      "grad_norm": 0.19701960682868958,
      "learning_rate": 2.5126790104354704e-05,
      "loss": 0.0302,
      "step": 57900
    },
    {
      "epoch": 3.988173004194458,
      "grad_norm": 0.18353530764579773,
      "learning_rate": 2.508381040796328e-05,
      "loss": 0.0315,
      "step": 58000
    },
    {
      "epoch": 3.995049164546517,
      "grad_norm": 0.2723342776298523,
      "learning_rate": 2.5040830711571855e-05,
      "loss": 0.0341,
      "step": 58100
    },
    {
      "epoch": 4.0,
      "eval_accuracy_macro_0.5": 0.9844164252281189,
      "eval_accuracy_micro_0.5": 0.9844164252281189,
      "eval_accuracy_weighted_0.5": 0.9823204874992371,
      "eval_f1_macro_0.5": 0.8012277483940125,
      "eval_f1_macro_0.6": 0.7933258414268494,
      "eval_f1_macro_0.7": 0.771440863609314,
      "eval_f1_macro_0.8": 0.6367762684822083,
      "eval_f1_micro_0.5": 0.7995237112045288,
      "eval_f1_micro_0.6": 0.7924643754959106,
      "eval_f1_micro_0.7": 0.7729427218437195,
      "eval_f1_micro_0.8": 0.7341118454933167,
      "eval_f1_micro_0.9": 0.6496244072914124,
      "eval_f1_weighted_0.5": 0.7963247299194336,
      "eval_f1_weighted_0.6": 0.7863994836807251,
      "eval_f1_weighted_0.7": 0.762866199016571,
      "eval_f1_weighted_0.8": 0.621149480342865,
      "eval_loss": 0.03241841495037079,
      "eval_runtime": 133.7813,
      "eval_samples_per_second": 217.048,
      "eval_steps_per_second": 27.134,
      "step": 58172
    },
    {
      "epoch": 4.001925324898576,
      "grad_norm": 0.1581568866968155,
      "learning_rate": 2.499785101518043e-05,
      "loss": 0.033,
      "step": 58200
    },
    {
      "epoch": 4.008801485250636,
      "grad_norm": 0.13822945952415466,
      "learning_rate": 2.4954871318789006e-05,
      "loss": 0.0324,
      "step": 58300
    },
    {
      "epoch": 4.015677645602695,
      "grad_norm": 0.20077672600746155,
      "learning_rate": 2.4911891622397583e-05,
      "loss": 0.0332,
      "step": 58400
    },
    {
      "epoch": 4.022553805954755,
      "grad_norm": 0.19634729623794556,
      "learning_rate": 2.4868911926006154e-05,
      "loss": 0.0361,
      "step": 58500
    },
    {
      "epoch": 4.0294299663068145,
      "grad_norm": 0.1403610110282898,
      "learning_rate": 2.482593222961473e-05,
      "loss": 0.0292,
      "step": 58600
    },
    {
      "epoch": 4.036306126658873,
      "grad_norm": 0.3773048520088196,
      "learning_rate": 2.4782952533223305e-05,
      "loss": 0.0315,
      "step": 58700
    },
    {
      "epoch": 4.043182287010933,
      "grad_norm": 0.21136149764060974,
      "learning_rate": 2.4739972836831883e-05,
      "loss": 0.0337,
      "step": 58800
    },
    {
      "epoch": 4.050058447362993,
      "grad_norm": 0.11243468523025513,
      "learning_rate": 2.4696993140440456e-05,
      "loss": 0.0321,
      "step": 58900
    },
    {
      "epoch": 4.056934607715052,
      "grad_norm": 0.14794045686721802,
      "learning_rate": 2.465401344404903e-05,
      "loss": 0.0331,
      "step": 59000
    },
    {
      "epoch": 4.063810768067111,
      "grad_norm": 0.14240817725658417,
      "learning_rate": 2.4611033747657608e-05,
      "loss": 0.0322,
      "step": 59100
    },
    {
      "epoch": 4.070686928419171,
      "grad_norm": 0.15325459837913513,
      "learning_rate": 2.456805405126618e-05,
      "loss": 0.0322,
      "step": 59200
    },
    {
      "epoch": 4.07756308877123,
      "grad_norm": 0.31468454003334045,
      "learning_rate": 2.452507435487476e-05,
      "loss": 0.0339,
      "step": 59300
    },
    {
      "epoch": 4.08443924912329,
      "grad_norm": 0.12163324654102325,
      "learning_rate": 2.4482094658483333e-05,
      "loss": 0.0326,
      "step": 59400
    },
    {
      "epoch": 4.0913154094753486,
      "grad_norm": 0.12108813971281052,
      "learning_rate": 2.4439544759055825e-05,
      "loss": 0.0308,
      "step": 59500
    },
    {
      "epoch": 4.098191569827408,
      "grad_norm": 0.051331549882888794,
      "learning_rate": 2.43965650626644e-05,
      "loss": 0.035,
      "step": 59600
    },
    {
      "epoch": 4.105067730179468,
      "grad_norm": 0.11742686480283737,
      "learning_rate": 2.4354015163236888e-05,
      "loss": 0.0327,
      "step": 59700
    },
    {
      "epoch": 4.111943890531527,
      "grad_norm": 0.2116968333721161,
      "learning_rate": 2.4311035466845462e-05,
      "loss": 0.0338,
      "step": 59800
    },
    {
      "epoch": 4.118820050883587,
      "grad_norm": 0.12009993940591812,
      "learning_rate": 2.4268055770454036e-05,
      "loss": 0.0353,
      "step": 59900
    },
    {
      "epoch": 4.125696211235646,
      "grad_norm": 0.12928295135498047,
      "learning_rate": 2.4225076074062613e-05,
      "loss": 0.0332,
      "step": 60000
    },
    {
      "epoch": 4.132572371587705,
      "grad_norm": 0.16977983713150024,
      "learning_rate": 2.4182526174635102e-05,
      "loss": 0.0313,
      "step": 60100
    },
    {
      "epoch": 4.139448531939765,
      "grad_norm": 0.19295939803123474,
      "learning_rate": 2.413954647824368e-05,
      "loss": 0.0291,
      "step": 60200
    },
    {
      "epoch": 4.146324692291825,
      "grad_norm": 0.13199260830879211,
      "learning_rate": 2.4096566781852254e-05,
      "loss": 0.0322,
      "step": 60300
    },
    {
      "epoch": 4.1532008526438835,
      "grad_norm": 0.22630871832370758,
      "learning_rate": 2.405358708546083e-05,
      "loss": 0.0332,
      "step": 60400
    },
    {
      "epoch": 4.160077012995943,
      "grad_norm": 0.14066745340824127,
      "learning_rate": 2.4010607389069405e-05,
      "loss": 0.0324,
      "step": 60500
    },
    {
      "epoch": 4.166953173348002,
      "grad_norm": 0.1529579609632492,
      "learning_rate": 2.396762769267798e-05,
      "loss": 0.032,
      "step": 60600
    },
    {
      "epoch": 4.173829333700062,
      "grad_norm": 0.19012735784053802,
      "learning_rate": 2.3924647996286556e-05,
      "loss": 0.0299,
      "step": 60700
    },
    {
      "epoch": 4.1807054940521216,
      "grad_norm": 0.21948683261871338,
      "learning_rate": 2.388166829989513e-05,
      "loss": 0.0317,
      "step": 60800
    },
    {
      "epoch": 4.18758165440418,
      "grad_norm": 0.15854233503341675,
      "learning_rate": 2.3838688603503707e-05,
      "loss": 0.0345,
      "step": 60900
    },
    {
      "epoch": 4.19445781475624,
      "grad_norm": 0.18320128321647644,
      "learning_rate": 2.379570890711228e-05,
      "loss": 0.032,
      "step": 61000
    },
    {
      "epoch": 4.2013339751083,
      "grad_norm": 0.19528786838054657,
      "learning_rate": 2.3752729210720855e-05,
      "loss": 0.0324,
      "step": 61100
    },
    {
      "epoch": 4.208210135460359,
      "grad_norm": 0.1894771158695221,
      "learning_rate": 2.3709749514329432e-05,
      "loss": 0.0323,
      "step": 61200
    },
    {
      "epoch": 4.2150862958124184,
      "grad_norm": 0.17871280014514923,
      "learning_rate": 2.3666769817938006e-05,
      "loss": 0.0313,
      "step": 61300
    },
    {
      "epoch": 4.221962456164478,
      "grad_norm": 0.1552405059337616,
      "learning_rate": 2.3623790121546584e-05,
      "loss": 0.0321,
      "step": 61400
    },
    {
      "epoch": 4.228838616516537,
      "grad_norm": 0.1881956309080124,
      "learning_rate": 2.3580810425155157e-05,
      "loss": 0.0308,
      "step": 61500
    },
    {
      "epoch": 4.235714776868597,
      "grad_norm": 0.17208921909332275,
      "learning_rate": 2.353783072876373e-05,
      "loss": 0.0348,
      "step": 61600
    },
    {
      "epoch": 4.242590937220656,
      "grad_norm": 0.16296929121017456,
      "learning_rate": 2.349485103237231e-05,
      "loss": 0.0346,
      "step": 61700
    },
    {
      "epoch": 4.249467097572715,
      "grad_norm": 0.26680681109428406,
      "learning_rate": 2.3451871335980886e-05,
      "loss": 0.0322,
      "step": 61800
    },
    {
      "epoch": 4.256343257924775,
      "grad_norm": 0.1873684823513031,
      "learning_rate": 2.340889163958946e-05,
      "loss": 0.0318,
      "step": 61900
    },
    {
      "epoch": 4.263219418276834,
      "grad_norm": 0.22040632367134094,
      "learning_rate": 2.3365911943198034e-05,
      "loss": 0.0353,
      "step": 62000
    },
    {
      "epoch": 4.270095578628894,
      "grad_norm": 0.25064989924430847,
      "learning_rate": 2.3322932246806608e-05,
      "loss": 0.0314,
      "step": 62100
    },
    {
      "epoch": 4.276971738980953,
      "grad_norm": 0.11416185647249222,
      "learning_rate": 2.3279952550415185e-05,
      "loss": 0.0311,
      "step": 62200
    },
    {
      "epoch": 4.283847899333012,
      "grad_norm": 0.1732795387506485,
      "learning_rate": 2.3236972854023762e-05,
      "loss": 0.0336,
      "step": 62300
    },
    {
      "epoch": 4.290724059685072,
      "grad_norm": 0.16870827972888947,
      "learning_rate": 2.3193993157632336e-05,
      "loss": 0.033,
      "step": 62400
    },
    {
      "epoch": 4.297600220037131,
      "grad_norm": 0.25386276841163635,
      "learning_rate": 2.315101346124091e-05,
      "loss": 0.0301,
      "step": 62500
    },
    {
      "epoch": 4.304476380389191,
      "grad_norm": 0.21873196959495544,
      "learning_rate": 2.3108033764849484e-05,
      "loss": 0.033,
      "step": 62600
    },
    {
      "epoch": 4.31135254074125,
      "grad_norm": 0.2441183626651764,
      "learning_rate": 2.306505406845806e-05,
      "loss": 0.0313,
      "step": 62700
    },
    {
      "epoch": 4.318228701093309,
      "grad_norm": 0.20747721195220947,
      "learning_rate": 2.302250416903055e-05,
      "loss": 0.0317,
      "step": 62800
    },
    {
      "epoch": 4.325104861445369,
      "grad_norm": 0.17349375784397125,
      "learning_rate": 2.2979524472639128e-05,
      "loss": 0.0324,
      "step": 62900
    },
    {
      "epoch": 4.331981021797429,
      "grad_norm": 0.20422938466072083,
      "learning_rate": 2.29365447762477e-05,
      "loss": 0.0347,
      "step": 63000
    },
    {
      "epoch": 4.3388571821494875,
      "grad_norm": 0.11619860678911209,
      "learning_rate": 2.289356507985628e-05,
      "loss": 0.0323,
      "step": 63100
    },
    {
      "epoch": 4.345733342501547,
      "grad_norm": 0.13672035932540894,
      "learning_rate": 2.2851015180428768e-05,
      "loss": 0.0337,
      "step": 63200
    },
    {
      "epoch": 4.352609502853607,
      "grad_norm": 0.13178899884223938,
      "learning_rate": 2.2808035484037342e-05,
      "loss": 0.0297,
      "step": 63300
    },
    {
      "epoch": 4.359485663205666,
      "grad_norm": 0.24050411581993103,
      "learning_rate": 2.2765055787645916e-05,
      "loss": 0.0338,
      "step": 63400
    },
    {
      "epoch": 4.3663618235577255,
      "grad_norm": 0.1843997985124588,
      "learning_rate": 2.2722076091254493e-05,
      "loss": 0.0334,
      "step": 63500
    },
    {
      "epoch": 4.373237983909785,
      "grad_norm": 0.19939649105072021,
      "learning_rate": 2.2679096394863067e-05,
      "loss": 0.0336,
      "step": 63600
    },
    {
      "epoch": 4.380114144261844,
      "grad_norm": 0.13795456290245056,
      "learning_rate": 2.2636116698471644e-05,
      "loss": 0.036,
      "step": 63700
    },
    {
      "epoch": 4.386990304613904,
      "grad_norm": 0.30142179131507874,
      "learning_rate": 2.2593137002080218e-05,
      "loss": 0.0327,
      "step": 63800
    },
    {
      "epoch": 4.393866464965963,
      "grad_norm": 0.11373312771320343,
      "learning_rate": 2.2550157305688792e-05,
      "loss": 0.0321,
      "step": 63900
    },
    {
      "epoch": 4.400742625318022,
      "grad_norm": 0.2745020389556885,
      "learning_rate": 2.250717760929737e-05,
      "loss": 0.0313,
      "step": 64000
    },
    {
      "epoch": 4.407618785670082,
      "grad_norm": 0.21325376629829407,
      "learning_rate": 2.2464197912905943e-05,
      "loss": 0.0314,
      "step": 64100
    },
    {
      "epoch": 4.414494946022141,
      "grad_norm": 0.10759784281253815,
      "learning_rate": 2.242121821651452e-05,
      "loss": 0.0328,
      "step": 64200
    },
    {
      "epoch": 4.421371106374201,
      "grad_norm": 0.14542900025844574,
      "learning_rate": 2.2378238520123094e-05,
      "loss": 0.0341,
      "step": 64300
    },
    {
      "epoch": 4.4282472667262605,
      "grad_norm": 0.2347891628742218,
      "learning_rate": 2.233525882373167e-05,
      "loss": 0.0325,
      "step": 64400
    },
    {
      "epoch": 4.435123427078319,
      "grad_norm": 0.2191341668367386,
      "learning_rate": 2.2292279127340246e-05,
      "loss": 0.0324,
      "step": 64500
    },
    {
      "epoch": 4.441999587430379,
      "grad_norm": 0.15441156923770905,
      "learning_rate": 2.224929943094882e-05,
      "loss": 0.0308,
      "step": 64600
    },
    {
      "epoch": 4.448875747782438,
      "grad_norm": 0.23389296233654022,
      "learning_rate": 2.2206319734557397e-05,
      "loss": 0.0299,
      "step": 64700
    },
    {
      "epoch": 4.455751908134498,
      "grad_norm": 0.21879702806472778,
      "learning_rate": 2.216334003816597e-05,
      "loss": 0.0318,
      "step": 64800
    },
    {
      "epoch": 4.462628068486557,
      "grad_norm": 0.09294425696134567,
      "learning_rate": 2.2120360341774545e-05,
      "loss": 0.0308,
      "step": 64900
    },
    {
      "epoch": 4.469504228838616,
      "grad_norm": 0.18274052441120148,
      "learning_rate": 2.2077380645383122e-05,
      "loss": 0.0311,
      "step": 65000
    },
    {
      "epoch": 4.476380389190676,
      "grad_norm": 0.1907072216272354,
      "learning_rate": 2.20344009489917e-05,
      "loss": 0.0319,
      "step": 65100
    },
    {
      "epoch": 4.483256549542736,
      "grad_norm": 0.12385129183530807,
      "learning_rate": 2.1991421252600273e-05,
      "loss": 0.0338,
      "step": 65200
    },
    {
      "epoch": 4.4901327098947945,
      "grad_norm": 0.23047126829624176,
      "learning_rate": 2.1948441556208847e-05,
      "loss": 0.0325,
      "step": 65300
    },
    {
      "epoch": 4.497008870246854,
      "grad_norm": 0.1722314953804016,
      "learning_rate": 2.190546185981742e-05,
      "loss": 0.032,
      "step": 65400
    },
    {
      "epoch": 4.503885030598914,
      "grad_norm": 0.1865333765745163,
      "learning_rate": 2.1862482163426e-05,
      "loss": 0.0305,
      "step": 65500
    },
    {
      "epoch": 4.510761190950973,
      "grad_norm": 0.22047355771064758,
      "learning_rate": 2.1819502467034576e-05,
      "loss": 0.0306,
      "step": 65600
    },
    {
      "epoch": 4.517637351303033,
      "grad_norm": 0.16445142030715942,
      "learning_rate": 2.177652277064315e-05,
      "loss": 0.0323,
      "step": 65700
    },
    {
      "epoch": 4.524513511655091,
      "grad_norm": 0.17586232721805573,
      "learning_rate": 2.1733543074251724e-05,
      "loss": 0.032,
      "step": 65800
    },
    {
      "epoch": 4.531389672007151,
      "grad_norm": 0.11774736642837524,
      "learning_rate": 2.1690563377860297e-05,
      "loss": 0.0296,
      "step": 65900
    },
    {
      "epoch": 4.538265832359211,
      "grad_norm": 0.07890865206718445,
      "learning_rate": 2.1647583681468875e-05,
      "loss": 0.0293,
      "step": 66000
    },
    {
      "epoch": 4.54514199271127,
      "grad_norm": 0.22137384116649628,
      "learning_rate": 2.1604603985077452e-05,
      "loss": 0.0337,
      "step": 66100
    },
    {
      "epoch": 4.5520181530633295,
      "grad_norm": 0.17948311567306519,
      "learning_rate": 2.1561624288686026e-05,
      "loss": 0.0341,
      "step": 66200
    },
    {
      "epoch": 4.558894313415389,
      "grad_norm": 0.19276821613311768,
      "learning_rate": 2.15186445922946e-05,
      "loss": 0.0328,
      "step": 66300
    },
    {
      "epoch": 4.565770473767448,
      "grad_norm": 0.21528051793575287,
      "learning_rate": 2.1475664895903177e-05,
      "loss": 0.0314,
      "step": 66400
    },
    {
      "epoch": 4.572646634119508,
      "grad_norm": 0.19155313074588776,
      "learning_rate": 2.143268519951175e-05,
      "loss": 0.031,
      "step": 66500
    },
    {
      "epoch": 4.579522794471567,
      "grad_norm": 0.11398034542798996,
      "learning_rate": 2.138970550312033e-05,
      "loss": 0.0305,
      "step": 66600
    },
    {
      "epoch": 4.586398954823626,
      "grad_norm": 0.21461406350135803,
      "learning_rate": 2.1346725806728902e-05,
      "loss": 0.0302,
      "step": 66700
    },
    {
      "epoch": 4.593275115175686,
      "grad_norm": 0.1616920530796051,
      "learning_rate": 2.1303746110337476e-05,
      "loss": 0.0335,
      "step": 66800
    },
    {
      "epoch": 4.600151275527745,
      "grad_norm": 0.2661133408546448,
      "learning_rate": 2.1260766413946053e-05,
      "loss": 0.0302,
      "step": 66900
    },
    {
      "epoch": 4.607027435879805,
      "grad_norm": 0.24807250499725342,
      "learning_rate": 2.1217786717554627e-05,
      "loss": 0.0313,
      "step": 67000
    },
    {
      "epoch": 4.613903596231864,
      "grad_norm": 0.20183779299259186,
      "learning_rate": 2.1175236818127116e-05,
      "loss": 0.0334,
      "step": 67100
    },
    {
      "epoch": 4.620779756583923,
      "grad_norm": 0.1806991696357727,
      "learning_rate": 2.1132257121735694e-05,
      "loss": 0.031,
      "step": 67200
    },
    {
      "epoch": 4.627655916935983,
      "grad_norm": 0.3709065914154053,
      "learning_rate": 2.1089277425344268e-05,
      "loss": 0.0321,
      "step": 67300
    },
    {
      "epoch": 4.634532077288043,
      "grad_norm": 0.17799057066440582,
      "learning_rate": 2.1046297728952845e-05,
      "loss": 0.0335,
      "step": 67400
    },
    {
      "epoch": 4.641408237640102,
      "grad_norm": 0.13311950862407684,
      "learning_rate": 2.100331803256142e-05,
      "loss": 0.0318,
      "step": 67500
    },
    {
      "epoch": 4.648284397992161,
      "grad_norm": 0.1898137480020523,
      "learning_rate": 2.0960338336169993e-05,
      "loss": 0.0307,
      "step": 67600
    },
    {
      "epoch": 4.655160558344221,
      "grad_norm": 0.21408496797084808,
      "learning_rate": 2.091735863977857e-05,
      "loss": 0.03,
      "step": 67700
    },
    {
      "epoch": 4.66203671869628,
      "grad_norm": 0.1566377580165863,
      "learning_rate": 2.0874378943387147e-05,
      "loss": 0.0312,
      "step": 67800
    },
    {
      "epoch": 4.66891287904834,
      "grad_norm": 0.22364088892936707,
      "learning_rate": 2.083139924699572e-05,
      "loss": 0.0333,
      "step": 67900
    },
    {
      "epoch": 4.6757890394003985,
      "grad_norm": 0.13573864102363586,
      "learning_rate": 2.0788419550604295e-05,
      "loss": 0.0328,
      "step": 68000
    },
    {
      "epoch": 4.682665199752458,
      "grad_norm": 0.19234149158000946,
      "learning_rate": 2.074543985421287e-05,
      "loss": 0.0331,
      "step": 68100
    },
    {
      "epoch": 4.689541360104518,
      "grad_norm": 0.12964145839214325,
      "learning_rate": 2.0702460157821446e-05,
      "loss": 0.0304,
      "step": 68200
    },
    {
      "epoch": 4.696417520456577,
      "grad_norm": 0.16508567333221436,
      "learning_rate": 2.0659480461430024e-05,
      "loss": 0.0317,
      "step": 68300
    },
    {
      "epoch": 4.7032936808086365,
      "grad_norm": 0.1325625777244568,
      "learning_rate": 2.0616500765038598e-05,
      "loss": 0.0325,
      "step": 68400
    },
    {
      "epoch": 4.710169841160695,
      "grad_norm": 0.12771058082580566,
      "learning_rate": 2.057352106864717e-05,
      "loss": 0.0317,
      "step": 68500
    },
    {
      "epoch": 4.717046001512755,
      "grad_norm": 0.1532255858182907,
      "learning_rate": 2.0530541372255745e-05,
      "loss": 0.0312,
      "step": 68600
    },
    {
      "epoch": 4.723922161864815,
      "grad_norm": 0.1828305870294571,
      "learning_rate": 2.0487561675864323e-05,
      "loss": 0.0322,
      "step": 68700
    },
    {
      "epoch": 4.730798322216874,
      "grad_norm": 0.16867274045944214,
      "learning_rate": 2.04445819794729e-05,
      "loss": 0.0299,
      "step": 68800
    },
    {
      "epoch": 4.737674482568933,
      "grad_norm": 0.2597162425518036,
      "learning_rate": 2.0401602283081474e-05,
      "loss": 0.0303,
      "step": 68900
    },
    {
      "epoch": 4.744550642920993,
      "grad_norm": 0.14003102481365204,
      "learning_rate": 2.0358622586690048e-05,
      "loss": 0.0296,
      "step": 69000
    },
    {
      "epoch": 4.751426803273052,
      "grad_norm": 0.14426730573177338,
      "learning_rate": 2.0315642890298625e-05,
      "loss": 0.0317,
      "step": 69100
    },
    {
      "epoch": 4.758302963625112,
      "grad_norm": 0.07275686413049698,
      "learning_rate": 2.02726631939072e-05,
      "loss": 0.0312,
      "step": 69200
    },
    {
      "epoch": 4.7651791239771715,
      "grad_norm": 0.2824949026107788,
      "learning_rate": 2.0229683497515776e-05,
      "loss": 0.0316,
      "step": 69300
    },
    {
      "epoch": 4.77205528432923,
      "grad_norm": 0.12433791160583496,
      "learning_rate": 2.018670380112435e-05,
      "loss": 0.0318,
      "step": 69400
    },
    {
      "epoch": 4.77893144468129,
      "grad_norm": 0.10216700285673141,
      "learning_rate": 2.0143724104732924e-05,
      "loss": 0.0338,
      "step": 69500
    },
    {
      "epoch": 4.78580760503335,
      "grad_norm": 0.09376528114080429,
      "learning_rate": 2.01007444083415e-05,
      "loss": 0.0309,
      "step": 69600
    },
    {
      "epoch": 4.792683765385409,
      "grad_norm": 0.2815162241458893,
      "learning_rate": 2.0057764711950075e-05,
      "loss": 0.0335,
      "step": 69700
    },
    {
      "epoch": 4.799559925737468,
      "grad_norm": 0.2811513841152191,
      "learning_rate": 2.0014785015558653e-05,
      "loss": 0.0296,
      "step": 69800
    },
    {
      "epoch": 4.806436086089528,
      "grad_norm": 0.13045772910118103,
      "learning_rate": 1.9971805319167227e-05,
      "loss": 0.0345,
      "step": 69900
    },
    {
      "epoch": 4.813312246441587,
      "grad_norm": 0.22564034163951874,
      "learning_rate": 1.99288256227758e-05,
      "loss": 0.0338,
      "step": 70000
    },
    {
      "epoch": 4.820188406793647,
      "grad_norm": 0.1876315474510193,
      "learning_rate": 1.9885845926384378e-05,
      "loss": 0.0327,
      "step": 70100
    },
    {
      "epoch": 4.8270645671457055,
      "grad_norm": 0.25691214203834534,
      "learning_rate": 1.9842866229992952e-05,
      "loss": 0.0346,
      "step": 70200
    },
    {
      "epoch": 4.833940727497765,
      "grad_norm": 0.10502178221940994,
      "learning_rate": 1.979988653360153e-05,
      "loss": 0.0322,
      "step": 70300
    },
    {
      "epoch": 4.840816887849825,
      "grad_norm": 0.1970822662115097,
      "learning_rate": 1.9756906837210103e-05,
      "loss": 0.0314,
      "step": 70400
    },
    {
      "epoch": 4.847693048201884,
      "grad_norm": 0.4155386686325073,
      "learning_rate": 1.9713927140818677e-05,
      "loss": 0.0351,
      "step": 70500
    },
    {
      "epoch": 4.854569208553944,
      "grad_norm": 0.1405263990163803,
      "learning_rate": 1.9670947444427254e-05,
      "loss": 0.0362,
      "step": 70600
    },
    {
      "epoch": 4.861445368906002,
      "grad_norm": 0.1359473466873169,
      "learning_rate": 1.9627967748035828e-05,
      "loss": 0.0329,
      "step": 70700
    },
    {
      "epoch": 4.868321529258062,
      "grad_norm": 0.1772979348897934,
      "learning_rate": 1.9584988051644405e-05,
      "loss": 0.0287,
      "step": 70800
    },
    {
      "epoch": 4.875197689610122,
      "grad_norm": 0.2173154354095459,
      "learning_rate": 1.954200835525298e-05,
      "loss": 0.0317,
      "step": 70900
    },
    {
      "epoch": 4.882073849962181,
      "grad_norm": 0.1415242850780487,
      "learning_rate": 1.9499028658861553e-05,
      "loss": 0.0339,
      "step": 71000
    },
    {
      "epoch": 4.8889500103142405,
      "grad_norm": 0.14573068916797638,
      "learning_rate": 1.945604896247013e-05,
      "loss": 0.0326,
      "step": 71100
    },
    {
      "epoch": 4.8958261706663,
      "grad_norm": 0.11339142173528671,
      "learning_rate": 1.9413069266078708e-05,
      "loss": 0.0325,
      "step": 71200
    },
    {
      "epoch": 4.902702331018359,
      "grad_norm": 0.2538868486881256,
      "learning_rate": 1.9370089569687282e-05,
      "loss": 0.0328,
      "step": 71300
    },
    {
      "epoch": 4.909578491370419,
      "grad_norm": 0.19635266065597534,
      "learning_rate": 1.9327109873295856e-05,
      "loss": 0.0317,
      "step": 71400
    },
    {
      "epoch": 4.9164546517224785,
      "grad_norm": 0.12431575357913971,
      "learning_rate": 1.928413017690443e-05,
      "loss": 0.0314,
      "step": 71500
    },
    {
      "epoch": 4.923330812074537,
      "grad_norm": 0.16271743178367615,
      "learning_rate": 1.9241150480513007e-05,
      "loss": 0.0348,
      "step": 71600
    },
    {
      "epoch": 4.930206972426597,
      "grad_norm": 0.1799646019935608,
      "learning_rate": 1.9198170784121584e-05,
      "loss": 0.0339,
      "step": 71700
    },
    {
      "epoch": 4.937083132778657,
      "grad_norm": 0.17961686849594116,
      "learning_rate": 1.9155191087730158e-05,
      "loss": 0.0323,
      "step": 71800
    },
    {
      "epoch": 4.943959293130716,
      "grad_norm": 0.19019512832164764,
      "learning_rate": 1.9112211391338732e-05,
      "loss": 0.0332,
      "step": 71900
    },
    {
      "epoch": 4.950835453482775,
      "grad_norm": 0.08887722343206406,
      "learning_rate": 1.9069231694947306e-05,
      "loss": 0.0305,
      "step": 72000
    },
    {
      "epoch": 4.957711613834834,
      "grad_norm": 0.1792479157447815,
      "learning_rate": 1.9026251998555883e-05,
      "loss": 0.0298,
      "step": 72100
    },
    {
      "epoch": 4.964587774186894,
      "grad_norm": 0.26183390617370605,
      "learning_rate": 1.898327230216446e-05,
      "loss": 0.0313,
      "step": 72200
    },
    {
      "epoch": 4.971463934538954,
      "grad_norm": 0.13896746933460236,
      "learning_rate": 1.8940292605773034e-05,
      "loss": 0.0292,
      "step": 72300
    },
    {
      "epoch": 4.978340094891013,
      "grad_norm": 0.40449628233909607,
      "learning_rate": 1.8897312909381608e-05,
      "loss": 0.0319,
      "step": 72400
    },
    {
      "epoch": 4.985216255243072,
      "grad_norm": 0.26497748494148254,
      "learning_rate": 1.8854333212990186e-05,
      "loss": 0.0353,
      "step": 72500
    },
    {
      "epoch": 4.992092415595132,
      "grad_norm": 0.23554539680480957,
      "learning_rate": 1.881135351659876e-05,
      "loss": 0.0302,
      "step": 72600
    },
    {
      "epoch": 4.998968575947191,
      "grad_norm": 0.3014107942581177,
      "learning_rate": 1.8768373820207337e-05,
      "loss": 0.0334,
      "step": 72700
    },
    {
      "epoch": 5.0,
      "eval_accuracy_macro_0.5": 0.984956681728363,
      "eval_accuracy_micro_0.5": 0.984956681728363,
      "eval_accuracy_weighted_0.5": 0.9828842282295227,
      "eval_f1_macro_0.5": 0.8091413378715515,
      "eval_f1_macro_0.6": 0.8018113970756531,
      "eval_f1_macro_0.7": 0.7807921171188354,
      "eval_f1_macro_0.8": 0.6532948613166809,
      "eval_f1_micro_0.5": 0.8072690963745117,
      "eval_f1_micro_0.6": 0.8010881543159485,
      "eval_f1_micro_0.7": 0.7826641201972961,
      "eval_f1_micro_0.8": 0.746744692325592,
      "eval_f1_micro_0.9": 0.6663387417793274,
      "eval_f1_weighted_0.5": 0.804573118686676,
      "eval_f1_weighted_0.6": 0.7956166863441467,
      "eval_f1_weighted_0.7": 0.7733349800109863,
      "eval_f1_weighted_0.8": 0.6396616101264954,
      "eval_loss": 0.03135807812213898,
      "eval_runtime": 133.5135,
      "eval_samples_per_second": 217.484,
      "eval_steps_per_second": 27.188,
      "step": 72715
    },
    {
      "epoch": 5.005844736299251,
      "grad_norm": 0.17323251068592072,
      "learning_rate": 1.872539412381591e-05,
      "loss": 0.0301,
      "step": 72800
    },
    {
      "epoch": 5.0127208966513095,
      "grad_norm": 0.23820210993289948,
      "learning_rate": 1.8682414427424485e-05,
      "loss": 0.0291,
      "step": 72900
    },
    {
      "epoch": 5.019597057003369,
      "grad_norm": 0.22759653627872467,
      "learning_rate": 1.8639434731033062e-05,
      "loss": 0.0308,
      "step": 73000
    },
    {
      "epoch": 5.026473217355429,
      "grad_norm": 0.21865977346897125,
      "learning_rate": 1.8596455034641636e-05,
      "loss": 0.0331,
      "step": 73100
    },
    {
      "epoch": 5.033349377707488,
      "grad_norm": 0.32759958505630493,
      "learning_rate": 1.8553905135214125e-05,
      "loss": 0.0313,
      "step": 73200
    },
    {
      "epoch": 5.0402255380595475,
      "grad_norm": 0.20077794790267944,
      "learning_rate": 1.8510925438822702e-05,
      "loss": 0.0297,
      "step": 73300
    },
    {
      "epoch": 5.047101698411607,
      "grad_norm": 0.15862931311130524,
      "learning_rate": 1.8467945742431276e-05,
      "loss": 0.0302,
      "step": 73400
    },
    {
      "epoch": 5.053977858763666,
      "grad_norm": 0.15417951345443726,
      "learning_rate": 1.842496604603985e-05,
      "loss": 0.0313,
      "step": 73500
    },
    {
      "epoch": 5.060854019115726,
      "grad_norm": 0.18203599750995636,
      "learning_rate": 1.8381986349648427e-05,
      "loss": 0.0326,
      "step": 73600
    },
    {
      "epoch": 5.067730179467786,
      "grad_norm": 0.3096776604652405,
      "learning_rate": 1.8339006653257e-05,
      "loss": 0.0317,
      "step": 73700
    },
    {
      "epoch": 5.074606339819844,
      "grad_norm": 0.1364765763282776,
      "learning_rate": 1.829602695686558e-05,
      "loss": 0.0315,
      "step": 73800
    },
    {
      "epoch": 5.081482500171904,
      "grad_norm": 0.2869093716144562,
      "learning_rate": 1.8253047260474156e-05,
      "loss": 0.0314,
      "step": 73900
    },
    {
      "epoch": 5.088358660523963,
      "grad_norm": 0.21184097230434418,
      "learning_rate": 1.8210067564082726e-05,
      "loss": 0.0318,
      "step": 74000
    },
    {
      "epoch": 5.095234820876023,
      "grad_norm": 0.17738862335681915,
      "learning_rate": 1.8167087867691304e-05,
      "loss": 0.0315,
      "step": 74100
    },
    {
      "epoch": 5.1021109812280825,
      "grad_norm": 0.21774663031101227,
      "learning_rate": 1.8124108171299878e-05,
      "loss": 0.0317,
      "step": 74200
    },
    {
      "epoch": 5.108987141580141,
      "grad_norm": 0.22306253015995026,
      "learning_rate": 1.8081558271872367e-05,
      "loss": 0.0314,
      "step": 74300
    },
    {
      "epoch": 5.115863301932201,
      "grad_norm": 0.198709636926651,
      "learning_rate": 1.8038578575480944e-05,
      "loss": 0.0311,
      "step": 74400
    },
    {
      "epoch": 5.122739462284261,
      "grad_norm": 0.18247075378894806,
      "learning_rate": 1.799559887908952e-05,
      "loss": 0.0313,
      "step": 74500
    },
    {
      "epoch": 5.12961562263632,
      "grad_norm": 0.1478782594203949,
      "learning_rate": 1.7952619182698095e-05,
      "loss": 0.0318,
      "step": 74600
    },
    {
      "epoch": 5.136491782988379,
      "grad_norm": 0.20799584686756134,
      "learning_rate": 1.790963948630667e-05,
      "loss": 0.0293,
      "step": 74700
    },
    {
      "epoch": 5.143367943340439,
      "grad_norm": 0.244709774851799,
      "learning_rate": 1.7866659789915243e-05,
      "loss": 0.034,
      "step": 74800
    },
    {
      "epoch": 5.150244103692498,
      "grad_norm": 0.08687691390514374,
      "learning_rate": 1.782368009352382e-05,
      "loss": 0.0298,
      "step": 74900
    },
    {
      "epoch": 5.157120264044558,
      "grad_norm": 0.18721897900104523,
      "learning_rate": 1.7780700397132398e-05,
      "loss": 0.0325,
      "step": 75000
    },
    {
      "epoch": 5.1639964243966165,
      "grad_norm": 0.1513342708349228,
      "learning_rate": 1.773772070074097e-05,
      "loss": 0.0313,
      "step": 75100
    },
    {
      "epoch": 5.170872584748676,
      "grad_norm": 0.13462398946285248,
      "learning_rate": 1.7694741004349545e-05,
      "loss": 0.0301,
      "step": 75200
    },
    {
      "epoch": 5.177748745100736,
      "grad_norm": 0.132777139544487,
      "learning_rate": 1.765176130795812e-05,
      "loss": 0.0287,
      "step": 75300
    },
    {
      "epoch": 5.184624905452795,
      "grad_norm": 0.1407117396593094,
      "learning_rate": 1.7608781611566697e-05,
      "loss": 0.0325,
      "step": 75400
    },
    {
      "epoch": 5.191501065804855,
      "grad_norm": 0.1561306267976761,
      "learning_rate": 1.7565801915175274e-05,
      "loss": 0.0341,
      "step": 75500
    },
    {
      "epoch": 5.198377226156914,
      "grad_norm": 0.1563321202993393,
      "learning_rate": 1.7522822218783848e-05,
      "loss": 0.0284,
      "step": 75600
    },
    {
      "epoch": 5.205253386508973,
      "grad_norm": 0.1828082948923111,
      "learning_rate": 1.747984252239242e-05,
      "loss": 0.033,
      "step": 75700
    },
    {
      "epoch": 5.212129546861033,
      "grad_norm": 0.10199927538633347,
      "learning_rate": 1.7436862826001e-05,
      "loss": 0.0313,
      "step": 75800
    },
    {
      "epoch": 5.219005707213093,
      "grad_norm": 0.11811207979917526,
      "learning_rate": 1.7393883129609573e-05,
      "loss": 0.0318,
      "step": 75900
    },
    {
      "epoch": 5.2258818675651515,
      "grad_norm": 0.2446589469909668,
      "learning_rate": 1.735090343321815e-05,
      "loss": 0.0316,
      "step": 76000
    },
    {
      "epoch": 5.232758027917211,
      "grad_norm": 0.11305102705955505,
      "learning_rate": 1.7307923736826724e-05,
      "loss": 0.0297,
      "step": 76100
    },
    {
      "epoch": 5.23963418826927,
      "grad_norm": 0.1623678356409073,
      "learning_rate": 1.7264944040435298e-05,
      "loss": 0.0315,
      "step": 76200
    },
    {
      "epoch": 5.24651034862133,
      "grad_norm": 0.19939588010311127,
      "learning_rate": 1.7221964344043875e-05,
      "loss": 0.0314,
      "step": 76300
    },
    {
      "epoch": 5.2533865089733895,
      "grad_norm": 0.10623279213905334,
      "learning_rate": 1.717898464765245e-05,
      "loss": 0.0314,
      "step": 76400
    },
    {
      "epoch": 5.260262669325448,
      "grad_norm": 0.0747983530163765,
      "learning_rate": 1.7136004951261027e-05,
      "loss": 0.0325,
      "step": 76500
    },
    {
      "epoch": 5.267138829677508,
      "grad_norm": 0.12483194470405579,
      "learning_rate": 1.70930252548696e-05,
      "loss": 0.0327,
      "step": 76600
    },
    {
      "epoch": 5.274014990029568,
      "grad_norm": 0.1911354809999466,
      "learning_rate": 1.7050045558478174e-05,
      "loss": 0.0295,
      "step": 76700
    },
    {
      "epoch": 5.280891150381627,
      "grad_norm": 0.18196451663970947,
      "learning_rate": 1.700706586208675e-05,
      "loss": 0.0312,
      "step": 76800
    },
    {
      "epoch": 5.287767310733686,
      "grad_norm": 0.25792691111564636,
      "learning_rate": 1.6964086165695326e-05,
      "loss": 0.0315,
      "step": 76900
    },
    {
      "epoch": 5.294643471085745,
      "grad_norm": 0.22340917587280273,
      "learning_rate": 1.6921106469303903e-05,
      "loss": 0.0311,
      "step": 77000
    },
    {
      "epoch": 5.301519631437805,
      "grad_norm": 0.3093512952327728,
      "learning_rate": 1.6878126772912477e-05,
      "loss": 0.0304,
      "step": 77100
    },
    {
      "epoch": 5.308395791789865,
      "grad_norm": 0.2235209345817566,
      "learning_rate": 1.683514707652105e-05,
      "loss": 0.03,
      "step": 77200
    },
    {
      "epoch": 5.315271952141924,
      "grad_norm": 0.140272855758667,
      "learning_rate": 1.6792167380129628e-05,
      "loss": 0.0326,
      "step": 77300
    },
    {
      "epoch": 5.322148112493983,
      "grad_norm": 0.15548871457576752,
      "learning_rate": 1.6749187683738202e-05,
      "loss": 0.0307,
      "step": 77400
    },
    {
      "epoch": 5.329024272846043,
      "grad_norm": 0.13087977468967438,
      "learning_rate": 1.670620798734678e-05,
      "loss": 0.0283,
      "step": 77500
    },
    {
      "epoch": 5.335900433198102,
      "grad_norm": 0.26564013957977295,
      "learning_rate": 1.6663228290955353e-05,
      "loss": 0.0344,
      "step": 77600
    },
    {
      "epoch": 5.342776593550162,
      "grad_norm": 0.08444389700889587,
      "learning_rate": 1.6620248594563927e-05,
      "loss": 0.0316,
      "step": 77700
    },
    {
      "epoch": 5.349652753902221,
      "grad_norm": 0.13523511588573456,
      "learning_rate": 1.6577268898172504e-05,
      "loss": 0.0309,
      "step": 77800
    },
    {
      "epoch": 5.35652891425428,
      "grad_norm": 0.21074938774108887,
      "learning_rate": 1.653428920178108e-05,
      "loss": 0.031,
      "step": 77900
    },
    {
      "epoch": 5.36340507460634,
      "grad_norm": 0.347572386264801,
      "learning_rate": 1.6491309505389656e-05,
      "loss": 0.0335,
      "step": 78000
    },
    {
      "epoch": 5.370281234958399,
      "grad_norm": 0.14597280323505402,
      "learning_rate": 1.644832980899823e-05,
      "loss": 0.032,
      "step": 78100
    },
    {
      "epoch": 5.3771573953104586,
      "grad_norm": 0.24657903611660004,
      "learning_rate": 1.6405350112606803e-05,
      "loss": 0.0303,
      "step": 78200
    },
    {
      "epoch": 5.384033555662518,
      "grad_norm": 0.24230226874351501,
      "learning_rate": 1.636237041621538e-05,
      "loss": 0.0331,
      "step": 78300
    },
    {
      "epoch": 5.390909716014577,
      "grad_norm": 0.2572794556617737,
      "learning_rate": 1.6319390719823958e-05,
      "loss": 0.0326,
      "step": 78400
    },
    {
      "epoch": 5.397785876366637,
      "grad_norm": 0.0844544842839241,
      "learning_rate": 1.6276840820396447e-05,
      "loss": 0.0324,
      "step": 78500
    },
    {
      "epoch": 5.404662036718697,
      "grad_norm": 0.27829259634017944,
      "learning_rate": 1.623386112400502e-05,
      "loss": 0.0339,
      "step": 78600
    },
    {
      "epoch": 5.4115381970707555,
      "grad_norm": 0.26049333810806274,
      "learning_rate": 1.6190881427613598e-05,
      "loss": 0.0307,
      "step": 78700
    },
    {
      "epoch": 5.418414357422815,
      "grad_norm": 0.1773691326379776,
      "learning_rate": 1.614790173122217e-05,
      "loss": 0.0305,
      "step": 78800
    },
    {
      "epoch": 5.425290517774875,
      "grad_norm": 0.202604740858078,
      "learning_rate": 1.6104922034830746e-05,
      "loss": 0.0296,
      "step": 78900
    },
    {
      "epoch": 5.432166678126934,
      "grad_norm": 0.12891525030136108,
      "learning_rate": 1.6061942338439323e-05,
      "loss": 0.0301,
      "step": 79000
    },
    {
      "epoch": 5.4390428384789935,
      "grad_norm": 0.2266489565372467,
      "learning_rate": 1.6018962642047897e-05,
      "loss": 0.0287,
      "step": 79100
    },
    {
      "epoch": 5.445918998831052,
      "grad_norm": 0.1340232938528061,
      "learning_rate": 1.5975982945656475e-05,
      "loss": 0.0312,
      "step": 79200
    },
    {
      "epoch": 5.452795159183112,
      "grad_norm": 0.31885504722595215,
      "learning_rate": 1.5933003249265045e-05,
      "loss": 0.0289,
      "step": 79300
    },
    {
      "epoch": 5.459671319535172,
      "grad_norm": 0.09959503263235092,
      "learning_rate": 1.5890023552873622e-05,
      "loss": 0.0286,
      "step": 79400
    },
    {
      "epoch": 5.466547479887231,
      "grad_norm": 0.12158577144145966,
      "learning_rate": 1.58470438564822e-05,
      "loss": 0.0307,
      "step": 79500
    },
    {
      "epoch": 5.47342364023929,
      "grad_norm": 0.12580560147762299,
      "learning_rate": 1.5804064160090774e-05,
      "loss": 0.033,
      "step": 79600
    },
    {
      "epoch": 5.48029980059135,
      "grad_norm": 0.17702177166938782,
      "learning_rate": 1.576108446369935e-05,
      "loss": 0.0311,
      "step": 79700
    },
    {
      "epoch": 5.487175960943409,
      "grad_norm": 0.14051243662834167,
      "learning_rate": 1.5718104767307925e-05,
      "loss": 0.0316,
      "step": 79800
    },
    {
      "epoch": 5.494052121295469,
      "grad_norm": 0.18098540604114532,
      "learning_rate": 1.56751250709165e-05,
      "loss": 0.0301,
      "step": 79900
    },
    {
      "epoch": 5.5009282816475285,
      "grad_norm": 0.14973710477352142,
      "learning_rate": 1.5632145374525076e-05,
      "loss": 0.03,
      "step": 80000
    },
    {
      "epoch": 5.507804441999587,
      "grad_norm": 0.15732049942016602,
      "learning_rate": 1.5589595475097565e-05,
      "loss": 0.0311,
      "step": 80100
    },
    {
      "epoch": 5.514680602351647,
      "grad_norm": 0.1529211699962616,
      "learning_rate": 1.554661577870614e-05,
      "loss": 0.0307,
      "step": 80200
    },
    {
      "epoch": 5.521556762703706,
      "grad_norm": 0.09379412978887558,
      "learning_rate": 1.5503636082314716e-05,
      "loss": 0.0285,
      "step": 80300
    },
    {
      "epoch": 5.528432923055766,
      "grad_norm": 0.11401546001434326,
      "learning_rate": 1.546065638592329e-05,
      "loss": 0.0307,
      "step": 80400
    },
    {
      "epoch": 5.535309083407825,
      "grad_norm": 0.19064073264598846,
      "learning_rate": 1.5417676689531864e-05,
      "loss": 0.0318,
      "step": 80500
    },
    {
      "epoch": 5.542185243759884,
      "grad_norm": 0.18900540471076965,
      "learning_rate": 1.537469699314044e-05,
      "loss": 0.0315,
      "step": 80600
    },
    {
      "epoch": 5.549061404111944,
      "grad_norm": 0.1576930582523346,
      "learning_rate": 1.5331717296749015e-05,
      "loss": 0.0298,
      "step": 80700
    },
    {
      "epoch": 5.555937564464004,
      "grad_norm": 0.10602795332670212,
      "learning_rate": 1.5288737600357593e-05,
      "loss": 0.0321,
      "step": 80800
    },
    {
      "epoch": 5.5628137248160625,
      "grad_norm": 0.17719897627830505,
      "learning_rate": 1.5245757903966168e-05,
      "loss": 0.0292,
      "step": 80900
    },
    {
      "epoch": 5.569689885168122,
      "grad_norm": 0.2532213032245636,
      "learning_rate": 1.5202778207574742e-05,
      "loss": 0.032,
      "step": 81000
    },
    {
      "epoch": 5.576566045520181,
      "grad_norm": 0.17682935297489166,
      "learning_rate": 1.5159798511183318e-05,
      "loss": 0.0312,
      "step": 81100
    },
    {
      "epoch": 5.583442205872241,
      "grad_norm": 0.09711892157793045,
      "learning_rate": 1.5116818814791895e-05,
      "loss": 0.0318,
      "step": 81200
    },
    {
      "epoch": 5.590318366224301,
      "grad_norm": 0.1647128164768219,
      "learning_rate": 1.5073839118400467e-05,
      "loss": 0.0318,
      "step": 81300
    },
    {
      "epoch": 5.597194526576359,
      "grad_norm": 0.18568181991577148,
      "learning_rate": 1.5030859422009045e-05,
      "loss": 0.03,
      "step": 81400
    },
    {
      "epoch": 5.604070686928419,
      "grad_norm": 0.23449449241161346,
      "learning_rate": 1.4987879725617618e-05,
      "loss": 0.0289,
      "step": 81500
    },
    {
      "epoch": 5.610946847280479,
      "grad_norm": 0.18309275805950165,
      "learning_rate": 1.4944900029226194e-05,
      "loss": 0.0314,
      "step": 81600
    },
    {
      "epoch": 5.617823007632538,
      "grad_norm": 0.12767349183559418,
      "learning_rate": 1.4901920332834771e-05,
      "loss": 0.0311,
      "step": 81700
    },
    {
      "epoch": 5.6246991679845975,
      "grad_norm": 0.1300159990787506,
      "learning_rate": 1.4858940636443344e-05,
      "loss": 0.0316,
      "step": 81800
    },
    {
      "epoch": 5.631575328336657,
      "grad_norm": 0.31386858224868774,
      "learning_rate": 1.4815960940051921e-05,
      "loss": 0.0342,
      "step": 81900
    },
    {
      "epoch": 5.638451488688716,
      "grad_norm": 0.1562294214963913,
      "learning_rate": 1.4772981243660495e-05,
      "loss": 0.032,
      "step": 82000
    },
    {
      "epoch": 5.645327649040776,
      "grad_norm": 0.1632920503616333,
      "learning_rate": 1.473000154726907e-05,
      "loss": 0.0304,
      "step": 82100
    },
    {
      "epoch": 5.6522038093928355,
      "grad_norm": 0.26677489280700684,
      "learning_rate": 1.4687021850877648e-05,
      "loss": 0.0315,
      "step": 82200
    },
    {
      "epoch": 5.659079969744894,
      "grad_norm": 0.1450473964214325,
      "learning_rate": 1.464404215448622e-05,
      "loss": 0.0282,
      "step": 82300
    },
    {
      "epoch": 5.665956130096954,
      "grad_norm": 0.17333149909973145,
      "learning_rate": 1.4601062458094797e-05,
      "loss": 0.0294,
      "step": 82400
    },
    {
      "epoch": 5.672832290449013,
      "grad_norm": 0.18453837931156158,
      "learning_rate": 1.4558082761703373e-05,
      "loss": 0.0305,
      "step": 82500
    },
    {
      "epoch": 5.679708450801073,
      "grad_norm": 0.20039695501327515,
      "learning_rate": 1.4515103065311947e-05,
      "loss": 0.0335,
      "step": 82600
    },
    {
      "epoch": 5.686584611153132,
      "grad_norm": 0.27718669176101685,
      "learning_rate": 1.4472123368920524e-05,
      "loss": 0.0301,
      "step": 82700
    },
    {
      "epoch": 5.693460771505191,
      "grad_norm": 0.14640742540359497,
      "learning_rate": 1.4429143672529096e-05,
      "loss": 0.0329,
      "step": 82800
    },
    {
      "epoch": 5.700336931857251,
      "grad_norm": 0.07928171753883362,
      "learning_rate": 1.4386163976137674e-05,
      "loss": 0.0299,
      "step": 82900
    },
    {
      "epoch": 5.70721309220931,
      "grad_norm": 0.27815645933151245,
      "learning_rate": 1.4343184279746249e-05,
      "loss": 0.0317,
      "step": 83000
    },
    {
      "epoch": 5.71408925256137,
      "grad_norm": 0.1697007566690445,
      "learning_rate": 1.4300204583354823e-05,
      "loss": 0.0314,
      "step": 83100
    },
    {
      "epoch": 5.720965412913429,
      "grad_norm": 0.2648702561855316,
      "learning_rate": 1.42572248869634e-05,
      "loss": 0.0317,
      "step": 83200
    },
    {
      "epoch": 5.727841573265488,
      "grad_norm": 0.22069184482097626,
      "learning_rate": 1.4214245190571973e-05,
      "loss": 0.033,
      "step": 83300
    },
    {
      "epoch": 5.734717733617548,
      "grad_norm": 0.23213006556034088,
      "learning_rate": 1.417126549418055e-05,
      "loss": 0.0317,
      "step": 83400
    },
    {
      "epoch": 5.741593893969608,
      "grad_norm": 0.24323683977127075,
      "learning_rate": 1.4128285797789125e-05,
      "loss": 0.0332,
      "step": 83500
    },
    {
      "epoch": 5.7484700543216665,
      "grad_norm": 0.24245920777320862,
      "learning_rate": 1.40853061013977e-05,
      "loss": 0.031,
      "step": 83600
    },
    {
      "epoch": 5.755346214673726,
      "grad_norm": 0.32321697473526,
      "learning_rate": 1.4042326405006275e-05,
      "loss": 0.0322,
      "step": 83700
    },
    {
      "epoch": 5.762222375025786,
      "grad_norm": 0.2061634659767151,
      "learning_rate": 1.3999346708614852e-05,
      "loss": 0.0295,
      "step": 83800
    },
    {
      "epoch": 5.769098535377845,
      "grad_norm": 0.19971680641174316,
      "learning_rate": 1.3956367012223426e-05,
      "loss": 0.0309,
      "step": 83900
    },
    {
      "epoch": 5.7759746957299045,
      "grad_norm": 0.130410298705101,
      "learning_rate": 1.3913387315832002e-05,
      "loss": 0.0304,
      "step": 84000
    },
    {
      "epoch": 5.782850856081964,
      "grad_norm": 0.20193994045257568,
      "learning_rate": 1.3870407619440576e-05,
      "loss": 0.0326,
      "step": 84100
    },
    {
      "epoch": 5.789727016434023,
      "grad_norm": 0.23089364171028137,
      "learning_rate": 1.3827427923049151e-05,
      "loss": 0.0304,
      "step": 84200
    },
    {
      "epoch": 5.796603176786083,
      "grad_norm": 0.17554207146167755,
      "learning_rate": 1.3784448226657729e-05,
      "loss": 0.0329,
      "step": 84300
    },
    {
      "epoch": 5.803479337138142,
      "grad_norm": 0.1661560833454132,
      "learning_rate": 1.3741468530266303e-05,
      "loss": 0.0324,
      "step": 84400
    },
    {
      "epoch": 5.810355497490201,
      "grad_norm": 0.11455333232879639,
      "learning_rate": 1.3698488833874878e-05,
      "loss": 0.0318,
      "step": 84500
    },
    {
      "epoch": 5.817231657842261,
      "grad_norm": 0.09223423153162003,
      "learning_rate": 1.3655509137483455e-05,
      "loss": 0.0306,
      "step": 84600
    },
    {
      "epoch": 5.82410781819432,
      "grad_norm": 0.26625871658325195,
      "learning_rate": 1.3612529441092028e-05,
      "loss": 0.0297,
      "step": 84700
    },
    {
      "epoch": 5.83098397854638,
      "grad_norm": 0.4813257157802582,
      "learning_rate": 1.3569549744700605e-05,
      "loss": 0.0311,
      "step": 84800
    },
    {
      "epoch": 5.8378601388984395,
      "grad_norm": 0.1232069805264473,
      "learning_rate": 1.3526570048309179e-05,
      "loss": 0.0313,
      "step": 84900
    },
    {
      "epoch": 5.844736299250498,
      "grad_norm": 0.17947885394096375,
      "learning_rate": 1.3483590351917754e-05,
      "loss": 0.0311,
      "step": 85000
    },
    {
      "epoch": 5.851612459602558,
      "grad_norm": 0.17168869078159332,
      "learning_rate": 1.3440610655526332e-05,
      "loss": 0.0291,
      "step": 85100
    },
    {
      "epoch": 5.858488619954617,
      "grad_norm": 0.2977182865142822,
      "learning_rate": 1.3397630959134904e-05,
      "loss": 0.0294,
      "step": 85200
    },
    {
      "epoch": 5.865364780306677,
      "grad_norm": 0.11374762654304504,
      "learning_rate": 1.3354651262743481e-05,
      "loss": 0.0293,
      "step": 85300
    },
    {
      "epoch": 5.872240940658736,
      "grad_norm": 0.32428842782974243,
      "learning_rate": 1.3311671566352055e-05,
      "loss": 0.0303,
      "step": 85400
    },
    {
      "epoch": 5.879117101010795,
      "grad_norm": 0.2037712037563324,
      "learning_rate": 1.326869186996063e-05,
      "loss": 0.0324,
      "step": 85500
    },
    {
      "epoch": 5.885993261362855,
      "grad_norm": 0.14268426597118378,
      "learning_rate": 1.3225712173569208e-05,
      "loss": 0.0303,
      "step": 85600
    },
    {
      "epoch": 5.892869421714915,
      "grad_norm": 0.2374705970287323,
      "learning_rate": 1.318273247717778e-05,
      "loss": 0.0349,
      "step": 85700
    },
    {
      "epoch": 5.8997455820669735,
      "grad_norm": 0.19629134237766266,
      "learning_rate": 1.3139752780786358e-05,
      "loss": 0.0321,
      "step": 85800
    },
    {
      "epoch": 5.906621742419033,
      "grad_norm": 0.1403426229953766,
      "learning_rate": 1.3096773084394933e-05,
      "loss": 0.0306,
      "step": 85900
    },
    {
      "epoch": 5.913497902771093,
      "grad_norm": 0.1521722376346588,
      "learning_rate": 1.3053793388003507e-05,
      "loss": 0.0274,
      "step": 86000
    },
    {
      "epoch": 5.920374063123152,
      "grad_norm": 0.20682860910892487,
      "learning_rate": 1.3010813691612084e-05,
      "loss": 0.0301,
      "step": 86100
    },
    {
      "epoch": 5.927250223475212,
      "grad_norm": 0.13672612607479095,
      "learning_rate": 1.2968263792184574e-05,
      "loss": 0.0296,
      "step": 86200
    },
    {
      "epoch": 5.934126383827271,
      "grad_norm": 0.1563790738582611,
      "learning_rate": 1.2925284095793147e-05,
      "loss": 0.0309,
      "step": 86300
    },
    {
      "epoch": 5.94100254417933,
      "grad_norm": 0.12101425975561142,
      "learning_rate": 1.2882304399401723e-05,
      "loss": 0.0316,
      "step": 86400
    },
    {
      "epoch": 5.94787870453139,
      "grad_norm": 0.11255792528390884,
      "learning_rate": 1.28393247030103e-05,
      "loss": 0.0311,
      "step": 86500
    },
    {
      "epoch": 5.954754864883449,
      "grad_norm": 0.191099613904953,
      "learning_rate": 1.2796345006618873e-05,
      "loss": 0.029,
      "step": 86600
    },
    {
      "epoch": 5.9616310252355085,
      "grad_norm": 0.193239226937294,
      "learning_rate": 1.275336531022745e-05,
      "loss": 0.03,
      "step": 86700
    },
    {
      "epoch": 5.968507185587568,
      "grad_norm": 0.26592743396759033,
      "learning_rate": 1.2710385613836024e-05,
      "loss": 0.0311,
      "step": 86800
    },
    {
      "epoch": 5.975383345939627,
      "grad_norm": 0.23032817244529724,
      "learning_rate": 1.26674059174446e-05,
      "loss": 0.0328,
      "step": 86900
    },
    {
      "epoch": 5.982259506291687,
      "grad_norm": 0.25225967168807983,
      "learning_rate": 1.2624426221053177e-05,
      "loss": 0.0287,
      "step": 87000
    },
    {
      "epoch": 5.989135666643746,
      "grad_norm": 0.22221516072750092,
      "learning_rate": 1.2581876321625666e-05,
      "loss": 0.0332,
      "step": 87100
    },
    {
      "epoch": 5.996011826995805,
      "grad_norm": 0.1601506471633911,
      "learning_rate": 1.253889662523424e-05,
      "loss": 0.0323,
      "step": 87200
    },
    {
      "epoch": 6.0,
      "eval_accuracy_macro_0.5": 0.9854193925857544,
      "eval_accuracy_micro_0.5": 0.9854194521903992,
      "eval_accuracy_weighted_0.5": 0.9833744764328003,
      "eval_f1_macro_0.5": 0.8164485692977905,
      "eval_f1_macro_0.6": 0.8086724281311035,
      "eval_f1_macro_0.7": 0.7902169227600098,
      "eval_f1_macro_0.8": 0.6627645492553711,
      "eval_f1_micro_0.5": 0.8132237792015076,
      "eval_f1_micro_0.6": 0.8068532943725586,
      "eval_f1_micro_0.7": 0.7896593809127808,
      "eval_f1_micro_0.8": 0.7545326352119446,
      "eval_f1_micro_0.9": 0.6730577349662781,
      "eval_f1_weighted_0.5": 0.8111422657966614,
      "eval_f1_weighted_0.6": 0.8022218942642212,
      "eval_f1_weighted_0.7": 0.7817782163619995,
      "eval_f1_weighted_0.8": 0.6492108702659607,
      "eval_loss": 0.030231155455112457,
      "eval_runtime": 133.658,
      "eval_samples_per_second": 217.249,
      "eval_steps_per_second": 27.159,
      "step": 87258
    },
    {
      "epoch": 6.002887987347865,
      "grad_norm": 0.211427241563797,
      "learning_rate": 1.2495916928842815e-05,
      "loss": 0.0312,
      "step": 87300
    },
    {
      "epoch": 6.009764147699924,
      "grad_norm": 0.13532964885234833,
      "learning_rate": 1.245293723245139e-05,
      "loss": 0.0302,
      "step": 87400
    },
    {
      "epoch": 6.016640308051984,
      "grad_norm": 0.1954648792743683,
      "learning_rate": 1.2409957536059966e-05,
      "loss": 0.0285,
      "step": 87500
    },
    {
      "epoch": 6.023516468404043,
      "grad_norm": 0.2913760542869568,
      "learning_rate": 1.236697783966854e-05,
      "loss": 0.0307,
      "step": 87600
    },
    {
      "epoch": 6.030392628756102,
      "grad_norm": 0.2056693434715271,
      "learning_rate": 1.2323998143277118e-05,
      "loss": 0.0327,
      "step": 87700
    },
    {
      "epoch": 6.037268789108162,
      "grad_norm": 0.19168546795845032,
      "learning_rate": 1.2281018446885692e-05,
      "loss": 0.0299,
      "step": 87800
    },
    {
      "epoch": 6.044144949460222,
      "grad_norm": 0.08094970136880875,
      "learning_rate": 1.2238038750494267e-05,
      "loss": 0.0327,
      "step": 87900
    },
    {
      "epoch": 6.051021109812281,
      "grad_norm": 0.2081356942653656,
      "learning_rate": 1.2195059054102843e-05,
      "loss": 0.0303,
      "step": 88000
    },
    {
      "epoch": 6.05789727016434,
      "grad_norm": 0.10505364835262299,
      "learning_rate": 1.2152079357711418e-05,
      "loss": 0.0284,
      "step": 88100
    },
    {
      "epoch": 6.0647734305164,
      "grad_norm": 0.1257980763912201,
      "learning_rate": 1.2109099661319994e-05,
      "loss": 0.0295,
      "step": 88200
    },
    {
      "epoch": 6.071649590868459,
      "grad_norm": 0.10045824199914932,
      "learning_rate": 1.2066119964928568e-05,
      "loss": 0.0303,
      "step": 88300
    },
    {
      "epoch": 6.078525751220519,
      "grad_norm": 0.2467607855796814,
      "learning_rate": 1.2023140268537143e-05,
      "loss": 0.0293,
      "step": 88400
    },
    {
      "epoch": 6.0854019115725775,
      "grad_norm": 0.30412235856056213,
      "learning_rate": 1.1980160572145719e-05,
      "loss": 0.0332,
      "step": 88500
    },
    {
      "epoch": 6.092278071924637,
      "grad_norm": 0.20035867393016815,
      "learning_rate": 1.1937180875754295e-05,
      "loss": 0.0328,
      "step": 88600
    },
    {
      "epoch": 6.099154232276697,
      "grad_norm": 0.15611934661865234,
      "learning_rate": 1.189420117936287e-05,
      "loss": 0.0307,
      "step": 88700
    },
    {
      "epoch": 6.106030392628756,
      "grad_norm": 0.13485194742679596,
      "learning_rate": 1.1851221482971444e-05,
      "loss": 0.0319,
      "step": 88800
    },
    {
      "epoch": 6.1129065529808155,
      "grad_norm": 0.0355389229953289,
      "learning_rate": 1.180824178658002e-05,
      "loss": 0.0294,
      "step": 88900
    },
    {
      "epoch": 6.119782713332875,
      "grad_norm": 0.14340898394584656,
      "learning_rate": 1.1765262090188595e-05,
      "loss": 0.0304,
      "step": 89000
    },
    {
      "epoch": 6.126658873684934,
      "grad_norm": 0.1689540296792984,
      "learning_rate": 1.1722282393797171e-05,
      "loss": 0.0313,
      "step": 89100
    },
    {
      "epoch": 6.133535034036994,
      "grad_norm": 0.21782390773296356,
      "learning_rate": 1.1679302697405747e-05,
      "loss": 0.0319,
      "step": 89200
    },
    {
      "epoch": 6.140411194389053,
      "grad_norm": 0.29332292079925537,
      "learning_rate": 1.163632300101432e-05,
      "loss": 0.0293,
      "step": 89300
    },
    {
      "epoch": 6.147287354741112,
      "grad_norm": 0.13396777212619781,
      "learning_rate": 1.1593343304622898e-05,
      "loss": 0.03,
      "step": 89400
    },
    {
      "epoch": 6.154163515093172,
      "grad_norm": 0.15407654643058777,
      "learning_rate": 1.1550363608231472e-05,
      "loss": 0.0297,
      "step": 89500
    },
    {
      "epoch": 6.161039675445231,
      "grad_norm": 0.36776915192604065,
      "learning_rate": 1.1507383911840047e-05,
      "loss": 0.0284,
      "step": 89600
    },
    {
      "epoch": 6.167915835797291,
      "grad_norm": 0.25568944215774536,
      "learning_rate": 1.1464404215448623e-05,
      "loss": 0.0303,
      "step": 89700
    },
    {
      "epoch": 6.1747919961493505,
      "grad_norm": 0.31111961603164673,
      "learning_rate": 1.1421424519057197e-05,
      "loss": 0.0325,
      "step": 89800
    },
    {
      "epoch": 6.181668156501409,
      "grad_norm": 0.2566542327404022,
      "learning_rate": 1.1378444822665774e-05,
      "loss": 0.0316,
      "step": 89900
    },
    {
      "epoch": 6.188544316853469,
      "grad_norm": 0.20473794639110565,
      "learning_rate": 1.1335465126274348e-05,
      "loss": 0.0311,
      "step": 90000
    },
    {
      "epoch": 6.195420477205529,
      "grad_norm": 0.29074326157569885,
      "learning_rate": 1.1292485429882924e-05,
      "loss": 0.0316,
      "step": 90100
    },
    {
      "epoch": 6.202296637557588,
      "grad_norm": 0.11653921008110046,
      "learning_rate": 1.12495057334915e-05,
      "loss": 0.0297,
      "step": 90200
    },
    {
      "epoch": 6.209172797909647,
      "grad_norm": 0.17803187668323517,
      "learning_rate": 1.1206526037100075e-05,
      "loss": 0.0302,
      "step": 90300
    },
    {
      "epoch": 6.216048958261707,
      "grad_norm": 0.22123347222805023,
      "learning_rate": 1.116354634070865e-05,
      "loss": 0.0297,
      "step": 90400
    },
    {
      "epoch": 6.222925118613766,
      "grad_norm": 0.13072751462459564,
      "learning_rate": 1.1120566644317224e-05,
      "loss": 0.0325,
      "step": 90500
    },
    {
      "epoch": 6.229801278965826,
      "grad_norm": 0.2004387527704239,
      "learning_rate": 1.1078016744889715e-05,
      "loss": 0.0292,
      "step": 90600
    },
    {
      "epoch": 6.2366774393178845,
      "grad_norm": 0.06277548521757126,
      "learning_rate": 1.1035037048498289e-05,
      "loss": 0.029,
      "step": 90700
    },
    {
      "epoch": 6.243553599669944,
      "grad_norm": 0.3287148177623749,
      "learning_rate": 1.0992057352106866e-05,
      "loss": 0.0301,
      "step": 90800
    },
    {
      "epoch": 6.250429760022004,
      "grad_norm": 0.2965472936630249,
      "learning_rate": 1.094907765571544e-05,
      "loss": 0.0306,
      "step": 90900
    },
    {
      "epoch": 6.257305920374063,
      "grad_norm": 0.14897342026233673,
      "learning_rate": 1.0906097959324016e-05,
      "loss": 0.0328,
      "step": 91000
    },
    {
      "epoch": 6.264182080726123,
      "grad_norm": 0.15323524177074432,
      "learning_rate": 1.0863118262932592e-05,
      "loss": 0.0313,
      "step": 91100
    },
    {
      "epoch": 6.271058241078182,
      "grad_norm": 0.19272756576538086,
      "learning_rate": 1.0820138566541165e-05,
      "loss": 0.0328,
      "step": 91200
    },
    {
      "epoch": 6.277934401430241,
      "grad_norm": 0.2093850076198578,
      "learning_rate": 1.0777158870149743e-05,
      "loss": 0.0288,
      "step": 91300
    },
    {
      "epoch": 6.284810561782301,
      "grad_norm": 0.2026931196451187,
      "learning_rate": 1.0734179173758317e-05,
      "loss": 0.0316,
      "step": 91400
    },
    {
      "epoch": 6.29168672213436,
      "grad_norm": 0.20832964777946472,
      "learning_rate": 1.0691199477366892e-05,
      "loss": 0.0299,
      "step": 91500
    },
    {
      "epoch": 6.2985628824864195,
      "grad_norm": 0.15261654555797577,
      "learning_rate": 1.0648219780975468e-05,
      "loss": 0.0288,
      "step": 91600
    },
    {
      "epoch": 6.305439042838479,
      "grad_norm": 0.16717606782913208,
      "learning_rate": 1.0605240084584043e-05,
      "loss": 0.0312,
      "step": 91700
    },
    {
      "epoch": 6.312315203190538,
      "grad_norm": 0.11886674165725708,
      "learning_rate": 1.0562260388192619e-05,
      "loss": 0.035,
      "step": 91800
    },
    {
      "epoch": 6.319191363542598,
      "grad_norm": 0.13834558427333832,
      "learning_rate": 1.0519280691801193e-05,
      "loss": 0.031,
      "step": 91900
    },
    {
      "epoch": 6.3260675238946575,
      "grad_norm": 0.16020631790161133,
      "learning_rate": 1.0476300995409769e-05,
      "loss": 0.0316,
      "step": 92000
    },
    {
      "epoch": 6.332943684246716,
      "grad_norm": 0.15508593618869781,
      "learning_rate": 1.0433321299018344e-05,
      "loss": 0.0299,
      "step": 92100
    },
    {
      "epoch": 6.339819844598776,
      "grad_norm": 0.24307966232299805,
      "learning_rate": 1.039034160262692e-05,
      "loss": 0.0293,
      "step": 92200
    },
    {
      "epoch": 6.346696004950836,
      "grad_norm": 0.16915051639080048,
      "learning_rate": 1.0347361906235495e-05,
      "loss": 0.0299,
      "step": 92300
    },
    {
      "epoch": 6.353572165302895,
      "grad_norm": 0.20931954681873322,
      "learning_rate": 1.030438220984407e-05,
      "loss": 0.0306,
      "step": 92400
    },
    {
      "epoch": 6.360448325654954,
      "grad_norm": 0.16867965459823608,
      "learning_rate": 1.0261402513452645e-05,
      "loss": 0.0332,
      "step": 92500
    },
    {
      "epoch": 6.367324486007013,
      "grad_norm": 0.15140771865844727,
      "learning_rate": 1.0218852614025134e-05,
      "loss": 0.0298,
      "step": 92600
    },
    {
      "epoch": 6.374200646359073,
      "grad_norm": 0.2534150779247284,
      "learning_rate": 1.0175872917633711e-05,
      "loss": 0.0314,
      "step": 92700
    },
    {
      "epoch": 6.381076806711133,
      "grad_norm": 0.22246237099170685,
      "learning_rate": 1.0132893221242285e-05,
      "loss": 0.0309,
      "step": 92800
    },
    {
      "epoch": 6.387952967063192,
      "grad_norm": 0.15871183574199677,
      "learning_rate": 1.008991352485086e-05,
      "loss": 0.0313,
      "step": 92900
    },
    {
      "epoch": 6.394829127415251,
      "grad_norm": 0.24119031429290771,
      "learning_rate": 1.0046933828459436e-05,
      "loss": 0.0298,
      "step": 93000
    },
    {
      "epoch": 6.401705287767311,
      "grad_norm": 0.12013331055641174,
      "learning_rate": 1.0003954132068012e-05,
      "loss": 0.0315,
      "step": 93100
    },
    {
      "epoch": 6.40858144811937,
      "grad_norm": 0.16654527187347412,
      "learning_rate": 9.960974435676588e-06,
      "loss": 0.0303,
      "step": 93200
    },
    {
      "epoch": 6.41545760847143,
      "grad_norm": 0.1443665474653244,
      "learning_rate": 9.917994739285162e-06,
      "loss": 0.0305,
      "step": 93300
    },
    {
      "epoch": 6.4223337688234885,
      "grad_norm": 0.16146843135356903,
      "learning_rate": 9.875015042893737e-06,
      "loss": 0.0289,
      "step": 93400
    },
    {
      "epoch": 6.429209929175548,
      "grad_norm": 0.21572460234165192,
      "learning_rate": 9.832035346502313e-06,
      "loss": 0.029,
      "step": 93500
    },
    {
      "epoch": 6.436086089527608,
      "grad_norm": 0.2752639651298523,
      "learning_rate": 9.789055650110888e-06,
      "loss": 0.031,
      "step": 93600
    },
    {
      "epoch": 6.442962249879667,
      "grad_norm": 0.1909530907869339,
      "learning_rate": 9.746075953719464e-06,
      "loss": 0.0288,
      "step": 93700
    },
    {
      "epoch": 6.4498384102317265,
      "grad_norm": 0.14232653379440308,
      "learning_rate": 9.703096257328038e-06,
      "loss": 0.0296,
      "step": 93800
    },
    {
      "epoch": 6.456714570583786,
      "grad_norm": 0.3138250410556793,
      "learning_rate": 9.660116560936613e-06,
      "loss": 0.0324,
      "step": 93900
    },
    {
      "epoch": 6.463590730935845,
      "grad_norm": 0.09106103330850601,
      "learning_rate": 9.617136864545189e-06,
      "loss": 0.0288,
      "step": 94000
    },
    {
      "epoch": 6.470466891287905,
      "grad_norm": 0.1797448843717575,
      "learning_rate": 9.574157168153765e-06,
      "loss": 0.0317,
      "step": 94100
    },
    {
      "epoch": 6.477343051639965,
      "grad_norm": 0.14203938841819763,
      "learning_rate": 9.53117747176234e-06,
      "loss": 0.0303,
      "step": 94200
    },
    {
      "epoch": 6.4842192119920234,
      "grad_norm": 0.2779402434825897,
      "learning_rate": 9.488197775370914e-06,
      "loss": 0.0274,
      "step": 94300
    },
    {
      "epoch": 6.491095372344083,
      "grad_norm": 0.12402638792991638,
      "learning_rate": 9.445218078979491e-06,
      "loss": 0.0302,
      "step": 94400
    },
    {
      "epoch": 6.497971532696143,
      "grad_norm": 0.12531375885009766,
      "learning_rate": 9.402238382588065e-06,
      "loss": 0.0293,
      "step": 94500
    },
    {
      "epoch": 6.504847693048202,
      "grad_norm": 0.18185819685459137,
      "learning_rate": 9.359258686196641e-06,
      "loss": 0.0307,
      "step": 94600
    },
    {
      "epoch": 6.5117238534002615,
      "grad_norm": 0.11931469291448593,
      "learning_rate": 9.31670878676913e-06,
      "loss": 0.0298,
      "step": 94700
    },
    {
      "epoch": 6.51860001375232,
      "grad_norm": 0.14917738735675812,
      "learning_rate": 9.273729090377706e-06,
      "loss": 0.0305,
      "step": 94800
    },
    {
      "epoch": 6.52547617410438,
      "grad_norm": 0.1811094433069229,
      "learning_rate": 9.230749393986281e-06,
      "loss": 0.0291,
      "step": 94900
    },
    {
      "epoch": 6.53235233445644,
      "grad_norm": 0.212812602519989,
      "learning_rate": 9.187769697594857e-06,
      "loss": 0.0289,
      "step": 95000
    },
    {
      "epoch": 6.539228494808499,
      "grad_norm": 0.11748748272657394,
      "learning_rate": 9.144790001203432e-06,
      "loss": 0.0296,
      "step": 95100
    },
    {
      "epoch": 6.546104655160558,
      "grad_norm": 0.2681105434894562,
      "learning_rate": 9.101810304812006e-06,
      "loss": 0.0319,
      "step": 95200
    },
    {
      "epoch": 6.552980815512618,
      "grad_norm": 0.14789646863937378,
      "learning_rate": 9.058830608420582e-06,
      "loss": 0.0299,
      "step": 95300
    },
    {
      "epoch": 6.559856975864677,
      "grad_norm": 0.13795311748981476,
      "learning_rate": 9.015850912029158e-06,
      "loss": 0.0295,
      "step": 95400
    },
    {
      "epoch": 6.566733136216737,
      "grad_norm": 0.08567240834236145,
      "learning_rate": 8.972871215637733e-06,
      "loss": 0.0288,
      "step": 95500
    },
    {
      "epoch": 6.573609296568796,
      "grad_norm": 0.14779789745807648,
      "learning_rate": 8.929891519246309e-06,
      "loss": 0.0288,
      "step": 95600
    },
    {
      "epoch": 6.580485456920855,
      "grad_norm": 0.28976285457611084,
      "learning_rate": 8.886911822854883e-06,
      "loss": 0.0328,
      "step": 95700
    },
    {
      "epoch": 6.587361617272915,
      "grad_norm": 0.21216368675231934,
      "learning_rate": 8.84393212646346e-06,
      "loss": 0.03,
      "step": 95800
    },
    {
      "epoch": 6.594237777624974,
      "grad_norm": 0.21513082087039948,
      "learning_rate": 8.800952430072034e-06,
      "loss": 0.03,
      "step": 95900
    },
    {
      "epoch": 6.601113937977034,
      "grad_norm": 0.24356548488140106,
      "learning_rate": 8.758402530644525e-06,
      "loss": 0.0288,
      "step": 96000
    },
    {
      "epoch": 6.607990098329093,
      "grad_norm": 0.19939720630645752,
      "learning_rate": 8.715422834253099e-06,
      "loss": 0.029,
      "step": 96100
    },
    {
      "epoch": 6.614866258681152,
      "grad_norm": 0.19697099924087524,
      "learning_rate": 8.672443137861674e-06,
      "loss": 0.0293,
      "step": 96200
    },
    {
      "epoch": 6.621742419033212,
      "grad_norm": 0.09915843605995178,
      "learning_rate": 8.62946344147025e-06,
      "loss": 0.0292,
      "step": 96300
    },
    {
      "epoch": 6.628618579385272,
      "grad_norm": 0.3044816851615906,
      "learning_rate": 8.586483745078825e-06,
      "loss": 0.0296,
      "step": 96400
    },
    {
      "epoch": 6.6354947397373305,
      "grad_norm": 0.15933404862880707,
      "learning_rate": 8.543504048687401e-06,
      "loss": 0.0277,
      "step": 96500
    },
    {
      "epoch": 6.64237090008939,
      "grad_norm": 0.17288486659526825,
      "learning_rate": 8.500524352295975e-06,
      "loss": 0.0297,
      "step": 96600
    },
    {
      "epoch": 6.64924706044145,
      "grad_norm": 0.20117303729057312,
      "learning_rate": 8.45754465590455e-06,
      "loss": 0.0282,
      "step": 96700
    },
    {
      "epoch": 6.656123220793509,
      "grad_norm": 0.1581302136182785,
      "learning_rate": 8.414564959513128e-06,
      "loss": 0.0317,
      "step": 96800
    },
    {
      "epoch": 6.662999381145569,
      "grad_norm": 0.2645430564880371,
      "learning_rate": 8.371585263121702e-06,
      "loss": 0.0312,
      "step": 96900
    },
    {
      "epoch": 6.669875541497627,
      "grad_norm": 0.15679021179676056,
      "learning_rate": 8.328605566730277e-06,
      "loss": 0.0323,
      "step": 97000
    },
    {
      "epoch": 6.676751701849687,
      "grad_norm": 0.0575898252427578,
      "learning_rate": 8.285625870338851e-06,
      "loss": 0.0303,
      "step": 97100
    },
    {
      "epoch": 6.683627862201747,
      "grad_norm": 0.24920257925987244,
      "learning_rate": 8.242646173947427e-06,
      "loss": 0.0299,
      "step": 97200
    },
    {
      "epoch": 6.690504022553806,
      "grad_norm": 0.5525205731391907,
      "learning_rate": 8.199666477556004e-06,
      "loss": 0.0314,
      "step": 97300
    },
    {
      "epoch": 6.6973801829058655,
      "grad_norm": 0.14124874770641327,
      "learning_rate": 8.156686781164578e-06,
      "loss": 0.033,
      "step": 97400
    },
    {
      "epoch": 6.704256343257924,
      "grad_norm": 0.17714771628379822,
      "learning_rate": 8.113707084773154e-06,
      "loss": 0.0298,
      "step": 97500
    },
    {
      "epoch": 6.711132503609984,
      "grad_norm": 0.22377006709575653,
      "learning_rate": 8.070727388381728e-06,
      "loss": 0.0299,
      "step": 97600
    },
    {
      "epoch": 6.718008663962044,
      "grad_norm": 0.1925124228000641,
      "learning_rate": 8.027747691990305e-06,
      "loss": 0.0303,
      "step": 97700
    },
    {
      "epoch": 6.724884824314103,
      "grad_norm": 0.19580507278442383,
      "learning_rate": 7.98476799559888e-06,
      "loss": 0.0319,
      "step": 97800
    },
    {
      "epoch": 6.731760984666162,
      "grad_norm": 0.260247141122818,
      "learning_rate": 7.941788299207454e-06,
      "loss": 0.0304,
      "step": 97900
    },
    {
      "epoch": 6.738637145018222,
      "grad_norm": 0.21062949299812317,
      "learning_rate": 7.89880860281603e-06,
      "loss": 0.0286,
      "step": 98000
    },
    {
      "epoch": 6.745513305370281,
      "grad_norm": 0.19807787239551544,
      "learning_rate": 7.855828906424606e-06,
      "loss": 0.0294,
      "step": 98100
    },
    {
      "epoch": 6.752389465722341,
      "grad_norm": 0.2848964333534241,
      "learning_rate": 7.813279006997095e-06,
      "loss": 0.03,
      "step": 98200
    },
    {
      "epoch": 6.7592656260744,
      "grad_norm": 0.2200457602739334,
      "learning_rate": 7.77029931060567e-06,
      "loss": 0.0316,
      "step": 98300
    },
    {
      "epoch": 6.766141786426459,
      "grad_norm": 0.124175064265728,
      "learning_rate": 7.727319614214246e-06,
      "loss": 0.0306,
      "step": 98400
    },
    {
      "epoch": 6.773017946778519,
      "grad_norm": 0.22736798226833344,
      "learning_rate": 7.684339917822821e-06,
      "loss": 0.0324,
      "step": 98500
    },
    {
      "epoch": 6.779894107130579,
      "grad_norm": 0.19883757829666138,
      "learning_rate": 7.641360221431395e-06,
      "loss": 0.0304,
      "step": 98600
    },
    {
      "epoch": 6.786770267482638,
      "grad_norm": 0.2279529869556427,
      "learning_rate": 7.598380525039972e-06,
      "loss": 0.03,
      "step": 98700
    },
    {
      "epoch": 6.793646427834697,
      "grad_norm": 0.19634424149990082,
      "learning_rate": 7.555400828648547e-06,
      "loss": 0.0318,
      "step": 98800
    },
    {
      "epoch": 6.800522588186756,
      "grad_norm": 0.1784573495388031,
      "learning_rate": 7.512421132257122e-06,
      "loss": 0.0296,
      "step": 98900
    },
    {
      "epoch": 6.807398748538816,
      "grad_norm": 0.14556162059307098,
      "learning_rate": 7.469441435865697e-06,
      "loss": 0.0296,
      "step": 99000
    },
    {
      "epoch": 6.814274908890876,
      "grad_norm": 0.22374126315116882,
      "learning_rate": 7.426461739474273e-06,
      "loss": 0.0329,
      "step": 99100
    },
    {
      "epoch": 6.8211510692429345,
      "grad_norm": 0.21035538613796234,
      "learning_rate": 7.383482043082848e-06,
      "loss": 0.0329,
      "step": 99200
    },
    {
      "epoch": 6.828027229594994,
      "grad_norm": 0.2246273308992386,
      "learning_rate": 7.340932143655338e-06,
      "loss": 0.0285,
      "step": 99300
    },
    {
      "epoch": 6.834903389947054,
      "grad_norm": 0.17525804042816162,
      "learning_rate": 7.297952447263913e-06,
      "loss": 0.0335,
      "step": 99400
    },
    {
      "epoch": 6.841779550299113,
      "grad_norm": 0.2559419572353363,
      "learning_rate": 7.254972750872488e-06,
      "loss": 0.032,
      "step": 99500
    },
    {
      "epoch": 6.8486557106511725,
      "grad_norm": 0.2002442628145218,
      "learning_rate": 7.211993054481063e-06,
      "loss": 0.0298,
      "step": 99600
    },
    {
      "epoch": 6.855531871003231,
      "grad_norm": 0.21328380703926086,
      "learning_rate": 7.16901335808964e-06,
      "loss": 0.0295,
      "step": 99700
    },
    {
      "epoch": 6.862408031355291,
      "grad_norm": 0.2585764527320862,
      "learning_rate": 7.126033661698214e-06,
      "loss": 0.0311,
      "step": 99800
    },
    {
      "epoch": 6.869284191707351,
      "grad_norm": 0.14001713693141937,
      "learning_rate": 7.083053965306789e-06,
      "loss": 0.031,
      "step": 99900
    },
    {
      "epoch": 6.87616035205941,
      "grad_norm": 0.07486356049776077,
      "learning_rate": 7.040074268915364e-06,
      "loss": 0.0302,
      "step": 100000
    },
    {
      "epoch": 6.883036512411469,
      "grad_norm": 0.15494532883167267,
      "learning_rate": 6.99709457252394e-06,
      "loss": 0.0321,
      "step": 100100
    },
    {
      "epoch": 6.889912672763529,
      "grad_norm": 0.1541474461555481,
      "learning_rate": 6.954114876132516e-06,
      "loss": 0.029,
      "step": 100200
    },
    {
      "epoch": 6.896788833115588,
      "grad_norm": 0.09211544692516327,
      "learning_rate": 6.911135179741091e-06,
      "loss": 0.0317,
      "step": 100300
    },
    {
      "epoch": 6.903664993467648,
      "grad_norm": 0.15726378560066223,
      "learning_rate": 6.8681554833496655e-06,
      "loss": 0.0283,
      "step": 100400
    },
    {
      "epoch": 6.9105411538197075,
      "grad_norm": 0.14045321941375732,
      "learning_rate": 6.825175786958242e-06,
      "loss": 0.0307,
      "step": 100500
    },
    {
      "epoch": 6.917417314171766,
      "grad_norm": 0.1601806879043579,
      "learning_rate": 6.782196090566817e-06,
      "loss": 0.0275,
      "step": 100600
    },
    {
      "epoch": 6.924293474523826,
      "grad_norm": 0.23842579126358032,
      "learning_rate": 6.739216394175392e-06,
      "loss": 0.03,
      "step": 100700
    },
    {
      "epoch": 6.931169634875886,
      "grad_norm": 0.24854016304016113,
      "learning_rate": 6.696236697783967e-06,
      "loss": 0.0298,
      "step": 100800
    },
    {
      "epoch": 6.938045795227945,
      "grad_norm": 0.22376327216625214,
      "learning_rate": 6.653257001392542e-06,
      "loss": 0.0297,
      "step": 100900
    },
    {
      "epoch": 6.944921955580004,
      "grad_norm": 0.12214921414852142,
      "learning_rate": 6.610277305001118e-06,
      "loss": 0.0311,
      "step": 101000
    },
    {
      "epoch": 6.951798115932063,
      "grad_norm": 0.2175341099500656,
      "learning_rate": 6.567297608609693e-06,
      "loss": 0.0279,
      "step": 101100
    },
    {
      "epoch": 6.958674276284123,
      "grad_norm": 0.09993094205856323,
      "learning_rate": 6.524317912218268e-06,
      "loss": 0.0311,
      "step": 101200
    },
    {
      "epoch": 6.965550436636183,
      "grad_norm": 0.09393094480037689,
      "learning_rate": 6.481338215826843e-06,
      "loss": 0.029,
      "step": 101300
    },
    {
      "epoch": 6.9724265969882415,
      "grad_norm": 0.3046731948852539,
      "learning_rate": 6.43835851943542e-06,
      "loss": 0.0296,
      "step": 101400
    },
    {
      "epoch": 6.979302757340301,
      "grad_norm": 0.10250058770179749,
      "learning_rate": 6.395378823043995e-06,
      "loss": 0.0337,
      "step": 101500
    },
    {
      "epoch": 6.98617891769236,
      "grad_norm": 0.2383732944726944,
      "learning_rate": 6.352399126652569e-06,
      "loss": 0.0277,
      "step": 101600
    },
    {
      "epoch": 6.99305507804442,
      "grad_norm": 0.2542324364185333,
      "learning_rate": 6.309419430261144e-06,
      "loss": 0.0315,
      "step": 101700
    },
    {
      "epoch": 6.99993123839648,
      "grad_norm": 0.2752174139022827,
      "learning_rate": 6.266439733869721e-06,
      "loss": 0.0275,
      "step": 101800
    },
    {
      "epoch": 7.0,
      "eval_accuracy_macro_0.5": 0.9856476783752441,
      "eval_accuracy_micro_0.5": 0.9856476187705994,
      "eval_accuracy_weighted_0.5": 0.9836498498916626,
      "eval_f1_macro_0.5": 0.8198875784873962,
      "eval_f1_macro_0.6": 0.8134899139404297,
      "eval_f1_macro_0.7": 0.7940486073493958,
      "eval_f1_macro_0.8": 0.673514187335968,
      "eval_f1_micro_0.5": 0.8166570663452148,
      "eval_f1_micro_0.6": 0.8113775253295898,
      "eval_f1_micro_0.7": 0.7936972379684448,
      "eval_f1_micro_0.8": 0.762268602848053,
      "eval_f1_micro_0.9": 0.6837007403373718,
      "eval_f1_weighted_0.5": 0.814548134803772,
      "eval_f1_weighted_0.6": 0.8069252967834473,
      "eval_f1_weighted_0.7": 0.7858927249908447,
      "eval_f1_weighted_0.8": 0.6601847410202026,
      "eval_loss": 0.02983114682137966,
      "eval_runtime": 133.7886,
      "eval_samples_per_second": 217.036,
      "eval_steps_per_second": 27.132,
      "step": 101801
    }
  ],
  "logging_steps": 100,
  "max_steps": 116344,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.636820625263411e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
