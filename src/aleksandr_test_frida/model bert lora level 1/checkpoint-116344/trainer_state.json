{
  "best_metric": 0.7037843465805054,
  "best_model_checkpoint": "aleksandr_test_frida/model bert lora level 1/checkpoint-116344",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 116344,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00687616035205941,
      "grad_norm": 0.3350415527820587,
      "learning_rate": 4.996131827324772e-05,
      "loss": 0.5486,
      "step": 100
    },
    {
      "epoch": 0.01375232070411882,
      "grad_norm": 0.19343632459640503,
      "learning_rate": 4.9918338576856295e-05,
      "loss": 0.2823,
      "step": 200
    },
    {
      "epoch": 0.02062848105617823,
      "grad_norm": 0.16062726080417633,
      "learning_rate": 4.9875358880464876e-05,
      "loss": 0.1589,
      "step": 300
    },
    {
      "epoch": 0.02750464140823764,
      "grad_norm": 0.14009137451648712,
      "learning_rate": 4.983237918407345e-05,
      "loss": 0.1426,
      "step": 400
    },
    {
      "epoch": 0.03438080176029705,
      "grad_norm": 0.1184418722987175,
      "learning_rate": 4.978939948768202e-05,
      "loss": 0.1356,
      "step": 500
    },
    {
      "epoch": 0.04125696211235646,
      "grad_norm": 0.11406698077917099,
      "learning_rate": 4.97464197912906e-05,
      "loss": 0.1375,
      "step": 600
    },
    {
      "epoch": 0.04813312246441587,
      "grad_norm": 0.13935446739196777,
      "learning_rate": 4.970344009489917e-05,
      "loss": 0.1374,
      "step": 700
    },
    {
      "epoch": 0.05500928281647528,
      "grad_norm": 0.13380712270736694,
      "learning_rate": 4.9660460398507745e-05,
      "loss": 0.1336,
      "step": 800
    },
    {
      "epoch": 0.06188544316853469,
      "grad_norm": 0.10231541097164154,
      "learning_rate": 4.961748070211632e-05,
      "loss": 0.1346,
      "step": 900
    },
    {
      "epoch": 0.0687616035205941,
      "grad_norm": 0.1670629233121872,
      "learning_rate": 4.95745010057249e-05,
      "loss": 0.134,
      "step": 1000
    },
    {
      "epoch": 0.07563776387265352,
      "grad_norm": 0.19169746339321136,
      "learning_rate": 4.9531521309333474e-05,
      "loss": 0.1356,
      "step": 1100
    },
    {
      "epoch": 0.08251392422471292,
      "grad_norm": 0.13487237691879272,
      "learning_rate": 4.948854161294205e-05,
      "loss": 0.1331,
      "step": 1200
    },
    {
      "epoch": 0.08939008457677233,
      "grad_norm": 0.13640615344047546,
      "learning_rate": 4.944556191655063e-05,
      "loss": 0.1354,
      "step": 1300
    },
    {
      "epoch": 0.09626624492883173,
      "grad_norm": 0.1261966973543167,
      "learning_rate": 4.94025822201592e-05,
      "loss": 0.1363,
      "step": 1400
    },
    {
      "epoch": 0.10314240528089115,
      "grad_norm": 0.12734867632389069,
      "learning_rate": 4.9359602523767776e-05,
      "loss": 0.1332,
      "step": 1500
    },
    {
      "epoch": 0.11001856563295057,
      "grad_norm": 0.14639517664909363,
      "learning_rate": 4.931662282737635e-05,
      "loss": 0.1303,
      "step": 1600
    },
    {
      "epoch": 0.11689472598500997,
      "grad_norm": 0.1091117411851883,
      "learning_rate": 4.9273643130984924e-05,
      "loss": 0.1329,
      "step": 1700
    },
    {
      "epoch": 0.12377088633706938,
      "grad_norm": 0.14600293338298798,
      "learning_rate": 4.92306634345935e-05,
      "loss": 0.1329,
      "step": 1800
    },
    {
      "epoch": 0.1306470466891288,
      "grad_norm": 0.14726358652114868,
      "learning_rate": 4.918768373820208e-05,
      "loss": 0.13,
      "step": 1900
    },
    {
      "epoch": 0.1375232070411882,
      "grad_norm": 0.10174703598022461,
      "learning_rate": 4.914470404181065e-05,
      "loss": 0.1278,
      "step": 2000
    },
    {
      "epoch": 0.1443993673932476,
      "grad_norm": 0.14468438923358917,
      "learning_rate": 4.9101724345419226e-05,
      "loss": 0.129,
      "step": 2100
    },
    {
      "epoch": 0.15127552774530703,
      "grad_norm": 0.12048649787902832,
      "learning_rate": 4.90587446490278e-05,
      "loss": 0.1264,
      "step": 2200
    },
    {
      "epoch": 0.15815168809736643,
      "grad_norm": 0.15535452961921692,
      "learning_rate": 4.901576495263638e-05,
      "loss": 0.1268,
      "step": 2300
    },
    {
      "epoch": 0.16502784844942583,
      "grad_norm": 0.12413351237773895,
      "learning_rate": 4.8972785256244955e-05,
      "loss": 0.1251,
      "step": 2400
    },
    {
      "epoch": 0.17190400880148526,
      "grad_norm": 0.09315285086631775,
      "learning_rate": 4.892980555985353e-05,
      "loss": 0.1207,
      "step": 2500
    },
    {
      "epoch": 0.17878016915354467,
      "grad_norm": 0.1409718245267868,
      "learning_rate": 4.88868258634621e-05,
      "loss": 0.124,
      "step": 2600
    },
    {
      "epoch": 0.18565632950560407,
      "grad_norm": 0.1382468193769455,
      "learning_rate": 4.8843846167070677e-05,
      "loss": 0.1197,
      "step": 2700
    },
    {
      "epoch": 0.19253248985766347,
      "grad_norm": 0.11920099705457687,
      "learning_rate": 4.880086647067925e-05,
      "loss": 0.1196,
      "step": 2800
    },
    {
      "epoch": 0.1994086502097229,
      "grad_norm": 0.16552822291851044,
      "learning_rate": 4.875788677428783e-05,
      "loss": 0.1165,
      "step": 2900
    },
    {
      "epoch": 0.2062848105617823,
      "grad_norm": 0.11450880020856857,
      "learning_rate": 4.8714907077896405e-05,
      "loss": 0.1148,
      "step": 3000
    },
    {
      "epoch": 0.2131609709138417,
      "grad_norm": 0.15873019397258759,
      "learning_rate": 4.867192738150498e-05,
      "loss": 0.1134,
      "step": 3100
    },
    {
      "epoch": 0.22003713126590113,
      "grad_norm": 0.13416452705860138,
      "learning_rate": 4.862894768511356e-05,
      "loss": 0.1128,
      "step": 3200
    },
    {
      "epoch": 0.22691329161796053,
      "grad_norm": 0.12238720804452896,
      "learning_rate": 4.8585967988722134e-05,
      "loss": 0.109,
      "step": 3300
    },
    {
      "epoch": 0.23378945197001993,
      "grad_norm": 0.17445731163024902,
      "learning_rate": 4.854298829233071e-05,
      "loss": 0.1089,
      "step": 3400
    },
    {
      "epoch": 0.24066561232207936,
      "grad_norm": 0.10705949366092682,
      "learning_rate": 4.850000859593928e-05,
      "loss": 0.1044,
      "step": 3500
    },
    {
      "epoch": 0.24754177267413877,
      "grad_norm": 0.26669493317604065,
      "learning_rate": 4.8457028899547855e-05,
      "loss": 0.1041,
      "step": 3600
    },
    {
      "epoch": 0.2544179330261982,
      "grad_norm": 0.17446430027484894,
      "learning_rate": 4.841404920315643e-05,
      "loss": 0.1014,
      "step": 3700
    },
    {
      "epoch": 0.2612940933782576,
      "grad_norm": 0.14774827659130096,
      "learning_rate": 4.8371069506765e-05,
      "loss": 0.1004,
      "step": 3800
    },
    {
      "epoch": 0.268170253730317,
      "grad_norm": 0.1457226723432541,
      "learning_rate": 4.8328089810373584e-05,
      "loss": 0.1014,
      "step": 3900
    },
    {
      "epoch": 0.2750464140823764,
      "grad_norm": 0.1136927455663681,
      "learning_rate": 4.828511011398216e-05,
      "loss": 0.0967,
      "step": 4000
    },
    {
      "epoch": 0.2819225744344358,
      "grad_norm": 0.12827129662036896,
      "learning_rate": 4.824213041759073e-05,
      "loss": 0.0967,
      "step": 4100
    },
    {
      "epoch": 0.2887987347864952,
      "grad_norm": 0.14310507476329803,
      "learning_rate": 4.819915072119931e-05,
      "loss": 0.094,
      "step": 4200
    },
    {
      "epoch": 0.2956748951385546,
      "grad_norm": 0.12882737815380096,
      "learning_rate": 4.8156171024807886e-05,
      "loss": 0.0923,
      "step": 4300
    },
    {
      "epoch": 0.30255105549061406,
      "grad_norm": 0.14378491044044495,
      "learning_rate": 4.811319132841646e-05,
      "loss": 0.091,
      "step": 4400
    },
    {
      "epoch": 0.30942721584267346,
      "grad_norm": 0.13162687420845032,
      "learning_rate": 4.8070211632025034e-05,
      "loss": 0.0905,
      "step": 4500
    },
    {
      "epoch": 0.31630337619473287,
      "grad_norm": 0.13989026844501495,
      "learning_rate": 4.802723193563361e-05,
      "loss": 0.0892,
      "step": 4600
    },
    {
      "epoch": 0.32317953654679227,
      "grad_norm": 0.10594753921031952,
      "learning_rate": 4.798425223924218e-05,
      "loss": 0.0886,
      "step": 4700
    },
    {
      "epoch": 0.33005569689885167,
      "grad_norm": 0.11765149980783463,
      "learning_rate": 4.7941272542850756e-05,
      "loss": 0.0886,
      "step": 4800
    },
    {
      "epoch": 0.33693185725091107,
      "grad_norm": 0.1352253407239914,
      "learning_rate": 4.7898292846459336e-05,
      "loss": 0.0869,
      "step": 4900
    },
    {
      "epoch": 0.34380801760297053,
      "grad_norm": 0.1588597297668457,
      "learning_rate": 4.785531315006791e-05,
      "loss": 0.0857,
      "step": 5000
    },
    {
      "epoch": 0.35068417795502993,
      "grad_norm": 0.12757156789302826,
      "learning_rate": 4.7812333453676484e-05,
      "loss": 0.0848,
      "step": 5100
    },
    {
      "epoch": 0.35756033830708933,
      "grad_norm": 0.13355091214179993,
      "learning_rate": 4.7769353757285065e-05,
      "loss": 0.0852,
      "step": 5200
    },
    {
      "epoch": 0.36443649865914873,
      "grad_norm": 0.12650880217552185,
      "learning_rate": 4.772637406089364e-05,
      "loss": 0.0847,
      "step": 5300
    },
    {
      "epoch": 0.37131265901120813,
      "grad_norm": 0.1328519880771637,
      "learning_rate": 4.768339436450221e-05,
      "loss": 0.0855,
      "step": 5400
    },
    {
      "epoch": 0.37818881936326754,
      "grad_norm": 0.17277880012989044,
      "learning_rate": 4.764041466811079e-05,
      "loss": 0.0828,
      "step": 5500
    },
    {
      "epoch": 0.38506497971532694,
      "grad_norm": 0.10483887791633606,
      "learning_rate": 4.759743497171936e-05,
      "loss": 0.0804,
      "step": 5600
    },
    {
      "epoch": 0.3919411400673864,
      "grad_norm": 0.11155959218740463,
      "learning_rate": 4.7554455275327935e-05,
      "loss": 0.0806,
      "step": 5700
    },
    {
      "epoch": 0.3988173004194458,
      "grad_norm": 0.15518657863140106,
      "learning_rate": 4.7511475578936515e-05,
      "loss": 0.0839,
      "step": 5800
    },
    {
      "epoch": 0.4056934607715052,
      "grad_norm": 0.13318659365177155,
      "learning_rate": 4.746849588254509e-05,
      "loss": 0.0827,
      "step": 5900
    },
    {
      "epoch": 0.4125696211235646,
      "grad_norm": 0.10994560271501541,
      "learning_rate": 4.742551618615366e-05,
      "loss": 0.0803,
      "step": 6000
    },
    {
      "epoch": 0.419445781475624,
      "grad_norm": 0.12515951693058014,
      "learning_rate": 4.738253648976224e-05,
      "loss": 0.0785,
      "step": 6100
    },
    {
      "epoch": 0.4263219418276834,
      "grad_norm": 0.09825009852647781,
      "learning_rate": 4.733955679337082e-05,
      "loss": 0.0777,
      "step": 6200
    },
    {
      "epoch": 0.4331981021797428,
      "grad_norm": 0.14863842725753784,
      "learning_rate": 4.729657709697939e-05,
      "loss": 0.0754,
      "step": 6300
    },
    {
      "epoch": 0.44007426253180226,
      "grad_norm": 0.12479501217603683,
      "learning_rate": 4.7253597400587965e-05,
      "loss": 0.0769,
      "step": 6400
    },
    {
      "epoch": 0.44695042288386166,
      "grad_norm": 0.160185769200325,
      "learning_rate": 4.721061770419654e-05,
      "loss": 0.0769,
      "step": 6500
    },
    {
      "epoch": 0.45382658323592107,
      "grad_norm": 0.10511671006679535,
      "learning_rate": 4.716763800780511e-05,
      "loss": 0.0771,
      "step": 6600
    },
    {
      "epoch": 0.46070274358798047,
      "grad_norm": 0.12540362775325775,
      "learning_rate": 4.712465831141369e-05,
      "loss": 0.0784,
      "step": 6700
    },
    {
      "epoch": 0.46757890394003987,
      "grad_norm": 0.14250002801418304,
      "learning_rate": 4.708167861502227e-05,
      "loss": 0.0797,
      "step": 6800
    },
    {
      "epoch": 0.47445506429209927,
      "grad_norm": 0.14557543396949768,
      "learning_rate": 4.703869891863084e-05,
      "loss": 0.0762,
      "step": 6900
    },
    {
      "epoch": 0.48133122464415873,
      "grad_norm": 0.12261806428432465,
      "learning_rate": 4.6995719222239416e-05,
      "loss": 0.075,
      "step": 7000
    },
    {
      "epoch": 0.48820738499621813,
      "grad_norm": 0.11894184350967407,
      "learning_rate": 4.6952739525847996e-05,
      "loss": 0.0752,
      "step": 7100
    },
    {
      "epoch": 0.49508354534827753,
      "grad_norm": 0.16142074763774872,
      "learning_rate": 4.690975982945657e-05,
      "loss": 0.0754,
      "step": 7200
    },
    {
      "epoch": 0.5019597057003369,
      "grad_norm": 0.14399020373821259,
      "learning_rate": 4.6866780133065144e-05,
      "loss": 0.0733,
      "step": 7300
    },
    {
      "epoch": 0.5088358660523964,
      "grad_norm": 0.14215883612632751,
      "learning_rate": 4.682380043667372e-05,
      "loss": 0.0722,
      "step": 7400
    },
    {
      "epoch": 0.5157120264044558,
      "grad_norm": 0.16302837431430817,
      "learning_rate": 4.678082074028229e-05,
      "loss": 0.0727,
      "step": 7500
    },
    {
      "epoch": 0.5225881867565152,
      "grad_norm": 0.12421737611293793,
      "learning_rate": 4.6737841043890866e-05,
      "loss": 0.0764,
      "step": 7600
    },
    {
      "epoch": 0.5294643471085746,
      "grad_norm": 0.17964871227741241,
      "learning_rate": 4.669486134749944e-05,
      "loss": 0.0739,
      "step": 7700
    },
    {
      "epoch": 0.536340507460634,
      "grad_norm": 0.11693662405014038,
      "learning_rate": 4.665188165110802e-05,
      "loss": 0.0774,
      "step": 7800
    },
    {
      "epoch": 0.5432166678126934,
      "grad_norm": 0.11858230829238892,
      "learning_rate": 4.6608901954716594e-05,
      "loss": 0.0727,
      "step": 7900
    },
    {
      "epoch": 0.5500928281647528,
      "grad_norm": 0.16693535447120667,
      "learning_rate": 4.656592225832517e-05,
      "loss": 0.072,
      "step": 8000
    },
    {
      "epoch": 0.5569689885168122,
      "grad_norm": 0.11035700887441635,
      "learning_rate": 4.652294256193375e-05,
      "loss": 0.0704,
      "step": 8100
    },
    {
      "epoch": 0.5638451488688716,
      "grad_norm": 0.1672648936510086,
      "learning_rate": 4.647996286554232e-05,
      "loss": 0.0727,
      "step": 8200
    },
    {
      "epoch": 0.570721309220931,
      "grad_norm": 0.15644365549087524,
      "learning_rate": 4.64369831691509e-05,
      "loss": 0.0728,
      "step": 8300
    },
    {
      "epoch": 0.5775974695729904,
      "grad_norm": 0.15932707488536835,
      "learning_rate": 4.639400347275947e-05,
      "loss": 0.0715,
      "step": 8400
    },
    {
      "epoch": 0.5844736299250498,
      "grad_norm": 0.11635280400514603,
      "learning_rate": 4.6351023776368045e-05,
      "loss": 0.0736,
      "step": 8500
    },
    {
      "epoch": 0.5913497902771092,
      "grad_norm": 0.10681158304214478,
      "learning_rate": 4.630804407997662e-05,
      "loss": 0.0738,
      "step": 8600
    },
    {
      "epoch": 0.5982259506291687,
      "grad_norm": 0.10610450059175491,
      "learning_rate": 4.62650643835852e-05,
      "loss": 0.0696,
      "step": 8700
    },
    {
      "epoch": 0.6051021109812281,
      "grad_norm": 0.1467730551958084,
      "learning_rate": 4.622208468719377e-05,
      "loss": 0.0708,
      "step": 8800
    },
    {
      "epoch": 0.6119782713332875,
      "grad_norm": 0.12849926948547363,
      "learning_rate": 4.617910499080235e-05,
      "loss": 0.0722,
      "step": 8900
    },
    {
      "epoch": 0.6188544316853469,
      "grad_norm": 0.12849955260753632,
      "learning_rate": 4.613612529441092e-05,
      "loss": 0.0707,
      "step": 9000
    },
    {
      "epoch": 0.6257305920374063,
      "grad_norm": 0.15610653162002563,
      "learning_rate": 4.60931455980195e-05,
      "loss": 0.071,
      "step": 9100
    },
    {
      "epoch": 0.6326067523894657,
      "grad_norm": 0.1514684110879898,
      "learning_rate": 4.6050165901628076e-05,
      "loss": 0.0729,
      "step": 9200
    },
    {
      "epoch": 0.6394829127415251,
      "grad_norm": 0.13151401281356812,
      "learning_rate": 4.600718620523665e-05,
      "loss": 0.0709,
      "step": 9300
    },
    {
      "epoch": 0.6463590730935845,
      "grad_norm": 0.13530944287776947,
      "learning_rate": 4.5964206508845223e-05,
      "loss": 0.0679,
      "step": 9400
    },
    {
      "epoch": 0.6532352334456439,
      "grad_norm": 0.0909171998500824,
      "learning_rate": 4.59212268124538e-05,
      "loss": 0.0703,
      "step": 9500
    },
    {
      "epoch": 0.6601113937977033,
      "grad_norm": 0.15129779279232025,
      "learning_rate": 4.587824711606237e-05,
      "loss": 0.0704,
      "step": 9600
    },
    {
      "epoch": 0.6669875541497627,
      "grad_norm": 0.09946879744529724,
      "learning_rate": 4.583526741967095e-05,
      "loss": 0.0688,
      "step": 9700
    },
    {
      "epoch": 0.6738637145018221,
      "grad_norm": 0.2249511182308197,
      "learning_rate": 4.5792287723279526e-05,
      "loss": 0.0675,
      "step": 9800
    },
    {
      "epoch": 0.6807398748538815,
      "grad_norm": 0.17581313848495483,
      "learning_rate": 4.57493080268881e-05,
      "loss": 0.068,
      "step": 9900
    },
    {
      "epoch": 0.6876160352059411,
      "grad_norm": 0.11111868172883987,
      "learning_rate": 4.570632833049668e-05,
      "loss": 0.0687,
      "step": 10000
    },
    {
      "epoch": 0.6944921955580005,
      "grad_norm": 0.1538511961698532,
      "learning_rate": 4.5663348634105254e-05,
      "loss": 0.07,
      "step": 10100
    },
    {
      "epoch": 0.7013683559100599,
      "grad_norm": 0.16791066527366638,
      "learning_rate": 4.562036893771383e-05,
      "loss": 0.0692,
      "step": 10200
    },
    {
      "epoch": 0.7082445162621193,
      "grad_norm": 0.13587361574172974,
      "learning_rate": 4.55773892413224e-05,
      "loss": 0.0672,
      "step": 10300
    },
    {
      "epoch": 0.7151206766141787,
      "grad_norm": 0.1001506969332695,
      "learning_rate": 4.5534409544930976e-05,
      "loss": 0.0665,
      "step": 10400
    },
    {
      "epoch": 0.7219968369662381,
      "grad_norm": 0.1267450749874115,
      "learning_rate": 4.549142984853955e-05,
      "loss": 0.0683,
      "step": 10500
    },
    {
      "epoch": 0.7288729973182975,
      "grad_norm": 0.14420363306999207,
      "learning_rate": 4.5448450152148124e-05,
      "loss": 0.07,
      "step": 10600
    },
    {
      "epoch": 0.7357491576703569,
      "grad_norm": 0.16862721741199493,
      "learning_rate": 4.5405470455756705e-05,
      "loss": 0.0642,
      "step": 10700
    },
    {
      "epoch": 0.7426253180224163,
      "grad_norm": 0.13154593110084534,
      "learning_rate": 4.536249075936528e-05,
      "loss": 0.0678,
      "step": 10800
    },
    {
      "epoch": 0.7495014783744757,
      "grad_norm": 0.14726175367832184,
      "learning_rate": 4.531951106297385e-05,
      "loss": 0.069,
      "step": 10900
    },
    {
      "epoch": 0.7563776387265351,
      "grad_norm": 0.18080729246139526,
      "learning_rate": 4.527653136658243e-05,
      "loss": 0.0666,
      "step": 11000
    },
    {
      "epoch": 0.7632537990785945,
      "grad_norm": 0.10700750350952148,
      "learning_rate": 4.523355167019101e-05,
      "loss": 0.0648,
      "step": 11100
    },
    {
      "epoch": 0.7701299594306539,
      "grad_norm": 0.1488790214061737,
      "learning_rate": 4.519057197379958e-05,
      "loss": 0.066,
      "step": 11200
    },
    {
      "epoch": 0.7770061197827133,
      "grad_norm": 0.10954894870519638,
      "learning_rate": 4.5147592277408155e-05,
      "loss": 0.0663,
      "step": 11300
    },
    {
      "epoch": 0.7838822801347728,
      "grad_norm": 0.13876663148403168,
      "learning_rate": 4.510461258101673e-05,
      "loss": 0.069,
      "step": 11400
    },
    {
      "epoch": 0.7907584404868322,
      "grad_norm": 0.11528214812278748,
      "learning_rate": 4.50616328846253e-05,
      "loss": 0.0662,
      "step": 11500
    },
    {
      "epoch": 0.7976346008388916,
      "grad_norm": 0.12314612418413162,
      "learning_rate": 4.501865318823388e-05,
      "loss": 0.0681,
      "step": 11600
    },
    {
      "epoch": 0.804510761190951,
      "grad_norm": 0.10665950924158096,
      "learning_rate": 4.497567349184246e-05,
      "loss": 0.0663,
      "step": 11700
    },
    {
      "epoch": 0.8113869215430104,
      "grad_norm": 0.08311057090759277,
      "learning_rate": 4.493269379545103e-05,
      "loss": 0.0643,
      "step": 11800
    },
    {
      "epoch": 0.8182630818950698,
      "grad_norm": 0.12246163934469223,
      "learning_rate": 4.4889714099059605e-05,
      "loss": 0.0662,
      "step": 11900
    },
    {
      "epoch": 0.8251392422471292,
      "grad_norm": 0.16116589307785034,
      "learning_rate": 4.4846734402668186e-05,
      "loss": 0.0673,
      "step": 12000
    },
    {
      "epoch": 0.8320154025991886,
      "grad_norm": 0.10453524440526962,
      "learning_rate": 4.480375470627676e-05,
      "loss": 0.0655,
      "step": 12100
    },
    {
      "epoch": 0.838891562951248,
      "grad_norm": 0.11951164156198502,
      "learning_rate": 4.4760775009885334e-05,
      "loss": 0.0626,
      "step": 12200
    },
    {
      "epoch": 0.8457677233033074,
      "grad_norm": 0.11908961087465286,
      "learning_rate": 4.471779531349391e-05,
      "loss": 0.0609,
      "step": 12300
    },
    {
      "epoch": 0.8526438836553668,
      "grad_norm": 0.14646734297275543,
      "learning_rate": 4.467481561710248e-05,
      "loss": 0.0633,
      "step": 12400
    },
    {
      "epoch": 0.8595200440074262,
      "grad_norm": 0.1187795102596283,
      "learning_rate": 4.4631835920711055e-05,
      "loss": 0.0647,
      "step": 12500
    },
    {
      "epoch": 0.8663962043594856,
      "grad_norm": 0.15897388756275177,
      "learning_rate": 4.458928602128355e-05,
      "loss": 0.0657,
      "step": 12600
    },
    {
      "epoch": 0.8732723647115451,
      "grad_norm": 0.1082955002784729,
      "learning_rate": 4.4546306324892125e-05,
      "loss": 0.065,
      "step": 12700
    },
    {
      "epoch": 0.8801485250636045,
      "grad_norm": 0.11694148927927017,
      "learning_rate": 4.45033266285007e-05,
      "loss": 0.0672,
      "step": 12800
    },
    {
      "epoch": 0.8870246854156639,
      "grad_norm": 0.1385386884212494,
      "learning_rate": 4.446034693210927e-05,
      "loss": 0.0659,
      "step": 12900
    },
    {
      "epoch": 0.8939008457677233,
      "grad_norm": 0.16967758536338806,
      "learning_rate": 4.441736723571785e-05,
      "loss": 0.0663,
      "step": 13000
    },
    {
      "epoch": 0.9007770061197827,
      "grad_norm": 0.14948126673698425,
      "learning_rate": 4.437438753932642e-05,
      "loss": 0.0645,
      "step": 13100
    },
    {
      "epoch": 0.9076531664718421,
      "grad_norm": 0.11339463293552399,
      "learning_rate": 4.4331407842935e-05,
      "loss": 0.0667,
      "step": 13200
    },
    {
      "epoch": 0.9145293268239015,
      "grad_norm": 0.14071953296661377,
      "learning_rate": 4.4288428146543575e-05,
      "loss": 0.0649,
      "step": 13300
    },
    {
      "epoch": 0.9214054871759609,
      "grad_norm": 0.14880181849002838,
      "learning_rate": 4.424544845015215e-05,
      "loss": 0.0619,
      "step": 13400
    },
    {
      "epoch": 0.9282816475280203,
      "grad_norm": 0.12657828629016876,
      "learning_rate": 4.420246875376072e-05,
      "loss": 0.0641,
      "step": 13500
    },
    {
      "epoch": 0.9351578078800797,
      "grad_norm": 0.13059686124324799,
      "learning_rate": 4.4159489057369304e-05,
      "loss": 0.0636,
      "step": 13600
    },
    {
      "epoch": 0.9420339682321391,
      "grad_norm": 0.10446398705244064,
      "learning_rate": 4.411650936097788e-05,
      "loss": 0.0627,
      "step": 13700
    },
    {
      "epoch": 0.9489101285841985,
      "grad_norm": 0.14226172864437103,
      "learning_rate": 4.407352966458645e-05,
      "loss": 0.0657,
      "step": 13800
    },
    {
      "epoch": 0.9557862889362579,
      "grad_norm": 0.14208586513996124,
      "learning_rate": 4.4030549968195026e-05,
      "loss": 0.0641,
      "step": 13900
    },
    {
      "epoch": 0.9626624492883175,
      "grad_norm": 0.11268169432878494,
      "learning_rate": 4.39875702718036e-05,
      "loss": 0.0648,
      "step": 14000
    },
    {
      "epoch": 0.9695386096403769,
      "grad_norm": 0.12545940279960632,
      "learning_rate": 4.3944590575412173e-05,
      "loss": 0.0655,
      "step": 14100
    },
    {
      "epoch": 0.9764147699924363,
      "grad_norm": 0.14785759150981903,
      "learning_rate": 4.3901610879020754e-05,
      "loss": 0.0645,
      "step": 14200
    },
    {
      "epoch": 0.9832909303444957,
      "grad_norm": 0.13909651339054108,
      "learning_rate": 4.385863118262933e-05,
      "loss": 0.0622,
      "step": 14300
    },
    {
      "epoch": 0.9901670906965551,
      "grad_norm": 0.14398322999477386,
      "learning_rate": 4.38156514862379e-05,
      "loss": 0.0606,
      "step": 14400
    },
    {
      "epoch": 0.9970432510486145,
      "grad_norm": 0.09822813421487808,
      "learning_rate": 4.377267178984648e-05,
      "loss": 0.0625,
      "step": 14500
    },
    {
      "epoch": 1.0,
      "eval_accuracy_macro_0.5": 0.9718677997589111,
      "eval_accuracy_micro_0.5": 0.9718677997589111,
      "eval_accuracy_weighted_0.5": 0.968504786491394,
      "eval_f1_macro_0.5": 0.5355393886566162,
      "eval_f1_macro_0.6": 0.47785502672195435,
      "eval_f1_macro_0.7": 0.3806980550289154,
      "eval_f1_macro_0.8": 0.08814606070518494,
      "eval_f1_micro_0.5": 0.5799858570098877,
      "eval_f1_micro_0.6": 0.5251048803329468,
      "eval_f1_micro_0.7": 0.42519906163215637,
      "eval_f1_micro_0.8": 0.2914946973323822,
      "eval_f1_micro_0.9": 0.10560049116611481,
      "eval_f1_weighted_0.5": 0.5413304567337036,
      "eval_f1_weighted_0.6": 0.47793006896972656,
      "eval_f1_weighted_0.7": 0.3714282214641571,
      "eval_f1_weighted_0.8": 0.08823423087596893,
      "eval_loss": 0.06009691581130028,
      "eval_runtime": 115.3497,
      "eval_samples_per_second": 251.73,
      "eval_steps_per_second": 31.47,
      "step": 14543
    },
    {
      "epoch": 1.0039194114006738,
      "grad_norm": 0.14461097121238708,
      "learning_rate": 4.3729692093455057e-05,
      "loss": 0.063,
      "step": 14600
    },
    {
      "epoch": 1.0107955717527333,
      "grad_norm": 0.10562682151794434,
      "learning_rate": 4.368671239706363e-05,
      "loss": 0.0634,
      "step": 14700
    },
    {
      "epoch": 1.0176717321047928,
      "grad_norm": 0.13340328633785248,
      "learning_rate": 4.3643732700672204e-05,
      "loss": 0.0608,
      "step": 14800
    },
    {
      "epoch": 1.024547892456852,
      "grad_norm": 0.12165195494890213,
      "learning_rate": 4.360075300428078e-05,
      "loss": 0.063,
      "step": 14900
    },
    {
      "epoch": 1.0314240528089116,
      "grad_norm": 0.17471279203891754,
      "learning_rate": 4.355777330788935e-05,
      "loss": 0.0639,
      "step": 15000
    },
    {
      "epoch": 1.0383002131609709,
      "grad_norm": 0.1426566243171692,
      "learning_rate": 4.3514793611497926e-05,
      "loss": 0.0645,
      "step": 15100
    },
    {
      "epoch": 1.0451763735130304,
      "grad_norm": 0.08600223809480667,
      "learning_rate": 4.347181391510651e-05,
      "loss": 0.06,
      "step": 15200
    },
    {
      "epoch": 1.0520525338650897,
      "grad_norm": 0.10125719755887985,
      "learning_rate": 4.3429264015678996e-05,
      "loss": 0.061,
      "step": 15300
    },
    {
      "epoch": 1.0589286942171492,
      "grad_norm": 0.12398714572191238,
      "learning_rate": 4.338628431928757e-05,
      "loss": 0.0644,
      "step": 15400
    },
    {
      "epoch": 1.0658048545692085,
      "grad_norm": 0.12089789658784866,
      "learning_rate": 4.3343304622896144e-05,
      "loss": 0.0621,
      "step": 15500
    },
    {
      "epoch": 1.072681014921268,
      "grad_norm": 0.10721462965011597,
      "learning_rate": 4.330032492650472e-05,
      "loss": 0.0597,
      "step": 15600
    },
    {
      "epoch": 1.0795571752733273,
      "grad_norm": 0.12224875390529633,
      "learning_rate": 4.325734523011329e-05,
      "loss": 0.0629,
      "step": 15700
    },
    {
      "epoch": 1.0864333356253868,
      "grad_norm": 0.11224023997783661,
      "learning_rate": 4.321436553372187e-05,
      "loss": 0.0617,
      "step": 15800
    },
    {
      "epoch": 1.0933094959774463,
      "grad_norm": 0.13448990881443024,
      "learning_rate": 4.3171385837330446e-05,
      "loss": 0.0634,
      "step": 15900
    },
    {
      "epoch": 1.1001856563295056,
      "grad_norm": 0.1230575293302536,
      "learning_rate": 4.312840614093902e-05,
      "loss": 0.063,
      "step": 16000
    },
    {
      "epoch": 1.1070618166815651,
      "grad_norm": 0.12742140889167786,
      "learning_rate": 4.30854264445476e-05,
      "loss": 0.0586,
      "step": 16100
    },
    {
      "epoch": 1.1139379770336244,
      "grad_norm": 0.1371876299381256,
      "learning_rate": 4.3042446748156175e-05,
      "loss": 0.0594,
      "step": 16200
    },
    {
      "epoch": 1.120814137385684,
      "grad_norm": 0.12909696996212006,
      "learning_rate": 4.299946705176475e-05,
      "loss": 0.0593,
      "step": 16300
    },
    {
      "epoch": 1.1276902977377432,
      "grad_norm": 0.11397235840559006,
      "learning_rate": 4.295648735537333e-05,
      "loss": 0.0616,
      "step": 16400
    },
    {
      "epoch": 1.1345664580898027,
      "grad_norm": 0.145175039768219,
      "learning_rate": 4.2913507658981896e-05,
      "loss": 0.0628,
      "step": 16500
    },
    {
      "epoch": 1.141442618441862,
      "grad_norm": 0.10037820786237717,
      "learning_rate": 4.287052796259047e-05,
      "loss": 0.0626,
      "step": 16600
    },
    {
      "epoch": 1.1483187787939215,
      "grad_norm": 0.1518758237361908,
      "learning_rate": 4.282754826619905e-05,
      "loss": 0.0607,
      "step": 16700
    },
    {
      "epoch": 1.1551949391459808,
      "grad_norm": 0.1423468440771103,
      "learning_rate": 4.2784568569807625e-05,
      "loss": 0.0609,
      "step": 16800
    },
    {
      "epoch": 1.1620710994980403,
      "grad_norm": 0.15017971396446228,
      "learning_rate": 4.27415888734162e-05,
      "loss": 0.0608,
      "step": 16900
    },
    {
      "epoch": 1.1689472598500996,
      "grad_norm": 0.1025128960609436,
      "learning_rate": 4.269860917702477e-05,
      "loss": 0.0616,
      "step": 17000
    },
    {
      "epoch": 1.1758234202021591,
      "grad_norm": 0.15357014536857605,
      "learning_rate": 4.265562948063335e-05,
      "loss": 0.0608,
      "step": 17100
    },
    {
      "epoch": 1.1826995805542184,
      "grad_norm": 0.1317501962184906,
      "learning_rate": 4.261264978424193e-05,
      "loss": 0.0627,
      "step": 17200
    },
    {
      "epoch": 1.189575740906278,
      "grad_norm": 0.12960918247699738,
      "learning_rate": 4.25696700878505e-05,
      "loss": 0.064,
      "step": 17300
    },
    {
      "epoch": 1.1964519012583374,
      "grad_norm": 0.16334570944309235,
      "learning_rate": 4.252712018842299e-05,
      "loss": 0.0626,
      "step": 17400
    },
    {
      "epoch": 1.2033280616103967,
      "grad_norm": 0.14428766071796417,
      "learning_rate": 4.2484140492031564e-05,
      "loss": 0.0613,
      "step": 17500
    },
    {
      "epoch": 1.2102042219624563,
      "grad_norm": 0.12037571519613266,
      "learning_rate": 4.244116079564014e-05,
      "loss": 0.0613,
      "step": 17600
    },
    {
      "epoch": 1.2170803823145155,
      "grad_norm": 0.1157577782869339,
      "learning_rate": 4.239818109924872e-05,
      "loss": 0.0625,
      "step": 17700
    },
    {
      "epoch": 1.223956542666575,
      "grad_norm": 0.11168044060468674,
      "learning_rate": 4.235520140285729e-05,
      "loss": 0.0608,
      "step": 17800
    },
    {
      "epoch": 1.2308327030186343,
      "grad_norm": 0.13126301765441895,
      "learning_rate": 4.2312221706465867e-05,
      "loss": 0.0594,
      "step": 17900
    },
    {
      "epoch": 1.2377088633706939,
      "grad_norm": 0.12998494505882263,
      "learning_rate": 4.226924201007445e-05,
      "loss": 0.0612,
      "step": 18000
    },
    {
      "epoch": 1.2445850237227531,
      "grad_norm": 0.1029873788356781,
      "learning_rate": 4.222626231368302e-05,
      "loss": 0.0599,
      "step": 18100
    },
    {
      "epoch": 1.2514611840748127,
      "grad_norm": 0.1752173900604248,
      "learning_rate": 4.2183282617291595e-05,
      "loss": 0.0612,
      "step": 18200
    },
    {
      "epoch": 1.258337344426872,
      "grad_norm": 0.16601206362247467,
      "learning_rate": 4.214030292090017e-05,
      "loss": 0.0584,
      "step": 18300
    },
    {
      "epoch": 1.2652135047789315,
      "grad_norm": 0.14530444145202637,
      "learning_rate": 4.209732322450874e-05,
      "loss": 0.0583,
      "step": 18400
    },
    {
      "epoch": 1.272089665130991,
      "grad_norm": 0.1257399618625641,
      "learning_rate": 4.205434352811732e-05,
      "loss": 0.0597,
      "step": 18500
    },
    {
      "epoch": 1.2789658254830503,
      "grad_norm": 0.21771922707557678,
      "learning_rate": 4.20113638317259e-05,
      "loss": 0.0589,
      "step": 18600
    },
    {
      "epoch": 1.2858419858351096,
      "grad_norm": 0.1393871307373047,
      "learning_rate": 4.196838413533447e-05,
      "loss": 0.0571,
      "step": 18700
    },
    {
      "epoch": 1.292718146187169,
      "grad_norm": 0.11161191761493683,
      "learning_rate": 4.1925404438943045e-05,
      "loss": 0.0618,
      "step": 18800
    },
    {
      "epoch": 1.2995943065392286,
      "grad_norm": 0.13805463910102844,
      "learning_rate": 4.188242474255162e-05,
      "loss": 0.0589,
      "step": 18900
    },
    {
      "epoch": 1.3064704668912879,
      "grad_norm": 0.09434720873832703,
      "learning_rate": 4.18394450461602e-05,
      "loss": 0.059,
      "step": 19000
    },
    {
      "epoch": 1.3133466272433474,
      "grad_norm": 0.09092583507299423,
      "learning_rate": 4.1796465349768774e-05,
      "loss": 0.0597,
      "step": 19100
    },
    {
      "epoch": 1.3202227875954067,
      "grad_norm": 0.14830785989761353,
      "learning_rate": 4.175348565337735e-05,
      "loss": 0.0626,
      "step": 19200
    },
    {
      "epoch": 1.3270989479474662,
      "grad_norm": 0.13735178112983704,
      "learning_rate": 4.171050595698592e-05,
      "loss": 0.0603,
      "step": 19300
    },
    {
      "epoch": 1.3339751082995255,
      "grad_norm": 0.10327726602554321,
      "learning_rate": 4.1667526260594496e-05,
      "loss": 0.0566,
      "step": 19400
    },
    {
      "epoch": 1.340851268651585,
      "grad_norm": 0.11576008051633835,
      "learning_rate": 4.162454656420307e-05,
      "loss": 0.0609,
      "step": 19500
    },
    {
      "epoch": 1.3477274290036443,
      "grad_norm": 0.17412029206752777,
      "learning_rate": 4.1581996664775565e-05,
      "loss": 0.0575,
      "step": 19600
    },
    {
      "epoch": 1.3546035893557038,
      "grad_norm": 0.13223958015441895,
      "learning_rate": 4.153901696838414e-05,
      "loss": 0.0596,
      "step": 19700
    },
    {
      "epoch": 1.361479749707763,
      "grad_norm": 0.10614436864852905,
      "learning_rate": 4.149603727199271e-05,
      "loss": 0.0588,
      "step": 19800
    },
    {
      "epoch": 1.3683559100598226,
      "grad_norm": 0.1367625594139099,
      "learning_rate": 4.145305757560129e-05,
      "loss": 0.0584,
      "step": 19900
    },
    {
      "epoch": 1.3752320704118821,
      "grad_norm": 0.09326872229576111,
      "learning_rate": 4.141007787920986e-05,
      "loss": 0.0571,
      "step": 20000
    },
    {
      "epoch": 1.3821082307639414,
      "grad_norm": 0.14509525895118713,
      "learning_rate": 4.1367098182818435e-05,
      "loss": 0.057,
      "step": 20100
    },
    {
      "epoch": 1.3889843911160007,
      "grad_norm": 0.14114174246788025,
      "learning_rate": 4.1324118486427016e-05,
      "loss": 0.059,
      "step": 20200
    },
    {
      "epoch": 1.3958605514680602,
      "grad_norm": 0.09456304460763931,
      "learning_rate": 4.128113879003559e-05,
      "loss": 0.0588,
      "step": 20300
    },
    {
      "epoch": 1.4027367118201197,
      "grad_norm": 0.1383804976940155,
      "learning_rate": 4.123815909364416e-05,
      "loss": 0.0607,
      "step": 20400
    },
    {
      "epoch": 1.409612872172179,
      "grad_norm": 0.1387786865234375,
      "learning_rate": 4.1195179397252744e-05,
      "loss": 0.0592,
      "step": 20500
    },
    {
      "epoch": 1.4164890325242385,
      "grad_norm": 0.11535993963479996,
      "learning_rate": 4.115219970086132e-05,
      "loss": 0.0572,
      "step": 20600
    },
    {
      "epoch": 1.4233651928762978,
      "grad_norm": 0.15178629755973816,
      "learning_rate": 4.110922000446989e-05,
      "loss": 0.0611,
      "step": 20700
    },
    {
      "epoch": 1.4302413532283573,
      "grad_norm": 0.11456377059221268,
      "learning_rate": 4.1066240308078466e-05,
      "loss": 0.0567,
      "step": 20800
    },
    {
      "epoch": 1.4371175135804166,
      "grad_norm": 0.10848721861839294,
      "learning_rate": 4.102326061168704e-05,
      "loss": 0.0607,
      "step": 20900
    },
    {
      "epoch": 1.4439936739324761,
      "grad_norm": 0.137808695435524,
      "learning_rate": 4.0980280915295614e-05,
      "loss": 0.0616,
      "step": 21000
    },
    {
      "epoch": 1.4508698342845356,
      "grad_norm": 0.1032722145318985,
      "learning_rate": 4.093730121890419e-05,
      "loss": 0.06,
      "step": 21100
    },
    {
      "epoch": 1.457745994636595,
      "grad_norm": 0.12540294229984283,
      "learning_rate": 4.089432152251277e-05,
      "loss": 0.0577,
      "step": 21200
    },
    {
      "epoch": 1.4646221549886542,
      "grad_norm": 0.1538602113723755,
      "learning_rate": 4.085134182612134e-05,
      "loss": 0.0594,
      "step": 21300
    },
    {
      "epoch": 1.4714983153407137,
      "grad_norm": 0.19389177858829498,
      "learning_rate": 4.0808362129729916e-05,
      "loss": 0.0552,
      "step": 21400
    },
    {
      "epoch": 1.4783744756927732,
      "grad_norm": 0.14678654074668884,
      "learning_rate": 4.07653824333385e-05,
      "loss": 0.0602,
      "step": 21500
    },
    {
      "epoch": 1.4852506360448325,
      "grad_norm": 0.18513664603233337,
      "learning_rate": 4.072240273694707e-05,
      "loss": 0.0586,
      "step": 21600
    },
    {
      "epoch": 1.492126796396892,
      "grad_norm": 0.13173891603946686,
      "learning_rate": 4.067985283751955e-05,
      "loss": 0.0593,
      "step": 21700
    },
    {
      "epoch": 1.4990029567489513,
      "grad_norm": 0.10260940343141556,
      "learning_rate": 4.0636873141128134e-05,
      "loss": 0.0569,
      "step": 21800
    },
    {
      "epoch": 1.5058791171010109,
      "grad_norm": 0.08367956429719925,
      "learning_rate": 4.059389344473671e-05,
      "loss": 0.0592,
      "step": 21900
    },
    {
      "epoch": 1.5127552774530701,
      "grad_norm": 0.16915346682071686,
      "learning_rate": 4.055091374834528e-05,
      "loss": 0.0585,
      "step": 22000
    },
    {
      "epoch": 1.5196314378051297,
      "grad_norm": 0.13275407254695892,
      "learning_rate": 4.050793405195386e-05,
      "loss": 0.0573,
      "step": 22100
    },
    {
      "epoch": 1.5265075981571892,
      "grad_norm": 0.12795469164848328,
      "learning_rate": 4.0464954355562436e-05,
      "loss": 0.0551,
      "step": 22200
    },
    {
      "epoch": 1.5333837585092485,
      "grad_norm": 0.16254472732543945,
      "learning_rate": 4.042197465917101e-05,
      "loss": 0.057,
      "step": 22300
    },
    {
      "epoch": 1.5402599188613078,
      "grad_norm": 0.15049295127391815,
      "learning_rate": 4.0378994962779584e-05,
      "loss": 0.0607,
      "step": 22400
    },
    {
      "epoch": 1.5471360792133673,
      "grad_norm": 0.11685799062252045,
      "learning_rate": 4.033601526638816e-05,
      "loss": 0.0559,
      "step": 22500
    },
    {
      "epoch": 1.5540122395654268,
      "grad_norm": 0.18144552409648895,
      "learning_rate": 4.029303556999673e-05,
      "loss": 0.0568,
      "step": 22600
    },
    {
      "epoch": 1.560888399917486,
      "grad_norm": 0.19172793626785278,
      "learning_rate": 4.025005587360531e-05,
      "loss": 0.0589,
      "step": 22700
    },
    {
      "epoch": 1.5677645602695454,
      "grad_norm": 0.09578855335712433,
      "learning_rate": 4.0207076177213886e-05,
      "loss": 0.0587,
      "step": 22800
    },
    {
      "epoch": 1.5746407206216049,
      "grad_norm": 0.11994123458862305,
      "learning_rate": 4.016409648082246e-05,
      "loss": 0.0602,
      "step": 22900
    },
    {
      "epoch": 1.5815168809736644,
      "grad_norm": 0.13643980026245117,
      "learning_rate": 4.0121116784431034e-05,
      "loss": 0.0562,
      "step": 23000
    },
    {
      "epoch": 1.5883930413257237,
      "grad_norm": 0.17321744561195374,
      "learning_rate": 4.0078137088039615e-05,
      "loss": 0.0569,
      "step": 23100
    },
    {
      "epoch": 1.595269201677783,
      "grad_norm": 0.08626609295606613,
      "learning_rate": 4.003515739164819e-05,
      "loss": 0.0564,
      "step": 23200
    },
    {
      "epoch": 1.6021453620298427,
      "grad_norm": 0.1280510276556015,
      "learning_rate": 3.999217769525676e-05,
      "loss": 0.0591,
      "step": 23300
    },
    {
      "epoch": 1.609021522381902,
      "grad_norm": 0.2079019993543625,
      "learning_rate": 3.9949197998865337e-05,
      "loss": 0.057,
      "step": 23400
    },
    {
      "epoch": 1.6158976827339613,
      "grad_norm": 0.15183374285697937,
      "learning_rate": 3.990621830247391e-05,
      "loss": 0.0591,
      "step": 23500
    },
    {
      "epoch": 1.6227738430860208,
      "grad_norm": 0.15215513110160828,
      "learning_rate": 3.9863238606082484e-05,
      "loss": 0.0587,
      "step": 23600
    },
    {
      "epoch": 1.6296500034380803,
      "grad_norm": 0.13316190242767334,
      "learning_rate": 3.9820258909691065e-05,
      "loss": 0.0583,
      "step": 23700
    },
    {
      "epoch": 1.6365261637901396,
      "grad_norm": 0.1271357238292694,
      "learning_rate": 3.977727921329964e-05,
      "loss": 0.0566,
      "step": 23800
    },
    {
      "epoch": 1.643402324142199,
      "grad_norm": 0.15510091185569763,
      "learning_rate": 3.973429951690821e-05,
      "loss": 0.0586,
      "step": 23900
    },
    {
      "epoch": 1.6502784844942584,
      "grad_norm": 0.14563490450382233,
      "learning_rate": 3.969174961748071e-05,
      "loss": 0.0591,
      "step": 24000
    },
    {
      "epoch": 1.657154644846318,
      "grad_norm": 0.10379991680383682,
      "learning_rate": 3.964876992108928e-05,
      "loss": 0.0596,
      "step": 24100
    },
    {
      "epoch": 1.6640308051983772,
      "grad_norm": 0.17975616455078125,
      "learning_rate": 3.960579022469785e-05,
      "loss": 0.0576,
      "step": 24200
    },
    {
      "epoch": 1.6709069655504365,
      "grad_norm": 0.2080218493938446,
      "learning_rate": 3.956281052830643e-05,
      "loss": 0.0554,
      "step": 24300
    },
    {
      "epoch": 1.677783125902496,
      "grad_norm": 0.16829994320869446,
      "learning_rate": 3.9519830831915004e-05,
      "loss": 0.0562,
      "step": 24400
    },
    {
      "epoch": 1.6846592862545555,
      "grad_norm": 0.1114218682050705,
      "learning_rate": 3.947685113552358e-05,
      "loss": 0.0566,
      "step": 24500
    },
    {
      "epoch": 1.6915354466066148,
      "grad_norm": 0.10313490033149719,
      "learning_rate": 3.943387143913216e-05,
      "loss": 0.0584,
      "step": 24600
    },
    {
      "epoch": 1.6984116069586743,
      "grad_norm": 0.16702090203762054,
      "learning_rate": 3.939089174274073e-05,
      "loss": 0.0561,
      "step": 24700
    },
    {
      "epoch": 1.7052877673107338,
      "grad_norm": 0.15299661457538605,
      "learning_rate": 3.934791204634931e-05,
      "loss": 0.0589,
      "step": 24800
    },
    {
      "epoch": 1.7121639276627931,
      "grad_norm": 0.18905194103717804,
      "learning_rate": 3.930493234995788e-05,
      "loss": 0.0553,
      "step": 24900
    },
    {
      "epoch": 1.7190400880148524,
      "grad_norm": 0.0773254781961441,
      "learning_rate": 3.926195265356646e-05,
      "loss": 0.0563,
      "step": 25000
    },
    {
      "epoch": 1.725916248366912,
      "grad_norm": 0.13652817904949188,
      "learning_rate": 3.9218972957175035e-05,
      "loss": 0.0575,
      "step": 25100
    },
    {
      "epoch": 1.7327924087189714,
      "grad_norm": 0.146948903799057,
      "learning_rate": 3.91759932607836e-05,
      "loss": 0.0593,
      "step": 25200
    },
    {
      "epoch": 1.7396685690710307,
      "grad_norm": 0.13371047377586365,
      "learning_rate": 3.913301356439218e-05,
      "loss": 0.0547,
      "step": 25300
    },
    {
      "epoch": 1.74654472942309,
      "grad_norm": 0.09884762763977051,
      "learning_rate": 3.909003386800076e-05,
      "loss": 0.0552,
      "step": 25400
    },
    {
      "epoch": 1.7534208897751495,
      "grad_norm": 0.1373947113752365,
      "learning_rate": 3.904705417160933e-05,
      "loss": 0.0556,
      "step": 25500
    },
    {
      "epoch": 1.760297050127209,
      "grad_norm": 0.1273133009672165,
      "learning_rate": 3.900450427218183e-05,
      "loss": 0.0579,
      "step": 25600
    },
    {
      "epoch": 1.7671732104792683,
      "grad_norm": 0.1977173537015915,
      "learning_rate": 3.89615245757904e-05,
      "loss": 0.0574,
      "step": 25700
    },
    {
      "epoch": 1.7740493708313276,
      "grad_norm": 0.13880670070648193,
      "learning_rate": 3.8918544879398975e-05,
      "loss": 0.0594,
      "step": 25800
    },
    {
      "epoch": 1.7809255311833871,
      "grad_norm": 0.15563853085041046,
      "learning_rate": 3.887556518300755e-05,
      "loss": 0.0593,
      "step": 25900
    },
    {
      "epoch": 1.7878016915354467,
      "grad_norm": 0.07970083504915237,
      "learning_rate": 3.883258548661612e-05,
      "loss": 0.054,
      "step": 26000
    },
    {
      "epoch": 1.794677851887506,
      "grad_norm": 0.11284565925598145,
      "learning_rate": 3.8789605790224696e-05,
      "loss": 0.0564,
      "step": 26100
    },
    {
      "epoch": 1.8015540122395655,
      "grad_norm": 0.14219723641872406,
      "learning_rate": 3.874662609383328e-05,
      "loss": 0.057,
      "step": 26200
    },
    {
      "epoch": 1.808430172591625,
      "grad_norm": 0.1016409620642662,
      "learning_rate": 3.870364639744185e-05,
      "loss": 0.0567,
      "step": 26300
    },
    {
      "epoch": 1.8153063329436843,
      "grad_norm": 0.13775700330734253,
      "learning_rate": 3.8660666701050425e-05,
      "loss": 0.057,
      "step": 26400
    },
    {
      "epoch": 1.8221824932957436,
      "grad_norm": 0.13627877831459045,
      "learning_rate": 3.8617687004659005e-05,
      "loss": 0.0619,
      "step": 26500
    },
    {
      "epoch": 1.829058653647803,
      "grad_norm": 0.11899976432323456,
      "learning_rate": 3.857470730826758e-05,
      "loss": 0.0585,
      "step": 26600
    },
    {
      "epoch": 1.8359348139998626,
      "grad_norm": 0.1772228628396988,
      "learning_rate": 3.853172761187615e-05,
      "loss": 0.0569,
      "step": 26700
    },
    {
      "epoch": 1.8428109743519219,
      "grad_norm": 0.11273213475942612,
      "learning_rate": 3.848874791548473e-05,
      "loss": 0.0554,
      "step": 26800
    },
    {
      "epoch": 1.8496871347039812,
      "grad_norm": 0.1627754122018814,
      "learning_rate": 3.84457682190933e-05,
      "loss": 0.0555,
      "step": 26900
    },
    {
      "epoch": 1.8565632950560407,
      "grad_norm": 0.11296644061803818,
      "learning_rate": 3.8402788522701875e-05,
      "loss": 0.0552,
      "step": 27000
    },
    {
      "epoch": 1.8634394554081002,
      "grad_norm": 0.18229031562805176,
      "learning_rate": 3.835980882631045e-05,
      "loss": 0.0555,
      "step": 27100
    },
    {
      "epoch": 1.8703156157601595,
      "grad_norm": 0.1845160275697708,
      "learning_rate": 3.831682912991903e-05,
      "loss": 0.0578,
      "step": 27200
    },
    {
      "epoch": 1.877191776112219,
      "grad_norm": 0.1083439365029335,
      "learning_rate": 3.8273849433527604e-05,
      "loss": 0.0573,
      "step": 27300
    },
    {
      "epoch": 1.8840679364642785,
      "grad_norm": 0.11911560595035553,
      "learning_rate": 3.823086973713618e-05,
      "loss": 0.0557,
      "step": 27400
    },
    {
      "epoch": 1.8909440968163378,
      "grad_norm": 0.12519623339176178,
      "learning_rate": 3.818789004074476e-05,
      "loss": 0.0549,
      "step": 27500
    },
    {
      "epoch": 1.897820257168397,
      "grad_norm": 0.17966823279857635,
      "learning_rate": 3.814491034435333e-05,
      "loss": 0.0563,
      "step": 27600
    },
    {
      "epoch": 1.9046964175204566,
      "grad_norm": 0.15454719960689545,
      "learning_rate": 3.8101930647961906e-05,
      "loss": 0.0557,
      "step": 27700
    },
    {
      "epoch": 1.911572577872516,
      "grad_norm": 0.12857314944267273,
      "learning_rate": 3.805895095157048e-05,
      "loss": 0.0563,
      "step": 27800
    },
    {
      "epoch": 1.9184487382245754,
      "grad_norm": 0.08220361173152924,
      "learning_rate": 3.8015971255179054e-05,
      "loss": 0.0586,
      "step": 27900
    },
    {
      "epoch": 1.9253248985766347,
      "grad_norm": 0.09285380691289902,
      "learning_rate": 3.797299155878763e-05,
      "loss": 0.0559,
      "step": 28000
    },
    {
      "epoch": 1.9322010589286942,
      "grad_norm": 0.2197868376970291,
      "learning_rate": 3.7930441659360124e-05,
      "loss": 0.0548,
      "step": 28100
    },
    {
      "epoch": 1.9390772192807537,
      "grad_norm": 0.15886877477169037,
      "learning_rate": 3.78874619629687e-05,
      "loss": 0.0614,
      "step": 28200
    },
    {
      "epoch": 1.945953379632813,
      "grad_norm": 0.1369580626487732,
      "learning_rate": 3.784448226657727e-05,
      "loss": 0.0559,
      "step": 28300
    },
    {
      "epoch": 1.9528295399848723,
      "grad_norm": 0.08925870805978775,
      "learning_rate": 3.7801502570185845e-05,
      "loss": 0.0566,
      "step": 28400
    },
    {
      "epoch": 1.9597057003369318,
      "grad_norm": 0.17584949731826782,
      "learning_rate": 3.775852287379442e-05,
      "loss": 0.0542,
      "step": 28500
    },
    {
      "epoch": 1.9665818606889913,
      "grad_norm": 0.12357272207736969,
      "learning_rate": 3.771554317740299e-05,
      "loss": 0.0577,
      "step": 28600
    },
    {
      "epoch": 1.9734580210410506,
      "grad_norm": 0.10888675600290298,
      "learning_rate": 3.7672563481011574e-05,
      "loss": 0.0545,
      "step": 28700
    },
    {
      "epoch": 1.9803341813931101,
      "grad_norm": 0.06996534019708633,
      "learning_rate": 3.762958378462015e-05,
      "loss": 0.0573,
      "step": 28800
    },
    {
      "epoch": 1.9872103417451696,
      "grad_norm": 0.0832018330693245,
      "learning_rate": 3.758660408822872e-05,
      "loss": 0.0567,
      "step": 28900
    },
    {
      "epoch": 1.994086502097229,
      "grad_norm": 0.1103680431842804,
      "learning_rate": 3.7543624391837296e-05,
      "loss": 0.0575,
      "step": 29000
    },
    {
      "epoch": 2.0,
      "eval_accuracy_macro_0.5": 0.9751287698745728,
      "eval_accuracy_micro_0.5": 0.975128710269928,
      "eval_accuracy_weighted_0.5": 0.9721329808235168,
      "eval_f1_macro_0.5": 0.6244237422943115,
      "eval_f1_macro_0.6": 0.578034520149231,
      "eval_f1_macro_0.7": 0.5118567943572998,
      "eval_f1_macro_0.8": 0.2449781596660614,
      "eval_f1_micro_0.5": 0.6488909125328064,
      "eval_f1_micro_0.6": 0.612988293170929,
      "eval_f1_micro_0.7": 0.5521561503410339,
      "eval_f1_micro_0.8": 0.4553397595882416,
      "eval_f1_micro_0.9": 0.26656806468963623,
      "eval_f1_weighted_0.5": 0.6253010034561157,
      "eval_f1_weighted_0.6": 0.578945517539978,
      "eval_f1_weighted_0.7": 0.5109663009643555,
      "eval_f1_weighted_0.8": 0.23218701779842377,
      "eval_loss": 0.05256805568933487,
      "eval_runtime": 114.8866,
      "eval_samples_per_second": 252.745,
      "eval_steps_per_second": 31.596,
      "step": 29086
    },
    {
      "epoch": 2.000962662449288,
      "grad_norm": 0.18272057175636292,
      "learning_rate": 3.7500644695445876e-05,
      "loss": 0.0536,
      "step": 29100
    },
    {
      "epoch": 2.0078388228013475,
      "grad_norm": 0.14020048081874847,
      "learning_rate": 3.745766499905445e-05,
      "loss": 0.056,
      "step": 29200
    },
    {
      "epoch": 2.0147149831534072,
      "grad_norm": 0.13425150513648987,
      "learning_rate": 3.7414685302663024e-05,
      "loss": 0.0571,
      "step": 29300
    },
    {
      "epoch": 2.0215911435054665,
      "grad_norm": 0.17622385919094086,
      "learning_rate": 3.73717056062716e-05,
      "loss": 0.0586,
      "step": 29400
    },
    {
      "epoch": 2.028467303857526,
      "grad_norm": 0.14290101826190948,
      "learning_rate": 3.732872590988017e-05,
      "loss": 0.0564,
      "step": 29500
    },
    {
      "epoch": 2.0353434642095856,
      "grad_norm": 0.1074695885181427,
      "learning_rate": 3.7285746213488746e-05,
      "loss": 0.0536,
      "step": 29600
    },
    {
      "epoch": 2.042219624561645,
      "grad_norm": 0.14205612242221832,
      "learning_rate": 3.7242766517097326e-05,
      "loss": 0.0556,
      "step": 29700
    },
    {
      "epoch": 2.049095784913704,
      "grad_norm": 0.11878173053264618,
      "learning_rate": 3.71997868207059e-05,
      "loss": 0.0552,
      "step": 29800
    },
    {
      "epoch": 2.0559719452657634,
      "grad_norm": 0.12149553000926971,
      "learning_rate": 3.7156807124314474e-05,
      "loss": 0.0555,
      "step": 29900
    },
    {
      "epoch": 2.062848105617823,
      "grad_norm": 0.1366838961839676,
      "learning_rate": 3.7113827427923055e-05,
      "loss": 0.0539,
      "step": 30000
    },
    {
      "epoch": 2.0697242659698825,
      "grad_norm": 0.12577998638153076,
      "learning_rate": 3.707084773153163e-05,
      "loss": 0.0566,
      "step": 30100
    },
    {
      "epoch": 2.0766004263219418,
      "grad_norm": 0.14017610251903534,
      "learning_rate": 3.70278680351402e-05,
      "loss": 0.0564,
      "step": 30200
    },
    {
      "epoch": 2.083476586674001,
      "grad_norm": 0.14884768426418304,
      "learning_rate": 3.698488833874878e-05,
      "loss": 0.0521,
      "step": 30300
    },
    {
      "epoch": 2.0903527470260608,
      "grad_norm": 0.12520772218704224,
      "learning_rate": 3.694190864235735e-05,
      "loss": 0.0563,
      "step": 30400
    },
    {
      "epoch": 2.09722890737812,
      "grad_norm": 0.11217646300792694,
      "learning_rate": 3.6898928945965925e-05,
      "loss": 0.0576,
      "step": 30500
    },
    {
      "epoch": 2.1041050677301794,
      "grad_norm": 0.1637163758277893,
      "learning_rate": 3.68559492495745e-05,
      "loss": 0.0564,
      "step": 30600
    },
    {
      "epoch": 2.110981228082239,
      "grad_norm": 0.19067631661891937,
      "learning_rate": 3.681296955318308e-05,
      "loss": 0.0592,
      "step": 30700
    },
    {
      "epoch": 2.1178573884342984,
      "grad_norm": 0.09139484912157059,
      "learning_rate": 3.676998985679165e-05,
      "loss": 0.0557,
      "step": 30800
    },
    {
      "epoch": 2.1247335487863577,
      "grad_norm": 0.16749590635299683,
      "learning_rate": 3.672701016040023e-05,
      "loss": 0.0568,
      "step": 30900
    },
    {
      "epoch": 2.131609709138417,
      "grad_norm": 0.1655353456735611,
      "learning_rate": 3.668403046400881e-05,
      "loss": 0.0546,
      "step": 31000
    },
    {
      "epoch": 2.1384858694904767,
      "grad_norm": 0.12470682710409164,
      "learning_rate": 3.664105076761738e-05,
      "loss": 0.0569,
      "step": 31100
    },
    {
      "epoch": 2.145362029842536,
      "grad_norm": 0.18844981491565704,
      "learning_rate": 3.6598500868189864e-05,
      "loss": 0.055,
      "step": 31200
    },
    {
      "epoch": 2.1522381901945953,
      "grad_norm": 0.11418375372886658,
      "learning_rate": 3.6555521171798445e-05,
      "loss": 0.0549,
      "step": 31300
    },
    {
      "epoch": 2.1591143505466546,
      "grad_norm": 0.08556529134511948,
      "learning_rate": 3.651254147540702e-05,
      "loss": 0.0553,
      "step": 31400
    },
    {
      "epoch": 2.1659905108987143,
      "grad_norm": 0.21334199607372284,
      "learning_rate": 3.646956177901559e-05,
      "loss": 0.0541,
      "step": 31500
    },
    {
      "epoch": 2.1728666712507736,
      "grad_norm": 0.12099583446979523,
      "learning_rate": 3.642658208262417e-05,
      "loss": 0.056,
      "step": 31600
    },
    {
      "epoch": 2.179742831602833,
      "grad_norm": 0.11223580688238144,
      "learning_rate": 3.638360238623275e-05,
      "loss": 0.0549,
      "step": 31700
    },
    {
      "epoch": 2.1866189919548926,
      "grad_norm": 0.1441737562417984,
      "learning_rate": 3.634062268984132e-05,
      "loss": 0.0498,
      "step": 31800
    },
    {
      "epoch": 2.193495152306952,
      "grad_norm": 0.13854187726974487,
      "learning_rate": 3.62976429934499e-05,
      "loss": 0.0538,
      "step": 31900
    },
    {
      "epoch": 2.200371312659011,
      "grad_norm": 0.0944124087691307,
      "learning_rate": 3.6254663297058475e-05,
      "loss": 0.0546,
      "step": 32000
    },
    {
      "epoch": 2.2072474730110705,
      "grad_norm": 0.09111179411411285,
      "learning_rate": 3.621168360066704e-05,
      "loss": 0.0542,
      "step": 32100
    },
    {
      "epoch": 2.2141236333631302,
      "grad_norm": 0.15251509845256805,
      "learning_rate": 3.6168703904275616e-05,
      "loss": 0.0575,
      "step": 32200
    },
    {
      "epoch": 2.2209997937151895,
      "grad_norm": 0.10886473208665848,
      "learning_rate": 3.61257242078842e-05,
      "loss": 0.0524,
      "step": 32300
    },
    {
      "epoch": 2.227875954067249,
      "grad_norm": 0.1382024735212326,
      "learning_rate": 3.608274451149277e-05,
      "loss": 0.0517,
      "step": 32400
    },
    {
      "epoch": 2.234752114419308,
      "grad_norm": 0.18131951987743378,
      "learning_rate": 3.6039764815101345e-05,
      "loss": 0.0555,
      "step": 32500
    },
    {
      "epoch": 2.241628274771368,
      "grad_norm": 0.27515503764152527,
      "learning_rate": 3.5996785118709926e-05,
      "loss": 0.0536,
      "step": 32600
    },
    {
      "epoch": 2.248504435123427,
      "grad_norm": 0.1948164701461792,
      "learning_rate": 3.59538054223185e-05,
      "loss": 0.0547,
      "step": 32700
    },
    {
      "epoch": 2.2553805954754864,
      "grad_norm": 0.12170293927192688,
      "learning_rate": 3.5910825725927074e-05,
      "loss": 0.0543,
      "step": 32800
    },
    {
      "epoch": 2.2622567558275457,
      "grad_norm": 0.16671012341976166,
      "learning_rate": 3.5867846029535654e-05,
      "loss": 0.0538,
      "step": 32900
    },
    {
      "epoch": 2.2691329161796054,
      "grad_norm": 0.18203571438789368,
      "learning_rate": 3.582486633314422e-05,
      "loss": 0.0545,
      "step": 33000
    },
    {
      "epoch": 2.2760090765316647,
      "grad_norm": 0.149015873670578,
      "learning_rate": 3.5781886636752795e-05,
      "loss": 0.0532,
      "step": 33100
    },
    {
      "epoch": 2.282885236883724,
      "grad_norm": 0.16202621161937714,
      "learning_rate": 3.5738906940361376e-05,
      "loss": 0.0574,
      "step": 33200
    },
    {
      "epoch": 2.2897613972357833,
      "grad_norm": 0.07709567993879318,
      "learning_rate": 3.5696357040933865e-05,
      "loss": 0.0549,
      "step": 33300
    },
    {
      "epoch": 2.296637557587843,
      "grad_norm": 0.15874305367469788,
      "learning_rate": 3.565337734454244e-05,
      "loss": 0.0551,
      "step": 33400
    },
    {
      "epoch": 2.3035137179399023,
      "grad_norm": 0.1586989313364029,
      "learning_rate": 3.561039764815102e-05,
      "loss": 0.0561,
      "step": 33500
    },
    {
      "epoch": 2.3103898782919616,
      "grad_norm": 0.16658444702625275,
      "learning_rate": 3.5567417951759593e-05,
      "loss": 0.0552,
      "step": 33600
    },
    {
      "epoch": 2.3172660386440214,
      "grad_norm": 0.18282559514045715,
      "learning_rate": 3.552443825536817e-05,
      "loss": 0.0551,
      "step": 33700
    },
    {
      "epoch": 2.3241421989960807,
      "grad_norm": 0.10229405015707016,
      "learning_rate": 3.548145855897674e-05,
      "loss": 0.0509,
      "step": 33800
    },
    {
      "epoch": 2.33101835934814,
      "grad_norm": 0.130337193608284,
      "learning_rate": 3.5438478862585315e-05,
      "loss": 0.0546,
      "step": 33900
    },
    {
      "epoch": 2.3378945197001992,
      "grad_norm": 0.1434798389673233,
      "learning_rate": 3.539549916619389e-05,
      "loss": 0.0543,
      "step": 34000
    },
    {
      "epoch": 2.344770680052259,
      "grad_norm": 0.16563008725643158,
      "learning_rate": 3.535251946980247e-05,
      "loss": 0.0557,
      "step": 34100
    },
    {
      "epoch": 2.3516468404043183,
      "grad_norm": 0.11126619577407837,
      "learning_rate": 3.5309539773411044e-05,
      "loss": 0.0561,
      "step": 34200
    },
    {
      "epoch": 2.3585230007563776,
      "grad_norm": 0.18728797137737274,
      "learning_rate": 3.526656007701962e-05,
      "loss": 0.0532,
      "step": 34300
    },
    {
      "epoch": 2.365399161108437,
      "grad_norm": 0.22271868586540222,
      "learning_rate": 3.522358038062819e-05,
      "loss": 0.0521,
      "step": 34400
    },
    {
      "epoch": 2.3722753214604966,
      "grad_norm": 0.11549250781536102,
      "learning_rate": 3.518060068423677e-05,
      "loss": 0.0569,
      "step": 34500
    },
    {
      "epoch": 2.379151481812556,
      "grad_norm": 0.25066903233528137,
      "learning_rate": 3.5137620987845346e-05,
      "loss": 0.0548,
      "step": 34600
    },
    {
      "epoch": 2.386027642164615,
      "grad_norm": 0.14518743753433228,
      "learning_rate": 3.509464129145392e-05,
      "loss": 0.0554,
      "step": 34700
    },
    {
      "epoch": 2.392903802516675,
      "grad_norm": 0.20890913903713226,
      "learning_rate": 3.5051661595062494e-05,
      "loss": 0.053,
      "step": 34800
    },
    {
      "epoch": 2.399779962868734,
      "grad_norm": 0.1511247158050537,
      "learning_rate": 3.500868189867107e-05,
      "loss": 0.0522,
      "step": 34900
    },
    {
      "epoch": 2.4066561232207935,
      "grad_norm": 0.15536774694919586,
      "learning_rate": 3.496570220227964e-05,
      "loss": 0.0562,
      "step": 35000
    },
    {
      "epoch": 2.4135322835728528,
      "grad_norm": 0.15119478106498718,
      "learning_rate": 3.492272250588822e-05,
      "loss": 0.0519,
      "step": 35100
    },
    {
      "epoch": 2.4204084439249125,
      "grad_norm": 0.17978234589099884,
      "learning_rate": 3.4879742809496796e-05,
      "loss": 0.0537,
      "step": 35200
    },
    {
      "epoch": 2.427284604276972,
      "grad_norm": 0.14938263595104218,
      "learning_rate": 3.483676311310537e-05,
      "loss": 0.0554,
      "step": 35300
    },
    {
      "epoch": 2.434160764629031,
      "grad_norm": 0.09080744534730911,
      "learning_rate": 3.479378341671395e-05,
      "loss": 0.0517,
      "step": 35400
    },
    {
      "epoch": 2.4410369249810904,
      "grad_norm": 0.13104259967803955,
      "learning_rate": 3.4750803720322525e-05,
      "loss": 0.0564,
      "step": 35500
    },
    {
      "epoch": 2.44791308533315,
      "grad_norm": 0.11873885989189148,
      "learning_rate": 3.470825382089501e-05,
      "loss": 0.0572,
      "step": 35600
    },
    {
      "epoch": 2.4547892456852094,
      "grad_norm": 0.14195974171161652,
      "learning_rate": 3.466527412450359e-05,
      "loss": 0.0536,
      "step": 35700
    },
    {
      "epoch": 2.4616654060372687,
      "grad_norm": 0.17110510170459747,
      "learning_rate": 3.462229442811216e-05,
      "loss": 0.0536,
      "step": 35800
    },
    {
      "epoch": 2.4685415663893284,
      "grad_norm": 0.14155873656272888,
      "learning_rate": 3.4579314731720736e-05,
      "loss": 0.0509,
      "step": 35900
    },
    {
      "epoch": 2.4754177267413877,
      "grad_norm": 0.11850569397211075,
      "learning_rate": 3.4536335035329316e-05,
      "loss": 0.0516,
      "step": 36000
    },
    {
      "epoch": 2.482293887093447,
      "grad_norm": 0.11727552115917206,
      "learning_rate": 3.449335533893789e-05,
      "loss": 0.0548,
      "step": 36100
    },
    {
      "epoch": 2.4891700474455063,
      "grad_norm": 0.16768771409988403,
      "learning_rate": 3.4450375642546464e-05,
      "loss": 0.0574,
      "step": 36200
    },
    {
      "epoch": 2.496046207797566,
      "grad_norm": 0.1504315286874771,
      "learning_rate": 3.440739594615504e-05,
      "loss": 0.0535,
      "step": 36300
    },
    {
      "epoch": 2.5029223681496253,
      "grad_norm": 0.07347436249256134,
      "learning_rate": 3.436441624976361e-05,
      "loss": 0.0535,
      "step": 36400
    },
    {
      "epoch": 2.5097985285016846,
      "grad_norm": 0.12371592223644257,
      "learning_rate": 3.4321436553372186e-05,
      "loss": 0.0557,
      "step": 36500
    },
    {
      "epoch": 2.516674688853744,
      "grad_norm": 0.22198183834552765,
      "learning_rate": 3.427845685698076e-05,
      "loss": 0.0551,
      "step": 36600
    },
    {
      "epoch": 2.5235508492058036,
      "grad_norm": 0.1954849809408188,
      "learning_rate": 3.423547716058934e-05,
      "loss": 0.0553,
      "step": 36700
    },
    {
      "epoch": 2.530427009557863,
      "grad_norm": 0.1639074683189392,
      "learning_rate": 3.4192497464197914e-05,
      "loss": 0.0536,
      "step": 36800
    },
    {
      "epoch": 2.537303169909922,
      "grad_norm": 0.19947612285614014,
      "learning_rate": 3.414951776780649e-05,
      "loss": 0.0557,
      "step": 36900
    },
    {
      "epoch": 2.544179330261982,
      "grad_norm": 0.14273715019226074,
      "learning_rate": 3.410653807141507e-05,
      "loss": 0.0524,
      "step": 37000
    },
    {
      "epoch": 2.5510554906140412,
      "grad_norm": 0.11349157243967056,
      "learning_rate": 3.406355837502364e-05,
      "loss": 0.0532,
      "step": 37100
    },
    {
      "epoch": 2.5579316509661005,
      "grad_norm": 0.0860394835472107,
      "learning_rate": 3.402057867863222e-05,
      "loss": 0.0525,
      "step": 37200
    },
    {
      "epoch": 2.56480781131816,
      "grad_norm": 0.1662042737007141,
      "learning_rate": 3.397759898224079e-05,
      "loss": 0.0542,
      "step": 37300
    },
    {
      "epoch": 2.571683971670219,
      "grad_norm": 0.0985260158777237,
      "learning_rate": 3.3934619285849365e-05,
      "loss": 0.0517,
      "step": 37400
    },
    {
      "epoch": 2.578560132022279,
      "grad_norm": 0.1361766755580902,
      "learning_rate": 3.389163958945794e-05,
      "loss": 0.0579,
      "step": 37500
    },
    {
      "epoch": 2.585436292374338,
      "grad_norm": 0.17315533757209778,
      "learning_rate": 3.384865989306651e-05,
      "loss": 0.052,
      "step": 37600
    },
    {
      "epoch": 2.5923124527263974,
      "grad_norm": 0.1303468942642212,
      "learning_rate": 3.380568019667509e-05,
      "loss": 0.0545,
      "step": 37700
    },
    {
      "epoch": 2.599188613078457,
      "grad_norm": 0.10082301497459412,
      "learning_rate": 3.376270050028367e-05,
      "loss": 0.0517,
      "step": 37800
    },
    {
      "epoch": 2.6060647734305165,
      "grad_norm": 0.19977982342243195,
      "learning_rate": 3.371972080389224e-05,
      "loss": 0.0532,
      "step": 37900
    },
    {
      "epoch": 2.6129409337825757,
      "grad_norm": 0.12541563808918,
      "learning_rate": 3.367674110750082e-05,
      "loss": 0.0546,
      "step": 38000
    },
    {
      "epoch": 2.6198170941346355,
      "grad_norm": 0.1346740424633026,
      "learning_rate": 3.3633761411109396e-05,
      "loss": 0.0532,
      "step": 38100
    },
    {
      "epoch": 2.6266932544866948,
      "grad_norm": 0.11700006574392319,
      "learning_rate": 3.359078171471797e-05,
      "loss": 0.0535,
      "step": 38200
    },
    {
      "epoch": 2.633569414838754,
      "grad_norm": 0.13517378270626068,
      "learning_rate": 3.3547802018326543e-05,
      "loss": 0.0544,
      "step": 38300
    },
    {
      "epoch": 2.6404455751908134,
      "grad_norm": 0.10030564665794373,
      "learning_rate": 3.350482232193512e-05,
      "loss": 0.0505,
      "step": 38400
    },
    {
      "epoch": 2.6473217355428726,
      "grad_norm": 0.15285912156105042,
      "learning_rate": 3.346184262554369e-05,
      "loss": 0.0535,
      "step": 38500
    },
    {
      "epoch": 2.6541978958949324,
      "grad_norm": 0.14174781739711761,
      "learning_rate": 3.341886292915227e-05,
      "loss": 0.0507,
      "step": 38600
    },
    {
      "epoch": 2.6610740562469917,
      "grad_norm": 0.08594100177288055,
      "learning_rate": 3.3375883232760846e-05,
      "loss": 0.054,
      "step": 38700
    },
    {
      "epoch": 2.667950216599051,
      "grad_norm": 0.1669646054506302,
      "learning_rate": 3.333290353636942e-05,
      "loss": 0.0556,
      "step": 38800
    },
    {
      "epoch": 2.6748263769511107,
      "grad_norm": 0.16919976472854614,
      "learning_rate": 3.3289923839977994e-05,
      "loss": 0.0505,
      "step": 38900
    },
    {
      "epoch": 2.68170253730317,
      "grad_norm": 0.12167365103960037,
      "learning_rate": 3.3246944143586574e-05,
      "loss": 0.0522,
      "step": 39000
    },
    {
      "epoch": 2.6885786976552293,
      "grad_norm": 0.193373903632164,
      "learning_rate": 3.320396444719515e-05,
      "loss": 0.0534,
      "step": 39100
    },
    {
      "epoch": 2.6954548580072886,
      "grad_norm": 0.1387282907962799,
      "learning_rate": 3.316098475080372e-05,
      "loss": 0.0524,
      "step": 39200
    },
    {
      "epoch": 2.7023310183593483,
      "grad_norm": 0.1197381243109703,
      "learning_rate": 3.3118005054412296e-05,
      "loss": 0.0532,
      "step": 39300
    },
    {
      "epoch": 2.7092071787114076,
      "grad_norm": 0.1546970009803772,
      "learning_rate": 3.307502535802087e-05,
      "loss": 0.0537,
      "step": 39400
    },
    {
      "epoch": 2.716083339063467,
      "grad_norm": 0.13142727315425873,
      "learning_rate": 3.3032045661629444e-05,
      "loss": 0.0511,
      "step": 39500
    },
    {
      "epoch": 2.722959499415526,
      "grad_norm": 0.15926674008369446,
      "learning_rate": 3.298949576220194e-05,
      "loss": 0.0526,
      "step": 39600
    },
    {
      "epoch": 2.729835659767586,
      "grad_norm": 0.08956260979175568,
      "learning_rate": 3.2946516065810514e-05,
      "loss": 0.0527,
      "step": 39700
    },
    {
      "epoch": 2.736711820119645,
      "grad_norm": 0.16497619450092316,
      "learning_rate": 3.290353636941909e-05,
      "loss": 0.0557,
      "step": 39800
    },
    {
      "epoch": 2.7435879804717045,
      "grad_norm": 0.1011849120259285,
      "learning_rate": 3.286055667302766e-05,
      "loss": 0.0524,
      "step": 39900
    },
    {
      "epoch": 2.7504641408237642,
      "grad_norm": 0.10860496014356613,
      "learning_rate": 3.2817576976636235e-05,
      "loss": 0.0542,
      "step": 40000
    },
    {
      "epoch": 2.7573403011758235,
      "grad_norm": 0.11399856954813004,
      "learning_rate": 3.277459728024481e-05,
      "loss": 0.0533,
      "step": 40100
    },
    {
      "epoch": 2.764216461527883,
      "grad_norm": 0.08760517090559006,
      "learning_rate": 3.273161758385339e-05,
      "loss": 0.0492,
      "step": 40200
    },
    {
      "epoch": 2.771092621879942,
      "grad_norm": 0.18384063243865967,
      "learning_rate": 3.2688637887461964e-05,
      "loss": 0.0558,
      "step": 40300
    },
    {
      "epoch": 2.7779687822320014,
      "grad_norm": 0.10616087168455124,
      "learning_rate": 3.264565819107054e-05,
      "loss": 0.0532,
      "step": 40400
    },
    {
      "epoch": 2.784844942584061,
      "grad_norm": 0.13804610073566437,
      "learning_rate": 3.260267849467912e-05,
      "loss": 0.0556,
      "step": 40500
    },
    {
      "epoch": 2.7917211029361204,
      "grad_norm": 0.133079394698143,
      "learning_rate": 3.255969879828769e-05,
      "loss": 0.0557,
      "step": 40600
    },
    {
      "epoch": 2.7985972632881797,
      "grad_norm": 0.10859520733356476,
      "learning_rate": 3.2516719101896266e-05,
      "loss": 0.0546,
      "step": 40700
    },
    {
      "epoch": 2.8054734236402394,
      "grad_norm": 0.1592242568731308,
      "learning_rate": 3.247373940550485e-05,
      "loss": 0.0509,
      "step": 40800
    },
    {
      "epoch": 2.8123495839922987,
      "grad_norm": 0.1041233018040657,
      "learning_rate": 3.2430759709113414e-05,
      "loss": 0.0521,
      "step": 40900
    },
    {
      "epoch": 2.819225744344358,
      "grad_norm": 0.16513675451278687,
      "learning_rate": 3.238778001272199e-05,
      "loss": 0.0511,
      "step": 41000
    },
    {
      "epoch": 2.8261019046964178,
      "grad_norm": 0.1540519893169403,
      "learning_rate": 3.234480031633056e-05,
      "loss": 0.0532,
      "step": 41100
    },
    {
      "epoch": 2.832978065048477,
      "grad_norm": 0.11956416815519333,
      "learning_rate": 3.230225041690306e-05,
      "loss": 0.0546,
      "step": 41200
    },
    {
      "epoch": 2.8398542254005363,
      "grad_norm": 0.16847169399261475,
      "learning_rate": 3.225927072051163e-05,
      "loss": 0.0506,
      "step": 41300
    },
    {
      "epoch": 2.8467303857525956,
      "grad_norm": 0.11810825020074844,
      "learning_rate": 3.221629102412021e-05,
      "loss": 0.0537,
      "step": 41400
    },
    {
      "epoch": 2.853606546104655,
      "grad_norm": 0.11081346869468689,
      "learning_rate": 3.2173311327728786e-05,
      "loss": 0.0482,
      "step": 41500
    },
    {
      "epoch": 2.8604827064567147,
      "grad_norm": 0.10795975476503372,
      "learning_rate": 3.213033163133736e-05,
      "loss": 0.054,
      "step": 41600
    },
    {
      "epoch": 2.867358866808774,
      "grad_norm": 0.10239513963460922,
      "learning_rate": 3.208735193494593e-05,
      "loss": 0.0515,
      "step": 41700
    },
    {
      "epoch": 2.8742350271608332,
      "grad_norm": 0.16130535304546356,
      "learning_rate": 3.204437223855451e-05,
      "loss": 0.051,
      "step": 41800
    },
    {
      "epoch": 2.881111187512893,
      "grad_norm": 0.2052260786294937,
      "learning_rate": 3.200139254216308e-05,
      "loss": 0.0525,
      "step": 41900
    },
    {
      "epoch": 2.8879873478649523,
      "grad_norm": 0.1652754843235016,
      "learning_rate": 3.1958412845771656e-05,
      "loss": 0.0547,
      "step": 42000
    },
    {
      "epoch": 2.8948635082170115,
      "grad_norm": 0.19547484815120697,
      "learning_rate": 3.1915433149380237e-05,
      "loss": 0.0531,
      "step": 42100
    },
    {
      "epoch": 2.9017396685690713,
      "grad_norm": 0.12178108841180801,
      "learning_rate": 3.187245345298881e-05,
      "loss": 0.0515,
      "step": 42200
    },
    {
      "epoch": 2.9086158289211306,
      "grad_norm": 0.16218094527721405,
      "learning_rate": 3.1829473756597384e-05,
      "loss": 0.0498,
      "step": 42300
    },
    {
      "epoch": 2.91549198927319,
      "grad_norm": 0.1315533071756363,
      "learning_rate": 3.1786494060205965e-05,
      "loss": 0.051,
      "step": 42400
    },
    {
      "epoch": 2.922368149625249,
      "grad_norm": 0.09448672086000443,
      "learning_rate": 3.174351436381454e-05,
      "loss": 0.0521,
      "step": 42500
    },
    {
      "epoch": 2.9292443099773084,
      "grad_norm": 0.14654473960399628,
      "learning_rate": 3.170053466742311e-05,
      "loss": 0.0537,
      "step": 42600
    },
    {
      "epoch": 2.936120470329368,
      "grad_norm": 0.13981123268604279,
      "learning_rate": 3.165755497103169e-05,
      "loss": 0.0531,
      "step": 42700
    },
    {
      "epoch": 2.9429966306814275,
      "grad_norm": 0.07587505877017975,
      "learning_rate": 3.161457527464026e-05,
      "loss": 0.051,
      "step": 42800
    },
    {
      "epoch": 2.9498727910334868,
      "grad_norm": 0.18240565061569214,
      "learning_rate": 3.1571595578248835e-05,
      "loss": 0.0526,
      "step": 42900
    },
    {
      "epoch": 2.9567489513855465,
      "grad_norm": 0.12996810674667358,
      "learning_rate": 3.152861588185741e-05,
      "loss": 0.0544,
      "step": 43000
    },
    {
      "epoch": 2.963625111737606,
      "grad_norm": 0.10307443886995316,
      "learning_rate": 3.1486065982429904e-05,
      "loss": 0.0509,
      "step": 43100
    },
    {
      "epoch": 2.970501272089665,
      "grad_norm": 0.11776487529277802,
      "learning_rate": 3.144308628603848e-05,
      "loss": 0.054,
      "step": 43200
    },
    {
      "epoch": 2.977377432441725,
      "grad_norm": 0.13626164197921753,
      "learning_rate": 3.140010658964705e-05,
      "loss": 0.0509,
      "step": 43300
    },
    {
      "epoch": 2.984253592793784,
      "grad_norm": 0.10997972637414932,
      "learning_rate": 3.1357126893255626e-05,
      "loss": 0.0521,
      "step": 43400
    },
    {
      "epoch": 2.9911297531458434,
      "grad_norm": 0.1774846762418747,
      "learning_rate": 3.13141471968642e-05,
      "loss": 0.0522,
      "step": 43500
    },
    {
      "epoch": 2.9980059134979027,
      "grad_norm": 0.157144695520401,
      "learning_rate": 3.1271167500472774e-05,
      "loss": 0.0527,
      "step": 43600
    },
    {
      "epoch": 3.0,
      "eval_accuracy_macro_0.5": 0.9764664173126221,
      "eval_accuracy_micro_0.5": 0.9764664769172668,
      "eval_accuracy_weighted_0.5": 0.9735832214355469,
      "eval_f1_macro_0.5": 0.6622599363327026,
      "eval_f1_macro_0.6": 0.6231523752212524,
      "eval_f1_macro_0.7": 0.5658740997314453,
      "eval_f1_macro_0.8": 0.33074307441711426,
      "eval_f1_micro_0.5": 0.6753663420677185,
      "eval_f1_micro_0.6": 0.6469407081604004,
      "eval_f1_micro_0.7": 0.5990837812423706,
      "eval_f1_micro_0.8": 0.516789436340332,
      "eval_f1_micro_0.9": 0.35797324776649475,
      "eval_f1_weighted_0.5": 0.6594781875610352,
      "eval_f1_weighted_0.6": 0.6210123300552368,
      "eval_f1_weighted_0.7": 0.5625243186950684,
      "eval_f1_weighted_0.8": 0.31800907850265503,
      "eval_loss": 0.049183428287506104,
      "eval_runtime": 115.5554,
      "eval_samples_per_second": 251.282,
      "eval_steps_per_second": 31.413,
      "step": 43629
    },
    {
      "epoch": 3.004882073849962,
      "grad_norm": 0.12358611822128296,
      "learning_rate": 3.1228187804081355e-05,
      "loss": 0.0546,
      "step": 43700
    },
    {
      "epoch": 3.0117582342020217,
      "grad_norm": 0.15629374980926514,
      "learning_rate": 3.118520810768993e-05,
      "loss": 0.0527,
      "step": 43800
    },
    {
      "epoch": 3.018634394554081,
      "grad_norm": 0.22971582412719727,
      "learning_rate": 3.11422284112985e-05,
      "loss": 0.0509,
      "step": 43900
    },
    {
      "epoch": 3.0255105549061403,
      "grad_norm": 0.09549563378095627,
      "learning_rate": 3.109924871490708e-05,
      "loss": 0.0528,
      "step": 44000
    },
    {
      "epoch": 3.0323867152582,
      "grad_norm": 0.19261445105075836,
      "learning_rate": 3.105626901851566e-05,
      "loss": 0.0512,
      "step": 44100
    },
    {
      "epoch": 3.0392628756102593,
      "grad_norm": 0.1476210653781891,
      "learning_rate": 3.101328932212423e-05,
      "loss": 0.0534,
      "step": 44200
    },
    {
      "epoch": 3.0461390359623186,
      "grad_norm": 0.12127023935317993,
      "learning_rate": 3.0970309625732805e-05,
      "loss": 0.0526,
      "step": 44300
    },
    {
      "epoch": 3.053015196314378,
      "grad_norm": 0.1606743335723877,
      "learning_rate": 3.092732992934138e-05,
      "loss": 0.052,
      "step": 44400
    },
    {
      "epoch": 3.0598913566664376,
      "grad_norm": 0.12111600488424301,
      "learning_rate": 3.088435023294995e-05,
      "loss": 0.0524,
      "step": 44500
    },
    {
      "epoch": 3.066767517018497,
      "grad_norm": 0.13735553622245789,
      "learning_rate": 3.0841370536558533e-05,
      "loss": 0.0511,
      "step": 44600
    },
    {
      "epoch": 3.073643677370556,
      "grad_norm": 0.2464722841978073,
      "learning_rate": 3.079839084016711e-05,
      "loss": 0.053,
      "step": 44700
    },
    {
      "epoch": 3.0805198377226155,
      "grad_norm": 0.15651150047779083,
      "learning_rate": 3.075541114377568e-05,
      "loss": 0.0529,
      "step": 44800
    },
    {
      "epoch": 3.0873959980746752,
      "grad_norm": 0.11040756851434708,
      "learning_rate": 3.0712431447384255e-05,
      "loss": 0.0515,
      "step": 44900
    },
    {
      "epoch": 3.0942721584267345,
      "grad_norm": 0.16030320525169373,
      "learning_rate": 3.0669451750992836e-05,
      "loss": 0.0539,
      "step": 45000
    },
    {
      "epoch": 3.101148318778794,
      "grad_norm": 0.1464458554983139,
      "learning_rate": 3.062647205460141e-05,
      "loss": 0.05,
      "step": 45100
    },
    {
      "epoch": 3.1080244791308536,
      "grad_norm": 0.14926713705062866,
      "learning_rate": 3.0583492358209984e-05,
      "loss": 0.0523,
      "step": 45200
    },
    {
      "epoch": 3.114900639482913,
      "grad_norm": 0.16974516212940216,
      "learning_rate": 3.054051266181856e-05,
      "loss": 0.0531,
      "step": 45300
    },
    {
      "epoch": 3.121776799834972,
      "grad_norm": 0.20451778173446655,
      "learning_rate": 3.0497532965427135e-05,
      "loss": 0.0536,
      "step": 45400
    },
    {
      "epoch": 3.1286529601870314,
      "grad_norm": 0.12803541123867035,
      "learning_rate": 3.045455326903571e-05,
      "loss": 0.0529,
      "step": 45500
    },
    {
      "epoch": 3.135529120539091,
      "grad_norm": 0.1334446221590042,
      "learning_rate": 3.0411573572644286e-05,
      "loss": 0.0523,
      "step": 45600
    },
    {
      "epoch": 3.1424052808911505,
      "grad_norm": 0.11771972477436066,
      "learning_rate": 3.036859387625286e-05,
      "loss": 0.0503,
      "step": 45700
    },
    {
      "epoch": 3.1492814412432097,
      "grad_norm": 0.17215780913829803,
      "learning_rate": 3.0325614179861434e-05,
      "loss": 0.0519,
      "step": 45800
    },
    {
      "epoch": 3.156157601595269,
      "grad_norm": 0.12048709392547607,
      "learning_rate": 3.028263448347001e-05,
      "loss": 0.0533,
      "step": 45900
    },
    {
      "epoch": 3.1630337619473288,
      "grad_norm": 0.11141030490398407,
      "learning_rate": 3.0239654787078585e-05,
      "loss": 0.053,
      "step": 46000
    },
    {
      "epoch": 3.169909922299388,
      "grad_norm": 0.12046082317829132,
      "learning_rate": 3.019667509068716e-05,
      "loss": 0.0534,
      "step": 46100
    },
    {
      "epoch": 3.1767860826514474,
      "grad_norm": 0.0996246412396431,
      "learning_rate": 3.0153695394295733e-05,
      "loss": 0.0504,
      "step": 46200
    },
    {
      "epoch": 3.1836622430035066,
      "grad_norm": 0.10135351121425629,
      "learning_rate": 3.0110715697904314e-05,
      "loss": 0.0509,
      "step": 46300
    },
    {
      "epoch": 3.1905384033555664,
      "grad_norm": 0.18753504753112793,
      "learning_rate": 3.0067736001512888e-05,
      "loss": 0.0482,
      "step": 46400
    },
    {
      "epoch": 3.1974145637076257,
      "grad_norm": 0.1309097558259964,
      "learning_rate": 3.002475630512146e-05,
      "loss": 0.0527,
      "step": 46500
    },
    {
      "epoch": 3.204290724059685,
      "grad_norm": 0.15808777511119843,
      "learning_rate": 2.998177660873004e-05,
      "loss": 0.0535,
      "step": 46600
    },
    {
      "epoch": 3.2111668844117442,
      "grad_norm": 0.11012369394302368,
      "learning_rate": 2.9938796912338613e-05,
      "loss": 0.0524,
      "step": 46700
    },
    {
      "epoch": 3.218043044763804,
      "grad_norm": 0.1694938689470291,
      "learning_rate": 2.9895817215947187e-05,
      "loss": 0.0514,
      "step": 46800
    },
    {
      "epoch": 3.2249192051158633,
      "grad_norm": 0.15940897166728973,
      "learning_rate": 2.9852837519555764e-05,
      "loss": 0.0536,
      "step": 46900
    },
    {
      "epoch": 3.2317953654679226,
      "grad_norm": 0.16171924769878387,
      "learning_rate": 2.9809857823164338e-05,
      "loss": 0.0531,
      "step": 47000
    },
    {
      "epoch": 3.2386715258199823,
      "grad_norm": 0.11782436072826385,
      "learning_rate": 2.976687812677291e-05,
      "loss": 0.052,
      "step": 47100
    },
    {
      "epoch": 3.2455476861720416,
      "grad_norm": 0.12939974665641785,
      "learning_rate": 2.9723898430381492e-05,
      "loss": 0.0508,
      "step": 47200
    },
    {
      "epoch": 3.252423846524101,
      "grad_norm": 0.18388555943965912,
      "learning_rate": 2.9680918733990066e-05,
      "loss": 0.0519,
      "step": 47300
    },
    {
      "epoch": 3.25930000687616,
      "grad_norm": 0.16076794266700745,
      "learning_rate": 2.963793903759864e-05,
      "loss": 0.0499,
      "step": 47400
    },
    {
      "epoch": 3.26617616722822,
      "grad_norm": 0.11883418262004852,
      "learning_rate": 2.959495934120721e-05,
      "loss": 0.049,
      "step": 47500
    },
    {
      "epoch": 3.273052327580279,
      "grad_norm": 0.07886073738336563,
      "learning_rate": 2.955197964481579e-05,
      "loss": 0.0519,
      "step": 47600
    },
    {
      "epoch": 3.2799284879323385,
      "grad_norm": 0.1398496925830841,
      "learning_rate": 2.9508999948424365e-05,
      "loss": 0.05,
      "step": 47700
    },
    {
      "epoch": 3.286804648284398,
      "grad_norm": 0.14037568867206573,
      "learning_rate": 2.946602025203294e-05,
      "loss": 0.0524,
      "step": 47800
    },
    {
      "epoch": 3.2936808086364575,
      "grad_norm": 0.21956601738929749,
      "learning_rate": 2.942347035260543e-05,
      "loss": 0.0504,
      "step": 47900
    },
    {
      "epoch": 3.300556968988517,
      "grad_norm": 0.10098467022180557,
      "learning_rate": 2.9380490656214006e-05,
      "loss": 0.0548,
      "step": 48000
    },
    {
      "epoch": 3.307433129340576,
      "grad_norm": 0.10181265324354172,
      "learning_rate": 2.9337510959822583e-05,
      "loss": 0.0536,
      "step": 48100
    },
    {
      "epoch": 3.314309289692636,
      "grad_norm": 0.21277514100074768,
      "learning_rate": 2.9294531263431157e-05,
      "loss": 0.0508,
      "step": 48200
    },
    {
      "epoch": 3.321185450044695,
      "grad_norm": 0.177803635597229,
      "learning_rate": 2.925155156703973e-05,
      "loss": 0.0486,
      "step": 48300
    },
    {
      "epoch": 3.3280616103967544,
      "grad_norm": 0.14053353667259216,
      "learning_rate": 2.9208571870648305e-05,
      "loss": 0.0501,
      "step": 48400
    },
    {
      "epoch": 3.3349377707488137,
      "grad_norm": 0.09644860029220581,
      "learning_rate": 2.9165592174256885e-05,
      "loss": 0.0518,
      "step": 48500
    },
    {
      "epoch": 3.3418139311008734,
      "grad_norm": 0.12658976018428802,
      "learning_rate": 2.9122612477865456e-05,
      "loss": 0.0528,
      "step": 48600
    },
    {
      "epoch": 3.3486900914529327,
      "grad_norm": 0.09754359722137451,
      "learning_rate": 2.907963278147403e-05,
      "loss": 0.0518,
      "step": 48700
    },
    {
      "epoch": 3.355566251804992,
      "grad_norm": 0.12817534804344177,
      "learning_rate": 2.903665308508261e-05,
      "loss": 0.0507,
      "step": 48800
    },
    {
      "epoch": 3.3624424121570513,
      "grad_norm": 0.10694415867328644,
      "learning_rate": 2.8993673388691184e-05,
      "loss": 0.051,
      "step": 48900
    },
    {
      "epoch": 3.369318572509111,
      "grad_norm": 0.1551099568605423,
      "learning_rate": 2.8950693692299758e-05,
      "loss": 0.0543,
      "step": 49000
    },
    {
      "epoch": 3.3761947328611703,
      "grad_norm": 0.14370861649513245,
      "learning_rate": 2.8907713995908336e-05,
      "loss": 0.053,
      "step": 49100
    },
    {
      "epoch": 3.3830708932132296,
      "grad_norm": 0.13379625976085663,
      "learning_rate": 2.886473429951691e-05,
      "loss": 0.0479,
      "step": 49200
    },
    {
      "epoch": 3.3899470535652894,
      "grad_norm": 0.10208126157522202,
      "learning_rate": 2.8821754603125483e-05,
      "loss": 0.0495,
      "step": 49300
    },
    {
      "epoch": 3.3968232139173486,
      "grad_norm": 0.1538204550743103,
      "learning_rate": 2.8778774906734064e-05,
      "loss": 0.0535,
      "step": 49400
    },
    {
      "epoch": 3.403699374269408,
      "grad_norm": 0.13609865307807922,
      "learning_rate": 2.8735795210342638e-05,
      "loss": 0.0505,
      "step": 49500
    },
    {
      "epoch": 3.4105755346214672,
      "grad_norm": 0.1905682384967804,
      "learning_rate": 2.869281551395121e-05,
      "loss": 0.0526,
      "step": 49600
    },
    {
      "epoch": 3.417451694973527,
      "grad_norm": 0.15187464654445648,
      "learning_rate": 2.86502656145237e-05,
      "loss": 0.0495,
      "step": 49700
    },
    {
      "epoch": 3.4243278553255863,
      "grad_norm": 0.22418195009231567,
      "learning_rate": 2.8607285918132275e-05,
      "loss": 0.0533,
      "step": 49800
    },
    {
      "epoch": 3.4312040156776455,
      "grad_norm": 0.19479845464229584,
      "learning_rate": 2.856430622174085e-05,
      "loss": 0.0524,
      "step": 49900
    },
    {
      "epoch": 3.438080176029705,
      "grad_norm": 0.13337883353233337,
      "learning_rate": 2.852132652534943e-05,
      "loss": 0.0526,
      "step": 50000
    },
    {
      "epoch": 3.4449563363817646,
      "grad_norm": 0.18662968277931213,
      "learning_rate": 2.8478346828958003e-05,
      "loss": 0.0506,
      "step": 50100
    },
    {
      "epoch": 3.451832496733824,
      "grad_norm": 0.15754452347755432,
      "learning_rate": 2.8435367132566577e-05,
      "loss": 0.0509,
      "step": 50200
    },
    {
      "epoch": 3.458708657085883,
      "grad_norm": 0.14954669773578644,
      "learning_rate": 2.839238743617515e-05,
      "loss": 0.0522,
      "step": 50300
    },
    {
      "epoch": 3.465584817437943,
      "grad_norm": 0.1606137454509735,
      "learning_rate": 2.834940773978373e-05,
      "loss": 0.0544,
      "step": 50400
    },
    {
      "epoch": 3.472460977790002,
      "grad_norm": 0.12220673263072968,
      "learning_rate": 2.8306428043392302e-05,
      "loss": 0.0505,
      "step": 50500
    },
    {
      "epoch": 3.4793371381420615,
      "grad_norm": 0.1135057732462883,
      "learning_rate": 2.8263448347000876e-05,
      "loss": 0.0487,
      "step": 50600
    },
    {
      "epoch": 3.4862132984941208,
      "grad_norm": 0.1528833508491516,
      "learning_rate": 2.8220468650609454e-05,
      "loss": 0.0543,
      "step": 50700
    },
    {
      "epoch": 3.49308945884618,
      "grad_norm": 0.11610642075538635,
      "learning_rate": 2.8177488954218028e-05,
      "loss": 0.0512,
      "step": 50800
    },
    {
      "epoch": 3.49996561919824,
      "grad_norm": 0.18498912453651428,
      "learning_rate": 2.81345092578266e-05,
      "loss": 0.0522,
      "step": 50900
    },
    {
      "epoch": 3.506841779550299,
      "grad_norm": 0.09721500426530838,
      "learning_rate": 2.8091529561435182e-05,
      "loss": 0.0518,
      "step": 51000
    },
    {
      "epoch": 3.5137179399023584,
      "grad_norm": 0.12622568011283875,
      "learning_rate": 2.8048549865043756e-05,
      "loss": 0.0515,
      "step": 51100
    },
    {
      "epoch": 3.520594100254418,
      "grad_norm": 0.18108823895454407,
      "learning_rate": 2.800557016865233e-05,
      "loss": 0.051,
      "step": 51200
    },
    {
      "epoch": 3.5274702606064774,
      "grad_norm": 0.11260104924440384,
      "learning_rate": 2.7962590472260907e-05,
      "loss": 0.0532,
      "step": 51300
    },
    {
      "epoch": 3.5343464209585367,
      "grad_norm": 0.11973711848258972,
      "learning_rate": 2.791961077586948e-05,
      "loss": 0.0511,
      "step": 51400
    },
    {
      "epoch": 3.5412225813105964,
      "grad_norm": 0.24921803176403046,
      "learning_rate": 2.7876631079478055e-05,
      "loss": 0.05,
      "step": 51500
    },
    {
      "epoch": 3.5480987416626557,
      "grad_norm": 0.16074511408805847,
      "learning_rate": 2.783365138308663e-05,
      "loss": 0.0544,
      "step": 51600
    },
    {
      "epoch": 3.554974902014715,
      "grad_norm": 0.1558135449886322,
      "learning_rate": 2.7790671686695206e-05,
      "loss": 0.0528,
      "step": 51700
    },
    {
      "epoch": 3.5618510623667743,
      "grad_norm": 0.15996243059635162,
      "learning_rate": 2.774769199030378e-05,
      "loss": 0.0509,
      "step": 51800
    },
    {
      "epoch": 3.5687272227188336,
      "grad_norm": 0.12098829448223114,
      "learning_rate": 2.7704712293912354e-05,
      "loss": 0.0539,
      "step": 51900
    },
    {
      "epoch": 3.5756033830708933,
      "grad_norm": 0.1336759328842163,
      "learning_rate": 2.7661732597520935e-05,
      "loss": 0.0502,
      "step": 52000
    },
    {
      "epoch": 3.5824795434229526,
      "grad_norm": 0.09181155264377594,
      "learning_rate": 2.761875290112951e-05,
      "loss": 0.0526,
      "step": 52100
    },
    {
      "epoch": 3.589355703775012,
      "grad_norm": 0.22950488328933716,
      "learning_rate": 2.7575773204738083e-05,
      "loss": 0.0534,
      "step": 52200
    },
    {
      "epoch": 3.5962318641270716,
      "grad_norm": 0.14033158123493195,
      "learning_rate": 2.753279350834666e-05,
      "loss": 0.0513,
      "step": 52300
    },
    {
      "epoch": 3.603108024479131,
      "grad_norm": 0.10123974829912186,
      "learning_rate": 2.7489813811955234e-05,
      "loss": 0.0506,
      "step": 52400
    },
    {
      "epoch": 3.60998418483119,
      "grad_norm": 0.11897530406713486,
      "learning_rate": 2.7446834115563808e-05,
      "loss": 0.0545,
      "step": 52500
    },
    {
      "epoch": 3.61686034518325,
      "grad_norm": 0.16025355458259583,
      "learning_rate": 2.740385441917239e-05,
      "loss": 0.0507,
      "step": 52600
    },
    {
      "epoch": 3.6237365055353092,
      "grad_norm": 0.15949690341949463,
      "learning_rate": 2.736087472278096e-05,
      "loss": 0.0479,
      "step": 52700
    },
    {
      "epoch": 3.6306126658873685,
      "grad_norm": 0.11337072402238846,
      "learning_rate": 2.7317895026389533e-05,
      "loss": 0.052,
      "step": 52800
    },
    {
      "epoch": 3.637488826239428,
      "grad_norm": 0.1266109049320221,
      "learning_rate": 2.7274915329998107e-05,
      "loss": 0.0509,
      "step": 52900
    },
    {
      "epoch": 3.644364986591487,
      "grad_norm": 0.10702218115329742,
      "learning_rate": 2.7231935633606687e-05,
      "loss": 0.0512,
      "step": 53000
    },
    {
      "epoch": 3.651241146943547,
      "grad_norm": 0.09976302087306976,
      "learning_rate": 2.718895593721526e-05,
      "loss": 0.0499,
      "step": 53100
    },
    {
      "epoch": 3.658117307295606,
      "grad_norm": 0.16537608206272125,
      "learning_rate": 2.7145976240823835e-05,
      "loss": 0.0511,
      "step": 53200
    },
    {
      "epoch": 3.6649934676476654,
      "grad_norm": 0.1531374603509903,
      "learning_rate": 2.7102996544432413e-05,
      "loss": 0.052,
      "step": 53300
    },
    {
      "epoch": 3.671869627999725,
      "grad_norm": 0.20952507853507996,
      "learning_rate": 2.7060016848040986e-05,
      "loss": 0.0504,
      "step": 53400
    },
    {
      "epoch": 3.6787457883517845,
      "grad_norm": 0.11348377168178558,
      "learning_rate": 2.701703715164956e-05,
      "loss": 0.0503,
      "step": 53500
    },
    {
      "epoch": 3.6856219487038437,
      "grad_norm": 0.13555434346199036,
      "learning_rate": 2.6974057455258138e-05,
      "loss": 0.0481,
      "step": 53600
    },
    {
      "epoch": 3.692498109055903,
      "grad_norm": 0.1395018845796585,
      "learning_rate": 2.693107775886671e-05,
      "loss": 0.0514,
      "step": 53700
    },
    {
      "epoch": 3.6993742694079623,
      "grad_norm": 0.08679629117250443,
      "learning_rate": 2.6888098062475286e-05,
      "loss": 0.0527,
      "step": 53800
    },
    {
      "epoch": 3.706250429760022,
      "grad_norm": 0.19484484195709229,
      "learning_rate": 2.6845118366083866e-05,
      "loss": 0.0504,
      "step": 53900
    },
    {
      "epoch": 3.7131265901120813,
      "grad_norm": 0.2288120985031128,
      "learning_rate": 2.680213866969244e-05,
      "loss": 0.0515,
      "step": 54000
    },
    {
      "epoch": 3.7200027504641406,
      "grad_norm": 0.0985567569732666,
      "learning_rate": 2.6759158973301014e-05,
      "loss": 0.0497,
      "step": 54100
    },
    {
      "epoch": 3.7268789108162004,
      "grad_norm": 0.15966014564037323,
      "learning_rate": 2.6716179276909588e-05,
      "loss": 0.0502,
      "step": 54200
    },
    {
      "epoch": 3.7337550711682597,
      "grad_norm": 0.1269875466823578,
      "learning_rate": 2.6673199580518165e-05,
      "loss": 0.0493,
      "step": 54300
    },
    {
      "epoch": 3.740631231520319,
      "grad_norm": 0.171347975730896,
      "learning_rate": 2.663021988412674e-05,
      "loss": 0.0504,
      "step": 54400
    },
    {
      "epoch": 3.7475073918723787,
      "grad_norm": 0.14824923872947693,
      "learning_rate": 2.6587240187735313e-05,
      "loss": 0.0531,
      "step": 54500
    },
    {
      "epoch": 3.754383552224438,
      "grad_norm": 0.13614371418952942,
      "learning_rate": 2.654426049134389e-05,
      "loss": 0.0502,
      "step": 54600
    },
    {
      "epoch": 3.7612597125764973,
      "grad_norm": 0.16117942333221436,
      "learning_rate": 2.6501280794952464e-05,
      "loss": 0.0516,
      "step": 54700
    },
    {
      "epoch": 3.7681358729285566,
      "grad_norm": 0.12261836230754852,
      "learning_rate": 2.6458301098561038e-05,
      "loss": 0.0518,
      "step": 54800
    },
    {
      "epoch": 3.775012033280616,
      "grad_norm": 0.17882317304611206,
      "learning_rate": 2.641532140216962e-05,
      "loss": 0.046,
      "step": 54900
    },
    {
      "epoch": 3.7818881936326756,
      "grad_norm": 0.12649601697921753,
      "learning_rate": 2.6372341705778193e-05,
      "loss": 0.0495,
      "step": 55000
    },
    {
      "epoch": 3.788764353984735,
      "grad_norm": 0.11400388926267624,
      "learning_rate": 2.6329362009386767e-05,
      "loss": 0.0497,
      "step": 55100
    },
    {
      "epoch": 3.795640514336794,
      "grad_norm": 0.10677624493837357,
      "learning_rate": 2.6286382312995344e-05,
      "loss": 0.0527,
      "step": 55200
    },
    {
      "epoch": 3.802516674688854,
      "grad_norm": 0.1508961319923401,
      "learning_rate": 2.6243402616603918e-05,
      "loss": 0.0496,
      "step": 55300
    },
    {
      "epoch": 3.809392835040913,
      "grad_norm": 0.12592491507530212,
      "learning_rate": 2.6200422920212492e-05,
      "loss": 0.0507,
      "step": 55400
    },
    {
      "epoch": 3.8162689953929725,
      "grad_norm": 0.09834695607423782,
      "learning_rate": 2.6157443223821072e-05,
      "loss": 0.0523,
      "step": 55500
    },
    {
      "epoch": 3.823145155745032,
      "grad_norm": 0.16571033000946045,
      "learning_rate": 2.6114463527429643e-05,
      "loss": 0.0523,
      "step": 55600
    },
    {
      "epoch": 3.8300213160970915,
      "grad_norm": 0.16350308060646057,
      "learning_rate": 2.6071913628002132e-05,
      "loss": 0.0493,
      "step": 55700
    },
    {
      "epoch": 3.836897476449151,
      "grad_norm": 0.11152662336826324,
      "learning_rate": 2.602893393161071e-05,
      "loss": 0.0468,
      "step": 55800
    },
    {
      "epoch": 3.84377363680121,
      "grad_norm": 0.23069563508033752,
      "learning_rate": 2.5985954235219283e-05,
      "loss": 0.048,
      "step": 55900
    },
    {
      "epoch": 3.8506497971532694,
      "grad_norm": 0.1301007717847824,
      "learning_rate": 2.5942974538827857e-05,
      "loss": 0.0486,
      "step": 56000
    },
    {
      "epoch": 3.857525957505329,
      "grad_norm": 0.1642492711544037,
      "learning_rate": 2.5899994842436438e-05,
      "loss": 0.0509,
      "step": 56100
    },
    {
      "epoch": 3.8644021178573884,
      "grad_norm": 0.17375430464744568,
      "learning_rate": 2.5857015146045012e-05,
      "loss": 0.0526,
      "step": 56200
    },
    {
      "epoch": 3.8712782782094477,
      "grad_norm": 0.18295493721961975,
      "learning_rate": 2.5814035449653586e-05,
      "loss": 0.0505,
      "step": 56300
    },
    {
      "epoch": 3.8781544385615074,
      "grad_norm": 0.12335962802171707,
      "learning_rate": 2.5771055753262156e-05,
      "loss": 0.0497,
      "step": 56400
    },
    {
      "epoch": 3.8850305989135667,
      "grad_norm": 0.17048674821853638,
      "learning_rate": 2.5728076056870737e-05,
      "loss": 0.0485,
      "step": 56500
    },
    {
      "epoch": 3.891906759265626,
      "grad_norm": 0.12923607230186462,
      "learning_rate": 2.568509636047931e-05,
      "loss": 0.0526,
      "step": 56600
    },
    {
      "epoch": 3.8987829196176857,
      "grad_norm": 0.1543651670217514,
      "learning_rate": 2.5642116664087885e-05,
      "loss": 0.0515,
      "step": 56700
    },
    {
      "epoch": 3.905659079969745,
      "grad_norm": 0.164812371134758,
      "learning_rate": 2.5599136967696462e-05,
      "loss": 0.0524,
      "step": 56800
    },
    {
      "epoch": 3.9125352403218043,
      "grad_norm": 0.17300666868686676,
      "learning_rate": 2.555658706826895e-05,
      "loss": 0.0548,
      "step": 56900
    },
    {
      "epoch": 3.9194114006738636,
      "grad_norm": 0.11366243660449982,
      "learning_rate": 2.5513607371877525e-05,
      "loss": 0.0464,
      "step": 57000
    },
    {
      "epoch": 3.926287561025923,
      "grad_norm": 0.15978315472602844,
      "learning_rate": 2.5470627675486102e-05,
      "loss": 0.0499,
      "step": 57100
    },
    {
      "epoch": 3.9331637213779826,
      "grad_norm": 0.131068155169487,
      "learning_rate": 2.5427647979094676e-05,
      "loss": 0.0516,
      "step": 57200
    },
    {
      "epoch": 3.940039881730042,
      "grad_norm": 0.21303008496761322,
      "learning_rate": 2.538466828270325e-05,
      "loss": 0.0487,
      "step": 57300
    },
    {
      "epoch": 3.9469160420821012,
      "grad_norm": 0.10172846168279648,
      "learning_rate": 2.534168858631183e-05,
      "loss": 0.0506,
      "step": 57400
    },
    {
      "epoch": 3.953792202434161,
      "grad_norm": 0.12363528460264206,
      "learning_rate": 2.52987088899204e-05,
      "loss": 0.0496,
      "step": 57500
    },
    {
      "epoch": 3.9606683627862203,
      "grad_norm": 0.16156123578548431,
      "learning_rate": 2.5255729193528975e-05,
      "loss": 0.0486,
      "step": 57600
    },
    {
      "epoch": 3.9675445231382795,
      "grad_norm": 0.20838885009288788,
      "learning_rate": 2.5212749497137556e-05,
      "loss": 0.0505,
      "step": 57700
    },
    {
      "epoch": 3.974420683490339,
      "grad_norm": 0.1701369285583496,
      "learning_rate": 2.516976980074613e-05,
      "loss": 0.0502,
      "step": 57800
    },
    {
      "epoch": 3.9812968438423986,
      "grad_norm": 0.11166965216398239,
      "learning_rate": 2.5126790104354704e-05,
      "loss": 0.0494,
      "step": 57900
    },
    {
      "epoch": 3.988173004194458,
      "grad_norm": 0.09953880310058594,
      "learning_rate": 2.508381040796328e-05,
      "loss": 0.049,
      "step": 58000
    },
    {
      "epoch": 3.995049164546517,
      "grad_norm": 0.12413642555475235,
      "learning_rate": 2.5040830711571855e-05,
      "loss": 0.0512,
      "step": 58100
    },
    {
      "epoch": 4.0,
      "eval_accuracy_macro_0.5": 0.9772143959999084,
      "eval_accuracy_micro_0.5": 0.9772143959999084,
      "eval_accuracy_weighted_0.5": 0.9744279384613037,
      "eval_f1_macro_0.5": 0.6826928853988647,
      "eval_f1_macro_0.6": 0.6514304876327515,
      "eval_f1_macro_0.7": 0.6023828983306885,
      "eval_f1_macro_0.8": 0.382834792137146,
      "eval_f1_micro_0.5": 0.6925712823867798,
      "eval_f1_micro_0.6": 0.6690391302108765,
      "eval_f1_micro_0.7": 0.6279577612876892,
      "eval_f1_micro_0.8": 0.5551171898841858,
      "eval_f1_micro_0.9": 0.40874528884887695,
      "eval_f1_weighted_0.5": 0.6802995800971985,
      "eval_f1_weighted_0.6": 0.6487917304039001,
      "eval_f1_weighted_0.7": 0.5985255241394043,
      "eval_f1_weighted_0.8": 0.3657681345939636,
      "eval_loss": 0.047641120851039886,
      "eval_runtime": 139.9951,
      "eval_samples_per_second": 207.414,
      "eval_steps_per_second": 25.929,
      "step": 58172
    },
    {
      "epoch": 4.001925324898576,
      "grad_norm": 0.12578098475933075,
      "learning_rate": 2.499785101518043e-05,
      "loss": 0.0524,
      "step": 58200
    },
    {
      "epoch": 4.008801485250636,
      "grad_norm": 0.11844933032989502,
      "learning_rate": 2.4954871318789006e-05,
      "loss": 0.0501,
      "step": 58300
    },
    {
      "epoch": 4.015677645602695,
      "grad_norm": 0.15317802131175995,
      "learning_rate": 2.4911891622397583e-05,
      "loss": 0.0519,
      "step": 58400
    },
    {
      "epoch": 4.022553805954755,
      "grad_norm": 0.07561005651950836,
      "learning_rate": 2.4868911926006154e-05,
      "loss": 0.0538,
      "step": 58500
    },
    {
      "epoch": 4.0294299663068145,
      "grad_norm": 0.12948888540267944,
      "learning_rate": 2.482593222961473e-05,
      "loss": 0.0476,
      "step": 58600
    },
    {
      "epoch": 4.036306126658873,
      "grad_norm": 0.11232072114944458,
      "learning_rate": 2.4782952533223305e-05,
      "loss": 0.0493,
      "step": 58700
    },
    {
      "epoch": 4.043182287010933,
      "grad_norm": 0.11689271777868271,
      "learning_rate": 2.4739972836831883e-05,
      "loss": 0.0504,
      "step": 58800
    },
    {
      "epoch": 4.050058447362993,
      "grad_norm": 0.17097550630569458,
      "learning_rate": 2.4696993140440456e-05,
      "loss": 0.0502,
      "step": 58900
    },
    {
      "epoch": 4.056934607715052,
      "grad_norm": 0.10081790387630463,
      "learning_rate": 2.465401344404903e-05,
      "loss": 0.051,
      "step": 59000
    },
    {
      "epoch": 4.063810768067111,
      "grad_norm": 0.14533807337284088,
      "learning_rate": 2.4611463544621523e-05,
      "loss": 0.0491,
      "step": 59100
    },
    {
      "epoch": 4.070686928419171,
      "grad_norm": 0.12142489105463028,
      "learning_rate": 2.4568483848230097e-05,
      "loss": 0.0494,
      "step": 59200
    },
    {
      "epoch": 4.07756308877123,
      "grad_norm": 0.09396130591630936,
      "learning_rate": 2.452550415183867e-05,
      "loss": 0.049,
      "step": 59300
    },
    {
      "epoch": 4.08443924912329,
      "grad_norm": 0.12211224436759949,
      "learning_rate": 2.4482524455447248e-05,
      "loss": 0.0518,
      "step": 59400
    },
    {
      "epoch": 4.0913154094753486,
      "grad_norm": 0.1148509830236435,
      "learning_rate": 2.4439544759055825e-05,
      "loss": 0.0492,
      "step": 59500
    },
    {
      "epoch": 4.098191569827408,
      "grad_norm": 0.08767148107290268,
      "learning_rate": 2.43965650626644e-05,
      "loss": 0.0525,
      "step": 59600
    },
    {
      "epoch": 4.105067730179468,
      "grad_norm": 0.1667359322309494,
      "learning_rate": 2.4353585366272973e-05,
      "loss": 0.0508,
      "step": 59700
    },
    {
      "epoch": 4.111943890531527,
      "grad_norm": 0.18455985188484192,
      "learning_rate": 2.431060566988155e-05,
      "loss": 0.0526,
      "step": 59800
    },
    {
      "epoch": 4.118820050883587,
      "grad_norm": 0.08726295828819275,
      "learning_rate": 2.4267625973490124e-05,
      "loss": 0.0504,
      "step": 59900
    },
    {
      "epoch": 4.125696211235646,
      "grad_norm": 0.10484130680561066,
      "learning_rate": 2.42246462770987e-05,
      "loss": 0.0489,
      "step": 60000
    },
    {
      "epoch": 4.132572371587705,
      "grad_norm": 0.14844416081905365,
      "learning_rate": 2.4181666580707275e-05,
      "loss": 0.0503,
      "step": 60100
    },
    {
      "epoch": 4.139448531939765,
      "grad_norm": 0.09415807574987411,
      "learning_rate": 2.413868688431585e-05,
      "loss": 0.0472,
      "step": 60200
    },
    {
      "epoch": 4.146324692291825,
      "grad_norm": 0.13474886119365692,
      "learning_rate": 2.4095707187924427e-05,
      "loss": 0.0479,
      "step": 60300
    },
    {
      "epoch": 4.1532008526438835,
      "grad_norm": 0.22977913916110992,
      "learning_rate": 2.4052727491533e-05,
      "loss": 0.0506,
      "step": 60400
    },
    {
      "epoch": 4.160077012995943,
      "grad_norm": 0.10145000368356705,
      "learning_rate": 2.4009747795141578e-05,
      "loss": 0.0515,
      "step": 60500
    },
    {
      "epoch": 4.166953173348002,
      "grad_norm": 0.1312226951122284,
      "learning_rate": 2.3966768098750152e-05,
      "loss": 0.0497,
      "step": 60600
    },
    {
      "epoch": 4.173829333700062,
      "grad_norm": 0.13913217186927795,
      "learning_rate": 2.3923788402358726e-05,
      "loss": 0.0467,
      "step": 60700
    },
    {
      "epoch": 4.1807054940521216,
      "grad_norm": 0.13751628994941711,
      "learning_rate": 2.3880808705967303e-05,
      "loss": 0.0488,
      "step": 60800
    },
    {
      "epoch": 4.18758165440418,
      "grad_norm": 0.19733022153377533,
      "learning_rate": 2.3837829009575877e-05,
      "loss": 0.0527,
      "step": 60900
    },
    {
      "epoch": 4.19445781475624,
      "grad_norm": 0.15510334074497223,
      "learning_rate": 2.3794849313184454e-05,
      "loss": 0.05,
      "step": 61000
    },
    {
      "epoch": 4.2013339751083,
      "grad_norm": 0.07811350375413895,
      "learning_rate": 2.3751869616793028e-05,
      "loss": 0.0494,
      "step": 61100
    },
    {
      "epoch": 4.208210135460359,
      "grad_norm": 0.1874166876077652,
      "learning_rate": 2.3708889920401602e-05,
      "loss": 0.0484,
      "step": 61200
    },
    {
      "epoch": 4.2150862958124184,
      "grad_norm": 0.15688323974609375,
      "learning_rate": 2.366591022401018e-05,
      "loss": 0.0493,
      "step": 61300
    },
    {
      "epoch": 4.221962456164478,
      "grad_norm": 0.11124417930841446,
      "learning_rate": 2.3622930527618753e-05,
      "loss": 0.0496,
      "step": 61400
    },
    {
      "epoch": 4.228838616516537,
      "grad_norm": 0.22229810059070587,
      "learning_rate": 2.357995083122733e-05,
      "loss": 0.0512,
      "step": 61500
    },
    {
      "epoch": 4.235714776868597,
      "grad_norm": 0.12665387988090515,
      "learning_rate": 2.3536971134835904e-05,
      "loss": 0.0519,
      "step": 61600
    },
    {
      "epoch": 4.242590937220656,
      "grad_norm": 0.16357670724391937,
      "learning_rate": 2.349399143844448e-05,
      "loss": 0.0508,
      "step": 61700
    },
    {
      "epoch": 4.249467097572715,
      "grad_norm": 0.15136894583702087,
      "learning_rate": 2.3451011742053056e-05,
      "loss": 0.0497,
      "step": 61800
    },
    {
      "epoch": 4.256343257924775,
      "grad_norm": 0.1531905233860016,
      "learning_rate": 2.340803204566163e-05,
      "loss": 0.0509,
      "step": 61900
    },
    {
      "epoch": 4.263219418276834,
      "grad_norm": 0.14369794726371765,
      "learning_rate": 2.336548214623412e-05,
      "loss": 0.0542,
      "step": 62000
    },
    {
      "epoch": 4.270095578628894,
      "grad_norm": 0.1795559823513031,
      "learning_rate": 2.3322502449842696e-05,
      "loss": 0.0504,
      "step": 62100
    },
    {
      "epoch": 4.276971738980953,
      "grad_norm": 0.14419442415237427,
      "learning_rate": 2.3279522753451273e-05,
      "loss": 0.0477,
      "step": 62200
    },
    {
      "epoch": 4.283847899333012,
      "grad_norm": 0.16960382461547852,
      "learning_rate": 2.3236543057059844e-05,
      "loss": 0.0502,
      "step": 62300
    },
    {
      "epoch": 4.290724059685072,
      "grad_norm": 0.14035947620868683,
      "learning_rate": 2.319356336066842e-05,
      "loss": 0.0504,
      "step": 62400
    },
    {
      "epoch": 4.297600220037131,
      "grad_norm": 0.0934518426656723,
      "learning_rate": 2.3150583664277e-05,
      "loss": 0.0468,
      "step": 62500
    },
    {
      "epoch": 4.304476380389191,
      "grad_norm": 0.15589849650859833,
      "learning_rate": 2.3107603967885572e-05,
      "loss": 0.0519,
      "step": 62600
    },
    {
      "epoch": 4.31135254074125,
      "grad_norm": 0.159209743142128,
      "learning_rate": 2.306462427149415e-05,
      "loss": 0.0498,
      "step": 62700
    },
    {
      "epoch": 4.318228701093309,
      "grad_norm": 0.11208628863096237,
      "learning_rate": 2.302164457510272e-05,
      "loss": 0.0505,
      "step": 62800
    },
    {
      "epoch": 4.325104861445369,
      "grad_norm": 0.1372165083885193,
      "learning_rate": 2.2978664878711297e-05,
      "loss": 0.0487,
      "step": 62900
    },
    {
      "epoch": 4.331981021797429,
      "grad_norm": 0.14665277302265167,
      "learning_rate": 2.2935685182319875e-05,
      "loss": 0.05,
      "step": 63000
    },
    {
      "epoch": 4.3388571821494875,
      "grad_norm": 0.11360183358192444,
      "learning_rate": 2.289270548592845e-05,
      "loss": 0.0492,
      "step": 63100
    },
    {
      "epoch": 4.345733342501547,
      "grad_norm": 0.18490175902843475,
      "learning_rate": 2.2849725789537026e-05,
      "loss": 0.0509,
      "step": 63200
    },
    {
      "epoch": 4.352609502853607,
      "grad_norm": 0.16872932016849518,
      "learning_rate": 2.2806746093145596e-05,
      "loss": 0.0473,
      "step": 63300
    },
    {
      "epoch": 4.359485663205666,
      "grad_norm": 0.2035466879606247,
      "learning_rate": 2.2763766396754174e-05,
      "loss": 0.0488,
      "step": 63400
    },
    {
      "epoch": 4.3663618235577255,
      "grad_norm": 0.14430706202983856,
      "learning_rate": 2.272078670036275e-05,
      "loss": 0.0526,
      "step": 63500
    },
    {
      "epoch": 4.373237983909785,
      "grad_norm": 0.25468456745147705,
      "learning_rate": 2.2677807003971325e-05,
      "loss": 0.0516,
      "step": 63600
    },
    {
      "epoch": 4.380114144261844,
      "grad_norm": 0.11467650532722473,
      "learning_rate": 2.2634827307579902e-05,
      "loss": 0.0533,
      "step": 63700
    },
    {
      "epoch": 4.386990304613904,
      "grad_norm": 0.26906540989875793,
      "learning_rate": 2.2591847611188476e-05,
      "loss": 0.0502,
      "step": 63800
    },
    {
      "epoch": 4.393866464965963,
      "grad_norm": 0.15901799499988556,
      "learning_rate": 2.254886791479705e-05,
      "loss": 0.0507,
      "step": 63900
    },
    {
      "epoch": 4.400742625318022,
      "grad_norm": 0.16230107843875885,
      "learning_rate": 2.2505888218405627e-05,
      "loss": 0.0476,
      "step": 64000
    },
    {
      "epoch": 4.407618785670082,
      "grad_norm": 0.10012995451688766,
      "learning_rate": 2.24629085220142e-05,
      "loss": 0.0469,
      "step": 64100
    },
    {
      "epoch": 4.414494946022141,
      "grad_norm": 0.1522522270679474,
      "learning_rate": 2.2419928825622775e-05,
      "loss": 0.0499,
      "step": 64200
    },
    {
      "epoch": 4.421371106374201,
      "grad_norm": 0.13656926155090332,
      "learning_rate": 2.2376949129231352e-05,
      "loss": 0.0517,
      "step": 64300
    },
    {
      "epoch": 4.4282472667262605,
      "grad_norm": 0.1024218276143074,
      "learning_rate": 2.233439922980384e-05,
      "loss": 0.0475,
      "step": 64400
    },
    {
      "epoch": 4.435123427078319,
      "grad_norm": 0.1260976344347,
      "learning_rate": 2.2291419533412415e-05,
      "loss": 0.0496,
      "step": 64500
    },
    {
      "epoch": 4.441999587430379,
      "grad_norm": 0.24357759952545166,
      "learning_rate": 2.2248439837020993e-05,
      "loss": 0.0492,
      "step": 64600
    },
    {
      "epoch": 4.448875747782438,
      "grad_norm": 0.14530788362026215,
      "learning_rate": 2.2205460140629567e-05,
      "loss": 0.0481,
      "step": 64700
    },
    {
      "epoch": 4.455751908134498,
      "grad_norm": 0.1529475301504135,
      "learning_rate": 2.2162480444238144e-05,
      "loss": 0.0507,
      "step": 64800
    },
    {
      "epoch": 4.462628068486557,
      "grad_norm": 0.2330145537853241,
      "learning_rate": 2.2119500747846718e-05,
      "loss": 0.0499,
      "step": 64900
    },
    {
      "epoch": 4.469504228838616,
      "grad_norm": 0.19051948189735413,
      "learning_rate": 2.2076521051455292e-05,
      "loss": 0.0489,
      "step": 65000
    },
    {
      "epoch": 4.476380389190676,
      "grad_norm": 0.16259941458702087,
      "learning_rate": 2.203354135506387e-05,
      "loss": 0.0491,
      "step": 65100
    },
    {
      "epoch": 4.483256549542736,
      "grad_norm": 0.20264099538326263,
      "learning_rate": 2.1990561658672446e-05,
      "loss": 0.0504,
      "step": 65200
    },
    {
      "epoch": 4.4901327098947945,
      "grad_norm": 0.12144093215465546,
      "learning_rate": 2.194758196228102e-05,
      "loss": 0.0509,
      "step": 65300
    },
    {
      "epoch": 4.497008870246854,
      "grad_norm": 0.19138799607753754,
      "learning_rate": 2.1904602265889594e-05,
      "loss": 0.0476,
      "step": 65400
    },
    {
      "epoch": 4.503885030598914,
      "grad_norm": 0.144973486661911,
      "learning_rate": 2.1861622569498168e-05,
      "loss": 0.05,
      "step": 65500
    },
    {
      "epoch": 4.510761190950973,
      "grad_norm": 0.20991136133670807,
      "learning_rate": 2.1818642873106745e-05,
      "loss": 0.0492,
      "step": 65600
    },
    {
      "epoch": 4.517637351303033,
      "grad_norm": 0.19459787011146545,
      "learning_rate": 2.1775663176715323e-05,
      "loss": 0.0515,
      "step": 65700
    },
    {
      "epoch": 4.524513511655091,
      "grad_norm": 0.15265128016471863,
      "learning_rate": 2.1732683480323897e-05,
      "loss": 0.0516,
      "step": 65800
    },
    {
      "epoch": 4.531389672007151,
      "grad_norm": 0.12519878149032593,
      "learning_rate": 2.168970378393247e-05,
      "loss": 0.0486,
      "step": 65900
    },
    {
      "epoch": 4.538265832359211,
      "grad_norm": 0.11196811497211456,
      "learning_rate": 2.1646724087541044e-05,
      "loss": 0.0473,
      "step": 66000
    },
    {
      "epoch": 4.54514199271127,
      "grad_norm": 0.17915944755077362,
      "learning_rate": 2.1603744391149622e-05,
      "loss": 0.0498,
      "step": 66100
    },
    {
      "epoch": 4.5520181530633295,
      "grad_norm": 0.15156452357769012,
      "learning_rate": 2.15607646947582e-05,
      "loss": 0.0514,
      "step": 66200
    },
    {
      "epoch": 4.558894313415389,
      "grad_norm": 0.15428031980991364,
      "learning_rate": 2.1517784998366773e-05,
      "loss": 0.0505,
      "step": 66300
    },
    {
      "epoch": 4.565770473767448,
      "grad_norm": 0.15401685237884521,
      "learning_rate": 2.1474805301975347e-05,
      "loss": 0.0483,
      "step": 66400
    },
    {
      "epoch": 4.572646634119508,
      "grad_norm": 0.17513667047023773,
      "learning_rate": 2.1431825605583924e-05,
      "loss": 0.0485,
      "step": 66500
    },
    {
      "epoch": 4.579522794471567,
      "grad_norm": 0.15812884271144867,
      "learning_rate": 2.1388845909192498e-05,
      "loss": 0.047,
      "step": 66600
    },
    {
      "epoch": 4.586398954823626,
      "grad_norm": 0.17689105868339539,
      "learning_rate": 2.1345866212801075e-05,
      "loss": 0.0488,
      "step": 66700
    },
    {
      "epoch": 4.593275115175686,
      "grad_norm": 0.15619134902954102,
      "learning_rate": 2.1303316313373564e-05,
      "loss": 0.0498,
      "step": 66800
    },
    {
      "epoch": 4.600151275527745,
      "grad_norm": 0.12474676221609116,
      "learning_rate": 2.126033661698214e-05,
      "loss": 0.049,
      "step": 66900
    },
    {
      "epoch": 4.607027435879805,
      "grad_norm": 0.21386583149433136,
      "learning_rate": 2.1217356920590716e-05,
      "loss": 0.048,
      "step": 67000
    },
    {
      "epoch": 4.613903596231864,
      "grad_norm": 0.16121043264865875,
      "learning_rate": 2.117437722419929e-05,
      "loss": 0.0495,
      "step": 67100
    },
    {
      "epoch": 4.620779756583923,
      "grad_norm": 0.13500525057315826,
      "learning_rate": 2.1131397527807863e-05,
      "loss": 0.049,
      "step": 67200
    },
    {
      "epoch": 4.627655916935983,
      "grad_norm": 0.11410637199878693,
      "learning_rate": 2.108841783141644e-05,
      "loss": 0.0492,
      "step": 67300
    },
    {
      "epoch": 4.634532077288043,
      "grad_norm": 0.18385624885559082,
      "learning_rate": 2.1045438135025015e-05,
      "loss": 0.0513,
      "step": 67400
    },
    {
      "epoch": 4.641408237640102,
      "grad_norm": 0.1717684119939804,
      "learning_rate": 2.1002458438633592e-05,
      "loss": 0.0475,
      "step": 67500
    },
    {
      "epoch": 4.648284397992161,
      "grad_norm": 0.07689651101827621,
      "learning_rate": 2.0959478742242166e-05,
      "loss": 0.0498,
      "step": 67600
    },
    {
      "epoch": 4.655160558344221,
      "grad_norm": 0.24524344503879547,
      "learning_rate": 2.091649904585074e-05,
      "loss": 0.0477,
      "step": 67700
    },
    {
      "epoch": 4.66203671869628,
      "grad_norm": 0.11734385788440704,
      "learning_rate": 2.0873519349459317e-05,
      "loss": 0.048,
      "step": 67800
    },
    {
      "epoch": 4.66891287904834,
      "grad_norm": 0.25343313813209534,
      "learning_rate": 2.083053965306789e-05,
      "loss": 0.0513,
      "step": 67900
    },
    {
      "epoch": 4.6757890394003985,
      "grad_norm": 0.173197939991951,
      "learning_rate": 2.0787559956676468e-05,
      "loss": 0.049,
      "step": 68000
    },
    {
      "epoch": 4.682665199752458,
      "grad_norm": 0.15536236763000488,
      "learning_rate": 2.0745010057248957e-05,
      "loss": 0.0513,
      "step": 68100
    },
    {
      "epoch": 4.689541360104518,
      "grad_norm": 0.181182399392128,
      "learning_rate": 2.070203036085753e-05,
      "loss": 0.0462,
      "step": 68200
    },
    {
      "epoch": 4.696417520456577,
      "grad_norm": 0.11124307662248611,
      "learning_rate": 2.0659050664466105e-05,
      "loss": 0.0482,
      "step": 68300
    },
    {
      "epoch": 4.7032936808086365,
      "grad_norm": 0.145380437374115,
      "learning_rate": 2.0616070968074682e-05,
      "loss": 0.0506,
      "step": 68400
    },
    {
      "epoch": 4.710169841160695,
      "grad_norm": 0.0901968851685524,
      "learning_rate": 2.057309127168326e-05,
      "loss": 0.0496,
      "step": 68500
    },
    {
      "epoch": 4.717046001512755,
      "grad_norm": 0.15262190997600555,
      "learning_rate": 2.0530111575291834e-05,
      "loss": 0.0473,
      "step": 68600
    },
    {
      "epoch": 4.723922161864815,
      "grad_norm": 0.09642549604177475,
      "learning_rate": 2.0487131878900408e-05,
      "loss": 0.0487,
      "step": 68700
    },
    {
      "epoch": 4.730798322216874,
      "grad_norm": 0.16571269929409027,
      "learning_rate": 2.044415218250898e-05,
      "loss": 0.0491,
      "step": 68800
    },
    {
      "epoch": 4.737674482568933,
      "grad_norm": 0.18636347353458405,
      "learning_rate": 2.040117248611756e-05,
      "loss": 0.0473,
      "step": 68900
    },
    {
      "epoch": 4.744550642920993,
      "grad_norm": 0.13141068816184998,
      "learning_rate": 2.0358192789726136e-05,
      "loss": 0.048,
      "step": 69000
    },
    {
      "epoch": 4.751426803273052,
      "grad_norm": 0.1651466339826584,
      "learning_rate": 2.031521309333471e-05,
      "loss": 0.0471,
      "step": 69100
    },
    {
      "epoch": 4.758302963625112,
      "grad_norm": 0.11613678187131882,
      "learning_rate": 2.0272233396943284e-05,
      "loss": 0.0478,
      "step": 69200
    },
    {
      "epoch": 4.7651791239771715,
      "grad_norm": 0.12558449804782867,
      "learning_rate": 2.0229253700551858e-05,
      "loss": 0.0485,
      "step": 69300
    },
    {
      "epoch": 4.77205528432923,
      "grad_norm": 0.20921850204467773,
      "learning_rate": 2.0186274004160435e-05,
      "loss": 0.0506,
      "step": 69400
    },
    {
      "epoch": 4.77893144468129,
      "grad_norm": 0.1658802181482315,
      "learning_rate": 2.0143294307769012e-05,
      "loss": 0.0506,
      "step": 69500
    },
    {
      "epoch": 4.78580760503335,
      "grad_norm": 0.15585608780384064,
      "learning_rate": 2.0100314611377586e-05,
      "loss": 0.0486,
      "step": 69600
    },
    {
      "epoch": 4.792683765385409,
      "grad_norm": 0.07901585847139359,
      "learning_rate": 2.005733491498616e-05,
      "loss": 0.0504,
      "step": 69700
    },
    {
      "epoch": 4.799559925737468,
      "grad_norm": 0.10801797360181808,
      "learning_rate": 2.0014355218594738e-05,
      "loss": 0.0474,
      "step": 69800
    },
    {
      "epoch": 4.806436086089528,
      "grad_norm": 0.16285717487335205,
      "learning_rate": 1.997137552220331e-05,
      "loss": 0.0498,
      "step": 69900
    },
    {
      "epoch": 4.813312246441587,
      "grad_norm": 0.1656612604856491,
      "learning_rate": 1.992839582581189e-05,
      "loss": 0.0501,
      "step": 70000
    },
    {
      "epoch": 4.820188406793647,
      "grad_norm": 0.1743510663509369,
      "learning_rate": 1.9885416129420463e-05,
      "loss": 0.0487,
      "step": 70100
    },
    {
      "epoch": 4.8270645671457055,
      "grad_norm": 0.1407289355993271,
      "learning_rate": 1.9842436433029037e-05,
      "loss": 0.0521,
      "step": 70200
    },
    {
      "epoch": 4.833940727497765,
      "grad_norm": 0.17913036048412323,
      "learning_rate": 1.9799456736637614e-05,
      "loss": 0.0492,
      "step": 70300
    },
    {
      "epoch": 4.840816887849825,
      "grad_norm": 0.1508304923772812,
      "learning_rate": 1.9756477040246188e-05,
      "loss": 0.0471,
      "step": 70400
    },
    {
      "epoch": 4.847693048201884,
      "grad_norm": 0.22462958097457886,
      "learning_rate": 1.9713497343854765e-05,
      "loss": 0.054,
      "step": 70500
    },
    {
      "epoch": 4.854569208553944,
      "grad_norm": 0.09698271751403809,
      "learning_rate": 1.967051764746334e-05,
      "loss": 0.0531,
      "step": 70600
    },
    {
      "epoch": 4.861445368906002,
      "grad_norm": 0.1535636931657791,
      "learning_rate": 1.9627537951071913e-05,
      "loss": 0.053,
      "step": 70700
    },
    {
      "epoch": 4.868321529258062,
      "grad_norm": 0.16849300265312195,
      "learning_rate": 1.958455825468049e-05,
      "loss": 0.0465,
      "step": 70800
    },
    {
      "epoch": 4.875197689610122,
      "grad_norm": 0.1191772073507309,
      "learning_rate": 1.9541578558289064e-05,
      "loss": 0.0495,
      "step": 70900
    },
    {
      "epoch": 4.882073849962181,
      "grad_norm": 0.12970541417598724,
      "learning_rate": 1.949859886189764e-05,
      "loss": 0.0544,
      "step": 71000
    },
    {
      "epoch": 4.8889500103142405,
      "grad_norm": 0.1483684927225113,
      "learning_rate": 1.9455619165506215e-05,
      "loss": 0.0487,
      "step": 71100
    },
    {
      "epoch": 4.8958261706663,
      "grad_norm": 0.14651036262512207,
      "learning_rate": 1.941263946911479e-05,
      "loss": 0.0509,
      "step": 71200
    },
    {
      "epoch": 4.902702331018359,
      "grad_norm": 0.18745486438274384,
      "learning_rate": 1.9369659772723367e-05,
      "loss": 0.0517,
      "step": 71300
    },
    {
      "epoch": 4.909578491370419,
      "grad_norm": 0.20460811257362366,
      "learning_rate": 1.932668007633194e-05,
      "loss": 0.0481,
      "step": 71400
    },
    {
      "epoch": 4.9164546517224785,
      "grad_norm": 0.11823459714651108,
      "learning_rate": 1.9283700379940518e-05,
      "loss": 0.0483,
      "step": 71500
    },
    {
      "epoch": 4.923330812074537,
      "grad_norm": 0.13275055587291718,
      "learning_rate": 1.924072068354909e-05,
      "loss": 0.0512,
      "step": 71600
    },
    {
      "epoch": 4.930206972426597,
      "grad_norm": 0.16008862853050232,
      "learning_rate": 1.9197740987157666e-05,
      "loss": 0.0512,
      "step": 71700
    },
    {
      "epoch": 4.937083132778657,
      "grad_norm": 0.2083747684955597,
      "learning_rate": 1.9154761290766243e-05,
      "loss": 0.0498,
      "step": 71800
    },
    {
      "epoch": 4.943959293130716,
      "grad_norm": 0.14559143781661987,
      "learning_rate": 1.911178159437482e-05,
      "loss": 0.0504,
      "step": 71900
    },
    {
      "epoch": 4.950835453482775,
      "grad_norm": 0.12257727980613708,
      "learning_rate": 1.9068801897983394e-05,
      "loss": 0.0475,
      "step": 72000
    },
    {
      "epoch": 4.957711613834834,
      "grad_norm": 0.16305379569530487,
      "learning_rate": 1.9026251998555883e-05,
      "loss": 0.0493,
      "step": 72100
    },
    {
      "epoch": 4.964587774186894,
      "grad_norm": 0.08191574364900589,
      "learning_rate": 1.898327230216446e-05,
      "loss": 0.0481,
      "step": 72200
    },
    {
      "epoch": 4.971463934538954,
      "grad_norm": 0.1344222128391266,
      "learning_rate": 1.8940292605773034e-05,
      "loss": 0.0478,
      "step": 72300
    },
    {
      "epoch": 4.978340094891013,
      "grad_norm": 0.20667162537574768,
      "learning_rate": 1.8897312909381608e-05,
      "loss": 0.0475,
      "step": 72400
    },
    {
      "epoch": 4.985216255243072,
      "grad_norm": 0.17395880818367004,
      "learning_rate": 1.8854333212990186e-05,
      "loss": 0.0508,
      "step": 72500
    },
    {
      "epoch": 4.992092415595132,
      "grad_norm": 0.1511916220188141,
      "learning_rate": 1.881135351659876e-05,
      "loss": 0.049,
      "step": 72600
    },
    {
      "epoch": 4.998968575947191,
      "grad_norm": 0.19492416083812714,
      "learning_rate": 1.8768373820207337e-05,
      "loss": 0.0501,
      "step": 72700
    },
    {
      "epoch": 5.0,
      "eval_accuracy_macro_0.5": 0.9778053164482117,
      "eval_accuracy_micro_0.5": 0.9778052568435669,
      "eval_accuracy_weighted_0.5": 0.9750648736953735,
      "eval_f1_macro_0.5": 0.6920568943023682,
      "eval_f1_macro_0.6": 0.6636481285095215,
      "eval_f1_macro_0.7": 0.616624653339386,
      "eval_f1_macro_0.8": 0.40733498334884644,
      "eval_f1_micro_0.5": 0.7025429010391235,
      "eval_f1_micro_0.6": 0.6813862323760986,
      "eval_f1_micro_0.7": 0.6436389088630676,
      "eval_f1_micro_0.8": 0.5750041007995605,
      "eval_f1_micro_0.9": 0.435178279876709,
      "eval_f1_weighted_0.5": 0.6910668611526489,
      "eval_f1_weighted_0.6": 0.6622613668441772,
      "eval_f1_weighted_0.7": 0.6149361729621887,
      "eval_f1_weighted_0.8": 0.3916717767715454,
      "eval_loss": 0.0463724248111248,
      "eval_runtime": 140.4044,
      "eval_samples_per_second": 206.81,
      "eval_steps_per_second": 25.854,
      "step": 72715
    },
    {
      "epoch": 5.005844736299251,
      "grad_norm": 0.1448170691728592,
      "learning_rate": 1.872539412381591e-05,
      "loss": 0.0502,
      "step": 72800
    },
    {
      "epoch": 5.0127208966513095,
      "grad_norm": 0.1445193886756897,
      "learning_rate": 1.8682414427424485e-05,
      "loss": 0.047,
      "step": 72900
    },
    {
      "epoch": 5.019597057003369,
      "grad_norm": 0.17651358246803284,
      "learning_rate": 1.8639434731033062e-05,
      "loss": 0.0496,
      "step": 73000
    },
    {
      "epoch": 5.026473217355429,
      "grad_norm": 0.14566625654697418,
      "learning_rate": 1.8596455034641636e-05,
      "loss": 0.0496,
      "step": 73100
    },
    {
      "epoch": 5.033349377707488,
      "grad_norm": 0.20413930714130402,
      "learning_rate": 1.8553475338250213e-05,
      "loss": 0.0486,
      "step": 73200
    },
    {
      "epoch": 5.0402255380595475,
      "grad_norm": 0.198207288980484,
      "learning_rate": 1.8510495641858787e-05,
      "loss": 0.045,
      "step": 73300
    },
    {
      "epoch": 5.047101698411607,
      "grad_norm": 0.11006741225719452,
      "learning_rate": 1.846751594546736e-05,
      "loss": 0.0491,
      "step": 73400
    },
    {
      "epoch": 5.053977858763666,
      "grad_norm": 0.14965631067752838,
      "learning_rate": 1.8424536249075938e-05,
      "loss": 0.0476,
      "step": 73500
    },
    {
      "epoch": 5.060854019115726,
      "grad_norm": 0.1268870234489441,
      "learning_rate": 1.8381556552684512e-05,
      "loss": 0.0492,
      "step": 73600
    },
    {
      "epoch": 5.067730179467786,
      "grad_norm": 0.1391812562942505,
      "learning_rate": 1.8339006653257e-05,
      "loss": 0.0497,
      "step": 73700
    },
    {
      "epoch": 5.074606339819844,
      "grad_norm": 0.12569257616996765,
      "learning_rate": 1.829602695686558e-05,
      "loss": 0.0491,
      "step": 73800
    },
    {
      "epoch": 5.081482500171904,
      "grad_norm": 0.19518272578716278,
      "learning_rate": 1.8253047260474156e-05,
      "loss": 0.0478,
      "step": 73900
    },
    {
      "epoch": 5.088358660523963,
      "grad_norm": 0.10938584059476852,
      "learning_rate": 1.8210067564082726e-05,
      "loss": 0.0506,
      "step": 74000
    },
    {
      "epoch": 5.095234820876023,
      "grad_norm": 0.14974524080753326,
      "learning_rate": 1.8167087867691304e-05,
      "loss": 0.0487,
      "step": 74100
    },
    {
      "epoch": 5.1021109812280825,
      "grad_norm": 0.15482011437416077,
      "learning_rate": 1.8124108171299878e-05,
      "loss": 0.0469,
      "step": 74200
    },
    {
      "epoch": 5.108987141580141,
      "grad_norm": 0.10821209847927094,
      "learning_rate": 1.8081128474908455e-05,
      "loss": 0.0482,
      "step": 74300
    },
    {
      "epoch": 5.115863301932201,
      "grad_norm": 0.16933207213878632,
      "learning_rate": 1.8038148778517032e-05,
      "loss": 0.0498,
      "step": 74400
    },
    {
      "epoch": 5.122739462284261,
      "grad_norm": 0.14753073453903198,
      "learning_rate": 1.7995169082125603e-05,
      "loss": 0.0493,
      "step": 74500
    },
    {
      "epoch": 5.12961562263632,
      "grad_norm": 0.1323249638080597,
      "learning_rate": 1.795218938573418e-05,
      "loss": 0.0497,
      "step": 74600
    },
    {
      "epoch": 5.136491782988379,
      "grad_norm": 0.16851411759853363,
      "learning_rate": 1.7909209689342754e-05,
      "loss": 0.046,
      "step": 74700
    },
    {
      "epoch": 5.143367943340439,
      "grad_norm": 0.18702490627765656,
      "learning_rate": 1.786622999295133e-05,
      "loss": 0.0504,
      "step": 74800
    },
    {
      "epoch": 5.150244103692498,
      "grad_norm": 0.22909463942050934,
      "learning_rate": 1.782325029655991e-05,
      "loss": 0.0486,
      "step": 74900
    },
    {
      "epoch": 5.157120264044558,
      "grad_norm": 0.20731456577777863,
      "learning_rate": 1.778027060016848e-05,
      "loss": 0.0476,
      "step": 75000
    },
    {
      "epoch": 5.1639964243966165,
      "grad_norm": 0.17362022399902344,
      "learning_rate": 1.7737290903777056e-05,
      "loss": 0.0494,
      "step": 75100
    },
    {
      "epoch": 5.170872584748676,
      "grad_norm": 0.20561286807060242,
      "learning_rate": 1.7694311207385634e-05,
      "loss": 0.0477,
      "step": 75200
    },
    {
      "epoch": 5.177748745100736,
      "grad_norm": 0.17305739223957062,
      "learning_rate": 1.7651331510994208e-05,
      "loss": 0.0456,
      "step": 75300
    },
    {
      "epoch": 5.184624905452795,
      "grad_norm": 0.14923293888568878,
      "learning_rate": 1.7608351814602785e-05,
      "loss": 0.0503,
      "step": 75400
    },
    {
      "epoch": 5.191501065804855,
      "grad_norm": 0.1894727647304535,
      "learning_rate": 1.7565372118211355e-05,
      "loss": 0.0494,
      "step": 75500
    },
    {
      "epoch": 5.198377226156914,
      "grad_norm": 0.07308191061019897,
      "learning_rate": 1.7522392421819933e-05,
      "loss": 0.0431,
      "step": 75600
    },
    {
      "epoch": 5.205253386508973,
      "grad_norm": 0.12662988901138306,
      "learning_rate": 1.747941272542851e-05,
      "loss": 0.049,
      "step": 75700
    },
    {
      "epoch": 5.212129546861033,
      "grad_norm": 0.17969845235347748,
      "learning_rate": 1.7436433029037084e-05,
      "loss": 0.0488,
      "step": 75800
    },
    {
      "epoch": 5.219005707213093,
      "grad_norm": 0.17250172793865204,
      "learning_rate": 1.739345333264566e-05,
      "loss": 0.0492,
      "step": 75900
    },
    {
      "epoch": 5.2258818675651515,
      "grad_norm": 0.1728897988796234,
      "learning_rate": 1.735047363625423e-05,
      "loss": 0.0488,
      "step": 76000
    },
    {
      "epoch": 5.232758027917211,
      "grad_norm": 0.12328902631998062,
      "learning_rate": 1.730749393986281e-05,
      "loss": 0.0486,
      "step": 76100
    },
    {
      "epoch": 5.23963418826927,
      "grad_norm": 0.19943386316299438,
      "learning_rate": 1.7264514243471386e-05,
      "loss": 0.0516,
      "step": 76200
    },
    {
      "epoch": 5.24651034862133,
      "grad_norm": 0.27346011996269226,
      "learning_rate": 1.722153454707996e-05,
      "loss": 0.0498,
      "step": 76300
    },
    {
      "epoch": 5.2533865089733895,
      "grad_norm": 0.19795361161231995,
      "learning_rate": 1.7178554850688534e-05,
      "loss": 0.0483,
      "step": 76400
    },
    {
      "epoch": 5.260262669325448,
      "grad_norm": 0.1480417549610138,
      "learning_rate": 1.713557515429711e-05,
      "loss": 0.0495,
      "step": 76500
    },
    {
      "epoch": 5.267138829677508,
      "grad_norm": 0.18303321301937103,
      "learning_rate": 1.7092595457905685e-05,
      "loss": 0.0487,
      "step": 76600
    },
    {
      "epoch": 5.274014990029568,
      "grad_norm": 0.11127611249685287,
      "learning_rate": 1.7049615761514263e-05,
      "loss": 0.0466,
      "step": 76700
    },
    {
      "epoch": 5.280891150381627,
      "grad_norm": 0.07910097390413284,
      "learning_rate": 1.7006636065122837e-05,
      "loss": 0.0476,
      "step": 76800
    },
    {
      "epoch": 5.287767310733686,
      "grad_norm": 0.12872692942619324,
      "learning_rate": 1.696365636873141e-05,
      "loss": 0.0502,
      "step": 76900
    },
    {
      "epoch": 5.294643471085745,
      "grad_norm": 0.16969962418079376,
      "learning_rate": 1.6920676672339988e-05,
      "loss": 0.0472,
      "step": 77000
    },
    {
      "epoch": 5.301519631437805,
      "grad_norm": 0.12055014818906784,
      "learning_rate": 1.687769697594856e-05,
      "loss": 0.0503,
      "step": 77100
    },
    {
      "epoch": 5.308395791789865,
      "grad_norm": 0.08620749413967133,
      "learning_rate": 1.683471727955714e-05,
      "loss": 0.0474,
      "step": 77200
    },
    {
      "epoch": 5.315271952141924,
      "grad_norm": 0.12233346700668335,
      "learning_rate": 1.6791737583165713e-05,
      "loss": 0.0497,
      "step": 77300
    },
    {
      "epoch": 5.322148112493983,
      "grad_norm": 0.15588858723640442,
      "learning_rate": 1.6748757886774287e-05,
      "loss": 0.0488,
      "step": 77400
    },
    {
      "epoch": 5.329024272846043,
      "grad_norm": 0.14576466381549835,
      "learning_rate": 1.6705778190382864e-05,
      "loss": 0.0463,
      "step": 77500
    },
    {
      "epoch": 5.335900433198102,
      "grad_norm": 0.14555563032627106,
      "learning_rate": 1.6662798493991438e-05,
      "loss": 0.0507,
      "step": 77600
    },
    {
      "epoch": 5.342776593550162,
      "grad_norm": 0.1496870070695877,
      "learning_rate": 1.6619818797600015e-05,
      "loss": 0.0493,
      "step": 77700
    },
    {
      "epoch": 5.349652753902221,
      "grad_norm": 0.08969131112098694,
      "learning_rate": 1.6577698695136416e-05,
      "loss": 0.0477,
      "step": 77800
    },
    {
      "epoch": 5.35652891425428,
      "grad_norm": 0.1823236048221588,
      "learning_rate": 1.6534718998744993e-05,
      "loss": 0.0479,
      "step": 77900
    },
    {
      "epoch": 5.36340507460634,
      "grad_norm": 0.15710213780403137,
      "learning_rate": 1.6491739302353567e-05,
      "loss": 0.0494,
      "step": 78000
    },
    {
      "epoch": 5.370281234958399,
      "grad_norm": 0.153098002076149,
      "learning_rate": 1.6448759605962145e-05,
      "loss": 0.0477,
      "step": 78100
    },
    {
      "epoch": 5.3771573953104586,
      "grad_norm": 0.24137037992477417,
      "learning_rate": 1.6405779909570722e-05,
      "loss": 0.0477,
      "step": 78200
    },
    {
      "epoch": 5.384033555662518,
      "grad_norm": 0.1271142214536667,
      "learning_rate": 1.6362800213179292e-05,
      "loss": 0.0475,
      "step": 78300
    },
    {
      "epoch": 5.390909716014577,
      "grad_norm": 0.16202981770038605,
      "learning_rate": 1.631982051678787e-05,
      "loss": 0.0499,
      "step": 78400
    },
    {
      "epoch": 5.397785876366637,
      "grad_norm": 0.22067545354366302,
      "learning_rate": 1.6276840820396447e-05,
      "loss": 0.0501,
      "step": 78500
    },
    {
      "epoch": 5.404662036718697,
      "grad_norm": 0.20635096728801727,
      "learning_rate": 1.623386112400502e-05,
      "loss": 0.0493,
      "step": 78600
    },
    {
      "epoch": 5.4115381970707555,
      "grad_norm": 0.15589186549186707,
      "learning_rate": 1.6190881427613598e-05,
      "loss": 0.0478,
      "step": 78700
    },
    {
      "epoch": 5.418414357422815,
      "grad_norm": 0.15628767013549805,
      "learning_rate": 1.614790173122217e-05,
      "loss": 0.047,
      "step": 78800
    },
    {
      "epoch": 5.425290517774875,
      "grad_norm": 0.18016931414604187,
      "learning_rate": 1.6104922034830746e-05,
      "loss": 0.0492,
      "step": 78900
    },
    {
      "epoch": 5.432166678126934,
      "grad_norm": 0.11329294741153717,
      "learning_rate": 1.6061942338439323e-05,
      "loss": 0.0494,
      "step": 79000
    },
    {
      "epoch": 5.4390428384789935,
      "grad_norm": 0.10778806358575821,
      "learning_rate": 1.6018962642047897e-05,
      "loss": 0.0468,
      "step": 79100
    },
    {
      "epoch": 5.445918998831052,
      "grad_norm": 0.10589610040187836,
      "learning_rate": 1.5975982945656475e-05,
      "loss": 0.0484,
      "step": 79200
    },
    {
      "epoch": 5.452795159183112,
      "grad_norm": 0.13598451018333435,
      "learning_rate": 1.5933003249265045e-05,
      "loss": 0.0472,
      "step": 79300
    },
    {
      "epoch": 5.459671319535172,
      "grad_norm": 0.16111600399017334,
      "learning_rate": 1.5890023552873622e-05,
      "loss": 0.0479,
      "step": 79400
    },
    {
      "epoch": 5.466547479887231,
      "grad_norm": 0.16695737838745117,
      "learning_rate": 1.58470438564822e-05,
      "loss": 0.0491,
      "step": 79500
    },
    {
      "epoch": 5.47342364023929,
      "grad_norm": 0.10734222084283829,
      "learning_rate": 1.5804064160090774e-05,
      "loss": 0.05,
      "step": 79600
    },
    {
      "epoch": 5.48029980059135,
      "grad_norm": 0.08841006457805634,
      "learning_rate": 1.576108446369935e-05,
      "loss": 0.047,
      "step": 79700
    },
    {
      "epoch": 5.487175960943409,
      "grad_norm": 0.2122567892074585,
      "learning_rate": 1.5718104767307925e-05,
      "loss": 0.0505,
      "step": 79800
    },
    {
      "epoch": 5.494052121295469,
      "grad_norm": 0.1673683077096939,
      "learning_rate": 1.56751250709165e-05,
      "loss": 0.0477,
      "step": 79900
    },
    {
      "epoch": 5.5009282816475285,
      "grad_norm": 0.13059347867965698,
      "learning_rate": 1.5632145374525076e-05,
      "loss": 0.0484,
      "step": 80000
    },
    {
      "epoch": 5.507804441999587,
      "grad_norm": 0.18031704425811768,
      "learning_rate": 1.558916567813365e-05,
      "loss": 0.048,
      "step": 80100
    },
    {
      "epoch": 5.514680602351647,
      "grad_norm": 0.1672086864709854,
      "learning_rate": 1.5546185981742227e-05,
      "loss": 0.0496,
      "step": 80200
    },
    {
      "epoch": 5.521556762703706,
      "grad_norm": 0.13020305335521698,
      "learning_rate": 1.55032062853508e-05,
      "loss": 0.0464,
      "step": 80300
    },
    {
      "epoch": 5.528432923055766,
      "grad_norm": 0.11730258166790009,
      "learning_rate": 1.5460226588959375e-05,
      "loss": 0.0496,
      "step": 80400
    },
    {
      "epoch": 5.535309083407825,
      "grad_norm": 0.09668248146772385,
      "learning_rate": 1.5417246892567952e-05,
      "loss": 0.0485,
      "step": 80500
    },
    {
      "epoch": 5.542185243759884,
      "grad_norm": 0.11707381159067154,
      "learning_rate": 1.537426719617653e-05,
      "loss": 0.0497,
      "step": 80600
    },
    {
      "epoch": 5.549061404111944,
      "grad_norm": 0.1347682625055313,
      "learning_rate": 1.5331287499785104e-05,
      "loss": 0.0466,
      "step": 80700
    },
    {
      "epoch": 5.555937564464004,
      "grad_norm": 0.13802623748779297,
      "learning_rate": 1.5288307803393677e-05,
      "loss": 0.0491,
      "step": 80800
    },
    {
      "epoch": 5.5628137248160625,
      "grad_norm": 0.23284867405891418,
      "learning_rate": 1.5245328107002251e-05,
      "loss": 0.0479,
      "step": 80900
    },
    {
      "epoch": 5.569689885168122,
      "grad_norm": 0.13501013815402985,
      "learning_rate": 1.5202348410610829e-05,
      "loss": 0.0496,
      "step": 81000
    },
    {
      "epoch": 5.576566045520181,
      "grad_norm": 0.15784141421318054,
      "learning_rate": 1.5159368714219404e-05,
      "loss": 0.0499,
      "step": 81100
    },
    {
      "epoch": 5.583442205872241,
      "grad_norm": 0.20949888229370117,
      "learning_rate": 1.5116389017827978e-05,
      "loss": 0.0482,
      "step": 81200
    },
    {
      "epoch": 5.590318366224301,
      "grad_norm": 0.1744917333126068,
      "learning_rate": 1.5073409321436554e-05,
      "loss": 0.0489,
      "step": 81300
    },
    {
      "epoch": 5.597194526576359,
      "grad_norm": 0.16879625618457794,
      "learning_rate": 1.5030429625045128e-05,
      "loss": 0.0486,
      "step": 81400
    },
    {
      "epoch": 5.604070686928419,
      "grad_norm": 0.10996562242507935,
      "learning_rate": 1.4987449928653705e-05,
      "loss": 0.0487,
      "step": 81500
    },
    {
      "epoch": 5.610946847280479,
      "grad_norm": 0.11683648824691772,
      "learning_rate": 1.494447023226228e-05,
      "loss": 0.0488,
      "step": 81600
    },
    {
      "epoch": 5.617823007632538,
      "grad_norm": 0.16789136826992035,
      "learning_rate": 1.4901490535870855e-05,
      "loss": 0.0466,
      "step": 81700
    },
    {
      "epoch": 5.6246991679845975,
      "grad_norm": 0.12952572107315063,
      "learning_rate": 1.485851083947943e-05,
      "loss": 0.049,
      "step": 81800
    },
    {
      "epoch": 5.631575328336657,
      "grad_norm": 0.2239399552345276,
      "learning_rate": 1.4815960940051921e-05,
      "loss": 0.0504,
      "step": 81900
    },
    {
      "epoch": 5.638451488688716,
      "grad_norm": 0.1385517716407776,
      "learning_rate": 1.4772981243660495e-05,
      "loss": 0.0498,
      "step": 82000
    },
    {
      "epoch": 5.645327649040776,
      "grad_norm": 0.15399794280529022,
      "learning_rate": 1.473000154726907e-05,
      "loss": 0.046,
      "step": 82100
    },
    {
      "epoch": 5.6522038093928355,
      "grad_norm": 0.18826591968536377,
      "learning_rate": 1.4687021850877648e-05,
      "loss": 0.0485,
      "step": 82200
    },
    {
      "epoch": 5.659079969744894,
      "grad_norm": 0.18940730392932892,
      "learning_rate": 1.464404215448622e-05,
      "loss": 0.0475,
      "step": 82300
    },
    {
      "epoch": 5.665956130096954,
      "grad_norm": 0.1152840331196785,
      "learning_rate": 1.4601062458094797e-05,
      "loss": 0.0473,
      "step": 82400
    },
    {
      "epoch": 5.672832290449013,
      "grad_norm": 0.13691438734531403,
      "learning_rate": 1.4558082761703373e-05,
      "loss": 0.0481,
      "step": 82500
    },
    {
      "epoch": 5.679708450801073,
      "grad_norm": 0.20241372287273407,
      "learning_rate": 1.4515103065311947e-05,
      "loss": 0.0503,
      "step": 82600
    },
    {
      "epoch": 5.686584611153132,
      "grad_norm": 0.15921853482723236,
      "learning_rate": 1.4472123368920524e-05,
      "loss": 0.0486,
      "step": 82700
    },
    {
      "epoch": 5.693460771505191,
      "grad_norm": 0.11491748690605164,
      "learning_rate": 1.4429143672529096e-05,
      "loss": 0.049,
      "step": 82800
    },
    {
      "epoch": 5.700336931857251,
      "grad_norm": 0.1311241239309311,
      "learning_rate": 1.4386163976137674e-05,
      "loss": 0.0465,
      "step": 82900
    },
    {
      "epoch": 5.70721309220931,
      "grad_norm": 0.12982934713363647,
      "learning_rate": 1.4343184279746249e-05,
      "loss": 0.0483,
      "step": 83000
    },
    {
      "epoch": 5.71408925256137,
      "grad_norm": 0.1244112178683281,
      "learning_rate": 1.4300204583354823e-05,
      "loss": 0.0479,
      "step": 83100
    },
    {
      "epoch": 5.720965412913429,
      "grad_norm": 0.18377496302127838,
      "learning_rate": 1.42572248869634e-05,
      "loss": 0.0495,
      "step": 83200
    },
    {
      "epoch": 5.727841573265488,
      "grad_norm": 0.18439888954162598,
      "learning_rate": 1.4214245190571973e-05,
      "loss": 0.0505,
      "step": 83300
    },
    {
      "epoch": 5.734717733617548,
      "grad_norm": 0.19733931124210358,
      "learning_rate": 1.4171695291144463e-05,
      "loss": 0.0485,
      "step": 83400
    },
    {
      "epoch": 5.741593893969608,
      "grad_norm": 0.32193422317504883,
      "learning_rate": 1.4128715594753039e-05,
      "loss": 0.0512,
      "step": 83500
    },
    {
      "epoch": 5.7484700543216665,
      "grad_norm": 0.21212033927440643,
      "learning_rate": 1.4085735898361616e-05,
      "loss": 0.0478,
      "step": 83600
    },
    {
      "epoch": 5.755346214673726,
      "grad_norm": 0.14117532968521118,
      "learning_rate": 1.4042756201970188e-05,
      "loss": 0.0495,
      "step": 83700
    },
    {
      "epoch": 5.762222375025786,
      "grad_norm": 0.15136349201202393,
      "learning_rate": 1.3999776505578766e-05,
      "loss": 0.0472,
      "step": 83800
    },
    {
      "epoch": 5.769098535377845,
      "grad_norm": 0.15195448696613312,
      "learning_rate": 1.3956796809187341e-05,
      "loss": 0.0478,
      "step": 83900
    },
    {
      "epoch": 5.7759746957299045,
      "grad_norm": 0.15422536432743073,
      "learning_rate": 1.3913817112795915e-05,
      "loss": 0.0481,
      "step": 84000
    },
    {
      "epoch": 5.782850856081964,
      "grad_norm": 0.16872315108776093,
      "learning_rate": 1.3870837416404493e-05,
      "loss": 0.0482,
      "step": 84100
    },
    {
      "epoch": 5.789727016434023,
      "grad_norm": 0.17819790542125702,
      "learning_rate": 1.3827857720013065e-05,
      "loss": 0.0485,
      "step": 84200
    },
    {
      "epoch": 5.796603176786083,
      "grad_norm": 0.21069926023483276,
      "learning_rate": 1.3784878023621642e-05,
      "loss": 0.0499,
      "step": 84300
    },
    {
      "epoch": 5.803479337138142,
      "grad_norm": 0.18354474008083344,
      "learning_rate": 1.3741898327230218e-05,
      "loss": 0.0499,
      "step": 84400
    },
    {
      "epoch": 5.810355497490201,
      "grad_norm": 0.14842644333839417,
      "learning_rate": 1.3698918630838792e-05,
      "loss": 0.0508,
      "step": 84500
    },
    {
      "epoch": 5.817231657842261,
      "grad_norm": 0.13018904626369476,
      "learning_rate": 1.3655938934447369e-05,
      "loss": 0.0481,
      "step": 84600
    },
    {
      "epoch": 5.82410781819432,
      "grad_norm": 0.13143974542617798,
      "learning_rate": 1.3612959238055941e-05,
      "loss": 0.0474,
      "step": 84700
    },
    {
      "epoch": 5.83098397854638,
      "grad_norm": 0.05018870532512665,
      "learning_rate": 1.3569979541664518e-05,
      "loss": 0.0474,
      "step": 84800
    },
    {
      "epoch": 5.8378601388984395,
      "grad_norm": 0.11978460848331451,
      "learning_rate": 1.3526999845273094e-05,
      "loss": 0.0501,
      "step": 84900
    },
    {
      "epoch": 5.844736299250498,
      "grad_norm": 0.21945767104625702,
      "learning_rate": 1.3484020148881668e-05,
      "loss": 0.0477,
      "step": 85000
    },
    {
      "epoch": 5.851612459602558,
      "grad_norm": 0.20146459341049194,
      "learning_rate": 1.3441040452490245e-05,
      "loss": 0.0476,
      "step": 85100
    },
    {
      "epoch": 5.858488619954617,
      "grad_norm": 0.20350155234336853,
      "learning_rate": 1.339806075609882e-05,
      "loss": 0.0466,
      "step": 85200
    },
    {
      "epoch": 5.865364780306677,
      "grad_norm": 0.1772884726524353,
      "learning_rate": 1.3355081059707395e-05,
      "loss": 0.0467,
      "step": 85300
    },
    {
      "epoch": 5.872240940658736,
      "grad_norm": 0.1562984734773636,
      "learning_rate": 1.331210136331597e-05,
      "loss": 0.0491,
      "step": 85400
    },
    {
      "epoch": 5.879117101010795,
      "grad_norm": 0.18082305788993835,
      "learning_rate": 1.3269121666924544e-05,
      "loss": 0.0478,
      "step": 85500
    },
    {
      "epoch": 5.885993261362855,
      "grad_norm": 0.16665136814117432,
      "learning_rate": 1.3226141970533122e-05,
      "loss": 0.047,
      "step": 85600
    },
    {
      "epoch": 5.892869421714915,
      "grad_norm": 0.13583192229270935,
      "learning_rate": 1.3183162274141697e-05,
      "loss": 0.0502,
      "step": 85700
    },
    {
      "epoch": 5.8997455820669735,
      "grad_norm": 0.13960468769073486,
      "learning_rate": 1.3140182577750271e-05,
      "loss": 0.0496,
      "step": 85800
    },
    {
      "epoch": 5.906621742419033,
      "grad_norm": 0.19897447526454926,
      "learning_rate": 1.3097202881358847e-05,
      "loss": 0.0473,
      "step": 85900
    },
    {
      "epoch": 5.913497902771093,
      "grad_norm": 0.13728925585746765,
      "learning_rate": 1.305422318496742e-05,
      "loss": 0.0458,
      "step": 86000
    },
    {
      "epoch": 5.920374063123152,
      "grad_norm": 0.1755548119544983,
      "learning_rate": 1.3011243488575998e-05,
      "loss": 0.0475,
      "step": 86100
    },
    {
      "epoch": 5.927250223475212,
      "grad_norm": 0.1262843757867813,
      "learning_rate": 1.2968263792184574e-05,
      "loss": 0.0469,
      "step": 86200
    },
    {
      "epoch": 5.934126383827271,
      "grad_norm": 0.1349143534898758,
      "learning_rate": 1.2925284095793147e-05,
      "loss": 0.048,
      "step": 86300
    },
    {
      "epoch": 5.94100254417933,
      "grad_norm": 0.15513311326503754,
      "learning_rate": 1.2882304399401723e-05,
      "loss": 0.0493,
      "step": 86400
    },
    {
      "epoch": 5.94787870453139,
      "grad_norm": 0.12051917612552643,
      "learning_rate": 1.2839754499974214e-05,
      "loss": 0.0492,
      "step": 86500
    },
    {
      "epoch": 5.954754864883449,
      "grad_norm": 0.12666736543178558,
      "learning_rate": 1.2797204600546703e-05,
      "loss": 0.0483,
      "step": 86600
    },
    {
      "epoch": 5.9616310252355085,
      "grad_norm": 0.13095174729824066,
      "learning_rate": 1.2754224904155277e-05,
      "loss": 0.0482,
      "step": 86700
    },
    {
      "epoch": 5.968507185587568,
      "grad_norm": 0.10391464829444885,
      "learning_rate": 1.2711245207763852e-05,
      "loss": 0.0484,
      "step": 86800
    },
    {
      "epoch": 5.975383345939627,
      "grad_norm": 0.2763872444629669,
      "learning_rate": 1.266826551137243e-05,
      "loss": 0.051,
      "step": 86900
    },
    {
      "epoch": 5.982259506291687,
      "grad_norm": 0.12615877389907837,
      "learning_rate": 1.2625285814981004e-05,
      "loss": 0.0447,
      "step": 87000
    },
    {
      "epoch": 5.989135666643746,
      "grad_norm": 0.12022920697927475,
      "learning_rate": 1.258230611858958e-05,
      "loss": 0.0502,
      "step": 87100
    },
    {
      "epoch": 5.996011826995805,
      "grad_norm": 0.15996621549129486,
      "learning_rate": 1.2539326422198155e-05,
      "loss": 0.048,
      "step": 87200
    },
    {
      "epoch": 6.0,
      "eval_accuracy_macro_0.5": 0.9782238006591797,
      "eval_accuracy_micro_0.5": 0.9782239198684692,
      "eval_accuracy_weighted_0.5": 0.975520133972168,
      "eval_f1_macro_0.5": 0.6999276876449585,
      "eval_f1_macro_0.6": 0.6730248928070068,
      "eval_f1_macro_0.7": 0.6278766393661499,
      "eval_f1_macro_0.8": 0.4180956482887268,
      "eval_f1_micro_0.5": 0.7077109813690186,
      "eval_f1_micro_0.6": 0.6876357793807983,
      "eval_f1_micro_0.7": 0.6498966217041016,
      "eval_f1_micro_0.8": 0.5837324261665344,
      "eval_f1_micro_0.9": 0.4463295340538025,
      "eval_f1_weighted_0.5": 0.696983277797699,
      "eval_f1_weighted_0.6": 0.6697799563407898,
      "eval_f1_weighted_0.7": 0.6236535906791687,
      "eval_f1_weighted_0.8": 0.40294307470321655,
      "eval_loss": 0.04531952738761902,
      "eval_runtime": 140.0944,
      "eval_samples_per_second": 207.267,
      "eval_steps_per_second": 25.911,
      "step": 87258
    },
    {
      "epoch": 6.002887987347865,
      "grad_norm": 0.13707953691482544,
      "learning_rate": 1.2496346725806729e-05,
      "loss": 0.048,
      "step": 87300
    },
    {
      "epoch": 6.009764147699924,
      "grad_norm": 0.1606263667345047,
      "learning_rate": 1.2453367029415306e-05,
      "loss": 0.0488,
      "step": 87400
    },
    {
      "epoch": 6.016640308051984,
      "grad_norm": 0.1784173548221588,
      "learning_rate": 1.241038733302388e-05,
      "loss": 0.0462,
      "step": 87500
    },
    {
      "epoch": 6.023516468404043,
      "grad_norm": 0.26009732484817505,
      "learning_rate": 1.2367407636632455e-05,
      "loss": 0.0483,
      "step": 87600
    },
    {
      "epoch": 6.030392628756102,
      "grad_norm": 0.17785286903381348,
      "learning_rate": 1.2324427940241031e-05,
      "loss": 0.0497,
      "step": 87700
    },
    {
      "epoch": 6.037268789108162,
      "grad_norm": 0.15181607007980347,
      "learning_rate": 1.2281448243849605e-05,
      "loss": 0.0459,
      "step": 87800
    },
    {
      "epoch": 6.044144949460222,
      "grad_norm": 0.11214988678693771,
      "learning_rate": 1.2238468547458182e-05,
      "loss": 0.051,
      "step": 87900
    },
    {
      "epoch": 6.051021109812281,
      "grad_norm": 0.18369175493717194,
      "learning_rate": 1.2195488851066756e-05,
      "loss": 0.0444,
      "step": 88000
    },
    {
      "epoch": 6.05789727016434,
      "grad_norm": 0.26353591680526733,
      "learning_rate": 1.2152509154675332e-05,
      "loss": 0.045,
      "step": 88100
    },
    {
      "epoch": 6.0647734305164,
      "grad_norm": 0.14287282526493073,
      "learning_rate": 1.2109529458283907e-05,
      "loss": 0.0477,
      "step": 88200
    },
    {
      "epoch": 6.071649590868459,
      "grad_norm": 0.0963377133011818,
      "learning_rate": 1.2066549761892483e-05,
      "loss": 0.0474,
      "step": 88300
    },
    {
      "epoch": 6.078525751220519,
      "grad_norm": 0.13292260468006134,
      "learning_rate": 1.2023570065501059e-05,
      "loss": 0.0481,
      "step": 88400
    },
    {
      "epoch": 6.0854019115725775,
      "grad_norm": 0.1976703405380249,
      "learning_rate": 1.1980590369109633e-05,
      "loss": 0.0511,
      "step": 88500
    },
    {
      "epoch": 6.092278071924637,
      "grad_norm": 0.2329275757074356,
      "learning_rate": 1.1937610672718208e-05,
      "loss": 0.0512,
      "step": 88600
    },
    {
      "epoch": 6.099154232276697,
      "grad_norm": 0.14546766877174377,
      "learning_rate": 1.1894630976326784e-05,
      "loss": 0.0452,
      "step": 88700
    },
    {
      "epoch": 6.106030392628756,
      "grad_norm": 0.20673151314258575,
      "learning_rate": 1.185165127993536e-05,
      "loss": 0.0497,
      "step": 88800
    },
    {
      "epoch": 6.1129065529808155,
      "grad_norm": 0.13231398165225983,
      "learning_rate": 1.1808671583543935e-05,
      "loss": 0.047,
      "step": 88900
    },
    {
      "epoch": 6.119782713332875,
      "grad_norm": 0.15644048154354095,
      "learning_rate": 1.1765691887152509e-05,
      "loss": 0.0476,
      "step": 89000
    },
    {
      "epoch": 6.126658873684934,
      "grad_norm": 0.18418507277965546,
      "learning_rate": 1.1722712190761086e-05,
      "loss": 0.0501,
      "step": 89100
    },
    {
      "epoch": 6.133535034036994,
      "grad_norm": 0.20936287939548492,
      "learning_rate": 1.167973249436966e-05,
      "loss": 0.0511,
      "step": 89200
    },
    {
      "epoch": 6.140411194389053,
      "grad_norm": 0.16742117702960968,
      "learning_rate": 1.1636752797978236e-05,
      "loss": 0.0461,
      "step": 89300
    },
    {
      "epoch": 6.147287354741112,
      "grad_norm": 0.21444450318813324,
      "learning_rate": 1.1593773101586811e-05,
      "loss": 0.0469,
      "step": 89400
    },
    {
      "epoch": 6.154163515093172,
      "grad_norm": 0.19453896582126617,
      "learning_rate": 1.1550793405195385e-05,
      "loss": 0.0462,
      "step": 89500
    },
    {
      "epoch": 6.161039675445231,
      "grad_norm": 0.12694872915744781,
      "learning_rate": 1.1507813708803963e-05,
      "loss": 0.0477,
      "step": 89600
    },
    {
      "epoch": 6.167915835797291,
      "grad_norm": 0.1628822386264801,
      "learning_rate": 1.1464834012412536e-05,
      "loss": 0.0477,
      "step": 89700
    },
    {
      "epoch": 6.1747919961493505,
      "grad_norm": 0.11921744793653488,
      "learning_rate": 1.1421854316021112e-05,
      "loss": 0.0501,
      "step": 89800
    },
    {
      "epoch": 6.181668156501409,
      "grad_norm": 0.21519218385219574,
      "learning_rate": 1.1378874619629688e-05,
      "loss": 0.0498,
      "step": 89900
    },
    {
      "epoch": 6.188544316853469,
      "grad_norm": 0.13151578605175018,
      "learning_rate": 1.1335894923238263e-05,
      "loss": 0.0488,
      "step": 90000
    },
    {
      "epoch": 6.195420477205529,
      "grad_norm": 0.16967803239822388,
      "learning_rate": 1.1292915226846839e-05,
      "loss": 0.0479,
      "step": 90100
    },
    {
      "epoch": 6.202296637557588,
      "grad_norm": 0.18140779435634613,
      "learning_rate": 1.1249935530455413e-05,
      "loss": 0.0482,
      "step": 90200
    },
    {
      "epoch": 6.209172797909647,
      "grad_norm": 0.2370729148387909,
      "learning_rate": 1.1206955834063988e-05,
      "loss": 0.0474,
      "step": 90300
    },
    {
      "epoch": 6.216048958261707,
      "grad_norm": 0.13994769752025604,
      "learning_rate": 1.1163976137672564e-05,
      "loss": 0.048,
      "step": 90400
    },
    {
      "epoch": 6.222925118613766,
      "grad_norm": 0.10387073457241058,
      "learning_rate": 1.112099644128114e-05,
      "loss": 0.0503,
      "step": 90500
    },
    {
      "epoch": 6.229801278965826,
      "grad_norm": 0.15675784647464752,
      "learning_rate": 1.1078016744889715e-05,
      "loss": 0.046,
      "step": 90600
    },
    {
      "epoch": 6.2366774393178845,
      "grad_norm": 0.08062180131673813,
      "learning_rate": 1.1035037048498289e-05,
      "loss": 0.0479,
      "step": 90700
    },
    {
      "epoch": 6.243553599669944,
      "grad_norm": 0.1585298329591751,
      "learning_rate": 1.0992057352106866e-05,
      "loss": 0.049,
      "step": 90800
    },
    {
      "epoch": 6.250429760022004,
      "grad_norm": 0.1821749061346054,
      "learning_rate": 1.094907765571544e-05,
      "loss": 0.0477,
      "step": 90900
    },
    {
      "epoch": 6.257305920374063,
      "grad_norm": 0.08879279345273972,
      "learning_rate": 1.0906097959324016e-05,
      "loss": 0.0489,
      "step": 91000
    },
    {
      "epoch": 6.264182080726123,
      "grad_norm": 0.15232902765274048,
      "learning_rate": 1.0863118262932592e-05,
      "loss": 0.0496,
      "step": 91100
    },
    {
      "epoch": 6.271058241078182,
      "grad_norm": 0.16426442563533783,
      "learning_rate": 1.0820138566541165e-05,
      "loss": 0.0491,
      "step": 91200
    },
    {
      "epoch": 6.277934401430241,
      "grad_norm": 0.0909295529127121,
      "learning_rate": 1.0777158870149743e-05,
      "loss": 0.0463,
      "step": 91300
    },
    {
      "epoch": 6.284810561782301,
      "grad_norm": 0.16671602427959442,
      "learning_rate": 1.0734179173758317e-05,
      "loss": 0.0491,
      "step": 91400
    },
    {
      "epoch": 6.29168672213436,
      "grad_norm": 0.28602737188339233,
      "learning_rate": 1.0691199477366892e-05,
      "loss": 0.0481,
      "step": 91500
    },
    {
      "epoch": 6.2985628824864195,
      "grad_norm": 0.26089993119239807,
      "learning_rate": 1.0648219780975468e-05,
      "loss": 0.0479,
      "step": 91600
    },
    {
      "epoch": 6.305439042838479,
      "grad_norm": 0.1486576646566391,
      "learning_rate": 1.0605240084584043e-05,
      "loss": 0.0498,
      "step": 91700
    },
    {
      "epoch": 6.312315203190538,
      "grad_norm": 0.1391456574201584,
      "learning_rate": 1.0562260388192619e-05,
      "loss": 0.0496,
      "step": 91800
    },
    {
      "epoch": 6.319191363542598,
      "grad_norm": 0.0852450281381607,
      "learning_rate": 1.0519280691801193e-05,
      "loss": 0.0473,
      "step": 91900
    },
    {
      "epoch": 6.3260675238946575,
      "grad_norm": 0.11256607621908188,
      "learning_rate": 1.0476300995409769e-05,
      "loss": 0.0472,
      "step": 92000
    },
    {
      "epoch": 6.332943684246716,
      "grad_norm": 0.14319546520709991,
      "learning_rate": 1.0433321299018344e-05,
      "loss": 0.0448,
      "step": 92100
    },
    {
      "epoch": 6.339819844598776,
      "grad_norm": 0.13412515819072723,
      "learning_rate": 1.039034160262692e-05,
      "loss": 0.0477,
      "step": 92200
    },
    {
      "epoch": 6.346696004950836,
      "grad_norm": 0.2089449167251587,
      "learning_rate": 1.0347361906235495e-05,
      "loss": 0.0499,
      "step": 92300
    },
    {
      "epoch": 6.353572165302895,
      "grad_norm": 0.24262677133083344,
      "learning_rate": 1.030438220984407e-05,
      "loss": 0.0483,
      "step": 92400
    },
    {
      "epoch": 6.360448325654954,
      "grad_norm": 0.17770427465438843,
      "learning_rate": 1.0261402513452645e-05,
      "loss": 0.0507,
      "step": 92500
    },
    {
      "epoch": 6.367324486007013,
      "grad_norm": 0.13342440128326416,
      "learning_rate": 1.0218852614025134e-05,
      "loss": 0.0467,
      "step": 92600
    },
    {
      "epoch": 6.374200646359073,
      "grad_norm": 0.16426800191402435,
      "learning_rate": 1.0175872917633711e-05,
      "loss": 0.0492,
      "step": 92700
    },
    {
      "epoch": 6.381076806711133,
      "grad_norm": 0.19422771036624908,
      "learning_rate": 1.0132893221242285e-05,
      "loss": 0.049,
      "step": 92800
    },
    {
      "epoch": 6.387952967063192,
      "grad_norm": 0.2606302797794342,
      "learning_rate": 1.008991352485086e-05,
      "loss": 0.048,
      "step": 92900
    },
    {
      "epoch": 6.394829127415251,
      "grad_norm": 0.08829638361930847,
      "learning_rate": 1.0046933828459436e-05,
      "loss": 0.0482,
      "step": 93000
    },
    {
      "epoch": 6.401705287767311,
      "grad_norm": 0.14470958709716797,
      "learning_rate": 1.0003954132068012e-05,
      "loss": 0.0464,
      "step": 93100
    },
    {
      "epoch": 6.40858144811937,
      "grad_norm": 0.13474337756633759,
      "learning_rate": 9.960974435676588e-06,
      "loss": 0.0468,
      "step": 93200
    },
    {
      "epoch": 6.41545760847143,
      "grad_norm": 0.22742906212806702,
      "learning_rate": 9.917994739285162e-06,
      "loss": 0.048,
      "step": 93300
    },
    {
      "epoch": 6.4223337688234885,
      "grad_norm": 0.08628911525011063,
      "learning_rate": 9.875015042893737e-06,
      "loss": 0.0458,
      "step": 93400
    },
    {
      "epoch": 6.429209929175548,
      "grad_norm": 0.1303044557571411,
      "learning_rate": 9.832035346502313e-06,
      "loss": 0.045,
      "step": 93500
    },
    {
      "epoch": 6.436086089527608,
      "grad_norm": 0.24588552117347717,
      "learning_rate": 9.789055650110888e-06,
      "loss": 0.0491,
      "step": 93600
    },
    {
      "epoch": 6.442962249879667,
      "grad_norm": 0.12056092172861099,
      "learning_rate": 9.746075953719464e-06,
      "loss": 0.0455,
      "step": 93700
    },
    {
      "epoch": 6.4498384102317265,
      "grad_norm": 0.13925926387310028,
      "learning_rate": 9.703096257328038e-06,
      "loss": 0.0468,
      "step": 93800
    },
    {
      "epoch": 6.456714570583786,
      "grad_norm": 0.18575328588485718,
      "learning_rate": 9.660116560936613e-06,
      "loss": 0.049,
      "step": 93900
    },
    {
      "epoch": 6.463590730935845,
      "grad_norm": 0.12227436900138855,
      "learning_rate": 9.617136864545189e-06,
      "loss": 0.0452,
      "step": 94000
    },
    {
      "epoch": 6.470466891287905,
      "grad_norm": 0.12726496160030365,
      "learning_rate": 9.574157168153765e-06,
      "loss": 0.0497,
      "step": 94100
    },
    {
      "epoch": 6.477343051639965,
      "grad_norm": 0.2083839476108551,
      "learning_rate": 9.53117747176234e-06,
      "loss": 0.0471,
      "step": 94200
    },
    {
      "epoch": 6.4842192119920234,
      "grad_norm": 0.1852038949728012,
      "learning_rate": 9.488197775370914e-06,
      "loss": 0.0457,
      "step": 94300
    },
    {
      "epoch": 6.491095372344083,
      "grad_norm": 0.09254592657089233,
      "learning_rate": 9.445647875943405e-06,
      "loss": 0.0472,
      "step": 94400
    },
    {
      "epoch": 6.497971532696143,
      "grad_norm": 0.12931299209594727,
      "learning_rate": 9.402668179551979e-06,
      "loss": 0.0458,
      "step": 94500
    },
    {
      "epoch": 6.504847693048202,
      "grad_norm": 0.14690303802490234,
      "learning_rate": 9.359688483160556e-06,
      "loss": 0.0468,
      "step": 94600
    },
    {
      "epoch": 6.5117238534002615,
      "grad_norm": 0.09094008058309555,
      "learning_rate": 9.31670878676913e-06,
      "loss": 0.0455,
      "step": 94700
    },
    {
      "epoch": 6.51860001375232,
      "grad_norm": 0.17577499151229858,
      "learning_rate": 9.273729090377706e-06,
      "loss": 0.0488,
      "step": 94800
    },
    {
      "epoch": 6.52547617410438,
      "grad_norm": 0.16725078225135803,
      "learning_rate": 9.230749393986281e-06,
      "loss": 0.0449,
      "step": 94900
    },
    {
      "epoch": 6.53235233445644,
      "grad_norm": 0.2189362496137619,
      "learning_rate": 9.187769697594857e-06,
      "loss": 0.0484,
      "step": 95000
    },
    {
      "epoch": 6.539228494808499,
      "grad_norm": 0.10330859571695328,
      "learning_rate": 9.144790001203432e-06,
      "loss": 0.0459,
      "step": 95100
    },
    {
      "epoch": 6.546104655160558,
      "grad_norm": 0.16764706373214722,
      "learning_rate": 9.101810304812006e-06,
      "loss": 0.051,
      "step": 95200
    },
    {
      "epoch": 6.552980815512618,
      "grad_norm": 0.18031781911849976,
      "learning_rate": 9.058830608420582e-06,
      "loss": 0.0481,
      "step": 95300
    },
    {
      "epoch": 6.559856975864677,
      "grad_norm": 0.18608328700065613,
      "learning_rate": 9.015850912029158e-06,
      "loss": 0.0455,
      "step": 95400
    },
    {
      "epoch": 6.566733136216737,
      "grad_norm": 0.10135911405086517,
      "learning_rate": 8.972871215637733e-06,
      "loss": 0.0454,
      "step": 95500
    },
    {
      "epoch": 6.573609296568796,
      "grad_norm": 0.2190857082605362,
      "learning_rate": 8.929891519246309e-06,
      "loss": 0.0472,
      "step": 95600
    },
    {
      "epoch": 6.580485456920855,
      "grad_norm": 0.13655951619148254,
      "learning_rate": 8.886911822854883e-06,
      "loss": 0.0515,
      "step": 95700
    },
    {
      "epoch": 6.587361617272915,
      "grad_norm": 0.10279934853315353,
      "learning_rate": 8.84393212646346e-06,
      "loss": 0.0489,
      "step": 95800
    },
    {
      "epoch": 6.594237777624974,
      "grad_norm": 0.1926049441099167,
      "learning_rate": 8.800952430072034e-06,
      "loss": 0.0484,
      "step": 95900
    },
    {
      "epoch": 6.601113937977034,
      "grad_norm": 0.1342141181230545,
      "learning_rate": 8.75797273368061e-06,
      "loss": 0.0465,
      "step": 96000
    },
    {
      "epoch": 6.607990098329093,
      "grad_norm": 0.1763480305671692,
      "learning_rate": 8.714993037289185e-06,
      "loss": 0.0478,
      "step": 96100
    },
    {
      "epoch": 6.614866258681152,
      "grad_norm": 0.171547994017601,
      "learning_rate": 8.672013340897759e-06,
      "loss": 0.0467,
      "step": 96200
    },
    {
      "epoch": 6.621742419033212,
      "grad_norm": 0.24666504561901093,
      "learning_rate": 8.629033644506336e-06,
      "loss": 0.0484,
      "step": 96300
    },
    {
      "epoch": 6.628618579385272,
      "grad_norm": 0.17594915628433228,
      "learning_rate": 8.58605394811491e-06,
      "loss": 0.0459,
      "step": 96400
    },
    {
      "epoch": 6.6354947397373305,
      "grad_norm": 0.14448025822639465,
      "learning_rate": 8.543074251723486e-06,
      "loss": 0.0451,
      "step": 96500
    },
    {
      "epoch": 6.64237090008939,
      "grad_norm": 0.11680885404348373,
      "learning_rate": 8.500094555332061e-06,
      "loss": 0.0464,
      "step": 96600
    },
    {
      "epoch": 6.64924706044145,
      "grad_norm": 0.11929688602685928,
      "learning_rate": 8.457114858940637e-06,
      "loss": 0.0455,
      "step": 96700
    },
    {
      "epoch": 6.656123220793509,
      "grad_norm": 0.2230902910232544,
      "learning_rate": 8.414135162549213e-06,
      "loss": 0.0491,
      "step": 96800
    },
    {
      "epoch": 6.662999381145569,
      "grad_norm": 0.16153371334075928,
      "learning_rate": 8.371155466157787e-06,
      "loss": 0.0486,
      "step": 96900
    },
    {
      "epoch": 6.669875541497627,
      "grad_norm": 0.1734471321105957,
      "learning_rate": 8.328175769766362e-06,
      "loss": 0.0516,
      "step": 97000
    },
    {
      "epoch": 6.676751701849687,
      "grad_norm": 0.272541880607605,
      "learning_rate": 8.28519607337494e-06,
      "loss": 0.0481,
      "step": 97100
    },
    {
      "epoch": 6.683627862201747,
      "grad_norm": 0.13281981647014618,
      "learning_rate": 8.242216376983513e-06,
      "loss": 0.0458,
      "step": 97200
    },
    {
      "epoch": 6.690504022553806,
      "grad_norm": 0.17394216358661652,
      "learning_rate": 8.199236680592089e-06,
      "loss": 0.0488,
      "step": 97300
    },
    {
      "epoch": 6.6973801829058655,
      "grad_norm": 0.3161277770996094,
      "learning_rate": 8.156256984200663e-06,
      "loss": 0.0497,
      "step": 97400
    },
    {
      "epoch": 6.704256343257924,
      "grad_norm": 0.12992079555988312,
      "learning_rate": 8.113277287809239e-06,
      "loss": 0.0479,
      "step": 97500
    },
    {
      "epoch": 6.711132503609984,
      "grad_norm": 0.1604345589876175,
      "learning_rate": 8.070297591417816e-06,
      "loss": 0.0461,
      "step": 97600
    },
    {
      "epoch": 6.718008663962044,
      "grad_norm": 0.10337740182876587,
      "learning_rate": 8.02731789502639e-06,
      "loss": 0.0496,
      "step": 97700
    },
    {
      "epoch": 6.724884824314103,
      "grad_norm": 0.10499121248722076,
      "learning_rate": 7.984338198634965e-06,
      "loss": 0.0506,
      "step": 97800
    },
    {
      "epoch": 6.731760984666162,
      "grad_norm": 0.2210586667060852,
      "learning_rate": 7.94135850224354e-06,
      "loss": 0.0491,
      "step": 97900
    },
    {
      "epoch": 6.738637145018222,
      "grad_norm": 0.20496748387813568,
      "learning_rate": 7.898378805852117e-06,
      "loss": 0.0457,
      "step": 98000
    },
    {
      "epoch": 6.745513305370281,
      "grad_norm": 0.18480120599269867,
      "learning_rate": 7.85539910946069e-06,
      "loss": 0.047,
      "step": 98100
    },
    {
      "epoch": 6.752389465722341,
      "grad_norm": 0.11349906027317047,
      "learning_rate": 7.812419413069266e-06,
      "loss": 0.0459,
      "step": 98200
    },
    {
      "epoch": 6.7592656260744,
      "grad_norm": 0.17414094507694244,
      "learning_rate": 7.769439716677842e-06,
      "loss": 0.0495,
      "step": 98300
    },
    {
      "epoch": 6.766141786426459,
      "grad_norm": 0.16894815862178802,
      "learning_rate": 7.726460020286417e-06,
      "loss": 0.0487,
      "step": 98400
    },
    {
      "epoch": 6.773017946778519,
      "grad_norm": 0.18206726014614105,
      "learning_rate": 7.683910120858906e-06,
      "loss": 0.0497,
      "step": 98500
    },
    {
      "epoch": 6.779894107130579,
      "grad_norm": 0.17230340838432312,
      "learning_rate": 7.640930424467482e-06,
      "loss": 0.0491,
      "step": 98600
    },
    {
      "epoch": 6.786770267482638,
      "grad_norm": 0.14964298903942108,
      "learning_rate": 7.5979507280760575e-06,
      "loss": 0.0463,
      "step": 98700
    },
    {
      "epoch": 6.793646427834697,
      "grad_norm": 0.10333041101694107,
      "learning_rate": 7.554971031684632e-06,
      "loss": 0.0479,
      "step": 98800
    },
    {
      "epoch": 6.800522588186756,
      "grad_norm": 0.14385944604873657,
      "learning_rate": 7.511991335293207e-06,
      "loss": 0.0475,
      "step": 98900
    },
    {
      "epoch": 6.807398748538816,
      "grad_norm": 0.16160543262958527,
      "learning_rate": 7.4690116389017835e-06,
      "loss": 0.0467,
      "step": 99000
    },
    {
      "epoch": 6.814274908890876,
      "grad_norm": 0.1259366124868393,
      "learning_rate": 7.426031942510358e-06,
      "loss": 0.049,
      "step": 99100
    },
    {
      "epoch": 6.8211510692429345,
      "grad_norm": 0.13509085774421692,
      "learning_rate": 7.383052246118934e-06,
      "loss": 0.0498,
      "step": 99200
    },
    {
      "epoch": 6.828027229594994,
      "grad_norm": 0.21241523325443268,
      "learning_rate": 7.340072549727509e-06,
      "loss": 0.0469,
      "step": 99300
    },
    {
      "epoch": 6.834903389947054,
      "grad_norm": 0.09730645269155502,
      "learning_rate": 7.297092853336085e-06,
      "loss": 0.0505,
      "step": 99400
    },
    {
      "epoch": 6.841779550299113,
      "grad_norm": 0.16952933371067047,
      "learning_rate": 7.25411315694466e-06,
      "loss": 0.0495,
      "step": 99500
    },
    {
      "epoch": 6.8486557106511725,
      "grad_norm": 0.13079620897769928,
      "learning_rate": 7.211133460553235e-06,
      "loss": 0.0468,
      "step": 99600
    },
    {
      "epoch": 6.855531871003231,
      "grad_norm": 0.15500286221504211,
      "learning_rate": 7.16815376416181e-06,
      "loss": 0.0468,
      "step": 99700
    },
    {
      "epoch": 6.862408031355291,
      "grad_norm": 0.14232252538204193,
      "learning_rate": 7.125174067770387e-06,
      "loss": 0.0476,
      "step": 99800
    },
    {
      "epoch": 6.869284191707351,
      "grad_norm": 0.22880184650421143,
      "learning_rate": 7.0821943713789614e-06,
      "loss": 0.0484,
      "step": 99900
    },
    {
      "epoch": 6.87616035205941,
      "grad_norm": 0.1867484748363495,
      "learning_rate": 7.039214674987536e-06,
      "loss": 0.0467,
      "step": 100000
    },
    {
      "epoch": 6.883036512411469,
      "grad_norm": 0.17608247697353363,
      "learning_rate": 6.996234978596111e-06,
      "loss": 0.05,
      "step": 100100
    },
    {
      "epoch": 6.889912672763529,
      "grad_norm": 0.15819911658763885,
      "learning_rate": 6.9532552822046865e-06,
      "loss": 0.0487,
      "step": 100200
    },
    {
      "epoch": 6.896788833115588,
      "grad_norm": 0.11488206684589386,
      "learning_rate": 6.910275585813262e-06,
      "loss": 0.0482,
      "step": 100300
    },
    {
      "epoch": 6.903664993467648,
      "grad_norm": 0.21124352514743805,
      "learning_rate": 6.867295889421838e-06,
      "loss": 0.0499,
      "step": 100400
    },
    {
      "epoch": 6.9105411538197075,
      "grad_norm": 0.1646973192691803,
      "learning_rate": 6.8243161930304125e-06,
      "loss": 0.0466,
      "step": 100500
    },
    {
      "epoch": 6.917417314171766,
      "grad_norm": 0.15038909018039703,
      "learning_rate": 6.781336496638987e-06,
      "loss": 0.0459,
      "step": 100600
    },
    {
      "epoch": 6.924293474523826,
      "grad_norm": 0.07373693585395813,
      "learning_rate": 6.738356800247564e-06,
      "loss": 0.0468,
      "step": 100700
    },
    {
      "epoch": 6.931169634875886,
      "grad_norm": 0.18466536700725555,
      "learning_rate": 6.6953771038561385e-06,
      "loss": 0.0481,
      "step": 100800
    },
    {
      "epoch": 6.938045795227945,
      "grad_norm": 0.25674009323120117,
      "learning_rate": 6.652827204428628e-06,
      "loss": 0.0495,
      "step": 100900
    },
    {
      "epoch": 6.944921955580004,
      "grad_norm": 0.17101743817329407,
      "learning_rate": 6.609847508037203e-06,
      "loss": 0.0504,
      "step": 101000
    },
    {
      "epoch": 6.951798115932063,
      "grad_norm": 0.08028215169906616,
      "learning_rate": 6.566867811645779e-06,
      "loss": 0.0468,
      "step": 101100
    },
    {
      "epoch": 6.958674276284123,
      "grad_norm": 0.3605242967605591,
      "learning_rate": 6.5238881152543535e-06,
      "loss": 0.0481,
      "step": 101200
    },
    {
      "epoch": 6.965550436636183,
      "grad_norm": 0.09169931709766388,
      "learning_rate": 6.48090841886293e-06,
      "loss": 0.0472,
      "step": 101300
    },
    {
      "epoch": 6.9724265969882415,
      "grad_norm": 0.1794421225786209,
      "learning_rate": 6.437928722471505e-06,
      "loss": 0.0468,
      "step": 101400
    },
    {
      "epoch": 6.979302757340301,
      "grad_norm": 0.18743617832660675,
      "learning_rate": 6.3949490260800795e-06,
      "loss": 0.0502,
      "step": 101500
    },
    {
      "epoch": 6.98617891769236,
      "grad_norm": 0.15292586386203766,
      "learning_rate": 6.351969329688655e-06,
      "loss": 0.0456,
      "step": 101600
    },
    {
      "epoch": 6.99305507804442,
      "grad_norm": 0.12708041071891785,
      "learning_rate": 6.3089896332972315e-06,
      "loss": 0.0476,
      "step": 101700
    },
    {
      "epoch": 6.99993123839648,
      "grad_norm": 0.18353280425071716,
      "learning_rate": 6.266009936905806e-06,
      "loss": 0.0449,
      "step": 101800
    },
    {
      "epoch": 7.0,
      "eval_accuracy_macro_0.5": 0.9783821105957031,
      "eval_accuracy_micro_0.5": 0.9783821105957031,
      "eval_accuracy_weighted_0.5": 0.9756881594657898,
      "eval_f1_macro_0.5": 0.7051690816879272,
      "eval_f1_macro_0.6": 0.6797230243682861,
      "eval_f1_macro_0.7": 0.6361382007598877,
      "eval_f1_macro_0.8": 0.42702364921569824,
      "eval_f1_micro_0.5": 0.7119027972221375,
      "eval_f1_micro_0.6": 0.6927732229232788,
      "eval_f1_micro_0.7": 0.6567960381507874,
      "eval_f1_micro_0.8": 0.5915178060531616,
      "eval_f1_micro_0.9": 0.45605090260505676,
      "eval_f1_weighted_0.5": 0.7024450898170471,
      "eval_f1_weighted_0.6": 0.6767341494560242,
      "eval_f1_weighted_0.7": 0.6322062015533447,
      "eval_f1_weighted_0.8": 0.41186949610710144,
      "eval_loss": 0.0450381338596344,
      "eval_runtime": 140.2023,
      "eval_samples_per_second": 207.108,
      "eval_steps_per_second": 25.891,
      "step": 101801
    },
    {
      "epoch": 7.006807398748538,
      "grad_norm": 0.09000100195407867,
      "learning_rate": 6.223030240514381e-06,
      "loss": 0.0466,
      "step": 101900
    },
    {
      "epoch": 7.013683559100598,
      "grad_norm": 0.10081173479557037,
      "learning_rate": 6.180050544122957e-06,
      "loss": 0.0456,
      "step": 102000
    },
    {
      "epoch": 7.020559719452658,
      "grad_norm": 0.1918809860944748,
      "learning_rate": 6.137070847731531e-06,
      "loss": 0.0524,
      "step": 102100
    },
    {
      "epoch": 7.027435879804717,
      "grad_norm": 0.20233546197414398,
      "learning_rate": 6.094091151340108e-06,
      "loss": 0.0475,
      "step": 102200
    },
    {
      "epoch": 7.0343120401567765,
      "grad_norm": 0.11033035814762115,
      "learning_rate": 6.051111454948683e-06,
      "loss": 0.047,
      "step": 102300
    },
    {
      "epoch": 7.041188200508836,
      "grad_norm": 0.16334104537963867,
      "learning_rate": 6.008131758557258e-06,
      "loss": 0.0461,
      "step": 102400
    },
    {
      "epoch": 7.048064360860895,
      "grad_norm": 0.15824590623378754,
      "learning_rate": 5.965152062165833e-06,
      "loss": 0.0479,
      "step": 102500
    },
    {
      "epoch": 7.054940521212955,
      "grad_norm": 0.11227893829345703,
      "learning_rate": 5.922172365774408e-06,
      "loss": 0.0453,
      "step": 102600
    },
    {
      "epoch": 7.0618166815650145,
      "grad_norm": 0.1463952213525772,
      "learning_rate": 5.879192669382984e-06,
      "loss": 0.0506,
      "step": 102700
    },
    {
      "epoch": 7.068692841917073,
      "grad_norm": 0.11218661069869995,
      "learning_rate": 5.836212972991559e-06,
      "loss": 0.0483,
      "step": 102800
    },
    {
      "epoch": 7.075569002269133,
      "grad_norm": 0.11595375835895538,
      "learning_rate": 5.7932332766001346e-06,
      "loss": 0.047,
      "step": 102900
    },
    {
      "epoch": 7.082445162621192,
      "grad_norm": 0.11480045318603516,
      "learning_rate": 5.750253580208709e-06,
      "loss": 0.0469,
      "step": 103000
    },
    {
      "epoch": 7.089321322973252,
      "grad_norm": 0.14849352836608887,
      "learning_rate": 5.707273883817285e-06,
      "loss": 0.0458,
      "step": 103100
    },
    {
      "epoch": 7.096197483325311,
      "grad_norm": 0.11757738143205643,
      "learning_rate": 5.66429418742586e-06,
      "loss": 0.0488,
      "step": 103200
    },
    {
      "epoch": 7.10307364367737,
      "grad_norm": 0.18082676827907562,
      "learning_rate": 5.621314491034436e-06,
      "loss": 0.0464,
      "step": 103300
    },
    {
      "epoch": 7.10994980402943,
      "grad_norm": 0.17710252106189728,
      "learning_rate": 5.578334794643011e-06,
      "loss": 0.0455,
      "step": 103400
    },
    {
      "epoch": 7.11682596438149,
      "grad_norm": 0.1541290581226349,
      "learning_rate": 5.5353550982515865e-06,
      "loss": 0.0499,
      "step": 103500
    },
    {
      "epoch": 7.123702124733549,
      "grad_norm": 0.19722676277160645,
      "learning_rate": 5.492375401860161e-06,
      "loss": 0.0461,
      "step": 103600
    },
    {
      "epoch": 7.130578285085608,
      "grad_norm": 0.1933814436197281,
      "learning_rate": 5.449395705468737e-06,
      "loss": 0.0483,
      "step": 103700
    },
    {
      "epoch": 7.137454445437667,
      "grad_norm": 0.12101192027330399,
      "learning_rate": 5.4064160090773125e-06,
      "loss": 0.0467,
      "step": 103800
    },
    {
      "epoch": 7.144330605789727,
      "grad_norm": 0.18169228732585907,
      "learning_rate": 5.3638661096498015e-06,
      "loss": 0.0481,
      "step": 103900
    },
    {
      "epoch": 7.151206766141787,
      "grad_norm": 0.1437503844499588,
      "learning_rate": 5.320886413258377e-06,
      "loss": 0.048,
      "step": 104000
    },
    {
      "epoch": 7.1580829264938455,
      "grad_norm": 0.15669824182987213,
      "learning_rate": 5.277906716866953e-06,
      "loss": 0.0472,
      "step": 104100
    },
    {
      "epoch": 7.164959086845905,
      "grad_norm": 0.11039358377456665,
      "learning_rate": 5.2349270204755275e-06,
      "loss": 0.049,
      "step": 104200
    },
    {
      "epoch": 7.171835247197965,
      "grad_norm": 0.2119925618171692,
      "learning_rate": 5.191947324084103e-06,
      "loss": 0.0483,
      "step": 104300
    },
    {
      "epoch": 7.178711407550024,
      "grad_norm": 0.1432570070028305,
      "learning_rate": 5.148967627692678e-06,
      "loss": 0.0472,
      "step": 104400
    },
    {
      "epoch": 7.1855875679020835,
      "grad_norm": 0.13164788484573364,
      "learning_rate": 5.1059879313012535e-06,
      "loss": 0.0503,
      "step": 104500
    },
    {
      "epoch": 7.192463728254143,
      "grad_norm": 0.13726764917373657,
      "learning_rate": 5.063008234909829e-06,
      "loss": 0.047,
      "step": 104600
    },
    {
      "epoch": 7.199339888606202,
      "grad_norm": 0.23884789645671844,
      "learning_rate": 5.020028538518405e-06,
      "loss": 0.0511,
      "step": 104700
    },
    {
      "epoch": 7.206216048958262,
      "grad_norm": 0.19457800686359406,
      "learning_rate": 4.977478639090894e-06,
      "loss": 0.0526,
      "step": 104800
    },
    {
      "epoch": 7.213092209310321,
      "grad_norm": 0.18254153430461884,
      "learning_rate": 4.934498942699469e-06,
      "loss": 0.0449,
      "step": 104900
    },
    {
      "epoch": 7.21996836966238,
      "grad_norm": 0.1753232330083847,
      "learning_rate": 4.891519246308044e-06,
      "loss": 0.047,
      "step": 105000
    },
    {
      "epoch": 7.22684453001444,
      "grad_norm": 0.13952969014644623,
      "learning_rate": 4.84853954991662e-06,
      "loss": 0.0483,
      "step": 105100
    },
    {
      "epoch": 7.233720690366499,
      "grad_norm": 0.18652260303497314,
      "learning_rate": 4.8055598535251945e-06,
      "loss": 0.0512,
      "step": 105200
    },
    {
      "epoch": 7.240596850718559,
      "grad_norm": 0.15575024485588074,
      "learning_rate": 4.76258015713377e-06,
      "loss": 0.049,
      "step": 105300
    },
    {
      "epoch": 7.2474730110706185,
      "grad_norm": 0.14570599794387817,
      "learning_rate": 4.719600460742346e-06,
      "loss": 0.0466,
      "step": 105400
    },
    {
      "epoch": 7.254349171422677,
      "grad_norm": 0.12851692736148834,
      "learning_rate": 4.676620764350921e-06,
      "loss": 0.0497,
      "step": 105500
    },
    {
      "epoch": 7.261225331774737,
      "grad_norm": 0.1832783818244934,
      "learning_rate": 4.633641067959496e-06,
      "loss": 0.0448,
      "step": 105600
    },
    {
      "epoch": 7.268101492126797,
      "grad_norm": 0.11100996285676956,
      "learning_rate": 4.590661371568072e-06,
      "loss": 0.051,
      "step": 105700
    },
    {
      "epoch": 7.274977652478856,
      "grad_norm": 0.1139390841126442,
      "learning_rate": 4.547681675176646e-06,
      "loss": 0.0478,
      "step": 105800
    },
    {
      "epoch": 7.281853812830915,
      "grad_norm": 0.09989363700151443,
      "learning_rate": 4.504701978785222e-06,
      "loss": 0.0471,
      "step": 105900
    },
    {
      "epoch": 7.288729973182974,
      "grad_norm": 0.10073838382959366,
      "learning_rate": 4.461722282393798e-06,
      "loss": 0.0471,
      "step": 106000
    },
    {
      "epoch": 7.295606133535034,
      "grad_norm": 0.12923157215118408,
      "learning_rate": 4.419172382966287e-06,
      "loss": 0.0465,
      "step": 106100
    },
    {
      "epoch": 7.302482293887094,
      "grad_norm": 0.17722153663635254,
      "learning_rate": 4.376192686574862e-06,
      "loss": 0.0468,
      "step": 106200
    },
    {
      "epoch": 7.3093584542391525,
      "grad_norm": 0.20529910922050476,
      "learning_rate": 4.333212990183438e-06,
      "loss": 0.0474,
      "step": 106300
    },
    {
      "epoch": 7.316234614591212,
      "grad_norm": 0.15983305871486664,
      "learning_rate": 4.290233293792013e-06,
      "loss": 0.0481,
      "step": 106400
    },
    {
      "epoch": 7.323110774943272,
      "grad_norm": 0.09799893200397491,
      "learning_rate": 4.247253597400588e-06,
      "loss": 0.0493,
      "step": 106500
    },
    {
      "epoch": 7.329986935295331,
      "grad_norm": 0.15161602199077606,
      "learning_rate": 4.204273901009163e-06,
      "loss": 0.0458,
      "step": 106600
    },
    {
      "epoch": 7.336863095647391,
      "grad_norm": 0.17076198756694794,
      "learning_rate": 4.161294204617739e-06,
      "loss": 0.0475,
      "step": 106700
    },
    {
      "epoch": 7.34373925599945,
      "grad_norm": 0.23790453374385834,
      "learning_rate": 4.118314508226314e-06,
      "loss": 0.0449,
      "step": 106800
    },
    {
      "epoch": 7.350615416351509,
      "grad_norm": 0.137905552983284,
      "learning_rate": 4.07533481183489e-06,
      "loss": 0.0461,
      "step": 106900
    },
    {
      "epoch": 7.357491576703569,
      "grad_norm": 0.17953093349933624,
      "learning_rate": 4.0323551154434646e-06,
      "loss": 0.0483,
      "step": 107000
    },
    {
      "epoch": 7.364367737055628,
      "grad_norm": 0.08719286322593689,
      "learning_rate": 3.98937541905204e-06,
      "loss": 0.048,
      "step": 107100
    },
    {
      "epoch": 7.3712438974076875,
      "grad_norm": 0.16478577256202698,
      "learning_rate": 3.946395722660615e-06,
      "loss": 0.0484,
      "step": 107200
    },
    {
      "epoch": 7.378120057759747,
      "grad_norm": 0.18702152371406555,
      "learning_rate": 3.9034160262691905e-06,
      "loss": 0.047,
      "step": 107300
    },
    {
      "epoch": 7.384996218111806,
      "grad_norm": 0.2115143984556198,
      "learning_rate": 3.860436329877766e-06,
      "loss": 0.0486,
      "step": 107400
    },
    {
      "epoch": 7.391872378463866,
      "grad_norm": 0.1621084362268448,
      "learning_rate": 3.817456633486341e-06,
      "loss": 0.0505,
      "step": 107500
    },
    {
      "epoch": 7.3987485388159255,
      "grad_norm": 0.10969552397727966,
      "learning_rate": 3.7744769370949165e-06,
      "loss": 0.0486,
      "step": 107600
    },
    {
      "epoch": 7.405624699167984,
      "grad_norm": 0.16647151112556458,
      "learning_rate": 3.7314972407034917e-06,
      "loss": 0.0472,
      "step": 107700
    },
    {
      "epoch": 7.412500859520044,
      "grad_norm": 0.1467570811510086,
      "learning_rate": 3.6885175443120673e-06,
      "loss": 0.0497,
      "step": 107800
    },
    {
      "epoch": 7.419377019872103,
      "grad_norm": 0.10631179809570312,
      "learning_rate": 3.6455378479206425e-06,
      "loss": 0.0466,
      "step": 107900
    },
    {
      "epoch": 7.426253180224163,
      "grad_norm": 0.16283056139945984,
      "learning_rate": 3.602558151529218e-06,
      "loss": 0.0499,
      "step": 108000
    },
    {
      "epoch": 7.433129340576222,
      "grad_norm": 0.11363281309604645,
      "learning_rate": 3.559578455137793e-06,
      "loss": 0.044,
      "step": 108100
    },
    {
      "epoch": 7.440005500928281,
      "grad_norm": 0.19559988379478455,
      "learning_rate": 3.5165987587463685e-06,
      "loss": 0.0465,
      "step": 108200
    },
    {
      "epoch": 7.446881661280341,
      "grad_norm": 0.1450611799955368,
      "learning_rate": 3.4736190623549436e-06,
      "loss": 0.0468,
      "step": 108300
    },
    {
      "epoch": 7.453757821632401,
      "grad_norm": 0.17513853311538696,
      "learning_rate": 3.4306393659635192e-06,
      "loss": 0.0457,
      "step": 108400
    },
    {
      "epoch": 7.46063398198446,
      "grad_norm": 0.18428535759449005,
      "learning_rate": 3.3876596695720944e-06,
      "loss": 0.0477,
      "step": 108500
    },
    {
      "epoch": 7.467510142336519,
      "grad_norm": 0.18028372526168823,
      "learning_rate": 3.34467997318067e-06,
      "loss": 0.0482,
      "step": 108600
    },
    {
      "epoch": 7.474386302688579,
      "grad_norm": 0.16069217026233673,
      "learning_rate": 3.3017002767892448e-06,
      "loss": 0.0516,
      "step": 108700
    },
    {
      "epoch": 7.481262463040638,
      "grad_norm": 0.2272215336561203,
      "learning_rate": 3.25872058039782e-06,
      "loss": 0.0447,
      "step": 108800
    },
    {
      "epoch": 7.488138623392698,
      "grad_norm": 0.18228745460510254,
      "learning_rate": 3.2157408840063956e-06,
      "loss": 0.0475,
      "step": 108900
    },
    {
      "epoch": 7.495014783744757,
      "grad_norm": 0.12245886772871017,
      "learning_rate": 3.1727611876149708e-06,
      "loss": 0.0464,
      "step": 109000
    },
    {
      "epoch": 7.501890944096816,
      "grad_norm": 0.14673484861850739,
      "learning_rate": 3.1297814912235464e-06,
      "loss": 0.051,
      "step": 109100
    },
    {
      "epoch": 7.508767104448876,
      "grad_norm": 0.16593492031097412,
      "learning_rate": 3.0868017948321215e-06,
      "loss": 0.0501,
      "step": 109200
    },
    {
      "epoch": 7.515643264800935,
      "grad_norm": 0.18268609046936035,
      "learning_rate": 3.0438220984406967e-06,
      "loss": 0.0485,
      "step": 109300
    },
    {
      "epoch": 7.5225194251529945,
      "grad_norm": 0.09915605187416077,
      "learning_rate": 3.0008424020492723e-06,
      "loss": 0.0459,
      "step": 109400
    },
    {
      "epoch": 7.529395585505054,
      "grad_norm": 0.10963233560323715,
      "learning_rate": 2.957862705657847e-06,
      "loss": 0.0474,
      "step": 109500
    },
    {
      "epoch": 7.536271745857113,
      "grad_norm": 0.21741272509098053,
      "learning_rate": 2.9148830092664227e-06,
      "loss": 0.0474,
      "step": 109600
    },
    {
      "epoch": 7.543147906209173,
      "grad_norm": 0.1328384131193161,
      "learning_rate": 2.871903312874998e-06,
      "loss": 0.0447,
      "step": 109700
    },
    {
      "epoch": 7.550024066561233,
      "grad_norm": 0.2649456560611725,
      "learning_rate": 2.828923616483573e-06,
      "loss": 0.047,
      "step": 109800
    },
    {
      "epoch": 7.556900226913291,
      "grad_norm": 0.17056238651275635,
      "learning_rate": 2.7859439200921487e-06,
      "loss": 0.0472,
      "step": 109900
    },
    {
      "epoch": 7.563776387265351,
      "grad_norm": 0.10678213834762573,
      "learning_rate": 2.742964223700724e-06,
      "loss": 0.0477,
      "step": 110000
    },
    {
      "epoch": 7.57065254761741,
      "grad_norm": 0.09785458445549011,
      "learning_rate": 2.699984527309299e-06,
      "loss": 0.049,
      "step": 110100
    },
    {
      "epoch": 7.57752870796947,
      "grad_norm": 0.19419868290424347,
      "learning_rate": 2.6570048309178746e-06,
      "loss": 0.0468,
      "step": 110200
    },
    {
      "epoch": 7.5844048683215295,
      "grad_norm": 0.14122238755226135,
      "learning_rate": 2.61402513452645e-06,
      "loss": 0.0475,
      "step": 110300
    },
    {
      "epoch": 7.591281028673588,
      "grad_norm": 0.23219968378543854,
      "learning_rate": 2.571045438135025e-06,
      "loss": 0.0457,
      "step": 110400
    },
    {
      "epoch": 7.598157189025648,
      "grad_norm": 0.1379900425672531,
      "learning_rate": 2.5280657417436006e-06,
      "loss": 0.0487,
      "step": 110500
    },
    {
      "epoch": 7.605033349377708,
      "grad_norm": 0.17826397716999054,
      "learning_rate": 2.4850860453521758e-06,
      "loss": 0.0484,
      "step": 110600
    },
    {
      "epoch": 7.611909509729767,
      "grad_norm": 0.21598856151103973,
      "learning_rate": 2.442106348960751e-06,
      "loss": 0.0484,
      "step": 110700
    },
    {
      "epoch": 7.618785670081826,
      "grad_norm": 0.09310423582792282,
      "learning_rate": 2.3991266525693266e-06,
      "loss": 0.0489,
      "step": 110800
    },
    {
      "epoch": 7.625661830433886,
      "grad_norm": 0.11665187031030655,
      "learning_rate": 2.3561469561779018e-06,
      "loss": 0.0464,
      "step": 110900
    },
    {
      "epoch": 7.632537990785945,
      "grad_norm": 0.1596742570400238,
      "learning_rate": 2.313167259786477e-06,
      "loss": 0.0478,
      "step": 111000
    },
    {
      "epoch": 7.639414151138005,
      "grad_norm": 0.22322587668895721,
      "learning_rate": 2.270187563395052e-06,
      "loss": 0.0448,
      "step": 111100
    },
    {
      "epoch": 7.646290311490064,
      "grad_norm": 0.1369195282459259,
      "learning_rate": 2.2272078670036273e-06,
      "loss": 0.0479,
      "step": 111200
    },
    {
      "epoch": 7.653166471842123,
      "grad_norm": 0.173237144947052,
      "learning_rate": 2.184228170612203e-06,
      "loss": 0.0469,
      "step": 111300
    },
    {
      "epoch": 7.660042632194183,
      "grad_norm": 0.10781455039978027,
      "learning_rate": 2.141248474220778e-06,
      "loss": 0.0497,
      "step": 111400
    },
    {
      "epoch": 7.666918792546242,
      "grad_norm": 0.18843255937099457,
      "learning_rate": 2.0982687778293533e-06,
      "loss": 0.0429,
      "step": 111500
    },
    {
      "epoch": 7.673794952898302,
      "grad_norm": 0.14116355776786804,
      "learning_rate": 2.055289081437929e-06,
      "loss": 0.0485,
      "step": 111600
    },
    {
      "epoch": 7.680671113250361,
      "grad_norm": 0.2511197328567505,
      "learning_rate": 2.012309385046504e-06,
      "loss": 0.0511,
      "step": 111700
    },
    {
      "epoch": 7.68754727360242,
      "grad_norm": 0.10112085193395615,
      "learning_rate": 1.9693296886550797e-06,
      "loss": 0.0466,
      "step": 111800
    },
    {
      "epoch": 7.69442343395448,
      "grad_norm": 0.18440647423267365,
      "learning_rate": 1.926349992263655e-06,
      "loss": 0.0484,
      "step": 111900
    },
    {
      "epoch": 7.701299594306539,
      "grad_norm": 0.20948009192943573,
      "learning_rate": 1.88337029587223e-06,
      "loss": 0.0468,
      "step": 112000
    },
    {
      "epoch": 7.7081757546585985,
      "grad_norm": 0.1364136040210724,
      "learning_rate": 1.8403905994808054e-06,
      "loss": 0.0489,
      "step": 112100
    },
    {
      "epoch": 7.715051915010658,
      "grad_norm": 0.10633902996778488,
      "learning_rate": 1.7974109030893808e-06,
      "loss": 0.0487,
      "step": 112200
    },
    {
      "epoch": 7.721928075362717,
      "grad_norm": 0.157622292637825,
      "learning_rate": 1.7544312066979562e-06,
      "loss": 0.0464,
      "step": 112300
    },
    {
      "epoch": 7.728804235714777,
      "grad_norm": 0.07247664034366608,
      "learning_rate": 1.7114515103065314e-06,
      "loss": 0.0461,
      "step": 112400
    },
    {
      "epoch": 7.7356803960668366,
      "grad_norm": 0.17969708144664764,
      "learning_rate": 1.6684718139151064e-06,
      "loss": 0.046,
      "step": 112500
    },
    {
      "epoch": 7.742556556418895,
      "grad_norm": 0.14479684829711914,
      "learning_rate": 1.625921914487596e-06,
      "loss": 0.0466,
      "step": 112600
    },
    {
      "epoch": 7.749432716770955,
      "grad_norm": 0.21191218495368958,
      "learning_rate": 1.5829422180961714e-06,
      "loss": 0.044,
      "step": 112700
    },
    {
      "epoch": 7.756308877123015,
      "grad_norm": 0.15251661837100983,
      "learning_rate": 1.5399625217047468e-06,
      "loss": 0.0444,
      "step": 112800
    },
    {
      "epoch": 7.763185037475074,
      "grad_norm": 0.07367172092199326,
      "learning_rate": 1.496982825313322e-06,
      "loss": 0.0489,
      "step": 112900
    },
    {
      "epoch": 7.7700611978271334,
      "grad_norm": 0.11874973773956299,
      "learning_rate": 1.4540031289218974e-06,
      "loss": 0.0487,
      "step": 113000
    },
    {
      "epoch": 7.776937358179193,
      "grad_norm": 0.13133946061134338,
      "learning_rate": 1.4110234325304728e-06,
      "loss": 0.0465,
      "step": 113100
    },
    {
      "epoch": 7.783813518531252,
      "grad_norm": 0.10043169558048248,
      "learning_rate": 1.368043736139048e-06,
      "loss": 0.048,
      "step": 113200
    },
    {
      "epoch": 7.790689678883312,
      "grad_norm": 0.13645613193511963,
      "learning_rate": 1.3250640397476232e-06,
      "loss": 0.0458,
      "step": 113300
    },
    {
      "epoch": 7.797565839235371,
      "grad_norm": 0.17792139947414398,
      "learning_rate": 1.2820843433561986e-06,
      "loss": 0.047,
      "step": 113400
    },
    {
      "epoch": 7.80444199958743,
      "grad_norm": 0.15760569274425507,
      "learning_rate": 1.239104646964774e-06,
      "loss": 0.0473,
      "step": 113500
    },
    {
      "epoch": 7.81131815993949,
      "grad_norm": 0.17908912897109985,
      "learning_rate": 1.1961249505733491e-06,
      "loss": 0.0493,
      "step": 113600
    },
    {
      "epoch": 7.818194320291549,
      "grad_norm": 0.12086287140846252,
      "learning_rate": 1.1531452541819245e-06,
      "loss": 0.0451,
      "step": 113700
    },
    {
      "epoch": 7.825070480643609,
      "grad_norm": 0.20564857125282288,
      "learning_rate": 1.1101655577905e-06,
      "loss": 0.0485,
      "step": 113800
    },
    {
      "epoch": 7.831946640995668,
      "grad_norm": 0.1363239586353302,
      "learning_rate": 1.0671858613990751e-06,
      "loss": 0.0457,
      "step": 113900
    },
    {
      "epoch": 7.838822801347727,
      "grad_norm": 0.19460386037826538,
      "learning_rate": 1.0242061650076503e-06,
      "loss": 0.0475,
      "step": 114000
    },
    {
      "epoch": 7.845698961699787,
      "grad_norm": 0.14972402155399323,
      "learning_rate": 9.812264686162257e-07,
      "loss": 0.0479,
      "step": 114100
    },
    {
      "epoch": 7.852575122051846,
      "grad_norm": 0.14038845896720886,
      "learning_rate": 9.382467722248011e-07,
      "loss": 0.0487,
      "step": 114200
    },
    {
      "epoch": 7.859451282403906,
      "grad_norm": 0.17881232500076294,
      "learning_rate": 8.952670758333764e-07,
      "loss": 0.0484,
      "step": 114300
    },
    {
      "epoch": 7.866327442755965,
      "grad_norm": 0.20418767631053925,
      "learning_rate": 8.522873794419517e-07,
      "loss": 0.046,
      "step": 114400
    },
    {
      "epoch": 7.873203603108024,
      "grad_norm": 0.16560280323028564,
      "learning_rate": 8.09307683050527e-07,
      "loss": 0.0507,
      "step": 114500
    },
    {
      "epoch": 7.880079763460084,
      "grad_norm": 0.11078904569149017,
      "learning_rate": 7.663279866591022e-07,
      "loss": 0.0487,
      "step": 114600
    },
    {
      "epoch": 7.886955923812144,
      "grad_norm": 0.2144021987915039,
      "learning_rate": 7.233482902676776e-07,
      "loss": 0.0491,
      "step": 114700
    },
    {
      "epoch": 7.8938320841642025,
      "grad_norm": 0.18549026548862457,
      "learning_rate": 6.803685938762529e-07,
      "loss": 0.046,
      "step": 114800
    },
    {
      "epoch": 7.900708244516262,
      "grad_norm": 0.16336682438850403,
      "learning_rate": 6.373888974848282e-07,
      "loss": 0.0492,
      "step": 114900
    },
    {
      "epoch": 7.907584404868322,
      "grad_norm": 0.12893937528133392,
      "learning_rate": 5.944092010934035e-07,
      "loss": 0.0477,
      "step": 115000
    },
    {
      "epoch": 7.914460565220381,
      "grad_norm": 0.11746378242969513,
      "learning_rate": 5.514295047019788e-07,
      "loss": 0.0466,
      "step": 115100
    },
    {
      "epoch": 7.9213367255724405,
      "grad_norm": 0.17210355401039124,
      "learning_rate": 5.084498083105542e-07,
      "loss": 0.0489,
      "step": 115200
    },
    {
      "epoch": 7.9282128859245,
      "grad_norm": 0.12413336336612701,
      "learning_rate": 4.654701119191294e-07,
      "loss": 0.0443,
      "step": 115300
    },
    {
      "epoch": 7.935089046276559,
      "grad_norm": 0.21472692489624023,
      "learning_rate": 4.2249041552770475e-07,
      "loss": 0.0449,
      "step": 115400
    },
    {
      "epoch": 7.941965206628619,
      "grad_norm": 0.11209962517023087,
      "learning_rate": 3.799405161001943e-07,
      "loss": 0.0489,
      "step": 115500
    },
    {
      "epoch": 7.948841366980678,
      "grad_norm": 0.1547521948814392,
      "learning_rate": 3.3696081970876956e-07,
      "loss": 0.0481,
      "step": 115600
    },
    {
      "epoch": 7.955717527332737,
      "grad_norm": 0.1792280077934265,
      "learning_rate": 2.939811233173449e-07,
      "loss": 0.0481,
      "step": 115700
    },
    {
      "epoch": 7.962593687684797,
      "grad_norm": 0.17103438079357147,
      "learning_rate": 2.510014269259202e-07,
      "loss": 0.0473,
      "step": 115800
    },
    {
      "epoch": 7.969469848036856,
      "grad_norm": 0.10615666955709457,
      "learning_rate": 2.0802173053449553e-07,
      "loss": 0.0457,
      "step": 115900
    },
    {
      "epoch": 7.976346008388916,
      "grad_norm": 0.15525206923484802,
      "learning_rate": 1.6504203414307082e-07,
      "loss": 0.0469,
      "step": 116000
    },
    {
      "epoch": 7.983222168740975,
      "grad_norm": 0.1479187160730362,
      "learning_rate": 1.220623377516461e-07,
      "loss": 0.0458,
      "step": 116100
    },
    {
      "epoch": 7.990098329093034,
      "grad_norm": 0.12189410626888275,
      "learning_rate": 7.908264136022144e-08,
      "loss": 0.0498,
      "step": 116200
    },
    {
      "epoch": 7.996974489445094,
      "grad_norm": 0.16358059644699097,
      "learning_rate": 3.610294496879674e-08,
      "loss": 0.047,
      "step": 116300
    },
    {
      "epoch": 8.0,
      "eval_accuracy_macro_0.5": 0.9784810543060303,
      "eval_accuracy_micro_0.5": 0.978481113910675,
      "eval_accuracy_weighted_0.5": 0.9757893085479736,
      "eval_f1_macro_0.5": 0.7066421508789062,
      "eval_f1_macro_0.6": 0.6802774667739868,
      "eval_f1_macro_0.7": 0.637298047542572,
      "eval_f1_macro_0.8": 0.43304163217544556,
      "eval_f1_micro_0.5": 0.7134524583816528,
      "eval_f1_micro_0.6": 0.6941105723381042,
      "eval_f1_micro_0.7": 0.658515214920044,
      "eval_f1_micro_0.8": 0.5947986245155334,
      "eval_f1_micro_0.9": 0.4621913433074951,
      "eval_f1_weighted_0.5": 0.7037843465805054,
      "eval_f1_weighted_0.6": 0.6774135828018188,
      "eval_f1_weighted_0.7": 0.6333005428314209,
      "eval_f1_weighted_0.8": 0.4178236126899719,
      "eval_loss": 0.04487764090299606,
      "eval_runtime": 140.4087,
      "eval_samples_per_second": 206.803,
      "eval_steps_per_second": 25.853,
      "step": 116344
    }
  ],
  "logging_steps": 100,
  "max_steps": 116344,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6181501599817440.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
