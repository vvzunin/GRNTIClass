{
  "best_metric": 0.7190386056900024,
  "best_model_checkpoint": "aleksandr_test_rubert_tiny_turbomodel bert lora level 1/checkpoint-199633",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 199633,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0035064343069532594,
      "grad_norm": 0.6341249942779541,
      "learning_rate": 4.998027544248758e-05,
      "loss": 0.8526,
      "step": 100
    },
    {
      "epoch": 0.007012868613906519,
      "grad_norm": 0.3823970854282379,
      "learning_rate": 4.995835926747377e-05,
      "loss": 0.4217,
      "step": 200
    },
    {
      "epoch": 0.010519302920859779,
      "grad_norm": 0.2763890027999878,
      "learning_rate": 4.9936443092459964e-05,
      "loss": 0.1735,
      "step": 300
    },
    {
      "epoch": 0.014025737227813037,
      "grad_norm": 0.2246071845293045,
      "learning_rate": 4.9914526917446155e-05,
      "loss": 0.1443,
      "step": 400
    },
    {
      "epoch": 0.017532171534766296,
      "grad_norm": 0.1467362344264984,
      "learning_rate": 4.989261074243235e-05,
      "loss": 0.143,
      "step": 500
    },
    {
      "epoch": 0.021038605841719557,
      "grad_norm": 0.22866225242614746,
      "learning_rate": 4.987069456741854e-05,
      "loss": 0.1374,
      "step": 600
    },
    {
      "epoch": 0.024545040148672814,
      "grad_norm": 0.18886050581932068,
      "learning_rate": 4.984877839240473e-05,
      "loss": 0.1347,
      "step": 700
    },
    {
      "epoch": 0.028051474455626075,
      "grad_norm": 0.19930040836334229,
      "learning_rate": 4.982686221739092e-05,
      "loss": 0.1403,
      "step": 800
    },
    {
      "epoch": 0.031557908762579336,
      "grad_norm": 0.19870807230472565,
      "learning_rate": 4.980494604237712e-05,
      "loss": 0.1371,
      "step": 900
    },
    {
      "epoch": 0.03506434306953259,
      "grad_norm": 0.18201331794261932,
      "learning_rate": 4.978302986736331e-05,
      "loss": 0.1499,
      "step": 1000
    },
    {
      "epoch": 0.03857077737648585,
      "grad_norm": 0.22126705944538116,
      "learning_rate": 4.97611136923495e-05,
      "loss": 0.1454,
      "step": 1100
    },
    {
      "epoch": 0.042077211683439114,
      "grad_norm": 0.13967138528823853,
      "learning_rate": 4.97391975173357e-05,
      "loss": 0.1375,
      "step": 1200
    },
    {
      "epoch": 0.04558364599039237,
      "grad_norm": 0.19450074434280396,
      "learning_rate": 4.9717281342321895e-05,
      "loss": 0.139,
      "step": 1300
    },
    {
      "epoch": 0.04909008029734563,
      "grad_norm": 0.19467324018478394,
      "learning_rate": 4.9695365167308085e-05,
      "loss": 0.1393,
      "step": 1400
    },
    {
      "epoch": 0.052596514604298886,
      "grad_norm": 0.17800922691822052,
      "learning_rate": 4.9673448992294275e-05,
      "loss": 0.1368,
      "step": 1500
    },
    {
      "epoch": 0.05610294891125215,
      "grad_norm": 0.17914047837257385,
      "learning_rate": 4.9651532817280466e-05,
      "loss": 0.1396,
      "step": 1600
    },
    {
      "epoch": 0.05960938321820541,
      "grad_norm": 0.21105162799358368,
      "learning_rate": 4.962961664226666e-05,
      "loss": 0.1369,
      "step": 1700
    },
    {
      "epoch": 0.06311581752515867,
      "grad_norm": 0.27356627583503723,
      "learning_rate": 4.960770046725285e-05,
      "loss": 0.1325,
      "step": 1800
    },
    {
      "epoch": 0.06662225183211193,
      "grad_norm": 0.20781652629375458,
      "learning_rate": 4.9585784292239044e-05,
      "loss": 0.1245,
      "step": 1900
    },
    {
      "epoch": 0.07012868613906519,
      "grad_norm": 0.2245895266532898,
      "learning_rate": 4.9563868117225234e-05,
      "loss": 0.1287,
      "step": 2000
    },
    {
      "epoch": 0.07363512044601844,
      "grad_norm": 0.19554094970226288,
      "learning_rate": 4.954195194221143e-05,
      "loss": 0.1247,
      "step": 2100
    },
    {
      "epoch": 0.0771415547529717,
      "grad_norm": 0.19346235692501068,
      "learning_rate": 4.952003576719763e-05,
      "loss": 0.1316,
      "step": 2200
    },
    {
      "epoch": 0.08064798905992496,
      "grad_norm": 0.25406351685523987,
      "learning_rate": 4.949811959218382e-05,
      "loss": 0.1263,
      "step": 2300
    },
    {
      "epoch": 0.08415442336687823,
      "grad_norm": 0.18491433560848236,
      "learning_rate": 4.947620341717001e-05,
      "loss": 0.125,
      "step": 2400
    },
    {
      "epoch": 0.08766085767383149,
      "grad_norm": 0.18545451760292053,
      "learning_rate": 4.9454287242156206e-05,
      "loss": 0.1207,
      "step": 2500
    },
    {
      "epoch": 0.09116729198078474,
      "grad_norm": 0.1908271312713623,
      "learning_rate": 4.9432371067142396e-05,
      "loss": 0.1271,
      "step": 2600
    },
    {
      "epoch": 0.094673726287738,
      "grad_norm": 0.19782637059688568,
      "learning_rate": 4.9410454892128586e-05,
      "loss": 0.1177,
      "step": 2700
    },
    {
      "epoch": 0.09818016059469126,
      "grad_norm": 0.10664897412061691,
      "learning_rate": 4.938853871711478e-05,
      "loss": 0.1203,
      "step": 2800
    },
    {
      "epoch": 0.10168659490164451,
      "grad_norm": 0.2212156057357788,
      "learning_rate": 4.9366622542100974e-05,
      "loss": 0.1184,
      "step": 2900
    },
    {
      "epoch": 0.10519302920859777,
      "grad_norm": 0.22329482436180115,
      "learning_rate": 4.934470636708717e-05,
      "loss": 0.1075,
      "step": 3000
    },
    {
      "epoch": 0.10869946351555104,
      "grad_norm": 0.33723050355911255,
      "learning_rate": 4.932279019207336e-05,
      "loss": 0.1124,
      "step": 3100
    },
    {
      "epoch": 0.1122058978225043,
      "grad_norm": 0.3744412362575531,
      "learning_rate": 4.930087401705955e-05,
      "loss": 0.1159,
      "step": 3200
    },
    {
      "epoch": 0.11571233212945756,
      "grad_norm": 0.2047894448041916,
      "learning_rate": 4.927895784204575e-05,
      "loss": 0.1135,
      "step": 3300
    },
    {
      "epoch": 0.11921876643641081,
      "grad_norm": 0.22935326397418976,
      "learning_rate": 4.925704166703194e-05,
      "loss": 0.1061,
      "step": 3400
    },
    {
      "epoch": 0.12272520074336407,
      "grad_norm": 0.12735116481781006,
      "learning_rate": 4.923512549201813e-05,
      "loss": 0.1042,
      "step": 3500
    },
    {
      "epoch": 0.12623163505031734,
      "grad_norm": 0.24674159288406372,
      "learning_rate": 4.921320931700432e-05,
      "loss": 0.1037,
      "step": 3600
    },
    {
      "epoch": 0.12973806935727059,
      "grad_norm": 0.2555341422557831,
      "learning_rate": 4.919129314199052e-05,
      "loss": 0.104,
      "step": 3700
    },
    {
      "epoch": 0.13324450366422386,
      "grad_norm": 0.11733219772577286,
      "learning_rate": 4.916937696697671e-05,
      "loss": 0.0979,
      "step": 3800
    },
    {
      "epoch": 0.1367509379711771,
      "grad_norm": 0.22003963589668274,
      "learning_rate": 4.9147460791962904e-05,
      "loss": 0.1019,
      "step": 3900
    },
    {
      "epoch": 0.14025737227813037,
      "grad_norm": 0.21716701984405518,
      "learning_rate": 4.9125544616949095e-05,
      "loss": 0.1013,
      "step": 4000
    },
    {
      "epoch": 0.14376380658508364,
      "grad_norm": 0.23721668124198914,
      "learning_rate": 4.910362844193529e-05,
      "loss": 0.1045,
      "step": 4100
    },
    {
      "epoch": 0.14727024089203689,
      "grad_norm": 0.2312726229429245,
      "learning_rate": 4.908171226692148e-05,
      "loss": 0.0976,
      "step": 4200
    },
    {
      "epoch": 0.15077667519899016,
      "grad_norm": 0.21560005843639374,
      "learning_rate": 4.905979609190767e-05,
      "loss": 0.0993,
      "step": 4300
    },
    {
      "epoch": 0.1542831095059434,
      "grad_norm": 0.24369490146636963,
      "learning_rate": 4.903787991689386e-05,
      "loss": 0.0977,
      "step": 4400
    },
    {
      "epoch": 0.15778954381289667,
      "grad_norm": 0.3482970893383026,
      "learning_rate": 4.901596374188006e-05,
      "loss": 0.1007,
      "step": 4500
    },
    {
      "epoch": 0.16129597811984991,
      "grad_norm": 0.16717161238193512,
      "learning_rate": 4.899404756686625e-05,
      "loss": 0.0936,
      "step": 4600
    },
    {
      "epoch": 0.16480241242680319,
      "grad_norm": 0.26941072940826416,
      "learning_rate": 4.897213139185245e-05,
      "loss": 0.1013,
      "step": 4700
    },
    {
      "epoch": 0.16830884673375646,
      "grad_norm": 0.20076145231723785,
      "learning_rate": 4.895021521683864e-05,
      "loss": 0.0927,
      "step": 4800
    },
    {
      "epoch": 0.1718152810407097,
      "grad_norm": 0.22875772416591644,
      "learning_rate": 4.8928299041824835e-05,
      "loss": 0.0911,
      "step": 4900
    },
    {
      "epoch": 0.17532171534766297,
      "grad_norm": 0.30258870124816895,
      "learning_rate": 4.8906382866811025e-05,
      "loss": 0.0917,
      "step": 5000
    },
    {
      "epoch": 0.17882814965461621,
      "grad_norm": 0.20302467048168182,
      "learning_rate": 4.8884466691797215e-05,
      "loss": 0.0897,
      "step": 5100
    },
    {
      "epoch": 0.18233458396156949,
      "grad_norm": 0.17600460350513458,
      "learning_rate": 4.886255051678341e-05,
      "loss": 0.0923,
      "step": 5200
    },
    {
      "epoch": 0.18584101826852273,
      "grad_norm": 0.22276625037193298,
      "learning_rate": 4.88406343417696e-05,
      "loss": 0.0908,
      "step": 5300
    },
    {
      "epoch": 0.189347452575476,
      "grad_norm": 0.21330001950263977,
      "learning_rate": 4.881871816675579e-05,
      "loss": 0.0874,
      "step": 5400
    },
    {
      "epoch": 0.19285388688242927,
      "grad_norm": 0.24442021548748016,
      "learning_rate": 4.879680199174198e-05,
      "loss": 0.0921,
      "step": 5500
    },
    {
      "epoch": 0.19636032118938251,
      "grad_norm": 0.1888360232114792,
      "learning_rate": 4.877488581672818e-05,
      "loss": 0.0884,
      "step": 5600
    },
    {
      "epoch": 0.19986675549633579,
      "grad_norm": 0.14676544070243835,
      "learning_rate": 4.875296964171438e-05,
      "loss": 0.0918,
      "step": 5700
    },
    {
      "epoch": 0.20337318980328903,
      "grad_norm": 0.28331318497657776,
      "learning_rate": 4.873105346670057e-05,
      "loss": 0.091,
      "step": 5800
    },
    {
      "epoch": 0.2068796241102423,
      "grad_norm": 0.4284195899963379,
      "learning_rate": 4.870913729168676e-05,
      "loss": 0.0917,
      "step": 5900
    },
    {
      "epoch": 0.21038605841719554,
      "grad_norm": 0.2920475900173187,
      "learning_rate": 4.8687221116672955e-05,
      "loss": 0.0933,
      "step": 6000
    },
    {
      "epoch": 0.2138924927241488,
      "grad_norm": 0.16418154537677765,
      "learning_rate": 4.8665304941659146e-05,
      "loss": 0.0872,
      "step": 6100
    },
    {
      "epoch": 0.21739892703110208,
      "grad_norm": 0.16901148855686188,
      "learning_rate": 4.8643388766645336e-05,
      "loss": 0.0866,
      "step": 6200
    },
    {
      "epoch": 0.22090536133805533,
      "grad_norm": 0.1929229348897934,
      "learning_rate": 4.8621472591631526e-05,
      "loss": 0.0778,
      "step": 6300
    },
    {
      "epoch": 0.2244117956450086,
      "grad_norm": 0.22737540304660797,
      "learning_rate": 4.859955641661772e-05,
      "loss": 0.0878,
      "step": 6400
    },
    {
      "epoch": 0.22791822995196184,
      "grad_norm": 0.2500922381877899,
      "learning_rate": 4.8577640241603914e-05,
      "loss": 0.0808,
      "step": 6500
    },
    {
      "epoch": 0.2314246642589151,
      "grad_norm": 0.17852596938610077,
      "learning_rate": 4.855572406659011e-05,
      "loss": 0.0837,
      "step": 6600
    },
    {
      "epoch": 0.23493109856586836,
      "grad_norm": 0.24339474737644196,
      "learning_rate": 4.85338078915763e-05,
      "loss": 0.0871,
      "step": 6700
    },
    {
      "epoch": 0.23843753287282163,
      "grad_norm": 0.22918954491615295,
      "learning_rate": 4.85118917165625e-05,
      "loss": 0.0813,
      "step": 6800
    },
    {
      "epoch": 0.2419439671797749,
      "grad_norm": 0.470971941947937,
      "learning_rate": 4.848997554154869e-05,
      "loss": 0.0838,
      "step": 6900
    },
    {
      "epoch": 0.24545040148672814,
      "grad_norm": 0.13935759663581848,
      "learning_rate": 4.846805936653488e-05,
      "loss": 0.0828,
      "step": 7000
    },
    {
      "epoch": 0.2489568357936814,
      "grad_norm": 0.1617506444454193,
      "learning_rate": 4.844614319152107e-05,
      "loss": 0.084,
      "step": 7100
    },
    {
      "epoch": 0.2524632701006347,
      "grad_norm": 0.15928111970424652,
      "learning_rate": 4.8424227016507266e-05,
      "loss": 0.0841,
      "step": 7200
    },
    {
      "epoch": 0.25596970440758793,
      "grad_norm": 0.24921058118343353,
      "learning_rate": 4.8402310841493457e-05,
      "loss": 0.0863,
      "step": 7300
    },
    {
      "epoch": 0.25947613871454117,
      "grad_norm": 0.21608473360538483,
      "learning_rate": 4.8380394666479654e-05,
      "loss": 0.0837,
      "step": 7400
    },
    {
      "epoch": 0.2629825730214944,
      "grad_norm": 0.21309655904769897,
      "learning_rate": 4.8358478491465844e-05,
      "loss": 0.085,
      "step": 7500
    },
    {
      "epoch": 0.2664890073284477,
      "grad_norm": 0.18077103793621063,
      "learning_rate": 4.833656231645204e-05,
      "loss": 0.0848,
      "step": 7600
    },
    {
      "epoch": 0.26999544163540096,
      "grad_norm": 0.2400263547897339,
      "learning_rate": 4.831464614143823e-05,
      "loss": 0.0806,
      "step": 7700
    },
    {
      "epoch": 0.2735018759423542,
      "grad_norm": 0.1814783662557602,
      "learning_rate": 4.829272996642442e-05,
      "loss": 0.0855,
      "step": 7800
    },
    {
      "epoch": 0.2770083102493075,
      "grad_norm": 0.1984332799911499,
      "learning_rate": 4.827081379141061e-05,
      "loss": 0.0827,
      "step": 7900
    },
    {
      "epoch": 0.28051474455626074,
      "grad_norm": 0.2175535261631012,
      "learning_rate": 4.824889761639681e-05,
      "loss": 0.0814,
      "step": 8000
    },
    {
      "epoch": 0.284021178863214,
      "grad_norm": 0.226277694106102,
      "learning_rate": 4.8226981441383e-05,
      "loss": 0.0812,
      "step": 8100
    },
    {
      "epoch": 0.2875276131701673,
      "grad_norm": 0.2213815152645111,
      "learning_rate": 4.820506526636919e-05,
      "loss": 0.0789,
      "step": 8200
    },
    {
      "epoch": 0.2910340474771205,
      "grad_norm": 0.3473301827907562,
      "learning_rate": 4.818314909135539e-05,
      "loss": 0.084,
      "step": 8300
    },
    {
      "epoch": 0.29454048178407377,
      "grad_norm": 0.19758407771587372,
      "learning_rate": 4.8161232916341584e-05,
      "loss": 0.0793,
      "step": 8400
    },
    {
      "epoch": 0.298046916091027,
      "grad_norm": 0.2570754289627075,
      "learning_rate": 4.8139316741327774e-05,
      "loss": 0.0762,
      "step": 8500
    },
    {
      "epoch": 0.3015533503979803,
      "grad_norm": 0.22624324262142181,
      "learning_rate": 4.8117400566313965e-05,
      "loss": 0.0782,
      "step": 8600
    },
    {
      "epoch": 0.30505978470493356,
      "grad_norm": 0.1325407177209854,
      "learning_rate": 4.8095484391300155e-05,
      "loss": 0.0824,
      "step": 8700
    },
    {
      "epoch": 0.3085662190118868,
      "grad_norm": 0.20689716935157776,
      "learning_rate": 4.807356821628635e-05,
      "loss": 0.0799,
      "step": 8800
    },
    {
      "epoch": 0.3120726533188401,
      "grad_norm": 0.3319401443004608,
      "learning_rate": 4.805165204127254e-05,
      "loss": 0.0778,
      "step": 8900
    },
    {
      "epoch": 0.31557908762579334,
      "grad_norm": 0.19049915671348572,
      "learning_rate": 4.802973586625873e-05,
      "loss": 0.0809,
      "step": 9000
    },
    {
      "epoch": 0.3190855219327466,
      "grad_norm": 0.23659950494766235,
      "learning_rate": 4.800781969124492e-05,
      "loss": 0.0792,
      "step": 9100
    },
    {
      "epoch": 0.32259195623969983,
      "grad_norm": 0.1846567839384079,
      "learning_rate": 4.798590351623112e-05,
      "loss": 0.0765,
      "step": 9200
    },
    {
      "epoch": 0.3260983905466531,
      "grad_norm": 0.2017209231853485,
      "learning_rate": 4.796398734121732e-05,
      "loss": 0.0805,
      "step": 9300
    },
    {
      "epoch": 0.32960482485360637,
      "grad_norm": 0.16946998238563538,
      "learning_rate": 4.794207116620351e-05,
      "loss": 0.0752,
      "step": 9400
    },
    {
      "epoch": 0.3331112591605596,
      "grad_norm": 0.24879173934459686,
      "learning_rate": 4.79201549911897e-05,
      "loss": 0.0736,
      "step": 9500
    },
    {
      "epoch": 0.3366176934675129,
      "grad_norm": 0.19794587790966034,
      "learning_rate": 4.7898238816175895e-05,
      "loss": 0.0773,
      "step": 9600
    },
    {
      "epoch": 0.34012412777446616,
      "grad_norm": 0.13650378584861755,
      "learning_rate": 4.7876322641162085e-05,
      "loss": 0.0826,
      "step": 9700
    },
    {
      "epoch": 0.3436305620814194,
      "grad_norm": 0.316110759973526,
      "learning_rate": 4.7854406466148276e-05,
      "loss": 0.0773,
      "step": 9800
    },
    {
      "epoch": 0.34713699638837264,
      "grad_norm": 0.13296391069889069,
      "learning_rate": 4.7832490291134466e-05,
      "loss": 0.0798,
      "step": 9900
    },
    {
      "epoch": 0.35064343069532594,
      "grad_norm": 0.1697620302438736,
      "learning_rate": 4.781057411612066e-05,
      "loss": 0.0796,
      "step": 10000
    },
    {
      "epoch": 0.3541498650022792,
      "grad_norm": 0.2010900229215622,
      "learning_rate": 4.778865794110686e-05,
      "loss": 0.0749,
      "step": 10100
    },
    {
      "epoch": 0.35765629930923243,
      "grad_norm": 0.2894188165664673,
      "learning_rate": 4.776674176609305e-05,
      "loss": 0.078,
      "step": 10200
    },
    {
      "epoch": 0.3611627336161857,
      "grad_norm": 0.2227107435464859,
      "learning_rate": 4.774482559107924e-05,
      "loss": 0.0754,
      "step": 10300
    },
    {
      "epoch": 0.36466916792313897,
      "grad_norm": 0.25445201992988586,
      "learning_rate": 4.772290941606544e-05,
      "loss": 0.0718,
      "step": 10400
    },
    {
      "epoch": 0.3681756022300922,
      "grad_norm": 0.23287348449230194,
      "learning_rate": 4.7701212402801764e-05,
      "loss": 0.078,
      "step": 10500
    },
    {
      "epoch": 0.37168203653704546,
      "grad_norm": 0.22106075286865234,
      "learning_rate": 4.7679296227787954e-05,
      "loss": 0.0753,
      "step": 10600
    },
    {
      "epoch": 0.37518847084399876,
      "grad_norm": 0.17950862646102905,
      "learning_rate": 4.765738005277415e-05,
      "loss": 0.0763,
      "step": 10700
    },
    {
      "epoch": 0.378694905150952,
      "grad_norm": 0.24146166443824768,
      "learning_rate": 4.763546387776034e-05,
      "loss": 0.0808,
      "step": 10800
    },
    {
      "epoch": 0.38220133945790524,
      "grad_norm": 0.28185954689979553,
      "learning_rate": 4.761354770274654e-05,
      "loss": 0.0803,
      "step": 10900
    },
    {
      "epoch": 0.38570777376485854,
      "grad_norm": 0.2180556058883667,
      "learning_rate": 4.759163152773273e-05,
      "loss": 0.0737,
      "step": 11000
    },
    {
      "epoch": 0.3892142080718118,
      "grad_norm": 0.2370724380016327,
      "learning_rate": 4.7569715352718926e-05,
      "loss": 0.0727,
      "step": 11100
    },
    {
      "epoch": 0.39272064237876503,
      "grad_norm": 0.22693604230880737,
      "learning_rate": 4.7547799177705117e-05,
      "loss": 0.0736,
      "step": 11200
    },
    {
      "epoch": 0.39622707668571827,
      "grad_norm": 0.18131579458713531,
      "learning_rate": 4.752588300269131e-05,
      "loss": 0.0757,
      "step": 11300
    },
    {
      "epoch": 0.39973351099267157,
      "grad_norm": 0.21889233589172363,
      "learning_rate": 4.7503966827677504e-05,
      "loss": 0.076,
      "step": 11400
    },
    {
      "epoch": 0.4032399452996248,
      "grad_norm": 0.2919410467147827,
      "learning_rate": 4.7482050652663694e-05,
      "loss": 0.0754,
      "step": 11500
    },
    {
      "epoch": 0.40674637960657806,
      "grad_norm": 0.37456268072128296,
      "learning_rate": 4.7460134477649885e-05,
      "loss": 0.0688,
      "step": 11600
    },
    {
      "epoch": 0.41025281391353136,
      "grad_norm": 0.24394485354423523,
      "learning_rate": 4.7438218302636075e-05,
      "loss": 0.0728,
      "step": 11700
    },
    {
      "epoch": 0.4137592482204846,
      "grad_norm": 0.18366162478923798,
      "learning_rate": 4.741630212762227e-05,
      "loss": 0.0731,
      "step": 11800
    },
    {
      "epoch": 0.41726568252743784,
      "grad_norm": 0.2022600919008255,
      "learning_rate": 4.739438595260847e-05,
      "loss": 0.0737,
      "step": 11900
    },
    {
      "epoch": 0.4207721168343911,
      "grad_norm": 0.24143065512180328,
      "learning_rate": 4.737246977759466e-05,
      "loss": 0.0718,
      "step": 12000
    },
    {
      "epoch": 0.4242785511413444,
      "grad_norm": 0.27899810671806335,
      "learning_rate": 4.735055360258085e-05,
      "loss": 0.075,
      "step": 12100
    },
    {
      "epoch": 0.4277849854482976,
      "grad_norm": 0.1779996156692505,
      "learning_rate": 4.732863742756705e-05,
      "loss": 0.0718,
      "step": 12200
    },
    {
      "epoch": 0.43129141975525087,
      "grad_norm": 0.3211350440979004,
      "learning_rate": 4.730672125255324e-05,
      "loss": 0.0777,
      "step": 12300
    },
    {
      "epoch": 0.43479785406220417,
      "grad_norm": 0.25922223925590515,
      "learning_rate": 4.728480507753943e-05,
      "loss": 0.0723,
      "step": 12400
    },
    {
      "epoch": 0.4383042883691574,
      "grad_norm": 0.12023616582155228,
      "learning_rate": 4.726288890252562e-05,
      "loss": 0.0722,
      "step": 12500
    },
    {
      "epoch": 0.44181072267611066,
      "grad_norm": 0.2750953137874603,
      "learning_rate": 4.724119188926196e-05,
      "loss": 0.0729,
      "step": 12600
    },
    {
      "epoch": 0.4453171569830639,
      "grad_norm": 0.21292656660079956,
      "learning_rate": 4.721927571424815e-05,
      "loss": 0.076,
      "step": 12700
    },
    {
      "epoch": 0.4488235912900172,
      "grad_norm": 0.12080748379230499,
      "learning_rate": 4.719735953923434e-05,
      "loss": 0.0717,
      "step": 12800
    },
    {
      "epoch": 0.45233002559697044,
      "grad_norm": 0.13753663003444672,
      "learning_rate": 4.7175443364220535e-05,
      "loss": 0.0748,
      "step": 12900
    },
    {
      "epoch": 0.4558364599039237,
      "grad_norm": 0.25737375020980835,
      "learning_rate": 4.7153527189206726e-05,
      "loss": 0.0751,
      "step": 13000
    },
    {
      "epoch": 0.459342894210877,
      "grad_norm": 0.27234378457069397,
      "learning_rate": 4.7131611014192916e-05,
      "loss": 0.0713,
      "step": 13100
    },
    {
      "epoch": 0.4628493285178302,
      "grad_norm": 0.22342532873153687,
      "learning_rate": 4.7109694839179106e-05,
      "loss": 0.0714,
      "step": 13200
    },
    {
      "epoch": 0.46635576282478347,
      "grad_norm": 0.3175855576992035,
      "learning_rate": 4.70877786641653e-05,
      "loss": 0.0698,
      "step": 13300
    },
    {
      "epoch": 0.4698621971317367,
      "grad_norm": 0.2446613311767578,
      "learning_rate": 4.7065862489151494e-05,
      "loss": 0.0734,
      "step": 13400
    },
    {
      "epoch": 0.47336863143869,
      "grad_norm": 0.18188051879405975,
      "learning_rate": 4.704394631413769e-05,
      "loss": 0.0688,
      "step": 13500
    },
    {
      "epoch": 0.47687506574564326,
      "grad_norm": 0.21757656335830688,
      "learning_rate": 4.702203013912388e-05,
      "loss": 0.0722,
      "step": 13600
    },
    {
      "epoch": 0.4803815000525965,
      "grad_norm": 0.18333163857460022,
      "learning_rate": 4.700011396411008e-05,
      "loss": 0.0706,
      "step": 13700
    },
    {
      "epoch": 0.4838879343595498,
      "grad_norm": 0.25649523735046387,
      "learning_rate": 4.697819778909627e-05,
      "loss": 0.0712,
      "step": 13800
    },
    {
      "epoch": 0.48739436866650304,
      "grad_norm": 0.1578381061553955,
      "learning_rate": 4.695628161408246e-05,
      "loss": 0.0719,
      "step": 13900
    },
    {
      "epoch": 0.4909008029734563,
      "grad_norm": 0.24661701917648315,
      "learning_rate": 4.693436543906865e-05,
      "loss": 0.0735,
      "step": 14000
    },
    {
      "epoch": 0.49440723728040953,
      "grad_norm": 0.17496922612190247,
      "learning_rate": 4.6912449264054846e-05,
      "loss": 0.0695,
      "step": 14100
    },
    {
      "epoch": 0.4979136715873628,
      "grad_norm": 0.16896039247512817,
      "learning_rate": 4.6890533089041037e-05,
      "loss": 0.0691,
      "step": 14200
    },
    {
      "epoch": 0.5014201058943161,
      "grad_norm": 0.2784472107887268,
      "learning_rate": 4.686861691402723e-05,
      "loss": 0.0677,
      "step": 14300
    },
    {
      "epoch": 0.5049265402012694,
      "grad_norm": 0.21062308549880981,
      "learning_rate": 4.6846700739013424e-05,
      "loss": 0.0729,
      "step": 14400
    },
    {
      "epoch": 0.5084329745082226,
      "grad_norm": 0.12898318469524384,
      "learning_rate": 4.682478456399962e-05,
      "loss": 0.0678,
      "step": 14500
    },
    {
      "epoch": 0.5119394088151759,
      "grad_norm": 0.15987418591976166,
      "learning_rate": 4.680286838898581e-05,
      "loss": 0.0735,
      "step": 14600
    },
    {
      "epoch": 0.5154458431221292,
      "grad_norm": 0.2554774582386017,
      "learning_rate": 4.6780952213972e-05,
      "loss": 0.0705,
      "step": 14700
    },
    {
      "epoch": 0.5189522774290823,
      "grad_norm": 0.20356783270835876,
      "learning_rate": 4.675903603895819e-05,
      "loss": 0.074,
      "step": 14800
    },
    {
      "epoch": 0.5224587117360356,
      "grad_norm": 0.19301235675811768,
      "learning_rate": 4.673711986394439e-05,
      "loss": 0.0703,
      "step": 14900
    },
    {
      "epoch": 0.5259651460429888,
      "grad_norm": 0.18183456361293793,
      "learning_rate": 4.671520368893058e-05,
      "loss": 0.0704,
      "step": 15000
    },
    {
      "epoch": 0.5294715803499421,
      "grad_norm": 0.15861378610134125,
      "learning_rate": 4.669328751391677e-05,
      "loss": 0.0663,
      "step": 15100
    },
    {
      "epoch": 0.5329780146568954,
      "grad_norm": 0.45285776257514954,
      "learning_rate": 4.667137133890297e-05,
      "loss": 0.0725,
      "step": 15200
    },
    {
      "epoch": 0.5364844489638486,
      "grad_norm": 0.3434939384460449,
      "learning_rate": 4.6649455163889164e-05,
      "loss": 0.0701,
      "step": 15300
    },
    {
      "epoch": 0.5399908832708019,
      "grad_norm": 0.15138258039951324,
      "learning_rate": 4.6627538988875354e-05,
      "loss": 0.0724,
      "step": 15400
    },
    {
      "epoch": 0.5434973175777552,
      "grad_norm": 0.17721600830554962,
      "learning_rate": 4.6605622813861545e-05,
      "loss": 0.0704,
      "step": 15500
    },
    {
      "epoch": 0.5470037518847084,
      "grad_norm": 0.23916594684123993,
      "learning_rate": 4.6583706638847735e-05,
      "loss": 0.0702,
      "step": 15600
    },
    {
      "epoch": 0.5505101861916617,
      "grad_norm": 0.2724175751209259,
      "learning_rate": 4.656179046383393e-05,
      "loss": 0.0684,
      "step": 15700
    },
    {
      "epoch": 0.554016620498615,
      "grad_norm": 0.1939619481563568,
      "learning_rate": 4.653987428882012e-05,
      "loss": 0.0676,
      "step": 15800
    },
    {
      "epoch": 0.5575230548055682,
      "grad_norm": 0.2064906507730484,
      "learning_rate": 4.651795811380631e-05,
      "loss": 0.0666,
      "step": 15900
    },
    {
      "epoch": 0.5610294891125215,
      "grad_norm": 0.21638785302639008,
      "learning_rate": 4.64960419387925e-05,
      "loss": 0.0684,
      "step": 16000
    },
    {
      "epoch": 0.5645359234194748,
      "grad_norm": 0.14393556118011475,
      "learning_rate": 4.647434492552884e-05,
      "loss": 0.0705,
      "step": 16100
    },
    {
      "epoch": 0.568042357726428,
      "grad_norm": 0.1057448759675026,
      "learning_rate": 4.645242875051503e-05,
      "loss": 0.0685,
      "step": 16200
    },
    {
      "epoch": 0.5715487920333813,
      "grad_norm": 0.23224356770515442,
      "learning_rate": 4.643051257550122e-05,
      "loss": 0.068,
      "step": 16300
    },
    {
      "epoch": 0.5750552263403346,
      "grad_norm": 0.23701171576976776,
      "learning_rate": 4.640859640048742e-05,
      "loss": 0.0743,
      "step": 16400
    },
    {
      "epoch": 0.5785616606472878,
      "grad_norm": 0.2674590051174164,
      "learning_rate": 4.638668022547361e-05,
      "loss": 0.07,
      "step": 16500
    },
    {
      "epoch": 0.582068094954241,
      "grad_norm": 0.13298697769641876,
      "learning_rate": 4.63647640504598e-05,
      "loss": 0.069,
      "step": 16600
    },
    {
      "epoch": 0.5855745292611942,
      "grad_norm": 0.21957579255104065,
      "learning_rate": 4.634284787544599e-05,
      "loss": 0.0692,
      "step": 16700
    },
    {
      "epoch": 0.5890809635681475,
      "grad_norm": 0.36279016733169556,
      "learning_rate": 4.632093170043219e-05,
      "loss": 0.0688,
      "step": 16800
    },
    {
      "epoch": 0.5925873978751008,
      "grad_norm": 0.13676050305366516,
      "learning_rate": 4.6299015525418386e-05,
      "loss": 0.0656,
      "step": 16900
    },
    {
      "epoch": 0.596093832182054,
      "grad_norm": 0.19455917179584503,
      "learning_rate": 4.6277099350404576e-05,
      "loss": 0.0722,
      "step": 17000
    },
    {
      "epoch": 0.5996002664890073,
      "grad_norm": 0.2823669910430908,
      "learning_rate": 4.6255183175390766e-05,
      "loss": 0.0697,
      "step": 17100
    },
    {
      "epoch": 0.6031067007959606,
      "grad_norm": 0.16301943361759186,
      "learning_rate": 4.623326700037696e-05,
      "loss": 0.0689,
      "step": 17200
    },
    {
      "epoch": 0.6066131351029138,
      "grad_norm": 0.22935393452644348,
      "learning_rate": 4.6211350825363154e-05,
      "loss": 0.066,
      "step": 17300
    },
    {
      "epoch": 0.6101195694098671,
      "grad_norm": 0.21661676466464996,
      "learning_rate": 4.6189434650349344e-05,
      "loss": 0.0662,
      "step": 17400
    },
    {
      "epoch": 0.6136260037168204,
      "grad_norm": 0.11029300093650818,
      "learning_rate": 4.6167518475335534e-05,
      "loss": 0.0681,
      "step": 17500
    },
    {
      "epoch": 0.6171324380237736,
      "grad_norm": 0.23038513958454132,
      "learning_rate": 4.614560230032173e-05,
      "loss": 0.064,
      "step": 17600
    },
    {
      "epoch": 0.6206388723307269,
      "grad_norm": 0.19661524891853333,
      "learning_rate": 4.612368612530792e-05,
      "loss": 0.0696,
      "step": 17700
    },
    {
      "epoch": 0.6241453066376802,
      "grad_norm": 0.25729790329933167,
      "learning_rate": 4.610176995029412e-05,
      "loss": 0.0706,
      "step": 17800
    },
    {
      "epoch": 0.6276517409446334,
      "grad_norm": 0.2717626392841339,
      "learning_rate": 4.6079853775280316e-05,
      "loss": 0.0683,
      "step": 17900
    },
    {
      "epoch": 0.6311581752515867,
      "grad_norm": 0.14745686948299408,
      "learning_rate": 4.6057937600266506e-05,
      "loss": 0.0711,
      "step": 18000
    },
    {
      "epoch": 0.6346646095585399,
      "grad_norm": 0.1530572474002838,
      "learning_rate": 4.6036021425252696e-05,
      "loss": 0.0677,
      "step": 18100
    },
    {
      "epoch": 0.6381710438654932,
      "grad_norm": 0.23203127086162567,
      "learning_rate": 4.601410525023889e-05,
      "loss": 0.0681,
      "step": 18200
    },
    {
      "epoch": 0.6416774781724465,
      "grad_norm": 0.20687033236026764,
      "learning_rate": 4.5992189075225084e-05,
      "loss": 0.0708,
      "step": 18300
    },
    {
      "epoch": 0.6451839124793997,
      "grad_norm": 0.2672192454338074,
      "learning_rate": 4.5970272900211274e-05,
      "loss": 0.0659,
      "step": 18400
    },
    {
      "epoch": 0.648690346786353,
      "grad_norm": 0.19809633493423462,
      "learning_rate": 4.5948356725197465e-05,
      "loss": 0.0633,
      "step": 18500
    },
    {
      "epoch": 0.6521967810933063,
      "grad_norm": 0.12311244755983353,
      "learning_rate": 4.5926440550183655e-05,
      "loss": 0.0657,
      "step": 18600
    },
    {
      "epoch": 0.6557032154002594,
      "grad_norm": 0.192540243268013,
      "learning_rate": 4.590452437516985e-05,
      "loss": 0.072,
      "step": 18700
    },
    {
      "epoch": 0.6592096497072127,
      "grad_norm": 0.13864478468894958,
      "learning_rate": 4.588260820015605e-05,
      "loss": 0.069,
      "step": 18800
    },
    {
      "epoch": 0.662716084014166,
      "grad_norm": 0.14241863787174225,
      "learning_rate": 4.5860911186892375e-05,
      "loss": 0.0728,
      "step": 18900
    },
    {
      "epoch": 0.6662225183211192,
      "grad_norm": 0.19980351626873016,
      "learning_rate": 4.583899501187857e-05,
      "loss": 0.0704,
      "step": 19000
    },
    {
      "epoch": 0.6697289526280725,
      "grad_norm": 0.20764321088790894,
      "learning_rate": 4.581707883686476e-05,
      "loss": 0.0706,
      "step": 19100
    },
    {
      "epoch": 0.6732353869350258,
      "grad_norm": 0.14102421700954437,
      "learning_rate": 4.579516266185095e-05,
      "loss": 0.0635,
      "step": 19200
    },
    {
      "epoch": 0.676741821241979,
      "grad_norm": 0.2648126184940338,
      "learning_rate": 4.577324648683714e-05,
      "loss": 0.0678,
      "step": 19300
    },
    {
      "epoch": 0.6802482555489323,
      "grad_norm": 0.11652907729148865,
      "learning_rate": 4.575133031182334e-05,
      "loss": 0.072,
      "step": 19400
    },
    {
      "epoch": 0.6837546898558855,
      "grad_norm": 0.18129576742649078,
      "learning_rate": 4.572941413680954e-05,
      "loss": 0.0659,
      "step": 19500
    },
    {
      "epoch": 0.6872611241628388,
      "grad_norm": 0.22129935026168823,
      "learning_rate": 4.570749796179573e-05,
      "loss": 0.0665,
      "step": 19600
    },
    {
      "epoch": 0.6907675584697921,
      "grad_norm": 0.334786593914032,
      "learning_rate": 4.568558178678192e-05,
      "loss": 0.0668,
      "step": 19700
    },
    {
      "epoch": 0.6942739927767453,
      "grad_norm": 0.2270861715078354,
      "learning_rate": 4.5663665611768115e-05,
      "loss": 0.0676,
      "step": 19800
    },
    {
      "epoch": 0.6977804270836986,
      "grad_norm": 0.19968369603157043,
      "learning_rate": 4.5641749436754305e-05,
      "loss": 0.0667,
      "step": 19900
    },
    {
      "epoch": 0.7012868613906519,
      "grad_norm": 0.15249095857143402,
      "learning_rate": 4.5619833261740496e-05,
      "loss": 0.0666,
      "step": 20000
    },
    {
      "epoch": 0.7047932956976051,
      "grad_norm": 0.2283490151166916,
      "learning_rate": 4.5597917086726686e-05,
      "loss": 0.0653,
      "step": 20100
    },
    {
      "epoch": 0.7082997300045584,
      "grad_norm": 0.11958608031272888,
      "learning_rate": 4.557600091171288e-05,
      "loss": 0.0679,
      "step": 20200
    },
    {
      "epoch": 0.7118061643115117,
      "grad_norm": 0.1291319727897644,
      "learning_rate": 4.5554084736699074e-05,
      "loss": 0.0668,
      "step": 20300
    },
    {
      "epoch": 0.7153125986184649,
      "grad_norm": 0.26533353328704834,
      "learning_rate": 4.553216856168527e-05,
      "loss": 0.065,
      "step": 20400
    },
    {
      "epoch": 0.7188190329254182,
      "grad_norm": 0.20578792691230774,
      "learning_rate": 4.551025238667146e-05,
      "loss": 0.0675,
      "step": 20500
    },
    {
      "epoch": 0.7223254672323715,
      "grad_norm": 0.19381017982959747,
      "learning_rate": 4.548833621165766e-05,
      "loss": 0.0674,
      "step": 20600
    },
    {
      "epoch": 0.7258319015393246,
      "grad_norm": 0.23364390432834625,
      "learning_rate": 4.546642003664385e-05,
      "loss": 0.0658,
      "step": 20700
    },
    {
      "epoch": 0.7293383358462779,
      "grad_norm": 0.25672996044158936,
      "learning_rate": 4.544450386163004e-05,
      "loss": 0.0659,
      "step": 20800
    },
    {
      "epoch": 0.7328447701532311,
      "grad_norm": 0.12887239456176758,
      "learning_rate": 4.542258768661623e-05,
      "loss": 0.0687,
      "step": 20900
    },
    {
      "epoch": 0.7363512044601844,
      "grad_norm": 0.21379858255386353,
      "learning_rate": 4.5400671511602426e-05,
      "loss": 0.0667,
      "step": 21000
    },
    {
      "epoch": 0.7398576387671377,
      "grad_norm": 0.34360697865486145,
      "learning_rate": 4.5378755336588616e-05,
      "loss": 0.0664,
      "step": 21100
    },
    {
      "epoch": 0.7433640730740909,
      "grad_norm": 0.31768226623535156,
      "learning_rate": 4.535683916157481e-05,
      "loss": 0.0724,
      "step": 21200
    },
    {
      "epoch": 0.7468705073810442,
      "grad_norm": 0.28038957715034485,
      "learning_rate": 4.5335142148311146e-05,
      "loss": 0.0644,
      "step": 21300
    },
    {
      "epoch": 0.7503769416879975,
      "grad_norm": 0.11776915937662125,
      "learning_rate": 4.531322597329734e-05,
      "loss": 0.0636,
      "step": 21400
    },
    {
      "epoch": 0.7538833759949507,
      "grad_norm": 0.23613333702087402,
      "learning_rate": 4.529130979828353e-05,
      "loss": 0.0684,
      "step": 21500
    },
    {
      "epoch": 0.757389810301904,
      "grad_norm": 0.2291785627603531,
      "learning_rate": 4.526939362326972e-05,
      "loss": 0.0688,
      "step": 21600
    },
    {
      "epoch": 0.7608962446088573,
      "grad_norm": 0.2812376022338867,
      "learning_rate": 4.5247477448255914e-05,
      "loss": 0.0666,
      "step": 21700
    },
    {
      "epoch": 0.7644026789158105,
      "grad_norm": 0.1516338288784027,
      "learning_rate": 4.5225561273242105e-05,
      "loss": 0.0658,
      "step": 21800
    },
    {
      "epoch": 0.7679091132227638,
      "grad_norm": 0.23217761516571045,
      "learning_rate": 4.5203645098228295e-05,
      "loss": 0.0683,
      "step": 21900
    },
    {
      "epoch": 0.7714155475297171,
      "grad_norm": 0.13975602388381958,
      "learning_rate": 4.518172892321449e-05,
      "loss": 0.0627,
      "step": 22000
    },
    {
      "epoch": 0.7749219818366703,
      "grad_norm": 0.13517552614212036,
      "learning_rate": 4.515981274820069e-05,
      "loss": 0.0695,
      "step": 22100
    },
    {
      "epoch": 0.7784284161436236,
      "grad_norm": 0.15586382150650024,
      "learning_rate": 4.513789657318688e-05,
      "loss": 0.0627,
      "step": 22200
    },
    {
      "epoch": 0.7819348504505768,
      "grad_norm": 0.3726634085178375,
      "learning_rate": 4.511598039817307e-05,
      "loss": 0.0676,
      "step": 22300
    },
    {
      "epoch": 0.7854412847575301,
      "grad_norm": 0.2550276517868042,
      "learning_rate": 4.509406422315926e-05,
      "loss": 0.0616,
      "step": 22400
    },
    {
      "epoch": 0.7889477190644834,
      "grad_norm": 0.10960780084133148,
      "learning_rate": 4.507214804814546e-05,
      "loss": 0.0613,
      "step": 22500
    },
    {
      "epoch": 0.7924541533714365,
      "grad_norm": 0.29678335785865784,
      "learning_rate": 4.505023187313165e-05,
      "loss": 0.0668,
      "step": 22600
    },
    {
      "epoch": 0.7959605876783898,
      "grad_norm": 0.13336782157421112,
      "learning_rate": 4.502831569811784e-05,
      "loss": 0.0643,
      "step": 22700
    },
    {
      "epoch": 0.7994670219853431,
      "grad_norm": 0.20915095508098602,
      "learning_rate": 4.500639952310403e-05,
      "loss": 0.0653,
      "step": 22800
    },
    {
      "epoch": 0.8029734562922963,
      "grad_norm": 0.22195805609226227,
      "learning_rate": 4.4984483348090225e-05,
      "loss": 0.0614,
      "step": 22900
    },
    {
      "epoch": 0.8064798905992496,
      "grad_norm": 0.19157932698726654,
      "learning_rate": 4.496256717307642e-05,
      "loss": 0.0667,
      "step": 23000
    },
    {
      "epoch": 0.8099863249062029,
      "grad_norm": 0.22527319192886353,
      "learning_rate": 4.494065099806261e-05,
      "loss": 0.0689,
      "step": 23100
    },
    {
      "epoch": 0.8134927592131561,
      "grad_norm": 0.19853220880031586,
      "learning_rate": 4.49187348230488e-05,
      "loss": 0.0665,
      "step": 23200
    },
    {
      "epoch": 0.8169991935201094,
      "grad_norm": 0.14107219874858856,
      "learning_rate": 4.4896818648035e-05,
      "loss": 0.0588,
      "step": 23300
    },
    {
      "epoch": 0.8205056278270627,
      "grad_norm": 0.21402135491371155,
      "learning_rate": 4.487490247302119e-05,
      "loss": 0.0664,
      "step": 23400
    },
    {
      "epoch": 0.8240120621340159,
      "grad_norm": 0.1301242709159851,
      "learning_rate": 4.485298629800738e-05,
      "loss": 0.0666,
      "step": 23500
    },
    {
      "epoch": 0.8275184964409692,
      "grad_norm": 0.25272098183631897,
      "learning_rate": 4.483107012299357e-05,
      "loss": 0.0648,
      "step": 23600
    },
    {
      "epoch": 0.8310249307479224,
      "grad_norm": 0.19357776641845703,
      "learning_rate": 4.480915394797977e-05,
      "loss": 0.0632,
      "step": 23700
    },
    {
      "epoch": 0.8345313650548757,
      "grad_norm": 0.2347564995288849,
      "learning_rate": 4.478723777296596e-05,
      "loss": 0.0683,
      "step": 23800
    },
    {
      "epoch": 0.838037799361829,
      "grad_norm": 0.21824857592582703,
      "learning_rate": 4.4765321597952156e-05,
      "loss": 0.0681,
      "step": 23900
    },
    {
      "epoch": 0.8415442336687822,
      "grad_norm": 0.2637687921524048,
      "learning_rate": 4.4743405422938346e-05,
      "loss": 0.067,
      "step": 24000
    },
    {
      "epoch": 0.8450506679757355,
      "grad_norm": 0.23045594990253448,
      "learning_rate": 4.472148924792454e-05,
      "loss": 0.0697,
      "step": 24100
    },
    {
      "epoch": 0.8485571022826888,
      "grad_norm": 0.2874357998371124,
      "learning_rate": 4.4699573072910734e-05,
      "loss": 0.0676,
      "step": 24200
    },
    {
      "epoch": 0.852063536589642,
      "grad_norm": 0.12833371758460999,
      "learning_rate": 4.4677656897896924e-05,
      "loss": 0.0627,
      "step": 24300
    },
    {
      "epoch": 0.8555699708965953,
      "grad_norm": 0.15274488925933838,
      "learning_rate": 4.465574072288312e-05,
      "loss": 0.0679,
      "step": 24400
    },
    {
      "epoch": 0.8590764052035486,
      "grad_norm": 0.2125363051891327,
      "learning_rate": 4.463382454786931e-05,
      "loss": 0.0651,
      "step": 24500
    },
    {
      "epoch": 0.8625828395105017,
      "grad_norm": 0.1598985642194748,
      "learning_rate": 4.46119083728555e-05,
      "loss": 0.0642,
      "step": 24600
    },
    {
      "epoch": 0.866089273817455,
      "grad_norm": 0.22691206634044647,
      "learning_rate": 4.45899921978417e-05,
      "loss": 0.0636,
      "step": 24700
    },
    {
      "epoch": 0.8695957081244083,
      "grad_norm": 0.19342951476573944,
      "learning_rate": 4.4568076022827896e-05,
      "loss": 0.0623,
      "step": 24800
    },
    {
      "epoch": 0.8731021424313615,
      "grad_norm": 0.20983046293258667,
      "learning_rate": 4.4546159847814086e-05,
      "loss": 0.0651,
      "step": 24900
    },
    {
      "epoch": 0.8766085767383148,
      "grad_norm": 0.26104235649108887,
      "learning_rate": 4.4524243672800276e-05,
      "loss": 0.0656,
      "step": 25000
    },
    {
      "epoch": 0.880115011045268,
      "grad_norm": 0.2258068174123764,
      "learning_rate": 4.450232749778647e-05,
      "loss": 0.0655,
      "step": 25100
    },
    {
      "epoch": 0.8836214453522213,
      "grad_norm": 0.19736547768115997,
      "learning_rate": 4.4480411322772664e-05,
      "loss": 0.0675,
      "step": 25200
    },
    {
      "epoch": 0.8871278796591746,
      "grad_norm": 0.13603807985782623,
      "learning_rate": 4.4458495147758854e-05,
      "loss": 0.0671,
      "step": 25300
    },
    {
      "epoch": 0.8906343139661278,
      "grad_norm": 0.16325291991233826,
      "learning_rate": 4.443679813449518e-05,
      "loss": 0.0634,
      "step": 25400
    },
    {
      "epoch": 0.8941407482730811,
      "grad_norm": 0.32795384526252747,
      "learning_rate": 4.441488195948138e-05,
      "loss": 0.0674,
      "step": 25500
    },
    {
      "epoch": 0.8976471825800344,
      "grad_norm": 0.19683495163917542,
      "learning_rate": 4.4392965784467574e-05,
      "loss": 0.0622,
      "step": 25600
    },
    {
      "epoch": 0.9011536168869876,
      "grad_norm": 0.23392006754875183,
      "learning_rate": 4.4371049609453765e-05,
      "loss": 0.0633,
      "step": 25700
    },
    {
      "epoch": 0.9046600511939409,
      "grad_norm": 0.23374083638191223,
      "learning_rate": 4.4349133434439955e-05,
      "loss": 0.0651,
      "step": 25800
    },
    {
      "epoch": 0.9081664855008942,
      "grad_norm": 0.21483729779720306,
      "learning_rate": 4.432721725942615e-05,
      "loss": 0.0616,
      "step": 25900
    },
    {
      "epoch": 0.9116729198078474,
      "grad_norm": 0.16817814111709595,
      "learning_rate": 4.430530108441234e-05,
      "loss": 0.0603,
      "step": 26000
    },
    {
      "epoch": 0.9151793541148007,
      "grad_norm": 0.4520232677459717,
      "learning_rate": 4.428338490939853e-05,
      "loss": 0.0635,
      "step": 26100
    },
    {
      "epoch": 0.918685788421754,
      "grad_norm": 0.14191648364067078,
      "learning_rate": 4.426146873438472e-05,
      "loss": 0.071,
      "step": 26200
    },
    {
      "epoch": 0.9221922227287072,
      "grad_norm": 0.15969280898571014,
      "learning_rate": 4.423955255937092e-05,
      "loss": 0.0658,
      "step": 26300
    },
    {
      "epoch": 0.9256986570356605,
      "grad_norm": 0.18534454703330994,
      "learning_rate": 4.421763638435711e-05,
      "loss": 0.0651,
      "step": 26400
    },
    {
      "epoch": 0.9292050913426136,
      "grad_norm": 0.16735605895519257,
      "learning_rate": 4.419572020934331e-05,
      "loss": 0.0677,
      "step": 26500
    },
    {
      "epoch": 0.9327115256495669,
      "grad_norm": 0.208583265542984,
      "learning_rate": 4.417402319607964e-05,
      "loss": 0.0638,
      "step": 26600
    },
    {
      "epoch": 0.9362179599565202,
      "grad_norm": 0.2711486220359802,
      "learning_rate": 4.415210702106583e-05,
      "loss": 0.0633,
      "step": 26700
    },
    {
      "epoch": 0.9397243942634734,
      "grad_norm": 0.131442129611969,
      "learning_rate": 4.413019084605202e-05,
      "loss": 0.0601,
      "step": 26800
    },
    {
      "epoch": 0.9432308285704267,
      "grad_norm": 0.17408140003681183,
      "learning_rate": 4.410827467103821e-05,
      "loss": 0.063,
      "step": 26900
    },
    {
      "epoch": 0.94673726287738,
      "grad_norm": 0.2925264239311218,
      "learning_rate": 4.408635849602441e-05,
      "loss": 0.0639,
      "step": 27000
    },
    {
      "epoch": 0.9502436971843332,
      "grad_norm": 0.28752410411834717,
      "learning_rate": 4.40644423210106e-05,
      "loss": 0.0628,
      "step": 27100
    },
    {
      "epoch": 0.9537501314912865,
      "grad_norm": 0.238529771566391,
      "learning_rate": 4.4042526145996796e-05,
      "loss": 0.0644,
      "step": 27200
    },
    {
      "epoch": 0.9572565657982398,
      "grad_norm": 0.22178998589515686,
      "learning_rate": 4.4020609970982986e-05,
      "loss": 0.0729,
      "step": 27300
    },
    {
      "epoch": 0.960763000105193,
      "grad_norm": 0.2252015620470047,
      "learning_rate": 4.3998693795969183e-05,
      "loss": 0.0642,
      "step": 27400
    },
    {
      "epoch": 0.9642694344121463,
      "grad_norm": 0.31941214203834534,
      "learning_rate": 4.3976777620955374e-05,
      "loss": 0.061,
      "step": 27500
    },
    {
      "epoch": 0.9677758687190996,
      "grad_norm": 0.3042803108692169,
      "learning_rate": 4.3954861445941564e-05,
      "loss": 0.0636,
      "step": 27600
    },
    {
      "epoch": 0.9712823030260528,
      "grad_norm": 0.3988215923309326,
      "learning_rate": 4.3932945270927754e-05,
      "loss": 0.065,
      "step": 27700
    },
    {
      "epoch": 0.9747887373330061,
      "grad_norm": 0.2614511549472809,
      "learning_rate": 4.391102909591395e-05,
      "loss": 0.0685,
      "step": 27800
    },
    {
      "epoch": 0.9782951716399593,
      "grad_norm": 0.2221420705318451,
      "learning_rate": 4.388911292090014e-05,
      "loss": 0.0635,
      "step": 27900
    },
    {
      "epoch": 0.9818016059469126,
      "grad_norm": 0.21364812552928925,
      "learning_rate": 4.386719674588633e-05,
      "loss": 0.0633,
      "step": 28000
    },
    {
      "epoch": 0.9853080402538659,
      "grad_norm": 0.18483005464076996,
      "learning_rate": 4.384528057087253e-05,
      "loss": 0.0699,
      "step": 28100
    },
    {
      "epoch": 0.9888144745608191,
      "grad_norm": 0.24990631639957428,
      "learning_rate": 4.3823364395858726e-05,
      "loss": 0.0647,
      "step": 28200
    },
    {
      "epoch": 0.9923209088677724,
      "grad_norm": 0.28819748759269714,
      "learning_rate": 4.380144822084492e-05,
      "loss": 0.0617,
      "step": 28300
    },
    {
      "epoch": 0.9958273431747257,
      "grad_norm": 0.1482626050710678,
      "learning_rate": 4.377953204583111e-05,
      "loss": 0.0612,
      "step": 28400
    },
    {
      "epoch": 0.9993337774816788,
      "grad_norm": 0.15251107513904572,
      "learning_rate": 4.37576158708173e-05,
      "loss": 0.062,
      "step": 28500
    },
    {
      "epoch": 1.0,
      "eval_accuracy_macro_0.5": 0.9743260741233826,
      "eval_accuracy_micro_0.5": 0.9743260741233826,
      "eval_accuracy_weighted_0.5": 0.9613149166107178,
      "eval_f1_macro_0.5": 0.5530027747154236,
      "eval_f1_macro_0.6": 0.48797500133514404,
      "eval_f1_macro_0.7": 0.4114832878112793,
      "eval_f1_macro_0.8": 0.17972327768802643,
      "eval_f1_micro_0.5": 0.6235038042068481,
      "eval_f1_micro_0.6": 0.5746000409126282,
      "eval_f1_micro_0.7": 0.5069726705551147,
      "eval_f1_micro_0.8": 0.40605074167251587,
      "eval_f1_micro_0.9": 0.23721876740455627,
      "eval_f1_weighted_0.5": 0.5957112908363342,
      "eval_f1_weighted_0.6": 0.5328919291496277,
      "eval_f1_weighted_0.7": 0.45647555589675903,
      "eval_f1_weighted_0.8": 0.21118679642677307,
      "eval_loss": 0.06026064604520798,
      "eval_runtime": 116.1923,
      "eval_samples_per_second": 490.627,
      "eval_steps_per_second": 61.329,
      "step": 28519
    },
    {
      "epoch": 1.0028402117886321,
      "grad_norm": 0.21833661198616028,
      "learning_rate": 4.3735699695803494e-05,
      "loss": 0.0601,
      "step": 28600
    },
    {
      "epoch": 1.0063466460955854,
      "grad_norm": 0.1318294256925583,
      "learning_rate": 4.3713783520789685e-05,
      "loss": 0.062,
      "step": 28700
    },
    {
      "epoch": 1.0098530804025387,
      "grad_norm": 0.09046052396297455,
      "learning_rate": 4.3691867345775875e-05,
      "loss": 0.0665,
      "step": 28800
    },
    {
      "epoch": 1.0133595147094918,
      "grad_norm": 0.14230003952980042,
      "learning_rate": 4.366995117076207e-05,
      "loss": 0.0567,
      "step": 28900
    },
    {
      "epoch": 1.0168659490164451,
      "grad_norm": 0.14739304780960083,
      "learning_rate": 4.364803499574827e-05,
      "loss": 0.0636,
      "step": 29000
    },
    {
      "epoch": 1.0203723833233984,
      "grad_norm": 0.21102815866470337,
      "learning_rate": 4.362611882073446e-05,
      "loss": 0.0618,
      "step": 29100
    },
    {
      "epoch": 1.0238788176303517,
      "grad_norm": 0.19737361371517181,
      "learning_rate": 4.360420264572065e-05,
      "loss": 0.0623,
      "step": 29200
    },
    {
      "epoch": 1.027385251937305,
      "grad_norm": 0.2396460324525833,
      "learning_rate": 4.358228647070684e-05,
      "loss": 0.0612,
      "step": 29300
    },
    {
      "epoch": 1.0308916862442583,
      "grad_norm": 0.15896636247634888,
      "learning_rate": 4.356037029569304e-05,
      "loss": 0.066,
      "step": 29400
    },
    {
      "epoch": 1.0343981205512114,
      "grad_norm": 0.24060440063476562,
      "learning_rate": 4.353845412067923e-05,
      "loss": 0.0624,
      "step": 29500
    },
    {
      "epoch": 1.0379045548581647,
      "grad_norm": 0.17795296013355255,
      "learning_rate": 4.351653794566542e-05,
      "loss": 0.0593,
      "step": 29600
    },
    {
      "epoch": 1.041410989165118,
      "grad_norm": 0.17168404161930084,
      "learning_rate": 4.349462177065161e-05,
      "loss": 0.0638,
      "step": 29700
    },
    {
      "epoch": 1.0449174234720713,
      "grad_norm": 0.19512996077537537,
      "learning_rate": 4.3472705595637805e-05,
      "loss": 0.0631,
      "step": 29800
    },
    {
      "epoch": 1.0484238577790246,
      "grad_norm": 0.19581535458564758,
      "learning_rate": 4.3450789420624e-05,
      "loss": 0.0614,
      "step": 29900
    },
    {
      "epoch": 1.0519302920859777,
      "grad_norm": 0.14205436408519745,
      "learning_rate": 4.342887324561019e-05,
      "loss": 0.0578,
      "step": 30000
    },
    {
      "epoch": 1.055436726392931,
      "grad_norm": 0.11033209413290024,
      "learning_rate": 4.340695707059638e-05,
      "loss": 0.0646,
      "step": 30100
    },
    {
      "epoch": 1.0589431606998843,
      "grad_norm": 0.2285543531179428,
      "learning_rate": 4.338504089558258e-05,
      "loss": 0.0623,
      "step": 30200
    },
    {
      "epoch": 1.0624495950068376,
      "grad_norm": 0.1879979372024536,
      "learning_rate": 4.336312472056877e-05,
      "loss": 0.063,
      "step": 30300
    },
    {
      "epoch": 1.0659560293137909,
      "grad_norm": 0.23111839592456818,
      "learning_rate": 4.33414277073051e-05,
      "loss": 0.0618,
      "step": 30400
    },
    {
      "epoch": 1.0694624636207442,
      "grad_norm": 0.37434840202331543,
      "learning_rate": 4.3319511532291294e-05,
      "loss": 0.0635,
      "step": 30500
    },
    {
      "epoch": 1.0729688979276972,
      "grad_norm": 0.23278197646141052,
      "learning_rate": 4.3297595357277484e-05,
      "loss": 0.0675,
      "step": 30600
    },
    {
      "epoch": 1.0764753322346505,
      "grad_norm": 0.24970144033432007,
      "learning_rate": 4.327567918226368e-05,
      "loss": 0.0631,
      "step": 30700
    },
    {
      "epoch": 1.0799817665416038,
      "grad_norm": 0.14155396819114685,
      "learning_rate": 4.325376300724987e-05,
      "loss": 0.0638,
      "step": 30800
    },
    {
      "epoch": 1.0834882008485571,
      "grad_norm": 0.3862878978252411,
      "learning_rate": 4.323184683223607e-05,
      "loss": 0.0624,
      "step": 30900
    },
    {
      "epoch": 1.0869946351555104,
      "grad_norm": 0.17950209975242615,
      "learning_rate": 4.320993065722226e-05,
      "loss": 0.063,
      "step": 31000
    },
    {
      "epoch": 1.0905010694624637,
      "grad_norm": 0.13403978943824768,
      "learning_rate": 4.318801448220845e-05,
      "loss": 0.0616,
      "step": 31100
    },
    {
      "epoch": 1.0940075037694168,
      "grad_norm": 0.2129567265510559,
      "learning_rate": 4.3166098307194646e-05,
      "loss": 0.0579,
      "step": 31200
    },
    {
      "epoch": 1.09751393807637,
      "grad_norm": 0.19136099517345428,
      "learning_rate": 4.314418213218084e-05,
      "loss": 0.0679,
      "step": 31300
    },
    {
      "epoch": 1.1010203723833234,
      "grad_norm": 0.0897800400853157,
      "learning_rate": 4.312226595716703e-05,
      "loss": 0.0602,
      "step": 31400
    },
    {
      "epoch": 1.1045268066902767,
      "grad_norm": 0.19221964478492737,
      "learning_rate": 4.3100349782153224e-05,
      "loss": 0.0618,
      "step": 31500
    },
    {
      "epoch": 1.10803324099723,
      "grad_norm": 0.1459290087223053,
      "learning_rate": 4.307843360713942e-05,
      "loss": 0.0625,
      "step": 31600
    },
    {
      "epoch": 1.111539675304183,
      "grad_norm": 0.14835625886917114,
      "learning_rate": 4.305651743212561e-05,
      "loss": 0.0628,
      "step": 31700
    },
    {
      "epoch": 1.1150461096111364,
      "grad_norm": 0.161957249045372,
      "learning_rate": 4.30346012571118e-05,
      "loss": 0.0608,
      "step": 31800
    },
    {
      "epoch": 1.1185525439180897,
      "grad_norm": 0.14771528542041779,
      "learning_rate": 4.301268508209799e-05,
      "loss": 0.0582,
      "step": 31900
    },
    {
      "epoch": 1.122058978225043,
      "grad_norm": 0.31265947222709656,
      "learning_rate": 4.299076890708419e-05,
      "loss": 0.0651,
      "step": 32000
    },
    {
      "epoch": 1.1255654125319963,
      "grad_norm": 0.13857337832450867,
      "learning_rate": 4.296885273207038e-05,
      "loss": 0.0601,
      "step": 32100
    },
    {
      "epoch": 1.1290718468389496,
      "grad_norm": 0.16667035222053528,
      "learning_rate": 4.294693655705657e-05,
      "loss": 0.0622,
      "step": 32200
    },
    {
      "epoch": 1.1325782811459026,
      "grad_norm": 0.15506722033023834,
      "learning_rate": 4.292502038204276e-05,
      "loss": 0.0636,
      "step": 32300
    },
    {
      "epoch": 1.136084715452856,
      "grad_norm": 0.15166662633419037,
      "learning_rate": 4.290310420702896e-05,
      "loss": 0.0611,
      "step": 32400
    },
    {
      "epoch": 1.1395911497598092,
      "grad_norm": 0.12198701500892639,
      "learning_rate": 4.2881188032015154e-05,
      "loss": 0.058,
      "step": 32500
    },
    {
      "epoch": 1.1430975840667625,
      "grad_norm": 0.16722208261489868,
      "learning_rate": 4.2859271857001345e-05,
      "loss": 0.0638,
      "step": 32600
    },
    {
      "epoch": 1.1466040183737158,
      "grad_norm": 0.12000538408756256,
      "learning_rate": 4.2837355681987535e-05,
      "loss": 0.0639,
      "step": 32700
    },
    {
      "epoch": 1.1501104526806691,
      "grad_norm": 0.19553938508033752,
      "learning_rate": 4.281543950697373e-05,
      "loss": 0.0625,
      "step": 32800
    },
    {
      "epoch": 1.1536168869876222,
      "grad_norm": 0.22394916415214539,
      "learning_rate": 4.279352333195992e-05,
      "loss": 0.0663,
      "step": 32900
    },
    {
      "epoch": 1.1571233212945755,
      "grad_norm": 0.12653927505016327,
      "learning_rate": 4.277182631869625e-05,
      "loss": 0.0646,
      "step": 33000
    },
    {
      "epoch": 1.1606297556015288,
      "grad_norm": 0.15021421015262604,
      "learning_rate": 4.2749910143682446e-05,
      "loss": 0.0602,
      "step": 33100
    },
    {
      "epoch": 1.164136189908482,
      "grad_norm": 0.09797565639019012,
      "learning_rate": 4.2727993968668636e-05,
      "loss": 0.057,
      "step": 33200
    },
    {
      "epoch": 1.1676426242154354,
      "grad_norm": 0.10518399626016617,
      "learning_rate": 4.270607779365483e-05,
      "loss": 0.064,
      "step": 33300
    },
    {
      "epoch": 1.1711490585223885,
      "grad_norm": 0.11318640410900116,
      "learning_rate": 4.268416161864102e-05,
      "loss": 0.0622,
      "step": 33400
    },
    {
      "epoch": 1.1746554928293418,
      "grad_norm": 0.1618545800447464,
      "learning_rate": 4.266224544362722e-05,
      "loss": 0.0616,
      "step": 33500
    },
    {
      "epoch": 1.178161927136295,
      "grad_norm": 0.1103086769580841,
      "learning_rate": 4.264032926861341e-05,
      "loss": 0.0614,
      "step": 33600
    },
    {
      "epoch": 1.1816683614432484,
      "grad_norm": 0.24451324343681335,
      "learning_rate": 4.26184130935996e-05,
      "loss": 0.0629,
      "step": 33700
    },
    {
      "epoch": 1.1851747957502017,
      "grad_norm": 0.12580975890159607,
      "learning_rate": 4.259649691858579e-05,
      "loss": 0.0632,
      "step": 33800
    },
    {
      "epoch": 1.188681230057155,
      "grad_norm": 0.28874799609184265,
      "learning_rate": 4.257458074357199e-05,
      "loss": 0.0595,
      "step": 33900
    },
    {
      "epoch": 1.192187664364108,
      "grad_norm": 0.18202286958694458,
      "learning_rate": 4.255266456855818e-05,
      "loss": 0.0586,
      "step": 34000
    },
    {
      "epoch": 1.1956940986710614,
      "grad_norm": 0.21472039818763733,
      "learning_rate": 4.2530748393544376e-05,
      "loss": 0.0576,
      "step": 34100
    },
    {
      "epoch": 1.1992005329780147,
      "grad_norm": 0.26759952306747437,
      "learning_rate": 4.2508832218530566e-05,
      "loss": 0.0544,
      "step": 34200
    },
    {
      "epoch": 1.202706967284968,
      "grad_norm": 0.12303703278303146,
      "learning_rate": 4.248691604351676e-05,
      "loss": 0.0611,
      "step": 34300
    },
    {
      "epoch": 1.2062134015919213,
      "grad_norm": 0.2518923580646515,
      "learning_rate": 4.2464999868502954e-05,
      "loss": 0.0586,
      "step": 34400
    },
    {
      "epoch": 1.2097198358988743,
      "grad_norm": 0.3016304671764374,
      "learning_rate": 4.2443083693489144e-05,
      "loss": 0.0587,
      "step": 34500
    },
    {
      "epoch": 1.2132262702058276,
      "grad_norm": 0.1694859266281128,
      "learning_rate": 4.2421167518475334e-05,
      "loss": 0.0624,
      "step": 34600
    },
    {
      "epoch": 1.216732704512781,
      "grad_norm": 0.09136710315942764,
      "learning_rate": 4.239925134346153e-05,
      "loss": 0.0591,
      "step": 34700
    },
    {
      "epoch": 1.2202391388197342,
      "grad_norm": 0.2095649689435959,
      "learning_rate": 4.237733516844772e-05,
      "loss": 0.0603,
      "step": 34800
    },
    {
      "epoch": 1.2237455731266875,
      "grad_norm": 0.2045668661594391,
      "learning_rate": 4.235541899343391e-05,
      "loss": 0.0627,
      "step": 34900
    },
    {
      "epoch": 1.2272520074336408,
      "grad_norm": 0.2389582395553589,
      "learning_rate": 4.233350281842011e-05,
      "loss": 0.0633,
      "step": 35000
    },
    {
      "epoch": 1.230758441740594,
      "grad_norm": 0.1925230771303177,
      "learning_rate": 4.2311586643406306e-05,
      "loss": 0.0578,
      "step": 35100
    },
    {
      "epoch": 1.2342648760475472,
      "grad_norm": 0.18424135446548462,
      "learning_rate": 4.22896704683925e-05,
      "loss": 0.0617,
      "step": 35200
    },
    {
      "epoch": 1.2377713103545005,
      "grad_norm": 0.24552568793296814,
      "learning_rate": 4.226775429337869e-05,
      "loss": 0.0631,
      "step": 35300
    },
    {
      "epoch": 1.2412777446614538,
      "grad_norm": 0.16728870570659637,
      "learning_rate": 4.224583811836488e-05,
      "loss": 0.0605,
      "step": 35400
    },
    {
      "epoch": 1.244784178968407,
      "grad_norm": 0.2523595988750458,
      "learning_rate": 4.2223921943351074e-05,
      "loss": 0.0616,
      "step": 35500
    },
    {
      "epoch": 1.2482906132753602,
      "grad_norm": 0.14858852326869965,
      "learning_rate": 4.2202005768337265e-05,
      "loss": 0.0644,
      "step": 35600
    },
    {
      "epoch": 1.2517970475823135,
      "grad_norm": 0.30378973484039307,
      "learning_rate": 4.2180089593323455e-05,
      "loss": 0.0614,
      "step": 35700
    },
    {
      "epoch": 1.2553034818892668,
      "grad_norm": 0.13146063685417175,
      "learning_rate": 4.215817341830965e-05,
      "loss": 0.0589,
      "step": 35800
    },
    {
      "epoch": 1.25880991619622,
      "grad_norm": 0.3789454400539398,
      "learning_rate": 4.213625724329584e-05,
      "loss": 0.0629,
      "step": 35900
    },
    {
      "epoch": 1.2623163505031734,
      "grad_norm": 0.23095537722110748,
      "learning_rate": 4.211434106828204e-05,
      "loss": 0.0588,
      "step": 36000
    },
    {
      "epoch": 1.2658227848101267,
      "grad_norm": 0.1190965473651886,
      "learning_rate": 4.209242489326823e-05,
      "loss": 0.0578,
      "step": 36100
    },
    {
      "epoch": 1.26932921911708,
      "grad_norm": 0.13259710371494293,
      "learning_rate": 4.207050871825442e-05,
      "loss": 0.0626,
      "step": 36200
    },
    {
      "epoch": 1.272835653424033,
      "grad_norm": 0.16901609301567078,
      "learning_rate": 4.204859254324062e-05,
      "loss": 0.0616,
      "step": 36300
    },
    {
      "epoch": 1.2763420877309863,
      "grad_norm": 0.10571550577878952,
      "learning_rate": 4.202689552997694e-05,
      "loss": 0.0631,
      "step": 36400
    },
    {
      "epoch": 1.2798485220379396,
      "grad_norm": 0.26635003089904785,
      "learning_rate": 4.2004979354963134e-05,
      "loss": 0.0599,
      "step": 36500
    },
    {
      "epoch": 1.283354956344893,
      "grad_norm": 0.22458505630493164,
      "learning_rate": 4.198306317994933e-05,
      "loss": 0.0617,
      "step": 36600
    },
    {
      "epoch": 1.286861390651846,
      "grad_norm": 0.3612225651741028,
      "learning_rate": 4.196114700493553e-05,
      "loss": 0.0657,
      "step": 36700
    },
    {
      "epoch": 1.2903678249587993,
      "grad_norm": 0.22486652433872223,
      "learning_rate": 4.193923082992172e-05,
      "loss": 0.0589,
      "step": 36800
    },
    {
      "epoch": 1.2938742592657526,
      "grad_norm": 0.22801823914051056,
      "learning_rate": 4.191731465490791e-05,
      "loss": 0.0668,
      "step": 36900
    },
    {
      "epoch": 1.297380693572706,
      "grad_norm": 0.24836449325084686,
      "learning_rate": 4.1895398479894106e-05,
      "loss": 0.0583,
      "step": 37000
    },
    {
      "epoch": 1.3008871278796592,
      "grad_norm": 0.14331118762493134,
      "learning_rate": 4.1873482304880296e-05,
      "loss": 0.0604,
      "step": 37100
    },
    {
      "epoch": 1.3043935621866125,
      "grad_norm": 0.2360483705997467,
      "learning_rate": 4.1851566129866486e-05,
      "loss": 0.061,
      "step": 37200
    },
    {
      "epoch": 1.3078999964935658,
      "grad_norm": 0.13909465074539185,
      "learning_rate": 4.1829649954852677e-05,
      "loss": 0.0631,
      "step": 37300
    },
    {
      "epoch": 1.3114064308005189,
      "grad_norm": 0.24434927105903625,
      "learning_rate": 4.1807733779838874e-05,
      "loss": 0.0601,
      "step": 37400
    },
    {
      "epoch": 1.3149128651074722,
      "grad_norm": 0.1434362232685089,
      "learning_rate": 4.1785817604825064e-05,
      "loss": 0.0588,
      "step": 37500
    },
    {
      "epoch": 1.3184192994144255,
      "grad_norm": 0.18288062512874603,
      "learning_rate": 4.176390142981126e-05,
      "loss": 0.0624,
      "step": 37600
    },
    {
      "epoch": 1.3219257337213788,
      "grad_norm": 0.23923709988594055,
      "learning_rate": 4.174198525479746e-05,
      "loss": 0.064,
      "step": 37700
    },
    {
      "epoch": 1.3254321680283319,
      "grad_norm": 0.24557071924209595,
      "learning_rate": 4.172006907978365e-05,
      "loss": 0.0644,
      "step": 37800
    },
    {
      "epoch": 1.3289386023352852,
      "grad_norm": 0.1528974324464798,
      "learning_rate": 4.169815290476984e-05,
      "loss": 0.0595,
      "step": 37900
    },
    {
      "epoch": 1.3324450366422385,
      "grad_norm": 0.20282955467700958,
      "learning_rate": 4.167623672975603e-05,
      "loss": 0.0581,
      "step": 38000
    },
    {
      "epoch": 1.3359514709491918,
      "grad_norm": 0.133872389793396,
      "learning_rate": 4.1654320554742226e-05,
      "loss": 0.0631,
      "step": 38100
    },
    {
      "epoch": 1.339457905256145,
      "grad_norm": 0.08619104325771332,
      "learning_rate": 4.1632404379728417e-05,
      "loss": 0.065,
      "step": 38200
    },
    {
      "epoch": 1.3429643395630984,
      "grad_norm": 0.1555207371711731,
      "learning_rate": 4.161048820471461e-05,
      "loss": 0.0581,
      "step": 38300
    },
    {
      "epoch": 1.3464707738700517,
      "grad_norm": 0.15383410453796387,
      "learning_rate": 4.1588572029700804e-05,
      "loss": 0.0623,
      "step": 38400
    },
    {
      "epoch": 1.3499772081770047,
      "grad_norm": 0.12740086019039154,
      "learning_rate": 4.1566655854687e-05,
      "loss": 0.0618,
      "step": 38500
    },
    {
      "epoch": 1.353483642483958,
      "grad_norm": 0.2182609885931015,
      "learning_rate": 4.154473967967319e-05,
      "loss": 0.0604,
      "step": 38600
    },
    {
      "epoch": 1.3569900767909113,
      "grad_norm": 0.11047884076833725,
      "learning_rate": 4.152282350465938e-05,
      "loss": 0.0621,
      "step": 38700
    },
    {
      "epoch": 1.3604965110978646,
      "grad_norm": 0.1768917590379715,
      "learning_rate": 4.150090732964557e-05,
      "loss": 0.0651,
      "step": 38800
    },
    {
      "epoch": 1.364002945404818,
      "grad_norm": 0.10115872323513031,
      "learning_rate": 4.147899115463177e-05,
      "loss": 0.0576,
      "step": 38900
    },
    {
      "epoch": 1.367509379711771,
      "grad_norm": 0.15653164684772491,
      "learning_rate": 4.145707497961796e-05,
      "loss": 0.0641,
      "step": 39000
    },
    {
      "epoch": 1.3710158140187243,
      "grad_norm": 0.22269465029239655,
      "learning_rate": 4.143515880460415e-05,
      "loss": 0.0591,
      "step": 39100
    },
    {
      "epoch": 1.3745222483256776,
      "grad_norm": 0.11686024069786072,
      "learning_rate": 4.141324262959034e-05,
      "loss": 0.0589,
      "step": 39200
    },
    {
      "epoch": 1.378028682632631,
      "grad_norm": 0.2371504306793213,
      "learning_rate": 4.139132645457654e-05,
      "loss": 0.0598,
      "step": 39300
    },
    {
      "epoch": 1.3815351169395842,
      "grad_norm": 0.16276295483112335,
      "learning_rate": 4.1369410279562734e-05,
      "loss": 0.0608,
      "step": 39400
    },
    {
      "epoch": 1.3850415512465375,
      "grad_norm": 0.11544299125671387,
      "learning_rate": 4.1347494104548925e-05,
      "loss": 0.0586,
      "step": 39500
    },
    {
      "epoch": 1.3885479855534908,
      "grad_norm": 0.0963013544678688,
      "learning_rate": 4.1325577929535115e-05,
      "loss": 0.0646,
      "step": 39600
    },
    {
      "epoch": 1.3920544198604439,
      "grad_norm": 0.23388616740703583,
      "learning_rate": 4.130366175452131e-05,
      "loss": 0.0603,
      "step": 39700
    },
    {
      "epoch": 1.3955608541673972,
      "grad_norm": 0.11810711771249771,
      "learning_rate": 4.128196474125764e-05,
      "loss": 0.0645,
      "step": 39800
    },
    {
      "epoch": 1.3990672884743505,
      "grad_norm": 0.13856692612171173,
      "learning_rate": 4.126004856624383e-05,
      "loss": 0.0572,
      "step": 39900
    },
    {
      "epoch": 1.4025737227813038,
      "grad_norm": 0.2665938138961792,
      "learning_rate": 4.1238132391230026e-05,
      "loss": 0.0602,
      "step": 40000
    },
    {
      "epoch": 1.4060801570882568,
      "grad_norm": 0.14013762772083282,
      "learning_rate": 4.1216216216216216e-05,
      "loss": 0.0649,
      "step": 40100
    },
    {
      "epoch": 1.4095865913952101,
      "grad_norm": 0.27709826827049255,
      "learning_rate": 4.119430004120241e-05,
      "loss": 0.0622,
      "step": 40200
    },
    {
      "epoch": 1.4130930257021634,
      "grad_norm": 0.25602981448173523,
      "learning_rate": 4.11723838661886e-05,
      "loss": 0.0601,
      "step": 40300
    },
    {
      "epoch": 1.4165994600091167,
      "grad_norm": 0.15147660672664642,
      "learning_rate": 4.11504676911748e-05,
      "loss": 0.0603,
      "step": 40400
    },
    {
      "epoch": 1.42010589431607,
      "grad_norm": 0.1400013566017151,
      "learning_rate": 4.112855151616099e-05,
      "loss": 0.0613,
      "step": 40500
    },
    {
      "epoch": 1.4236123286230233,
      "grad_norm": 0.23488809168338776,
      "learning_rate": 4.110663534114718e-05,
      "loss": 0.0588,
      "step": 40600
    },
    {
      "epoch": 1.4271187629299766,
      "grad_norm": 0.13520683348178864,
      "learning_rate": 4.108471916613337e-05,
      "loss": 0.0583,
      "step": 40700
    },
    {
      "epoch": 1.4306251972369297,
      "grad_norm": 0.10028853267431259,
      "learning_rate": 4.106280299111957e-05,
      "loss": 0.065,
      "step": 40800
    },
    {
      "epoch": 1.434131631543883,
      "grad_norm": 0.1576441079378128,
      "learning_rate": 4.104088681610576e-05,
      "loss": 0.0619,
      "step": 40900
    },
    {
      "epoch": 1.4376380658508363,
      "grad_norm": 0.14071917533874512,
      "learning_rate": 4.1018970641091956e-05,
      "loss": 0.0588,
      "step": 41000
    },
    {
      "epoch": 1.4411445001577896,
      "grad_norm": 0.11614608764648438,
      "learning_rate": 4.0997054466078146e-05,
      "loss": 0.0549,
      "step": 41100
    },
    {
      "epoch": 1.4446509344647427,
      "grad_norm": 0.19162940979003906,
      "learning_rate": 4.097513829106434e-05,
      "loss": 0.0591,
      "step": 41200
    },
    {
      "epoch": 1.448157368771696,
      "grad_norm": 0.20336924493312836,
      "learning_rate": 4.0953222116050534e-05,
      "loss": 0.0612,
      "step": 41300
    },
    {
      "epoch": 1.4516638030786493,
      "grad_norm": 0.29334187507629395,
      "learning_rate": 4.0931305941036724e-05,
      "loss": 0.0572,
      "step": 41400
    },
    {
      "epoch": 1.4551702373856026,
      "grad_norm": 0.1490361988544464,
      "learning_rate": 4.0909389766022914e-05,
      "loss": 0.0628,
      "step": 41500
    },
    {
      "epoch": 1.4586766716925559,
      "grad_norm": 0.0750475600361824,
      "learning_rate": 4.088747359100911e-05,
      "loss": 0.057,
      "step": 41600
    },
    {
      "epoch": 1.4621831059995092,
      "grad_norm": 0.253197580575943,
      "learning_rate": 4.08655574159953e-05,
      "loss": 0.0621,
      "step": 41700
    },
    {
      "epoch": 1.4656895403064625,
      "grad_norm": 0.12859730422496796,
      "learning_rate": 4.084364124098149e-05,
      "loss": 0.056,
      "step": 41800
    },
    {
      "epoch": 1.4691959746134156,
      "grad_norm": 0.17997848987579346,
      "learning_rate": 4.082172506596769e-05,
      "loss": 0.0593,
      "step": 41900
    },
    {
      "epoch": 1.4727024089203689,
      "grad_norm": 0.3175053298473358,
      "learning_rate": 4.0799808890953886e-05,
      "loss": 0.0607,
      "step": 42000
    },
    {
      "epoch": 1.4762088432273222,
      "grad_norm": 0.15865202248096466,
      "learning_rate": 4.0777892715940077e-05,
      "loss": 0.0605,
      "step": 42100
    },
    {
      "epoch": 1.4797152775342755,
      "grad_norm": 0.18458738923072815,
      "learning_rate": 4.075597654092627e-05,
      "loss": 0.0631,
      "step": 42200
    },
    {
      "epoch": 1.4832217118412285,
      "grad_norm": 0.28413835167884827,
      "learning_rate": 4.073406036591246e-05,
      "loss": 0.051,
      "step": 42300
    },
    {
      "epoch": 1.4867281461481818,
      "grad_norm": 0.2761777639389038,
      "learning_rate": 4.0712144190898654e-05,
      "loss": 0.0658,
      "step": 42400
    },
    {
      "epoch": 1.4902345804551351,
      "grad_norm": 0.09504197537899017,
      "learning_rate": 4.0690228015884845e-05,
      "loss": 0.0567,
      "step": 42500
    },
    {
      "epoch": 1.4937410147620884,
      "grad_norm": 0.08800254762172699,
      "learning_rate": 4.0668311840871035e-05,
      "loss": 0.0641,
      "step": 42600
    },
    {
      "epoch": 1.4972474490690417,
      "grad_norm": 0.15270839631557465,
      "learning_rate": 4.064661482760737e-05,
      "loss": 0.064,
      "step": 42700
    },
    {
      "epoch": 1.500753883375995,
      "grad_norm": 0.15410777926445007,
      "learning_rate": 4.0624698652593565e-05,
      "loss": 0.0568,
      "step": 42800
    },
    {
      "epoch": 1.5042603176829483,
      "grad_norm": 0.17512573301792145,
      "learning_rate": 4.0602782477579755e-05,
      "loss": 0.0608,
      "step": 42900
    },
    {
      "epoch": 1.5077667519899016,
      "grad_norm": 0.12734073400497437,
      "learning_rate": 4.0580866302565946e-05,
      "loss": 0.0579,
      "step": 43000
    },
    {
      "epoch": 1.5112731862968547,
      "grad_norm": 0.30646923184394836,
      "learning_rate": 4.055895012755214e-05,
      "loss": 0.0596,
      "step": 43100
    },
    {
      "epoch": 1.514779620603808,
      "grad_norm": 0.11821632087230682,
      "learning_rate": 4.053703395253833e-05,
      "loss": 0.0612,
      "step": 43200
    },
    {
      "epoch": 1.5182860549107613,
      "grad_norm": 0.3481670618057251,
      "learning_rate": 4.051511777752452e-05,
      "loss": 0.0632,
      "step": 43300
    },
    {
      "epoch": 1.5217924892177144,
      "grad_norm": 0.18040387332439423,
      "learning_rate": 4.0493201602510714e-05,
      "loss": 0.0598,
      "step": 43400
    },
    {
      "epoch": 1.5252989235246677,
      "grad_norm": 0.15381044149398804,
      "learning_rate": 4.047128542749691e-05,
      "loss": 0.0604,
      "step": 43500
    },
    {
      "epoch": 1.528805357831621,
      "grad_norm": 0.15940172970294952,
      "learning_rate": 4.044936925248311e-05,
      "loss": 0.0625,
      "step": 43600
    },
    {
      "epoch": 1.5323117921385743,
      "grad_norm": 0.10434569418430328,
      "learning_rate": 4.04274530774693e-05,
      "loss": 0.0563,
      "step": 43700
    },
    {
      "epoch": 1.5358182264455276,
      "grad_norm": 0.10980479419231415,
      "learning_rate": 4.040553690245549e-05,
      "loss": 0.0566,
      "step": 43800
    },
    {
      "epoch": 1.5393246607524809,
      "grad_norm": 0.14740921556949615,
      "learning_rate": 4.0383620727441686e-05,
      "loss": 0.0601,
      "step": 43900
    },
    {
      "epoch": 1.5428310950594342,
      "grad_norm": 0.15219874680042267,
      "learning_rate": 4.0361704552427876e-05,
      "loss": 0.0559,
      "step": 44000
    },
    {
      "epoch": 1.5463375293663875,
      "grad_norm": 0.20781219005584717,
      "learning_rate": 4.0339788377414066e-05,
      "loss": 0.0579,
      "step": 44100
    },
    {
      "epoch": 1.5498439636733405,
      "grad_norm": 0.14918802678585052,
      "learning_rate": 4.031787220240026e-05,
      "loss": 0.0616,
      "step": 44200
    },
    {
      "epoch": 1.5533503979802938,
      "grad_norm": 0.19059474766254425,
      "learning_rate": 4.0295956027386454e-05,
      "loss": 0.0626,
      "step": 44300
    },
    {
      "epoch": 1.5568568322872471,
      "grad_norm": 0.18922071158885956,
      "learning_rate": 4.0274039852372644e-05,
      "loss": 0.0636,
      "step": 44400
    },
    {
      "epoch": 1.5603632665942002,
      "grad_norm": 0.1078469529747963,
      "learning_rate": 4.025212367735884e-05,
      "loss": 0.0586,
      "step": 44500
    },
    {
      "epoch": 1.5638697009011535,
      "grad_norm": 0.16852989792823792,
      "learning_rate": 4.023020750234504e-05,
      "loss": 0.058,
      "step": 44600
    },
    {
      "epoch": 1.5673761352081068,
      "grad_norm": 0.18185126781463623,
      "learning_rate": 4.020829132733123e-05,
      "loss": 0.0626,
      "step": 44700
    },
    {
      "epoch": 1.5708825695150601,
      "grad_norm": 0.18171602487564087,
      "learning_rate": 4.018637515231742e-05,
      "loss": 0.0596,
      "step": 44800
    },
    {
      "epoch": 1.5743890038220134,
      "grad_norm": 0.15214435756206512,
      "learning_rate": 4.016467813905375e-05,
      "loss": 0.0582,
      "step": 44900
    },
    {
      "epoch": 1.5778954381289667,
      "grad_norm": 0.1266608089208603,
      "learning_rate": 4.014276196403994e-05,
      "loss": 0.0591,
      "step": 45000
    },
    {
      "epoch": 1.58140187243592,
      "grad_norm": 0.33120039105415344,
      "learning_rate": 4.012084578902613e-05,
      "loss": 0.0591,
      "step": 45100
    },
    {
      "epoch": 1.5849083067428733,
      "grad_norm": 0.13956448435783386,
      "learning_rate": 4.009892961401233e-05,
      "loss": 0.059,
      "step": 45200
    },
    {
      "epoch": 1.5884147410498264,
      "grad_norm": 0.24655941128730774,
      "learning_rate": 4.007701343899852e-05,
      "loss": 0.0593,
      "step": 45300
    },
    {
      "epoch": 1.5919211753567797,
      "grad_norm": 0.13925069570541382,
      "learning_rate": 4.005509726398472e-05,
      "loss": 0.0571,
      "step": 45400
    },
    {
      "epoch": 1.595427609663733,
      "grad_norm": 0.22795048356056213,
      "learning_rate": 4.003318108897091e-05,
      "loss": 0.0615,
      "step": 45500
    },
    {
      "epoch": 1.598934043970686,
      "grad_norm": 0.12844257056713104,
      "learning_rate": 4.00112649139571e-05,
      "loss": 0.0574,
      "step": 45600
    },
    {
      "epoch": 1.6024404782776394,
      "grad_norm": 0.14251737296581268,
      "learning_rate": 3.9989348738943295e-05,
      "loss": 0.0573,
      "step": 45700
    },
    {
      "epoch": 1.6059469125845927,
      "grad_norm": 0.3587399125099182,
      "learning_rate": 3.9967432563929485e-05,
      "loss": 0.0636,
      "step": 45800
    },
    {
      "epoch": 1.609453346891546,
      "grad_norm": 0.14225949347019196,
      "learning_rate": 3.9945516388915675e-05,
      "loss": 0.0582,
      "step": 45900
    },
    {
      "epoch": 1.6129597811984993,
      "grad_norm": 0.215657576918602,
      "learning_rate": 3.9923600213901866e-05,
      "loss": 0.0619,
      "step": 46000
    },
    {
      "epoch": 1.6164662155054526,
      "grad_norm": 0.23574788868427277,
      "learning_rate": 3.990168403888806e-05,
      "loss": 0.0548,
      "step": 46100
    },
    {
      "epoch": 1.6199726498124059,
      "grad_norm": 0.15911446511745453,
      "learning_rate": 3.987976786387426e-05,
      "loss": 0.0573,
      "step": 46200
    },
    {
      "epoch": 1.6234790841193592,
      "grad_norm": 0.11585264652967453,
      "learning_rate": 3.985785168886045e-05,
      "loss": 0.0651,
      "step": 46300
    },
    {
      "epoch": 1.6269855184263124,
      "grad_norm": 0.19489535689353943,
      "learning_rate": 3.983593551384664e-05,
      "loss": 0.0569,
      "step": 46400
    },
    {
      "epoch": 1.6304919527332655,
      "grad_norm": 0.19974353909492493,
      "learning_rate": 3.981401933883284e-05,
      "loss": 0.0608,
      "step": 46500
    },
    {
      "epoch": 1.6339983870402188,
      "grad_norm": 0.1207786500453949,
      "learning_rate": 3.979210316381903e-05,
      "loss": 0.0552,
      "step": 46600
    },
    {
      "epoch": 1.637504821347172,
      "grad_norm": 0.18862546980381012,
      "learning_rate": 3.977018698880522e-05,
      "loss": 0.0625,
      "step": 46700
    },
    {
      "epoch": 1.6410112556541252,
      "grad_norm": 0.1724182516336441,
      "learning_rate": 3.974827081379141e-05,
      "loss": 0.0599,
      "step": 46800
    },
    {
      "epoch": 1.6445176899610785,
      "grad_norm": 0.1620686650276184,
      "learning_rate": 3.9726354638777606e-05,
      "loss": 0.0605,
      "step": 46900
    },
    {
      "epoch": 1.6480241242680318,
      "grad_norm": 0.27672767639160156,
      "learning_rate": 3.970465762551394e-05,
      "loss": 0.0594,
      "step": 47000
    },
    {
      "epoch": 1.651530558574985,
      "grad_norm": 0.29767319560050964,
      "learning_rate": 3.968274145050013e-05,
      "loss": 0.0573,
      "step": 47100
    },
    {
      "epoch": 1.6550369928819384,
      "grad_norm": 0.1280701458454132,
      "learning_rate": 3.9660825275486326e-05,
      "loss": 0.0588,
      "step": 47200
    },
    {
      "epoch": 1.6585434271888917,
      "grad_norm": 0.25925809144973755,
      "learning_rate": 3.9638909100472516e-05,
      "loss": 0.0619,
      "step": 47300
    },
    {
      "epoch": 1.662049861495845,
      "grad_norm": 0.20862913131713867,
      "learning_rate": 3.9616992925458706e-05,
      "loss": 0.0588,
      "step": 47400
    },
    {
      "epoch": 1.6655562958027983,
      "grad_norm": 0.1171514093875885,
      "learning_rate": 3.95950767504449e-05,
      "loss": 0.0563,
      "step": 47500
    },
    {
      "epoch": 1.6690627301097514,
      "grad_norm": 0.28057730197906494,
      "learning_rate": 3.9573160575431094e-05,
      "loss": 0.0593,
      "step": 47600
    },
    {
      "epoch": 1.6725691644167047,
      "grad_norm": 0.150692418217659,
      "learning_rate": 3.9551244400417284e-05,
      "loss": 0.0582,
      "step": 47700
    },
    {
      "epoch": 1.676075598723658,
      "grad_norm": 0.28192150592803955,
      "learning_rate": 3.952932822540348e-05,
      "loss": 0.0543,
      "step": 47800
    },
    {
      "epoch": 1.679582033030611,
      "grad_norm": 0.2008417844772339,
      "learning_rate": 3.950741205038967e-05,
      "loss": 0.0596,
      "step": 47900
    },
    {
      "epoch": 1.6830884673375643,
      "grad_norm": 0.20742100477218628,
      "learning_rate": 3.948549587537587e-05,
      "loss": 0.0573,
      "step": 48000
    },
    {
      "epoch": 1.6865949016445176,
      "grad_norm": 0.11469540745019913,
      "learning_rate": 3.946357970036206e-05,
      "loss": 0.0575,
      "step": 48100
    },
    {
      "epoch": 1.690101335951471,
      "grad_norm": 0.14561598002910614,
      "learning_rate": 3.944166352534825e-05,
      "loss": 0.0543,
      "step": 48200
    },
    {
      "epoch": 1.6936077702584242,
      "grad_norm": 0.1250954568386078,
      "learning_rate": 3.941974735033444e-05,
      "loss": 0.0599,
      "step": 48300
    },
    {
      "epoch": 1.6971142045653775,
      "grad_norm": 0.25324225425720215,
      "learning_rate": 3.939783117532064e-05,
      "loss": 0.0551,
      "step": 48400
    },
    {
      "epoch": 1.7006206388723308,
      "grad_norm": 0.18438659608364105,
      "learning_rate": 3.937591500030683e-05,
      "loss": 0.0558,
      "step": 48500
    },
    {
      "epoch": 1.7041270731792841,
      "grad_norm": 0.09841625392436981,
      "learning_rate": 3.935399882529302e-05,
      "loss": 0.0566,
      "step": 48600
    },
    {
      "epoch": 1.7076335074862372,
      "grad_norm": 0.2306012213230133,
      "learning_rate": 3.9332082650279215e-05,
      "loss": 0.0574,
      "step": 48700
    },
    {
      "epoch": 1.7111399417931905,
      "grad_norm": 0.17739073932170868,
      "learning_rate": 3.931016647526541e-05,
      "loss": 0.0589,
      "step": 48800
    },
    {
      "epoch": 1.7146463761001438,
      "grad_norm": 0.2600133717060089,
      "learning_rate": 3.92882503002516e-05,
      "loss": 0.0577,
      "step": 48900
    },
    {
      "epoch": 1.7181528104070969,
      "grad_norm": 0.22013480961322784,
      "learning_rate": 3.926633412523779e-05,
      "loss": 0.0581,
      "step": 49000
    },
    {
      "epoch": 1.7216592447140502,
      "grad_norm": 0.15694868564605713,
      "learning_rate": 3.924441795022398e-05,
      "loss": 0.0595,
      "step": 49100
    },
    {
      "epoch": 1.7251656790210035,
      "grad_norm": 0.3486727178096771,
      "learning_rate": 3.922250177521018e-05,
      "loss": 0.0661,
      "step": 49200
    },
    {
      "epoch": 1.7286721133279568,
      "grad_norm": 0.1419142782688141,
      "learning_rate": 3.920058560019637e-05,
      "loss": 0.0584,
      "step": 49300
    },
    {
      "epoch": 1.73217854763491,
      "grad_norm": 0.12535379827022552,
      "learning_rate": 3.917866942518256e-05,
      "loss": 0.0626,
      "step": 49400
    },
    {
      "epoch": 1.7356849819418634,
      "grad_norm": 0.2291068434715271,
      "learning_rate": 3.915675325016875e-05,
      "loss": 0.0603,
      "step": 49500
    },
    {
      "epoch": 1.7391914162488167,
      "grad_norm": 0.3407721519470215,
      "learning_rate": 3.913505623690509e-05,
      "loss": 0.0641,
      "step": 49600
    },
    {
      "epoch": 1.74269785055577,
      "grad_norm": 0.16925089061260223,
      "learning_rate": 3.911314006189128e-05,
      "loss": 0.0595,
      "step": 49700
    },
    {
      "epoch": 1.746204284862723,
      "grad_norm": 0.14871777594089508,
      "learning_rate": 3.909122388687747e-05,
      "loss": 0.058,
      "step": 49800
    },
    {
      "epoch": 1.7497107191696764,
      "grad_norm": 0.37115001678466797,
      "learning_rate": 3.906930771186367e-05,
      "loss": 0.0537,
      "step": 49900
    },
    {
      "epoch": 1.7532171534766297,
      "grad_norm": 0.08386240899562836,
      "learning_rate": 3.904739153684986e-05,
      "loss": 0.0555,
      "step": 50000
    },
    {
      "epoch": 1.7567235877835827,
      "grad_norm": 0.27439984679222107,
      "learning_rate": 3.902547536183605e-05,
      "loss": 0.0575,
      "step": 50100
    },
    {
      "epoch": 1.760230022090536,
      "grad_norm": 0.23498095571994781,
      "learning_rate": 3.900355918682224e-05,
      "loss": 0.0537,
      "step": 50200
    },
    {
      "epoch": 1.7637364563974893,
      "grad_norm": 0.277005136013031,
      "learning_rate": 3.8981643011808436e-05,
      "loss": 0.0599,
      "step": 50300
    },
    {
      "epoch": 1.7672428907044426,
      "grad_norm": 0.15939852595329285,
      "learning_rate": 3.895972683679463e-05,
      "loss": 0.0556,
      "step": 50400
    },
    {
      "epoch": 1.770749325011396,
      "grad_norm": 0.14704489707946777,
      "learning_rate": 3.8937810661780823e-05,
      "loss": 0.06,
      "step": 50500
    },
    {
      "epoch": 1.7742557593183492,
      "grad_norm": 0.1926947683095932,
      "learning_rate": 3.8915894486767014e-05,
      "loss": 0.0583,
      "step": 50600
    },
    {
      "epoch": 1.7777621936253025,
      "grad_norm": 0.23146139085292816,
      "learning_rate": 3.889397831175321e-05,
      "loss": 0.0625,
      "step": 50700
    },
    {
      "epoch": 1.7812686279322558,
      "grad_norm": 0.1554272472858429,
      "learning_rate": 3.88720621367394e-05,
      "loss": 0.0535,
      "step": 50800
    },
    {
      "epoch": 1.784775062239209,
      "grad_norm": 0.07158415764570236,
      "learning_rate": 3.885014596172559e-05,
      "loss": 0.0565,
      "step": 50900
    },
    {
      "epoch": 1.7882814965461622,
      "grad_norm": 0.12316379696130753,
      "learning_rate": 3.882822978671178e-05,
      "loss": 0.055,
      "step": 51000
    },
    {
      "epoch": 1.7917879308531155,
      "grad_norm": 0.22570501267910004,
      "learning_rate": 3.880631361169798e-05,
      "loss": 0.0533,
      "step": 51100
    },
    {
      "epoch": 1.7952943651600686,
      "grad_norm": 0.39453282952308655,
      "learning_rate": 3.878439743668417e-05,
      "loss": 0.0602,
      "step": 51200
    },
    {
      "epoch": 1.7988007994670219,
      "grad_norm": 0.1693100929260254,
      "learning_rate": 3.8762481261670366e-05,
      "loss": 0.0599,
      "step": 51300
    },
    {
      "epoch": 1.8023072337739752,
      "grad_norm": 0.14574283361434937,
      "learning_rate": 3.8740565086656564e-05,
      "loss": 0.0541,
      "step": 51400
    },
    {
      "epoch": 1.8058136680809285,
      "grad_norm": 0.299518883228302,
      "learning_rate": 3.8718648911642754e-05,
      "loss": 0.0613,
      "step": 51500
    },
    {
      "epoch": 1.8093201023878818,
      "grad_norm": 0.30024516582489014,
      "learning_rate": 3.8696732736628944e-05,
      "loss": 0.0576,
      "step": 51600
    },
    {
      "epoch": 1.812826536694835,
      "grad_norm": 0.23932278156280518,
      "learning_rate": 3.8674816561615134e-05,
      "loss": 0.0634,
      "step": 51700
    },
    {
      "epoch": 1.8163329710017884,
      "grad_norm": 0.1439790427684784,
      "learning_rate": 3.865290038660133e-05,
      "loss": 0.059,
      "step": 51800
    },
    {
      "epoch": 1.8198394053087417,
      "grad_norm": 0.2418299913406372,
      "learning_rate": 3.863098421158752e-05,
      "loss": 0.0562,
      "step": 51900
    },
    {
      "epoch": 1.823345839615695,
      "grad_norm": 0.1604914367198944,
      "learning_rate": 3.860906803657371e-05,
      "loss": 0.0561,
      "step": 52000
    },
    {
      "epoch": 1.826852273922648,
      "grad_norm": 0.1718769669532776,
      "learning_rate": 3.85871518615599e-05,
      "loss": 0.0587,
      "step": 52100
    },
    {
      "epoch": 1.8303587082296013,
      "grad_norm": 0.25015121698379517,
      "learning_rate": 3.85652356865461e-05,
      "loss": 0.0548,
      "step": 52200
    },
    {
      "epoch": 1.8338651425365544,
      "grad_norm": 0.16066834330558777,
      "learning_rate": 3.854353867328243e-05,
      "loss": 0.0546,
      "step": 52300
    },
    {
      "epoch": 1.8373715768435077,
      "grad_norm": 0.1582731455564499,
      "learning_rate": 3.852162249826862e-05,
      "loss": 0.0622,
      "step": 52400
    },
    {
      "epoch": 1.840878011150461,
      "grad_norm": 0.2818114757537842,
      "learning_rate": 3.849970632325482e-05,
      "loss": 0.0579,
      "step": 52500
    },
    {
      "epoch": 1.8443844454574143,
      "grad_norm": 0.23591656982898712,
      "learning_rate": 3.847779014824101e-05,
      "loss": 0.0547,
      "step": 52600
    },
    {
      "epoch": 1.8478908797643676,
      "grad_norm": 0.1638636589050293,
      "learning_rate": 3.84558739732272e-05,
      "loss": 0.0575,
      "step": 52700
    },
    {
      "epoch": 1.851397314071321,
      "grad_norm": 0.12258061021566391,
      "learning_rate": 3.843395779821339e-05,
      "loss": 0.0591,
      "step": 52800
    },
    {
      "epoch": 1.8549037483782742,
      "grad_norm": 0.09891665726900101,
      "learning_rate": 3.841204162319959e-05,
      "loss": 0.0551,
      "step": 52900
    },
    {
      "epoch": 1.8584101826852275,
      "grad_norm": 0.20590272545814514,
      "learning_rate": 3.8390125448185785e-05,
      "loss": 0.0587,
      "step": 53000
    },
    {
      "epoch": 1.8619166169921808,
      "grad_norm": 0.1630602926015854,
      "learning_rate": 3.8368209273171975e-05,
      "loss": 0.0601,
      "step": 53100
    },
    {
      "epoch": 1.8654230512991339,
      "grad_norm": 0.22943978011608124,
      "learning_rate": 3.8346293098158166e-05,
      "loss": 0.0573,
      "step": 53200
    },
    {
      "epoch": 1.8689294856060872,
      "grad_norm": 0.175959974527359,
      "learning_rate": 3.832437692314436e-05,
      "loss": 0.0597,
      "step": 53300
    },
    {
      "epoch": 1.8724359199130405,
      "grad_norm": 0.09437303990125656,
      "learning_rate": 3.830246074813055e-05,
      "loss": 0.0556,
      "step": 53400
    },
    {
      "epoch": 1.8759423542199936,
      "grad_norm": 0.13978292047977448,
      "learning_rate": 3.8280544573116743e-05,
      "loss": 0.0554,
      "step": 53500
    },
    {
      "epoch": 1.8794487885269469,
      "grad_norm": 0.1652492880821228,
      "learning_rate": 3.8258628398102934e-05,
      "loss": 0.0615,
      "step": 53600
    },
    {
      "epoch": 1.8829552228339002,
      "grad_norm": 0.292947381734848,
      "learning_rate": 3.823671222308913e-05,
      "loss": 0.0604,
      "step": 53700
    },
    {
      "epoch": 1.8864616571408535,
      "grad_norm": 0.1251254379749298,
      "learning_rate": 3.821479604807532e-05,
      "loss": 0.0564,
      "step": 53800
    },
    {
      "epoch": 1.8899680914478068,
      "grad_norm": 0.10862012207508087,
      "learning_rate": 3.819287987306152e-05,
      "loss": 0.0593,
      "step": 53900
    },
    {
      "epoch": 1.89347452575476,
      "grad_norm": 0.15321968495845795,
      "learning_rate": 3.817096369804771e-05,
      "loss": 0.058,
      "step": 54000
    },
    {
      "epoch": 1.8969809600617134,
      "grad_norm": 0.23158785700798035,
      "learning_rate": 3.8149047523033906e-05,
      "loss": 0.0587,
      "step": 54100
    },
    {
      "epoch": 1.9004873943686666,
      "grad_norm": 0.24173428118228912,
      "learning_rate": 3.8127131348020096e-05,
      "loss": 0.0627,
      "step": 54200
    },
    {
      "epoch": 1.9039938286756197,
      "grad_norm": 0.1910579651594162,
      "learning_rate": 3.8105215173006286e-05,
      "loss": 0.0595,
      "step": 54300
    },
    {
      "epoch": 1.907500262982573,
      "grad_norm": 0.19477112591266632,
      "learning_rate": 3.808329899799248e-05,
      "loss": 0.0588,
      "step": 54400
    },
    {
      "epoch": 1.9110066972895263,
      "grad_norm": 0.20279955863952637,
      "learning_rate": 3.806160198472881e-05,
      "loss": 0.0572,
      "step": 54500
    },
    {
      "epoch": 1.9145131315964794,
      "grad_norm": 0.2571815848350525,
      "learning_rate": 3.803968580971501e-05,
      "loss": 0.0572,
      "step": 54600
    },
    {
      "epoch": 1.9180195659034327,
      "grad_norm": 0.20074647665023804,
      "learning_rate": 3.80177696347012e-05,
      "loss": 0.0564,
      "step": 54700
    },
    {
      "epoch": 1.921526000210386,
      "grad_norm": 0.17806807160377502,
      "learning_rate": 3.7995853459687394e-05,
      "loss": 0.059,
      "step": 54800
    },
    {
      "epoch": 1.9250324345173393,
      "grad_norm": 0.1742720752954483,
      "learning_rate": 3.7973937284673584e-05,
      "loss": 0.0569,
      "step": 54900
    },
    {
      "epoch": 1.9285388688242926,
      "grad_norm": 0.2525017261505127,
      "learning_rate": 3.7952021109659775e-05,
      "loss": 0.0562,
      "step": 55000
    },
    {
      "epoch": 1.932045303131246,
      "grad_norm": 0.15185923874378204,
      "learning_rate": 3.7930104934645965e-05,
      "loss": 0.0569,
      "step": 55100
    },
    {
      "epoch": 1.9355517374381992,
      "grad_norm": 0.29228824377059937,
      "learning_rate": 3.790818875963216e-05,
      "loss": 0.0601,
      "step": 55200
    },
    {
      "epoch": 1.9390581717451525,
      "grad_norm": 0.1682138741016388,
      "learning_rate": 3.788627258461835e-05,
      "loss": 0.0568,
      "step": 55300
    },
    {
      "epoch": 1.9425646060521056,
      "grad_norm": 0.1361328512430191,
      "learning_rate": 3.786435640960454e-05,
      "loss": 0.0566,
      "step": 55400
    },
    {
      "epoch": 1.9460710403590589,
      "grad_norm": 0.2037450224161148,
      "learning_rate": 3.784244023459074e-05,
      "loss": 0.0539,
      "step": 55500
    },
    {
      "epoch": 1.9495774746660122,
      "grad_norm": 0.10439430922269821,
      "learning_rate": 3.782052405957694e-05,
      "loss": 0.0553,
      "step": 55600
    },
    {
      "epoch": 1.9530839089729652,
      "grad_norm": 0.11860451102256775,
      "learning_rate": 3.779860788456313e-05,
      "loss": 0.0592,
      "step": 55700
    },
    {
      "epoch": 1.9565903432799185,
      "grad_norm": 0.11859898269176483,
      "learning_rate": 3.777669170954932e-05,
      "loss": 0.0544,
      "step": 55800
    },
    {
      "epoch": 1.9600967775868718,
      "grad_norm": 0.1865762621164322,
      "learning_rate": 3.775477553453551e-05,
      "loss": 0.0619,
      "step": 55900
    },
    {
      "epoch": 1.9636032118938251,
      "grad_norm": 0.3281310498714447,
      "learning_rate": 3.7732859359521705e-05,
      "loss": 0.0567,
      "step": 56000
    },
    {
      "epoch": 1.9671096462007784,
      "grad_norm": 0.374278724193573,
      "learning_rate": 3.7710943184507895e-05,
      "loss": 0.0605,
      "step": 56100
    },
    {
      "epoch": 1.9706160805077317,
      "grad_norm": 0.12728992104530334,
      "learning_rate": 3.7689027009494086e-05,
      "loss": 0.0603,
      "step": 56200
    },
    {
      "epoch": 1.974122514814685,
      "grad_norm": 0.16414393484592438,
      "learning_rate": 3.7667110834480276e-05,
      "loss": 0.0596,
      "step": 56300
    },
    {
      "epoch": 1.9776289491216383,
      "grad_norm": 0.1885214000940323,
      "learning_rate": 3.764519465946647e-05,
      "loss": 0.0608,
      "step": 56400
    },
    {
      "epoch": 1.9811353834285914,
      "grad_norm": 0.1263125091791153,
      "learning_rate": 3.762327848445267e-05,
      "loss": 0.056,
      "step": 56500
    },
    {
      "epoch": 1.9846418177355447,
      "grad_norm": 0.13698738813400269,
      "learning_rate": 3.760136230943886e-05,
      "loss": 0.0566,
      "step": 56600
    },
    {
      "epoch": 1.988148252042498,
      "grad_norm": 0.26228246092796326,
      "learning_rate": 3.757966529617519e-05,
      "loss": 0.0574,
      "step": 56700
    },
    {
      "epoch": 1.991654686349451,
      "grad_norm": 0.1906183511018753,
      "learning_rate": 3.7557749121161384e-05,
      "loss": 0.0541,
      "step": 56800
    },
    {
      "epoch": 1.9951611206564044,
      "grad_norm": 0.10501352697610855,
      "learning_rate": 3.7535832946147574e-05,
      "loss": 0.0577,
      "step": 56900
    },
    {
      "epoch": 1.9986675549633577,
      "grad_norm": 0.30639997124671936,
      "learning_rate": 3.7513916771133764e-05,
      "loss": 0.0546,
      "step": 57000
    },
    {
      "epoch": 2.0,
      "eval_accuracy_macro_0.5": 0.9765818119049072,
      "eval_accuracy_micro_0.5": 0.9765818119049072,
      "eval_accuracy_weighted_0.5": 0.9649651646614075,
      "eval_f1_macro_0.5": 0.6240497827529907,
      "eval_f1_macro_0.6": 0.5839835405349731,
      "eval_f1_macro_0.7": 0.5240113139152527,
      "eval_f1_macro_0.8": 0.29874491691589355,
      "eval_f1_micro_0.5": 0.6796208024024963,
      "eval_f1_micro_0.6": 0.6515995860099792,
      "eval_f1_micro_0.7": 0.6023688912391663,
      "eval_f1_micro_0.8": 0.5188673138618469,
      "eval_f1_micro_0.9": 0.3634219169616699,
      "eval_f1_weighted_0.5": 0.6647671461105347,
      "eval_f1_weighted_0.6": 0.6279059648513794,
      "eval_f1_weighted_0.7": 0.5688685774803162,
      "eval_f1_weighted_0.8": 0.3270472288131714,
      "eval_loss": 0.05424206331372261,
      "eval_runtime": 115.6065,
      "eval_samples_per_second": 493.112,
      "eval_steps_per_second": 61.64,
      "step": 57038
    },
    {
      "epoch": 2.002173989270311,
      "grad_norm": 0.10670590400695801,
      "learning_rate": 3.749200059611996e-05,
      "loss": 0.0535,
      "step": 57100
    },
    {
      "epoch": 2.0056804235772643,
      "grad_norm": 0.08953293412923813,
      "learning_rate": 3.747008442110616e-05,
      "loss": 0.059,
      "step": 57200
    },
    {
      "epoch": 2.0091868578842176,
      "grad_norm": 0.15143057703971863,
      "learning_rate": 3.744816824609235e-05,
      "loss": 0.0577,
      "step": 57300
    },
    {
      "epoch": 2.012693292191171,
      "grad_norm": 0.10743369907140732,
      "learning_rate": 3.742625207107854e-05,
      "loss": 0.0541,
      "step": 57400
    },
    {
      "epoch": 2.016199726498124,
      "grad_norm": 0.40554165840148926,
      "learning_rate": 3.7404335896064736e-05,
      "loss": 0.0608,
      "step": 57500
    },
    {
      "epoch": 2.0197061608050775,
      "grad_norm": 0.21517282724380493,
      "learning_rate": 3.7382419721050927e-05,
      "loss": 0.059,
      "step": 57600
    },
    {
      "epoch": 2.0232125951120308,
      "grad_norm": 0.14008939266204834,
      "learning_rate": 3.736050354603712e-05,
      "loss": 0.0501,
      "step": 57700
    },
    {
      "epoch": 2.0267190294189836,
      "grad_norm": 0.12907421588897705,
      "learning_rate": 3.733858737102331e-05,
      "loss": 0.058,
      "step": 57800
    },
    {
      "epoch": 2.030225463725937,
      "grad_norm": 0.19544801115989685,
      "learning_rate": 3.7316671196009504e-05,
      "loss": 0.0515,
      "step": 57900
    },
    {
      "epoch": 2.0337318980328902,
      "grad_norm": 0.12269315868616104,
      "learning_rate": 3.7294755020995695e-05,
      "loss": 0.0567,
      "step": 58000
    },
    {
      "epoch": 2.0372383323398435,
      "grad_norm": 0.12608031928539276,
      "learning_rate": 3.727283884598189e-05,
      "loss": 0.059,
      "step": 58100
    },
    {
      "epoch": 2.040744766646797,
      "grad_norm": 0.08683934062719345,
      "learning_rate": 3.725092267096808e-05,
      "loss": 0.0592,
      "step": 58200
    },
    {
      "epoch": 2.04425120095375,
      "grad_norm": 0.30369675159454346,
      "learning_rate": 3.722900649595428e-05,
      "loss": 0.0573,
      "step": 58300
    },
    {
      "epoch": 2.0477576352607034,
      "grad_norm": 0.1784551739692688,
      "learning_rate": 3.720709032094047e-05,
      "loss": 0.0542,
      "step": 58400
    },
    {
      "epoch": 2.0512640695676567,
      "grad_norm": 0.09905154258012772,
      "learning_rate": 3.718517414592666e-05,
      "loss": 0.0561,
      "step": 58500
    },
    {
      "epoch": 2.05477050387461,
      "grad_norm": 0.20391452312469482,
      "learning_rate": 3.716325797091286e-05,
      "loss": 0.0565,
      "step": 58600
    },
    {
      "epoch": 2.0582769381815633,
      "grad_norm": 0.2399507761001587,
      "learning_rate": 3.714134179589905e-05,
      "loss": 0.0569,
      "step": 58700
    },
    {
      "epoch": 2.0617833724885166,
      "grad_norm": 0.10399778187274933,
      "learning_rate": 3.711942562088524e-05,
      "loss": 0.0555,
      "step": 58800
    },
    {
      "epoch": 2.0652898067954695,
      "grad_norm": 0.24515855312347412,
      "learning_rate": 3.709772860762157e-05,
      "loss": 0.059,
      "step": 58900
    },
    {
      "epoch": 2.0687962411024228,
      "grad_norm": 0.09836437553167343,
      "learning_rate": 3.707581243260777e-05,
      "loss": 0.0596,
      "step": 59000
    },
    {
      "epoch": 2.072302675409376,
      "grad_norm": 0.11219212412834167,
      "learning_rate": 3.705389625759396e-05,
      "loss": 0.0558,
      "step": 59100
    },
    {
      "epoch": 2.0758091097163294,
      "grad_norm": 0.24574784934520721,
      "learning_rate": 3.703198008258015e-05,
      "loss": 0.0568,
      "step": 59200
    },
    {
      "epoch": 2.0793155440232827,
      "grad_norm": 0.17100077867507935,
      "learning_rate": 3.7010063907566345e-05,
      "loss": 0.0565,
      "step": 59300
    },
    {
      "epoch": 2.082821978330236,
      "grad_norm": 0.21035277843475342,
      "learning_rate": 3.6988147732552536e-05,
      "loss": 0.0591,
      "step": 59400
    },
    {
      "epoch": 2.0863284126371893,
      "grad_norm": 0.2487516552209854,
      "learning_rate": 3.6966231557538726e-05,
      "loss": 0.0576,
      "step": 59500
    },
    {
      "epoch": 2.0898348469441426,
      "grad_norm": 0.27073419094085693,
      "learning_rate": 3.6944315382524916e-05,
      "loss": 0.054,
      "step": 59600
    },
    {
      "epoch": 2.093341281251096,
      "grad_norm": 0.1274406760931015,
      "learning_rate": 3.692239920751111e-05,
      "loss": 0.0567,
      "step": 59700
    },
    {
      "epoch": 2.096847715558049,
      "grad_norm": 0.17072337865829468,
      "learning_rate": 3.690048303249731e-05,
      "loss": 0.0553,
      "step": 59800
    },
    {
      "epoch": 2.1003541498650025,
      "grad_norm": 0.09360630065202713,
      "learning_rate": 3.68785668574835e-05,
      "loss": 0.0577,
      "step": 59900
    },
    {
      "epoch": 2.1038605841719553,
      "grad_norm": 0.10030274838209152,
      "learning_rate": 3.685665068246969e-05,
      "loss": 0.0566,
      "step": 60000
    },
    {
      "epoch": 2.1073670184789086,
      "grad_norm": 0.12699030339717865,
      "learning_rate": 3.683473450745589e-05,
      "loss": 0.0569,
      "step": 60100
    },
    {
      "epoch": 2.110873452785862,
      "grad_norm": 0.19407866895198822,
      "learning_rate": 3.681281833244208e-05,
      "loss": 0.0527,
      "step": 60200
    },
    {
      "epoch": 2.114379887092815,
      "grad_norm": 0.15855835378170013,
      "learning_rate": 3.679090215742827e-05,
      "loss": 0.0587,
      "step": 60300
    },
    {
      "epoch": 2.1178863213997685,
      "grad_norm": 0.13322968780994415,
      "learning_rate": 3.676898598241446e-05,
      "loss": 0.054,
      "step": 60400
    },
    {
      "epoch": 2.121392755706722,
      "grad_norm": 0.1135793998837471,
      "learning_rate": 3.6747069807400656e-05,
      "loss": 0.0571,
      "step": 60500
    },
    {
      "epoch": 2.124899190013675,
      "grad_norm": 0.21070921421051025,
      "learning_rate": 3.6725153632386847e-05,
      "loss": 0.0601,
      "step": 60600
    },
    {
      "epoch": 2.1284056243206284,
      "grad_norm": 0.2443089336156845,
      "learning_rate": 3.6703237457373044e-05,
      "loss": 0.0622,
      "step": 60700
    },
    {
      "epoch": 2.1319120586275817,
      "grad_norm": 0.11069058626890182,
      "learning_rate": 3.6681321282359234e-05,
      "loss": 0.0586,
      "step": 60800
    },
    {
      "epoch": 2.135418492934535,
      "grad_norm": 0.14926254749298096,
      "learning_rate": 3.665940510734543e-05,
      "loss": 0.0536,
      "step": 60900
    },
    {
      "epoch": 2.1389249272414883,
      "grad_norm": 0.2176150381565094,
      "learning_rate": 3.663748893233162e-05,
      "loss": 0.0561,
      "step": 61000
    },
    {
      "epoch": 2.142431361548441,
      "grad_norm": 0.1477682739496231,
      "learning_rate": 3.661557275731781e-05,
      "loss": 0.0533,
      "step": 61100
    },
    {
      "epoch": 2.1459377958553945,
      "grad_norm": 0.12902238965034485,
      "learning_rate": 3.6593656582304e-05,
      "loss": 0.0546,
      "step": 61200
    },
    {
      "epoch": 2.1494442301623478,
      "grad_norm": 0.12047829478979111,
      "learning_rate": 3.6571959569040335e-05,
      "loss": 0.0575,
      "step": 61300
    },
    {
      "epoch": 2.152950664469301,
      "grad_norm": 0.10252504050731659,
      "learning_rate": 3.6550043394026525e-05,
      "loss": 0.0561,
      "step": 61400
    },
    {
      "epoch": 2.1564570987762544,
      "grad_norm": 0.15208585560321808,
      "learning_rate": 3.652812721901272e-05,
      "loss": 0.0549,
      "step": 61500
    },
    {
      "epoch": 2.1599635330832077,
      "grad_norm": 0.12276618927717209,
      "learning_rate": 3.650621104399892e-05,
      "loss": 0.057,
      "step": 61600
    },
    {
      "epoch": 2.163469967390161,
      "grad_norm": 0.20656609535217285,
      "learning_rate": 3.648429486898511e-05,
      "loss": 0.0519,
      "step": 61700
    },
    {
      "epoch": 2.1669764016971143,
      "grad_norm": 0.21572966873645782,
      "learning_rate": 3.64623786939713e-05,
      "loss": 0.0606,
      "step": 61800
    },
    {
      "epoch": 2.1704828360040676,
      "grad_norm": 0.08136578649282455,
      "learning_rate": 3.644046251895749e-05,
      "loss": 0.0588,
      "step": 61900
    },
    {
      "epoch": 2.173989270311021,
      "grad_norm": 0.19192098081111908,
      "learning_rate": 3.641854634394369e-05,
      "loss": 0.0581,
      "step": 62000
    },
    {
      "epoch": 2.177495704617974,
      "grad_norm": 0.09243730455636978,
      "learning_rate": 3.639663016892988e-05,
      "loss": 0.0578,
      "step": 62100
    },
    {
      "epoch": 2.1810021389249274,
      "grad_norm": 0.16258002817630768,
      "learning_rate": 3.637471399391607e-05,
      "loss": 0.053,
      "step": 62200
    },
    {
      "epoch": 2.1845085732318803,
      "grad_norm": 0.16703176498413086,
      "learning_rate": 3.6352797818902265e-05,
      "loss": 0.0595,
      "step": 62300
    },
    {
      "epoch": 2.1880150075388336,
      "grad_norm": 0.1376819759607315,
      "learning_rate": 3.633088164388846e-05,
      "loss": 0.0608,
      "step": 62400
    },
    {
      "epoch": 2.191521441845787,
      "grad_norm": 0.17793914675712585,
      "learning_rate": 3.630896546887465e-05,
      "loss": 0.0559,
      "step": 62500
    },
    {
      "epoch": 2.19502787615274,
      "grad_norm": 0.34748905897140503,
      "learning_rate": 3.628704929386084e-05,
      "loss": 0.0559,
      "step": 62600
    },
    {
      "epoch": 2.1985343104596935,
      "grad_norm": 0.31740739941596985,
      "learning_rate": 3.626513311884703e-05,
      "loss": 0.051,
      "step": 62700
    },
    {
      "epoch": 2.202040744766647,
      "grad_norm": 0.06781996041536331,
      "learning_rate": 3.624321694383323e-05,
      "loss": 0.0583,
      "step": 62800
    },
    {
      "epoch": 2.2055471790736,
      "grad_norm": 0.14833585917949677,
      "learning_rate": 3.622130076881942e-05,
      "loss": 0.0574,
      "step": 62900
    },
    {
      "epoch": 2.2090536133805534,
      "grad_norm": 0.18361018598079681,
      "learning_rate": 3.619938459380561e-05,
      "loss": 0.0556,
      "step": 63000
    },
    {
      "epoch": 2.2125600476875067,
      "grad_norm": 0.1839134246110916,
      "learning_rate": 3.61774684187918e-05,
      "loss": 0.0556,
      "step": 63100
    },
    {
      "epoch": 2.21606648199446,
      "grad_norm": 0.15445861220359802,
      "learning_rate": 3.6155552243778e-05,
      "loss": 0.0626,
      "step": 63200
    },
    {
      "epoch": 2.2195729163014133,
      "grad_norm": 0.16681711375713348,
      "learning_rate": 3.6133636068764196e-05,
      "loss": 0.0508,
      "step": 63300
    },
    {
      "epoch": 2.223079350608366,
      "grad_norm": 0.17920957505702972,
      "learning_rate": 3.6111719893750386e-05,
      "loss": 0.0508,
      "step": 63400
    },
    {
      "epoch": 2.2265857849153194,
      "grad_norm": 0.3019271790981293,
      "learning_rate": 3.6089803718736576e-05,
      "loss": 0.0593,
      "step": 63500
    },
    {
      "epoch": 2.2300922192222727,
      "grad_norm": 0.13507653772830963,
      "learning_rate": 3.606788754372277e-05,
      "loss": 0.0562,
      "step": 63600
    },
    {
      "epoch": 2.233598653529226,
      "grad_norm": 0.15464027225971222,
      "learning_rate": 3.60461905304591e-05,
      "loss": 0.056,
      "step": 63700
    },
    {
      "epoch": 2.2371050878361793,
      "grad_norm": 0.23890340328216553,
      "learning_rate": 3.602427435544529e-05,
      "loss": 0.0565,
      "step": 63800
    },
    {
      "epoch": 2.2406115221431326,
      "grad_norm": 0.1476072520017624,
      "learning_rate": 3.600235818043149e-05,
      "loss": 0.0604,
      "step": 63900
    },
    {
      "epoch": 2.244117956450086,
      "grad_norm": 0.22938992083072662,
      "learning_rate": 3.5980442005417684e-05,
      "loss": 0.0557,
      "step": 64000
    },
    {
      "epoch": 2.2476243907570392,
      "grad_norm": 0.18720847368240356,
      "learning_rate": 3.5958525830403874e-05,
      "loss": 0.0575,
      "step": 64100
    },
    {
      "epoch": 2.2511308250639925,
      "grad_norm": 0.233595073223114,
      "learning_rate": 3.5936609655390065e-05,
      "loss": 0.058,
      "step": 64200
    },
    {
      "epoch": 2.254637259370946,
      "grad_norm": 0.2907891273498535,
      "learning_rate": 3.591469348037626e-05,
      "loss": 0.0565,
      "step": 64300
    },
    {
      "epoch": 2.258143693677899,
      "grad_norm": 0.21433857083320618,
      "learning_rate": 3.589277730536245e-05,
      "loss": 0.0585,
      "step": 64400
    },
    {
      "epoch": 2.2616501279848524,
      "grad_norm": 0.12674053013324738,
      "learning_rate": 3.587086113034864e-05,
      "loss": 0.0575,
      "step": 64500
    },
    {
      "epoch": 2.2651565622918053,
      "grad_norm": 0.2228691726922989,
      "learning_rate": 3.584894495533483e-05,
      "loss": 0.0602,
      "step": 64600
    },
    {
      "epoch": 2.2686629965987586,
      "grad_norm": 0.11647112667560577,
      "learning_rate": 3.582702878032103e-05,
      "loss": 0.0571,
      "step": 64700
    },
    {
      "epoch": 2.272169430905712,
      "grad_norm": 0.16200827062129974,
      "learning_rate": 3.580511260530722e-05,
      "loss": 0.0588,
      "step": 64800
    },
    {
      "epoch": 2.275675865212665,
      "grad_norm": 0.2517165541648865,
      "learning_rate": 3.578319643029342e-05,
      "loss": 0.0575,
      "step": 64900
    },
    {
      "epoch": 2.2791822995196185,
      "grad_norm": 0.15447574853897095,
      "learning_rate": 3.576128025527961e-05,
      "loss": 0.0568,
      "step": 65000
    },
    {
      "epoch": 2.282688733826572,
      "grad_norm": 0.20134715735912323,
      "learning_rate": 3.5739364080265805e-05,
      "loss": 0.053,
      "step": 65100
    },
    {
      "epoch": 2.286195168133525,
      "grad_norm": 0.179879292845726,
      "learning_rate": 3.5717447905251995e-05,
      "loss": 0.058,
      "step": 65200
    },
    {
      "epoch": 2.2897016024404784,
      "grad_norm": 0.12556903064250946,
      "learning_rate": 3.5695531730238185e-05,
      "loss": 0.0566,
      "step": 65300
    },
    {
      "epoch": 2.2932080367474317,
      "grad_norm": 0.14403997361660004,
      "learning_rate": 3.567361555522438e-05,
      "loss": 0.0527,
      "step": 65400
    },
    {
      "epoch": 2.296714471054385,
      "grad_norm": 0.10222975164651871,
      "learning_rate": 3.565169938021057e-05,
      "loss": 0.0548,
      "step": 65500
    },
    {
      "epoch": 2.3002209053613383,
      "grad_norm": 0.15957696735858917,
      "learning_rate": 3.562978320519676e-05,
      "loss": 0.0629,
      "step": 65600
    },
    {
      "epoch": 2.303727339668291,
      "grad_norm": 0.10508875548839569,
      "learning_rate": 3.560786703018295e-05,
      "loss": 0.0533,
      "step": 65700
    },
    {
      "epoch": 2.3072337739752444,
      "grad_norm": 0.16217225790023804,
      "learning_rate": 3.558595085516915e-05,
      "loss": 0.0544,
      "step": 65800
    },
    {
      "epoch": 2.3107402082821977,
      "grad_norm": 0.16544987261295319,
      "learning_rate": 3.556425384190548e-05,
      "loss": 0.059,
      "step": 65900
    },
    {
      "epoch": 2.314246642589151,
      "grad_norm": 0.17210939526557922,
      "learning_rate": 3.5542337666891674e-05,
      "loss": 0.0603,
      "step": 66000
    },
    {
      "epoch": 2.3177530768961043,
      "grad_norm": 0.31242191791534424,
      "learning_rate": 3.552042149187787e-05,
      "loss": 0.0552,
      "step": 66100
    },
    {
      "epoch": 2.3212595112030576,
      "grad_norm": 0.2203870564699173,
      "learning_rate": 3.549850531686406e-05,
      "loss": 0.055,
      "step": 66200
    },
    {
      "epoch": 2.324765945510011,
      "grad_norm": 0.29349902272224426,
      "learning_rate": 3.547658914185025e-05,
      "loss": 0.0574,
      "step": 66300
    },
    {
      "epoch": 2.328272379816964,
      "grad_norm": 0.1796482652425766,
      "learning_rate": 3.545467296683644e-05,
      "loss": 0.0537,
      "step": 66400
    },
    {
      "epoch": 2.3317788141239175,
      "grad_norm": 0.178925558924675,
      "learning_rate": 3.543275679182264e-05,
      "loss": 0.0551,
      "step": 66500
    },
    {
      "epoch": 2.335285248430871,
      "grad_norm": 0.22349989414215088,
      "learning_rate": 3.5410840616808836e-05,
      "loss": 0.0566,
      "step": 66600
    },
    {
      "epoch": 2.338791682737824,
      "grad_norm": 0.18712127208709717,
      "learning_rate": 3.5388924441795026e-05,
      "loss": 0.0598,
      "step": 66700
    },
    {
      "epoch": 2.342298117044777,
      "grad_norm": 0.11851828545331955,
      "learning_rate": 3.5367008266781216e-05,
      "loss": 0.0585,
      "step": 66800
    },
    {
      "epoch": 2.3458045513517303,
      "grad_norm": 0.1039782464504242,
      "learning_rate": 3.5345092091767414e-05,
      "loss": 0.0539,
      "step": 66900
    },
    {
      "epoch": 2.3493109856586836,
      "grad_norm": 0.11854534596204758,
      "learning_rate": 3.5323175916753604e-05,
      "loss": 0.0541,
      "step": 67000
    },
    {
      "epoch": 2.352817419965637,
      "grad_norm": 0.16492809355258942,
      "learning_rate": 3.530147890348993e-05,
      "loss": 0.0576,
      "step": 67100
    },
    {
      "epoch": 2.35632385427259,
      "grad_norm": 0.1656142622232437,
      "learning_rate": 3.527956272847613e-05,
      "loss": 0.0515,
      "step": 67200
    },
    {
      "epoch": 2.3598302885795435,
      "grad_norm": 0.2587023973464966,
      "learning_rate": 3.525764655346232e-05,
      "loss": 0.0579,
      "step": 67300
    },
    {
      "epoch": 2.3633367228864968,
      "grad_norm": 0.28793537616729736,
      "learning_rate": 3.5235730378448514e-05,
      "loss": 0.0546,
      "step": 67400
    },
    {
      "epoch": 2.36684315719345,
      "grad_norm": 0.08759905397891998,
      "learning_rate": 3.5213814203434705e-05,
      "loss": 0.0584,
      "step": 67500
    },
    {
      "epoch": 2.3703495915004034,
      "grad_norm": 0.16408084332942963,
      "learning_rate": 3.51918980284209e-05,
      "loss": 0.0577,
      "step": 67600
    },
    {
      "epoch": 2.3738560258073567,
      "grad_norm": 0.19100897014141083,
      "learning_rate": 3.516998185340709e-05,
      "loss": 0.0598,
      "step": 67700
    },
    {
      "epoch": 2.37736246011431,
      "grad_norm": 0.23015600442886353,
      "learning_rate": 3.514806567839328e-05,
      "loss": 0.0531,
      "step": 67800
    },
    {
      "epoch": 2.380868894421263,
      "grad_norm": 0.17429114878177643,
      "learning_rate": 3.512614950337947e-05,
      "loss": 0.0585,
      "step": 67900
    },
    {
      "epoch": 2.384375328728216,
      "grad_norm": 0.30307328701019287,
      "learning_rate": 3.510423332836567e-05,
      "loss": 0.0556,
      "step": 68000
    },
    {
      "epoch": 2.3878817630351694,
      "grad_norm": 0.1336517333984375,
      "learning_rate": 3.508231715335186e-05,
      "loss": 0.0559,
      "step": 68100
    },
    {
      "epoch": 2.3913881973421227,
      "grad_norm": 0.3432278335094452,
      "learning_rate": 3.506040097833805e-05,
      "loss": 0.0534,
      "step": 68200
    },
    {
      "epoch": 2.394894631649076,
      "grad_norm": 0.20078866183757782,
      "learning_rate": 3.503848480332425e-05,
      "loss": 0.0575,
      "step": 68300
    },
    {
      "epoch": 2.3984010659560293,
      "grad_norm": 0.2102513164281845,
      "learning_rate": 3.5016568628310445e-05,
      "loss": 0.0583,
      "step": 68400
    },
    {
      "epoch": 2.4019075002629826,
      "grad_norm": 0.08050217479467392,
      "learning_rate": 3.4994652453296635e-05,
      "loss": 0.0589,
      "step": 68500
    },
    {
      "epoch": 2.405413934569936,
      "grad_norm": 0.18645502626895905,
      "learning_rate": 3.4972736278282825e-05,
      "loss": 0.0545,
      "step": 68600
    },
    {
      "epoch": 2.408920368876889,
      "grad_norm": 0.042135823518037796,
      "learning_rate": 3.4950820103269016e-05,
      "loss": 0.0577,
      "step": 68700
    },
    {
      "epoch": 2.4124268031838425,
      "grad_norm": 0.11688222736120224,
      "learning_rate": 3.492890392825521e-05,
      "loss": 0.0534,
      "step": 68800
    },
    {
      "epoch": 2.415933237490796,
      "grad_norm": 0.2946362793445587,
      "learning_rate": 3.49069877532414e-05,
      "loss": 0.0539,
      "step": 68900
    },
    {
      "epoch": 2.4194396717977487,
      "grad_norm": 0.19289886951446533,
      "learning_rate": 3.4885071578227593e-05,
      "loss": 0.0561,
      "step": 69000
    },
    {
      "epoch": 2.422946106104702,
      "grad_norm": 0.25358012318611145,
      "learning_rate": 3.486315540321379e-05,
      "loss": 0.056,
      "step": 69100
    },
    {
      "epoch": 2.4264525404116553,
      "grad_norm": 0.0751759335398674,
      "learning_rate": 3.484123922819999e-05,
      "loss": 0.0541,
      "step": 69200
    },
    {
      "epoch": 2.4299589747186086,
      "grad_norm": 0.3038584291934967,
      "learning_rate": 3.481932305318618e-05,
      "loss": 0.0542,
      "step": 69300
    },
    {
      "epoch": 2.433465409025562,
      "grad_norm": 0.10080554336309433,
      "learning_rate": 3.479740687817237e-05,
      "loss": 0.0525,
      "step": 69400
    },
    {
      "epoch": 2.436971843332515,
      "grad_norm": 0.16663146018981934,
      "learning_rate": 3.477549070315856e-05,
      "loss": 0.0564,
      "step": 69500
    },
    {
      "epoch": 2.4404782776394685,
      "grad_norm": 0.08932673186063766,
      "learning_rate": 3.4753574528144756e-05,
      "loss": 0.0532,
      "step": 69600
    },
    {
      "epoch": 2.4439847119464218,
      "grad_norm": 0.06350678205490112,
      "learning_rate": 3.4731658353130946e-05,
      "loss": 0.0586,
      "step": 69700
    },
    {
      "epoch": 2.447491146253375,
      "grad_norm": 0.1542813628911972,
      "learning_rate": 3.4709742178117136e-05,
      "loss": 0.0574,
      "step": 69800
    },
    {
      "epoch": 2.4509975805603283,
      "grad_norm": 0.11914385855197906,
      "learning_rate": 3.468782600310333e-05,
      "loss": 0.057,
      "step": 69900
    },
    {
      "epoch": 2.4545040148672816,
      "grad_norm": 0.2400103062391281,
      "learning_rate": 3.4665909828089524e-05,
      "loss": 0.0547,
      "step": 70000
    },
    {
      "epoch": 2.4580104491742345,
      "grad_norm": 0.08700885623693466,
      "learning_rate": 3.464399365307572e-05,
      "loss": 0.0553,
      "step": 70100
    },
    {
      "epoch": 2.461516883481188,
      "grad_norm": 0.20053057372570038,
      "learning_rate": 3.462207747806191e-05,
      "loss": 0.0582,
      "step": 70200
    },
    {
      "epoch": 2.465023317788141,
      "grad_norm": 0.1665387898683548,
      "learning_rate": 3.46001613030481e-05,
      "loss": 0.0593,
      "step": 70300
    },
    {
      "epoch": 2.4685297520950944,
      "grad_norm": 0.0827973261475563,
      "learning_rate": 3.45782451280343e-05,
      "loss": 0.0528,
      "step": 70400
    },
    {
      "epoch": 2.4720361864020477,
      "grad_norm": 0.1409558206796646,
      "learning_rate": 3.455632895302049e-05,
      "loss": 0.0518,
      "step": 70500
    },
    {
      "epoch": 2.475542620709001,
      "grad_norm": 0.1162656620144844,
      "learning_rate": 3.453441277800668e-05,
      "loss": 0.0512,
      "step": 70600
    },
    {
      "epoch": 2.4790490550159543,
      "grad_norm": 0.10374881327152252,
      "learning_rate": 3.451249660299287e-05,
      "loss": 0.0507,
      "step": 70700
    },
    {
      "epoch": 2.4825554893229076,
      "grad_norm": 0.21479962766170502,
      "learning_rate": 3.449058042797907e-05,
      "loss": 0.0556,
      "step": 70800
    },
    {
      "epoch": 2.486061923629861,
      "grad_norm": 0.12322128564119339,
      "learning_rate": 3.446866425296526e-05,
      "loss": 0.0506,
      "step": 70900
    },
    {
      "epoch": 2.489568357936814,
      "grad_norm": 0.11814969778060913,
      "learning_rate": 3.4446748077951454e-05,
      "loss": 0.053,
      "step": 71000
    },
    {
      "epoch": 2.4930747922437675,
      "grad_norm": 0.17432937026023865,
      "learning_rate": 3.4424831902937644e-05,
      "loss": 0.056,
      "step": 71100
    },
    {
      "epoch": 2.4965812265507203,
      "grad_norm": 0.2839914858341217,
      "learning_rate": 3.440291572792384e-05,
      "loss": 0.0565,
      "step": 71200
    },
    {
      "epoch": 2.500087660857674,
      "grad_norm": 0.30781418085098267,
      "learning_rate": 3.438099955291003e-05,
      "loss": 0.054,
      "step": 71300
    },
    {
      "epoch": 2.503594095164627,
      "grad_norm": 0.15302962064743042,
      "learning_rate": 3.435908337789622e-05,
      "loss": 0.0573,
      "step": 71400
    },
    {
      "epoch": 2.5071005294715802,
      "grad_norm": 0.13138249516487122,
      "learning_rate": 3.433716720288241e-05,
      "loss": 0.0555,
      "step": 71500
    },
    {
      "epoch": 2.5106069637785335,
      "grad_norm": 0.17330294847488403,
      "learning_rate": 3.431525102786861e-05,
      "loss": 0.0539,
      "step": 71600
    },
    {
      "epoch": 2.514113398085487,
      "grad_norm": 0.3222072720527649,
      "learning_rate": 3.42933348528548e-05,
      "loss": 0.0537,
      "step": 71700
    },
    {
      "epoch": 2.51761983239244,
      "grad_norm": 0.19562101364135742,
      "learning_rate": 3.4271418677841e-05,
      "loss": 0.0522,
      "step": 71800
    },
    {
      "epoch": 2.5211262666993934,
      "grad_norm": 0.049218110740184784,
      "learning_rate": 3.4249502502827194e-05,
      "loss": 0.0546,
      "step": 71900
    },
    {
      "epoch": 2.5246327010063467,
      "grad_norm": 0.0977221205830574,
      "learning_rate": 3.4227586327813385e-05,
      "loss": 0.0553,
      "step": 72000
    },
    {
      "epoch": 2.5281391353133,
      "grad_norm": 0.2771187126636505,
      "learning_rate": 3.4205670152799575e-05,
      "loss": 0.0541,
      "step": 72100
    },
    {
      "epoch": 2.5316455696202533,
      "grad_norm": 0.21925553679466248,
      "learning_rate": 3.4183753977785765e-05,
      "loss": 0.0567,
      "step": 72200
    },
    {
      "epoch": 2.535152003927206,
      "grad_norm": 0.1588377207517624,
      "learning_rate": 3.41620569645221e-05,
      "loss": 0.0533,
      "step": 72300
    },
    {
      "epoch": 2.53865843823416,
      "grad_norm": 0.16470493376255035,
      "learning_rate": 3.414014078950829e-05,
      "loss": 0.0548,
      "step": 72400
    },
    {
      "epoch": 2.542164872541113,
      "grad_norm": 0.1122516542673111,
      "learning_rate": 3.411822461449448e-05,
      "loss": 0.056,
      "step": 72500
    },
    {
      "epoch": 2.545671306848066,
      "grad_norm": 0.09744656831026077,
      "learning_rate": 3.4096308439480676e-05,
      "loss": 0.054,
      "step": 72600
    },
    {
      "epoch": 2.5491777411550194,
      "grad_norm": 0.15664923191070557,
      "learning_rate": 3.407439226446687e-05,
      "loss": 0.0601,
      "step": 72700
    },
    {
      "epoch": 2.5526841754619727,
      "grad_norm": 0.06426887214183807,
      "learning_rate": 3.405247608945306e-05,
      "loss": 0.0517,
      "step": 72800
    },
    {
      "epoch": 2.556190609768926,
      "grad_norm": 0.09797985106706619,
      "learning_rate": 3.4030559914439253e-05,
      "loss": 0.0528,
      "step": 72900
    },
    {
      "epoch": 2.5596970440758793,
      "grad_norm": 0.10686851292848587,
      "learning_rate": 3.400864373942545e-05,
      "loss": 0.0559,
      "step": 73000
    },
    {
      "epoch": 2.5632034783828326,
      "grad_norm": 0.1377471387386322,
      "learning_rate": 3.398672756441164e-05,
      "loss": 0.0505,
      "step": 73100
    },
    {
      "epoch": 2.566709912689786,
      "grad_norm": 0.11720021814107895,
      "learning_rate": 3.396481138939783e-05,
      "loss": 0.0584,
      "step": 73200
    },
    {
      "epoch": 2.570216346996739,
      "grad_norm": 0.15196500718593597,
      "learning_rate": 3.394289521438402e-05,
      "loss": 0.0517,
      "step": 73300
    },
    {
      "epoch": 2.573722781303692,
      "grad_norm": 0.14690729975700378,
      "learning_rate": 3.392097903937022e-05,
      "loss": 0.0559,
      "step": 73400
    },
    {
      "epoch": 2.5772292156106458,
      "grad_norm": 0.23833900690078735,
      "learning_rate": 3.389906286435641e-05,
      "loss": 0.0582,
      "step": 73500
    },
    {
      "epoch": 2.5807356499175986,
      "grad_norm": 0.22415363788604736,
      "learning_rate": 3.3877146689342606e-05,
      "loss": 0.0546,
      "step": 73600
    },
    {
      "epoch": 2.584242084224552,
      "grad_norm": 0.18616214394569397,
      "learning_rate": 3.3855230514328796e-05,
      "loss": 0.0574,
      "step": 73700
    },
    {
      "epoch": 2.5877485185315052,
      "grad_norm": 0.087038554251194,
      "learning_rate": 3.3833314339314993e-05,
      "loss": 0.0571,
      "step": 73800
    },
    {
      "epoch": 2.5912549528384585,
      "grad_norm": 0.1882282793521881,
      "learning_rate": 3.3811398164301184e-05,
      "loss": 0.0517,
      "step": 73900
    },
    {
      "epoch": 2.594761387145412,
      "grad_norm": 0.22380375862121582,
      "learning_rate": 3.3789481989287374e-05,
      "loss": 0.0589,
      "step": 74000
    },
    {
      "epoch": 2.598267821452365,
      "grad_norm": 0.38261187076568604,
      "learning_rate": 3.3767565814273564e-05,
      "loss": 0.0534,
      "step": 74100
    },
    {
      "epoch": 2.6017742557593184,
      "grad_norm": 0.16372431814670563,
      "learning_rate": 3.374564963925976e-05,
      "loss": 0.0507,
      "step": 74200
    },
    {
      "epoch": 2.6052806900662717,
      "grad_norm": 0.17199595272541046,
      "learning_rate": 3.372373346424595e-05,
      "loss": 0.0575,
      "step": 74300
    },
    {
      "epoch": 2.608787124373225,
      "grad_norm": 0.12955926358699799,
      "learning_rate": 3.370181728923215e-05,
      "loss": 0.0547,
      "step": 74400
    },
    {
      "epoch": 2.612293558680178,
      "grad_norm": 0.1785309761762619,
      "learning_rate": 3.367990111421834e-05,
      "loss": 0.0509,
      "step": 74500
    },
    {
      "epoch": 2.6157999929871316,
      "grad_norm": 0.21685577929019928,
      "learning_rate": 3.3657984939204536e-05,
      "loss": 0.0568,
      "step": 74600
    },
    {
      "epoch": 2.6193064272940845,
      "grad_norm": 0.15416572988033295,
      "learning_rate": 3.363606876419073e-05,
      "loss": 0.0543,
      "step": 74700
    },
    {
      "epoch": 2.6228128616010378,
      "grad_norm": 0.3155372142791748,
      "learning_rate": 3.361415258917692e-05,
      "loss": 0.0577,
      "step": 74800
    },
    {
      "epoch": 2.626319295907991,
      "grad_norm": 0.1404000222682953,
      "learning_rate": 3.359223641416311e-05,
      "loss": 0.056,
      "step": 74900
    },
    {
      "epoch": 2.6298257302149444,
      "grad_norm": 0.1450991928577423,
      "learning_rate": 3.357053940089944e-05,
      "loss": 0.0555,
      "step": 75000
    },
    {
      "epoch": 2.6333321645218977,
      "grad_norm": 0.11744678765535355,
      "learning_rate": 3.354862322588563e-05,
      "loss": 0.0523,
      "step": 75100
    },
    {
      "epoch": 2.636838598828851,
      "grad_norm": 0.23305346071720123,
      "learning_rate": 3.352670705087183e-05,
      "loss": 0.054,
      "step": 75200
    },
    {
      "epoch": 2.6403450331358043,
      "grad_norm": 0.0883123055100441,
      "learning_rate": 3.3504790875858025e-05,
      "loss": 0.0531,
      "step": 75300
    },
    {
      "epoch": 2.6438514674427576,
      "grad_norm": 0.09516693651676178,
      "learning_rate": 3.3482874700844215e-05,
      "loss": 0.0535,
      "step": 75400
    },
    {
      "epoch": 2.647357901749711,
      "grad_norm": 0.06894740462303162,
      "learning_rate": 3.3460958525830405e-05,
      "loss": 0.0499,
      "step": 75500
    },
    {
      "epoch": 2.6508643360566637,
      "grad_norm": 0.16024255752563477,
      "learning_rate": 3.3439042350816596e-05,
      "loss": 0.056,
      "step": 75600
    },
    {
      "epoch": 2.6543707703636175,
      "grad_norm": 0.18456900119781494,
      "learning_rate": 3.341712617580279e-05,
      "loss": 0.0524,
      "step": 75700
    },
    {
      "epoch": 2.6578772046705703,
      "grad_norm": 0.2605621814727783,
      "learning_rate": 3.339521000078898e-05,
      "loss": 0.0555,
      "step": 75800
    },
    {
      "epoch": 2.6613836389775236,
      "grad_norm": 0.15850543975830078,
      "learning_rate": 3.3373293825775173e-05,
      "loss": 0.0537,
      "step": 75900
    },
    {
      "epoch": 2.664890073284477,
      "grad_norm": 0.282458633184433,
      "learning_rate": 3.335137765076137e-05,
      "loss": 0.0586,
      "step": 76000
    },
    {
      "epoch": 2.66839650759143,
      "grad_norm": 0.30282145738601685,
      "learning_rate": 3.332946147574757e-05,
      "loss": 0.0583,
      "step": 76100
    },
    {
      "epoch": 2.6719029418983835,
      "grad_norm": 0.1443483680486679,
      "learning_rate": 3.330754530073376e-05,
      "loss": 0.0578,
      "step": 76200
    },
    {
      "epoch": 2.675409376205337,
      "grad_norm": 0.1372980773448944,
      "learning_rate": 3.328562912571995e-05,
      "loss": 0.0548,
      "step": 76300
    },
    {
      "epoch": 2.67891581051229,
      "grad_norm": 0.182353213429451,
      "learning_rate": 3.326371295070614e-05,
      "loss": 0.0551,
      "step": 76400
    },
    {
      "epoch": 2.6824222448192434,
      "grad_norm": 0.18866074085235596,
      "learning_rate": 3.3241796775692336e-05,
      "loss": 0.0501,
      "step": 76500
    },
    {
      "epoch": 2.6859286791261967,
      "grad_norm": 0.22861073911190033,
      "learning_rate": 3.3219880600678526e-05,
      "loss": 0.0546,
      "step": 76600
    },
    {
      "epoch": 2.6894351134331496,
      "grad_norm": 0.2977736294269562,
      "learning_rate": 3.3197964425664716e-05,
      "loss": 0.0561,
      "step": 76700
    },
    {
      "epoch": 2.6929415477401033,
      "grad_norm": 0.2136681228876114,
      "learning_rate": 3.317604825065091e-05,
      "loss": 0.0535,
      "step": 76800
    },
    {
      "epoch": 2.696447982047056,
      "grad_norm": 0.07363703101873398,
      "learning_rate": 3.3154132075637104e-05,
      "loss": 0.0514,
      "step": 76900
    },
    {
      "epoch": 2.6999544163540095,
      "grad_norm": 0.18378384411334991,
      "learning_rate": 3.31322159006233e-05,
      "loss": 0.0567,
      "step": 77000
    },
    {
      "epoch": 2.7034608506609628,
      "grad_norm": 0.10073453933000565,
      "learning_rate": 3.311029972560949e-05,
      "loss": 0.0571,
      "step": 77100
    },
    {
      "epoch": 2.706967284967916,
      "grad_norm": 0.09372426569461823,
      "learning_rate": 3.3088602712345824e-05,
      "loss": 0.0553,
      "step": 77200
    },
    {
      "epoch": 2.7104737192748694,
      "grad_norm": 0.1428600400686264,
      "learning_rate": 3.3066686537332014e-05,
      "loss": 0.0568,
      "step": 77300
    },
    {
      "epoch": 2.7139801535818227,
      "grad_norm": 0.32952165603637695,
      "learning_rate": 3.3044770362318205e-05,
      "loss": 0.0567,
      "step": 77400
    },
    {
      "epoch": 2.717486587888776,
      "grad_norm": 0.31366464495658875,
      "learning_rate": 3.3022854187304395e-05,
      "loss": 0.0565,
      "step": 77500
    },
    {
      "epoch": 2.7209930221957292,
      "grad_norm": 0.090150386095047,
      "learning_rate": 3.300093801229059e-05,
      "loss": 0.0535,
      "step": 77600
    },
    {
      "epoch": 2.7244994565026825,
      "grad_norm": 0.1751435250043869,
      "learning_rate": 3.297902183727678e-05,
      "loss": 0.0514,
      "step": 77700
    },
    {
      "epoch": 2.728005890809636,
      "grad_norm": 0.19130787253379822,
      "learning_rate": 3.295710566226298e-05,
      "loss": 0.0601,
      "step": 77800
    },
    {
      "epoch": 2.731512325116589,
      "grad_norm": 0.2867094576358795,
      "learning_rate": 3.293518948724917e-05,
      "loss": 0.0573,
      "step": 77900
    },
    {
      "epoch": 2.735018759423542,
      "grad_norm": 0.08774128556251526,
      "learning_rate": 3.291327331223537e-05,
      "loss": 0.0574,
      "step": 78000
    },
    {
      "epoch": 2.7385251937304953,
      "grad_norm": 0.10866645723581314,
      "learning_rate": 3.289135713722156e-05,
      "loss": 0.0519,
      "step": 78100
    },
    {
      "epoch": 2.7420316280374486,
      "grad_norm": 0.17216600477695465,
      "learning_rate": 3.286944096220775e-05,
      "loss": 0.054,
      "step": 78200
    },
    {
      "epoch": 2.745538062344402,
      "grad_norm": 0.29803597927093506,
      "learning_rate": 3.284752478719394e-05,
      "loss": 0.057,
      "step": 78300
    },
    {
      "epoch": 2.749044496651355,
      "grad_norm": 0.12210572510957718,
      "learning_rate": 3.2825608612180135e-05,
      "loss": 0.052,
      "step": 78400
    },
    {
      "epoch": 2.7525509309583085,
      "grad_norm": 0.18661682307720184,
      "learning_rate": 3.2803692437166325e-05,
      "loss": 0.0536,
      "step": 78500
    },
    {
      "epoch": 2.756057365265262,
      "grad_norm": 0.17083589732646942,
      "learning_rate": 3.278177626215252e-05,
      "loss": 0.0542,
      "step": 78600
    },
    {
      "epoch": 2.759563799572215,
      "grad_norm": 0.24203020334243774,
      "learning_rate": 3.275986008713871e-05,
      "loss": 0.055,
      "step": 78700
    },
    {
      "epoch": 2.7630702338791684,
      "grad_norm": 0.07261452078819275,
      "learning_rate": 3.273794391212491e-05,
      "loss": 0.0542,
      "step": 78800
    },
    {
      "epoch": 2.7665766681861217,
      "grad_norm": 0.24466608464717865,
      "learning_rate": 3.27160277371111e-05,
      "loss": 0.055,
      "step": 78900
    },
    {
      "epoch": 2.770083102493075,
      "grad_norm": 0.2459612786769867,
      "learning_rate": 3.269411156209729e-05,
      "loss": 0.055,
      "step": 79000
    },
    {
      "epoch": 2.773589536800028,
      "grad_norm": 0.05075916275382042,
      "learning_rate": 3.267219538708349e-05,
      "loss": 0.055,
      "step": 79100
    },
    {
      "epoch": 2.7770959711069816,
      "grad_norm": 0.22451598942279816,
      "learning_rate": 3.265027921206968e-05,
      "loss": 0.0559,
      "step": 79200
    },
    {
      "epoch": 2.7806024054139344,
      "grad_norm": 0.1366572231054306,
      "learning_rate": 3.2628582198806004e-05,
      "loss": 0.0543,
      "step": 79300
    },
    {
      "epoch": 2.7841088397208877,
      "grad_norm": 0.16573289036750793,
      "learning_rate": 3.26066660237922e-05,
      "loss": 0.0548,
      "step": 79400
    },
    {
      "epoch": 2.787615274027841,
      "grad_norm": 0.1655275672674179,
      "learning_rate": 3.25847498487784e-05,
      "loss": 0.0566,
      "step": 79500
    },
    {
      "epoch": 2.7911217083347943,
      "grad_norm": 0.23151125013828278,
      "learning_rate": 3.256283367376459e-05,
      "loss": 0.0536,
      "step": 79600
    },
    {
      "epoch": 2.7946281426417476,
      "grad_norm": 0.13660258054733276,
      "learning_rate": 3.254091749875078e-05,
      "loss": 0.0616,
      "step": 79700
    },
    {
      "epoch": 2.798134576948701,
      "grad_norm": 0.15168534219264984,
      "learning_rate": 3.2519001323736976e-05,
      "loss": 0.0541,
      "step": 79800
    },
    {
      "epoch": 2.8016410112556542,
      "grad_norm": 0.21168303489685059,
      "learning_rate": 3.2497085148723166e-05,
      "loss": 0.0595,
      "step": 79900
    },
    {
      "epoch": 2.8051474455626075,
      "grad_norm": 0.28193801641464233,
      "learning_rate": 3.2475168973709357e-05,
      "loss": 0.0599,
      "step": 80000
    },
    {
      "epoch": 2.808653879869561,
      "grad_norm": 0.11753994226455688,
      "learning_rate": 3.245325279869555e-05,
      "loss": 0.0575,
      "step": 80100
    },
    {
      "epoch": 2.8121603141765137,
      "grad_norm": 0.17170307040214539,
      "learning_rate": 3.2431336623681744e-05,
      "loss": 0.0546,
      "step": 80200
    },
    {
      "epoch": 2.8156667484834674,
      "grad_norm": 0.1279531717300415,
      "learning_rate": 3.2409420448667934e-05,
      "loss": 0.0529,
      "step": 80300
    },
    {
      "epoch": 2.8191731827904203,
      "grad_norm": 0.316933810710907,
      "learning_rate": 3.238750427365413e-05,
      "loss": 0.0571,
      "step": 80400
    },
    {
      "epoch": 2.8226796170973736,
      "grad_norm": 0.27915966510772705,
      "learning_rate": 3.236558809864032e-05,
      "loss": 0.0507,
      "step": 80500
    },
    {
      "epoch": 2.826186051404327,
      "grad_norm": 0.1338876634836197,
      "learning_rate": 3.234367192362652e-05,
      "loss": 0.0615,
      "step": 80600
    },
    {
      "epoch": 2.82969248571128,
      "grad_norm": 0.3966173827648163,
      "learning_rate": 3.232175574861271e-05,
      "loss": 0.0579,
      "step": 80700
    },
    {
      "epoch": 2.8331989200182335,
      "grad_norm": 0.07740116864442825,
      "learning_rate": 3.22998395735989e-05,
      "loss": 0.0561,
      "step": 80800
    },
    {
      "epoch": 2.836705354325187,
      "grad_norm": 0.13477329909801483,
      "learning_rate": 3.227792339858509e-05,
      "loss": 0.0528,
      "step": 80900
    },
    {
      "epoch": 2.84021178863214,
      "grad_norm": 0.11729137599468231,
      "learning_rate": 3.225600722357129e-05,
      "loss": 0.0533,
      "step": 81000
    },
    {
      "epoch": 2.8437182229390934,
      "grad_norm": 0.14807534217834473,
      "learning_rate": 3.223409104855748e-05,
      "loss": 0.0526,
      "step": 81100
    },
    {
      "epoch": 2.8472246572460467,
      "grad_norm": 0.27596908807754517,
      "learning_rate": 3.2212174873543674e-05,
      "loss": 0.0547,
      "step": 81200
    },
    {
      "epoch": 2.8507310915529995,
      "grad_norm": 0.2062978744506836,
      "learning_rate": 3.2190258698529865e-05,
      "loss": 0.0533,
      "step": 81300
    },
    {
      "epoch": 2.8542375258599533,
      "grad_norm": 0.3281909227371216,
      "learning_rate": 3.216834252351606e-05,
      "loss": 0.0579,
      "step": 81400
    },
    {
      "epoch": 2.857743960166906,
      "grad_norm": 0.15900735557079315,
      "learning_rate": 3.214664551025239e-05,
      "loss": 0.0516,
      "step": 81500
    },
    {
      "epoch": 2.8612503944738594,
      "grad_norm": 0.09964790940284729,
      "learning_rate": 3.212472933523858e-05,
      "loss": 0.0568,
      "step": 81600
    },
    {
      "epoch": 2.8647568287808127,
      "grad_norm": 0.10271904617547989,
      "learning_rate": 3.2102813160224775e-05,
      "loss": 0.055,
      "step": 81700
    },
    {
      "epoch": 2.868263263087766,
      "grad_norm": 0.06897354125976562,
      "learning_rate": 3.2080896985210966e-05,
      "loss": 0.0565,
      "step": 81800
    },
    {
      "epoch": 2.8717696973947193,
      "grad_norm": 0.19767820835113525,
      "learning_rate": 3.2058980810197156e-05,
      "loss": 0.0544,
      "step": 81900
    },
    {
      "epoch": 2.8752761317016726,
      "grad_norm": 0.14414022862911224,
      "learning_rate": 3.203706463518335e-05,
      "loss": 0.0552,
      "step": 82000
    },
    {
      "epoch": 2.878782566008626,
      "grad_norm": 0.10947789996862411,
      "learning_rate": 3.201514846016955e-05,
      "loss": 0.0563,
      "step": 82100
    },
    {
      "epoch": 2.882289000315579,
      "grad_norm": 0.12193002551794052,
      "learning_rate": 3.199323228515574e-05,
      "loss": 0.0535,
      "step": 82200
    },
    {
      "epoch": 2.8857954346225325,
      "grad_norm": 0.29683369398117065,
      "learning_rate": 3.197131611014193e-05,
      "loss": 0.0573,
      "step": 82300
    },
    {
      "epoch": 2.8893018689294854,
      "grad_norm": 0.11641182750463486,
      "learning_rate": 3.194939993512812e-05,
      "loss": 0.0565,
      "step": 82400
    },
    {
      "epoch": 2.892808303236439,
      "grad_norm": 0.17570991814136505,
      "learning_rate": 3.192748376011432e-05,
      "loss": 0.0591,
      "step": 82500
    },
    {
      "epoch": 2.896314737543392,
      "grad_norm": 0.0911373719573021,
      "learning_rate": 3.190556758510051e-05,
      "loss": 0.0569,
      "step": 82600
    },
    {
      "epoch": 2.8998211718503453,
      "grad_norm": 0.11896704882383347,
      "learning_rate": 3.18836514100867e-05,
      "loss": 0.0535,
      "step": 82700
    },
    {
      "epoch": 2.9033276061572986,
      "grad_norm": 0.29744958877563477,
      "learning_rate": 3.1861735235072896e-05,
      "loss": 0.0545,
      "step": 82800
    },
    {
      "epoch": 2.906834040464252,
      "grad_norm": 0.22256650030612946,
      "learning_rate": 3.1839819060059086e-05,
      "loss": 0.0535,
      "step": 82900
    },
    {
      "epoch": 2.910340474771205,
      "grad_norm": 0.2731490433216095,
      "learning_rate": 3.181790288504528e-05,
      "loss": 0.0537,
      "step": 83000
    },
    {
      "epoch": 2.9138469090781585,
      "grad_norm": 0.1556558907032013,
      "learning_rate": 3.1795986710031474e-05,
      "loss": 0.0563,
      "step": 83100
    },
    {
      "epoch": 2.9173533433851118,
      "grad_norm": 0.1254826933145523,
      "learning_rate": 3.1774070535017664e-05,
      "loss": 0.0517,
      "step": 83200
    },
    {
      "epoch": 2.920859777692065,
      "grad_norm": 0.15750561654567719,
      "learning_rate": 3.175215436000386e-05,
      "loss": 0.0556,
      "step": 83300
    },
    {
      "epoch": 2.9243662119990184,
      "grad_norm": 0.2776431143283844,
      "learning_rate": 3.173023818499005e-05,
      "loss": 0.0541,
      "step": 83400
    },
    {
      "epoch": 2.927872646305971,
      "grad_norm": 0.19388088583946228,
      "learning_rate": 3.170854117172638e-05,
      "loss": 0.0563,
      "step": 83500
    },
    {
      "epoch": 2.931379080612925,
      "grad_norm": 0.17587611079216003,
      "learning_rate": 3.1686624996712575e-05,
      "loss": 0.0554,
      "step": 83600
    },
    {
      "epoch": 2.934885514919878,
      "grad_norm": 0.07750892639160156,
      "learning_rate": 3.166470882169877e-05,
      "loss": 0.0524,
      "step": 83700
    },
    {
      "epoch": 2.938391949226831,
      "grad_norm": 0.2154163271188736,
      "learning_rate": 3.164279264668496e-05,
      "loss": 0.0547,
      "step": 83800
    },
    {
      "epoch": 2.9418983835337844,
      "grad_norm": 0.2307644635438919,
      "learning_rate": 3.162087647167115e-05,
      "loss": 0.0544,
      "step": 83900
    },
    {
      "epoch": 2.9454048178407377,
      "grad_norm": 0.24280405044555664,
      "learning_rate": 3.159896029665735e-05,
      "loss": 0.0534,
      "step": 84000
    },
    {
      "epoch": 2.948911252147691,
      "grad_norm": 0.07413451373577118,
      "learning_rate": 3.157704412164354e-05,
      "loss": 0.0545,
      "step": 84100
    },
    {
      "epoch": 2.9524176864546443,
      "grad_norm": 0.10476827621459961,
      "learning_rate": 3.155512794662973e-05,
      "loss": 0.0522,
      "step": 84200
    },
    {
      "epoch": 2.9559241207615976,
      "grad_norm": 0.12153156846761703,
      "learning_rate": 3.153321177161592e-05,
      "loss": 0.0549,
      "step": 84300
    },
    {
      "epoch": 2.959430555068551,
      "grad_norm": 0.17233994603157043,
      "learning_rate": 3.151129559660212e-05,
      "loss": 0.0539,
      "step": 84400
    },
    {
      "epoch": 2.962936989375504,
      "grad_norm": 0.3531123101711273,
      "learning_rate": 3.148937942158831e-05,
      "loss": 0.0525,
      "step": 84500
    },
    {
      "epoch": 2.966443423682457,
      "grad_norm": 0.14782215654850006,
      "learning_rate": 3.1467463246574505e-05,
      "loss": 0.054,
      "step": 84600
    },
    {
      "epoch": 2.969949857989411,
      "grad_norm": 0.16820946335792542,
      "learning_rate": 3.1445547071560695e-05,
      "loss": 0.0583,
      "step": 84700
    },
    {
      "epoch": 2.9734562922963637,
      "grad_norm": 0.13039691746234894,
      "learning_rate": 3.142363089654689e-05,
      "loss": 0.0541,
      "step": 84800
    },
    {
      "epoch": 2.976962726603317,
      "grad_norm": 0.2068873643875122,
      "learning_rate": 3.140171472153308e-05,
      "loss": 0.0513,
      "step": 84900
    },
    {
      "epoch": 2.9804691609102703,
      "grad_norm": 0.26508331298828125,
      "learning_rate": 3.137979854651927e-05,
      "loss": 0.0537,
      "step": 85000
    },
    {
      "epoch": 2.9839755952172236,
      "grad_norm": 0.14599624276161194,
      "learning_rate": 3.135788237150546e-05,
      "loss": 0.0544,
      "step": 85100
    },
    {
      "epoch": 2.987482029524177,
      "grad_norm": 0.18228760361671448,
      "learning_rate": 3.133596619649166e-05,
      "loss": 0.0501,
      "step": 85200
    },
    {
      "epoch": 2.99098846383113,
      "grad_norm": 0.11008784174919128,
      "learning_rate": 3.131405002147785e-05,
      "loss": 0.0483,
      "step": 85300
    },
    {
      "epoch": 2.9944948981380834,
      "grad_norm": 0.10442976653575897,
      "learning_rate": 3.129213384646405e-05,
      "loss": 0.0561,
      "step": 85400
    },
    {
      "epoch": 2.9980013324450367,
      "grad_norm": 0.09954410046339035,
      "learning_rate": 3.127021767145024e-05,
      "loss": 0.0583,
      "step": 85500
    },
    {
      "epoch": 3.0,
      "eval_accuracy_macro_0.5": 0.9776754379272461,
      "eval_accuracy_micro_0.5": 0.9776754379272461,
      "eval_accuracy_weighted_0.5": 0.9665486812591553,
      "eval_f1_macro_0.5": 0.6535485982894897,
      "eval_f1_macro_0.6": 0.6201679706573486,
      "eval_f1_macro_0.7": 0.567119300365448,
      "eval_f1_macro_0.8": 0.3560265302658081,
      "eval_f1_micro_0.5": 0.7013792395591736,
      "eval_f1_micro_0.6": 0.6792581081390381,
      "eval_f1_micro_0.7": 0.6368439197540283,
      "eval_f1_micro_0.8": 0.565865159034729,
      "eval_f1_micro_0.9": 0.4178522527217865,
      "eval_f1_weighted_0.5": 0.6905179619789124,
      "eval_f1_weighted_0.6": 0.6613364815711975,
      "eval_f1_weighted_0.7": 0.6103219985961914,
      "eval_f1_weighted_0.8": 0.3796837031841278,
      "eval_loss": 0.05127717927098274,
      "eval_runtime": 142.9314,
      "eval_samples_per_second": 398.842,
      "eval_steps_per_second": 49.856,
      "step": 85557
    },
    {
      "epoch": 3.00150776675199,
      "grad_norm": 0.1047443151473999,
      "learning_rate": 3.124852065818657e-05,
      "loss": 0.0585,
      "step": 85600
    },
    {
      "epoch": 3.0050142010589433,
      "grad_norm": 0.17426098883152008,
      "learning_rate": 3.122660448317276e-05,
      "loss": 0.0526,
      "step": 85700
    },
    {
      "epoch": 3.008520635365896,
      "grad_norm": 0.29542750120162964,
      "learning_rate": 3.120468830815895e-05,
      "loss": 0.055,
      "step": 85800
    },
    {
      "epoch": 3.0120270696728495,
      "grad_norm": 0.28410011529922485,
      "learning_rate": 3.118277213314515e-05,
      "loss": 0.0566,
      "step": 85900
    },
    {
      "epoch": 3.015533503979803,
      "grad_norm": 0.20214597880840302,
      "learning_rate": 3.116085595813134e-05,
      "loss": 0.057,
      "step": 86000
    },
    {
      "epoch": 3.019039938286756,
      "grad_norm": 0.32627010345458984,
      "learning_rate": 3.113893978311753e-05,
      "loss": 0.055,
      "step": 86100
    },
    {
      "epoch": 3.0225463725937094,
      "grad_norm": 0.16908246278762817,
      "learning_rate": 3.1117023608103726e-05,
      "loss": 0.0562,
      "step": 86200
    },
    {
      "epoch": 3.0260528069006627,
      "grad_norm": 0.14736561477184296,
      "learning_rate": 3.1095107433089924e-05,
      "loss": 0.0513,
      "step": 86300
    },
    {
      "epoch": 3.029559241207616,
      "grad_norm": 0.13028936088085175,
      "learning_rate": 3.1073191258076114e-05,
      "loss": 0.0564,
      "step": 86400
    },
    {
      "epoch": 3.0330656755145693,
      "grad_norm": 0.1190159022808075,
      "learning_rate": 3.1051275083062304e-05,
      "loss": 0.0542,
      "step": 86500
    },
    {
      "epoch": 3.0365721098215226,
      "grad_norm": 0.20274804532527924,
      "learning_rate": 3.10293589080485e-05,
      "loss": 0.0569,
      "step": 86600
    },
    {
      "epoch": 3.040078544128476,
      "grad_norm": 0.10006458312273026,
      "learning_rate": 3.100744273303469e-05,
      "loss": 0.0583,
      "step": 86700
    },
    {
      "epoch": 3.043584978435429,
      "grad_norm": 0.141121968626976,
      "learning_rate": 3.098552655802088e-05,
      "loss": 0.053,
      "step": 86800
    },
    {
      "epoch": 3.0470914127423825,
      "grad_norm": 0.2139941155910492,
      "learning_rate": 3.096361038300707e-05,
      "loss": 0.0551,
      "step": 86900
    },
    {
      "epoch": 3.0505978470493353,
      "grad_norm": 0.16559456288814545,
      "learning_rate": 3.094169420799327e-05,
      "loss": 0.0551,
      "step": 87000
    },
    {
      "epoch": 3.0541042813562886,
      "grad_norm": 0.19308549165725708,
      "learning_rate": 3.091977803297946e-05,
      "loss": 0.0526,
      "step": 87100
    },
    {
      "epoch": 3.057610715663242,
      "grad_norm": 0.2588374614715576,
      "learning_rate": 3.089786185796566e-05,
      "loss": 0.0597,
      "step": 87200
    },
    {
      "epoch": 3.0611171499701952,
      "grad_norm": 0.15533709526062012,
      "learning_rate": 3.087594568295185e-05,
      "loss": 0.0523,
      "step": 87300
    },
    {
      "epoch": 3.0646235842771485,
      "grad_norm": 0.17616333067417145,
      "learning_rate": 3.0854029507938044e-05,
      "loss": 0.0494,
      "step": 87400
    },
    {
      "epoch": 3.068130018584102,
      "grad_norm": 0.4461771249771118,
      "learning_rate": 3.0832113332924235e-05,
      "loss": 0.0537,
      "step": 87500
    },
    {
      "epoch": 3.071636452891055,
      "grad_norm": 0.2671995460987091,
      "learning_rate": 3.0810197157910425e-05,
      "loss": 0.057,
      "step": 87600
    },
    {
      "epoch": 3.0751428871980084,
      "grad_norm": 0.2601347863674164,
      "learning_rate": 3.078850014464676e-05,
      "loss": 0.0531,
      "step": 87700
    },
    {
      "epoch": 3.0786493215049617,
      "grad_norm": 0.25364625453948975,
      "learning_rate": 3.076658396963295e-05,
      "loss": 0.055,
      "step": 87800
    },
    {
      "epoch": 3.082155755811915,
      "grad_norm": 0.34476789832115173,
      "learning_rate": 3.0744667794619145e-05,
      "loss": 0.0511,
      "step": 87900
    },
    {
      "epoch": 3.0856621901188683,
      "grad_norm": 0.16425344347953796,
      "learning_rate": 3.0722751619605335e-05,
      "loss": 0.0554,
      "step": 88000
    },
    {
      "epoch": 3.089168624425821,
      "grad_norm": 0.3792807161808014,
      "learning_rate": 3.070083544459153e-05,
      "loss": 0.0548,
      "step": 88100
    },
    {
      "epoch": 3.0926750587327745,
      "grad_norm": 0.2737577259540558,
      "learning_rate": 3.067891926957772e-05,
      "loss": 0.0567,
      "step": 88200
    },
    {
      "epoch": 3.096181493039728,
      "grad_norm": 0.3542306125164032,
      "learning_rate": 3.065700309456391e-05,
      "loss": 0.0536,
      "step": 88300
    },
    {
      "epoch": 3.099687927346681,
      "grad_norm": 0.12563350796699524,
      "learning_rate": 3.0635086919550104e-05,
      "loss": 0.0549,
      "step": 88400
    },
    {
      "epoch": 3.1031943616536344,
      "grad_norm": 0.25466781854629517,
      "learning_rate": 3.06131707445363e-05,
      "loss": 0.055,
      "step": 88500
    },
    {
      "epoch": 3.1067007959605877,
      "grad_norm": 0.1893484890460968,
      "learning_rate": 3.059125456952249e-05,
      "loss": 0.0519,
      "step": 88600
    },
    {
      "epoch": 3.110207230267541,
      "grad_norm": 0.26964321732521057,
      "learning_rate": 3.056933839450868e-05,
      "loss": 0.0564,
      "step": 88700
    },
    {
      "epoch": 3.1137136645744943,
      "grad_norm": 0.37068116664886475,
      "learning_rate": 3.054742221949488e-05,
      "loss": 0.0539,
      "step": 88800
    },
    {
      "epoch": 3.1172200988814476,
      "grad_norm": 0.08186089247465134,
      "learning_rate": 3.0525506044481075e-05,
      "loss": 0.0514,
      "step": 88900
    },
    {
      "epoch": 3.120726533188401,
      "grad_norm": 0.17014658451080322,
      "learning_rate": 3.0503589869467262e-05,
      "loss": 0.0557,
      "step": 89000
    },
    {
      "epoch": 3.124232967495354,
      "grad_norm": 0.14944171905517578,
      "learning_rate": 3.0481673694453456e-05,
      "loss": 0.0498,
      "step": 89100
    },
    {
      "epoch": 3.127739401802307,
      "grad_norm": 0.2479085624217987,
      "learning_rate": 3.0459757519439646e-05,
      "loss": 0.0573,
      "step": 89200
    },
    {
      "epoch": 3.1312458361092603,
      "grad_norm": 0.2509849965572357,
      "learning_rate": 3.0437841344425844e-05,
      "loss": 0.056,
      "step": 89300
    },
    {
      "epoch": 3.1347522704162136,
      "grad_norm": 0.35349246859550476,
      "learning_rate": 3.0415925169412034e-05,
      "loss": 0.0523,
      "step": 89400
    },
    {
      "epoch": 3.138258704723167,
      "grad_norm": 0.3028571903705597,
      "learning_rate": 3.0394008994398228e-05,
      "loss": 0.0486,
      "step": 89500
    },
    {
      "epoch": 3.1417651390301202,
      "grad_norm": 0.18029898405075073,
      "learning_rate": 3.0372092819384418e-05,
      "loss": 0.0522,
      "step": 89600
    },
    {
      "epoch": 3.1452715733370735,
      "grad_norm": 0.21111179888248444,
      "learning_rate": 3.0350176644370615e-05,
      "loss": 0.0521,
      "step": 89700
    },
    {
      "epoch": 3.148778007644027,
      "grad_norm": 0.15414650738239288,
      "learning_rate": 3.0328260469356805e-05,
      "loss": 0.0539,
      "step": 89800
    },
    {
      "epoch": 3.15228444195098,
      "grad_norm": 0.25906869769096375,
      "learning_rate": 3.0306344294343e-05,
      "loss": 0.0521,
      "step": 89900
    },
    {
      "epoch": 3.1557908762579334,
      "grad_norm": 0.14222732186317444,
      "learning_rate": 3.0284647281079332e-05,
      "loss": 0.0506,
      "step": 90000
    },
    {
      "epoch": 3.1592973105648867,
      "grad_norm": 0.3189198970794678,
      "learning_rate": 3.0262731106065522e-05,
      "loss": 0.0512,
      "step": 90100
    },
    {
      "epoch": 3.16280374487184,
      "grad_norm": 0.36723798513412476,
      "learning_rate": 3.0240814931051712e-05,
      "loss": 0.0496,
      "step": 90200
    },
    {
      "epoch": 3.166310179178793,
      "grad_norm": 0.28412434458732605,
      "learning_rate": 3.0218898756037906e-05,
      "loss": 0.0551,
      "step": 90300
    },
    {
      "epoch": 3.169816613485746,
      "grad_norm": 0.1454496532678604,
      "learning_rate": 3.0196982581024103e-05,
      "loss": 0.0529,
      "step": 90400
    },
    {
      "epoch": 3.1733230477926995,
      "grad_norm": 0.24105989933013916,
      "learning_rate": 3.0175066406010294e-05,
      "loss": 0.0558,
      "step": 90500
    },
    {
      "epoch": 3.1768294820996528,
      "grad_norm": 0.08796227723360062,
      "learning_rate": 3.0153150230996484e-05,
      "loss": 0.0576,
      "step": 90600
    },
    {
      "epoch": 3.180335916406606,
      "grad_norm": 0.2556005120277405,
      "learning_rate": 3.0131234055982678e-05,
      "loss": 0.0549,
      "step": 90700
    },
    {
      "epoch": 3.1838423507135594,
      "grad_norm": 0.26480382680892944,
      "learning_rate": 3.0109317880968875e-05,
      "loss": 0.0496,
      "step": 90800
    },
    {
      "epoch": 3.1873487850205127,
      "grad_norm": 0.258789986371994,
      "learning_rate": 3.0087401705955065e-05,
      "loss": 0.058,
      "step": 90900
    },
    {
      "epoch": 3.190855219327466,
      "grad_norm": 0.3308645784854889,
      "learning_rate": 3.0065485530941255e-05,
      "loss": 0.0537,
      "step": 91000
    },
    {
      "epoch": 3.1943616536344193,
      "grad_norm": 0.3090886175632477,
      "learning_rate": 3.004356935592745e-05,
      "loss": 0.0556,
      "step": 91100
    },
    {
      "epoch": 3.1978680879413726,
      "grad_norm": 0.2651269733905792,
      "learning_rate": 3.0021653180913646e-05,
      "loss": 0.0516,
      "step": 91200
    },
    {
      "epoch": 3.201374522248326,
      "grad_norm": 0.3957650065422058,
      "learning_rate": 2.9999737005899837e-05,
      "loss": 0.0513,
      "step": 91300
    },
    {
      "epoch": 3.2048809565552787,
      "grad_norm": 0.16934716701507568,
      "learning_rate": 2.9977820830886027e-05,
      "loss": 0.0515,
      "step": 91400
    },
    {
      "epoch": 3.208387390862232,
      "grad_norm": 0.3686668574810028,
      "learning_rate": 2.995590465587222e-05,
      "loss": 0.0493,
      "step": 91500
    },
    {
      "epoch": 3.2118938251691853,
      "grad_norm": 0.3587246835231781,
      "learning_rate": 2.9933988480858414e-05,
      "loss": 0.0532,
      "step": 91600
    },
    {
      "epoch": 3.2154002594761386,
      "grad_norm": 0.34773820638656616,
      "learning_rate": 2.9912072305844608e-05,
      "loss": 0.052,
      "step": 91700
    },
    {
      "epoch": 3.218906693783092,
      "grad_norm": 0.1308096945285797,
      "learning_rate": 2.98901561308308e-05,
      "loss": 0.0501,
      "step": 91800
    },
    {
      "epoch": 3.222413128090045,
      "grad_norm": 0.3197219967842102,
      "learning_rate": 2.986823995581699e-05,
      "loss": 0.0532,
      "step": 91900
    },
    {
      "epoch": 3.2259195623969985,
      "grad_norm": 0.251354455947876,
      "learning_rate": 2.9846323780803186e-05,
      "loss": 0.0558,
      "step": 92000
    },
    {
      "epoch": 3.229425996703952,
      "grad_norm": 0.2688784599304199,
      "learning_rate": 2.9824626767539515e-05,
      "loss": 0.0553,
      "step": 92100
    },
    {
      "epoch": 3.232932431010905,
      "grad_norm": 0.1622275412082672,
      "learning_rate": 2.9802710592525706e-05,
      "loss": 0.052,
      "step": 92200
    },
    {
      "epoch": 3.2364388653178584,
      "grad_norm": 0.21996203064918518,
      "learning_rate": 2.9780794417511903e-05,
      "loss": 0.0545,
      "step": 92300
    },
    {
      "epoch": 3.2399452996248117,
      "grad_norm": 0.22582565248012543,
      "learning_rate": 2.9758878242498096e-05,
      "loss": 0.0544,
      "step": 92400
    },
    {
      "epoch": 3.2434517339317646,
      "grad_norm": 0.18851500749588013,
      "learning_rate": 2.9736962067484287e-05,
      "loss": 0.0542,
      "step": 92500
    },
    {
      "epoch": 3.246958168238718,
      "grad_norm": 0.2509227693080902,
      "learning_rate": 2.9715045892470477e-05,
      "loss": 0.0546,
      "step": 92600
    },
    {
      "epoch": 3.250464602545671,
      "grad_norm": 0.14111648499965668,
      "learning_rate": 2.9693129717456674e-05,
      "loss": 0.0525,
      "step": 92700
    },
    {
      "epoch": 3.2539710368526245,
      "grad_norm": 0.15026575326919556,
      "learning_rate": 2.9671213542442868e-05,
      "loss": 0.0529,
      "step": 92800
    },
    {
      "epoch": 3.2574774711595778,
      "grad_norm": 0.2616265118122101,
      "learning_rate": 2.9649297367429058e-05,
      "loss": 0.0581,
      "step": 92900
    },
    {
      "epoch": 3.260983905466531,
      "grad_norm": 0.3783242404460907,
      "learning_rate": 2.962738119241525e-05,
      "loss": 0.0521,
      "step": 93000
    },
    {
      "epoch": 3.2644903397734844,
      "grad_norm": 0.32042190432548523,
      "learning_rate": 2.9605465017401446e-05,
      "loss": 0.0513,
      "step": 93100
    },
    {
      "epoch": 3.2679967740804376,
      "grad_norm": 0.22312918305397034,
      "learning_rate": 2.9583548842387636e-05,
      "loss": 0.0532,
      "step": 93200
    },
    {
      "epoch": 3.271503208387391,
      "grad_norm": 0.23467889428138733,
      "learning_rate": 2.956163266737383e-05,
      "loss": 0.0511,
      "step": 93300
    },
    {
      "epoch": 3.2750096426943442,
      "grad_norm": 0.21101072430610657,
      "learning_rate": 2.953971649236002e-05,
      "loss": 0.0553,
      "step": 93400
    },
    {
      "epoch": 3.2785160770012975,
      "grad_norm": 0.23123827576637268,
      "learning_rate": 2.9517800317346217e-05,
      "loss": 0.0561,
      "step": 93500
    },
    {
      "epoch": 3.2820225113082504,
      "grad_norm": 0.16055212914943695,
      "learning_rate": 2.9495884142332407e-05,
      "loss": 0.0541,
      "step": 93600
    },
    {
      "epoch": 3.285528945615204,
      "grad_norm": 0.24449361860752106,
      "learning_rate": 2.94739679673186e-05,
      "loss": 0.0515,
      "step": 93700
    },
    {
      "epoch": 3.289035379922157,
      "grad_norm": 0.12658973038196564,
      "learning_rate": 2.9452051792304798e-05,
      "loss": 0.051,
      "step": 93800
    },
    {
      "epoch": 3.2925418142291103,
      "grad_norm": 0.2842487692832947,
      "learning_rate": 2.943013561729099e-05,
      "loss": 0.054,
      "step": 93900
    },
    {
      "epoch": 3.2960482485360636,
      "grad_norm": 0.11318394541740417,
      "learning_rate": 2.940821944227718e-05,
      "loss": 0.0562,
      "step": 94000
    },
    {
      "epoch": 3.299554682843017,
      "grad_norm": 0.08704891800880432,
      "learning_rate": 2.9386303267263372e-05,
      "loss": 0.0502,
      "step": 94100
    },
    {
      "epoch": 3.30306111714997,
      "grad_norm": 0.16629020869731903,
      "learning_rate": 2.9364387092249566e-05,
      "loss": 0.0545,
      "step": 94200
    },
    {
      "epoch": 3.3065675514569235,
      "grad_norm": 0.23792222142219543,
      "learning_rate": 2.934247091723576e-05,
      "loss": 0.0535,
      "step": 94300
    },
    {
      "epoch": 3.310073985763877,
      "grad_norm": 0.2930978536605835,
      "learning_rate": 2.932055474222195e-05,
      "loss": 0.0517,
      "step": 94400
    },
    {
      "epoch": 3.31358042007083,
      "grad_norm": 0.1431056708097458,
      "learning_rate": 2.929863856720814e-05,
      "loss": 0.0528,
      "step": 94500
    },
    {
      "epoch": 3.3170868543777834,
      "grad_norm": 0.09900721907615662,
      "learning_rate": 2.9276722392194338e-05,
      "loss": 0.0575,
      "step": 94600
    },
    {
      "epoch": 3.3205932886847362,
      "grad_norm": 0.15218792855739594,
      "learning_rate": 2.9255025378930667e-05,
      "loss": 0.0541,
      "step": 94700
    },
    {
      "epoch": 3.32409972299169,
      "grad_norm": 0.10927978903055191,
      "learning_rate": 2.9233109203916857e-05,
      "loss": 0.0566,
      "step": 94800
    },
    {
      "epoch": 3.327606157298643,
      "grad_norm": 0.16211892664432526,
      "learning_rate": 2.9211193028903054e-05,
      "loss": 0.0566,
      "step": 94900
    },
    {
      "epoch": 3.331112591605596,
      "grad_norm": 0.1964457929134369,
      "learning_rate": 2.9189276853889248e-05,
      "loss": 0.0531,
      "step": 95000
    },
    {
      "epoch": 3.3346190259125494,
      "grad_norm": 0.2570195198059082,
      "learning_rate": 2.916736067887544e-05,
      "loss": 0.0518,
      "step": 95100
    },
    {
      "epoch": 3.3381254602195027,
      "grad_norm": 0.13220900297164917,
      "learning_rate": 2.914544450386163e-05,
      "loss": 0.0492,
      "step": 95200
    },
    {
      "epoch": 3.341631894526456,
      "grad_norm": 0.3883036971092224,
      "learning_rate": 2.9123528328847826e-05,
      "loss": 0.0539,
      "step": 95300
    },
    {
      "epoch": 3.3451383288334093,
      "grad_norm": 0.16480784118175507,
      "learning_rate": 2.910161215383402e-05,
      "loss": 0.0546,
      "step": 95400
    },
    {
      "epoch": 3.3486447631403626,
      "grad_norm": 0.14030160009860992,
      "learning_rate": 2.907969597882021e-05,
      "loss": 0.0548,
      "step": 95500
    },
    {
      "epoch": 3.352151197447316,
      "grad_norm": 0.11748478561639786,
      "learning_rate": 2.90577798038064e-05,
      "loss": 0.0497,
      "step": 95600
    },
    {
      "epoch": 3.3556576317542692,
      "grad_norm": 0.1569283902645111,
      "learning_rate": 2.9035863628792597e-05,
      "loss": 0.0505,
      "step": 95700
    },
    {
      "epoch": 3.3591640660612225,
      "grad_norm": 0.14326955378055573,
      "learning_rate": 2.9013947453778788e-05,
      "loss": 0.0534,
      "step": 95800
    },
    {
      "epoch": 3.362670500368176,
      "grad_norm": 0.14776545763015747,
      "learning_rate": 2.899203127876498e-05,
      "loss": 0.0532,
      "step": 95900
    },
    {
      "epoch": 3.3661769346751287,
      "grad_norm": 0.2059972733259201,
      "learning_rate": 2.8970115103751172e-05,
      "loss": 0.0547,
      "step": 96000
    },
    {
      "epoch": 3.369683368982082,
      "grad_norm": 0.34926044940948486,
      "learning_rate": 2.894819892873737e-05,
      "loss": 0.0537,
      "step": 96100
    },
    {
      "epoch": 3.3731898032890353,
      "grad_norm": 0.11737829446792603,
      "learning_rate": 2.892628275372356e-05,
      "loss": 0.058,
      "step": 96200
    },
    {
      "epoch": 3.3766962375959886,
      "grad_norm": 0.3037338852882385,
      "learning_rate": 2.8904366578709753e-05,
      "loss": 0.0501,
      "step": 96300
    },
    {
      "epoch": 3.380202671902942,
      "grad_norm": 0.39697593450546265,
      "learning_rate": 2.8882450403695943e-05,
      "loss": 0.0571,
      "step": 96400
    },
    {
      "epoch": 3.383709106209895,
      "grad_norm": 0.14149585366249084,
      "learning_rate": 2.886053422868214e-05,
      "loss": 0.0497,
      "step": 96500
    },
    {
      "epoch": 3.3872155405168485,
      "grad_norm": 0.13294197618961334,
      "learning_rate": 2.883861805366833e-05,
      "loss": 0.049,
      "step": 96600
    },
    {
      "epoch": 3.3907219748238018,
      "grad_norm": 0.145257830619812,
      "learning_rate": 2.8816701878654524e-05,
      "loss": 0.0546,
      "step": 96700
    },
    {
      "epoch": 3.394228409130755,
      "grad_norm": 0.1551475077867508,
      "learning_rate": 2.8795004865390857e-05,
      "loss": 0.054,
      "step": 96800
    },
    {
      "epoch": 3.3977348434377084,
      "grad_norm": 0.3628693222999573,
      "learning_rate": 2.8773088690377048e-05,
      "loss": 0.0501,
      "step": 96900
    },
    {
      "epoch": 3.4012412777446617,
      "grad_norm": 0.22441434860229492,
      "learning_rate": 2.8751172515363238e-05,
      "loss": 0.0542,
      "step": 97000
    },
    {
      "epoch": 3.4047477120516145,
      "grad_norm": 0.23857362568378448,
      "learning_rate": 2.872925634034943e-05,
      "loss": 0.0515,
      "step": 97100
    },
    {
      "epoch": 3.408254146358568,
      "grad_norm": 0.15451286733150482,
      "learning_rate": 2.870734016533563e-05,
      "loss": 0.0513,
      "step": 97200
    },
    {
      "epoch": 3.411760580665521,
      "grad_norm": 0.25781211256980896,
      "learning_rate": 2.868542399032182e-05,
      "loss": 0.0559,
      "step": 97300
    },
    {
      "epoch": 3.4152670149724744,
      "grad_norm": 0.20652174949645996,
      "learning_rate": 2.866350781530801e-05,
      "loss": 0.0518,
      "step": 97400
    },
    {
      "epoch": 3.4187734492794277,
      "grad_norm": 0.2836974859237671,
      "learning_rate": 2.8641591640294203e-05,
      "loss": 0.0529,
      "step": 97500
    },
    {
      "epoch": 3.422279883586381,
      "grad_norm": 0.33063796162605286,
      "learning_rate": 2.86196754652804e-05,
      "loss": 0.0534,
      "step": 97600
    },
    {
      "epoch": 3.4257863178933343,
      "grad_norm": 0.17635470628738403,
      "learning_rate": 2.859775929026659e-05,
      "loss": 0.0537,
      "step": 97700
    },
    {
      "epoch": 3.4292927522002876,
      "grad_norm": 0.4028550684452057,
      "learning_rate": 2.857584311525278e-05,
      "loss": 0.0515,
      "step": 97800
    },
    {
      "epoch": 3.432799186507241,
      "grad_norm": 0.19805799424648285,
      "learning_rate": 2.8553926940238974e-05,
      "loss": 0.0543,
      "step": 97900
    },
    {
      "epoch": 3.436305620814194,
      "grad_norm": 0.35256481170654297,
      "learning_rate": 2.853201076522517e-05,
      "loss": 0.0549,
      "step": 98000
    },
    {
      "epoch": 3.4398120551211475,
      "grad_norm": 0.12890885770320892,
      "learning_rate": 2.8510094590211362e-05,
      "loss": 0.0533,
      "step": 98100
    },
    {
      "epoch": 3.4433184894281004,
      "grad_norm": 0.29826444387435913,
      "learning_rate": 2.8488178415197552e-05,
      "loss": 0.0553,
      "step": 98200
    },
    {
      "epoch": 3.4468249237350537,
      "grad_norm": 0.1731192022562027,
      "learning_rate": 2.8466262240183743e-05,
      "loss": 0.0523,
      "step": 98300
    },
    {
      "epoch": 3.450331358042007,
      "grad_norm": 0.15061406791210175,
      "learning_rate": 2.844434606516994e-05,
      "loss": 0.0508,
      "step": 98400
    },
    {
      "epoch": 3.4538377923489603,
      "grad_norm": 0.1739707887172699,
      "learning_rate": 2.8422429890156133e-05,
      "loss": 0.0528,
      "step": 98500
    },
    {
      "epoch": 3.4573442266559136,
      "grad_norm": 0.3006652593612671,
      "learning_rate": 2.8400513715142324e-05,
      "loss": 0.0513,
      "step": 98600
    },
    {
      "epoch": 3.460850660962867,
      "grad_norm": 0.16835904121398926,
      "learning_rate": 2.8378597540128514e-05,
      "loss": 0.0586,
      "step": 98700
    },
    {
      "epoch": 3.46435709526982,
      "grad_norm": 0.2317231297492981,
      "learning_rate": 2.835668136511471e-05,
      "loss": 0.054,
      "step": 98800
    },
    {
      "epoch": 3.4678635295767735,
      "grad_norm": 0.26235973834991455,
      "learning_rate": 2.833498435185104e-05,
      "loss": 0.051,
      "step": 98900
    },
    {
      "epoch": 3.4713699638837268,
      "grad_norm": 0.19065430760383606,
      "learning_rate": 2.831306817683723e-05,
      "loss": 0.0509,
      "step": 99000
    },
    {
      "epoch": 3.47487639819068,
      "grad_norm": 0.5368556380271912,
      "learning_rate": 2.8291152001823428e-05,
      "loss": 0.0536,
      "step": 99100
    },
    {
      "epoch": 3.4783828324976334,
      "grad_norm": 0.11958378553390503,
      "learning_rate": 2.826923582680962e-05,
      "loss": 0.0513,
      "step": 99200
    },
    {
      "epoch": 3.481889266804586,
      "grad_norm": 0.3117299973964691,
      "learning_rate": 2.8247319651795812e-05,
      "loss": 0.0573,
      "step": 99300
    },
    {
      "epoch": 3.4853957011115395,
      "grad_norm": 0.15691763162612915,
      "learning_rate": 2.8225403476782002e-05,
      "loss": 0.0521,
      "step": 99400
    },
    {
      "epoch": 3.488902135418493,
      "grad_norm": 0.16672782599925995,
      "learning_rate": 2.82034873017682e-05,
      "loss": 0.0534,
      "step": 99500
    },
    {
      "epoch": 3.492408569725446,
      "grad_norm": 0.33985280990600586,
      "learning_rate": 2.818157112675439e-05,
      "loss": 0.0522,
      "step": 99600
    },
    {
      "epoch": 3.4959150040323994,
      "grad_norm": 0.09990174323320389,
      "learning_rate": 2.8159654951740583e-05,
      "loss": 0.0507,
      "step": 99700
    },
    {
      "epoch": 3.4994214383393527,
      "grad_norm": 0.14362487196922302,
      "learning_rate": 2.8137738776726774e-05,
      "loss": 0.0544,
      "step": 99800
    },
    {
      "epoch": 3.502927872646306,
      "grad_norm": 0.10962202399969101,
      "learning_rate": 2.811582260171297e-05,
      "loss": 0.0549,
      "step": 99900
    },
    {
      "epoch": 3.5064343069532593,
      "grad_norm": 0.15445227921009064,
      "learning_rate": 2.809390642669916e-05,
      "loss": 0.0559,
      "step": 100000
    },
    {
      "epoch": 3.5099407412602126,
      "grad_norm": 0.09749395400285721,
      "learning_rate": 2.8071990251685355e-05,
      "loss": 0.0491,
      "step": 100100
    },
    {
      "epoch": 3.513447175567166,
      "grad_norm": 0.1788245141506195,
      "learning_rate": 2.8050074076671545e-05,
      "loss": 0.0506,
      "step": 100200
    },
    {
      "epoch": 3.516953609874119,
      "grad_norm": 0.3004210889339447,
      "learning_rate": 2.8028157901657742e-05,
      "loss": 0.0559,
      "step": 100300
    },
    {
      "epoch": 3.520460044181072,
      "grad_norm": 0.2988424599170685,
      "learning_rate": 2.8006241726643933e-05,
      "loss": 0.0524,
      "step": 100400
    },
    {
      "epoch": 3.523966478488026,
      "grad_norm": 0.21129103004932404,
      "learning_rate": 2.7984325551630126e-05,
      "loss": 0.054,
      "step": 100500
    },
    {
      "epoch": 3.5274729127949787,
      "grad_norm": 0.27606886625289917,
      "learning_rate": 2.7962409376616323e-05,
      "loss": 0.0577,
      "step": 100600
    },
    {
      "epoch": 3.530979347101932,
      "grad_norm": 0.335831880569458,
      "learning_rate": 2.7940493201602514e-05,
      "loss": 0.0505,
      "step": 100700
    },
    {
      "epoch": 3.5344857814088853,
      "grad_norm": 0.10328932106494904,
      "learning_rate": 2.7918577026588704e-05,
      "loss": 0.0501,
      "step": 100800
    },
    {
      "epoch": 3.5379922157158386,
      "grad_norm": 0.1901196986436844,
      "learning_rate": 2.7896660851574898e-05,
      "loss": 0.055,
      "step": 100900
    },
    {
      "epoch": 3.541498650022792,
      "grad_norm": 0.26595649123191833,
      "learning_rate": 2.787496383831123e-05,
      "loss": 0.057,
      "step": 101000
    },
    {
      "epoch": 3.545005084329745,
      "grad_norm": 0.15130573511123657,
      "learning_rate": 2.785304766329742e-05,
      "loss": 0.0525,
      "step": 101100
    },
    {
      "epoch": 3.5485115186366984,
      "grad_norm": 0.4053647816181183,
      "learning_rate": 2.783113148828361e-05,
      "loss": 0.0517,
      "step": 101200
    },
    {
      "epoch": 3.5520179529436517,
      "grad_norm": 0.2674849033355713,
      "learning_rate": 2.780921531326981e-05,
      "loss": 0.0515,
      "step": 101300
    },
    {
      "epoch": 3.555524387250605,
      "grad_norm": 0.25268757343292236,
      "learning_rate": 2.7787299138256002e-05,
      "loss": 0.0563,
      "step": 101400
    },
    {
      "epoch": 3.559030821557558,
      "grad_norm": 0.2828282117843628,
      "learning_rate": 2.7765382963242192e-05,
      "loss": 0.0505,
      "step": 101500
    },
    {
      "epoch": 3.5625372558645116,
      "grad_norm": 0.29207906126976013,
      "learning_rate": 2.7743466788228383e-05,
      "loss": 0.0559,
      "step": 101600
    },
    {
      "epoch": 3.5660436901714645,
      "grad_norm": 0.13904160261154175,
      "learning_rate": 2.772155061321458e-05,
      "loss": 0.054,
      "step": 101700
    },
    {
      "epoch": 3.569550124478418,
      "grad_norm": 0.3778799772262573,
      "learning_rate": 2.7699634438200774e-05,
      "loss": 0.0576,
      "step": 101800
    },
    {
      "epoch": 3.573056558785371,
      "grad_norm": 0.11672521382570267,
      "learning_rate": 2.7677718263186964e-05,
      "loss": 0.0543,
      "step": 101900
    },
    {
      "epoch": 3.5765629930923244,
      "grad_norm": 0.21423810720443726,
      "learning_rate": 2.7655802088173154e-05,
      "loss": 0.0531,
      "step": 102000
    },
    {
      "epoch": 3.5800694273992777,
      "grad_norm": 0.22901836037635803,
      "learning_rate": 2.763388591315935e-05,
      "loss": 0.0563,
      "step": 102100
    },
    {
      "epoch": 3.583575861706231,
      "grad_norm": 0.1700996458530426,
      "learning_rate": 2.761196973814554e-05,
      "loss": 0.0554,
      "step": 102200
    },
    {
      "epoch": 3.5870822960131843,
      "grad_norm": 0.13188564777374268,
      "learning_rate": 2.7590053563131735e-05,
      "loss": 0.0492,
      "step": 102300
    },
    {
      "epoch": 3.5905887303201376,
      "grad_norm": 0.27975329756736755,
      "learning_rate": 2.7568137388117926e-05,
      "loss": 0.054,
      "step": 102400
    },
    {
      "epoch": 3.594095164627091,
      "grad_norm": 0.2349974662065506,
      "learning_rate": 2.7546221213104123e-05,
      "loss": 0.0525,
      "step": 102500
    },
    {
      "epoch": 3.5976015989340437,
      "grad_norm": 0.3344990909099579,
      "learning_rate": 2.7524305038090313e-05,
      "loss": 0.0544,
      "step": 102600
    },
    {
      "epoch": 3.6011080332409975,
      "grad_norm": 0.2982139587402344,
      "learning_rate": 2.7502388863076507e-05,
      "loss": 0.0528,
      "step": 102700
    },
    {
      "epoch": 3.6046144675479503,
      "grad_norm": 0.14088758826255798,
      "learning_rate": 2.7480472688062697e-05,
      "loss": 0.0528,
      "step": 102800
    },
    {
      "epoch": 3.6081209018549036,
      "grad_norm": 0.3422216773033142,
      "learning_rate": 2.7458556513048894e-05,
      "loss": 0.0525,
      "step": 102900
    },
    {
      "epoch": 3.611627336161857,
      "grad_norm": 0.2159413844347,
      "learning_rate": 2.7436640338035085e-05,
      "loss": 0.0583,
      "step": 103000
    },
    {
      "epoch": 3.6151337704688102,
      "grad_norm": 0.23939990997314453,
      "learning_rate": 2.7414943324771414e-05,
      "loss": 0.0572,
      "step": 103100
    },
    {
      "epoch": 3.6186402047757635,
      "grad_norm": 0.22080907225608826,
      "learning_rate": 2.739302714975761e-05,
      "loss": 0.057,
      "step": 103200
    },
    {
      "epoch": 3.622146639082717,
      "grad_norm": 0.08147355169057846,
      "learning_rate": 2.73711109747438e-05,
      "loss": 0.0543,
      "step": 103300
    },
    {
      "epoch": 3.62565307338967,
      "grad_norm": 0.310135155916214,
      "learning_rate": 2.7349194799729995e-05,
      "loss": 0.0563,
      "step": 103400
    },
    {
      "epoch": 3.6291595076966234,
      "grad_norm": 0.23154251277446747,
      "learning_rate": 2.7327278624716185e-05,
      "loss": 0.0507,
      "step": 103500
    },
    {
      "epoch": 3.6326659420035767,
      "grad_norm": 0.1360321193933487,
      "learning_rate": 2.7305362449702383e-05,
      "loss": 0.0552,
      "step": 103600
    },
    {
      "epoch": 3.6361723763105296,
      "grad_norm": 0.22200226783752441,
      "learning_rate": 2.7283446274688573e-05,
      "loss": 0.0526,
      "step": 103700
    },
    {
      "epoch": 3.6396788106174833,
      "grad_norm": 0.297838419675827,
      "learning_rate": 2.7261530099674763e-05,
      "loss": 0.0542,
      "step": 103800
    },
    {
      "epoch": 3.643185244924436,
      "grad_norm": 0.16632546484470367,
      "learning_rate": 2.7239613924660957e-05,
      "loss": 0.0507,
      "step": 103900
    },
    {
      "epoch": 3.6466916792313895,
      "grad_norm": 0.5043283700942993,
      "learning_rate": 2.7217697749647154e-05,
      "loss": 0.0533,
      "step": 104000
    },
    {
      "epoch": 3.650198113538343,
      "grad_norm": 0.1936691403388977,
      "learning_rate": 2.7195781574633344e-05,
      "loss": 0.0598,
      "step": 104100
    },
    {
      "epoch": 3.653704547845296,
      "grad_norm": 0.4320053458213806,
      "learning_rate": 2.7173865399619535e-05,
      "loss": 0.0522,
      "step": 104200
    },
    {
      "epoch": 3.6572109821522494,
      "grad_norm": 0.11401653289794922,
      "learning_rate": 2.715194922460573e-05,
      "loss": 0.0499,
      "step": 104300
    },
    {
      "epoch": 3.6607174164592027,
      "grad_norm": 0.3106687068939209,
      "learning_rate": 2.7130033049591925e-05,
      "loss": 0.055,
      "step": 104400
    },
    {
      "epoch": 3.664223850766156,
      "grad_norm": 0.1933131068944931,
      "learning_rate": 2.7108116874578116e-05,
      "loss": 0.0492,
      "step": 104500
    },
    {
      "epoch": 3.6677302850731093,
      "grad_norm": 0.6242477893829346,
      "learning_rate": 2.7086200699564306e-05,
      "loss": 0.0539,
      "step": 104600
    },
    {
      "epoch": 3.6712367193800626,
      "grad_norm": 0.4132763147354126,
      "learning_rate": 2.70642845245505e-05,
      "loss": 0.052,
      "step": 104700
    },
    {
      "epoch": 3.6747431536870154,
      "grad_norm": 0.35034799575805664,
      "learning_rate": 2.7042368349536697e-05,
      "loss": 0.0509,
      "step": 104800
    },
    {
      "epoch": 3.678249587993969,
      "grad_norm": 0.175595223903656,
      "learning_rate": 2.7020452174522887e-05,
      "loss": 0.0575,
      "step": 104900
    },
    {
      "epoch": 3.681756022300922,
      "grad_norm": 0.20303376019001007,
      "learning_rate": 2.6998535999509078e-05,
      "loss": 0.0554,
      "step": 105000
    },
    {
      "epoch": 3.6852624566078753,
      "grad_norm": 0.08060969412326813,
      "learning_rate": 2.6976619824495268e-05,
      "loss": 0.0535,
      "step": 105100
    },
    {
      "epoch": 3.6887688909148286,
      "grad_norm": 0.2870636582374573,
      "learning_rate": 2.6954922811231604e-05,
      "loss": 0.0524,
      "step": 105200
    },
    {
      "epoch": 3.692275325221782,
      "grad_norm": 0.19400224089622498,
      "learning_rate": 2.6933006636217794e-05,
      "loss": 0.0545,
      "step": 105300
    },
    {
      "epoch": 3.695781759528735,
      "grad_norm": 0.40364423394203186,
      "learning_rate": 2.6911090461203985e-05,
      "loss": 0.0529,
      "step": 105400
    },
    {
      "epoch": 3.6992881938356885,
      "grad_norm": 0.28022444248199463,
      "learning_rate": 2.6889174286190182e-05,
      "loss": 0.0541,
      "step": 105500
    },
    {
      "epoch": 3.702794628142642,
      "grad_norm": 0.22395512461662292,
      "learning_rate": 2.6867258111176376e-05,
      "loss": 0.0566,
      "step": 105600
    },
    {
      "epoch": 3.706301062449595,
      "grad_norm": 0.10477498173713684,
      "learning_rate": 2.6845341936162566e-05,
      "loss": 0.0551,
      "step": 105700
    },
    {
      "epoch": 3.7098074967565484,
      "grad_norm": 0.1441904455423355,
      "learning_rate": 2.6823425761148756e-05,
      "loss": 0.0532,
      "step": 105800
    },
    {
      "epoch": 3.7133139310635013,
      "grad_norm": 0.2281157374382019,
      "learning_rate": 2.6801509586134953e-05,
      "loss": 0.0507,
      "step": 105900
    },
    {
      "epoch": 3.716820365370455,
      "grad_norm": 0.32292115688323975,
      "learning_rate": 2.6779593411121147e-05,
      "loss": 0.0488,
      "step": 106000
    },
    {
      "epoch": 3.720326799677408,
      "grad_norm": 0.16556678712368011,
      "learning_rate": 2.6757677236107337e-05,
      "loss": 0.0538,
      "step": 106100
    },
    {
      "epoch": 3.723833233984361,
      "grad_norm": 0.2386036366224289,
      "learning_rate": 2.6735761061093528e-05,
      "loss": 0.0522,
      "step": 106200
    },
    {
      "epoch": 3.7273396682913145,
      "grad_norm": 0.4997158944606781,
      "learning_rate": 2.6713844886079725e-05,
      "loss": 0.0507,
      "step": 106300
    },
    {
      "epoch": 3.7308461025982678,
      "grad_norm": 0.1903078258037567,
      "learning_rate": 2.6691928711065915e-05,
      "loss": 0.0511,
      "step": 106400
    },
    {
      "epoch": 3.734352536905221,
      "grad_norm": 0.20758438110351562,
      "learning_rate": 2.667001253605211e-05,
      "loss": 0.057,
      "step": 106500
    },
    {
      "epoch": 3.7378589712121744,
      "grad_norm": 0.4849691390991211,
      "learning_rate": 2.66480963610383e-05,
      "loss": 0.05,
      "step": 106600
    },
    {
      "epoch": 3.7413654055191277,
      "grad_norm": 0.2721852958202362,
      "learning_rate": 2.6626180186024496e-05,
      "loss": 0.0513,
      "step": 106700
    },
    {
      "epoch": 3.744871839826081,
      "grad_norm": 0.16085399687290192,
      "learning_rate": 2.6604264011010687e-05,
      "loss": 0.0527,
      "step": 106800
    },
    {
      "epoch": 3.7483782741330343,
      "grad_norm": 0.18840041756629944,
      "learning_rate": 2.658234783599688e-05,
      "loss": 0.0557,
      "step": 106900
    },
    {
      "epoch": 3.751884708439987,
      "grad_norm": 0.3040807843208313,
      "learning_rate": 2.656043166098307e-05,
      "loss": 0.0501,
      "step": 107000
    },
    {
      "epoch": 3.755391142746941,
      "grad_norm": 0.18027299642562866,
      "learning_rate": 2.6538515485969268e-05,
      "loss": 0.0503,
      "step": 107100
    },
    {
      "epoch": 3.7588975770538937,
      "grad_norm": 0.14581388235092163,
      "learning_rate": 2.6516599310955458e-05,
      "loss": 0.0519,
      "step": 107200
    },
    {
      "epoch": 3.762404011360847,
      "grad_norm": 0.25704365968704224,
      "learning_rate": 2.6494902297691787e-05,
      "loss": 0.0502,
      "step": 107300
    },
    {
      "epoch": 3.7659104456678003,
      "grad_norm": 0.15290752053260803,
      "learning_rate": 2.6472986122677985e-05,
      "loss": 0.0495,
      "step": 107400
    },
    {
      "epoch": 3.7694168799747536,
      "grad_norm": 0.33478689193725586,
      "learning_rate": 2.6451069947664175e-05,
      "loss": 0.0549,
      "step": 107500
    },
    {
      "epoch": 3.772923314281707,
      "grad_norm": 0.25686582922935486,
      "learning_rate": 2.6429153772650365e-05,
      "loss": 0.0529,
      "step": 107600
    },
    {
      "epoch": 3.77642974858866,
      "grad_norm": 0.1574556976556778,
      "learning_rate": 2.640723759763656e-05,
      "loss": 0.0494,
      "step": 107700
    },
    {
      "epoch": 3.7799361828956135,
      "grad_norm": 0.17599651217460632,
      "learning_rate": 2.6385321422622756e-05,
      "loss": 0.0509,
      "step": 107800
    },
    {
      "epoch": 3.783442617202567,
      "grad_norm": 0.15645445883274078,
      "learning_rate": 2.6363624409359082e-05,
      "loss": 0.054,
      "step": 107900
    },
    {
      "epoch": 3.78694905150952,
      "grad_norm": 0.19749873876571655,
      "learning_rate": 2.6341708234345276e-05,
      "loss": 0.0514,
      "step": 108000
    },
    {
      "epoch": 3.790455485816473,
      "grad_norm": 0.08557219803333282,
      "learning_rate": 2.6319792059331473e-05,
      "loss": 0.053,
      "step": 108100
    },
    {
      "epoch": 3.7939619201234267,
      "grad_norm": 0.2228006273508072,
      "learning_rate": 2.6297875884317663e-05,
      "loss": 0.0517,
      "step": 108200
    },
    {
      "epoch": 3.7974683544303796,
      "grad_norm": 0.4493441581726074,
      "learning_rate": 2.6275959709303854e-05,
      "loss": 0.0572,
      "step": 108300
    },
    {
      "epoch": 3.800974788737333,
      "grad_norm": 0.20396801829338074,
      "learning_rate": 2.6254043534290047e-05,
      "loss": 0.0505,
      "step": 108400
    },
    {
      "epoch": 3.804481223044286,
      "grad_norm": 0.21600930392742157,
      "learning_rate": 2.6232127359276244e-05,
      "loss": 0.0522,
      "step": 108500
    },
    {
      "epoch": 3.8079876573512395,
      "grad_norm": 0.2459055781364441,
      "learning_rate": 2.6210211184262435e-05,
      "loss": 0.0489,
      "step": 108600
    },
    {
      "epoch": 3.8114940916581928,
      "grad_norm": 0.2373982071876526,
      "learning_rate": 2.6188295009248625e-05,
      "loss": 0.0577,
      "step": 108700
    },
    {
      "epoch": 3.815000525965146,
      "grad_norm": 0.09608986228704453,
      "learning_rate": 2.6166378834234822e-05,
      "loss": 0.0516,
      "step": 108800
    },
    {
      "epoch": 3.8185069602720993,
      "grad_norm": 0.2902975380420685,
      "learning_rate": 2.6144462659221012e-05,
      "loss": 0.0529,
      "step": 108900
    },
    {
      "epoch": 3.8220133945790526,
      "grad_norm": 0.20893166959285736,
      "learning_rate": 2.6122546484207206e-05,
      "loss": 0.055,
      "step": 109000
    },
    {
      "epoch": 3.825519828886006,
      "grad_norm": 0.32262009382247925,
      "learning_rate": 2.6100630309193396e-05,
      "loss": 0.0492,
      "step": 109100
    },
    {
      "epoch": 3.8290262631929592,
      "grad_norm": 0.2844160795211792,
      "learning_rate": 2.6078714134179594e-05,
      "loss": 0.0536,
      "step": 109200
    },
    {
      "epoch": 3.8325326974999125,
      "grad_norm": 0.07975447177886963,
      "learning_rate": 2.6056797959165784e-05,
      "loss": 0.0502,
      "step": 109300
    },
    {
      "epoch": 3.8360391318068654,
      "grad_norm": 0.19482381641864777,
      "learning_rate": 2.6034881784151978e-05,
      "loss": 0.0542,
      "step": 109400
    },
    {
      "epoch": 3.8395455661138187,
      "grad_norm": 0.19818738102912903,
      "learning_rate": 2.6012965609138168e-05,
      "loss": 0.0499,
      "step": 109500
    },
    {
      "epoch": 3.843052000420772,
      "grad_norm": 0.2810520827770233,
      "learning_rate": 2.5991049434124365e-05,
      "loss": 0.0514,
      "step": 109600
    },
    {
      "epoch": 3.8465584347277253,
      "grad_norm": 0.112139992415905,
      "learning_rate": 2.5969133259110555e-05,
      "loss": 0.0518,
      "step": 109700
    },
    {
      "epoch": 3.8500648690346786,
      "grad_norm": 0.1847657710313797,
      "learning_rate": 2.594721708409675e-05,
      "loss": 0.0536,
      "step": 109800
    },
    {
      "epoch": 3.853571303341632,
      "grad_norm": 0.12825922667980194,
      "learning_rate": 2.592530090908294e-05,
      "loss": 0.056,
      "step": 109900
    },
    {
      "epoch": 3.857077737648585,
      "grad_norm": 0.16977857053279877,
      "learning_rate": 2.5903384734069136e-05,
      "loss": 0.0504,
      "step": 110000
    },
    {
      "epoch": 3.8605841719555385,
      "grad_norm": 0.2561340630054474,
      "learning_rate": 2.5881468559055327e-05,
      "loss": 0.0582,
      "step": 110100
    },
    {
      "epoch": 3.864090606262492,
      "grad_norm": 0.37445393204689026,
      "learning_rate": 2.585955238404152e-05,
      "loss": 0.0533,
      "step": 110200
    },
    {
      "epoch": 3.867597040569445,
      "grad_norm": 0.2521142065525055,
      "learning_rate": 2.583763620902771e-05,
      "loss": 0.0508,
      "step": 110300
    },
    {
      "epoch": 3.8711034748763984,
      "grad_norm": 0.2369765192270279,
      "learning_rate": 2.5815720034013908e-05,
      "loss": 0.0591,
      "step": 110400
    },
    {
      "epoch": 3.8746099091833512,
      "grad_norm": 0.13419687747955322,
      "learning_rate": 2.5793803859000098e-05,
      "loss": 0.0518,
      "step": 110500
    },
    {
      "epoch": 3.878116343490305,
      "grad_norm": 0.28600049018859863,
      "learning_rate": 2.577188768398629e-05,
      "loss": 0.0502,
      "step": 110600
    },
    {
      "epoch": 3.881622777797258,
      "grad_norm": 0.43688228726387024,
      "learning_rate": 2.5749971508972482e-05,
      "loss": 0.0535,
      "step": 110700
    },
    {
      "epoch": 3.885129212104211,
      "grad_norm": 0.20337052643299103,
      "learning_rate": 2.572805533395868e-05,
      "loss": 0.0484,
      "step": 110800
    },
    {
      "epoch": 3.8886356464111644,
      "grad_norm": 0.34097057580947876,
      "learning_rate": 2.570613915894487e-05,
      "loss": 0.0484,
      "step": 110900
    },
    {
      "epoch": 3.8921420807181177,
      "grad_norm": 0.23402245342731476,
      "learning_rate": 2.568422298393106e-05,
      "loss": 0.0547,
      "step": 111000
    },
    {
      "epoch": 3.895648515025071,
      "grad_norm": 0.22296416759490967,
      "learning_rate": 2.5662306808917254e-05,
      "loss": 0.0518,
      "step": 111100
    },
    {
      "epoch": 3.8991549493320243,
      "grad_norm": 0.182483971118927,
      "learning_rate": 2.564039063390345e-05,
      "loss": 0.0508,
      "step": 111200
    },
    {
      "epoch": 3.9026613836389776,
      "grad_norm": 0.31294548511505127,
      "learning_rate": 2.561847445888964e-05,
      "loss": 0.054,
      "step": 111300
    },
    {
      "epoch": 3.906167817945931,
      "grad_norm": 0.1712195873260498,
      "learning_rate": 2.559655828387583e-05,
      "loss": 0.0498,
      "step": 111400
    },
    {
      "epoch": 3.9096742522528842,
      "grad_norm": 0.14045776426792145,
      "learning_rate": 2.5574642108862025e-05,
      "loss": 0.0502,
      "step": 111500
    },
    {
      "epoch": 3.913180686559837,
      "grad_norm": 0.3290093243122101,
      "learning_rate": 2.555272593384822e-05,
      "loss": 0.052,
      "step": 111600
    },
    {
      "epoch": 3.916687120866791,
      "grad_norm": 0.23886336386203766,
      "learning_rate": 2.5530809758834413e-05,
      "loss": 0.0499,
      "step": 111700
    },
    {
      "epoch": 3.9201935551737437,
      "grad_norm": 0.1082075908780098,
      "learning_rate": 2.5508893583820603e-05,
      "loss": 0.0538,
      "step": 111800
    },
    {
      "epoch": 3.923699989480697,
      "grad_norm": 0.16731873154640198,
      "learning_rate": 2.5487196570556936e-05,
      "loss": 0.052,
      "step": 111900
    },
    {
      "epoch": 3.9272064237876503,
      "grad_norm": 0.2822735905647278,
      "learning_rate": 2.546528039554313e-05,
      "loss": 0.0529,
      "step": 112000
    },
    {
      "epoch": 3.9307128580946036,
      "grad_norm": 0.09690946340560913,
      "learning_rate": 2.544336422052932e-05,
      "loss": 0.0526,
      "step": 112100
    },
    {
      "epoch": 3.934219292401557,
      "grad_norm": 0.29546859860420227,
      "learning_rate": 2.542144804551551e-05,
      "loss": 0.0486,
      "step": 112200
    },
    {
      "epoch": 3.93772572670851,
      "grad_norm": 0.09532716125249863,
      "learning_rate": 2.5399531870501707e-05,
      "loss": 0.055,
      "step": 112300
    },
    {
      "epoch": 3.9412321610154635,
      "grad_norm": 0.17296582460403442,
      "learning_rate": 2.53776156954879e-05,
      "loss": 0.0547,
      "step": 112400
    },
    {
      "epoch": 3.9447385953224168,
      "grad_norm": 0.190155491232872,
      "learning_rate": 2.535569952047409e-05,
      "loss": 0.0521,
      "step": 112500
    },
    {
      "epoch": 3.94824502962937,
      "grad_norm": 0.2138391137123108,
      "learning_rate": 2.533378334546028e-05,
      "loss": 0.0514,
      "step": 112600
    },
    {
      "epoch": 3.951751463936323,
      "grad_norm": 0.21146872639656067,
      "learning_rate": 2.531186717044648e-05,
      "loss": 0.0581,
      "step": 112700
    },
    {
      "epoch": 3.9552578982432767,
      "grad_norm": 0.1554904580116272,
      "learning_rate": 2.5289950995432672e-05,
      "loss": 0.0542,
      "step": 112800
    },
    {
      "epoch": 3.9587643325502295,
      "grad_norm": 0.2870425879955292,
      "learning_rate": 2.5268034820418863e-05,
      "loss": 0.051,
      "step": 112900
    },
    {
      "epoch": 3.962270766857183,
      "grad_norm": 0.2626183032989502,
      "learning_rate": 2.5246118645405053e-05,
      "loss": 0.0528,
      "step": 113000
    },
    {
      "epoch": 3.965777201164136,
      "grad_norm": 0.16924633085727692,
      "learning_rate": 2.522420247039125e-05,
      "loss": 0.0559,
      "step": 113100
    },
    {
      "epoch": 3.9692836354710894,
      "grad_norm": 0.3523000180721283,
      "learning_rate": 2.520228629537744e-05,
      "loss": 0.0528,
      "step": 113200
    },
    {
      "epoch": 3.9727900697780427,
      "grad_norm": 0.2294044941663742,
      "learning_rate": 2.5180370120363634e-05,
      "loss": 0.0509,
      "step": 113300
    },
    {
      "epoch": 3.976296504084996,
      "grad_norm": 0.22592711448669434,
      "learning_rate": 2.5158453945349824e-05,
      "loss": 0.0547,
      "step": 113400
    },
    {
      "epoch": 3.9798029383919493,
      "grad_norm": 0.10945861786603928,
      "learning_rate": 2.513653777033602e-05,
      "loss": 0.053,
      "step": 113500
    },
    {
      "epoch": 3.9833093726989026,
      "grad_norm": 0.20749342441558838,
      "learning_rate": 2.5114621595322212e-05,
      "loss": 0.048,
      "step": 113600
    },
    {
      "epoch": 3.986815807005856,
      "grad_norm": 0.25791674852371216,
      "learning_rate": 2.5092705420308406e-05,
      "loss": 0.0482,
      "step": 113700
    },
    {
      "epoch": 3.9903222413128088,
      "grad_norm": 0.11380579322576523,
      "learning_rate": 2.5070789245294596e-05,
      "loss": 0.0503,
      "step": 113800
    },
    {
      "epoch": 3.9938286756197625,
      "grad_norm": 0.0916447713971138,
      "learning_rate": 2.5048873070280793e-05,
      "loss": 0.0496,
      "step": 113900
    },
    {
      "epoch": 3.9973351099267154,
      "grad_norm": 0.23637819290161133,
      "learning_rate": 2.5026956895266983e-05,
      "loss": 0.0529,
      "step": 114000
    },
    {
      "epoch": 4.0,
      "eval_accuracy_macro_0.5": 0.9784911274909973,
      "eval_accuracy_micro_0.5": 0.9784911274909973,
      "eval_accuracy_weighted_0.5": 0.9678143262863159,
      "eval_f1_macro_0.5": 0.6673071980476379,
      "eval_f1_macro_0.6": 0.6363932490348816,
      "eval_f1_macro_0.7": 0.5876070261001587,
      "eval_f1_macro_0.8": 0.38565951585769653,
      "eval_f1_micro_0.5": 0.7121846675872803,
      "eval_f1_micro_0.6": 0.6912891864776611,
      "eval_f1_micro_0.7": 0.651417076587677,
      "eval_f1_micro_0.8": 0.5841028094291687,
      "eval_f1_micro_0.9": 0.44489753246307373,
      "eval_f1_weighted_0.5": 0.7012015581130981,
      "eval_f1_weighted_0.6": 0.6736695766448975,
      "eval_f1_weighted_0.7": 0.6256811618804932,
      "eval_f1_weighted_0.8": 0.4064542055130005,
      "eval_loss": 0.0491316132247448,
      "eval_runtime": 144.2435,
      "eval_samples_per_second": 395.214,
      "eval_steps_per_second": 49.403,
      "step": 114076
    },
    {
      "epoch": 4.000841544233669,
      "grad_norm": 0.19203004240989685,
      "learning_rate": 2.5005259882003313e-05,
      "loss": 0.0467,
      "step": 114100
    },
    {
      "epoch": 4.004347978540622,
      "grad_norm": 0.18813969194889069,
      "learning_rate": 2.4983343706989507e-05,
      "loss": 0.0533,
      "step": 114200
    },
    {
      "epoch": 4.007854412847576,
      "grad_norm": 0.2349877655506134,
      "learning_rate": 2.49614275319757e-05,
      "loss": 0.05,
      "step": 114300
    },
    {
      "epoch": 4.011360847154529,
      "grad_norm": 0.336678683757782,
      "learning_rate": 2.4939730518712033e-05,
      "loss": 0.0553,
      "step": 114400
    },
    {
      "epoch": 4.014867281461481,
      "grad_norm": 0.1992228478193283,
      "learning_rate": 2.4917814343698223e-05,
      "loss": 0.0525,
      "step": 114500
    },
    {
      "epoch": 4.018373715768435,
      "grad_norm": 0.12754122912883759,
      "learning_rate": 2.4895898168684417e-05,
      "loss": 0.0458,
      "step": 114600
    },
    {
      "epoch": 4.021880150075388,
      "grad_norm": 0.12641046941280365,
      "learning_rate": 2.4873981993670607e-05,
      "loss": 0.049,
      "step": 114700
    },
    {
      "epoch": 4.025386584382342,
      "grad_norm": 0.15944091975688934,
      "learning_rate": 2.4852065818656805e-05,
      "loss": 0.0517,
      "step": 114800
    },
    {
      "epoch": 4.028893018689295,
      "grad_norm": 0.48665955662727356,
      "learning_rate": 2.4830149643642995e-05,
      "loss": 0.0493,
      "step": 114900
    },
    {
      "epoch": 4.032399452996248,
      "grad_norm": 0.3113281726837158,
      "learning_rate": 2.480823346862919e-05,
      "loss": 0.0563,
      "step": 115000
    },
    {
      "epoch": 4.035905887303201,
      "grad_norm": 0.28527188301086426,
      "learning_rate": 2.478631729361538e-05,
      "loss": 0.0481,
      "step": 115100
    },
    {
      "epoch": 4.039412321610155,
      "grad_norm": 0.21766521036624908,
      "learning_rate": 2.4764401118601573e-05,
      "loss": 0.0506,
      "step": 115200
    },
    {
      "epoch": 4.042918755917108,
      "grad_norm": 0.08352335542440414,
      "learning_rate": 2.4742484943587766e-05,
      "loss": 0.0514,
      "step": 115300
    },
    {
      "epoch": 4.0464251902240616,
      "grad_norm": 0.13439634442329407,
      "learning_rate": 2.472056876857396e-05,
      "loss": 0.0529,
      "step": 115400
    },
    {
      "epoch": 4.049931624531014,
      "grad_norm": 0.13899685442447662,
      "learning_rate": 2.469865259356015e-05,
      "loss": 0.0491,
      "step": 115500
    },
    {
      "epoch": 4.053438058837967,
      "grad_norm": 0.36607825756073,
      "learning_rate": 2.4676736418546344e-05,
      "loss": 0.0528,
      "step": 115600
    },
    {
      "epoch": 4.056944493144921,
      "grad_norm": 0.28524985909461975,
      "learning_rate": 2.4654820243532538e-05,
      "loss": 0.0484,
      "step": 115700
    },
    {
      "epoch": 4.060450927451874,
      "grad_norm": 0.1602383852005005,
      "learning_rate": 2.463290406851873e-05,
      "loss": 0.0508,
      "step": 115800
    },
    {
      "epoch": 4.063957361758828,
      "grad_norm": 0.12815701961517334,
      "learning_rate": 2.4610987893504925e-05,
      "loss": 0.0515,
      "step": 115900
    },
    {
      "epoch": 4.0674637960657805,
      "grad_norm": 0.24525433778762817,
      "learning_rate": 2.4589071718491116e-05,
      "loss": 0.049,
      "step": 116000
    },
    {
      "epoch": 4.070970230372734,
      "grad_norm": 0.17726898193359375,
      "learning_rate": 2.456715554347731e-05,
      "loss": 0.0507,
      "step": 116100
    },
    {
      "epoch": 4.074476664679687,
      "grad_norm": 0.12470261007547379,
      "learning_rate": 2.4545239368463503e-05,
      "loss": 0.0544,
      "step": 116200
    },
    {
      "epoch": 4.077983098986641,
      "grad_norm": 0.1815735548734665,
      "learning_rate": 2.4523323193449697e-05,
      "loss": 0.0519,
      "step": 116300
    },
    {
      "epoch": 4.081489533293594,
      "grad_norm": 0.10307080298662186,
      "learning_rate": 2.4501407018435887e-05,
      "loss": 0.0531,
      "step": 116400
    },
    {
      "epoch": 4.084995967600547,
      "grad_norm": 0.29796773195266724,
      "learning_rate": 2.447949084342208e-05,
      "loss": 0.0507,
      "step": 116500
    },
    {
      "epoch": 4.0885024019075,
      "grad_norm": 0.18683874607086182,
      "learning_rate": 2.4457574668408274e-05,
      "loss": 0.0507,
      "step": 116600
    },
    {
      "epoch": 4.092008836214453,
      "grad_norm": 0.30713748931884766,
      "learning_rate": 2.4435658493394468e-05,
      "loss": 0.0527,
      "step": 116700
    },
    {
      "epoch": 4.095515270521407,
      "grad_norm": 0.21825428307056427,
      "learning_rate": 2.441374231838066e-05,
      "loss": 0.0533,
      "step": 116800
    },
    {
      "epoch": 4.09902170482836,
      "grad_norm": 0.09565236419439316,
      "learning_rate": 2.4391826143366852e-05,
      "loss": 0.0552,
      "step": 116900
    },
    {
      "epoch": 4.1025281391353134,
      "grad_norm": 0.12221704423427582,
      "learning_rate": 2.4369909968353042e-05,
      "loss": 0.0536,
      "step": 117000
    },
    {
      "epoch": 4.106034573442266,
      "grad_norm": 0.18722200393676758,
      "learning_rate": 2.434799379333924e-05,
      "loss": 0.0521,
      "step": 117100
    },
    {
      "epoch": 4.10954100774922,
      "grad_norm": 0.20679953694343567,
      "learning_rate": 2.432607761832543e-05,
      "loss": 0.0515,
      "step": 117200
    },
    {
      "epoch": 4.113047442056173,
      "grad_norm": 0.11349241435527802,
      "learning_rate": 2.4304161443311624e-05,
      "loss": 0.051,
      "step": 117300
    },
    {
      "epoch": 4.116553876363127,
      "grad_norm": 0.22767572104930878,
      "learning_rate": 2.4282245268297814e-05,
      "loss": 0.055,
      "step": 117400
    },
    {
      "epoch": 4.1200603106700795,
      "grad_norm": 0.16821083426475525,
      "learning_rate": 2.426032909328401e-05,
      "loss": 0.0494,
      "step": 117500
    },
    {
      "epoch": 4.123566744977033,
      "grad_norm": 0.20340992510318756,
      "learning_rate": 2.42384129182702e-05,
      "loss": 0.05,
      "step": 117600
    },
    {
      "epoch": 4.127073179283986,
      "grad_norm": 0.19612786173820496,
      "learning_rate": 2.4216496743256395e-05,
      "loss": 0.0494,
      "step": 117700
    },
    {
      "epoch": 4.130579613590939,
      "grad_norm": 0.2535971403121948,
      "learning_rate": 2.4194580568242585e-05,
      "loss": 0.0492,
      "step": 117800
    },
    {
      "epoch": 4.134086047897893,
      "grad_norm": 0.3563092052936554,
      "learning_rate": 2.417266439322878e-05,
      "loss": 0.0551,
      "step": 117900
    },
    {
      "epoch": 4.1375924822048455,
      "grad_norm": 0.3393876850605011,
      "learning_rate": 2.4150748218214973e-05,
      "loss": 0.05,
      "step": 118000
    },
    {
      "epoch": 4.141098916511799,
      "grad_norm": 0.1558694690465927,
      "learning_rate": 2.4128832043201167e-05,
      "loss": 0.0498,
      "step": 118100
    },
    {
      "epoch": 4.144605350818752,
      "grad_norm": 0.10016640275716782,
      "learning_rate": 2.4106915868187357e-05,
      "loss": 0.0509,
      "step": 118200
    },
    {
      "epoch": 4.148111785125706,
      "grad_norm": 0.15353642404079437,
      "learning_rate": 2.408499969317355e-05,
      "loss": 0.053,
      "step": 118300
    },
    {
      "epoch": 4.151618219432659,
      "grad_norm": 0.07154901325702667,
      "learning_rate": 2.4063083518159744e-05,
      "loss": 0.0536,
      "step": 118400
    },
    {
      "epoch": 4.1551246537396125,
      "grad_norm": 0.3359544575214386,
      "learning_rate": 2.4041386504896074e-05,
      "loss": 0.0572,
      "step": 118500
    },
    {
      "epoch": 4.158631088046565,
      "grad_norm": 0.10921796411275864,
      "learning_rate": 2.4019470329882267e-05,
      "loss": 0.0514,
      "step": 118600
    },
    {
      "epoch": 4.162137522353519,
      "grad_norm": 0.19997362792491913,
      "learning_rate": 2.399755415486846e-05,
      "loss": 0.056,
      "step": 118700
    },
    {
      "epoch": 4.165643956660472,
      "grad_norm": 0.5826276540756226,
      "learning_rate": 2.3975637979854655e-05,
      "loss": 0.0533,
      "step": 118800
    },
    {
      "epoch": 4.169150390967426,
      "grad_norm": 0.10363531112670898,
      "learning_rate": 2.3953721804840845e-05,
      "loss": 0.0543,
      "step": 118900
    },
    {
      "epoch": 4.1726568252743785,
      "grad_norm": 0.2986721992492676,
      "learning_rate": 2.393180562982704e-05,
      "loss": 0.0526,
      "step": 119000
    },
    {
      "epoch": 4.176163259581331,
      "grad_norm": 0.2870430648326874,
      "learning_rate": 2.390988945481323e-05,
      "loss": 0.052,
      "step": 119100
    },
    {
      "epoch": 4.179669693888285,
      "grad_norm": 0.24651944637298584,
      "learning_rate": 2.3887973279799426e-05,
      "loss": 0.0532,
      "step": 119200
    },
    {
      "epoch": 4.183176128195238,
      "grad_norm": 0.10743948072195053,
      "learning_rate": 2.3866057104785617e-05,
      "loss": 0.0543,
      "step": 119300
    },
    {
      "epoch": 4.186682562502192,
      "grad_norm": 0.2707218527793884,
      "learning_rate": 2.384414092977181e-05,
      "loss": 0.0523,
      "step": 119400
    },
    {
      "epoch": 4.190188996809145,
      "grad_norm": 0.13831576704978943,
      "learning_rate": 2.3822224754758e-05,
      "loss": 0.0496,
      "step": 119500
    },
    {
      "epoch": 4.193695431116098,
      "grad_norm": 0.10397820174694061,
      "learning_rate": 2.3800308579744194e-05,
      "loss": 0.0562,
      "step": 119600
    },
    {
      "epoch": 4.197201865423051,
      "grad_norm": 0.20546123385429382,
      "learning_rate": 2.3778392404730388e-05,
      "loss": 0.0567,
      "step": 119700
    },
    {
      "epoch": 4.200708299730005,
      "grad_norm": 0.1616349071264267,
      "learning_rate": 2.3756476229716582e-05,
      "loss": 0.0582,
      "step": 119800
    },
    {
      "epoch": 4.204214734036958,
      "grad_norm": 0.10870260745286942,
      "learning_rate": 2.3734560054702772e-05,
      "loss": 0.0497,
      "step": 119900
    },
    {
      "epoch": 4.207721168343911,
      "grad_norm": 0.16427496075630188,
      "learning_rate": 2.3712643879688966e-05,
      "loss": 0.0539,
      "step": 120000
    },
    {
      "epoch": 4.211227602650864,
      "grad_norm": 0.11532078683376312,
      "learning_rate": 2.369072770467516e-05,
      "loss": 0.05,
      "step": 120100
    },
    {
      "epoch": 4.214734036957817,
      "grad_norm": 0.07966145873069763,
      "learning_rate": 2.3668811529661353e-05,
      "loss": 0.0492,
      "step": 120200
    },
    {
      "epoch": 4.218240471264771,
      "grad_norm": 0.19408808648586273,
      "learning_rate": 2.3646895354647544e-05,
      "loss": 0.0481,
      "step": 120300
    },
    {
      "epoch": 4.221746905571724,
      "grad_norm": 0.17122235894203186,
      "learning_rate": 2.3624979179633737e-05,
      "loss": 0.0525,
      "step": 120400
    },
    {
      "epoch": 4.225253339878678,
      "grad_norm": 0.18332669138908386,
      "learning_rate": 2.360306300461993e-05,
      "loss": 0.054,
      "step": 120500
    },
    {
      "epoch": 4.22875977418563,
      "grad_norm": 0.13415177166461945,
      "learning_rate": 2.3581146829606125e-05,
      "loss": 0.0486,
      "step": 120600
    },
    {
      "epoch": 4.232266208492584,
      "grad_norm": 0.2877677083015442,
      "learning_rate": 2.3559230654592315e-05,
      "loss": 0.0505,
      "step": 120700
    },
    {
      "epoch": 4.235772642799537,
      "grad_norm": 0.205472931265831,
      "learning_rate": 2.3537533641328648e-05,
      "loss": 0.0516,
      "step": 120800
    },
    {
      "epoch": 4.239279077106491,
      "grad_norm": 0.14352859556674957,
      "learning_rate": 2.351561746631484e-05,
      "loss": 0.0529,
      "step": 120900
    },
    {
      "epoch": 4.242785511413444,
      "grad_norm": 0.21002322435379028,
      "learning_rate": 2.3493701291301032e-05,
      "loss": 0.0503,
      "step": 121000
    },
    {
      "epoch": 4.246291945720397,
      "grad_norm": 0.25841012597084045,
      "learning_rate": 2.3471785116287226e-05,
      "loss": 0.0493,
      "step": 121100
    },
    {
      "epoch": 4.24979838002735,
      "grad_norm": 0.2567605972290039,
      "learning_rate": 2.3449868941273416e-05,
      "loss": 0.0513,
      "step": 121200
    },
    {
      "epoch": 4.253304814334303,
      "grad_norm": 0.35257840156555176,
      "learning_rate": 2.3427952766259613e-05,
      "loss": 0.0535,
      "step": 121300
    },
    {
      "epoch": 4.256811248641257,
      "grad_norm": 0.17973290383815765,
      "learning_rate": 2.3406036591245803e-05,
      "loss": 0.0538,
      "step": 121400
    },
    {
      "epoch": 4.26031768294821,
      "grad_norm": 0.17367549240589142,
      "learning_rate": 2.3384120416231997e-05,
      "loss": 0.0472,
      "step": 121500
    },
    {
      "epoch": 4.263824117255163,
      "grad_norm": 0.18878549337387085,
      "learning_rate": 2.3362204241218187e-05,
      "loss": 0.0483,
      "step": 121600
    },
    {
      "epoch": 4.267330551562116,
      "grad_norm": 0.26029279828071594,
      "learning_rate": 2.334028806620438e-05,
      "loss": 0.0539,
      "step": 121700
    },
    {
      "epoch": 4.27083698586907,
      "grad_norm": 0.10938757658004761,
      "learning_rate": 2.3318371891190575e-05,
      "loss": 0.052,
      "step": 121800
    },
    {
      "epoch": 4.274343420176023,
      "grad_norm": 0.34394407272338867,
      "learning_rate": 2.329645571617677e-05,
      "loss": 0.0514,
      "step": 121900
    },
    {
      "epoch": 4.277849854482977,
      "grad_norm": 0.08702755719423294,
      "learning_rate": 2.327453954116296e-05,
      "loss": 0.0513,
      "step": 122000
    },
    {
      "epoch": 4.2813562887899295,
      "grad_norm": 0.17752337455749512,
      "learning_rate": 2.3252623366149153e-05,
      "loss": 0.051,
      "step": 122100
    },
    {
      "epoch": 4.284862723096882,
      "grad_norm": 0.18064634501934052,
      "learning_rate": 2.323070719113535e-05,
      "loss": 0.0536,
      "step": 122200
    },
    {
      "epoch": 4.288369157403836,
      "grad_norm": 0.15518106520175934,
      "learning_rate": 2.320879101612154e-05,
      "loss": 0.0558,
      "step": 122300
    },
    {
      "epoch": 4.291875591710789,
      "grad_norm": 0.1899852603673935,
      "learning_rate": 2.3186874841107734e-05,
      "loss": 0.051,
      "step": 122400
    },
    {
      "epoch": 4.295382026017743,
      "grad_norm": 0.18200790882110596,
      "learning_rate": 2.3164958666093924e-05,
      "loss": 0.0493,
      "step": 122500
    },
    {
      "epoch": 4.2988884603246955,
      "grad_norm": 0.10582305490970612,
      "learning_rate": 2.3143042491080118e-05,
      "loss": 0.0536,
      "step": 122600
    },
    {
      "epoch": 4.302394894631649,
      "grad_norm": 0.219086155295372,
      "learning_rate": 2.312112631606631e-05,
      "loss": 0.0555,
      "step": 122700
    },
    {
      "epoch": 4.305901328938602,
      "grad_norm": 0.1779971420764923,
      "learning_rate": 2.3099210141052505e-05,
      "loss": 0.0522,
      "step": 122800
    },
    {
      "epoch": 4.309407763245556,
      "grad_norm": 0.12051630020141602,
      "learning_rate": 2.3077293966038695e-05,
      "loss": 0.0532,
      "step": 122900
    },
    {
      "epoch": 4.312914197552509,
      "grad_norm": 0.08090346306562424,
      "learning_rate": 2.3055596952775028e-05,
      "loss": 0.052,
      "step": 123000
    },
    {
      "epoch": 4.3164206318594625,
      "grad_norm": 0.17591364681720734,
      "learning_rate": 2.3033680777761222e-05,
      "loss": 0.0508,
      "step": 123100
    },
    {
      "epoch": 4.319927066166415,
      "grad_norm": 0.2094491422176361,
      "learning_rate": 2.3011764602747412e-05,
      "loss": 0.0494,
      "step": 123200
    },
    {
      "epoch": 4.323433500473369,
      "grad_norm": 0.1832021027803421,
      "learning_rate": 2.2989848427733606e-05,
      "loss": 0.0545,
      "step": 123300
    },
    {
      "epoch": 4.326939934780322,
      "grad_norm": 0.2226155400276184,
      "learning_rate": 2.29679322527198e-05,
      "loss": 0.0513,
      "step": 123400
    },
    {
      "epoch": 4.330446369087275,
      "grad_norm": 0.2906178832054138,
      "learning_rate": 2.2946016077705993e-05,
      "loss": 0.0539,
      "step": 123500
    },
    {
      "epoch": 4.3339528033942285,
      "grad_norm": 0.1995602697134018,
      "learning_rate": 2.2924099902692184e-05,
      "loss": 0.0524,
      "step": 123600
    },
    {
      "epoch": 4.337459237701181,
      "grad_norm": 0.09927454590797424,
      "learning_rate": 2.2902183727678377e-05,
      "loss": 0.0499,
      "step": 123700
    },
    {
      "epoch": 4.340965672008135,
      "grad_norm": 0.1208462044596672,
      "learning_rate": 2.2880267552664568e-05,
      "loss": 0.0544,
      "step": 123800
    },
    {
      "epoch": 4.344472106315088,
      "grad_norm": 0.3151985704898834,
      "learning_rate": 2.2858351377650765e-05,
      "loss": 0.052,
      "step": 123900
    },
    {
      "epoch": 4.347978540622042,
      "grad_norm": 0.288523405790329,
      "learning_rate": 2.2836435202636955e-05,
      "loss": 0.0519,
      "step": 124000
    },
    {
      "epoch": 4.3514849749289946,
      "grad_norm": 0.13158190250396729,
      "learning_rate": 2.281451902762315e-05,
      "loss": 0.0522,
      "step": 124100
    },
    {
      "epoch": 4.354991409235948,
      "grad_norm": 0.1776343286037445,
      "learning_rate": 2.279260285260934e-05,
      "loss": 0.0522,
      "step": 124200
    },
    {
      "epoch": 4.358497843542901,
      "grad_norm": 0.17073211073875427,
      "learning_rate": 2.2770686677595533e-05,
      "loss": 0.0497,
      "step": 124300
    },
    {
      "epoch": 4.362004277849855,
      "grad_norm": 0.14121952652931213,
      "learning_rate": 2.2748770502581727e-05,
      "loss": 0.0526,
      "step": 124400
    },
    {
      "epoch": 4.365510712156808,
      "grad_norm": 0.1705356240272522,
      "learning_rate": 2.272685432756792e-05,
      "loss": 0.0495,
      "step": 124500
    },
    {
      "epoch": 4.369017146463761,
      "grad_norm": 0.2560019791126251,
      "learning_rate": 2.270493815255411e-05,
      "loss": 0.0503,
      "step": 124600
    },
    {
      "epoch": 4.372523580770714,
      "grad_norm": 0.2177586853504181,
      "learning_rate": 2.2683021977540304e-05,
      "loss": 0.0561,
      "step": 124700
    },
    {
      "epoch": 4.376030015077667,
      "grad_norm": 0.2661334276199341,
      "learning_rate": 2.2661105802526498e-05,
      "loss": 0.055,
      "step": 124800
    },
    {
      "epoch": 4.379536449384621,
      "grad_norm": 0.2941875755786896,
      "learning_rate": 2.2639189627512692e-05,
      "loss": 0.0518,
      "step": 124900
    },
    {
      "epoch": 4.383042883691574,
      "grad_norm": 0.08479566127061844,
      "learning_rate": 2.261749261424902e-05,
      "loss": 0.0553,
      "step": 125000
    },
    {
      "epoch": 4.3865493179985275,
      "grad_norm": 0.24573218822479248,
      "learning_rate": 2.2595576439235215e-05,
      "loss": 0.0489,
      "step": 125100
    },
    {
      "epoch": 4.39005575230548,
      "grad_norm": 0.3352763056755066,
      "learning_rate": 2.257366026422141e-05,
      "loss": 0.0546,
      "step": 125200
    },
    {
      "epoch": 4.393562186612434,
      "grad_norm": 0.15607602894306183,
      "learning_rate": 2.25517440892076e-05,
      "loss": 0.0504,
      "step": 125300
    },
    {
      "epoch": 4.397068620919387,
      "grad_norm": 0.29644033312797546,
      "learning_rate": 2.2529827914193793e-05,
      "loss": 0.0505,
      "step": 125400
    },
    {
      "epoch": 4.400575055226341,
      "grad_norm": 0.28482237458229065,
      "learning_rate": 2.2507911739179986e-05,
      "loss": 0.0487,
      "step": 125500
    },
    {
      "epoch": 4.404081489533294,
      "grad_norm": 0.09073356539011002,
      "learning_rate": 2.248599556416618e-05,
      "loss": 0.0544,
      "step": 125600
    },
    {
      "epoch": 4.4075879238402464,
      "grad_norm": 0.406471848487854,
      "learning_rate": 2.246407938915237e-05,
      "loss": 0.0528,
      "step": 125700
    },
    {
      "epoch": 4.4110943581472,
      "grad_norm": 0.18283049762248993,
      "learning_rate": 2.2442163214138564e-05,
      "loss": 0.0565,
      "step": 125800
    },
    {
      "epoch": 4.414600792454153,
      "grad_norm": 0.10946981608867645,
      "learning_rate": 2.2420247039124755e-05,
      "loss": 0.051,
      "step": 125900
    },
    {
      "epoch": 4.418107226761107,
      "grad_norm": 0.31323766708374023,
      "learning_rate": 2.239833086411095e-05,
      "loss": 0.0529,
      "step": 126000
    },
    {
      "epoch": 4.42161366106806,
      "grad_norm": 0.2746334671974182,
      "learning_rate": 2.2376414689097142e-05,
      "loss": 0.0528,
      "step": 126100
    },
    {
      "epoch": 4.425120095375013,
      "grad_norm": 0.32299351692199707,
      "learning_rate": 2.2354498514083336e-05,
      "loss": 0.0521,
      "step": 126200
    },
    {
      "epoch": 4.428626529681966,
      "grad_norm": 0.16666147112846375,
      "learning_rate": 2.2332582339069526e-05,
      "loss": 0.0514,
      "step": 126300
    },
    {
      "epoch": 4.43213296398892,
      "grad_norm": 0.08766883611679077,
      "learning_rate": 2.231066616405572e-05,
      "loss": 0.0479,
      "step": 126400
    },
    {
      "epoch": 4.435639398295873,
      "grad_norm": 0.27062615752220154,
      "learning_rate": 2.2288749989041913e-05,
      "loss": 0.0531,
      "step": 126500
    },
    {
      "epoch": 4.439145832602827,
      "grad_norm": 0.08357902616262436,
      "learning_rate": 2.2266833814028107e-05,
      "loss": 0.0549,
      "step": 126600
    },
    {
      "epoch": 4.442652266909779,
      "grad_norm": 0.19504611194133759,
      "learning_rate": 2.2244917639014297e-05,
      "loss": 0.0525,
      "step": 126700
    },
    {
      "epoch": 4.446158701216732,
      "grad_norm": 0.12806196510791779,
      "learning_rate": 2.222300146400049e-05,
      "loss": 0.0522,
      "step": 126800
    },
    {
      "epoch": 4.449665135523686,
      "grad_norm": 0.11876972019672394,
      "learning_rate": 2.2201085288986685e-05,
      "loss": 0.0488,
      "step": 126900
    },
    {
      "epoch": 4.453171569830639,
      "grad_norm": 0.13561297953128815,
      "learning_rate": 2.217916911397288e-05,
      "loss": 0.0515,
      "step": 127000
    },
    {
      "epoch": 4.456678004137593,
      "grad_norm": 0.27823886275291443,
      "learning_rate": 2.2157472100709208e-05,
      "loss": 0.0478,
      "step": 127100
    },
    {
      "epoch": 4.4601844384445455,
      "grad_norm": 0.06290340423583984,
      "learning_rate": 2.2135555925695402e-05,
      "loss": 0.0498,
      "step": 127200
    },
    {
      "epoch": 4.463690872751499,
      "grad_norm": 0.1881018728017807,
      "learning_rate": 2.2113639750681595e-05,
      "loss": 0.0477,
      "step": 127300
    },
    {
      "epoch": 4.467197307058452,
      "grad_norm": 0.18219566345214844,
      "learning_rate": 2.2091723575667786e-05,
      "loss": 0.0526,
      "step": 127400
    },
    {
      "epoch": 4.470703741365406,
      "grad_norm": 0.24051454663276672,
      "learning_rate": 2.206980740065398e-05,
      "loss": 0.0508,
      "step": 127500
    },
    {
      "epoch": 4.474210175672359,
      "grad_norm": 0.12756550312042236,
      "learning_rate": 2.2047891225640173e-05,
      "loss": 0.0552,
      "step": 127600
    },
    {
      "epoch": 4.477716609979312,
      "grad_norm": 0.14430058002471924,
      "learning_rate": 2.2025975050626367e-05,
      "loss": 0.0527,
      "step": 127700
    },
    {
      "epoch": 4.481223044286265,
      "grad_norm": 0.08650098741054535,
      "learning_rate": 2.2004058875612557e-05,
      "loss": 0.0496,
      "step": 127800
    },
    {
      "epoch": 4.484729478593218,
      "grad_norm": 0.13708925247192383,
      "learning_rate": 2.198214270059875e-05,
      "loss": 0.0489,
      "step": 127900
    },
    {
      "epoch": 4.488235912900172,
      "grad_norm": 0.2238159030675888,
      "learning_rate": 2.196022652558494e-05,
      "loss": 0.0507,
      "step": 128000
    },
    {
      "epoch": 4.491742347207125,
      "grad_norm": 0.21100762486457825,
      "learning_rate": 2.193831035057114e-05,
      "loss": 0.0496,
      "step": 128100
    },
    {
      "epoch": 4.4952487815140785,
      "grad_norm": 0.15661850571632385,
      "learning_rate": 2.191639417555733e-05,
      "loss": 0.0499,
      "step": 128200
    },
    {
      "epoch": 4.498755215821031,
      "grad_norm": 0.13114672899246216,
      "learning_rate": 2.1894478000543522e-05,
      "loss": 0.0566,
      "step": 128300
    },
    {
      "epoch": 4.502261650127985,
      "grad_norm": 0.26463061571121216,
      "learning_rate": 2.1872561825529713e-05,
      "loss": 0.05,
      "step": 128400
    },
    {
      "epoch": 4.505768084434938,
      "grad_norm": 0.19072940945625305,
      "learning_rate": 2.1850645650515906e-05,
      "loss": 0.0508,
      "step": 128500
    },
    {
      "epoch": 4.509274518741892,
      "grad_norm": 0.19924196600914001,
      "learning_rate": 2.18287294755021e-05,
      "loss": 0.0538,
      "step": 128600
    },
    {
      "epoch": 4.5127809530488445,
      "grad_norm": 0.27962228655815125,
      "learning_rate": 2.1806813300488294e-05,
      "loss": 0.0577,
      "step": 128700
    },
    {
      "epoch": 4.516287387355798,
      "grad_norm": 0.22248578071594238,
      "learning_rate": 2.1784897125474484e-05,
      "loss": 0.0469,
      "step": 128800
    },
    {
      "epoch": 4.519793821662751,
      "grad_norm": 0.36346808075904846,
      "learning_rate": 2.1762980950460678e-05,
      "loss": 0.0512,
      "step": 128900
    },
    {
      "epoch": 4.523300255969705,
      "grad_norm": 0.10647062212228775,
      "learning_rate": 2.174106477544687e-05,
      "loss": 0.0539,
      "step": 129000
    },
    {
      "epoch": 4.526806690276658,
      "grad_norm": 0.23453044891357422,
      "learning_rate": 2.17193677621832e-05,
      "loss": 0.054,
      "step": 129100
    },
    {
      "epoch": 4.530313124583611,
      "grad_norm": 0.2789987027645111,
      "learning_rate": 2.1697451587169395e-05,
      "loss": 0.0516,
      "step": 129200
    },
    {
      "epoch": 4.533819558890564,
      "grad_norm": 0.14750871062278748,
      "learning_rate": 2.167553541215559e-05,
      "loss": 0.0497,
      "step": 129300
    },
    {
      "epoch": 4.537325993197517,
      "grad_norm": 0.16111449897289276,
      "learning_rate": 2.1653619237141782e-05,
      "loss": 0.0497,
      "step": 129400
    },
    {
      "epoch": 4.540832427504471,
      "grad_norm": 0.12541218101978302,
      "learning_rate": 2.1631703062127973e-05,
      "loss": 0.0508,
      "step": 129500
    },
    {
      "epoch": 4.544338861811424,
      "grad_norm": 0.14589083194732666,
      "learning_rate": 2.1609786887114166e-05,
      "loss": 0.0495,
      "step": 129600
    },
    {
      "epoch": 4.5478452961183775,
      "grad_norm": 0.20014725625514984,
      "learning_rate": 2.158787071210036e-05,
      "loss": 0.0493,
      "step": 129700
    },
    {
      "epoch": 4.55135173042533,
      "grad_norm": 0.2793368101119995,
      "learning_rate": 2.1565954537086554e-05,
      "loss": 0.057,
      "step": 129800
    },
    {
      "epoch": 4.554858164732284,
      "grad_norm": 0.14652115106582642,
      "learning_rate": 2.1544038362072747e-05,
      "loss": 0.0543,
      "step": 129900
    },
    {
      "epoch": 4.558364599039237,
      "grad_norm": 0.20132093131542206,
      "learning_rate": 2.1522122187058938e-05,
      "loss": 0.05,
      "step": 130000
    },
    {
      "epoch": 4.56187103334619,
      "grad_norm": 0.2646749019622803,
      "learning_rate": 2.150020601204513e-05,
      "loss": 0.0526,
      "step": 130100
    },
    {
      "epoch": 4.565377467653144,
      "grad_norm": 0.08225622028112411,
      "learning_rate": 2.1478289837031325e-05,
      "loss": 0.0525,
      "step": 130200
    },
    {
      "epoch": 4.568883901960096,
      "grad_norm": 0.18658995628356934,
      "learning_rate": 2.145637366201752e-05,
      "loss": 0.0555,
      "step": 130300
    },
    {
      "epoch": 4.57239033626705,
      "grad_norm": 0.2864944636821747,
      "learning_rate": 2.143445748700371e-05,
      "loss": 0.0534,
      "step": 130400
    },
    {
      "epoch": 4.575896770574003,
      "grad_norm": 0.29046064615249634,
      "learning_rate": 2.1412541311989903e-05,
      "loss": 0.0526,
      "step": 130500
    },
    {
      "epoch": 4.579403204880957,
      "grad_norm": 0.24125543236732483,
      "learning_rate": 2.1390625136976093e-05,
      "loss": 0.0481,
      "step": 130600
    },
    {
      "epoch": 4.58290963918791,
      "grad_norm": 0.18161197006702423,
      "learning_rate": 2.136870896196229e-05,
      "loss": 0.0526,
      "step": 130700
    },
    {
      "epoch": 4.586416073494863,
      "grad_norm": 0.13314855098724365,
      "learning_rate": 2.134679278694848e-05,
      "loss": 0.0522,
      "step": 130800
    },
    {
      "epoch": 4.589922507801816,
      "grad_norm": 0.21564768254756927,
      "learning_rate": 2.1324876611934674e-05,
      "loss": 0.0504,
      "step": 130900
    },
    {
      "epoch": 4.59342894210877,
      "grad_norm": 0.2048548310995102,
      "learning_rate": 2.1302960436920865e-05,
      "loss": 0.0504,
      "step": 131000
    },
    {
      "epoch": 4.596935376415723,
      "grad_norm": 0.16882923245429993,
      "learning_rate": 2.1281263423657197e-05,
      "loss": 0.0495,
      "step": 131100
    },
    {
      "epoch": 4.6004418107226765,
      "grad_norm": 0.2860553562641144,
      "learning_rate": 2.1259566410393527e-05,
      "loss": 0.0586,
      "step": 131200
    },
    {
      "epoch": 4.603948245029629,
      "grad_norm": 0.15441331267356873,
      "learning_rate": 2.123765023537972e-05,
      "loss": 0.0509,
      "step": 131300
    },
    {
      "epoch": 4.607454679336582,
      "grad_norm": 0.09246920794248581,
      "learning_rate": 2.1215734060365914e-05,
      "loss": 0.0539,
      "step": 131400
    },
    {
      "epoch": 4.610961113643536,
      "grad_norm": 0.2123563289642334,
      "learning_rate": 2.1193817885352108e-05,
      "loss": 0.0507,
      "step": 131500
    },
    {
      "epoch": 4.614467547950489,
      "grad_norm": 0.27929145097732544,
      "learning_rate": 2.11719017103383e-05,
      "loss": 0.0547,
      "step": 131600
    },
    {
      "epoch": 4.617973982257443,
      "grad_norm": 0.08774708956480026,
      "learning_rate": 2.1149985535324492e-05,
      "loss": 0.0519,
      "step": 131700
    },
    {
      "epoch": 4.6214804165643955,
      "grad_norm": 0.06394480913877487,
      "learning_rate": 2.1128069360310686e-05,
      "loss": 0.0527,
      "step": 131800
    },
    {
      "epoch": 4.624986850871349,
      "grad_norm": 0.19415651261806488,
      "learning_rate": 2.110615318529688e-05,
      "loss": 0.0511,
      "step": 131900
    },
    {
      "epoch": 4.628493285178302,
      "grad_norm": 0.10260210931301117,
      "learning_rate": 2.108423701028307e-05,
      "loss": 0.0494,
      "step": 132000
    },
    {
      "epoch": 4.631999719485256,
      "grad_norm": 0.11253229528665543,
      "learning_rate": 2.1062320835269264e-05,
      "loss": 0.0532,
      "step": 132100
    },
    {
      "epoch": 4.635506153792209,
      "grad_norm": 0.18034294247627258,
      "learning_rate": 2.1040404660255454e-05,
      "loss": 0.0546,
      "step": 132200
    },
    {
      "epoch": 4.6390125880991615,
      "grad_norm": 0.14095669984817505,
      "learning_rate": 2.101848848524165e-05,
      "loss": 0.0529,
      "step": 132300
    },
    {
      "epoch": 4.642519022406115,
      "grad_norm": 0.3895774483680725,
      "learning_rate": 2.099657231022784e-05,
      "loss": 0.0513,
      "step": 132400
    },
    {
      "epoch": 4.646025456713068,
      "grad_norm": 0.14391008019447327,
      "learning_rate": 2.0974656135214035e-05,
      "loss": 0.0524,
      "step": 132500
    },
    {
      "epoch": 4.649531891020022,
      "grad_norm": 0.148480623960495,
      "learning_rate": 2.0952739960200225e-05,
      "loss": 0.0529,
      "step": 132600
    },
    {
      "epoch": 4.653038325326975,
      "grad_norm": 0.10546208918094635,
      "learning_rate": 2.0930823785186422e-05,
      "loss": 0.0514,
      "step": 132700
    },
    {
      "epoch": 4.656544759633928,
      "grad_norm": 0.38479727506637573,
      "learning_rate": 2.0908907610172613e-05,
      "loss": 0.0505,
      "step": 132800
    },
    {
      "epoch": 4.660051193940881,
      "grad_norm": 0.19569143652915955,
      "learning_rate": 2.0886991435158806e-05,
      "loss": 0.05,
      "step": 132900
    },
    {
      "epoch": 4.663557628247835,
      "grad_norm": 0.08903933316469193,
      "learning_rate": 2.0865075260144997e-05,
      "loss": 0.0484,
      "step": 133000
    },
    {
      "epoch": 4.667064062554788,
      "grad_norm": 0.23381145298480988,
      "learning_rate": 2.084315908513119e-05,
      "loss": 0.0519,
      "step": 133100
    },
    {
      "epoch": 4.670570496861742,
      "grad_norm": 0.13172516226768494,
      "learning_rate": 2.0821242910117384e-05,
      "loss": 0.0463,
      "step": 133200
    },
    {
      "epoch": 4.6740769311686945,
      "grad_norm": 0.1967407464981079,
      "learning_rate": 2.0799326735103578e-05,
      "loss": 0.0522,
      "step": 133300
    },
    {
      "epoch": 4.677583365475648,
      "grad_norm": 0.18861688673496246,
      "learning_rate": 2.0777410560089768e-05,
      "loss": 0.0517,
      "step": 133400
    },
    {
      "epoch": 4.681089799782601,
      "grad_norm": 0.1098237857222557,
      "learning_rate": 2.0755494385075962e-05,
      "loss": 0.0512,
      "step": 133500
    },
    {
      "epoch": 4.684596234089554,
      "grad_norm": 0.16204944252967834,
      "learning_rate": 2.0733578210062156e-05,
      "loss": 0.0548,
      "step": 133600
    },
    {
      "epoch": 4.688102668396508,
      "grad_norm": 0.18115033209323883,
      "learning_rate": 2.071166203504835e-05,
      "loss": 0.0546,
      "step": 133700
    },
    {
      "epoch": 4.6916091027034605,
      "grad_norm": 0.1251060664653778,
      "learning_rate": 2.068974586003454e-05,
      "loss": 0.0486,
      "step": 133800
    },
    {
      "epoch": 4.695115537010414,
      "grad_norm": 0.23807168006896973,
      "learning_rate": 2.0667829685020733e-05,
      "loss": 0.0516,
      "step": 133900
    },
    {
      "epoch": 4.698621971317367,
      "grad_norm": 0.3007436692714691,
      "learning_rate": 2.0645913510006927e-05,
      "loss": 0.0486,
      "step": 134000
    },
    {
      "epoch": 4.702128405624321,
      "grad_norm": 0.10371702164411545,
      "learning_rate": 2.062399733499312e-05,
      "loss": 0.0539,
      "step": 134100
    },
    {
      "epoch": 4.705634839931274,
      "grad_norm": 0.09518997371196747,
      "learning_rate": 2.060208115997931e-05,
      "loss": 0.0581,
      "step": 134200
    },
    {
      "epoch": 4.7091412742382275,
      "grad_norm": 0.320728600025177,
      "learning_rate": 2.0580164984965505e-05,
      "loss": 0.0518,
      "step": 134300
    },
    {
      "epoch": 4.71264770854518,
      "grad_norm": 0.36003243923187256,
      "learning_rate": 2.0558248809951695e-05,
      "loss": 0.0534,
      "step": 134400
    },
    {
      "epoch": 4.716154142852133,
      "grad_norm": 0.3120978772640228,
      "learning_rate": 2.0536332634937892e-05,
      "loss": 0.0558,
      "step": 134500
    },
    {
      "epoch": 4.719660577159087,
      "grad_norm": 0.32638028264045715,
      "learning_rate": 2.0514416459924083e-05,
      "loss": 0.0517,
      "step": 134600
    },
    {
      "epoch": 4.723167011466041,
      "grad_norm": 0.2682734727859497,
      "learning_rate": 2.0492500284910276e-05,
      "loss": 0.0501,
      "step": 134700
    },
    {
      "epoch": 4.7266734457729935,
      "grad_norm": 0.10642065107822418,
      "learning_rate": 2.0470584109896467e-05,
      "loss": 0.0489,
      "step": 134800
    },
    {
      "epoch": 4.730179880079946,
      "grad_norm": 0.428272545337677,
      "learning_rate": 2.0448667934882664e-05,
      "loss": 0.0521,
      "step": 134900
    },
    {
      "epoch": 4.7336863143869,
      "grad_norm": 0.2915169596672058,
      "learning_rate": 2.0426751759868854e-05,
      "loss": 0.0509,
      "step": 135000
    },
    {
      "epoch": 4.737192748693853,
      "grad_norm": 0.26591089367866516,
      "learning_rate": 2.0404835584855048e-05,
      "loss": 0.0525,
      "step": 135100
    },
    {
      "epoch": 4.740699183000807,
      "grad_norm": 0.20986062288284302,
      "learning_rate": 2.0383138571591377e-05,
      "loss": 0.0525,
      "step": 135200
    },
    {
      "epoch": 4.74420561730776,
      "grad_norm": 0.26540735363960266,
      "learning_rate": 2.036122239657757e-05,
      "loss": 0.0516,
      "step": 135300
    },
    {
      "epoch": 4.747712051614713,
      "grad_norm": 0.20638057589530945,
      "learning_rate": 2.0339306221563765e-05,
      "loss": 0.0501,
      "step": 135400
    },
    {
      "epoch": 4.751218485921666,
      "grad_norm": 0.16141493618488312,
      "learning_rate": 2.0317390046549955e-05,
      "loss": 0.0541,
      "step": 135500
    },
    {
      "epoch": 4.75472492022862,
      "grad_norm": 0.18442393839359283,
      "learning_rate": 2.029547387153615e-05,
      "loss": 0.0481,
      "step": 135600
    },
    {
      "epoch": 4.758231354535573,
      "grad_norm": 0.31834015250205994,
      "learning_rate": 2.0273557696522342e-05,
      "loss": 0.0548,
      "step": 135700
    },
    {
      "epoch": 4.761737788842526,
      "grad_norm": 0.16486331820487976,
      "learning_rate": 2.0251641521508536e-05,
      "loss": 0.0477,
      "step": 135800
    },
    {
      "epoch": 4.765244223149479,
      "grad_norm": 0.30583855509757996,
      "learning_rate": 2.0229725346494726e-05,
      "loss": 0.053,
      "step": 135900
    },
    {
      "epoch": 4.768750657456432,
      "grad_norm": 0.25653213262557983,
      "learning_rate": 2.020780917148092e-05,
      "loss": 0.0555,
      "step": 136000
    },
    {
      "epoch": 4.772257091763386,
      "grad_norm": 0.12269933521747589,
      "learning_rate": 2.0185892996467114e-05,
      "loss": 0.0521,
      "step": 136100
    },
    {
      "epoch": 4.775763526070339,
      "grad_norm": 0.25994473695755005,
      "learning_rate": 2.0163976821453308e-05,
      "loss": 0.0502,
      "step": 136200
    },
    {
      "epoch": 4.779269960377293,
      "grad_norm": 0.30438151955604553,
      "learning_rate": 2.0142060646439498e-05,
      "loss": 0.0527,
      "step": 136300
    },
    {
      "epoch": 4.782776394684245,
      "grad_norm": 0.15378637611865997,
      "learning_rate": 2.012014447142569e-05,
      "loss": 0.0538,
      "step": 136400
    },
    {
      "epoch": 4.786282828991199,
      "grad_norm": 0.24740871787071228,
      "learning_rate": 2.0098228296411882e-05,
      "loss": 0.0577,
      "step": 136500
    },
    {
      "epoch": 4.789789263298152,
      "grad_norm": 0.24109689891338348,
      "learning_rate": 2.007631212139808e-05,
      "loss": 0.0482,
      "step": 136600
    },
    {
      "epoch": 4.793295697605105,
      "grad_norm": 0.23463088274002075,
      "learning_rate": 2.0054395946384273e-05,
      "loss": 0.0513,
      "step": 136700
    },
    {
      "epoch": 4.796802131912059,
      "grad_norm": 0.2272939682006836,
      "learning_rate": 2.0032479771370463e-05,
      "loss": 0.0459,
      "step": 136800
    },
    {
      "epoch": 4.800308566219012,
      "grad_norm": 0.1149047315120697,
      "learning_rate": 2.0010563596356657e-05,
      "loss": 0.0524,
      "step": 136900
    },
    {
      "epoch": 4.803815000525965,
      "grad_norm": 0.4215007722377777,
      "learning_rate": 1.9988647421342847e-05,
      "loss": 0.0535,
      "step": 137000
    },
    {
      "epoch": 4.807321434832918,
      "grad_norm": 0.1111319437623024,
      "learning_rate": 1.9966731246329044e-05,
      "loss": 0.0524,
      "step": 137100
    },
    {
      "epoch": 4.810827869139872,
      "grad_norm": 0.140205517411232,
      "learning_rate": 1.9944815071315234e-05,
      "loss": 0.0566,
      "step": 137200
    },
    {
      "epoch": 4.814334303446825,
      "grad_norm": 0.11019300669431686,
      "learning_rate": 1.9923118058051564e-05,
      "loss": 0.0512,
      "step": 137300
    },
    {
      "epoch": 4.817840737753778,
      "grad_norm": 0.15202370285987854,
      "learning_rate": 1.990120188303776e-05,
      "loss": 0.0494,
      "step": 137400
    },
    {
      "epoch": 4.821347172060731,
      "grad_norm": 0.1965268850326538,
      "learning_rate": 1.987928570802395e-05,
      "loss": 0.0502,
      "step": 137500
    },
    {
      "epoch": 4.824853606367685,
      "grad_norm": 0.28419116139411926,
      "learning_rate": 1.9857369533010145e-05,
      "loss": 0.0468,
      "step": 137600
    },
    {
      "epoch": 4.828360040674638,
      "grad_norm": 0.1577105075120926,
      "learning_rate": 1.9835453357996335e-05,
      "loss": 0.0505,
      "step": 137700
    },
    {
      "epoch": 4.831866474981592,
      "grad_norm": 0.34861379861831665,
      "learning_rate": 1.981353718298253e-05,
      "loss": 0.052,
      "step": 137800
    },
    {
      "epoch": 4.8353729092885445,
      "grad_norm": 0.20647366344928741,
      "learning_rate": 1.9791621007968723e-05,
      "loss": 0.0505,
      "step": 137900
    },
    {
      "epoch": 4.838879343595497,
      "grad_norm": 0.15859414637088776,
      "learning_rate": 1.9769704832954917e-05,
      "loss": 0.0463,
      "step": 138000
    },
    {
      "epoch": 4.842385777902451,
      "grad_norm": 0.22086745500564575,
      "learning_rate": 1.9747788657941107e-05,
      "loss": 0.0492,
      "step": 138100
    },
    {
      "epoch": 4.845892212209404,
      "grad_norm": 0.2646222710609436,
      "learning_rate": 1.97258724829273e-05,
      "loss": 0.0503,
      "step": 138200
    },
    {
      "epoch": 4.849398646516358,
      "grad_norm": 0.139290452003479,
      "learning_rate": 1.9703956307913494e-05,
      "loss": 0.0544,
      "step": 138300
    },
    {
      "epoch": 4.8529050808233105,
      "grad_norm": 0.13238005340099335,
      "learning_rate": 1.9682040132899688e-05,
      "loss": 0.0518,
      "step": 138400
    },
    {
      "epoch": 4.856411515130264,
      "grad_norm": 0.2648693025112152,
      "learning_rate": 1.966012395788588e-05,
      "loss": 0.0514,
      "step": 138500
    },
    {
      "epoch": 4.859917949437217,
      "grad_norm": 0.1082218661904335,
      "learning_rate": 1.9638207782872072e-05,
      "loss": 0.0498,
      "step": 138600
    },
    {
      "epoch": 4.863424383744171,
      "grad_norm": 0.1636519879102707,
      "learning_rate": 1.9616291607858266e-05,
      "loss": 0.0532,
      "step": 138700
    },
    {
      "epoch": 4.866930818051124,
      "grad_norm": 0.1719961166381836,
      "learning_rate": 1.959437543284446e-05,
      "loss": 0.0488,
      "step": 138800
    },
    {
      "epoch": 4.8704372523580775,
      "grad_norm": 0.3207988739013672,
      "learning_rate": 1.957245925783065e-05,
      "loss": 0.0546,
      "step": 138900
    },
    {
      "epoch": 4.87394368666503,
      "grad_norm": 0.09652715921401978,
      "learning_rate": 1.9550543082816843e-05,
      "loss": 0.0492,
      "step": 139000
    },
    {
      "epoch": 4.877450120971984,
      "grad_norm": 0.4970971941947937,
      "learning_rate": 1.9528626907803034e-05,
      "loss": 0.0536,
      "step": 139100
    },
    {
      "epoch": 4.880956555278937,
      "grad_norm": 0.2606298327445984,
      "learning_rate": 1.950671073278923e-05,
      "loss": 0.0568,
      "step": 139200
    },
    {
      "epoch": 4.88446298958589,
      "grad_norm": 0.39954546093940735,
      "learning_rate": 1.948479455777542e-05,
      "loss": 0.0544,
      "step": 139300
    },
    {
      "epoch": 4.8879694238928435,
      "grad_norm": 0.20804601907730103,
      "learning_rate": 1.946309754451175e-05,
      "loss": 0.0524,
      "step": 139400
    },
    {
      "epoch": 4.891475858199796,
      "grad_norm": 0.04403664544224739,
      "learning_rate": 1.9441181369497948e-05,
      "loss": 0.0523,
      "step": 139500
    },
    {
      "epoch": 4.89498229250675,
      "grad_norm": 0.38134467601776123,
      "learning_rate": 1.9419265194484138e-05,
      "loss": 0.0508,
      "step": 139600
    },
    {
      "epoch": 4.898488726813703,
      "grad_norm": 0.16358532011508942,
      "learning_rate": 1.9397349019470332e-05,
      "loss": 0.0469,
      "step": 139700
    },
    {
      "epoch": 4.901995161120657,
      "grad_norm": 0.2540200352668762,
      "learning_rate": 1.9375432844456522e-05,
      "loss": 0.055,
      "step": 139800
    },
    {
      "epoch": 4.9055015954276096,
      "grad_norm": 0.14165684580802917,
      "learning_rate": 1.9353516669442716e-05,
      "loss": 0.0519,
      "step": 139900
    },
    {
      "epoch": 4.909008029734563,
      "grad_norm": 0.2268572300672531,
      "learning_rate": 1.933160049442891e-05,
      "loss": 0.0488,
      "step": 140000
    },
    {
      "epoch": 4.912514464041516,
      "grad_norm": 0.2460673600435257,
      "learning_rate": 1.9309684319415103e-05,
      "loss": 0.0531,
      "step": 140100
    },
    {
      "epoch": 4.916020898348469,
      "grad_norm": 0.12072205543518066,
      "learning_rate": 1.9287768144401294e-05,
      "loss": 0.0493,
      "step": 140200
    },
    {
      "epoch": 4.919527332655423,
      "grad_norm": 0.24027302861213684,
      "learning_rate": 1.9265851969387487e-05,
      "loss": 0.0523,
      "step": 140300
    },
    {
      "epoch": 4.923033766962376,
      "grad_norm": 0.23094356060028076,
      "learning_rate": 1.924393579437368e-05,
      "loss": 0.0522,
      "step": 140400
    },
    {
      "epoch": 4.926540201269329,
      "grad_norm": 0.18640881776809692,
      "learning_rate": 1.9222019619359875e-05,
      "loss": 0.0529,
      "step": 140500
    },
    {
      "epoch": 4.930046635576282,
      "grad_norm": 0.21077802777290344,
      "learning_rate": 1.9200103444346065e-05,
      "loss": 0.0524,
      "step": 140600
    },
    {
      "epoch": 4.933553069883236,
      "grad_norm": 0.2215290665626526,
      "learning_rate": 1.917818726933226e-05,
      "loss": 0.0522,
      "step": 140700
    },
    {
      "epoch": 4.937059504190189,
      "grad_norm": 0.19066548347473145,
      "learning_rate": 1.9156271094318452e-05,
      "loss": 0.048,
      "step": 140800
    },
    {
      "epoch": 4.9405659384971425,
      "grad_norm": 0.08871215581893921,
      "learning_rate": 1.9134354919304646e-05,
      "loss": 0.0543,
      "step": 140900
    },
    {
      "epoch": 4.944072372804095,
      "grad_norm": 0.1722107082605362,
      "learning_rate": 1.9112438744290836e-05,
      "loss": 0.0516,
      "step": 141000
    },
    {
      "epoch": 4.947578807111049,
      "grad_norm": 0.22699004411697388,
      "learning_rate": 1.909052256927703e-05,
      "loss": 0.0542,
      "step": 141100
    },
    {
      "epoch": 4.951085241418002,
      "grad_norm": 0.19807444512844086,
      "learning_rate": 1.906860639426322e-05,
      "loss": 0.0494,
      "step": 141200
    },
    {
      "epoch": 4.954591675724956,
      "grad_norm": 0.22637926042079926,
      "learning_rate": 1.9046690219249418e-05,
      "loss": 0.0486,
      "step": 141300
    },
    {
      "epoch": 4.958098110031909,
      "grad_norm": 0.12527258694171906,
      "learning_rate": 1.9024993205985747e-05,
      "loss": 0.0524,
      "step": 141400
    },
    {
      "epoch": 4.9616045443388614,
      "grad_norm": 0.151387557387352,
      "learning_rate": 1.9003077030971937e-05,
      "loss": 0.0511,
      "step": 141500
    },
    {
      "epoch": 4.965110978645815,
      "grad_norm": 0.2027585208415985,
      "learning_rate": 1.898116085595813e-05,
      "loss": 0.0511,
      "step": 141600
    },
    {
      "epoch": 4.968617412952768,
      "grad_norm": 0.25257351994514465,
      "learning_rate": 1.8959244680944325e-05,
      "loss": 0.0495,
      "step": 141700
    },
    {
      "epoch": 4.972123847259722,
      "grad_norm": 0.4657929837703705,
      "learning_rate": 1.893732850593052e-05,
      "loss": 0.05,
      "step": 141800
    },
    {
      "epoch": 4.975630281566675,
      "grad_norm": 0.19890384376049042,
      "learning_rate": 1.891541233091671e-05,
      "loss": 0.051,
      "step": 141900
    },
    {
      "epoch": 4.979136715873628,
      "grad_norm": 0.2764730453491211,
      "learning_rate": 1.8893496155902903e-05,
      "loss": 0.0545,
      "step": 142000
    },
    {
      "epoch": 4.982643150180581,
      "grad_norm": 0.36504286527633667,
      "learning_rate": 1.8871579980889096e-05,
      "loss": 0.0488,
      "step": 142100
    },
    {
      "epoch": 4.986149584487535,
      "grad_norm": 0.07614128291606903,
      "learning_rate": 1.884966380587529e-05,
      "loss": 0.0535,
      "step": 142200
    },
    {
      "epoch": 4.989656018794488,
      "grad_norm": 0.24401012063026428,
      "learning_rate": 1.882774763086148e-05,
      "loss": 0.0506,
      "step": 142300
    },
    {
      "epoch": 4.993162453101441,
      "grad_norm": 0.127022847533226,
      "learning_rate": 1.8805831455847674e-05,
      "loss": 0.051,
      "step": 142400
    },
    {
      "epoch": 4.996668887408394,
      "grad_norm": 0.09385472536087036,
      "learning_rate": 1.8783915280833868e-05,
      "loss": 0.0556,
      "step": 142500
    },
    {
      "epoch": 5.0,
      "eval_accuracy_macro_0.5": 0.9788989424705505,
      "eval_accuracy_micro_0.5": 0.9788990020751953,
      "eval_accuracy_weighted_0.5": 0.968457818031311,
      "eval_f1_macro_0.5": 0.6762927174568176,
      "eval_f1_macro_0.6": 0.6466761231422424,
      "eval_f1_macro_0.7": 0.6002476811408997,
      "eval_f1_macro_0.8": 0.4000515639781952,
      "eval_f1_micro_0.5": 0.7189491987228394,
      "eval_f1_micro_0.6": 0.6981285810470581,
      "eval_f1_micro_0.7": 0.658553421497345,
      "eval_f1_micro_0.8": 0.5892043113708496,
      "eval_f1_micro_0.9": 0.44851216673851013,
      "eval_f1_weighted_0.5": 0.7097857594490051,
      "eval_f1_weighted_0.6": 0.6829351186752319,
      "eval_f1_weighted_0.7": 0.6362600922584534,
      "eval_f1_weighted_0.8": 0.4136837422847748,
      "eval_loss": 0.04818185791373253,
      "eval_runtime": 142.5785,
      "eval_samples_per_second": 399.829,
      "eval_steps_per_second": 49.979,
      "step": 142595
    },
    {
      "epoch": 5.000175321715347,
      "grad_norm": 0.11933394521474838,
      "learning_rate": 1.876199910582006e-05,
      "loss": 0.0503,
      "step": 142600
    },
    {
      "epoch": 5.003681756022301,
      "grad_norm": 0.09598935395479202,
      "learning_rate": 1.8740082930806252e-05,
      "loss": 0.0535,
      "step": 142700
    },
    {
      "epoch": 5.007188190329254,
      "grad_norm": 0.14805427193641663,
      "learning_rate": 1.8718166755792445e-05,
      "loss": 0.0565,
      "step": 142800
    },
    {
      "epoch": 5.010694624636208,
      "grad_norm": 0.09967547655105591,
      "learning_rate": 1.869625058077864e-05,
      "loss": 0.0566,
      "step": 142900
    },
    {
      "epoch": 5.0142010589431605,
      "grad_norm": 0.2105902135372162,
      "learning_rate": 1.8674334405764833e-05,
      "loss": 0.0508,
      "step": 143000
    },
    {
      "epoch": 5.017707493250114,
      "grad_norm": 0.08383999019861221,
      "learning_rate": 1.8652418230751023e-05,
      "loss": 0.048,
      "step": 143100
    },
    {
      "epoch": 5.021213927557067,
      "grad_norm": 0.11292029917240143,
      "learning_rate": 1.8630502055737217e-05,
      "loss": 0.048,
      "step": 143200
    },
    {
      "epoch": 5.024720361864021,
      "grad_norm": 0.2037273645401001,
      "learning_rate": 1.8608585880723407e-05,
      "loss": 0.0503,
      "step": 143300
    },
    {
      "epoch": 5.028226796170974,
      "grad_norm": 0.03885267302393913,
      "learning_rate": 1.8586669705709604e-05,
      "loss": 0.0523,
      "step": 143400
    },
    {
      "epoch": 5.031733230477927,
      "grad_norm": 0.32754045724868774,
      "learning_rate": 1.8564753530695795e-05,
      "loss": 0.0489,
      "step": 143500
    },
    {
      "epoch": 5.03523966478488,
      "grad_norm": 0.11567481607198715,
      "learning_rate": 1.854283735568199e-05,
      "loss": 0.0489,
      "step": 143600
    },
    {
      "epoch": 5.038746099091833,
      "grad_norm": 0.06280604749917984,
      "learning_rate": 1.8520921180668182e-05,
      "loss": 0.0477,
      "step": 143700
    },
    {
      "epoch": 5.042252533398787,
      "grad_norm": 0.10631516575813293,
      "learning_rate": 1.849922416740451e-05,
      "loss": 0.0555,
      "step": 143800
    },
    {
      "epoch": 5.04575896770574,
      "grad_norm": 0.1973363608121872,
      "learning_rate": 1.8477307992390705e-05,
      "loss": 0.0498,
      "step": 143900
    },
    {
      "epoch": 5.0492654020126935,
      "grad_norm": 0.21677519381046295,
      "learning_rate": 1.8455391817376896e-05,
      "loss": 0.0493,
      "step": 144000
    },
    {
      "epoch": 5.052771836319646,
      "grad_norm": 0.16330085694789886,
      "learning_rate": 1.843347564236309e-05,
      "loss": 0.0489,
      "step": 144100
    },
    {
      "epoch": 5.0562782706266,
      "grad_norm": 0.2238486409187317,
      "learning_rate": 1.8411559467349286e-05,
      "loss": 0.0553,
      "step": 144200
    },
    {
      "epoch": 5.059784704933553,
      "grad_norm": 0.08208492398262024,
      "learning_rate": 1.8389643292335477e-05,
      "loss": 0.0471,
      "step": 144300
    },
    {
      "epoch": 5.063291139240507,
      "grad_norm": 0.16074839234352112,
      "learning_rate": 1.836772711732167e-05,
      "loss": 0.0497,
      "step": 144400
    },
    {
      "epoch": 5.0667975735474595,
      "grad_norm": 0.08079540729522705,
      "learning_rate": 1.834581094230786e-05,
      "loss": 0.0543,
      "step": 144500
    },
    {
      "epoch": 5.070304007854413,
      "grad_norm": 0.19318605959415436,
      "learning_rate": 1.8323894767294054e-05,
      "loss": 0.0506,
      "step": 144600
    },
    {
      "epoch": 5.073810442161366,
      "grad_norm": 0.13208723068237305,
      "learning_rate": 1.8301978592280248e-05,
      "loss": 0.0458,
      "step": 144700
    },
    {
      "epoch": 5.077316876468319,
      "grad_norm": 0.18570342659950256,
      "learning_rate": 1.8280062417266442e-05,
      "loss": 0.0489,
      "step": 144800
    },
    {
      "epoch": 5.080823310775273,
      "grad_norm": 0.24390335381031036,
      "learning_rate": 1.825836540400277e-05,
      "loss": 0.0509,
      "step": 144900
    },
    {
      "epoch": 5.084329745082226,
      "grad_norm": 0.22174189984798431,
      "learning_rate": 1.8236449228988965e-05,
      "loss": 0.0462,
      "step": 145000
    },
    {
      "epoch": 5.087836179389179,
      "grad_norm": 0.07567616552114487,
      "learning_rate": 1.821453305397516e-05,
      "loss": 0.0506,
      "step": 145100
    },
    {
      "epoch": 5.091342613696132,
      "grad_norm": 0.22457212209701538,
      "learning_rate": 1.819261687896135e-05,
      "loss": 0.0473,
      "step": 145200
    },
    {
      "epoch": 5.094849048003086,
      "grad_norm": 0.10365857928991318,
      "learning_rate": 1.8170700703947543e-05,
      "loss": 0.0515,
      "step": 145300
    },
    {
      "epoch": 5.098355482310039,
      "grad_norm": 0.20212441682815552,
      "learning_rate": 1.8148784528933736e-05,
      "loss": 0.0499,
      "step": 145400
    },
    {
      "epoch": 5.1018619166169925,
      "grad_norm": 0.18821433186531067,
      "learning_rate": 1.812686835391993e-05,
      "loss": 0.0514,
      "step": 145500
    },
    {
      "epoch": 5.105368350923945,
      "grad_norm": 0.21240897476673126,
      "learning_rate": 1.810495217890612e-05,
      "loss": 0.0561,
      "step": 145600
    },
    {
      "epoch": 5.108874785230899,
      "grad_norm": 0.1268303096294403,
      "learning_rate": 1.8083036003892314e-05,
      "loss": 0.0508,
      "step": 145700
    },
    {
      "epoch": 5.112381219537852,
      "grad_norm": 0.0869230180978775,
      "learning_rate": 1.8061119828878505e-05,
      "loss": 0.0503,
      "step": 145800
    },
    {
      "epoch": 5.115887653844805,
      "grad_norm": 0.07701590657234192,
      "learning_rate": 1.80392036538647e-05,
      "loss": 0.0502,
      "step": 145900
    },
    {
      "epoch": 5.119394088151759,
      "grad_norm": 0.1880534291267395,
      "learning_rate": 1.8017287478850892e-05,
      "loss": 0.0515,
      "step": 146000
    },
    {
      "epoch": 5.122900522458711,
      "grad_norm": 0.13126416504383087,
      "learning_rate": 1.7995371303837086e-05,
      "loss": 0.0513,
      "step": 146100
    },
    {
      "epoch": 5.126406956765665,
      "grad_norm": 0.08819250017404556,
      "learning_rate": 1.7973455128823276e-05,
      "loss": 0.0518,
      "step": 146200
    },
    {
      "epoch": 5.129913391072618,
      "grad_norm": 0.1393088698387146,
      "learning_rate": 1.795153895380947e-05,
      "loss": 0.0544,
      "step": 146300
    },
    {
      "epoch": 5.133419825379572,
      "grad_norm": 0.17401023209095,
      "learning_rate": 1.7929622778795663e-05,
      "loss": 0.0512,
      "step": 146400
    },
    {
      "epoch": 5.136926259686525,
      "grad_norm": 0.09040670841932297,
      "learning_rate": 1.7907706603781857e-05,
      "loss": 0.0525,
      "step": 146500
    },
    {
      "epoch": 5.140432693993478,
      "grad_norm": 0.13884106278419495,
      "learning_rate": 1.7885790428768047e-05,
      "loss": 0.0475,
      "step": 146600
    },
    {
      "epoch": 5.143939128300431,
      "grad_norm": 0.17451804876327515,
      "learning_rate": 1.786387425375424e-05,
      "loss": 0.053,
      "step": 146700
    },
    {
      "epoch": 5.147445562607385,
      "grad_norm": 0.17003048956394196,
      "learning_rate": 1.7841958078740435e-05,
      "loss": 0.052,
      "step": 146800
    },
    {
      "epoch": 5.150951996914338,
      "grad_norm": 0.09983989596366882,
      "learning_rate": 1.782004190372663e-05,
      "loss": 0.0516,
      "step": 146900
    },
    {
      "epoch": 5.154458431221291,
      "grad_norm": 0.0958857610821724,
      "learning_rate": 1.779812572871282e-05,
      "loss": 0.0561,
      "step": 147000
    },
    {
      "epoch": 5.157964865528244,
      "grad_norm": 0.09882242977619171,
      "learning_rate": 1.7776209553699013e-05,
      "loss": 0.0487,
      "step": 147100
    },
    {
      "epoch": 5.161471299835197,
      "grad_norm": 0.1857166588306427,
      "learning_rate": 1.7754293378685206e-05,
      "loss": 0.0517,
      "step": 147200
    },
    {
      "epoch": 5.164977734142151,
      "grad_norm": 0.15304307639598846,
      "learning_rate": 1.77323772036714e-05,
      "loss": 0.053,
      "step": 147300
    },
    {
      "epoch": 5.168484168449104,
      "grad_norm": 0.1982274204492569,
      "learning_rate": 1.771046102865759e-05,
      "loss": 0.05,
      "step": 147400
    },
    {
      "epoch": 5.171990602756058,
      "grad_norm": 0.19454099237918854,
      "learning_rate": 1.7688544853643784e-05,
      "loss": 0.0498,
      "step": 147500
    },
    {
      "epoch": 5.1754970370630105,
      "grad_norm": 0.2607336938381195,
      "learning_rate": 1.7666628678629978e-05,
      "loss": 0.0472,
      "step": 147600
    },
    {
      "epoch": 5.179003471369964,
      "grad_norm": 0.10080545395612717,
      "learning_rate": 1.764471250361617e-05,
      "loss": 0.0539,
      "step": 147700
    },
    {
      "epoch": 5.182509905676917,
      "grad_norm": 0.1928575336933136,
      "learning_rate": 1.7622796328602362e-05,
      "loss": 0.0503,
      "step": 147800
    },
    {
      "epoch": 5.186016339983871,
      "grad_norm": 0.24094533920288086,
      "learning_rate": 1.7600880153588556e-05,
      "loss": 0.0534,
      "step": 147900
    },
    {
      "epoch": 5.189522774290824,
      "grad_norm": 0.09916111081838608,
      "learning_rate": 1.7578963978574746e-05,
      "loss": 0.05,
      "step": 148000
    },
    {
      "epoch": 5.1930292085977765,
      "grad_norm": 0.16716809570789337,
      "learning_rate": 1.7557047803560943e-05,
      "loss": 0.0531,
      "step": 148100
    },
    {
      "epoch": 5.19653564290473,
      "grad_norm": 0.08651509135961533,
      "learning_rate": 1.7535131628547133e-05,
      "loss": 0.0532,
      "step": 148200
    },
    {
      "epoch": 5.200042077211683,
      "grad_norm": 0.18795445561408997,
      "learning_rate": 1.7513215453533327e-05,
      "loss": 0.0512,
      "step": 148300
    },
    {
      "epoch": 5.203548511518637,
      "grad_norm": 0.1310163140296936,
      "learning_rate": 1.7491299278519517e-05,
      "loss": 0.0497,
      "step": 148400
    },
    {
      "epoch": 5.20705494582559,
      "grad_norm": 0.14017225801944733,
      "learning_rate": 1.746938310350571e-05,
      "loss": 0.0504,
      "step": 148500
    },
    {
      "epoch": 5.210561380132543,
      "grad_norm": 0.3774867355823517,
      "learning_rate": 1.7447466928491905e-05,
      "loss": 0.0477,
      "step": 148600
    },
    {
      "epoch": 5.214067814439496,
      "grad_norm": 0.12931539118289948,
      "learning_rate": 1.74255507534781e-05,
      "loss": 0.0482,
      "step": 148700
    },
    {
      "epoch": 5.21757424874645,
      "grad_norm": 0.10698650777339935,
      "learning_rate": 1.740363457846429e-05,
      "loss": 0.0545,
      "step": 148800
    },
    {
      "epoch": 5.221080683053403,
      "grad_norm": 0.11857794970273972,
      "learning_rate": 1.7381718403450483e-05,
      "loss": 0.0464,
      "step": 148900
    },
    {
      "epoch": 5.224587117360357,
      "grad_norm": 0.09259378165006638,
      "learning_rate": 1.7360021390186815e-05,
      "loss": 0.0503,
      "step": 149000
    },
    {
      "epoch": 5.2280935516673095,
      "grad_norm": 0.07672592252492905,
      "learning_rate": 1.7338105215173006e-05,
      "loss": 0.0534,
      "step": 149100
    },
    {
      "epoch": 5.231599985974262,
      "grad_norm": 0.08624274283647537,
      "learning_rate": 1.73161890401592e-05,
      "loss": 0.0507,
      "step": 149200
    },
    {
      "epoch": 5.235106420281216,
      "grad_norm": 0.15552766621112823,
      "learning_rate": 1.7294272865145393e-05,
      "loss": 0.0539,
      "step": 149300
    },
    {
      "epoch": 5.238612854588169,
      "grad_norm": 0.10812093317508698,
      "learning_rate": 1.7272356690131587e-05,
      "loss": 0.0538,
      "step": 149400
    },
    {
      "epoch": 5.242119288895123,
      "grad_norm": 0.17486605048179626,
      "learning_rate": 1.7250440515117777e-05,
      "loss": 0.0521,
      "step": 149500
    },
    {
      "epoch": 5.2456257232020755,
      "grad_norm": 0.1810680627822876,
      "learning_rate": 1.722852434010397e-05,
      "loss": 0.0468,
      "step": 149600
    },
    {
      "epoch": 5.249132157509029,
      "grad_norm": 0.17406903207302094,
      "learning_rate": 1.720660816509016e-05,
      "loss": 0.0498,
      "step": 149700
    },
    {
      "epoch": 5.252638591815982,
      "grad_norm": 0.12335317581892014,
      "learning_rate": 1.7184691990076358e-05,
      "loss": 0.0522,
      "step": 149800
    },
    {
      "epoch": 5.256145026122936,
      "grad_norm": 0.15455183386802673,
      "learning_rate": 1.716277581506255e-05,
      "loss": 0.0504,
      "step": 149900
    },
    {
      "epoch": 5.259651460429889,
      "grad_norm": 0.11451927572488785,
      "learning_rate": 1.7140859640048742e-05,
      "loss": 0.0527,
      "step": 150000
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 0.1205521896481514,
      "learning_rate": 1.7118943465034933e-05,
      "loss": 0.0472,
      "step": 150100
    },
    {
      "epoch": 5.266664329043795,
      "grad_norm": 0.14789971709251404,
      "learning_rate": 1.709702729002113e-05,
      "loss": 0.0526,
      "step": 150200
    },
    {
      "epoch": 5.270170763350748,
      "grad_norm": 0.09443648159503937,
      "learning_rate": 1.707511111500732e-05,
      "loss": 0.0547,
      "step": 150300
    },
    {
      "epoch": 5.273677197657702,
      "grad_norm": 0.2731877267360687,
      "learning_rate": 1.7053194939993514e-05,
      "loss": 0.0496,
      "step": 150400
    },
    {
      "epoch": 5.277183631964655,
      "grad_norm": 0.08918377757072449,
      "learning_rate": 1.7031278764979704e-05,
      "loss": 0.0506,
      "step": 150500
    },
    {
      "epoch": 5.2806900662716085,
      "grad_norm": 0.07846280932426453,
      "learning_rate": 1.7009362589965898e-05,
      "loss": 0.0532,
      "step": 150600
    },
    {
      "epoch": 5.284196500578561,
      "grad_norm": 0.08430572599172592,
      "learning_rate": 1.6987446414952095e-05,
      "loss": 0.0483,
      "step": 150700
    },
    {
      "epoch": 5.287702934885515,
      "grad_norm": 0.1408585011959076,
      "learning_rate": 1.6965530239938285e-05,
      "loss": 0.0475,
      "step": 150800
    },
    {
      "epoch": 5.291209369192468,
      "grad_norm": 0.09399686753749847,
      "learning_rate": 1.694361406492448e-05,
      "loss": 0.0514,
      "step": 150900
    },
    {
      "epoch": 5.294715803499422,
      "grad_norm": 0.1488058865070343,
      "learning_rate": 1.692169788991067e-05,
      "loss": 0.0503,
      "step": 151000
    },
    {
      "epoch": 5.298222237806375,
      "grad_norm": 0.3198724389076233,
      "learning_rate": 1.6900000876647002e-05,
      "loss": 0.0498,
      "step": 151100
    },
    {
      "epoch": 5.301728672113328,
      "grad_norm": 0.315511018037796,
      "learning_rate": 1.687830386338333e-05,
      "loss": 0.0527,
      "step": 151200
    },
    {
      "epoch": 5.305235106420281,
      "grad_norm": 0.240962415933609,
      "learning_rate": 1.6856387688369525e-05,
      "loss": 0.0485,
      "step": 151300
    },
    {
      "epoch": 5.308741540727235,
      "grad_norm": 0.09832414239645004,
      "learning_rate": 1.683447151335572e-05,
      "loss": 0.0518,
      "step": 151400
    },
    {
      "epoch": 5.312247975034188,
      "grad_norm": 0.3977231979370117,
      "learning_rate": 1.681255533834191e-05,
      "loss": 0.0559,
      "step": 151500
    },
    {
      "epoch": 5.315754409341141,
      "grad_norm": 0.15477818250656128,
      "learning_rate": 1.6790639163328103e-05,
      "loss": 0.0489,
      "step": 151600
    },
    {
      "epoch": 5.319260843648094,
      "grad_norm": 0.07641812413930893,
      "learning_rate": 1.6768722988314297e-05,
      "loss": 0.0494,
      "step": 151700
    },
    {
      "epoch": 5.322767277955047,
      "grad_norm": 0.16645079851150513,
      "learning_rate": 1.674680681330049e-05,
      "loss": 0.0497,
      "step": 151800
    },
    {
      "epoch": 5.326273712262001,
      "grad_norm": 0.14001710712909698,
      "learning_rate": 1.6724890638286684e-05,
      "loss": 0.0479,
      "step": 151900
    },
    {
      "epoch": 5.329780146568954,
      "grad_norm": 0.0569896399974823,
      "learning_rate": 1.6702974463272874e-05,
      "loss": 0.0474,
      "step": 152000
    },
    {
      "epoch": 5.333286580875908,
      "grad_norm": 0.176406592130661,
      "learning_rate": 1.6681058288259068e-05,
      "loss": 0.0524,
      "step": 152100
    },
    {
      "epoch": 5.33679301518286,
      "grad_norm": 0.26210999488830566,
      "learning_rate": 1.6659142113245262e-05,
      "loss": 0.0554,
      "step": 152200
    },
    {
      "epoch": 5.340299449489814,
      "grad_norm": 0.08548906445503235,
      "learning_rate": 1.6637225938231456e-05,
      "loss": 0.0508,
      "step": 152300
    },
    {
      "epoch": 5.343805883796767,
      "grad_norm": 0.12051282078027725,
      "learning_rate": 1.6615309763217646e-05,
      "loss": 0.0501,
      "step": 152400
    },
    {
      "epoch": 5.34731231810372,
      "grad_norm": 0.10858885198831558,
      "learning_rate": 1.659339358820384e-05,
      "loss": 0.053,
      "step": 152500
    },
    {
      "epoch": 5.350818752410674,
      "grad_norm": 0.28317055106163025,
      "learning_rate": 1.657147741319003e-05,
      "loss": 0.0461,
      "step": 152600
    },
    {
      "epoch": 5.3543251867176265,
      "grad_norm": 0.139553502202034,
      "learning_rate": 1.6549561238176227e-05,
      "loss": 0.0533,
      "step": 152700
    },
    {
      "epoch": 5.35783162102458,
      "grad_norm": 0.1064099669456482,
      "learning_rate": 1.6527645063162417e-05,
      "loss": 0.0485,
      "step": 152800
    },
    {
      "epoch": 5.361338055331533,
      "grad_norm": 0.11113659292459488,
      "learning_rate": 1.650572888814861e-05,
      "loss": 0.0499,
      "step": 152900
    },
    {
      "epoch": 5.364844489638487,
      "grad_norm": 0.1397564709186554,
      "learning_rate": 1.64838127131348e-05,
      "loss": 0.0537,
      "step": 153000
    },
    {
      "epoch": 5.36835092394544,
      "grad_norm": 0.16289427876472473,
      "learning_rate": 1.6461896538120995e-05,
      "loss": 0.0523,
      "step": 153100
    },
    {
      "epoch": 5.371857358252393,
      "grad_norm": 0.17851363122463226,
      "learning_rate": 1.643998036310719e-05,
      "loss": 0.0502,
      "step": 153200
    },
    {
      "epoch": 5.375363792559346,
      "grad_norm": 0.13447192311286926,
      "learning_rate": 1.6418064188093383e-05,
      "loss": 0.0502,
      "step": 153300
    },
    {
      "epoch": 5.3788702268663,
      "grad_norm": 0.20224110782146454,
      "learning_rate": 1.6396148013079573e-05,
      "loss": 0.0501,
      "step": 153400
    },
    {
      "epoch": 5.382376661173253,
      "grad_norm": 0.12212537974119186,
      "learning_rate": 1.6374231838065767e-05,
      "loss": 0.0504,
      "step": 153500
    },
    {
      "epoch": 5.385883095480207,
      "grad_norm": 0.07135482132434845,
      "learning_rate": 1.635231566305196e-05,
      "loss": 0.0492,
      "step": 153600
    },
    {
      "epoch": 5.3893895297871595,
      "grad_norm": 0.15542981028556824,
      "learning_rate": 1.6330399488038154e-05,
      "loss": 0.0548,
      "step": 153700
    },
    {
      "epoch": 5.392895964094112,
      "grad_norm": 0.14095740020275116,
      "learning_rate": 1.6308483313024344e-05,
      "loss": 0.0548,
      "step": 153800
    },
    {
      "epoch": 5.396402398401066,
      "grad_norm": 0.13047362864017487,
      "learning_rate": 1.6286567138010538e-05,
      "loss": 0.052,
      "step": 153900
    },
    {
      "epoch": 5.399908832708019,
      "grad_norm": 0.16795237362384796,
      "learning_rate": 1.6264650962996732e-05,
      "loss": 0.047,
      "step": 154000
    },
    {
      "epoch": 5.403415267014973,
      "grad_norm": 0.16375941038131714,
      "learning_rate": 1.6242734787982925e-05,
      "loss": 0.0562,
      "step": 154100
    },
    {
      "epoch": 5.4069217013219255,
      "grad_norm": 0.1348445862531662,
      "learning_rate": 1.6220818612969116e-05,
      "loss": 0.0508,
      "step": 154200
    },
    {
      "epoch": 5.410428135628879,
      "grad_norm": 0.06596308201551437,
      "learning_rate": 1.619890243795531e-05,
      "loss": 0.0528,
      "step": 154300
    },
    {
      "epoch": 5.413934569935832,
      "grad_norm": 0.31383296847343445,
      "learning_rate": 1.61769862629415e-05,
      "loss": 0.052,
      "step": 154400
    },
    {
      "epoch": 5.417441004242786,
      "grad_norm": 0.1347159892320633,
      "learning_rate": 1.6155070087927697e-05,
      "loss": 0.0567,
      "step": 154500
    },
    {
      "epoch": 5.420947438549739,
      "grad_norm": 0.08868613839149475,
      "learning_rate": 1.6133153912913887e-05,
      "loss": 0.0521,
      "step": 154600
    },
    {
      "epoch": 5.424453872856692,
      "grad_norm": 0.08149074763059616,
      "learning_rate": 1.611123773790008e-05,
      "loss": 0.0483,
      "step": 154700
    },
    {
      "epoch": 5.427960307163645,
      "grad_norm": 0.18014568090438843,
      "learning_rate": 1.608932156288627e-05,
      "loss": 0.0527,
      "step": 154800
    },
    {
      "epoch": 5.431466741470598,
      "grad_norm": 0.26507824659347534,
      "learning_rate": 1.606740538787247e-05,
      "loss": 0.0478,
      "step": 154900
    },
    {
      "epoch": 5.434973175777552,
      "grad_norm": 0.1515093445777893,
      "learning_rate": 1.604548921285866e-05,
      "loss": 0.0486,
      "step": 155000
    },
    {
      "epoch": 5.438479610084505,
      "grad_norm": 0.20566530525684357,
      "learning_rate": 1.6023573037844852e-05,
      "loss": 0.0474,
      "step": 155100
    },
    {
      "epoch": 5.4419860443914585,
      "grad_norm": 0.0905497595667839,
      "learning_rate": 1.6001656862831043e-05,
      "loss": 0.0494,
      "step": 155200
    },
    {
      "epoch": 5.445492478698411,
      "grad_norm": 0.10551930218935013,
      "learning_rate": 1.5979740687817236e-05,
      "loss": 0.0466,
      "step": 155300
    },
    {
      "epoch": 5.448998913005365,
      "grad_norm": 0.1325322538614273,
      "learning_rate": 1.595782451280343e-05,
      "loss": 0.0467,
      "step": 155400
    },
    {
      "epoch": 5.452505347312318,
      "grad_norm": 0.15720123052597046,
      "learning_rate": 1.593612749953976e-05,
      "loss": 0.0493,
      "step": 155500
    },
    {
      "epoch": 5.456011781619272,
      "grad_norm": 0.26694759726524353,
      "learning_rate": 1.5914211324525953e-05,
      "loss": 0.0488,
      "step": 155600
    },
    {
      "epoch": 5.4595182159262245,
      "grad_norm": 0.07416053861379623,
      "learning_rate": 1.5892295149512147e-05,
      "loss": 0.0478,
      "step": 155700
    },
    {
      "epoch": 5.463024650233178,
      "grad_norm": 0.19853182137012482,
      "learning_rate": 1.587037897449834e-05,
      "loss": 0.054,
      "step": 155800
    },
    {
      "epoch": 5.466531084540131,
      "grad_norm": 0.24685658514499664,
      "learning_rate": 1.584846279948453e-05,
      "loss": 0.0512,
      "step": 155900
    },
    {
      "epoch": 5.470037518847084,
      "grad_norm": 0.16634808480739594,
      "learning_rate": 1.5826546624470725e-05,
      "loss": 0.0529,
      "step": 156000
    },
    {
      "epoch": 5.473543953154038,
      "grad_norm": 0.22198918461799622,
      "learning_rate": 1.580463044945692e-05,
      "loss": 0.0498,
      "step": 156100
    },
    {
      "epoch": 5.477050387460991,
      "grad_norm": 0.14083853363990784,
      "learning_rate": 1.5782714274443112e-05,
      "loss": 0.0518,
      "step": 156200
    },
    {
      "epoch": 5.480556821767944,
      "grad_norm": 0.2853217124938965,
      "learning_rate": 1.5760798099429302e-05,
      "loss": 0.0571,
      "step": 156300
    },
    {
      "epoch": 5.484063256074897,
      "grad_norm": 0.2780112028121948,
      "learning_rate": 1.5738881924415496e-05,
      "loss": 0.0519,
      "step": 156400
    },
    {
      "epoch": 5.487569690381851,
      "grad_norm": 0.34315407276153564,
      "learning_rate": 1.5716965749401687e-05,
      "loss": 0.0484,
      "step": 156500
    },
    {
      "epoch": 5.491076124688804,
      "grad_norm": 0.31881964206695557,
      "learning_rate": 1.5695049574387884e-05,
      "loss": 0.0537,
      "step": 156600
    },
    {
      "epoch": 5.4945825589957575,
      "grad_norm": 0.1416633278131485,
      "learning_rate": 1.5673133399374074e-05,
      "loss": 0.0524,
      "step": 156700
    },
    {
      "epoch": 5.49808899330271,
      "grad_norm": 0.16857996582984924,
      "learning_rate": 1.5651217224360268e-05,
      "loss": 0.0503,
      "step": 156800
    },
    {
      "epoch": 5.501595427609663,
      "grad_norm": 0.14031900465488434,
      "learning_rate": 1.5629301049346458e-05,
      "loss": 0.0466,
      "step": 156900
    },
    {
      "epoch": 5.505101861916617,
      "grad_norm": 0.13590170443058014,
      "learning_rate": 1.5607384874332655e-05,
      "loss": 0.0514,
      "step": 157000
    },
    {
      "epoch": 5.508608296223571,
      "grad_norm": 0.08034875243902206,
      "learning_rate": 1.5585468699318845e-05,
      "loss": 0.0477,
      "step": 157100
    },
    {
      "epoch": 5.512114730530524,
      "grad_norm": 0.13672706484794617,
      "learning_rate": 1.556355252430504e-05,
      "loss": 0.0492,
      "step": 157200
    },
    {
      "epoch": 5.515621164837476,
      "grad_norm": 0.0707436352968216,
      "learning_rate": 1.554163634929123e-05,
      "loss": 0.0545,
      "step": 157300
    },
    {
      "epoch": 5.51912759914443,
      "grad_norm": 0.16400016844272614,
      "learning_rate": 1.5519720174277423e-05,
      "loss": 0.0488,
      "step": 157400
    },
    {
      "epoch": 5.522634033451383,
      "grad_norm": 0.18917176127433777,
      "learning_rate": 1.5497803999263617e-05,
      "loss": 0.0489,
      "step": 157500
    },
    {
      "epoch": 5.526140467758337,
      "grad_norm": 0.17316220700740814,
      "learning_rate": 1.5476106985999946e-05,
      "loss": 0.0515,
      "step": 157600
    },
    {
      "epoch": 5.52964690206529,
      "grad_norm": 0.2430596649646759,
      "learning_rate": 1.545419081098614e-05,
      "loss": 0.048,
      "step": 157700
    },
    {
      "epoch": 5.533153336372243,
      "grad_norm": 0.27634385228157043,
      "learning_rate": 1.5432274635972334e-05,
      "loss": 0.0493,
      "step": 157800
    },
    {
      "epoch": 5.536659770679196,
      "grad_norm": 0.12853772938251495,
      "learning_rate": 1.5410358460958527e-05,
      "loss": 0.0506,
      "step": 157900
    },
    {
      "epoch": 5.54016620498615,
      "grad_norm": 0.09571465849876404,
      "learning_rate": 1.5388442285944718e-05,
      "loss": 0.046,
      "step": 158000
    },
    {
      "epoch": 5.543672639293103,
      "grad_norm": 0.15291570127010345,
      "learning_rate": 1.536652611093091e-05,
      "loss": 0.0513,
      "step": 158100
    },
    {
      "epoch": 5.547179073600056,
      "grad_norm": 0.20371395349502563,
      "learning_rate": 1.5344609935917105e-05,
      "loss": 0.0492,
      "step": 158200
    },
    {
      "epoch": 5.550685507907009,
      "grad_norm": 0.13337886333465576,
      "learning_rate": 1.53226937609033e-05,
      "loss": 0.05,
      "step": 158300
    },
    {
      "epoch": 5.554191942213962,
      "grad_norm": 0.2653757631778717,
      "learning_rate": 1.5300777585889493e-05,
      "loss": 0.0482,
      "step": 158400
    },
    {
      "epoch": 5.557698376520916,
      "grad_norm": 0.10036972910165787,
      "learning_rate": 1.5278861410875683e-05,
      "loss": 0.0492,
      "step": 158500
    },
    {
      "epoch": 5.561204810827869,
      "grad_norm": 0.17233890295028687,
      "learning_rate": 1.5256945235861878e-05,
      "loss": 0.0535,
      "step": 158600
    },
    {
      "epoch": 5.564711245134823,
      "grad_norm": 0.12281506508588791,
      "learning_rate": 1.5235029060848069e-05,
      "loss": 0.0515,
      "step": 158700
    },
    {
      "epoch": 5.5682176794417755,
      "grad_norm": 0.40397682785987854,
      "learning_rate": 1.5213112885834262e-05,
      "loss": 0.0516,
      "step": 158800
    },
    {
      "epoch": 5.571724113748729,
      "grad_norm": 0.1261027604341507,
      "learning_rate": 1.5191196710820454e-05,
      "loss": 0.0548,
      "step": 158900
    },
    {
      "epoch": 5.575230548055682,
      "grad_norm": 0.3715173900127411,
      "learning_rate": 1.5169280535806648e-05,
      "loss": 0.0516,
      "step": 159000
    },
    {
      "epoch": 5.578736982362636,
      "grad_norm": 0.11479294300079346,
      "learning_rate": 1.514736436079284e-05,
      "loss": 0.0562,
      "step": 159100
    },
    {
      "epoch": 5.582243416669589,
      "grad_norm": 0.11039095371961594,
      "learning_rate": 1.5125448185779034e-05,
      "loss": 0.051,
      "step": 159200
    },
    {
      "epoch": 5.585749850976542,
      "grad_norm": 0.1673501580953598,
      "learning_rate": 1.5103532010765226e-05,
      "loss": 0.0561,
      "step": 159300
    },
    {
      "epoch": 5.589256285283495,
      "grad_norm": 0.18881578743457794,
      "learning_rate": 1.508161583575142e-05,
      "loss": 0.0507,
      "step": 159400
    },
    {
      "epoch": 5.592762719590448,
      "grad_norm": 0.061879962682724,
      "learning_rate": 1.5059699660737612e-05,
      "loss": 0.0515,
      "step": 159500
    },
    {
      "epoch": 5.596269153897402,
      "grad_norm": 0.4537678062915802,
      "learning_rate": 1.5037783485723805e-05,
      "loss": 0.0514,
      "step": 159600
    },
    {
      "epoch": 5.599775588204355,
      "grad_norm": 0.09305504709482193,
      "learning_rate": 1.5015867310709997e-05,
      "loss": 0.0481,
      "step": 159700
    },
    {
      "epoch": 5.6032820225113085,
      "grad_norm": 0.16547568142414093,
      "learning_rate": 1.4994170297446328e-05,
      "loss": 0.0499,
      "step": 159800
    },
    {
      "epoch": 5.606788456818261,
      "grad_norm": 0.07438511401414871,
      "learning_rate": 1.4972254122432522e-05,
      "loss": 0.0496,
      "step": 159900
    },
    {
      "epoch": 5.610294891125215,
      "grad_norm": 0.18964526057243347,
      "learning_rate": 1.4950337947418712e-05,
      "loss": 0.052,
      "step": 160000
    },
    {
      "epoch": 5.613801325432168,
      "grad_norm": 0.23199795186519623,
      "learning_rate": 1.4928421772404908e-05,
      "loss": 0.0514,
      "step": 160100
    },
    {
      "epoch": 5.617307759739122,
      "grad_norm": 0.23296639323234558,
      "learning_rate": 1.4906505597391098e-05,
      "loss": 0.0502,
      "step": 160200
    },
    {
      "epoch": 5.6208141940460745,
      "grad_norm": 0.1816161423921585,
      "learning_rate": 1.4884589422377294e-05,
      "loss": 0.0527,
      "step": 160300
    },
    {
      "epoch": 5.624320628353027,
      "grad_norm": 0.1569160521030426,
      "learning_rate": 1.4862673247363484e-05,
      "loss": 0.046,
      "step": 160400
    },
    {
      "epoch": 5.627827062659981,
      "grad_norm": 0.16276444494724274,
      "learning_rate": 1.484075707234968e-05,
      "loss": 0.0506,
      "step": 160500
    },
    {
      "epoch": 5.631333496966934,
      "grad_norm": 0.16229665279388428,
      "learning_rate": 1.481884089733587e-05,
      "loss": 0.0487,
      "step": 160600
    },
    {
      "epoch": 5.634839931273888,
      "grad_norm": 0.183318093419075,
      "learning_rate": 1.4796924722322063e-05,
      "loss": 0.0517,
      "step": 160700
    },
    {
      "epoch": 5.638346365580841,
      "grad_norm": 0.10485411435365677,
      "learning_rate": 1.4775008547308255e-05,
      "loss": 0.0517,
      "step": 160800
    },
    {
      "epoch": 5.641852799887794,
      "grad_norm": 0.06698451936244965,
      "learning_rate": 1.4753092372294449e-05,
      "loss": 0.0518,
      "step": 160900
    },
    {
      "epoch": 5.645359234194747,
      "grad_norm": 0.11631223559379578,
      "learning_rate": 1.4731176197280641e-05,
      "loss": 0.0483,
      "step": 161000
    },
    {
      "epoch": 5.648865668501701,
      "grad_norm": 0.1311069130897522,
      "learning_rate": 1.4709260022266835e-05,
      "loss": 0.0547,
      "step": 161100
    },
    {
      "epoch": 5.652372102808654,
      "grad_norm": 0.21388337016105652,
      "learning_rate": 1.4687343847253027e-05,
      "loss": 0.0502,
      "step": 161200
    },
    {
      "epoch": 5.6558785371156075,
      "grad_norm": 0.12180798500776291,
      "learning_rate": 1.466542767223922e-05,
      "loss": 0.0464,
      "step": 161300
    },
    {
      "epoch": 5.65938497142256,
      "grad_norm": 0.14004749059677124,
      "learning_rate": 1.4643511497225413e-05,
      "loss": 0.0485,
      "step": 161400
    },
    {
      "epoch": 5.662891405729514,
      "grad_norm": 0.26885145902633667,
      "learning_rate": 1.4621595322211606e-05,
      "loss": 0.0571,
      "step": 161500
    },
    {
      "epoch": 5.666397840036467,
      "grad_norm": 0.12138676643371582,
      "learning_rate": 1.4599679147197798e-05,
      "loss": 0.046,
      "step": 161600
    },
    {
      "epoch": 5.66990427434342,
      "grad_norm": 0.37682244181632996,
      "learning_rate": 1.4577762972183992e-05,
      "loss": 0.0526,
      "step": 161700
    },
    {
      "epoch": 5.673410708650374,
      "grad_norm": 0.11382699757814407,
      "learning_rate": 1.4556065958920323e-05,
      "loss": 0.0477,
      "step": 161800
    },
    {
      "epoch": 5.676917142957326,
      "grad_norm": 0.24235785007476807,
      "learning_rate": 1.4534149783906515e-05,
      "loss": 0.0462,
      "step": 161900
    },
    {
      "epoch": 5.68042357726428,
      "grad_norm": 0.03915504738688469,
      "learning_rate": 1.4512233608892709e-05,
      "loss": 0.0538,
      "step": 162000
    },
    {
      "epoch": 5.683930011571233,
      "grad_norm": 0.17385460436344147,
      "learning_rate": 1.44903174338789e-05,
      "loss": 0.0513,
      "step": 162100
    },
    {
      "epoch": 5.687436445878187,
      "grad_norm": 0.2922574579715729,
      "learning_rate": 1.4468401258865095e-05,
      "loss": 0.0546,
      "step": 162200
    },
    {
      "epoch": 5.69094288018514,
      "grad_norm": 0.08682852983474731,
      "learning_rate": 1.4446485083851285e-05,
      "loss": 0.0497,
      "step": 162300
    },
    {
      "epoch": 5.694449314492093,
      "grad_norm": 0.10242994129657745,
      "learning_rate": 1.442456890883748e-05,
      "loss": 0.053,
      "step": 162400
    },
    {
      "epoch": 5.697955748799046,
      "grad_norm": 0.20691409707069397,
      "learning_rate": 1.440265273382367e-05,
      "loss": 0.0508,
      "step": 162500
    },
    {
      "epoch": 5.701462183105999,
      "grad_norm": 0.17735923826694489,
      "learning_rate": 1.4380736558809866e-05,
      "loss": 0.0496,
      "step": 162600
    },
    {
      "epoch": 5.704968617412953,
      "grad_norm": 0.13585178554058075,
      "learning_rate": 1.4358820383796056e-05,
      "loss": 0.0517,
      "step": 162700
    },
    {
      "epoch": 5.708475051719906,
      "grad_norm": 0.16080191731452942,
      "learning_rate": 1.433690420878225e-05,
      "loss": 0.0479,
      "step": 162800
    },
    {
      "epoch": 5.711981486026859,
      "grad_norm": 0.16880938410758972,
      "learning_rate": 1.4314988033768442e-05,
      "loss": 0.0498,
      "step": 162900
    },
    {
      "epoch": 5.715487920333812,
      "grad_norm": 0.17373627424240112,
      "learning_rate": 1.4293071858754636e-05,
      "loss": 0.0514,
      "step": 163000
    },
    {
      "epoch": 5.718994354640766,
      "grad_norm": 0.10555429756641388,
      "learning_rate": 1.4271155683740828e-05,
      "loss": 0.0519,
      "step": 163100
    },
    {
      "epoch": 5.722500788947719,
      "grad_norm": 0.15177689492702484,
      "learning_rate": 1.4249239508727022e-05,
      "loss": 0.0513,
      "step": 163200
    },
    {
      "epoch": 5.726007223254673,
      "grad_norm": 0.1829470992088318,
      "learning_rate": 1.4227323333713214e-05,
      "loss": 0.0491,
      "step": 163300
    },
    {
      "epoch": 5.7295136575616255,
      "grad_norm": 0.1778997927904129,
      "learning_rate": 1.4205407158699407e-05,
      "loss": 0.0505,
      "step": 163400
    },
    {
      "epoch": 5.733020091868579,
      "grad_norm": 0.23723864555358887,
      "learning_rate": 1.41834909836856e-05,
      "loss": 0.0493,
      "step": 163500
    },
    {
      "epoch": 5.736526526175532,
      "grad_norm": 0.34180325269699097,
      "learning_rate": 1.4161574808671793e-05,
      "loss": 0.0494,
      "step": 163600
    },
    {
      "epoch": 5.740032960482486,
      "grad_norm": 0.08071674406528473,
      "learning_rate": 1.4139658633657985e-05,
      "loss": 0.0498,
      "step": 163700
    },
    {
      "epoch": 5.743539394789439,
      "grad_norm": 0.08192551881074905,
      "learning_rate": 1.4117742458644179e-05,
      "loss": 0.0541,
      "step": 163800
    },
    {
      "epoch": 5.7470458290963915,
      "grad_norm": 0.21248815953731537,
      "learning_rate": 1.409604544538051e-05,
      "loss": 0.0515,
      "step": 163900
    },
    {
      "epoch": 5.750552263403345,
      "grad_norm": 0.12239545583724976,
      "learning_rate": 1.40741292703667e-05,
      "loss": 0.0524,
      "step": 164000
    },
    {
      "epoch": 5.754058697710298,
      "grad_norm": 0.12639844417572021,
      "learning_rate": 1.4052213095352896e-05,
      "loss": 0.0508,
      "step": 164100
    },
    {
      "epoch": 5.757565132017252,
      "grad_norm": 0.21225762367248535,
      "learning_rate": 1.4030296920339086e-05,
      "loss": 0.0535,
      "step": 164200
    },
    {
      "epoch": 5.761071566324205,
      "grad_norm": 0.18052366375923157,
      "learning_rate": 1.4008380745325281e-05,
      "loss": 0.0491,
      "step": 164300
    },
    {
      "epoch": 5.764578000631158,
      "grad_norm": 0.12431629002094269,
      "learning_rate": 1.3986464570311472e-05,
      "loss": 0.0522,
      "step": 164400
    },
    {
      "epoch": 5.768084434938111,
      "grad_norm": 0.1050763875246048,
      "learning_rate": 1.3964548395297667e-05,
      "loss": 0.048,
      "step": 164500
    },
    {
      "epoch": 5.771590869245065,
      "grad_norm": 0.20746713876724243,
      "learning_rate": 1.3942632220283857e-05,
      "loss": 0.0483,
      "step": 164600
    },
    {
      "epoch": 5.775097303552018,
      "grad_norm": 0.2918403446674347,
      "learning_rate": 1.3920716045270051e-05,
      "loss": 0.0511,
      "step": 164700
    },
    {
      "epoch": 5.778603737858971,
      "grad_norm": 0.08529854565858841,
      "learning_rate": 1.3898799870256243e-05,
      "loss": 0.0486,
      "step": 164800
    },
    {
      "epoch": 5.7821101721659245,
      "grad_norm": 0.17156624794006348,
      "learning_rate": 1.3876883695242437e-05,
      "loss": 0.0523,
      "step": 164900
    },
    {
      "epoch": 5.785616606472877,
      "grad_norm": 0.2668640911579132,
      "learning_rate": 1.3854967520228629e-05,
      "loss": 0.0525,
      "step": 165000
    },
    {
      "epoch": 5.789123040779831,
      "grad_norm": 0.37117448449134827,
      "learning_rate": 1.3833051345214823e-05,
      "loss": 0.053,
      "step": 165100
    },
    {
      "epoch": 5.792629475086784,
      "grad_norm": 0.157185360789299,
      "learning_rate": 1.3811135170201015e-05,
      "loss": 0.0476,
      "step": 165200
    },
    {
      "epoch": 5.796135909393738,
      "grad_norm": 0.12632258236408234,
      "learning_rate": 1.3789218995187208e-05,
      "loss": 0.0504,
      "step": 165300
    },
    {
      "epoch": 5.7996423437006905,
      "grad_norm": 0.19557708501815796,
      "learning_rate": 1.3767302820173402e-05,
      "loss": 0.0532,
      "step": 165400
    },
    {
      "epoch": 5.803148778007644,
      "grad_norm": 0.1602323204278946,
      "learning_rate": 1.3745386645159594e-05,
      "loss": 0.0501,
      "step": 165500
    },
    {
      "epoch": 5.806655212314597,
      "grad_norm": 0.06830295920372009,
      "learning_rate": 1.3723470470145788e-05,
      "loss": 0.0498,
      "step": 165600
    },
    {
      "epoch": 5.810161646621551,
      "grad_norm": 0.10365930944681168,
      "learning_rate": 1.370155429513198e-05,
      "loss": 0.0517,
      "step": 165700
    },
    {
      "epoch": 5.813668080928504,
      "grad_norm": 0.2832537889480591,
      "learning_rate": 1.3679638120118173e-05,
      "loss": 0.0525,
      "step": 165800
    },
    {
      "epoch": 5.8171745152354575,
      "grad_norm": 0.14545492827892303,
      "learning_rate": 1.3657721945104365e-05,
      "loss": 0.0483,
      "step": 165900
    },
    {
      "epoch": 5.82068094954241,
      "grad_norm": 0.1946447193622589,
      "learning_rate": 1.3636024931840697e-05,
      "loss": 0.0506,
      "step": 166000
    },
    {
      "epoch": 5.824187383849363,
      "grad_norm": 0.12551282346248627,
      "learning_rate": 1.361410875682689e-05,
      "loss": 0.0517,
      "step": 166100
    },
    {
      "epoch": 5.827693818156317,
      "grad_norm": 0.07360853254795074,
      "learning_rate": 1.3592192581813082e-05,
      "loss": 0.0492,
      "step": 166200
    },
    {
      "epoch": 5.83120025246327,
      "grad_norm": 0.29849472641944885,
      "learning_rate": 1.3570276406799276e-05,
      "loss": 0.0484,
      "step": 166300
    },
    {
      "epoch": 5.8347066867702235,
      "grad_norm": 0.3302786946296692,
      "learning_rate": 1.3548360231785468e-05,
      "loss": 0.0498,
      "step": 166400
    },
    {
      "epoch": 5.838213121077176,
      "grad_norm": 0.39791399240493774,
      "learning_rate": 1.3526444056771662e-05,
      "loss": 0.0544,
      "step": 166500
    },
    {
      "epoch": 5.84171955538413,
      "grad_norm": 0.24512508511543274,
      "learning_rate": 1.3504527881757854e-05,
      "loss": 0.0519,
      "step": 166600
    },
    {
      "epoch": 5.845225989691083,
      "grad_norm": 0.20406293869018555,
      "learning_rate": 1.3482611706744047e-05,
      "loss": 0.0518,
      "step": 166700
    },
    {
      "epoch": 5.848732423998037,
      "grad_norm": 0.11801375448703766,
      "learning_rate": 1.3460695531730238e-05,
      "loss": 0.0471,
      "step": 166800
    },
    {
      "epoch": 5.85223885830499,
      "grad_norm": 0.06697547435760498,
      "learning_rate": 1.3438779356716433e-05,
      "loss": 0.0528,
      "step": 166900
    },
    {
      "epoch": 5.855745292611942,
      "grad_norm": 0.2626877427101135,
      "learning_rate": 1.3416863181702624e-05,
      "loss": 0.0525,
      "step": 167000
    },
    {
      "epoch": 5.859251726918896,
      "grad_norm": 0.20007053017616272,
      "learning_rate": 1.3394947006688819e-05,
      "loss": 0.0532,
      "step": 167100
    },
    {
      "epoch": 5.86275816122585,
      "grad_norm": 0.11902093142271042,
      "learning_rate": 1.337303083167501e-05,
      "loss": 0.0507,
      "step": 167200
    },
    {
      "epoch": 5.866264595532803,
      "grad_norm": 0.12892258167266846,
      "learning_rate": 1.3351114656661205e-05,
      "loss": 0.05,
      "step": 167300
    },
    {
      "epoch": 5.869771029839756,
      "grad_norm": 0.2116827666759491,
      "learning_rate": 1.3329198481647395e-05,
      "loss": 0.0518,
      "step": 167400
    },
    {
      "epoch": 5.873277464146709,
      "grad_norm": 0.05109028518199921,
      "learning_rate": 1.3307282306633589e-05,
      "loss": 0.0527,
      "step": 167500
    },
    {
      "epoch": 5.876783898453662,
      "grad_norm": 0.30139443278312683,
      "learning_rate": 1.328536613161978e-05,
      "loss": 0.05,
      "step": 167600
    },
    {
      "epoch": 5.880290332760616,
      "grad_norm": 0.18650344014167786,
      "learning_rate": 1.3263449956605974e-05,
      "loss": 0.0586,
      "step": 167700
    },
    {
      "epoch": 5.883796767067569,
      "grad_norm": 0.14724603295326233,
      "learning_rate": 1.3241533781592166e-05,
      "loss": 0.0544,
      "step": 167800
    },
    {
      "epoch": 5.887303201374523,
      "grad_norm": 0.33403781056404114,
      "learning_rate": 1.321961760657836e-05,
      "loss": 0.0541,
      "step": 167900
    },
    {
      "epoch": 5.890809635681475,
      "grad_norm": 0.18672963976860046,
      "learning_rate": 1.3197701431564552e-05,
      "loss": 0.0467,
      "step": 168000
    },
    {
      "epoch": 5.894316069988429,
      "grad_norm": 0.2440008819103241,
      "learning_rate": 1.3175785256550746e-05,
      "loss": 0.0512,
      "step": 168100
    },
    {
      "epoch": 5.897822504295382,
      "grad_norm": 0.22285974025726318,
      "learning_rate": 1.3153869081536938e-05,
      "loss": 0.0477,
      "step": 168200
    },
    {
      "epoch": 5.901328938602335,
      "grad_norm": 0.0903998464345932,
      "learning_rate": 1.3131952906523132e-05,
      "loss": 0.0449,
      "step": 168300
    },
    {
      "epoch": 5.904835372909289,
      "grad_norm": 0.16953590512275696,
      "learning_rate": 1.3110255893259463e-05,
      "loss": 0.0485,
      "step": 168400
    },
    {
      "epoch": 5.9083418072162415,
      "grad_norm": 0.15756796300411224,
      "learning_rate": 1.3088339718245655e-05,
      "loss": 0.0501,
      "step": 168500
    },
    {
      "epoch": 5.911848241523195,
      "grad_norm": 0.14436310529708862,
      "learning_rate": 1.3066423543231848e-05,
      "loss": 0.0478,
      "step": 168600
    },
    {
      "epoch": 5.915354675830148,
      "grad_norm": 0.12514856457710266,
      "learning_rate": 1.3044507368218039e-05,
      "loss": 0.052,
      "step": 168700
    },
    {
      "epoch": 5.918861110137102,
      "grad_norm": 0.17067676782608032,
      "learning_rate": 1.3022591193204234e-05,
      "loss": 0.0489,
      "step": 168800
    },
    {
      "epoch": 5.922367544444055,
      "grad_norm": 0.07869236171245575,
      "learning_rate": 1.3000675018190425e-05,
      "loss": 0.0477,
      "step": 168900
    },
    {
      "epoch": 5.925873978751008,
      "grad_norm": 0.2534653842449188,
      "learning_rate": 1.297875884317662e-05,
      "loss": 0.0484,
      "step": 169000
    },
    {
      "epoch": 5.929380413057961,
      "grad_norm": 0.04366814345121384,
      "learning_rate": 1.295684266816281e-05,
      "loss": 0.0528,
      "step": 169100
    },
    {
      "epoch": 5.932886847364915,
      "grad_norm": 0.17933565378189087,
      "learning_rate": 1.2934926493149006e-05,
      "loss": 0.0487,
      "step": 169200
    },
    {
      "epoch": 5.936393281671868,
      "grad_norm": 0.0958583652973175,
      "learning_rate": 1.2913010318135196e-05,
      "loss": 0.0476,
      "step": 169300
    },
    {
      "epoch": 5.939899715978822,
      "grad_norm": 0.2718923091888428,
      "learning_rate": 1.289109414312139e-05,
      "loss": 0.0487,
      "step": 169400
    },
    {
      "epoch": 5.9434061502857745,
      "grad_norm": 0.202291801571846,
      "learning_rate": 1.2869177968107582e-05,
      "loss": 0.0517,
      "step": 169500
    },
    {
      "epoch": 5.946912584592727,
      "grad_norm": 0.29396823048591614,
      "learning_rate": 1.2847261793093775e-05,
      "loss": 0.0507,
      "step": 169600
    },
    {
      "epoch": 5.950419018899681,
      "grad_norm": 0.23922383785247803,
      "learning_rate": 1.2825345618079967e-05,
      "loss": 0.0485,
      "step": 169700
    },
    {
      "epoch": 5.953925453206634,
      "grad_norm": 0.14560547471046448,
      "learning_rate": 1.2803429443066161e-05,
      "loss": 0.0501,
      "step": 169800
    },
    {
      "epoch": 5.957431887513588,
      "grad_norm": 0.19479712843894958,
      "learning_rate": 1.2781513268052353e-05,
      "loss": 0.0536,
      "step": 169900
    },
    {
      "epoch": 5.9609383218205405,
      "grad_norm": 0.3699828088283539,
      "learning_rate": 1.2759597093038547e-05,
      "loss": 0.0471,
      "step": 170000
    },
    {
      "epoch": 5.964444756127494,
      "grad_norm": 0.1430591195821762,
      "learning_rate": 1.2737680918024739e-05,
      "loss": 0.0525,
      "step": 170100
    },
    {
      "epoch": 5.967951190434447,
      "grad_norm": 0.07597068697214127,
      "learning_rate": 1.2715764743010933e-05,
      "loss": 0.0489,
      "step": 170200
    },
    {
      "epoch": 5.971457624741401,
      "grad_norm": 0.15684762597084045,
      "learning_rate": 1.2693848567997125e-05,
      "loss": 0.0489,
      "step": 170300
    },
    {
      "epoch": 5.974964059048354,
      "grad_norm": 0.15573860704898834,
      "learning_rate": 1.2671932392983318e-05,
      "loss": 0.0467,
      "step": 170400
    },
    {
      "epoch": 5.978470493355307,
      "grad_norm": 0.08233985304832458,
      "learning_rate": 1.265023537971965e-05,
      "loss": 0.0518,
      "step": 170500
    },
    {
      "epoch": 5.98197692766226,
      "grad_norm": 0.1642751693725586,
      "learning_rate": 1.2628319204705842e-05,
      "loss": 0.0508,
      "step": 170600
    },
    {
      "epoch": 5.985483361969213,
      "grad_norm": 0.2176128476858139,
      "learning_rate": 1.2606403029692035e-05,
      "loss": 0.0466,
      "step": 170700
    },
    {
      "epoch": 5.988989796276167,
      "grad_norm": 0.09928499907255173,
      "learning_rate": 1.2584486854678226e-05,
      "loss": 0.0494,
      "step": 170800
    },
    {
      "epoch": 5.99249623058312,
      "grad_norm": 0.1975918859243393,
      "learning_rate": 1.2562570679664421e-05,
      "loss": 0.0504,
      "step": 170900
    },
    {
      "epoch": 5.9960026648900735,
      "grad_norm": 0.0672975406050682,
      "learning_rate": 1.2540654504650611e-05,
      "loss": 0.0486,
      "step": 171000
    },
    {
      "epoch": 5.999509099197026,
      "grad_norm": 0.19788941740989685,
      "learning_rate": 1.2518738329636807e-05,
      "loss": 0.0508,
      "step": 171100
    },
    {
      "epoch": 6.0,
      "eval_accuracy_macro_0.5": 0.9792641401290894,
      "eval_accuracy_micro_0.5": 0.9792640805244446,
      "eval_accuracy_weighted_0.5": 0.969057559967041,
      "eval_f1_macro_0.5": 0.682451605796814,
      "eval_f1_macro_0.6": 0.6545585989952087,
      "eval_f1_macro_0.7": 0.6081360578536987,
      "eval_f1_macro_0.8": 0.4127669632434845,
      "eval_f1_micro_0.5": 0.7237069606781006,
      "eval_f1_micro_0.6": 0.7035184502601624,
      "eval_f1_micro_0.7": 0.6659456491470337,
      "eval_f1_micro_0.8": 0.5990825295448303,
      "eval_f1_micro_0.9": 0.46497848629951477,
      "eval_f1_weighted_0.5": 0.7143126130104065,
      "eval_f1_weighted_0.6": 0.6881167888641357,
      "eval_f1_weighted_0.7": 0.6428605914115906,
      "eval_f1_weighted_0.8": 0.42802298069000244,
      "eval_loss": 0.04729216545820236,
      "eval_runtime": 142.2646,
      "eval_samples_per_second": 400.711,
      "eval_steps_per_second": 50.09,
      "step": 171114
    },
    {
      "epoch": 6.00301553350398,
      "grad_norm": 0.19588090479373932,
      "learning_rate": 1.2496822154622999e-05,
      "loss": 0.0496,
      "step": 171200
    },
    {
      "epoch": 6.006521967810933,
      "grad_norm": 0.22441339492797852,
      "learning_rate": 1.247512514135933e-05,
      "loss": 0.0493,
      "step": 171300
    },
    {
      "epoch": 6.010028402117887,
      "grad_norm": 0.19224537909030914,
      "learning_rate": 1.2453208966345522e-05,
      "loss": 0.0485,
      "step": 171400
    },
    {
      "epoch": 6.0135348364248395,
      "grad_norm": 0.09175513684749603,
      "learning_rate": 1.2431292791331716e-05,
      "loss": 0.0505,
      "step": 171500
    },
    {
      "epoch": 6.017041270731792,
      "grad_norm": 0.24463346600532532,
      "learning_rate": 1.2409376616317908e-05,
      "loss": 0.0541,
      "step": 171600
    },
    {
      "epoch": 6.020547705038746,
      "grad_norm": 0.20040760934352875,
      "learning_rate": 1.2387460441304101e-05,
      "loss": 0.0506,
      "step": 171700
    },
    {
      "epoch": 6.024054139345699,
      "grad_norm": 0.19140435755252838,
      "learning_rate": 1.2365544266290293e-05,
      "loss": 0.0475,
      "step": 171800
    },
    {
      "epoch": 6.027560573652653,
      "grad_norm": 0.3188122808933258,
      "learning_rate": 1.2343628091276487e-05,
      "loss": 0.0482,
      "step": 171900
    },
    {
      "epoch": 6.031067007959606,
      "grad_norm": 0.32143256068229675,
      "learning_rate": 1.2321711916262679e-05,
      "loss": 0.0528,
      "step": 172000
    },
    {
      "epoch": 6.034573442266559,
      "grad_norm": 0.24339225888252258,
      "learning_rate": 1.2299795741248873e-05,
      "loss": 0.0535,
      "step": 172100
    },
    {
      "epoch": 6.038079876573512,
      "grad_norm": 0.15361852943897247,
      "learning_rate": 1.2277879566235065e-05,
      "loss": 0.05,
      "step": 172200
    },
    {
      "epoch": 6.041586310880466,
      "grad_norm": 0.1391519010066986,
      "learning_rate": 1.2255963391221258e-05,
      "loss": 0.0475,
      "step": 172300
    },
    {
      "epoch": 6.045092745187419,
      "grad_norm": 0.5590682029724121,
      "learning_rate": 1.223404721620745e-05,
      "loss": 0.0511,
      "step": 172400
    },
    {
      "epoch": 6.0485991794943725,
      "grad_norm": 0.34819456934928894,
      "learning_rate": 1.2212131041193643e-05,
      "loss": 0.0533,
      "step": 172500
    },
    {
      "epoch": 6.052105613801325,
      "grad_norm": 0.1387128233909607,
      "learning_rate": 1.2190214866179836e-05,
      "loss": 0.0512,
      "step": 172600
    },
    {
      "epoch": 6.055612048108278,
      "grad_norm": 0.09953388571739197,
      "learning_rate": 1.2168298691166028e-05,
      "loss": 0.0493,
      "step": 172700
    },
    {
      "epoch": 6.059118482415232,
      "grad_norm": 0.2554026246070862,
      "learning_rate": 1.2146382516152222e-05,
      "loss": 0.0509,
      "step": 172800
    },
    {
      "epoch": 6.062624916722185,
      "grad_norm": 0.13033944368362427,
      "learning_rate": 1.2124466341138414e-05,
      "loss": 0.0487,
      "step": 172900
    },
    {
      "epoch": 6.066131351029139,
      "grad_norm": 0.19351935386657715,
      "learning_rate": 1.2102550166124608e-05,
      "loss": 0.0489,
      "step": 173000
    },
    {
      "epoch": 6.069637785336091,
      "grad_norm": 0.1630653738975525,
      "learning_rate": 1.20806339911108e-05,
      "loss": 0.0476,
      "step": 173100
    },
    {
      "epoch": 6.073144219643045,
      "grad_norm": 0.15727394819259644,
      "learning_rate": 1.2058717816096993e-05,
      "loss": 0.0492,
      "step": 173200
    },
    {
      "epoch": 6.076650653949998,
      "grad_norm": 0.19200517237186432,
      "learning_rate": 1.2036801641083185e-05,
      "loss": 0.0499,
      "step": 173300
    },
    {
      "epoch": 6.080157088256952,
      "grad_norm": 0.21003921329975128,
      "learning_rate": 1.2014885466069377e-05,
      "loss": 0.053,
      "step": 173400
    },
    {
      "epoch": 6.083663522563905,
      "grad_norm": 0.11983636766672134,
      "learning_rate": 1.1992969291055571e-05,
      "loss": 0.054,
      "step": 173500
    },
    {
      "epoch": 6.087169956870858,
      "grad_norm": 0.1091977134346962,
      "learning_rate": 1.1971053116041763e-05,
      "loss": 0.0524,
      "step": 173600
    },
    {
      "epoch": 6.090676391177811,
      "grad_norm": 0.11343070864677429,
      "learning_rate": 1.1949136941027957e-05,
      "loss": 0.0526,
      "step": 173700
    },
    {
      "epoch": 6.094182825484765,
      "grad_norm": 0.16486097872257233,
      "learning_rate": 1.1927220766014149e-05,
      "loss": 0.0537,
      "step": 173800
    },
    {
      "epoch": 6.097689259791718,
      "grad_norm": 0.1548948585987091,
      "learning_rate": 1.1905304591000343e-05,
      "loss": 0.0474,
      "step": 173900
    },
    {
      "epoch": 6.101195694098671,
      "grad_norm": 0.24512764811515808,
      "learning_rate": 1.1883388415986535e-05,
      "loss": 0.0494,
      "step": 174000
    },
    {
      "epoch": 6.104702128405624,
      "grad_norm": 0.14432458579540253,
      "learning_rate": 1.1861472240972728e-05,
      "loss": 0.0528,
      "step": 174100
    },
    {
      "epoch": 6.108208562712577,
      "grad_norm": 0.13651831448078156,
      "learning_rate": 1.183955606595892e-05,
      "loss": 0.0471,
      "step": 174200
    },
    {
      "epoch": 6.111714997019531,
      "grad_norm": 0.2483735978603363,
      "learning_rate": 1.1817639890945114e-05,
      "loss": 0.0516,
      "step": 174300
    },
    {
      "epoch": 6.115221431326484,
      "grad_norm": 0.15639807283878326,
      "learning_rate": 1.1795723715931306e-05,
      "loss": 0.0519,
      "step": 174400
    },
    {
      "epoch": 6.118727865633438,
      "grad_norm": 0.16349461674690247,
      "learning_rate": 1.1773807540917498e-05,
      "loss": 0.0508,
      "step": 174500
    },
    {
      "epoch": 6.1222342999403905,
      "grad_norm": 0.22187818586826324,
      "learning_rate": 1.1751891365903692e-05,
      "loss": 0.0499,
      "step": 174600
    },
    {
      "epoch": 6.125740734247344,
      "grad_norm": 0.33610838651657104,
      "learning_rate": 1.1729975190889884e-05,
      "loss": 0.0511,
      "step": 174700
    },
    {
      "epoch": 6.129247168554297,
      "grad_norm": 0.1008743941783905,
      "learning_rate": 1.1708059015876078e-05,
      "loss": 0.0469,
      "step": 174800
    },
    {
      "epoch": 6.132753602861251,
      "grad_norm": 0.3703703284263611,
      "learning_rate": 1.1686362002612409e-05,
      "loss": 0.0522,
      "step": 174900
    },
    {
      "epoch": 6.136260037168204,
      "grad_norm": 0.14892429113388062,
      "learning_rate": 1.16644458275986e-05,
      "loss": 0.0489,
      "step": 175000
    },
    {
      "epoch": 6.1397664714751565,
      "grad_norm": 0.20150774717330933,
      "learning_rate": 1.1642529652584794e-05,
      "loss": 0.0487,
      "step": 175100
    },
    {
      "epoch": 6.14327290578211,
      "grad_norm": 0.13163895905017853,
      "learning_rate": 1.1620613477570986e-05,
      "loss": 0.0495,
      "step": 175200
    },
    {
      "epoch": 6.146779340089063,
      "grad_norm": 0.17918570339679718,
      "learning_rate": 1.159869730255718e-05,
      "loss": 0.0487,
      "step": 175300
    },
    {
      "epoch": 6.150285774396017,
      "grad_norm": 0.10910952836275101,
      "learning_rate": 1.1576781127543372e-05,
      "loss": 0.0487,
      "step": 175400
    },
    {
      "epoch": 6.15379220870297,
      "grad_norm": 0.12898051738739014,
      "learning_rate": 1.1554864952529564e-05,
      "loss": 0.0509,
      "step": 175500
    },
    {
      "epoch": 6.1572986430099235,
      "grad_norm": 0.1898343414068222,
      "learning_rate": 1.1532948777515758e-05,
      "loss": 0.0513,
      "step": 175600
    },
    {
      "epoch": 6.160805077316876,
      "grad_norm": 0.24494720995426178,
      "learning_rate": 1.151103260250195e-05,
      "loss": 0.0552,
      "step": 175700
    },
    {
      "epoch": 6.16431151162383,
      "grad_norm": 0.14321236312389374,
      "learning_rate": 1.1489116427488144e-05,
      "loss": 0.0519,
      "step": 175800
    },
    {
      "epoch": 6.167817945930783,
      "grad_norm": 0.17809046804904938,
      "learning_rate": 1.1467200252474336e-05,
      "loss": 0.0514,
      "step": 175900
    },
    {
      "epoch": 6.171324380237737,
      "grad_norm": 0.4071987569332123,
      "learning_rate": 1.144528407746053e-05,
      "loss": 0.0517,
      "step": 176000
    },
    {
      "epoch": 6.1748308145446895,
      "grad_norm": 0.19960075616836548,
      "learning_rate": 1.1423367902446723e-05,
      "loss": 0.0504,
      "step": 176100
    },
    {
      "epoch": 6.178337248851642,
      "grad_norm": 0.18614444136619568,
      "learning_rate": 1.1401451727432915e-05,
      "loss": 0.0475,
      "step": 176200
    },
    {
      "epoch": 6.181843683158596,
      "grad_norm": 0.1399807333946228,
      "learning_rate": 1.1379535552419109e-05,
      "loss": 0.0483,
      "step": 176300
    },
    {
      "epoch": 6.185350117465549,
      "grad_norm": 0.17061205208301544,
      "learning_rate": 1.13576193774053e-05,
      "loss": 0.0495,
      "step": 176400
    },
    {
      "epoch": 6.188856551772503,
      "grad_norm": 0.19924859702587128,
      "learning_rate": 1.1335703202391495e-05,
      "loss": 0.0517,
      "step": 176500
    },
    {
      "epoch": 6.192362986079456,
      "grad_norm": 0.22613085806369781,
      "learning_rate": 1.1313787027377687e-05,
      "loss": 0.0525,
      "step": 176600
    },
    {
      "epoch": 6.195869420386409,
      "grad_norm": 0.25344350934028625,
      "learning_rate": 1.129187085236388e-05,
      "loss": 0.0511,
      "step": 176700
    },
    {
      "epoch": 6.199375854693362,
      "grad_norm": 0.30713391304016113,
      "learning_rate": 1.1269954677350072e-05,
      "loss": 0.0494,
      "step": 176800
    },
    {
      "epoch": 6.202882289000316,
      "grad_norm": 0.1705135703086853,
      "learning_rate": 1.1248038502336266e-05,
      "loss": 0.0516,
      "step": 176900
    },
    {
      "epoch": 6.206388723307269,
      "grad_norm": 0.1771882176399231,
      "learning_rate": 1.1226122327322458e-05,
      "loss": 0.0492,
      "step": 177000
    },
    {
      "epoch": 6.2098951576142225,
      "grad_norm": 0.2764361798763275,
      "learning_rate": 1.120420615230865e-05,
      "loss": 0.0503,
      "step": 177100
    },
    {
      "epoch": 6.213401591921175,
      "grad_norm": 0.2365880161523819,
      "learning_rate": 1.1182289977294844e-05,
      "loss": 0.0489,
      "step": 177200
    },
    {
      "epoch": 6.216908026228128,
      "grad_norm": 0.2371005415916443,
      "learning_rate": 1.1160373802281036e-05,
      "loss": 0.0501,
      "step": 177300
    },
    {
      "epoch": 6.220414460535082,
      "grad_norm": 0.31091034412384033,
      "learning_rate": 1.113845762726723e-05,
      "loss": 0.0521,
      "step": 177400
    },
    {
      "epoch": 6.223920894842035,
      "grad_norm": 0.24274203181266785,
      "learning_rate": 1.1116541452253421e-05,
      "loss": 0.0498,
      "step": 177500
    },
    {
      "epoch": 6.2274273291489886,
      "grad_norm": 0.3553462028503418,
      "learning_rate": 1.1094625277239615e-05,
      "loss": 0.0496,
      "step": 177600
    },
    {
      "epoch": 6.230933763455941,
      "grad_norm": 0.22469978034496307,
      "learning_rate": 1.1072709102225807e-05,
      "loss": 0.0479,
      "step": 177700
    },
    {
      "epoch": 6.234440197762895,
      "grad_norm": 0.37695491313934326,
      "learning_rate": 1.1050792927212001e-05,
      "loss": 0.0519,
      "step": 177800
    },
    {
      "epoch": 6.237946632069848,
      "grad_norm": 0.11343660205602646,
      "learning_rate": 1.1028876752198193e-05,
      "loss": 0.0455,
      "step": 177900
    },
    {
      "epoch": 6.241453066376802,
      "grad_norm": 0.23966506123542786,
      "learning_rate": 1.1006960577184387e-05,
      "loss": 0.0502,
      "step": 178000
    },
    {
      "epoch": 6.244959500683755,
      "grad_norm": 0.1839979887008667,
      "learning_rate": 1.0985044402170579e-05,
      "loss": 0.0507,
      "step": 178100
    },
    {
      "epoch": 6.248465934990708,
      "grad_norm": 0.17950405180454254,
      "learning_rate": 1.096312822715677e-05,
      "loss": 0.0473,
      "step": 178200
    },
    {
      "epoch": 6.251972369297661,
      "grad_norm": 0.18296712636947632,
      "learning_rate": 1.0941212052142964e-05,
      "loss": 0.0519,
      "step": 178300
    },
    {
      "epoch": 6.255478803604614,
      "grad_norm": 0.15692740678787231,
      "learning_rate": 1.0919295877129156e-05,
      "loss": 0.0482,
      "step": 178400
    },
    {
      "epoch": 6.258985237911568,
      "grad_norm": 0.32368791103363037,
      "learning_rate": 1.089737970211535e-05,
      "loss": 0.0466,
      "step": 178500
    },
    {
      "epoch": 6.262491672218521,
      "grad_norm": 0.10849951207637787,
      "learning_rate": 1.0875463527101542e-05,
      "loss": 0.0507,
      "step": 178600
    },
    {
      "epoch": 6.265998106525474,
      "grad_norm": 0.28962650895118713,
      "learning_rate": 1.0853547352087736e-05,
      "loss": 0.0507,
      "step": 178700
    },
    {
      "epoch": 6.269504540832427,
      "grad_norm": 0.20026947557926178,
      "learning_rate": 1.0831631177073928e-05,
      "loss": 0.0503,
      "step": 178800
    },
    {
      "epoch": 6.273010975139381,
      "grad_norm": 0.12778185307979584,
      "learning_rate": 1.0809715002060122e-05,
      "loss": 0.0497,
      "step": 178900
    },
    {
      "epoch": 6.276517409446334,
      "grad_norm": 0.3872358202934265,
      "learning_rate": 1.0788017988796453e-05,
      "loss": 0.0508,
      "step": 179000
    },
    {
      "epoch": 6.280023843753288,
      "grad_norm": 0.2829408049583435,
      "learning_rate": 1.0766101813782645e-05,
      "loss": 0.0504,
      "step": 179100
    },
    {
      "epoch": 6.2835302780602404,
      "grad_norm": 0.21389159560203552,
      "learning_rate": 1.0744185638768837e-05,
      "loss": 0.0497,
      "step": 179200
    },
    {
      "epoch": 6.287036712367194,
      "grad_norm": 0.17829594016075134,
      "learning_rate": 1.072226946375503e-05,
      "loss": 0.0519,
      "step": 179300
    },
    {
      "epoch": 6.290543146674147,
      "grad_norm": 0.2031935304403305,
      "learning_rate": 1.0700353288741222e-05,
      "loss": 0.0507,
      "step": 179400
    },
    {
      "epoch": 6.294049580981101,
      "grad_norm": 0.08951450139284134,
      "learning_rate": 1.0678437113727416e-05,
      "loss": 0.05,
      "step": 179500
    },
    {
      "epoch": 6.297556015288054,
      "grad_norm": 0.2516278922557831,
      "learning_rate": 1.0656520938713608e-05,
      "loss": 0.0488,
      "step": 179600
    },
    {
      "epoch": 6.3010624495950065,
      "grad_norm": 0.25729116797447205,
      "learning_rate": 1.0634604763699802e-05,
      "loss": 0.0549,
      "step": 179700
    },
    {
      "epoch": 6.30456888390196,
      "grad_norm": 0.26215285062789917,
      "learning_rate": 1.0612688588685994e-05,
      "loss": 0.0491,
      "step": 179800
    },
    {
      "epoch": 6.308075318208913,
      "grad_norm": 0.1224399134516716,
      "learning_rate": 1.0590772413672188e-05,
      "loss": 0.0486,
      "step": 179900
    },
    {
      "epoch": 6.311581752515867,
      "grad_norm": 0.2512153387069702,
      "learning_rate": 1.056885623865838e-05,
      "loss": 0.0453,
      "step": 180000
    },
    {
      "epoch": 6.31508818682282,
      "grad_norm": 0.19334745407104492,
      "learning_rate": 1.0546940063644573e-05,
      "loss": 0.0554,
      "step": 180100
    },
    {
      "epoch": 6.318594621129773,
      "grad_norm": 0.11940651386976242,
      "learning_rate": 1.0525023888630765e-05,
      "loss": 0.0477,
      "step": 180200
    },
    {
      "epoch": 6.322101055436726,
      "grad_norm": 0.32963094115257263,
      "learning_rate": 1.0503107713616957e-05,
      "loss": 0.051,
      "step": 180300
    },
    {
      "epoch": 6.32560748974368,
      "grad_norm": 0.30922919511795044,
      "learning_rate": 1.0481191538603151e-05,
      "loss": 0.0471,
      "step": 180400
    },
    {
      "epoch": 6.329113924050633,
      "grad_norm": 0.29534274339675903,
      "learning_rate": 1.0459275363589343e-05,
      "loss": 0.0512,
      "step": 180500
    },
    {
      "epoch": 6.332620358357586,
      "grad_norm": 0.15014779567718506,
      "learning_rate": 1.0437359188575537e-05,
      "loss": 0.0503,
      "step": 180600
    },
    {
      "epoch": 6.3361267926645395,
      "grad_norm": 0.18883882462978363,
      "learning_rate": 1.0415443013561729e-05,
      "loss": 0.0513,
      "step": 180700
    },
    {
      "epoch": 6.339633226971492,
      "grad_norm": 0.26435908675193787,
      "learning_rate": 1.0393526838547923e-05,
      "loss": 0.05,
      "step": 180800
    },
    {
      "epoch": 6.343139661278446,
      "grad_norm": 0.2599232792854309,
      "learning_rate": 1.0371610663534115e-05,
      "loss": 0.0508,
      "step": 180900
    },
    {
      "epoch": 6.346646095585399,
      "grad_norm": 0.32489800453186035,
      "learning_rate": 1.0349694488520308e-05,
      "loss": 0.05,
      "step": 181000
    },
    {
      "epoch": 6.350152529892353,
      "grad_norm": 0.1130586564540863,
      "learning_rate": 1.0327997475256638e-05,
      "loss": 0.0539,
      "step": 181100
    },
    {
      "epoch": 6.3536589641993055,
      "grad_norm": 0.14162059128284454,
      "learning_rate": 1.0306081300242831e-05,
      "loss": 0.0534,
      "step": 181200
    },
    {
      "epoch": 6.357165398506259,
      "grad_norm": 0.3097822964191437,
      "learning_rate": 1.0284165125229023e-05,
      "loss": 0.0501,
      "step": 181300
    },
    {
      "epoch": 6.360671832813212,
      "grad_norm": 0.17391332983970642,
      "learning_rate": 1.0262248950215217e-05,
      "loss": 0.0545,
      "step": 181400
    },
    {
      "epoch": 6.364178267120166,
      "grad_norm": 0.17725011706352234,
      "learning_rate": 1.024033277520141e-05,
      "loss": 0.0481,
      "step": 181500
    },
    {
      "epoch": 6.367684701427119,
      "grad_norm": 0.21212564408779144,
      "learning_rate": 1.0218416600187603e-05,
      "loss": 0.0462,
      "step": 181600
    },
    {
      "epoch": 6.3711911357340725,
      "grad_norm": 0.19827476143836975,
      "learning_rate": 1.0196500425173795e-05,
      "loss": 0.0494,
      "step": 181700
    },
    {
      "epoch": 6.374697570041025,
      "grad_norm": 0.11204277724027634,
      "learning_rate": 1.0174584250159989e-05,
      "loss": 0.0465,
      "step": 181800
    },
    {
      "epoch": 6.378204004347978,
      "grad_norm": 0.1536024659872055,
      "learning_rate": 1.015266807514618e-05,
      "loss": 0.0491,
      "step": 181900
    },
    {
      "epoch": 6.381710438654932,
      "grad_norm": 0.18826565146446228,
      "learning_rate": 1.0130751900132374e-05,
      "loss": 0.0524,
      "step": 182000
    },
    {
      "epoch": 6.385216872961885,
      "grad_norm": 0.2826976180076599,
      "learning_rate": 1.0108835725118566e-05,
      "loss": 0.0469,
      "step": 182100
    },
    {
      "epoch": 6.3887233072688385,
      "grad_norm": 0.2594083845615387,
      "learning_rate": 1.0086919550104758e-05,
      "loss": 0.0531,
      "step": 182200
    },
    {
      "epoch": 6.392229741575791,
      "grad_norm": 0.12932421267032623,
      "learning_rate": 1.0065003375090952e-05,
      "loss": 0.0477,
      "step": 182300
    },
    {
      "epoch": 6.395736175882745,
      "grad_norm": 0.18450123071670532,
      "learning_rate": 1.0043087200077144e-05,
      "loss": 0.0498,
      "step": 182400
    },
    {
      "epoch": 6.399242610189698,
      "grad_norm": 0.29382234811782837,
      "learning_rate": 1.0021171025063338e-05,
      "loss": 0.05,
      "step": 182500
    },
    {
      "epoch": 6.402749044496652,
      "grad_norm": 0.08115055412054062,
      "learning_rate": 9.999254850049532e-06,
      "loss": 0.0483,
      "step": 182600
    },
    {
      "epoch": 6.406255478803605,
      "grad_norm": 0.11213488131761551,
      "learning_rate": 9.977338675035725e-06,
      "loss": 0.045,
      "step": 182700
    },
    {
      "epoch": 6.409761913110557,
      "grad_norm": 0.2857584059238434,
      "learning_rate": 9.955422500021917e-06,
      "loss": 0.055,
      "step": 182800
    },
    {
      "epoch": 6.413268347417511,
      "grad_norm": 0.17902885377407074,
      "learning_rate": 9.93350632500811e-06,
      "loss": 0.0477,
      "step": 182900
    },
    {
      "epoch": 6.416774781724464,
      "grad_norm": 0.15365764498710632,
      "learning_rate": 9.911590149994303e-06,
      "loss": 0.0524,
      "step": 183000
    },
    {
      "epoch": 6.420281216031418,
      "grad_norm": 0.21424399316310883,
      "learning_rate": 9.889673974980495e-06,
      "loss": 0.0473,
      "step": 183100
    },
    {
      "epoch": 6.423787650338371,
      "grad_norm": 0.2919556498527527,
      "learning_rate": 9.867757799966689e-06,
      "loss": 0.0526,
      "step": 183200
    },
    {
      "epoch": 6.427294084645324,
      "grad_norm": 0.15990716218948364,
      "learning_rate": 9.84606078670302e-06,
      "loss": 0.0528,
      "step": 183300
    },
    {
      "epoch": 6.430800518952277,
      "grad_norm": 0.11233338713645935,
      "learning_rate": 9.824144611689212e-06,
      "loss": 0.0517,
      "step": 183400
    },
    {
      "epoch": 6.434306953259231,
      "grad_norm": 0.12119046598672867,
      "learning_rate": 9.802228436675406e-06,
      "loss": 0.0518,
      "step": 183500
    },
    {
      "epoch": 6.437813387566184,
      "grad_norm": 0.17883263528347015,
      "learning_rate": 9.780312261661598e-06,
      "loss": 0.0506,
      "step": 183600
    },
    {
      "epoch": 6.441319821873138,
      "grad_norm": 0.23894831538200378,
      "learning_rate": 9.758396086647791e-06,
      "loss": 0.0508,
      "step": 183700
    },
    {
      "epoch": 6.44482625618009,
      "grad_norm": 0.12489908933639526,
      "learning_rate": 9.736479911633983e-06,
      "loss": 0.0509,
      "step": 183800
    },
    {
      "epoch": 6.448332690487044,
      "grad_norm": 0.21465975046157837,
      "learning_rate": 9.714563736620175e-06,
      "loss": 0.051,
      "step": 183900
    },
    {
      "epoch": 6.451839124793997,
      "grad_norm": 0.20851466059684753,
      "learning_rate": 9.692647561606369e-06,
      "loss": 0.0528,
      "step": 184000
    },
    {
      "epoch": 6.45534555910095,
      "grad_norm": 0.13470977544784546,
      "learning_rate": 9.670731386592561e-06,
      "loss": 0.0515,
      "step": 184100
    },
    {
      "epoch": 6.458851993407904,
      "grad_norm": 0.22667472064495087,
      "learning_rate": 9.648815211578755e-06,
      "loss": 0.0522,
      "step": 184200
    },
    {
      "epoch": 6.4623584277148565,
      "grad_norm": 0.31877583265304565,
      "learning_rate": 9.626899036564947e-06,
      "loss": 0.0551,
      "step": 184300
    },
    {
      "epoch": 6.46586486202181,
      "grad_norm": 0.24977868795394897,
      "learning_rate": 9.60498286155114e-06,
      "loss": 0.0493,
      "step": 184400
    },
    {
      "epoch": 6.469371296328763,
      "grad_norm": 0.1982487291097641,
      "learning_rate": 9.583066686537333e-06,
      "loss": 0.0515,
      "step": 184500
    },
    {
      "epoch": 6.472877730635717,
      "grad_norm": 0.16220198571681976,
      "learning_rate": 9.561150511523526e-06,
      "loss": 0.0509,
      "step": 184600
    },
    {
      "epoch": 6.47638416494267,
      "grad_norm": 0.11631231755018234,
      "learning_rate": 9.539234336509718e-06,
      "loss": 0.0494,
      "step": 184700
    },
    {
      "epoch": 6.479890599249623,
      "grad_norm": 0.3737848699092865,
      "learning_rate": 9.517318161495912e-06,
      "loss": 0.0538,
      "step": 184800
    },
    {
      "epoch": 6.483397033556576,
      "grad_norm": 0.24215610325336456,
      "learning_rate": 9.495401986482104e-06,
      "loss": 0.0493,
      "step": 184900
    },
    {
      "epoch": 6.486903467863529,
      "grad_norm": 0.14927461743354797,
      "learning_rate": 9.473485811468296e-06,
      "loss": 0.05,
      "step": 185000
    },
    {
      "epoch": 6.490409902170483,
      "grad_norm": 0.06774172186851501,
      "learning_rate": 9.45156963645449e-06,
      "loss": 0.049,
      "step": 185100
    },
    {
      "epoch": 6.493916336477436,
      "grad_norm": 0.14449824392795563,
      "learning_rate": 9.429653461440682e-06,
      "loss": 0.0525,
      "step": 185200
    },
    {
      "epoch": 6.4974227707843895,
      "grad_norm": 0.22058095037937164,
      "learning_rate": 9.407737286426875e-06,
      "loss": 0.0542,
      "step": 185300
    },
    {
      "epoch": 6.500929205091342,
      "grad_norm": 0.25050413608551025,
      "learning_rate": 9.385821111413067e-06,
      "loss": 0.0527,
      "step": 185400
    },
    {
      "epoch": 6.504435639398296,
      "grad_norm": 0.4926854074001312,
      "learning_rate": 9.363904936399261e-06,
      "loss": 0.0506,
      "step": 185500
    },
    {
      "epoch": 6.507942073705249,
      "grad_norm": 0.15945583581924438,
      "learning_rate": 9.341988761385453e-06,
      "loss": 0.0491,
      "step": 185600
    },
    {
      "epoch": 6.511448508012203,
      "grad_norm": 0.1514168679714203,
      "learning_rate": 9.320291748121784e-06,
      "loss": 0.0474,
      "step": 185700
    },
    {
      "epoch": 6.5149549423191555,
      "grad_norm": 0.24538639187812805,
      "learning_rate": 9.298375573107976e-06,
      "loss": 0.0515,
      "step": 185800
    },
    {
      "epoch": 6.518461376626109,
      "grad_norm": 0.2971239387989044,
      "learning_rate": 9.27645939809417e-06,
      "loss": 0.0473,
      "step": 185900
    },
    {
      "epoch": 6.521967810933062,
      "grad_norm": 0.3619607985019684,
      "learning_rate": 9.254543223080362e-06,
      "loss": 0.0475,
      "step": 186000
    },
    {
      "epoch": 6.525474245240016,
      "grad_norm": 0.5153419971466064,
      "learning_rate": 9.232627048066556e-06,
      "loss": 0.0514,
      "step": 186100
    },
    {
      "epoch": 6.528980679546969,
      "grad_norm": 0.33075714111328125,
      "learning_rate": 9.210710873052748e-06,
      "loss": 0.0514,
      "step": 186200
    },
    {
      "epoch": 6.532487113853922,
      "grad_norm": 0.1723126769065857,
      "learning_rate": 9.188794698038942e-06,
      "loss": 0.0493,
      "step": 186300
    },
    {
      "epoch": 6.535993548160875,
      "grad_norm": 0.1205267384648323,
      "learning_rate": 9.166878523025134e-06,
      "loss": 0.0489,
      "step": 186400
    },
    {
      "epoch": 6.539499982467828,
      "grad_norm": 0.18835937976837158,
      "learning_rate": 9.144962348011327e-06,
      "loss": 0.0485,
      "step": 186500
    },
    {
      "epoch": 6.543006416774782,
      "grad_norm": 0.22488287091255188,
      "learning_rate": 9.12304617299752e-06,
      "loss": 0.0503,
      "step": 186600
    },
    {
      "epoch": 6.546512851081735,
      "grad_norm": 0.23179414868354797,
      "learning_rate": 9.101129997983713e-06,
      "loss": 0.0458,
      "step": 186700
    },
    {
      "epoch": 6.5500192853886885,
      "grad_norm": 0.09981229901313782,
      "learning_rate": 9.079213822969905e-06,
      "loss": 0.0495,
      "step": 186800
    },
    {
      "epoch": 6.553525719695641,
      "grad_norm": 0.2056240737438202,
      "learning_rate": 9.057297647956097e-06,
      "loss": 0.0486,
      "step": 186900
    },
    {
      "epoch": 6.557032154002595,
      "grad_norm": 0.2822780907154083,
      "learning_rate": 9.03538147294229e-06,
      "loss": 0.0536,
      "step": 187000
    },
    {
      "epoch": 6.560538588309548,
      "grad_norm": 0.14509187638759613,
      "learning_rate": 9.013465297928483e-06,
      "loss": 0.0471,
      "step": 187100
    },
    {
      "epoch": 6.564045022616501,
      "grad_norm": 0.1070268452167511,
      "learning_rate": 8.991549122914676e-06,
      "loss": 0.0524,
      "step": 187200
    },
    {
      "epoch": 6.5675514569234545,
      "grad_norm": 0.29549068212509155,
      "learning_rate": 8.969632947900868e-06,
      "loss": 0.0511,
      "step": 187300
    },
    {
      "epoch": 6.571057891230408,
      "grad_norm": 0.12387243658304214,
      "learning_rate": 8.947716772887062e-06,
      "loss": 0.0478,
      "step": 187400
    },
    {
      "epoch": 6.574564325537361,
      "grad_norm": 0.18121491372585297,
      "learning_rate": 8.925800597873254e-06,
      "loss": 0.0509,
      "step": 187500
    },
    {
      "epoch": 6.578070759844314,
      "grad_norm": 0.3216841220855713,
      "learning_rate": 8.903884422859448e-06,
      "loss": 0.0499,
      "step": 187600
    },
    {
      "epoch": 6.581577194151268,
      "grad_norm": 0.14294065535068512,
      "learning_rate": 8.882187409595779e-06,
      "loss": 0.053,
      "step": 187700
    },
    {
      "epoch": 6.585083628458221,
      "grad_norm": 0.12967129051685333,
      "learning_rate": 8.860271234581971e-06,
      "loss": 0.0487,
      "step": 187800
    },
    {
      "epoch": 6.588590062765174,
      "grad_norm": 0.27133047580718994,
      "learning_rate": 8.838355059568163e-06,
      "loss": 0.0551,
      "step": 187900
    },
    {
      "epoch": 6.592096497072127,
      "grad_norm": 0.14081323146820068,
      "learning_rate": 8.816438884554357e-06,
      "loss": 0.0478,
      "step": 188000
    },
    {
      "epoch": 6.595602931379081,
      "grad_norm": 0.1557428240776062,
      "learning_rate": 8.794522709540549e-06,
      "loss": 0.0517,
      "step": 188100
    },
    {
      "epoch": 6.599109365686034,
      "grad_norm": 0.2586781680583954,
      "learning_rate": 8.772606534526743e-06,
      "loss": 0.0478,
      "step": 188200
    },
    {
      "epoch": 6.6026157999929875,
      "grad_norm": 0.28105849027633667,
      "learning_rate": 8.750690359512935e-06,
      "loss": 0.0493,
      "step": 188300
    },
    {
      "epoch": 6.60612223429994,
      "grad_norm": 0.32420647144317627,
      "learning_rate": 8.728774184499128e-06,
      "loss": 0.0494,
      "step": 188400
    },
    {
      "epoch": 6.609628668606893,
      "grad_norm": 0.21086302399635315,
      "learning_rate": 8.70685800948532e-06,
      "loss": 0.053,
      "step": 188500
    },
    {
      "epoch": 6.613135102913847,
      "grad_norm": 0.11712168902158737,
      "learning_rate": 8.684941834471514e-06,
      "loss": 0.0485,
      "step": 188600
    },
    {
      "epoch": 6.6166415372208,
      "grad_norm": 0.2422567903995514,
      "learning_rate": 8.663025659457706e-06,
      "loss": 0.0495,
      "step": 188700
    },
    {
      "epoch": 6.620147971527754,
      "grad_norm": 0.24409520626068115,
      "learning_rate": 8.6411094844439e-06,
      "loss": 0.0501,
      "step": 188800
    },
    {
      "epoch": 6.623654405834706,
      "grad_norm": 0.20693890750408173,
      "learning_rate": 8.619193309430092e-06,
      "loss": 0.0487,
      "step": 188900
    },
    {
      "epoch": 6.62716084014166,
      "grad_norm": 0.2717572748661041,
      "learning_rate": 8.597277134416284e-06,
      "loss": 0.0522,
      "step": 189000
    },
    {
      "epoch": 6.630667274448613,
      "grad_norm": 0.2153642177581787,
      "learning_rate": 8.575360959402477e-06,
      "loss": 0.0496,
      "step": 189100
    },
    {
      "epoch": 6.634173708755567,
      "grad_norm": 0.24829396605491638,
      "learning_rate": 8.55344478438867e-06,
      "loss": 0.0497,
      "step": 189200
    },
    {
      "epoch": 6.63768014306252,
      "grad_norm": 0.2650721073150635,
      "learning_rate": 8.531528609374863e-06,
      "loss": 0.0509,
      "step": 189300
    },
    {
      "epoch": 6.6411865773694725,
      "grad_norm": 0.24759605526924133,
      "learning_rate": 8.509612434361055e-06,
      "loss": 0.0509,
      "step": 189400
    },
    {
      "epoch": 6.644693011676426,
      "grad_norm": 0.16208067536354065,
      "learning_rate": 8.487696259347249e-06,
      "loss": 0.0489,
      "step": 189500
    },
    {
      "epoch": 6.64819944598338,
      "grad_norm": 0.1417563259601593,
      "learning_rate": 8.465780084333443e-06,
      "loss": 0.0533,
      "step": 189600
    },
    {
      "epoch": 6.651705880290333,
      "grad_norm": 0.29466262459754944,
      "learning_rate": 8.443863909319635e-06,
      "loss": 0.0506,
      "step": 189700
    },
    {
      "epoch": 6.655212314597286,
      "grad_norm": 0.3923066258430481,
      "learning_rate": 8.422166896055964e-06,
      "loss": 0.0528,
      "step": 189800
    },
    {
      "epoch": 6.658718748904239,
      "grad_norm": 0.29584619402885437,
      "learning_rate": 8.400250721042158e-06,
      "loss": 0.0488,
      "step": 189900
    },
    {
      "epoch": 6.662225183211192,
      "grad_norm": 0.1536659151315689,
      "learning_rate": 8.37833454602835e-06,
      "loss": 0.054,
      "step": 190000
    },
    {
      "epoch": 6.665731617518146,
      "grad_norm": 0.13423961400985718,
      "learning_rate": 8.356418371014545e-06,
      "loss": 0.0508,
      "step": 190100
    },
    {
      "epoch": 6.669238051825099,
      "grad_norm": 0.16140857338905334,
      "learning_rate": 8.334502196000737e-06,
      "loss": 0.0495,
      "step": 190200
    },
    {
      "epoch": 6.672744486132053,
      "grad_norm": 0.08594714105129242,
      "learning_rate": 8.312586020986931e-06,
      "loss": 0.0507,
      "step": 190300
    },
    {
      "epoch": 6.6762509204390055,
      "grad_norm": 0.16467787325382233,
      "learning_rate": 8.290669845973123e-06,
      "loss": 0.0495,
      "step": 190400
    },
    {
      "epoch": 6.679757354745959,
      "grad_norm": 0.22179187834262848,
      "learning_rate": 8.268753670959315e-06,
      "loss": 0.049,
      "step": 190500
    },
    {
      "epoch": 6.683263789052912,
      "grad_norm": 0.23314857482910156,
      "learning_rate": 8.246837495945509e-06,
      "loss": 0.0513,
      "step": 190600
    },
    {
      "epoch": 6.686770223359865,
      "grad_norm": 0.23133954405784607,
      "learning_rate": 8.2249213209317e-06,
      "loss": 0.0477,
      "step": 190700
    },
    {
      "epoch": 6.690276657666819,
      "grad_norm": 0.23476086556911469,
      "learning_rate": 8.203005145917894e-06,
      "loss": 0.0514,
      "step": 190800
    },
    {
      "epoch": 6.6937830919737715,
      "grad_norm": 0.1618795245885849,
      "learning_rate": 8.181088970904086e-06,
      "loss": 0.0482,
      "step": 190900
    },
    {
      "epoch": 6.697289526280725,
      "grad_norm": 0.1782301664352417,
      "learning_rate": 8.15917279589028e-06,
      "loss": 0.0492,
      "step": 191000
    },
    {
      "epoch": 6.700795960587678,
      "grad_norm": 0.10845967382192612,
      "learning_rate": 8.137256620876472e-06,
      "loss": 0.0531,
      "step": 191100
    },
    {
      "epoch": 6.704302394894632,
      "grad_norm": 0.23386532068252563,
      "learning_rate": 8.115340445862666e-06,
      "loss": 0.0519,
      "step": 191200
    },
    {
      "epoch": 6.707808829201585,
      "grad_norm": 0.13285040855407715,
      "learning_rate": 8.093424270848858e-06,
      "loss": 0.0509,
      "step": 191300
    },
    {
      "epoch": 6.7113152635085385,
      "grad_norm": 0.2343958020210266,
      "learning_rate": 8.071508095835052e-06,
      "loss": 0.0481,
      "step": 191400
    },
    {
      "epoch": 6.714821697815491,
      "grad_norm": 0.2561945915222168,
      "learning_rate": 8.049591920821244e-06,
      "loss": 0.0479,
      "step": 191500
    },
    {
      "epoch": 6.718328132122445,
      "grad_norm": 0.12495900690555573,
      "learning_rate": 8.027675745807436e-06,
      "loss": 0.0525,
      "step": 191600
    },
    {
      "epoch": 6.721834566429398,
      "grad_norm": 0.37477782368659973,
      "learning_rate": 8.00575957079363e-06,
      "loss": 0.0503,
      "step": 191700
    },
    {
      "epoch": 6.725341000736352,
      "grad_norm": 0.3536023199558258,
      "learning_rate": 7.98406255752996e-06,
      "loss": 0.0533,
      "step": 191800
    },
    {
      "epoch": 6.7288474350433045,
      "grad_norm": 0.15642745792865753,
      "learning_rate": 7.962146382516153e-06,
      "loss": 0.0468,
      "step": 191900
    },
    {
      "epoch": 6.732353869350257,
      "grad_norm": 0.25522464513778687,
      "learning_rate": 7.940230207502346e-06,
      "loss": 0.0489,
      "step": 192000
    },
    {
      "epoch": 6.735860303657211,
      "grad_norm": 0.2081901878118515,
      "learning_rate": 7.918314032488538e-06,
      "loss": 0.0482,
      "step": 192100
    },
    {
      "epoch": 6.739366737964164,
      "grad_norm": 0.2632383406162262,
      "learning_rate": 7.896397857474732e-06,
      "loss": 0.0497,
      "step": 192200
    },
    {
      "epoch": 6.742873172271118,
      "grad_norm": 0.1259741187095642,
      "learning_rate": 7.874481682460924e-06,
      "loss": 0.0458,
      "step": 192300
    },
    {
      "epoch": 6.746379606578071,
      "grad_norm": 0.30080386996269226,
      "learning_rate": 7.852565507447118e-06,
      "loss": 0.0469,
      "step": 192400
    },
    {
      "epoch": 6.749886040885024,
      "grad_norm": 0.09894180297851562,
      "learning_rate": 7.83064933243331e-06,
      "loss": 0.0509,
      "step": 192500
    },
    {
      "epoch": 6.753392475191977,
      "grad_norm": 0.4294307231903076,
      "learning_rate": 7.808733157419502e-06,
      "loss": 0.0538,
      "step": 192600
    },
    {
      "epoch": 6.756898909498931,
      "grad_norm": 0.3168138861656189,
      "learning_rate": 7.786816982405695e-06,
      "loss": 0.0497,
      "step": 192700
    },
    {
      "epoch": 6.760405343805884,
      "grad_norm": 0.19056963920593262,
      "learning_rate": 7.764900807391887e-06,
      "loss": 0.0502,
      "step": 192800
    },
    {
      "epoch": 6.763911778112837,
      "grad_norm": 0.20093105733394623,
      "learning_rate": 7.742984632378081e-06,
      "loss": 0.0493,
      "step": 192900
    },
    {
      "epoch": 6.76741821241979,
      "grad_norm": 0.3543168604373932,
      "learning_rate": 7.721068457364273e-06,
      "loss": 0.0528,
      "step": 193000
    },
    {
      "epoch": 6.770924646726743,
      "grad_norm": 0.13681083917617798,
      "learning_rate": 7.699152282350467e-06,
      "loss": 0.0491,
      "step": 193100
    },
    {
      "epoch": 6.774431081033697,
      "grad_norm": 0.3483808636665344,
      "learning_rate": 7.677236107336659e-06,
      "loss": 0.0489,
      "step": 193200
    },
    {
      "epoch": 6.77793751534065,
      "grad_norm": 0.13462769985198975,
      "learning_rate": 7.655319932322853e-06,
      "loss": 0.048,
      "step": 193300
    },
    {
      "epoch": 6.7814439496476036,
      "grad_norm": 0.1923353374004364,
      "learning_rate": 7.633403757309045e-06,
      "loss": 0.0481,
      "step": 193400
    },
    {
      "epoch": 6.784950383954556,
      "grad_norm": 0.23990647494792938,
      "learning_rate": 7.6114875822952375e-06,
      "loss": 0.0482,
      "step": 193500
    },
    {
      "epoch": 6.78845681826151,
      "grad_norm": 0.3423519432544708,
      "learning_rate": 7.58957140728143e-06,
      "loss": 0.0472,
      "step": 193600
    },
    {
      "epoch": 6.791963252568463,
      "grad_norm": 0.19374775886535645,
      "learning_rate": 7.567655232267623e-06,
      "loss": 0.0501,
      "step": 193700
    },
    {
      "epoch": 6.795469686875417,
      "grad_norm": 0.2052849978208542,
      "learning_rate": 7.545739057253816e-06,
      "loss": 0.0502,
      "step": 193800
    },
    {
      "epoch": 6.79897612118237,
      "grad_norm": 0.1649644374847412,
      "learning_rate": 7.523822882240009e-06,
      "loss": 0.0515,
      "step": 193900
    },
    {
      "epoch": 6.802482555489323,
      "grad_norm": 0.26178988814353943,
      "learning_rate": 7.501906707226202e-06,
      "loss": 0.052,
      "step": 194000
    },
    {
      "epoch": 6.805988989796276,
      "grad_norm": 0.08653915673494339,
      "learning_rate": 7.479990532212394e-06,
      "loss": 0.0479,
      "step": 194100
    },
    {
      "epoch": 6.809495424103229,
      "grad_norm": 0.15206636488437653,
      "learning_rate": 7.458074357198587e-06,
      "loss": 0.0511,
      "step": 194200
    },
    {
      "epoch": 6.813001858410183,
      "grad_norm": 0.07557742297649384,
      "learning_rate": 7.43615818218478e-06,
      "loss": 0.0464,
      "step": 194300
    },
    {
      "epoch": 6.816508292717136,
      "grad_norm": 0.2634008526802063,
      "learning_rate": 7.414461168921111e-06,
      "loss": 0.0482,
      "step": 194400
    },
    {
      "epoch": 6.820014727024089,
      "grad_norm": 0.1968730241060257,
      "learning_rate": 7.392544993907304e-06,
      "loss": 0.0499,
      "step": 194500
    },
    {
      "epoch": 6.823521161331042,
      "grad_norm": 0.31457000970840454,
      "learning_rate": 7.3706288188934964e-06,
      "loss": 0.0496,
      "step": 194600
    },
    {
      "epoch": 6.827027595637996,
      "grad_norm": 0.16513921320438385,
      "learning_rate": 7.348712643879689e-06,
      "loss": 0.0498,
      "step": 194700
    },
    {
      "epoch": 6.830534029944949,
      "grad_norm": 0.4184012711048126,
      "learning_rate": 7.326796468865882e-06,
      "loss": 0.0496,
      "step": 194800
    },
    {
      "epoch": 6.834040464251903,
      "grad_norm": 0.11144321411848068,
      "learning_rate": 7.304880293852075e-06,
      "loss": 0.0501,
      "step": 194900
    },
    {
      "epoch": 6.8375468985588554,
      "grad_norm": 0.17364175617694855,
      "learning_rate": 7.282964118838267e-06,
      "loss": 0.0482,
      "step": 195000
    },
    {
      "epoch": 6.841053332865808,
      "grad_norm": 0.2305193841457367,
      "learning_rate": 7.26104794382446e-06,
      "loss": 0.0467,
      "step": 195100
    },
    {
      "epoch": 6.844559767172762,
      "grad_norm": 0.29854023456573486,
      "learning_rate": 7.239131768810653e-06,
      "loss": 0.0526,
      "step": 195200
    },
    {
      "epoch": 6.848066201479715,
      "grad_norm": 0.31174996495246887,
      "learning_rate": 7.217215593796846e-06,
      "loss": 0.0466,
      "step": 195300
    },
    {
      "epoch": 6.851572635786669,
      "grad_norm": 0.17709511518478394,
      "learning_rate": 7.1952994187830385e-06,
      "loss": 0.0523,
      "step": 195400
    },
    {
      "epoch": 6.8550790700936215,
      "grad_norm": 0.21201378107070923,
      "learning_rate": 7.173383243769231e-06,
      "loss": 0.047,
      "step": 195500
    },
    {
      "epoch": 6.858585504400575,
      "grad_norm": 0.2137889266014099,
      "learning_rate": 7.151467068755424e-06,
      "loss": 0.0501,
      "step": 195600
    },
    {
      "epoch": 6.862091938707528,
      "grad_norm": 0.23070211708545685,
      "learning_rate": 7.129550893741617e-06,
      "loss": 0.0505,
      "step": 195700
    },
    {
      "epoch": 6.865598373014482,
      "grad_norm": 0.185043066740036,
      "learning_rate": 7.10763471872781e-06,
      "loss": 0.0525,
      "step": 195800
    },
    {
      "epoch": 6.869104807321435,
      "grad_norm": 0.16774031519889832,
      "learning_rate": 7.085718543714003e-06,
      "loss": 0.0482,
      "step": 195900
    },
    {
      "epoch": 6.872611241628388,
      "grad_norm": 0.06559675186872482,
      "learning_rate": 7.063802368700196e-06,
      "loss": 0.0501,
      "step": 196000
    },
    {
      "epoch": 6.876117675935341,
      "grad_norm": 0.23114249110221863,
      "learning_rate": 7.041886193686388e-06,
      "loss": 0.0499,
      "step": 196100
    },
    {
      "epoch": 6.879624110242295,
      "grad_norm": 0.20192143321037292,
      "learning_rate": 7.019970018672581e-06,
      "loss": 0.0513,
      "step": 196200
    },
    {
      "epoch": 6.883130544549248,
      "grad_norm": 0.31906694173812866,
      "learning_rate": 6.9980538436587734e-06,
      "loss": 0.0493,
      "step": 196300
    },
    {
      "epoch": 6.886636978856201,
      "grad_norm": 0.14746716618537903,
      "learning_rate": 6.976356830395105e-06,
      "loss": 0.0475,
      "step": 196400
    },
    {
      "epoch": 6.8901434131631545,
      "grad_norm": 0.18108496069908142,
      "learning_rate": 6.9544406553812974e-06,
      "loss": 0.0508,
      "step": 196500
    },
    {
      "epoch": 6.893649847470107,
      "grad_norm": 0.38790053129196167,
      "learning_rate": 6.93252448036749e-06,
      "loss": 0.051,
      "step": 196600
    },
    {
      "epoch": 6.897156281777061,
      "grad_norm": 0.17727422714233398,
      "learning_rate": 6.9108274671038214e-06,
      "loss": 0.0505,
      "step": 196700
    },
    {
      "epoch": 6.900662716084014,
      "grad_norm": 0.14524951577186584,
      "learning_rate": 6.888911292090014e-06,
      "loss": 0.0513,
      "step": 196800
    },
    {
      "epoch": 6.904169150390968,
      "grad_norm": 0.3468100428581238,
      "learning_rate": 6.866995117076206e-06,
      "loss": 0.053,
      "step": 196900
    },
    {
      "epoch": 6.9076755846979205,
      "grad_norm": 0.11757570505142212,
      "learning_rate": 6.845078942062399e-06,
      "loss": 0.0507,
      "step": 197000
    },
    {
      "epoch": 6.911182019004874,
      "grad_norm": 0.3516451418399811,
      "learning_rate": 6.823162767048592e-06,
      "loss": 0.0531,
      "step": 197100
    },
    {
      "epoch": 6.914688453311827,
      "grad_norm": 0.26591038703918457,
      "learning_rate": 6.801246592034785e-06,
      "loss": 0.0519,
      "step": 197200
    },
    {
      "epoch": 6.91819488761878,
      "grad_norm": 0.1909705251455307,
      "learning_rate": 6.779330417020978e-06,
      "loss": 0.055,
      "step": 197300
    },
    {
      "epoch": 6.921701321925734,
      "grad_norm": 0.4487670063972473,
      "learning_rate": 6.757414242007171e-06,
      "loss": 0.0484,
      "step": 197400
    },
    {
      "epoch": 6.9252077562326875,
      "grad_norm": 0.17059871554374695,
      "learning_rate": 6.7354980669933635e-06,
      "loss": 0.0523,
      "step": 197500
    },
    {
      "epoch": 6.92871419053964,
      "grad_norm": 0.1508915275335312,
      "learning_rate": 6.713581891979556e-06,
      "loss": 0.0508,
      "step": 197600
    },
    {
      "epoch": 6.932220624846593,
      "grad_norm": 0.15997973084449768,
      "learning_rate": 6.69166571696575e-06,
      "loss": 0.0499,
      "step": 197700
    },
    {
      "epoch": 6.935727059153547,
      "grad_norm": 0.1563093364238739,
      "learning_rate": 6.669749541951943e-06,
      "loss": 0.0519,
      "step": 197800
    },
    {
      "epoch": 6.9392334934605,
      "grad_norm": 0.2794976532459259,
      "learning_rate": 6.647833366938136e-06,
      "loss": 0.0488,
      "step": 197900
    },
    {
      "epoch": 6.9427399277674535,
      "grad_norm": 0.20945698022842407,
      "learning_rate": 6.625917191924329e-06,
      "loss": 0.0456,
      "step": 198000
    },
    {
      "epoch": 6.946246362074406,
      "grad_norm": 0.13300444185733795,
      "learning_rate": 6.6040010169105215e-06,
      "loss": 0.0503,
      "step": 198100
    },
    {
      "epoch": 6.94975279638136,
      "grad_norm": 0.11541645228862762,
      "learning_rate": 6.582084841896714e-06,
      "loss": 0.0464,
      "step": 198200
    },
    {
      "epoch": 6.953259230688313,
      "grad_norm": 0.14764614403247833,
      "learning_rate": 6.560168666882907e-06,
      "loss": 0.0508,
      "step": 198300
    },
    {
      "epoch": 6.956765664995267,
      "grad_norm": 0.20529362559318542,
      "learning_rate": 6.5382524918691e-06,
      "loss": 0.0511,
      "step": 198400
    },
    {
      "epoch": 6.96027209930222,
      "grad_norm": 0.08305378258228302,
      "learning_rate": 6.516336316855293e-06,
      "loss": 0.0485,
      "step": 198500
    },
    {
      "epoch": 6.963778533609172,
      "grad_norm": 0.12051532417535782,
      "learning_rate": 6.494420141841486e-06,
      "loss": 0.0528,
      "step": 198600
    },
    {
      "epoch": 6.967284967916126,
      "grad_norm": 0.19575360417366028,
      "learning_rate": 6.472503966827678e-06,
      "loss": 0.0508,
      "step": 198700
    },
    {
      "epoch": 6.970791402223079,
      "grad_norm": 0.1559123545885086,
      "learning_rate": 6.450587791813871e-06,
      "loss": 0.0531,
      "step": 198800
    },
    {
      "epoch": 6.974297836530033,
      "grad_norm": 0.19417019188404083,
      "learning_rate": 6.428671616800064e-06,
      "loss": 0.0464,
      "step": 198900
    },
    {
      "epoch": 6.977804270836986,
      "grad_norm": 0.1419597715139389,
      "learning_rate": 6.4067554417862565e-06,
      "loss": 0.0508,
      "step": 199000
    },
    {
      "epoch": 6.981310705143939,
      "grad_norm": 0.12599292397499084,
      "learning_rate": 6.384839266772449e-06,
      "loss": 0.0501,
      "step": 199100
    },
    {
      "epoch": 6.984817139450892,
      "grad_norm": 0.3231828212738037,
      "learning_rate": 6.362923091758642e-06,
      "loss": 0.0512,
      "step": 199200
    },
    {
      "epoch": 6.988323573757846,
      "grad_norm": 0.17615775763988495,
      "learning_rate": 6.341006916744835e-06,
      "loss": 0.0494,
      "step": 199300
    },
    {
      "epoch": 6.991830008064799,
      "grad_norm": 0.16816461086273193,
      "learning_rate": 6.319090741731028e-06,
      "loss": 0.0531,
      "step": 199400
    },
    {
      "epoch": 6.995336442371752,
      "grad_norm": 0.4017657935619354,
      "learning_rate": 6.297174566717221e-06,
      "loss": 0.0461,
      "step": 199500
    },
    {
      "epoch": 6.998842876678705,
      "grad_norm": 0.14688001573085785,
      "learning_rate": 6.275258391703414e-06,
      "loss": 0.0551,
      "step": 199600
    },
    {
      "epoch": 7.0,
      "eval_accuracy_macro_0.5": 0.9794849753379822,
      "eval_accuracy_micro_0.5": 0.9794849753379822,
      "eval_accuracy_weighted_0.5": 0.9693699479103088,
      "eval_f1_macro_0.5": 0.6876923441886902,
      "eval_f1_macro_0.6": 0.6591458320617676,
      "eval_f1_macro_0.7": 0.6130350232124329,
      "eval_f1_macro_0.8": 0.4219583570957184,
      "eval_f1_micro_0.5": 0.7278887629508972,
      "eval_f1_micro_0.6": 0.7081713080406189,
      "eval_f1_micro_0.7": 0.6712306141853333,
      "eval_f1_micro_0.8": 0.6062461137771606,
      "eval_f1_micro_0.9": 0.4750719964504242,
      "eval_f1_weighted_0.5": 0.7190386056900024,
      "eval_f1_weighted_0.6": 0.6934046149253845,
      "eval_f1_weighted_0.7": 0.6489620208740234,
      "eval_f1_weighted_0.8": 0.4385851323604584,
      "eval_loss": 0.04689200967550278,
      "eval_runtime": 142.8724,
      "eval_samples_per_second": 399.006,
      "eval_steps_per_second": 49.877,
      "step": 199633
    }
  ],
  "logging_steps": 100,
  "max_steps": 228152,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5059641380259072.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
