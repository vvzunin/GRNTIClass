{
  "best_metric": 0.8629751205444336,
  "best_model_checkpoint": "aleksandr-test-user-bge-m3/model bert lora level 1/checkpoint-101801",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 101801,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00687616035205941,
      "grad_norm": 0.2821318805217743,
      "learning_rate": 4.996131827324772e-05,
      "loss": 0.2391,
      "step": 100
    },
    {
      "epoch": 0.01375232070411882,
      "grad_norm": 0.24919112026691437,
      "learning_rate": 4.9918338576856295e-05,
      "loss": 0.1311,
      "step": 200
    },
    {
      "epoch": 0.02062848105617823,
      "grad_norm": 0.32881203293800354,
      "learning_rate": 4.9875358880464876e-05,
      "loss": 0.1218,
      "step": 300
    },
    {
      "epoch": 0.02750464140823764,
      "grad_norm": 0.24443885684013367,
      "learning_rate": 4.983237918407345e-05,
      "loss": 0.1051,
      "step": 400
    },
    {
      "epoch": 0.03438080176029705,
      "grad_norm": 0.2794269919395447,
      "learning_rate": 4.978939948768202e-05,
      "loss": 0.0927,
      "step": 500
    },
    {
      "epoch": 0.04125696211235646,
      "grad_norm": 0.3534920811653137,
      "learning_rate": 4.97464197912906e-05,
      "loss": 0.0829,
      "step": 600
    },
    {
      "epoch": 0.04813312246441587,
      "grad_norm": 0.23768649995326996,
      "learning_rate": 4.970344009489917e-05,
      "loss": 0.0757,
      "step": 700
    },
    {
      "epoch": 0.05500928281647528,
      "grad_norm": 0.1699337512254715,
      "learning_rate": 4.9660460398507745e-05,
      "loss": 0.0716,
      "step": 800
    },
    {
      "epoch": 0.06188544316853469,
      "grad_norm": 0.2364499270915985,
      "learning_rate": 4.961748070211632e-05,
      "loss": 0.0716,
      "step": 900
    },
    {
      "epoch": 0.0687616035205941,
      "grad_norm": 0.2786012291908264,
      "learning_rate": 4.95745010057249e-05,
      "loss": 0.0656,
      "step": 1000
    },
    {
      "epoch": 0.07563776387265352,
      "grad_norm": 0.17715056240558624,
      "learning_rate": 4.9531521309333474e-05,
      "loss": 0.0657,
      "step": 1100
    },
    {
      "epoch": 0.08251392422471292,
      "grad_norm": 0.2747783660888672,
      "learning_rate": 4.948854161294205e-05,
      "loss": 0.0626,
      "step": 1200
    },
    {
      "epoch": 0.08939008457677233,
      "grad_norm": 0.3030909299850464,
      "learning_rate": 4.944556191655063e-05,
      "loss": 0.0636,
      "step": 1300
    },
    {
      "epoch": 0.09626624492883173,
      "grad_norm": 0.24266347289085388,
      "learning_rate": 4.94025822201592e-05,
      "loss": 0.0603,
      "step": 1400
    },
    {
      "epoch": 0.10314240528089115,
      "grad_norm": 0.3037450611591339,
      "learning_rate": 4.9359602523767776e-05,
      "loss": 0.0597,
      "step": 1500
    },
    {
      "epoch": 0.11001856563295057,
      "grad_norm": 0.274652898311615,
      "learning_rate": 4.931662282737635e-05,
      "loss": 0.0611,
      "step": 1600
    },
    {
      "epoch": 0.11689472598500997,
      "grad_norm": 0.20116101205348969,
      "learning_rate": 4.9273643130984924e-05,
      "loss": 0.0582,
      "step": 1700
    },
    {
      "epoch": 0.12377088633706938,
      "grad_norm": 0.18737301230430603,
      "learning_rate": 4.92306634345935e-05,
      "loss": 0.056,
      "step": 1800
    },
    {
      "epoch": 0.1306470466891288,
      "grad_norm": 0.2201353907585144,
      "learning_rate": 4.918768373820208e-05,
      "loss": 0.0551,
      "step": 1900
    },
    {
      "epoch": 0.1375232070411882,
      "grad_norm": 0.33275851607322693,
      "learning_rate": 4.914470404181065e-05,
      "loss": 0.0538,
      "step": 2000
    },
    {
      "epoch": 0.1443993673932476,
      "grad_norm": 0.3153029978275299,
      "learning_rate": 4.9101724345419226e-05,
      "loss": 0.0554,
      "step": 2100
    },
    {
      "epoch": 0.15127552774530703,
      "grad_norm": 0.2940288484096527,
      "learning_rate": 4.90587446490278e-05,
      "loss": 0.0554,
      "step": 2200
    },
    {
      "epoch": 0.15815168809736643,
      "grad_norm": 0.30285200476646423,
      "learning_rate": 4.901576495263638e-05,
      "loss": 0.0544,
      "step": 2300
    },
    {
      "epoch": 0.16502784844942583,
      "grad_norm": 0.1475108414888382,
      "learning_rate": 4.8972785256244955e-05,
      "loss": 0.0546,
      "step": 2400
    },
    {
      "epoch": 0.17190400880148526,
      "grad_norm": 0.22863654792308807,
      "learning_rate": 4.892980555985353e-05,
      "loss": 0.0517,
      "step": 2500
    },
    {
      "epoch": 0.17878016915354467,
      "grad_norm": 0.24616463482379913,
      "learning_rate": 4.88868258634621e-05,
      "loss": 0.0525,
      "step": 2600
    },
    {
      "epoch": 0.18565632950560407,
      "grad_norm": 0.18510568141937256,
      "learning_rate": 4.8843846167070677e-05,
      "loss": 0.0545,
      "step": 2700
    },
    {
      "epoch": 0.19253248985766347,
      "grad_norm": 0.15392248332500458,
      "learning_rate": 4.880086647067925e-05,
      "loss": 0.052,
      "step": 2800
    },
    {
      "epoch": 0.1994086502097229,
      "grad_norm": 0.13649484515190125,
      "learning_rate": 4.875788677428783e-05,
      "loss": 0.0508,
      "step": 2900
    },
    {
      "epoch": 0.2062848105617823,
      "grad_norm": 0.19723878800868988,
      "learning_rate": 4.8714907077896405e-05,
      "loss": 0.0496,
      "step": 3000
    },
    {
      "epoch": 0.2131609709138417,
      "grad_norm": 0.25643277168273926,
      "learning_rate": 4.867192738150498e-05,
      "loss": 0.048,
      "step": 3100
    },
    {
      "epoch": 0.22003713126590113,
      "grad_norm": 0.10103421658277512,
      "learning_rate": 4.862894768511356e-05,
      "loss": 0.0515,
      "step": 3200
    },
    {
      "epoch": 0.22691329161796053,
      "grad_norm": 0.12475414574146271,
      "learning_rate": 4.8585967988722134e-05,
      "loss": 0.0507,
      "step": 3300
    },
    {
      "epoch": 0.23378945197001993,
      "grad_norm": 0.3111993670463562,
      "learning_rate": 4.854298829233071e-05,
      "loss": 0.0512,
      "step": 3400
    },
    {
      "epoch": 0.24066561232207936,
      "grad_norm": 0.22473205626010895,
      "learning_rate": 4.850000859593928e-05,
      "loss": 0.051,
      "step": 3500
    },
    {
      "epoch": 0.24754177267413877,
      "grad_norm": 0.20249874889850616,
      "learning_rate": 4.8457028899547855e-05,
      "loss": 0.0505,
      "step": 3600
    },
    {
      "epoch": 0.2544179330261982,
      "grad_norm": 0.22047966718673706,
      "learning_rate": 4.841404920315643e-05,
      "loss": 0.0467,
      "step": 3700
    },
    {
      "epoch": 0.2612940933782576,
      "grad_norm": 0.23854005336761475,
      "learning_rate": 4.8371069506765e-05,
      "loss": 0.0497,
      "step": 3800
    },
    {
      "epoch": 0.268170253730317,
      "grad_norm": 0.18691392242908478,
      "learning_rate": 4.8328089810373584e-05,
      "loss": 0.0492,
      "step": 3900
    },
    {
      "epoch": 0.2750464140823764,
      "grad_norm": 0.26627591252326965,
      "learning_rate": 4.828511011398216e-05,
      "loss": 0.0514,
      "step": 4000
    },
    {
      "epoch": 0.2819225744344358,
      "grad_norm": 0.2531837821006775,
      "learning_rate": 4.824213041759073e-05,
      "loss": 0.0486,
      "step": 4100
    },
    {
      "epoch": 0.2887987347864952,
      "grad_norm": 0.2545351982116699,
      "learning_rate": 4.819915072119931e-05,
      "loss": 0.05,
      "step": 4200
    },
    {
      "epoch": 0.2956748951385546,
      "grad_norm": 0.21930080652236938,
      "learning_rate": 4.8156171024807886e-05,
      "loss": 0.045,
      "step": 4300
    },
    {
      "epoch": 0.30255105549061406,
      "grad_norm": 0.1932736039161682,
      "learning_rate": 4.811319132841646e-05,
      "loss": 0.0432,
      "step": 4400
    },
    {
      "epoch": 0.30942721584267346,
      "grad_norm": 0.24535468220710754,
      "learning_rate": 4.8070211632025034e-05,
      "loss": 0.0462,
      "step": 4500
    },
    {
      "epoch": 0.31630337619473287,
      "grad_norm": 0.22676238417625427,
      "learning_rate": 4.802723193563361e-05,
      "loss": 0.0464,
      "step": 4600
    },
    {
      "epoch": 0.32317953654679227,
      "grad_norm": 0.29382210969924927,
      "learning_rate": 4.798425223924218e-05,
      "loss": 0.0468,
      "step": 4700
    },
    {
      "epoch": 0.33005569689885167,
      "grad_norm": 0.2982441186904907,
      "learning_rate": 4.7941272542850756e-05,
      "loss": 0.0464,
      "step": 4800
    },
    {
      "epoch": 0.33693185725091107,
      "grad_norm": 0.22328542172908783,
      "learning_rate": 4.7898292846459336e-05,
      "loss": 0.0454,
      "step": 4900
    },
    {
      "epoch": 0.34380801760297053,
      "grad_norm": 0.1355314403772354,
      "learning_rate": 4.785531315006791e-05,
      "loss": 0.0435,
      "step": 5000
    },
    {
      "epoch": 0.35068417795502993,
      "grad_norm": 0.16210779547691345,
      "learning_rate": 4.7812333453676484e-05,
      "loss": 0.0467,
      "step": 5100
    },
    {
      "epoch": 0.35756033830708933,
      "grad_norm": 0.18686969578266144,
      "learning_rate": 4.7769353757285065e-05,
      "loss": 0.0444,
      "step": 5200
    },
    {
      "epoch": 0.36443649865914873,
      "grad_norm": 0.21319682896137238,
      "learning_rate": 4.772637406089364e-05,
      "loss": 0.0484,
      "step": 5300
    },
    {
      "epoch": 0.37131265901120813,
      "grad_norm": 0.2789630591869354,
      "learning_rate": 4.768339436450221e-05,
      "loss": 0.0425,
      "step": 5400
    },
    {
      "epoch": 0.37818881936326754,
      "grad_norm": 0.23054347932338715,
      "learning_rate": 4.764041466811079e-05,
      "loss": 0.0447,
      "step": 5500
    },
    {
      "epoch": 0.38506497971532694,
      "grad_norm": 0.14029663801193237,
      "learning_rate": 4.759743497171936e-05,
      "loss": 0.0459,
      "step": 5600
    },
    {
      "epoch": 0.3919411400673864,
      "grad_norm": 0.25329461693763733,
      "learning_rate": 4.7554455275327935e-05,
      "loss": 0.0436,
      "step": 5700
    },
    {
      "epoch": 0.3988173004194458,
      "grad_norm": 0.16356848180294037,
      "learning_rate": 4.7511475578936515e-05,
      "loss": 0.0463,
      "step": 5800
    },
    {
      "epoch": 0.4056934607715052,
      "grad_norm": 0.26964834332466125,
      "learning_rate": 4.746849588254509e-05,
      "loss": 0.045,
      "step": 5900
    },
    {
      "epoch": 0.4125696211235646,
      "grad_norm": 0.13184581696987152,
      "learning_rate": 4.742551618615366e-05,
      "loss": 0.0386,
      "step": 6000
    },
    {
      "epoch": 0.419445781475624,
      "grad_norm": 0.29280295968055725,
      "learning_rate": 4.738253648976224e-05,
      "loss": 0.0429,
      "step": 6100
    },
    {
      "epoch": 0.4263219418276834,
      "grad_norm": 0.2758505046367645,
      "learning_rate": 4.733955679337082e-05,
      "loss": 0.0436,
      "step": 6200
    },
    {
      "epoch": 0.4331981021797428,
      "grad_norm": 0.44927093386650085,
      "learning_rate": 4.729657709697939e-05,
      "loss": 0.0449,
      "step": 6300
    },
    {
      "epoch": 0.44007426253180226,
      "grad_norm": 0.30197620391845703,
      "learning_rate": 4.725402719755188e-05,
      "loss": 0.0453,
      "step": 6400
    },
    {
      "epoch": 0.44695042288386166,
      "grad_norm": 0.20243260264396667,
      "learning_rate": 4.7211047501160455e-05,
      "loss": 0.0447,
      "step": 6500
    },
    {
      "epoch": 0.45382658323592107,
      "grad_norm": 0.2582584321498871,
      "learning_rate": 4.716806780476903e-05,
      "loss": 0.0446,
      "step": 6600
    },
    {
      "epoch": 0.46070274358798047,
      "grad_norm": 0.27354392409324646,
      "learning_rate": 4.71250881083776e-05,
      "loss": 0.0424,
      "step": 6700
    },
    {
      "epoch": 0.46757890394003987,
      "grad_norm": 0.2812720537185669,
      "learning_rate": 4.708210841198618e-05,
      "loss": 0.0429,
      "step": 6800
    },
    {
      "epoch": 0.47445506429209927,
      "grad_norm": 0.25570181012153625,
      "learning_rate": 4.703912871559476e-05,
      "loss": 0.0443,
      "step": 6900
    },
    {
      "epoch": 0.48133122464415873,
      "grad_norm": 0.16890522837638855,
      "learning_rate": 4.699614901920333e-05,
      "loss": 0.0397,
      "step": 7000
    },
    {
      "epoch": 0.48820738499621813,
      "grad_norm": 0.24142161011695862,
      "learning_rate": 4.6953169322811905e-05,
      "loss": 0.0427,
      "step": 7100
    },
    {
      "epoch": 0.49508354534827753,
      "grad_norm": 0.26525989174842834,
      "learning_rate": 4.691018962642048e-05,
      "loss": 0.0418,
      "step": 7200
    },
    {
      "epoch": 0.5019597057003369,
      "grad_norm": 0.38344383239746094,
      "learning_rate": 4.686720993002905e-05,
      "loss": 0.0429,
      "step": 7300
    },
    {
      "epoch": 0.5088358660523964,
      "grad_norm": 0.17181231081485748,
      "learning_rate": 4.682423023363763e-05,
      "loss": 0.0404,
      "step": 7400
    },
    {
      "epoch": 0.5157120264044558,
      "grad_norm": 0.30791765451431274,
      "learning_rate": 4.678125053724621e-05,
      "loss": 0.0458,
      "step": 7500
    },
    {
      "epoch": 0.5225881867565152,
      "grad_norm": 0.19059157371520996,
      "learning_rate": 4.673827084085478e-05,
      "loss": 0.0431,
      "step": 7600
    },
    {
      "epoch": 0.5294643471085746,
      "grad_norm": 0.2824118137359619,
      "learning_rate": 4.669529114446336e-05,
      "loss": 0.0396,
      "step": 7700
    },
    {
      "epoch": 0.536340507460634,
      "grad_norm": 0.3595360219478607,
      "learning_rate": 4.6652311448071936e-05,
      "loss": 0.0425,
      "step": 7800
    },
    {
      "epoch": 0.5432166678126934,
      "grad_norm": 0.21382580697536469,
      "learning_rate": 4.660933175168051e-05,
      "loss": 0.0437,
      "step": 7900
    },
    {
      "epoch": 0.5500928281647528,
      "grad_norm": 0.2853698432445526,
      "learning_rate": 4.6566352055289084e-05,
      "loss": 0.038,
      "step": 8000
    },
    {
      "epoch": 0.5569689885168122,
      "grad_norm": 0.21204502880573273,
      "learning_rate": 4.652337235889766e-05,
      "loss": 0.0408,
      "step": 8100
    },
    {
      "epoch": 0.5638451488688716,
      "grad_norm": 0.27408286929130554,
      "learning_rate": 4.648039266250623e-05,
      "loss": 0.0412,
      "step": 8200
    },
    {
      "epoch": 0.570721309220931,
      "grad_norm": 0.2061978131532669,
      "learning_rate": 4.6437412966114805e-05,
      "loss": 0.0409,
      "step": 8300
    },
    {
      "epoch": 0.5775974695729904,
      "grad_norm": 0.2069263905286789,
      "learning_rate": 4.6394433269723386e-05,
      "loss": 0.0418,
      "step": 8400
    },
    {
      "epoch": 0.5844736299250498,
      "grad_norm": 0.16869421303272247,
      "learning_rate": 4.635145357333196e-05,
      "loss": 0.0405,
      "step": 8500
    },
    {
      "epoch": 0.5913497902771092,
      "grad_norm": 0.2933180630207062,
      "learning_rate": 4.6308473876940534e-05,
      "loss": 0.0389,
      "step": 8600
    },
    {
      "epoch": 0.5982259506291687,
      "grad_norm": 0.43226194381713867,
      "learning_rate": 4.6265494180549114e-05,
      "loss": 0.0416,
      "step": 8700
    },
    {
      "epoch": 0.6051021109812281,
      "grad_norm": 0.24454732239246368,
      "learning_rate": 4.622251448415769e-05,
      "loss": 0.0392,
      "step": 8800
    },
    {
      "epoch": 0.6119782713332875,
      "grad_norm": 0.47308996319770813,
      "learning_rate": 4.617953478776626e-05,
      "loss": 0.04,
      "step": 8900
    },
    {
      "epoch": 0.6188544316853469,
      "grad_norm": 0.10073868930339813,
      "learning_rate": 4.6136555091374836e-05,
      "loss": 0.0387,
      "step": 9000
    },
    {
      "epoch": 0.6257305920374063,
      "grad_norm": 0.23874406516551971,
      "learning_rate": 4.609357539498341e-05,
      "loss": 0.0382,
      "step": 9100
    },
    {
      "epoch": 0.6326067523894657,
      "grad_norm": 0.35001468658447266,
      "learning_rate": 4.6050595698591984e-05,
      "loss": 0.0396,
      "step": 9200
    },
    {
      "epoch": 0.6394829127415251,
      "grad_norm": 0.2162274867296219,
      "learning_rate": 4.6007616002200565e-05,
      "loss": 0.0404,
      "step": 9300
    },
    {
      "epoch": 0.6463590730935845,
      "grad_norm": 0.20952169597148895,
      "learning_rate": 4.596463630580914e-05,
      "loss": 0.0392,
      "step": 9400
    },
    {
      "epoch": 0.6532352334456439,
      "grad_norm": 0.17797596752643585,
      "learning_rate": 4.592165660941771e-05,
      "loss": 0.0379,
      "step": 9500
    },
    {
      "epoch": 0.6601113937977033,
      "grad_norm": 0.2519623041152954,
      "learning_rate": 4.5878676913026286e-05,
      "loss": 0.041,
      "step": 9600
    },
    {
      "epoch": 0.6669875541497627,
      "grad_norm": 0.31720155477523804,
      "learning_rate": 4.583569721663487e-05,
      "loss": 0.0377,
      "step": 9700
    },
    {
      "epoch": 0.6738637145018221,
      "grad_norm": 0.26805347204208374,
      "learning_rate": 4.579271752024344e-05,
      "loss": 0.0401,
      "step": 9800
    },
    {
      "epoch": 0.6807398748538815,
      "grad_norm": 0.1973644644021988,
      "learning_rate": 4.5749737823852015e-05,
      "loss": 0.0386,
      "step": 9900
    },
    {
      "epoch": 0.6876160352059411,
      "grad_norm": 0.28630346059799194,
      "learning_rate": 4.5707187924424504e-05,
      "loss": 0.0398,
      "step": 10000
    },
    {
      "epoch": 0.6944921955580005,
      "grad_norm": 0.14910788834095,
      "learning_rate": 4.566420822803308e-05,
      "loss": 0.0403,
      "step": 10100
    },
    {
      "epoch": 0.7013683559100599,
      "grad_norm": 0.3710712194442749,
      "learning_rate": 4.562122853164165e-05,
      "loss": 0.0392,
      "step": 10200
    },
    {
      "epoch": 0.7082445162621193,
      "grad_norm": 0.14047813415527344,
      "learning_rate": 4.557824883525023e-05,
      "loss": 0.039,
      "step": 10300
    },
    {
      "epoch": 0.7151206766141787,
      "grad_norm": 0.20810355246067047,
      "learning_rate": 4.5535269138858806e-05,
      "loss": 0.0403,
      "step": 10400
    },
    {
      "epoch": 0.7219968369662381,
      "grad_norm": 0.18108615279197693,
      "learning_rate": 4.549228944246738e-05,
      "loss": 0.04,
      "step": 10500
    },
    {
      "epoch": 0.7288729973182975,
      "grad_norm": 0.16465216875076294,
      "learning_rate": 4.5449309746075954e-05,
      "loss": 0.0384,
      "step": 10600
    },
    {
      "epoch": 0.7357491576703569,
      "grad_norm": 0.28071868419647217,
      "learning_rate": 4.540633004968453e-05,
      "loss": 0.0374,
      "step": 10700
    },
    {
      "epoch": 0.7426253180224163,
      "grad_norm": 0.2590932846069336,
      "learning_rate": 4.53633503532931e-05,
      "loss": 0.0414,
      "step": 10800
    },
    {
      "epoch": 0.7495014783744757,
      "grad_norm": 0.3015652894973755,
      "learning_rate": 4.532037065690168e-05,
      "loss": 0.0394,
      "step": 10900
    },
    {
      "epoch": 0.7563776387265351,
      "grad_norm": 0.15279799699783325,
      "learning_rate": 4.527739096051026e-05,
      "loss": 0.036,
      "step": 11000
    },
    {
      "epoch": 0.7632537990785945,
      "grad_norm": 0.32583504915237427,
      "learning_rate": 4.523441126411883e-05,
      "loss": 0.0408,
      "step": 11100
    },
    {
      "epoch": 0.7701299594306539,
      "grad_norm": 0.19959239661693573,
      "learning_rate": 4.519143156772741e-05,
      "loss": 0.0379,
      "step": 11200
    },
    {
      "epoch": 0.7770061197827133,
      "grad_norm": 0.3173525631427765,
      "learning_rate": 4.5148451871335985e-05,
      "loss": 0.0387,
      "step": 11300
    },
    {
      "epoch": 0.7838822801347728,
      "grad_norm": 0.25962889194488525,
      "learning_rate": 4.510590197190847e-05,
      "loss": 0.0402,
      "step": 11400
    },
    {
      "epoch": 0.7907584404868322,
      "grad_norm": 0.22333145141601562,
      "learning_rate": 4.506292227551705e-05,
      "loss": 0.0339,
      "step": 11500
    },
    {
      "epoch": 0.7976346008388916,
      "grad_norm": 0.10518164932727814,
      "learning_rate": 4.501994257912562e-05,
      "loss": 0.0354,
      "step": 11600
    },
    {
      "epoch": 0.804510761190951,
      "grad_norm": 0.31558555364608765,
      "learning_rate": 4.4976962882734196e-05,
      "loss": 0.0376,
      "step": 11700
    },
    {
      "epoch": 0.8113869215430104,
      "grad_norm": 0.20855511724948883,
      "learning_rate": 4.493398318634278e-05,
      "loss": 0.0374,
      "step": 11800
    },
    {
      "epoch": 0.8182630818950698,
      "grad_norm": 0.11799785494804382,
      "learning_rate": 4.489100348995135e-05,
      "loss": 0.0377,
      "step": 11900
    },
    {
      "epoch": 0.8251392422471292,
      "grad_norm": 0.29495593905448914,
      "learning_rate": 4.4848023793559924e-05,
      "loss": 0.0363,
      "step": 12000
    },
    {
      "epoch": 0.8320154025991886,
      "grad_norm": 0.12358508259057999,
      "learning_rate": 4.48050440971685e-05,
      "loss": 0.0377,
      "step": 12100
    },
    {
      "epoch": 0.838891562951248,
      "grad_norm": 0.31430375576019287,
      "learning_rate": 4.476206440077708e-05,
      "loss": 0.0373,
      "step": 12200
    },
    {
      "epoch": 0.8457677233033074,
      "grad_norm": 0.15193891525268555,
      "learning_rate": 4.471908470438565e-05,
      "loss": 0.0369,
      "step": 12300
    },
    {
      "epoch": 0.8526438836553668,
      "grad_norm": 0.20905530452728271,
      "learning_rate": 4.467610500799422e-05,
      "loss": 0.0377,
      "step": 12400
    },
    {
      "epoch": 0.8595200440074262,
      "grad_norm": 0.1488531231880188,
      "learning_rate": 4.46331253116028e-05,
      "loss": 0.0363,
      "step": 12500
    },
    {
      "epoch": 0.8663962043594856,
      "grad_norm": 0.20711413025856018,
      "learning_rate": 4.4590145615211375e-05,
      "loss": 0.0374,
      "step": 12600
    },
    {
      "epoch": 0.8732723647115451,
      "grad_norm": 0.20260313153266907,
      "learning_rate": 4.454716591881995e-05,
      "loss": 0.0347,
      "step": 12700
    },
    {
      "epoch": 0.8801485250636045,
      "grad_norm": 0.38209137320518494,
      "learning_rate": 4.450418622242853e-05,
      "loss": 0.0358,
      "step": 12800
    },
    {
      "epoch": 0.8870246854156639,
      "grad_norm": 0.2924131751060486,
      "learning_rate": 4.44612065260371e-05,
      "loss": 0.0341,
      "step": 12900
    },
    {
      "epoch": 0.8939008457677233,
      "grad_norm": 0.27097320556640625,
      "learning_rate": 4.441822682964568e-05,
      "loss": 0.038,
      "step": 13000
    },
    {
      "epoch": 0.9007770061197827,
      "grad_norm": 0.334810346364975,
      "learning_rate": 4.437524713325426e-05,
      "loss": 0.0403,
      "step": 13100
    },
    {
      "epoch": 0.9076531664718421,
      "grad_norm": 0.19039054214954376,
      "learning_rate": 4.433226743686283e-05,
      "loss": 0.037,
      "step": 13200
    },
    {
      "epoch": 0.9145293268239015,
      "grad_norm": 0.17048798501491547,
      "learning_rate": 4.4289287740471406e-05,
      "loss": 0.0355,
      "step": 13300
    },
    {
      "epoch": 0.9214054871759609,
      "grad_norm": 0.21651385724544525,
      "learning_rate": 4.424630804407997e-05,
      "loss": 0.0386,
      "step": 13400
    },
    {
      "epoch": 0.9282816475280203,
      "grad_norm": 0.2983185350894928,
      "learning_rate": 4.4203328347688553e-05,
      "loss": 0.0372,
      "step": 13500
    },
    {
      "epoch": 0.9351578078800797,
      "grad_norm": 0.08863796293735504,
      "learning_rate": 4.416034865129713e-05,
      "loss": 0.0405,
      "step": 13600
    },
    {
      "epoch": 0.9420339682321391,
      "grad_norm": 0.24152322113513947,
      "learning_rate": 4.41173689549057e-05,
      "loss": 0.0328,
      "step": 13700
    },
    {
      "epoch": 0.9489101285841985,
      "grad_norm": 0.32333409786224365,
      "learning_rate": 4.407438925851428e-05,
      "loss": 0.0336,
      "step": 13800
    },
    {
      "epoch": 0.9557862889362579,
      "grad_norm": 0.17330290377140045,
      "learning_rate": 4.4031409562122856e-05,
      "loss": 0.035,
      "step": 13900
    },
    {
      "epoch": 0.9626624492883175,
      "grad_norm": 0.2142915576696396,
      "learning_rate": 4.398842986573143e-05,
      "loss": 0.0371,
      "step": 14000
    },
    {
      "epoch": 0.9695386096403769,
      "grad_norm": 0.2578390836715698,
      "learning_rate": 4.394545016934001e-05,
      "loss": 0.036,
      "step": 14100
    },
    {
      "epoch": 0.9764147699924363,
      "grad_norm": 0.21244414150714874,
      "learning_rate": 4.3902470472948584e-05,
      "loss": 0.0372,
      "step": 14200
    },
    {
      "epoch": 0.9832909303444957,
      "grad_norm": 0.24000711739063263,
      "learning_rate": 4.385949077655716e-05,
      "loss": 0.0344,
      "step": 14300
    },
    {
      "epoch": 0.9901670906965551,
      "grad_norm": 0.2223370522260666,
      "learning_rate": 4.381651108016573e-05,
      "loss": 0.0359,
      "step": 14400
    },
    {
      "epoch": 0.9970432510486145,
      "grad_norm": 0.2320646494626999,
      "learning_rate": 4.3773531383774306e-05,
      "loss": 0.0355,
      "step": 14500
    },
    {
      "epoch": 1.0,
      "eval_accuracy_macro_0.5": 0.9836426377296448,
      "eval_accuracy_micro_0.5": 0.9836426377296448,
      "eval_accuracy_weighted_0.5": 0.9815173745155334,
      "eval_f1_macro_0.5": 0.7779458165168762,
      "eval_f1_macro_0.6": 0.758772075176239,
      "eval_f1_macro_0.7": 0.7219874262809753,
      "eval_f1_macro_0.8": 0.534906268119812,
      "eval_f1_micro_0.5": 0.7803009748458862,
      "eval_f1_micro_0.6": 0.7645688652992249,
      "eval_f1_micro_0.7": 0.7317277193069458,
      "eval_f1_micro_0.8": 0.6770856380462646,
      "eval_f1_micro_0.9": 0.5599464178085327,
      "eval_f1_weighted_0.5": 0.7751761674880981,
      "eval_f1_weighted_0.6": 0.7554253339767456,
      "eval_f1_weighted_0.7": 0.7171807289123535,
      "eval_f1_weighted_0.8": 0.5220533609390259,
      "eval_loss": 0.03418710082769394,
      "eval_runtime": 466.2739,
      "eval_samples_per_second": 62.275,
      "eval_steps_per_second": 7.785,
      "step": 14543
    },
    {
      "epoch": 1.0039194114006738,
      "grad_norm": 0.23682525753974915,
      "learning_rate": 4.373055168738288e-05,
      "loss": 0.0341,
      "step": 14600
    },
    {
      "epoch": 1.0107955717527333,
      "grad_norm": 0.18039944767951965,
      "learning_rate": 4.368757199099146e-05,
      "loss": 0.0339,
      "step": 14700
    },
    {
      "epoch": 1.0176717321047928,
      "grad_norm": 0.2969330847263336,
      "learning_rate": 4.3644592294600035e-05,
      "loss": 0.0328,
      "step": 14800
    },
    {
      "epoch": 1.024547892456852,
      "grad_norm": 0.175253227353096,
      "learning_rate": 4.360161259820861e-05,
      "loss": 0.0352,
      "step": 14900
    },
    {
      "epoch": 1.0314240528089116,
      "grad_norm": 0.14958016574382782,
      "learning_rate": 4.355863290181718e-05,
      "loss": 0.034,
      "step": 15000
    },
    {
      "epoch": 1.0383002131609709,
      "grad_norm": 0.16061267256736755,
      "learning_rate": 4.351565320542576e-05,
      "loss": 0.0344,
      "step": 15100
    },
    {
      "epoch": 1.0451763735130304,
      "grad_norm": 0.14494743943214417,
      "learning_rate": 4.347267350903434e-05,
      "loss": 0.0348,
      "step": 15200
    },
    {
      "epoch": 1.0520525338650897,
      "grad_norm": 0.08543314784765244,
      "learning_rate": 4.342969381264291e-05,
      "loss": 0.0374,
      "step": 15300
    },
    {
      "epoch": 1.0589286942171492,
      "grad_norm": 0.13682140409946442,
      "learning_rate": 4.3386714116251485e-05,
      "loss": 0.0332,
      "step": 15400
    },
    {
      "epoch": 1.0658048545692085,
      "grad_norm": 0.1438821703195572,
      "learning_rate": 4.334373441986006e-05,
      "loss": 0.0331,
      "step": 15500
    },
    {
      "epoch": 1.072681014921268,
      "grad_norm": 0.33890795707702637,
      "learning_rate": 4.330075472346863e-05,
      "loss": 0.0373,
      "step": 15600
    },
    {
      "epoch": 1.0795571752733273,
      "grad_norm": 0.26666098833084106,
      "learning_rate": 4.3257775027077213e-05,
      "loss": 0.0361,
      "step": 15700
    },
    {
      "epoch": 1.0864333356253868,
      "grad_norm": 0.22585026919841766,
      "learning_rate": 4.321479533068579e-05,
      "loss": 0.0315,
      "step": 15800
    },
    {
      "epoch": 1.0933094959774463,
      "grad_norm": 0.24336858093738556,
      "learning_rate": 4.317181563429436e-05,
      "loss": 0.033,
      "step": 15900
    },
    {
      "epoch": 1.1001856563295056,
      "grad_norm": 0.23611237108707428,
      "learning_rate": 4.312883593790294e-05,
      "loss": 0.0316,
      "step": 16000
    },
    {
      "epoch": 1.1070618166815651,
      "grad_norm": 0.4675404131412506,
      "learning_rate": 4.3085856241511516e-05,
      "loss": 0.0319,
      "step": 16100
    },
    {
      "epoch": 1.1139379770336244,
      "grad_norm": 0.30977490544319153,
      "learning_rate": 4.304287654512009e-05,
      "loss": 0.0376,
      "step": 16200
    },
    {
      "epoch": 1.120814137385684,
      "grad_norm": 0.09682868421077728,
      "learning_rate": 4.299989684872866e-05,
      "loss": 0.0319,
      "step": 16300
    },
    {
      "epoch": 1.1276902977377432,
      "grad_norm": 0.10409457236528397,
      "learning_rate": 4.295691715233724e-05,
      "loss": 0.0354,
      "step": 16400
    },
    {
      "epoch": 1.1345664580898027,
      "grad_norm": 0.19402840733528137,
      "learning_rate": 4.291393745594581e-05,
      "loss": 0.0319,
      "step": 16500
    },
    {
      "epoch": 1.141442618441862,
      "grad_norm": 0.30927202105522156,
      "learning_rate": 4.2870957759554385e-05,
      "loss": 0.0353,
      "step": 16600
    },
    {
      "epoch": 1.1483187787939215,
      "grad_norm": 0.19730687141418457,
      "learning_rate": 4.2827978063162966e-05,
      "loss": 0.0328,
      "step": 16700
    },
    {
      "epoch": 1.1551949391459808,
      "grad_norm": 0.28518155217170715,
      "learning_rate": 4.278499836677154e-05,
      "loss": 0.0347,
      "step": 16800
    },
    {
      "epoch": 1.1620710994980403,
      "grad_norm": 0.19519731402397156,
      "learning_rate": 4.2742018670380114e-05,
      "loss": 0.0332,
      "step": 16900
    },
    {
      "epoch": 1.1689472598500996,
      "grad_norm": 0.33658912777900696,
      "learning_rate": 4.2699038973988695e-05,
      "loss": 0.0343,
      "step": 17000
    },
    {
      "epoch": 1.1758234202021591,
      "grad_norm": 0.12947486340999603,
      "learning_rate": 4.265605927759727e-05,
      "loss": 0.0332,
      "step": 17100
    },
    {
      "epoch": 1.1826995805542184,
      "grad_norm": 0.22761709988117218,
      "learning_rate": 4.261307958120584e-05,
      "loss": 0.0343,
      "step": 17200
    },
    {
      "epoch": 1.189575740906278,
      "grad_norm": 0.18817918002605438,
      "learning_rate": 4.2570099884814416e-05,
      "loss": 0.0315,
      "step": 17300
    },
    {
      "epoch": 1.1964519012583374,
      "grad_norm": 0.2786191403865814,
      "learning_rate": 4.252712018842299e-05,
      "loss": 0.0357,
      "step": 17400
    },
    {
      "epoch": 1.2033280616103967,
      "grad_norm": 0.1814873367547989,
      "learning_rate": 4.2484140492031564e-05,
      "loss": 0.0326,
      "step": 17500
    },
    {
      "epoch": 1.2102042219624563,
      "grad_norm": 0.255416601896286,
      "learning_rate": 4.244116079564014e-05,
      "loss": 0.0321,
      "step": 17600
    },
    {
      "epoch": 1.2170803823145155,
      "grad_norm": 0.21404719352722168,
      "learning_rate": 4.239818109924872e-05,
      "loss": 0.0339,
      "step": 17700
    },
    {
      "epoch": 1.223956542666575,
      "grad_norm": 0.19573301076889038,
      "learning_rate": 4.235520140285729e-05,
      "loss": 0.0336,
      "step": 17800
    },
    {
      "epoch": 1.2308327030186343,
      "grad_norm": 0.23553746938705444,
      "learning_rate": 4.2312221706465867e-05,
      "loss": 0.0327,
      "step": 17900
    },
    {
      "epoch": 1.2377088633706939,
      "grad_norm": 0.21464717388153076,
      "learning_rate": 4.226924201007445e-05,
      "loss": 0.0334,
      "step": 18000
    },
    {
      "epoch": 1.2445850237227531,
      "grad_norm": 0.19098903238773346,
      "learning_rate": 4.222626231368302e-05,
      "loss": 0.0313,
      "step": 18100
    },
    {
      "epoch": 1.2514611840748127,
      "grad_norm": 0.08069022744894028,
      "learning_rate": 4.2183282617291595e-05,
      "loss": 0.0312,
      "step": 18200
    },
    {
      "epoch": 1.258337344426872,
      "grad_norm": 0.18380215764045715,
      "learning_rate": 4.2140732717864084e-05,
      "loss": 0.0323,
      "step": 18300
    },
    {
      "epoch": 1.2652135047789315,
      "grad_norm": 0.22438926994800568,
      "learning_rate": 4.209775302147266e-05,
      "loss": 0.0364,
      "step": 18400
    },
    {
      "epoch": 1.272089665130991,
      "grad_norm": 0.20507566630840302,
      "learning_rate": 4.205477332508123e-05,
      "loss": 0.0332,
      "step": 18500
    },
    {
      "epoch": 1.2789658254830503,
      "grad_norm": 0.2053912878036499,
      "learning_rate": 4.201179362868981e-05,
      "loss": 0.0344,
      "step": 18600
    },
    {
      "epoch": 1.2858419858351096,
      "grad_norm": 0.3292141854763031,
      "learning_rate": 4.1968813932298387e-05,
      "loss": 0.0341,
      "step": 18700
    },
    {
      "epoch": 1.292718146187169,
      "grad_norm": 0.21340103447437286,
      "learning_rate": 4.192583423590696e-05,
      "loss": 0.035,
      "step": 18800
    },
    {
      "epoch": 1.2995943065392286,
      "grad_norm": 0.4521637260913849,
      "learning_rate": 4.1882854539515534e-05,
      "loss": 0.0342,
      "step": 18900
    },
    {
      "epoch": 1.3064704668912879,
      "grad_norm": 0.10361578315496445,
      "learning_rate": 4.183987484312411e-05,
      "loss": 0.035,
      "step": 19000
    },
    {
      "epoch": 1.3133466272433474,
      "grad_norm": 0.08891603350639343,
      "learning_rate": 4.179689514673268e-05,
      "loss": 0.0351,
      "step": 19100
    },
    {
      "epoch": 1.3202227875954067,
      "grad_norm": 0.27939462661743164,
      "learning_rate": 4.175391545034126e-05,
      "loss": 0.0356,
      "step": 19200
    },
    {
      "epoch": 1.3270989479474662,
      "grad_norm": 0.11741101741790771,
      "learning_rate": 4.171093575394984e-05,
      "loss": 0.0315,
      "step": 19300
    },
    {
      "epoch": 1.3339751082995255,
      "grad_norm": 0.2736221253871918,
      "learning_rate": 4.166795605755841e-05,
      "loss": 0.036,
      "step": 19400
    },
    {
      "epoch": 1.340851268651585,
      "grad_norm": 0.17843377590179443,
      "learning_rate": 4.1624976361166985e-05,
      "loss": 0.0313,
      "step": 19500
    },
    {
      "epoch": 1.3477274290036443,
      "grad_norm": 0.19094298779964447,
      "learning_rate": 4.1581996664775565e-05,
      "loss": 0.0337,
      "step": 19600
    },
    {
      "epoch": 1.3546035893557038,
      "grad_norm": 0.5365875959396362,
      "learning_rate": 4.153901696838414e-05,
      "loss": 0.032,
      "step": 19700
    },
    {
      "epoch": 1.361479749707763,
      "grad_norm": 0.30849748849868774,
      "learning_rate": 4.149603727199271e-05,
      "loss": 0.0314,
      "step": 19800
    },
    {
      "epoch": 1.3683559100598226,
      "grad_norm": 0.15645326673984528,
      "learning_rate": 4.145305757560129e-05,
      "loss": 0.0325,
      "step": 19900
    },
    {
      "epoch": 1.3752320704118821,
      "grad_norm": 0.28571444749832153,
      "learning_rate": 4.141007787920986e-05,
      "loss": 0.0347,
      "step": 20000
    },
    {
      "epoch": 1.3821082307639414,
      "grad_norm": 0.2533703148365021,
      "learning_rate": 4.1367098182818435e-05,
      "loss": 0.033,
      "step": 20100
    },
    {
      "epoch": 1.3889843911160007,
      "grad_norm": 0.243310809135437,
      "learning_rate": 4.1324118486427016e-05,
      "loss": 0.0324,
      "step": 20200
    },
    {
      "epoch": 1.3958605514680602,
      "grad_norm": 0.1690647155046463,
      "learning_rate": 4.128113879003559e-05,
      "loss": 0.0321,
      "step": 20300
    },
    {
      "epoch": 1.4027367118201197,
      "grad_norm": 0.2511681318283081,
      "learning_rate": 4.123815909364416e-05,
      "loss": 0.034,
      "step": 20400
    },
    {
      "epoch": 1.409612872172179,
      "grad_norm": 0.3835379481315613,
      "learning_rate": 4.1195179397252744e-05,
      "loss": 0.0339,
      "step": 20500
    },
    {
      "epoch": 1.4164890325242385,
      "grad_norm": 0.21500378847122192,
      "learning_rate": 4.1152629497825226e-05,
      "loss": 0.0299,
      "step": 20600
    },
    {
      "epoch": 1.4233651928762978,
      "grad_norm": 0.13058415055274963,
      "learning_rate": 4.11096498014338e-05,
      "loss": 0.0324,
      "step": 20700
    },
    {
      "epoch": 1.4302413532283573,
      "grad_norm": 0.1949632167816162,
      "learning_rate": 4.106667010504238e-05,
      "loss": 0.0332,
      "step": 20800
    },
    {
      "epoch": 1.4371175135804166,
      "grad_norm": 0.3442499041557312,
      "learning_rate": 4.1023690408650955e-05,
      "loss": 0.0346,
      "step": 20900
    },
    {
      "epoch": 1.4439936739324761,
      "grad_norm": 0.31711050868034363,
      "learning_rate": 4.098071071225953e-05,
      "loss": 0.0332,
      "step": 21000
    },
    {
      "epoch": 1.4508698342845356,
      "grad_norm": 0.13568046689033508,
      "learning_rate": 4.093773101586811e-05,
      "loss": 0.0325,
      "step": 21100
    },
    {
      "epoch": 1.457745994636595,
      "grad_norm": 0.32417696714401245,
      "learning_rate": 4.089475131947668e-05,
      "loss": 0.0307,
      "step": 21200
    },
    {
      "epoch": 1.4646221549886542,
      "grad_norm": 0.16670550405979156,
      "learning_rate": 4.085177162308526e-05,
      "loss": 0.0329,
      "step": 21300
    },
    {
      "epoch": 1.4714983153407137,
      "grad_norm": 0.2575273811817169,
      "learning_rate": 4.080879192669383e-05,
      "loss": 0.0318,
      "step": 21400
    },
    {
      "epoch": 1.4783744756927732,
      "grad_norm": 0.20067323744297028,
      "learning_rate": 4.0765812230302405e-05,
      "loss": 0.0333,
      "step": 21500
    },
    {
      "epoch": 1.4852506360448325,
      "grad_norm": 0.3443460762500763,
      "learning_rate": 4.072283253391098e-05,
      "loss": 0.0317,
      "step": 21600
    },
    {
      "epoch": 1.492126796396892,
      "grad_norm": 0.10830774158239365,
      "learning_rate": 4.067985283751955e-05,
      "loss": 0.0313,
      "step": 21700
    },
    {
      "epoch": 1.4990029567489513,
      "grad_norm": 0.12088683247566223,
      "learning_rate": 4.0636873141128134e-05,
      "loss": 0.0331,
      "step": 21800
    },
    {
      "epoch": 1.5058791171010109,
      "grad_norm": 0.20584627985954285,
      "learning_rate": 4.059389344473671e-05,
      "loss": 0.0324,
      "step": 21900
    },
    {
      "epoch": 1.5127552774530701,
      "grad_norm": 0.2620186507701874,
      "learning_rate": 4.05513435453092e-05,
      "loss": 0.031,
      "step": 22000
    },
    {
      "epoch": 1.5196314378051297,
      "grad_norm": 0.15606512129306793,
      "learning_rate": 4.050836384891778e-05,
      "loss": 0.032,
      "step": 22100
    },
    {
      "epoch": 1.5265075981571892,
      "grad_norm": 0.4139515459537506,
      "learning_rate": 4.0465384152526344e-05,
      "loss": 0.0324,
      "step": 22200
    },
    {
      "epoch": 1.5333837585092485,
      "grad_norm": 0.19529719650745392,
      "learning_rate": 4.042240445613492e-05,
      "loss": 0.0307,
      "step": 22300
    },
    {
      "epoch": 1.5402599188613078,
      "grad_norm": 0.19694054126739502,
      "learning_rate": 4.03794247597435e-05,
      "loss": 0.0314,
      "step": 22400
    },
    {
      "epoch": 1.5471360792133673,
      "grad_norm": 0.32182663679122925,
      "learning_rate": 4.033644506335207e-05,
      "loss": 0.033,
      "step": 22500
    },
    {
      "epoch": 1.5540122395654268,
      "grad_norm": 0.22273536026477814,
      "learning_rate": 4.029346536696065e-05,
      "loss": 0.0299,
      "step": 22600
    },
    {
      "epoch": 1.560888399917486,
      "grad_norm": 0.1530417650938034,
      "learning_rate": 4.025048567056923e-05,
      "loss": 0.0291,
      "step": 22700
    },
    {
      "epoch": 1.5677645602695454,
      "grad_norm": 0.3769378662109375,
      "learning_rate": 4.02075059741778e-05,
      "loss": 0.0327,
      "step": 22800
    },
    {
      "epoch": 1.5746407206216049,
      "grad_norm": 0.21412912011146545,
      "learning_rate": 4.0164526277786375e-05,
      "loss": 0.0291,
      "step": 22900
    },
    {
      "epoch": 1.5815168809736644,
      "grad_norm": 0.24295660853385925,
      "learning_rate": 4.0121546581394956e-05,
      "loss": 0.0333,
      "step": 23000
    },
    {
      "epoch": 1.5883930413257237,
      "grad_norm": 0.25795233249664307,
      "learning_rate": 4.007856688500353e-05,
      "loss": 0.0311,
      "step": 23100
    },
    {
      "epoch": 1.595269201677783,
      "grad_norm": 0.4493732750415802,
      "learning_rate": 4.00355871886121e-05,
      "loss": 0.0319,
      "step": 23200
    },
    {
      "epoch": 1.6021453620298427,
      "grad_norm": 0.397394061088562,
      "learning_rate": 3.999260749222068e-05,
      "loss": 0.0332,
      "step": 23300
    },
    {
      "epoch": 1.609021522381902,
      "grad_norm": 0.22500111162662506,
      "learning_rate": 3.994962779582925e-05,
      "loss": 0.0326,
      "step": 23400
    },
    {
      "epoch": 1.6158976827339613,
      "grad_norm": 0.47448572516441345,
      "learning_rate": 3.9906648099437826e-05,
      "loss": 0.0317,
      "step": 23500
    },
    {
      "epoch": 1.6227738430860208,
      "grad_norm": 0.29097962379455566,
      "learning_rate": 3.98636684030464e-05,
      "loss": 0.0325,
      "step": 23600
    },
    {
      "epoch": 1.6296500034380803,
      "grad_norm": 0.38545143604278564,
      "learning_rate": 3.982068870665498e-05,
      "loss": 0.0297,
      "step": 23700
    },
    {
      "epoch": 1.6365261637901396,
      "grad_norm": 0.21151062846183777,
      "learning_rate": 3.9777709010263554e-05,
      "loss": 0.0309,
      "step": 23800
    },
    {
      "epoch": 1.643402324142199,
      "grad_norm": 0.37484505772590637,
      "learning_rate": 3.973472931387213e-05,
      "loss": 0.0314,
      "step": 23900
    },
    {
      "epoch": 1.6502784844942584,
      "grad_norm": 0.35006195306777954,
      "learning_rate": 3.969174961748071e-05,
      "loss": 0.0304,
      "step": 24000
    },
    {
      "epoch": 1.657154644846318,
      "grad_norm": 0.14343540370464325,
      "learning_rate": 3.964919971805319e-05,
      "loss": 0.0324,
      "step": 24100
    },
    {
      "epoch": 1.6640308051983772,
      "grad_norm": 0.2749002277851105,
      "learning_rate": 3.9606220021661765e-05,
      "loss": 0.0297,
      "step": 24200
    },
    {
      "epoch": 1.6709069655504365,
      "grad_norm": 0.16652435064315796,
      "learning_rate": 3.9563240325270346e-05,
      "loss": 0.031,
      "step": 24300
    },
    {
      "epoch": 1.677783125902496,
      "grad_norm": 0.2715246081352234,
      "learning_rate": 3.952026062887892e-05,
      "loss": 0.0308,
      "step": 24400
    },
    {
      "epoch": 1.6846592862545555,
      "grad_norm": 0.12791387736797333,
      "learning_rate": 3.947728093248749e-05,
      "loss": 0.0304,
      "step": 24500
    },
    {
      "epoch": 1.6915354466066148,
      "grad_norm": 0.16992074251174927,
      "learning_rate": 3.9434301236096074e-05,
      "loss": 0.0308,
      "step": 24600
    },
    {
      "epoch": 1.6984116069586743,
      "grad_norm": 0.11274360120296478,
      "learning_rate": 3.939132153970465e-05,
      "loss": 0.0314,
      "step": 24700
    },
    {
      "epoch": 1.7052877673107338,
      "grad_norm": 0.3185449540615082,
      "learning_rate": 3.934834184331322e-05,
      "loss": 0.029,
      "step": 24800
    },
    {
      "epoch": 1.7121639276627931,
      "grad_norm": 0.4154418408870697,
      "learning_rate": 3.9305362146921796e-05,
      "loss": 0.0341,
      "step": 24900
    },
    {
      "epoch": 1.7190400880148524,
      "grad_norm": 0.2152225375175476,
      "learning_rate": 3.926238245053037e-05,
      "loss": 0.0319,
      "step": 25000
    },
    {
      "epoch": 1.725916248366912,
      "grad_norm": 0.19609035551548004,
      "learning_rate": 3.9219402754138944e-05,
      "loss": 0.0311,
      "step": 25100
    },
    {
      "epoch": 1.7327924087189714,
      "grad_norm": 0.11215502768754959,
      "learning_rate": 3.9176423057747524e-05,
      "loss": 0.0298,
      "step": 25200
    },
    {
      "epoch": 1.7396685690710307,
      "grad_norm": 0.07529892027378082,
      "learning_rate": 3.91334433613561e-05,
      "loss": 0.0305,
      "step": 25300
    },
    {
      "epoch": 1.74654472942309,
      "grad_norm": 0.20394933223724365,
      "learning_rate": 3.909046366496467e-05,
      "loss": 0.0311,
      "step": 25400
    },
    {
      "epoch": 1.7534208897751495,
      "grad_norm": 0.13617442548274994,
      "learning_rate": 3.9047483968573246e-05,
      "loss": 0.0306,
      "step": 25500
    },
    {
      "epoch": 1.760297050127209,
      "grad_norm": 0.2402854859828949,
      "learning_rate": 3.900450427218183e-05,
      "loss": 0.0319,
      "step": 25600
    },
    {
      "epoch": 1.7671732104792683,
      "grad_norm": 0.1307205855846405,
      "learning_rate": 3.89615245757904e-05,
      "loss": 0.0332,
      "step": 25700
    },
    {
      "epoch": 1.7740493708313276,
      "grad_norm": 0.21592283248901367,
      "learning_rate": 3.8918544879398975e-05,
      "loss": 0.03,
      "step": 25800
    },
    {
      "epoch": 1.7809255311833871,
      "grad_norm": 0.23422789573669434,
      "learning_rate": 3.887556518300755e-05,
      "loss": 0.0315,
      "step": 25900
    },
    {
      "epoch": 1.7878016915354467,
      "grad_norm": 0.341477632522583,
      "learning_rate": 3.883258548661612e-05,
      "loss": 0.0287,
      "step": 26000
    },
    {
      "epoch": 1.794677851887506,
      "grad_norm": 0.1242167204618454,
      "learning_rate": 3.879003558718861e-05,
      "loss": 0.0287,
      "step": 26100
    },
    {
      "epoch": 1.8015540122395655,
      "grad_norm": 0.38905444741249084,
      "learning_rate": 3.87474856877611e-05,
      "loss": 0.0305,
      "step": 26200
    },
    {
      "epoch": 1.808430172591625,
      "grad_norm": 0.17141273617744446,
      "learning_rate": 3.8704505991369674e-05,
      "loss": 0.0273,
      "step": 26300
    },
    {
      "epoch": 1.8153063329436843,
      "grad_norm": 0.13916224241256714,
      "learning_rate": 3.8661526294978255e-05,
      "loss": 0.0273,
      "step": 26400
    },
    {
      "epoch": 1.8221824932957436,
      "grad_norm": 0.3329641819000244,
      "learning_rate": 3.861854659858683e-05,
      "loss": 0.0353,
      "step": 26500
    },
    {
      "epoch": 1.829058653647803,
      "grad_norm": 0.3724750578403473,
      "learning_rate": 3.85755669021954e-05,
      "loss": 0.028,
      "step": 26600
    },
    {
      "epoch": 1.8359348139998626,
      "grad_norm": 0.15444421768188477,
      "learning_rate": 3.8532587205803984e-05,
      "loss": 0.0309,
      "step": 26700
    },
    {
      "epoch": 1.8428109743519219,
      "grad_norm": 0.18262149393558502,
      "learning_rate": 3.848960750941256e-05,
      "loss": 0.0308,
      "step": 26800
    },
    {
      "epoch": 1.8496871347039812,
      "grad_norm": 0.1294877827167511,
      "learning_rate": 3.844662781302113e-05,
      "loss": 0.0306,
      "step": 26900
    },
    {
      "epoch": 1.8565632950560407,
      "grad_norm": 0.27822768688201904,
      "learning_rate": 3.8403648116629705e-05,
      "loss": 0.0261,
      "step": 27000
    },
    {
      "epoch": 1.8634394554081002,
      "grad_norm": 0.23845264315605164,
      "learning_rate": 3.8360668420238286e-05,
      "loss": 0.0315,
      "step": 27100
    },
    {
      "epoch": 1.8703156157601595,
      "grad_norm": 0.4557218849658966,
      "learning_rate": 3.831768872384685e-05,
      "loss": 0.0317,
      "step": 27200
    },
    {
      "epoch": 1.877191776112219,
      "grad_norm": 0.49181485176086426,
      "learning_rate": 3.827470902745543e-05,
      "loss": 0.0322,
      "step": 27300
    },
    {
      "epoch": 1.8840679364642785,
      "grad_norm": 0.306688517332077,
      "learning_rate": 3.823172933106401e-05,
      "loss": 0.0312,
      "step": 27400
    },
    {
      "epoch": 1.8909440968163378,
      "grad_norm": 0.3150063157081604,
      "learning_rate": 3.818874963467258e-05,
      "loss": 0.0329,
      "step": 27500
    },
    {
      "epoch": 1.897820257168397,
      "grad_norm": 0.3328959345817566,
      "learning_rate": 3.8145769938281156e-05,
      "loss": 0.029,
      "step": 27600
    },
    {
      "epoch": 1.9046964175204566,
      "grad_norm": 0.18872328102588654,
      "learning_rate": 3.8102790241889736e-05,
      "loss": 0.0287,
      "step": 27700
    },
    {
      "epoch": 1.911572577872516,
      "grad_norm": 0.17711512744426727,
      "learning_rate": 3.805981054549831e-05,
      "loss": 0.0297,
      "step": 27800
    },
    {
      "epoch": 1.9184487382245754,
      "grad_norm": 0.32551196217536926,
      "learning_rate": 3.8016830849106884e-05,
      "loss": 0.0305,
      "step": 27900
    },
    {
      "epoch": 1.9253248985766347,
      "grad_norm": 0.2861999273300171,
      "learning_rate": 3.7973851152715465e-05,
      "loss": 0.0295,
      "step": 28000
    },
    {
      "epoch": 1.9322010589286942,
      "grad_norm": 0.209346204996109,
      "learning_rate": 3.793087145632403e-05,
      "loss": 0.028,
      "step": 28100
    },
    {
      "epoch": 1.9390772192807537,
      "grad_norm": 0.19786827266216278,
      "learning_rate": 3.7887891759932606e-05,
      "loss": 0.0278,
      "step": 28200
    },
    {
      "epoch": 1.945953379632813,
      "grad_norm": 0.35954079031944275,
      "learning_rate": 3.784491206354118e-05,
      "loss": 0.0295,
      "step": 28300
    },
    {
      "epoch": 1.9528295399848723,
      "grad_norm": 0.25898316502571106,
      "learning_rate": 3.780193236714976e-05,
      "loss": 0.0308,
      "step": 28400
    },
    {
      "epoch": 1.9597057003369318,
      "grad_norm": 0.216238871216774,
      "learning_rate": 3.7758952670758334e-05,
      "loss": 0.0293,
      "step": 28500
    },
    {
      "epoch": 1.9665818606889913,
      "grad_norm": 0.21476417779922485,
      "learning_rate": 3.771597297436691e-05,
      "loss": 0.0269,
      "step": 28600
    },
    {
      "epoch": 1.9734580210410506,
      "grad_norm": 0.2717495262622833,
      "learning_rate": 3.767299327797549e-05,
      "loss": 0.0305,
      "step": 28700
    },
    {
      "epoch": 1.9803341813931101,
      "grad_norm": 0.35142651200294495,
      "learning_rate": 3.763001358158406e-05,
      "loss": 0.0297,
      "step": 28800
    },
    {
      "epoch": 1.9872103417451696,
      "grad_norm": 0.353231817483902,
      "learning_rate": 3.758703388519264e-05,
      "loss": 0.0315,
      "step": 28900
    },
    {
      "epoch": 1.994086502097229,
      "grad_norm": 0.2499394565820694,
      "learning_rate": 3.754405418880122e-05,
      "loss": 0.0323,
      "step": 29000
    },
    {
      "epoch": 2.0,
      "eval_accuracy_macro_0.5": 0.9866291284561157,
      "eval_accuracy_micro_0.5": 0.9866291284561157,
      "eval_accuracy_weighted_0.5": 0.9847993850708008,
      "eval_f1_macro_0.5": 0.8284522294998169,
      "eval_f1_macro_0.6": 0.8171122074127197,
      "eval_f1_macro_0.7": 0.7960128784179688,
      "eval_f1_macro_0.8": 0.6661859154701233,
      "eval_f1_micro_0.5": 0.8264756202697754,
      "eval_f1_micro_0.6": 0.8168911337852478,
      "eval_f1_micro_0.7": 0.7978676557540894,
      "eval_f1_micro_0.8": 0.7625684142112732,
      "eval_f1_micro_0.9": 0.6801531910896301,
      "eval_f1_weighted_0.5": 0.8234574198722839,
      "eval_f1_weighted_0.6": 0.8112407326698303,
      "eval_f1_weighted_0.7": 0.7885386347770691,
      "eval_f1_weighted_0.8": 0.6527833342552185,
      "eval_loss": 0.028044596314430237,
      "eval_runtime": 466.7419,
      "eval_samples_per_second": 62.212,
      "eval_steps_per_second": 7.777,
      "step": 29086
    },
    {
      "epoch": 2.000962662449288,
      "grad_norm": 0.3057364821434021,
      "learning_rate": 3.7501074492409785e-05,
      "loss": 0.0298,
      "step": 29100
    },
    {
      "epoch": 2.0078388228013475,
      "grad_norm": 0.5138622522354126,
      "learning_rate": 3.745809479601836e-05,
      "loss": 0.0304,
      "step": 29200
    },
    {
      "epoch": 2.0147149831534072,
      "grad_norm": 0.190320685505867,
      "learning_rate": 3.741511509962694e-05,
      "loss": 0.029,
      "step": 29300
    },
    {
      "epoch": 2.0215911435054665,
      "grad_norm": 0.218915194272995,
      "learning_rate": 3.737213540323551e-05,
      "loss": 0.0277,
      "step": 29400
    },
    {
      "epoch": 2.028467303857526,
      "grad_norm": 0.41039469838142395,
      "learning_rate": 3.732915570684409e-05,
      "loss": 0.0281,
      "step": 29500
    },
    {
      "epoch": 2.0353434642095856,
      "grad_norm": 0.250936359167099,
      "learning_rate": 3.728617601045266e-05,
      "loss": 0.0277,
      "step": 29600
    },
    {
      "epoch": 2.042219624561645,
      "grad_norm": 0.1716129630804062,
      "learning_rate": 3.724319631406124e-05,
      "loss": 0.0294,
      "step": 29700
    },
    {
      "epoch": 2.049095784913704,
      "grad_norm": 0.38918519020080566,
      "learning_rate": 3.7200216617669816e-05,
      "loss": 0.0295,
      "step": 29800
    },
    {
      "epoch": 2.0559719452657634,
      "grad_norm": 0.2986878454685211,
      "learning_rate": 3.715723692127839e-05,
      "loss": 0.0283,
      "step": 29900
    },
    {
      "epoch": 2.062848105617823,
      "grad_norm": 0.16061873733997345,
      "learning_rate": 3.711425722488697e-05,
      "loss": 0.0297,
      "step": 30000
    },
    {
      "epoch": 2.0697242659698825,
      "grad_norm": 0.18723450601100922,
      "learning_rate": 3.707127752849554e-05,
      "loss": 0.0279,
      "step": 30100
    },
    {
      "epoch": 2.0766004263219418,
      "grad_norm": 0.20585288107395172,
      "learning_rate": 3.702829783210411e-05,
      "loss": 0.0284,
      "step": 30200
    },
    {
      "epoch": 2.083476586674001,
      "grad_norm": 0.26760798692703247,
      "learning_rate": 3.698531813571269e-05,
      "loss": 0.0297,
      "step": 30300
    },
    {
      "epoch": 2.0903527470260608,
      "grad_norm": 0.34803879261016846,
      "learning_rate": 3.6942338439321266e-05,
      "loss": 0.0296,
      "step": 30400
    },
    {
      "epoch": 2.09722890737812,
      "grad_norm": 0.20308566093444824,
      "learning_rate": 3.689935874292984e-05,
      "loss": 0.0291,
      "step": 30500
    },
    {
      "epoch": 2.1041050677301794,
      "grad_norm": 0.14086464047431946,
      "learning_rate": 3.685637904653842e-05,
      "loss": 0.0287,
      "step": 30600
    },
    {
      "epoch": 2.110981228082239,
      "grad_norm": 0.21138940751552582,
      "learning_rate": 3.6813399350146994e-05,
      "loss": 0.0288,
      "step": 30700
    },
    {
      "epoch": 2.1178573884342984,
      "grad_norm": 0.13581138849258423,
      "learning_rate": 3.677041965375557e-05,
      "loss": 0.0281,
      "step": 30800
    },
    {
      "epoch": 2.1247335487863577,
      "grad_norm": 0.23438036441802979,
      "learning_rate": 3.672743995736414e-05,
      "loss": 0.0287,
      "step": 30900
    },
    {
      "epoch": 2.131609709138417,
      "grad_norm": 0.20696036517620087,
      "learning_rate": 3.668446026097272e-05,
      "loss": 0.0284,
      "step": 31000
    },
    {
      "epoch": 2.1384858694904767,
      "grad_norm": 0.2726719081401825,
      "learning_rate": 3.664148056458129e-05,
      "loss": 0.0278,
      "step": 31100
    },
    {
      "epoch": 2.145362029842536,
      "grad_norm": 0.16015659272670746,
      "learning_rate": 3.6598500868189864e-05,
      "loss": 0.0282,
      "step": 31200
    },
    {
      "epoch": 2.1522381901945953,
      "grad_norm": 0.417024701833725,
      "learning_rate": 3.6555521171798445e-05,
      "loss": 0.028,
      "step": 31300
    },
    {
      "epoch": 2.1591143505466546,
      "grad_norm": 0.29797568917274475,
      "learning_rate": 3.6512971272370934e-05,
      "loss": 0.032,
      "step": 31400
    },
    {
      "epoch": 2.1659905108987143,
      "grad_norm": 0.3209478259086609,
      "learning_rate": 3.646999157597951e-05,
      "loss": 0.0293,
      "step": 31500
    },
    {
      "epoch": 2.1728666712507736,
      "grad_norm": 0.11787465959787369,
      "learning_rate": 3.642701187958809e-05,
      "loss": 0.0282,
      "step": 31600
    },
    {
      "epoch": 2.179742831602833,
      "grad_norm": 0.14621210098266602,
      "learning_rate": 3.638403218319666e-05,
      "loss": 0.0275,
      "step": 31700
    },
    {
      "epoch": 2.1866189919548926,
      "grad_norm": 0.2811467945575714,
      "learning_rate": 3.6341052486805236e-05,
      "loss": 0.0281,
      "step": 31800
    },
    {
      "epoch": 2.193495152306952,
      "grad_norm": 0.17604336142539978,
      "learning_rate": 3.629807279041381e-05,
      "loss": 0.0276,
      "step": 31900
    },
    {
      "epoch": 2.200371312659011,
      "grad_norm": 0.3010922372341156,
      "learning_rate": 3.6255093094022384e-05,
      "loss": 0.0292,
      "step": 32000
    },
    {
      "epoch": 2.2072474730110705,
      "grad_norm": 0.44164931774139404,
      "learning_rate": 3.621211339763096e-05,
      "loss": 0.0301,
      "step": 32100
    },
    {
      "epoch": 2.2141236333631302,
      "grad_norm": 0.3049883544445038,
      "learning_rate": 3.616913370123954e-05,
      "loss": 0.028,
      "step": 32200
    },
    {
      "epoch": 2.2209997937151895,
      "grad_norm": 0.19066518545150757,
      "learning_rate": 3.612615400484811e-05,
      "loss": 0.029,
      "step": 32300
    },
    {
      "epoch": 2.227875954067249,
      "grad_norm": 0.3080463111400604,
      "learning_rate": 3.6083174308456686e-05,
      "loss": 0.0264,
      "step": 32400
    },
    {
      "epoch": 2.234752114419308,
      "grad_norm": 0.42557570338249207,
      "learning_rate": 3.604019461206527e-05,
      "loss": 0.0303,
      "step": 32500
    },
    {
      "epoch": 2.241628274771368,
      "grad_norm": 0.3416931629180908,
      "learning_rate": 3.599721491567384e-05,
      "loss": 0.0295,
      "step": 32600
    },
    {
      "epoch": 2.248504435123427,
      "grad_norm": 0.38101479411125183,
      "learning_rate": 3.5954235219282415e-05,
      "loss": 0.0286,
      "step": 32700
    },
    {
      "epoch": 2.2553805954754864,
      "grad_norm": 0.3760465383529663,
      "learning_rate": 3.591125552289099e-05,
      "loss": 0.027,
      "step": 32800
    },
    {
      "epoch": 2.2622567558275457,
      "grad_norm": 0.12079372256994247,
      "learning_rate": 3.586827582649956e-05,
      "loss": 0.0309,
      "step": 32900
    },
    {
      "epoch": 2.2691329161796054,
      "grad_norm": 0.44830644130706787,
      "learning_rate": 3.5825296130108136e-05,
      "loss": 0.0267,
      "step": 33000
    },
    {
      "epoch": 2.2760090765316647,
      "grad_norm": 0.25871869921684265,
      "learning_rate": 3.578231643371671e-05,
      "loss": 0.0292,
      "step": 33100
    },
    {
      "epoch": 2.282885236883724,
      "grad_norm": 0.13255749642848969,
      "learning_rate": 3.573933673732529e-05,
      "loss": 0.0293,
      "step": 33200
    },
    {
      "epoch": 2.2897613972357833,
      "grad_norm": 0.27958944439888,
      "learning_rate": 3.5696357040933865e-05,
      "loss": 0.0273,
      "step": 33300
    },
    {
      "epoch": 2.296637557587843,
      "grad_norm": 0.27902042865753174,
      "learning_rate": 3.565337734454244e-05,
      "loss": 0.0273,
      "step": 33400
    },
    {
      "epoch": 2.3035137179399023,
      "grad_norm": 0.33653026819229126,
      "learning_rate": 3.561039764815102e-05,
      "loss": 0.03,
      "step": 33500
    },
    {
      "epoch": 2.3103898782919616,
      "grad_norm": 0.06798574328422546,
      "learning_rate": 3.5567417951759593e-05,
      "loss": 0.029,
      "step": 33600
    },
    {
      "epoch": 2.3172660386440214,
      "grad_norm": 0.13604436814785004,
      "learning_rate": 3.552443825536817e-05,
      "loss": 0.0281,
      "step": 33700
    },
    {
      "epoch": 2.3241421989960807,
      "grad_norm": 0.33651354908943176,
      "learning_rate": 3.548231815290457e-05,
      "loss": 0.0283,
      "step": 33800
    },
    {
      "epoch": 2.33101835934814,
      "grad_norm": 0.33782958984375,
      "learning_rate": 3.5439338456513146e-05,
      "loss": 0.0295,
      "step": 33900
    },
    {
      "epoch": 2.3378945197001992,
      "grad_norm": 0.20569266378879547,
      "learning_rate": 3.539635876012172e-05,
      "loss": 0.0258,
      "step": 34000
    },
    {
      "epoch": 2.344770680052259,
      "grad_norm": 0.16220730543136597,
      "learning_rate": 3.535337906373029e-05,
      "loss": 0.0292,
      "step": 34100
    },
    {
      "epoch": 2.3516468404043183,
      "grad_norm": 0.20292659103870392,
      "learning_rate": 3.531039936733887e-05,
      "loss": 0.0277,
      "step": 34200
    },
    {
      "epoch": 2.3585230007563776,
      "grad_norm": 0.36042746901512146,
      "learning_rate": 3.526741967094744e-05,
      "loss": 0.0285,
      "step": 34300
    },
    {
      "epoch": 2.365399161108437,
      "grad_norm": 0.24450822174549103,
      "learning_rate": 3.522443997455602e-05,
      "loss": 0.0295,
      "step": 34400
    },
    {
      "epoch": 2.3722753214604966,
      "grad_norm": 0.1322399079799652,
      "learning_rate": 3.5181460278164596e-05,
      "loss": 0.027,
      "step": 34500
    },
    {
      "epoch": 2.379151481812556,
      "grad_norm": 0.19298604130744934,
      "learning_rate": 3.513848058177317e-05,
      "loss": 0.0268,
      "step": 34600
    },
    {
      "epoch": 2.386027642164615,
      "grad_norm": 0.2706140875816345,
      "learning_rate": 3.509550088538175e-05,
      "loss": 0.0271,
      "step": 34700
    },
    {
      "epoch": 2.392903802516675,
      "grad_norm": 0.23074378073215485,
      "learning_rate": 3.5052521188990324e-05,
      "loss": 0.0258,
      "step": 34800
    },
    {
      "epoch": 2.399779962868734,
      "grad_norm": 0.48192116618156433,
      "learning_rate": 3.50095414925989e-05,
      "loss": 0.0264,
      "step": 34900
    },
    {
      "epoch": 2.4066561232207935,
      "grad_norm": 0.2383706122636795,
      "learning_rate": 3.496656179620747e-05,
      "loss": 0.0246,
      "step": 35000
    },
    {
      "epoch": 2.4135322835728528,
      "grad_norm": 0.35845792293548584,
      "learning_rate": 3.4923582099816046e-05,
      "loss": 0.0267,
      "step": 35100
    },
    {
      "epoch": 2.4204084439249125,
      "grad_norm": 0.19974622130393982,
      "learning_rate": 3.488060240342462e-05,
      "loss": 0.0291,
      "step": 35200
    },
    {
      "epoch": 2.427284604276972,
      "grad_norm": 0.23642663657665253,
      "learning_rate": 3.48376227070332e-05,
      "loss": 0.0267,
      "step": 35300
    },
    {
      "epoch": 2.434160764629031,
      "grad_norm": 0.36086633801460266,
      "learning_rate": 3.4794643010641775e-05,
      "loss": 0.0265,
      "step": 35400
    },
    {
      "epoch": 2.4410369249810904,
      "grad_norm": 0.4887775778770447,
      "learning_rate": 3.475166331425035e-05,
      "loss": 0.0294,
      "step": 35500
    },
    {
      "epoch": 2.44791308533315,
      "grad_norm": 0.3099674582481384,
      "learning_rate": 3.470868361785892e-05,
      "loss": 0.0278,
      "step": 35600
    },
    {
      "epoch": 2.4547892456852094,
      "grad_norm": 0.19382807612419128,
      "learning_rate": 3.46657039214675e-05,
      "loss": 0.0288,
      "step": 35700
    },
    {
      "epoch": 2.4616654060372687,
      "grad_norm": 0.2858067750930786,
      "learning_rate": 3.462272422507608e-05,
      "loss": 0.0293,
      "step": 35800
    },
    {
      "epoch": 2.4685415663893284,
      "grad_norm": 0.21481060981750488,
      "learning_rate": 3.457974452868465e-05,
      "loss": 0.0272,
      "step": 35900
    },
    {
      "epoch": 2.4754177267413877,
      "grad_norm": 0.21813194453716278,
      "learning_rate": 3.4536764832293225e-05,
      "loss": 0.0271,
      "step": 36000
    },
    {
      "epoch": 2.482293887093447,
      "grad_norm": 0.20056690275669098,
      "learning_rate": 3.44937851359018e-05,
      "loss": 0.0284,
      "step": 36100
    },
    {
      "epoch": 2.4891700474455063,
      "grad_norm": 0.3236292600631714,
      "learning_rate": 3.445080543951037e-05,
      "loss": 0.0268,
      "step": 36200
    },
    {
      "epoch": 2.496046207797566,
      "grad_norm": 0.17860916256904602,
      "learning_rate": 3.440782574311895e-05,
      "loss": 0.0284,
      "step": 36300
    },
    {
      "epoch": 2.5029223681496253,
      "grad_norm": 0.3090613782405853,
      "learning_rate": 3.436484604672753e-05,
      "loss": 0.0269,
      "step": 36400
    },
    {
      "epoch": 2.5097985285016846,
      "grad_norm": 0.3198346793651581,
      "learning_rate": 3.43218663503361e-05,
      "loss": 0.031,
      "step": 36500
    },
    {
      "epoch": 2.516674688853744,
      "grad_norm": 0.33853206038475037,
      "learning_rate": 3.427888665394468e-05,
      "loss": 0.0258,
      "step": 36600
    },
    {
      "epoch": 2.5235508492058036,
      "grad_norm": 0.20343883335590363,
      "learning_rate": 3.4235906957553256e-05,
      "loss": 0.0264,
      "step": 36700
    },
    {
      "epoch": 2.530427009557863,
      "grad_norm": 0.4155529737472534,
      "learning_rate": 3.419292726116183e-05,
      "loss": 0.0293,
      "step": 36800
    },
    {
      "epoch": 2.537303169909922,
      "grad_norm": 0.2334669828414917,
      "learning_rate": 3.415037736173432e-05,
      "loss": 0.0273,
      "step": 36900
    },
    {
      "epoch": 2.544179330261982,
      "grad_norm": 0.15448646247386932,
      "learning_rate": 3.410739766534289e-05,
      "loss": 0.0245,
      "step": 37000
    },
    {
      "epoch": 2.5510554906140412,
      "grad_norm": 0.16402184963226318,
      "learning_rate": 3.4064417968951466e-05,
      "loss": 0.0278,
      "step": 37100
    },
    {
      "epoch": 2.5579316509661005,
      "grad_norm": 0.14943476021289825,
      "learning_rate": 3.402143827256005e-05,
      "loss": 0.0259,
      "step": 37200
    },
    {
      "epoch": 2.56480781131816,
      "grad_norm": 0.28720125555992126,
      "learning_rate": 3.397845857616862e-05,
      "loss": 0.0307,
      "step": 37300
    },
    {
      "epoch": 2.571683971670219,
      "grad_norm": 0.3794570863246918,
      "learning_rate": 3.3935478879777195e-05,
      "loss": 0.0283,
      "step": 37400
    },
    {
      "epoch": 2.578560132022279,
      "grad_norm": 0.17257556319236755,
      "learning_rate": 3.389249918338577e-05,
      "loss": 0.03,
      "step": 37500
    },
    {
      "epoch": 2.585436292374338,
      "grad_norm": 0.2461409717798233,
      "learning_rate": 3.384951948699435e-05,
      "loss": 0.0292,
      "step": 37600
    },
    {
      "epoch": 2.5923124527263974,
      "grad_norm": 0.17962943017482758,
      "learning_rate": 3.3806539790602923e-05,
      "loss": 0.0279,
      "step": 37700
    },
    {
      "epoch": 2.599188613078457,
      "grad_norm": 0.11821748316287994,
      "learning_rate": 3.376356009421149e-05,
      "loss": 0.0285,
      "step": 37800
    },
    {
      "epoch": 2.6060647734305165,
      "grad_norm": 0.290457159280777,
      "learning_rate": 3.372058039782007e-05,
      "loss": 0.0269,
      "step": 37900
    },
    {
      "epoch": 2.6129409337825757,
      "grad_norm": 0.15826813876628876,
      "learning_rate": 3.3677600701428645e-05,
      "loss": 0.0257,
      "step": 38000
    },
    {
      "epoch": 2.6198170941346355,
      "grad_norm": 0.29798412322998047,
      "learning_rate": 3.363462100503722e-05,
      "loss": 0.0283,
      "step": 38100
    },
    {
      "epoch": 2.6266932544866948,
      "grad_norm": 0.21686123311519623,
      "learning_rate": 3.35916413086458e-05,
      "loss": 0.0256,
      "step": 38200
    },
    {
      "epoch": 2.633569414838754,
      "grad_norm": 0.09053986519575119,
      "learning_rate": 3.3548661612254374e-05,
      "loss": 0.0295,
      "step": 38300
    },
    {
      "epoch": 2.6404455751908134,
      "grad_norm": 0.17924489080905914,
      "learning_rate": 3.350568191586295e-05,
      "loss": 0.0272,
      "step": 38400
    },
    {
      "epoch": 2.6473217355428726,
      "grad_norm": 0.21701166033744812,
      "learning_rate": 3.346270221947153e-05,
      "loss": 0.0266,
      "step": 38500
    },
    {
      "epoch": 2.6541978958949324,
      "grad_norm": 0.2273956835269928,
      "learning_rate": 3.34197225230801e-05,
      "loss": 0.0279,
      "step": 38600
    },
    {
      "epoch": 2.6610740562469917,
      "grad_norm": 0.3825787901878357,
      "learning_rate": 3.3376742826688676e-05,
      "loss": 0.0304,
      "step": 38700
    },
    {
      "epoch": 2.667950216599051,
      "grad_norm": 0.1774001121520996,
      "learning_rate": 3.333376313029725e-05,
      "loss": 0.0278,
      "step": 38800
    },
    {
      "epoch": 2.6748263769511107,
      "grad_norm": 0.26000329852104187,
      "learning_rate": 3.3290783433905824e-05,
      "loss": 0.0308,
      "step": 38900
    },
    {
      "epoch": 2.68170253730317,
      "grad_norm": 0.26614975929260254,
      "learning_rate": 3.32478037375144e-05,
      "loss": 0.0263,
      "step": 39000
    },
    {
      "epoch": 2.6885786976552293,
      "grad_norm": 0.10978269577026367,
      "learning_rate": 3.3205253838086894e-05,
      "loss": 0.0267,
      "step": 39100
    },
    {
      "epoch": 2.6954548580072886,
      "grad_norm": 0.18940283358097076,
      "learning_rate": 3.3162703938659376e-05,
      "loss": 0.029,
      "step": 39200
    },
    {
      "epoch": 2.7023310183593483,
      "grad_norm": 0.1862153261899948,
      "learning_rate": 3.311972424226795e-05,
      "loss": 0.0261,
      "step": 39300
    },
    {
      "epoch": 2.7092071787114076,
      "grad_norm": 0.3928709328174591,
      "learning_rate": 3.307674454587653e-05,
      "loss": 0.0281,
      "step": 39400
    },
    {
      "epoch": 2.716083339063467,
      "grad_norm": 0.14349620044231415,
      "learning_rate": 3.3033764849485105e-05,
      "loss": 0.0275,
      "step": 39500
    },
    {
      "epoch": 2.722959499415526,
      "grad_norm": 0.12612523138523102,
      "learning_rate": 3.299078515309368e-05,
      "loss": 0.026,
      "step": 39600
    },
    {
      "epoch": 2.729835659767586,
      "grad_norm": 0.2480655014514923,
      "learning_rate": 3.294780545670226e-05,
      "loss": 0.0262,
      "step": 39700
    },
    {
      "epoch": 2.736711820119645,
      "grad_norm": 0.18392755091190338,
      "learning_rate": 3.290482576031083e-05,
      "loss": 0.025,
      "step": 39800
    },
    {
      "epoch": 2.7435879804717045,
      "grad_norm": 0.18395622074604034,
      "learning_rate": 3.286184606391941e-05,
      "loss": 0.0271,
      "step": 39900
    },
    {
      "epoch": 2.7504641408237642,
      "grad_norm": 0.19594964385032654,
      "learning_rate": 3.281886636752798e-05,
      "loss": 0.0288,
      "step": 40000
    },
    {
      "epoch": 2.7573403011758235,
      "grad_norm": 0.2606758177280426,
      "learning_rate": 3.2775886671136555e-05,
      "loss": 0.0259,
      "step": 40100
    },
    {
      "epoch": 2.764216461527883,
      "grad_norm": 0.14804919064044952,
      "learning_rate": 3.273290697474513e-05,
      "loss": 0.026,
      "step": 40200
    },
    {
      "epoch": 2.771092621879942,
      "grad_norm": 0.2762278914451599,
      "learning_rate": 3.26899272783537e-05,
      "loss": 0.0269,
      "step": 40300
    },
    {
      "epoch": 2.7779687822320014,
      "grad_norm": 0.39866507053375244,
      "learning_rate": 3.264694758196228e-05,
      "loss": 0.0273,
      "step": 40400
    },
    {
      "epoch": 2.784844942584061,
      "grad_norm": 0.23012815415859222,
      "learning_rate": 3.260396788557086e-05,
      "loss": 0.0239,
      "step": 40500
    },
    {
      "epoch": 2.7917211029361204,
      "grad_norm": 0.25060126185417175,
      "learning_rate": 3.256098818917943e-05,
      "loss": 0.0263,
      "step": 40600
    },
    {
      "epoch": 2.7985972632881797,
      "grad_norm": 0.2688923180103302,
      "learning_rate": 3.251800849278801e-05,
      "loss": 0.0293,
      "step": 40700
    },
    {
      "epoch": 2.8054734236402394,
      "grad_norm": 0.21133729815483093,
      "learning_rate": 3.2475028796396586e-05,
      "loss": 0.0295,
      "step": 40800
    },
    {
      "epoch": 2.8123495839922987,
      "grad_norm": 0.19784675538539886,
      "learning_rate": 3.243204910000516e-05,
      "loss": 0.029,
      "step": 40900
    },
    {
      "epoch": 2.819225744344358,
      "grad_norm": 0.16246065497398376,
      "learning_rate": 3.2389069403613734e-05,
      "loss": 0.0247,
      "step": 41000
    },
    {
      "epoch": 2.8261019046964178,
      "grad_norm": 0.1412133276462555,
      "learning_rate": 3.234651950418622e-05,
      "loss": 0.0294,
      "step": 41100
    },
    {
      "epoch": 2.832978065048477,
      "grad_norm": 0.2831330895423889,
      "learning_rate": 3.2303539807794796e-05,
      "loss": 0.0285,
      "step": 41200
    },
    {
      "epoch": 2.8398542254005363,
      "grad_norm": 0.1576903611421585,
      "learning_rate": 3.226056011140338e-05,
      "loss": 0.0255,
      "step": 41300
    },
    {
      "epoch": 2.8467303857525956,
      "grad_norm": 0.2053927779197693,
      "learning_rate": 3.221758041501195e-05,
      "loss": 0.0279,
      "step": 41400
    },
    {
      "epoch": 2.853606546104655,
      "grad_norm": 0.24907109141349792,
      "learning_rate": 3.2174600718620525e-05,
      "loss": 0.0252,
      "step": 41500
    },
    {
      "epoch": 2.8604827064567147,
      "grad_norm": 0.24940700829029083,
      "learning_rate": 3.2131621022229106e-05,
      "loss": 0.0275,
      "step": 41600
    },
    {
      "epoch": 2.867358866808774,
      "grad_norm": 0.13816243410110474,
      "learning_rate": 3.208864132583767e-05,
      "loss": 0.0258,
      "step": 41700
    },
    {
      "epoch": 2.8742350271608332,
      "grad_norm": 0.26742950081825256,
      "learning_rate": 3.204566162944625e-05,
      "loss": 0.0261,
      "step": 41800
    },
    {
      "epoch": 2.881111187512893,
      "grad_norm": 0.7995902299880981,
      "learning_rate": 3.200268193305483e-05,
      "loss": 0.0253,
      "step": 41900
    },
    {
      "epoch": 2.8879873478649523,
      "grad_norm": 0.1730484962463379,
      "learning_rate": 3.19597022366634e-05,
      "loss": 0.026,
      "step": 42000
    },
    {
      "epoch": 2.8948635082170115,
      "grad_norm": 0.27168595790863037,
      "learning_rate": 3.1916722540271975e-05,
      "loss": 0.0233,
      "step": 42100
    },
    {
      "epoch": 2.9017396685690713,
      "grad_norm": 0.22323529422283173,
      "learning_rate": 3.187374284388055e-05,
      "loss": 0.0258,
      "step": 42200
    },
    {
      "epoch": 2.9086158289211306,
      "grad_norm": 0.2114347368478775,
      "learning_rate": 3.183076314748913e-05,
      "loss": 0.0263,
      "step": 42300
    },
    {
      "epoch": 2.91549198927319,
      "grad_norm": 0.13864880800247192,
      "learning_rate": 3.1787783451097704e-05,
      "loss": 0.0256,
      "step": 42400
    },
    {
      "epoch": 2.922368149625249,
      "grad_norm": 0.5784207582473755,
      "learning_rate": 3.174480375470628e-05,
      "loss": 0.0282,
      "step": 42500
    },
    {
      "epoch": 2.9292443099773084,
      "grad_norm": 0.11900349706411362,
      "learning_rate": 3.170182405831486e-05,
      "loss": 0.026,
      "step": 42600
    },
    {
      "epoch": 2.936120470329368,
      "grad_norm": 0.3089665174484253,
      "learning_rate": 3.1658844361923425e-05,
      "loss": 0.0275,
      "step": 42700
    },
    {
      "epoch": 2.9429966306814275,
      "grad_norm": 0.2786613404750824,
      "learning_rate": 3.1615864665532e-05,
      "loss": 0.0257,
      "step": 42800
    },
    {
      "epoch": 2.9498727910334868,
      "grad_norm": 0.409840852022171,
      "learning_rate": 3.157288496914058e-05,
      "loss": 0.0269,
      "step": 42900
    },
    {
      "epoch": 2.9567489513855465,
      "grad_norm": 0.18198934197425842,
      "learning_rate": 3.1529905272749154e-05,
      "loss": 0.0262,
      "step": 43000
    },
    {
      "epoch": 2.963625111737606,
      "grad_norm": 0.13694410026073456,
      "learning_rate": 3.148692557635773e-05,
      "loss": 0.0272,
      "step": 43100
    },
    {
      "epoch": 2.970501272089665,
      "grad_norm": 0.21283258497714996,
      "learning_rate": 3.144394587996631e-05,
      "loss": 0.0242,
      "step": 43200
    },
    {
      "epoch": 2.977377432441725,
      "grad_norm": 0.3066132366657257,
      "learning_rate": 3.140096618357488e-05,
      "loss": 0.0274,
      "step": 43300
    },
    {
      "epoch": 2.984253592793784,
      "grad_norm": 0.21328552067279816,
      "learning_rate": 3.1357986487183456e-05,
      "loss": 0.0265,
      "step": 43400
    },
    {
      "epoch": 2.9911297531458434,
      "grad_norm": 0.4905264675617218,
      "learning_rate": 3.131500679079203e-05,
      "loss": 0.0261,
      "step": 43500
    },
    {
      "epoch": 2.9980059134979027,
      "grad_norm": 0.20830920338630676,
      "learning_rate": 3.127202709440061e-05,
      "loss": 0.0243,
      "step": 43600
    },
    {
      "epoch": 3.0,
      "eval_accuracy_macro_0.5": 0.9875137805938721,
      "eval_accuracy_micro_0.5": 0.9875137805938721,
      "eval_accuracy_weighted_0.5": 0.9857364296913147,
      "eval_f1_macro_0.5": 0.8423940539360046,
      "eval_f1_macro_0.6": 0.8363315463066101,
      "eval_f1_macro_0.7": 0.8214860558509827,
      "eval_f1_macro_0.8": 0.7141857147216797,
      "eval_f1_micro_0.5": 0.8391693830490112,
      "eval_f1_micro_0.6": 0.8348281979560852,
      "eval_f1_micro_0.7": 0.8212248086929321,
      "eval_f1_micro_0.8": 0.7900835275650024,
      "eval_f1_micro_0.9": 0.7225371599197388,
      "eval_f1_weighted_0.5": 0.8375856280326843,
      "eval_f1_weighted_0.6": 0.8309932351112366,
      "eval_f1_weighted_0.7": 0.8147048354148865,
      "eval_f1_weighted_0.8": 0.7021979093551636,
      "eval_loss": 0.025702912360429764,
      "eval_runtime": 441.1753,
      "eval_samples_per_second": 65.817,
      "eval_steps_per_second": 8.228,
      "step": 43629
    },
    {
      "epoch": 3.004882073849962,
      "grad_norm": 0.3161596953868866,
      "learning_rate": 3.122904739800918e-05,
      "loss": 0.0251,
      "step": 43700
    },
    {
      "epoch": 3.0117582342020217,
      "grad_norm": 0.25387802720069885,
      "learning_rate": 3.118606770161775e-05,
      "loss": 0.0238,
      "step": 43800
    },
    {
      "epoch": 3.018634394554081,
      "grad_norm": 0.2123366743326187,
      "learning_rate": 3.114308800522633e-05,
      "loss": 0.0248,
      "step": 43900
    },
    {
      "epoch": 3.0255105549061403,
      "grad_norm": 0.3986639976501465,
      "learning_rate": 3.110010830883491e-05,
      "loss": 0.0249,
      "step": 44000
    },
    {
      "epoch": 3.0323867152582,
      "grad_norm": 0.12837357819080353,
      "learning_rate": 3.105712861244348e-05,
      "loss": 0.0239,
      "step": 44100
    },
    {
      "epoch": 3.0392628756102593,
      "grad_norm": 0.1879049688577652,
      "learning_rate": 3.101414891605206e-05,
      "loss": 0.0278,
      "step": 44200
    },
    {
      "epoch": 3.0461390359623186,
      "grad_norm": 0.2435997724533081,
      "learning_rate": 3.0971169219660635e-05,
      "loss": 0.026,
      "step": 44300
    },
    {
      "epoch": 3.053015196314378,
      "grad_norm": 0.34687772393226624,
      "learning_rate": 3.092818952326921e-05,
      "loss": 0.0246,
      "step": 44400
    },
    {
      "epoch": 3.0598913566664376,
      "grad_norm": 0.3419852554798126,
      "learning_rate": 3.088520982687779e-05,
      "loss": 0.0252,
      "step": 44500
    },
    {
      "epoch": 3.066767517018497,
      "grad_norm": 0.3232717216014862,
      "learning_rate": 3.0842230130486364e-05,
      "loss": 0.0262,
      "step": 44600
    },
    {
      "epoch": 3.073643677370556,
      "grad_norm": 0.2967439889907837,
      "learning_rate": 3.079925043409493e-05,
      "loss": 0.0273,
      "step": 44700
    },
    {
      "epoch": 3.0805198377226155,
      "grad_norm": 0.13536153733730316,
      "learning_rate": 3.075627073770351e-05,
      "loss": 0.0279,
      "step": 44800
    },
    {
      "epoch": 3.0873959980746752,
      "grad_norm": 0.1474723219871521,
      "learning_rate": 3.0713291041312085e-05,
      "loss": 0.0241,
      "step": 44900
    },
    {
      "epoch": 3.0942721584267345,
      "grad_norm": 0.14061352610588074,
      "learning_rate": 3.067031134492066e-05,
      "loss": 0.0244,
      "step": 45000
    },
    {
      "epoch": 3.101148318778794,
      "grad_norm": 0.3126330077648163,
      "learning_rate": 3.062733164852923e-05,
      "loss": 0.0261,
      "step": 45100
    },
    {
      "epoch": 3.1080244791308536,
      "grad_norm": 0.28019386529922485,
      "learning_rate": 3.0584351952137814e-05,
      "loss": 0.0243,
      "step": 45200
    },
    {
      "epoch": 3.114900639482913,
      "grad_norm": 0.12333910167217255,
      "learning_rate": 3.054137225574639e-05,
      "loss": 0.0238,
      "step": 45300
    },
    {
      "epoch": 3.121776799834972,
      "grad_norm": 0.4298861622810364,
      "learning_rate": 3.0498392559354962e-05,
      "loss": 0.0235,
      "step": 45400
    },
    {
      "epoch": 3.1286529601870314,
      "grad_norm": 0.2228679656982422,
      "learning_rate": 3.045541286296354e-05,
      "loss": 0.0246,
      "step": 45500
    },
    {
      "epoch": 3.135529120539091,
      "grad_norm": 0.14480483531951904,
      "learning_rate": 3.0412433166572113e-05,
      "loss": 0.0233,
      "step": 45600
    },
    {
      "epoch": 3.1424052808911505,
      "grad_norm": 0.3214283883571625,
      "learning_rate": 3.0369453470180687e-05,
      "loss": 0.0252,
      "step": 45700
    },
    {
      "epoch": 3.1492814412432097,
      "grad_norm": 0.2455417960882187,
      "learning_rate": 3.0326473773789264e-05,
      "loss": 0.0238,
      "step": 45800
    },
    {
      "epoch": 3.156157601595269,
      "grad_norm": 0.18660999834537506,
      "learning_rate": 3.0283494077397838e-05,
      "loss": 0.0244,
      "step": 45900
    },
    {
      "epoch": 3.1630337619473288,
      "grad_norm": 0.38012510538101196,
      "learning_rate": 3.0240514381006412e-05,
      "loss": 0.0252,
      "step": 46000
    },
    {
      "epoch": 3.169909922299388,
      "grad_norm": 0.1451648473739624,
      "learning_rate": 3.0197534684614993e-05,
      "loss": 0.0247,
      "step": 46100
    },
    {
      "epoch": 3.1767860826514474,
      "grad_norm": 0.28720924258232117,
      "learning_rate": 3.0154554988223567e-05,
      "loss": 0.0237,
      "step": 46200
    },
    {
      "epoch": 3.1836622430035066,
      "grad_norm": 0.16505955159664154,
      "learning_rate": 3.011157529183214e-05,
      "loss": 0.0244,
      "step": 46300
    },
    {
      "epoch": 3.1905384033555664,
      "grad_norm": 0.14519086480140686,
      "learning_rate": 3.0068595595440714e-05,
      "loss": 0.025,
      "step": 46400
    },
    {
      "epoch": 3.1974145637076257,
      "grad_norm": 0.21251270174980164,
      "learning_rate": 3.0025615899049292e-05,
      "loss": 0.0265,
      "step": 46500
    },
    {
      "epoch": 3.204290724059685,
      "grad_norm": 0.14343689382076263,
      "learning_rate": 2.9982636202657866e-05,
      "loss": 0.0239,
      "step": 46600
    },
    {
      "epoch": 3.2111668844117442,
      "grad_norm": 0.11527570337057114,
      "learning_rate": 2.993965650626644e-05,
      "loss": 0.026,
      "step": 46700
    },
    {
      "epoch": 3.218043044763804,
      "grad_norm": 0.4225611984729767,
      "learning_rate": 2.9896676809875017e-05,
      "loss": 0.0244,
      "step": 46800
    },
    {
      "epoch": 3.2249192051158633,
      "grad_norm": 0.3619830310344696,
      "learning_rate": 2.985369711348359e-05,
      "loss": 0.0243,
      "step": 46900
    },
    {
      "epoch": 3.2317953654679226,
      "grad_norm": 0.2762942910194397,
      "learning_rate": 2.9810717417092165e-05,
      "loss": 0.0249,
      "step": 47000
    },
    {
      "epoch": 3.2386715258199823,
      "grad_norm": 0.2292248010635376,
      "learning_rate": 2.9767737720700745e-05,
      "loss": 0.0246,
      "step": 47100
    },
    {
      "epoch": 3.2455476861720416,
      "grad_norm": 0.21537108719348907,
      "learning_rate": 2.972475802430932e-05,
      "loss": 0.0248,
      "step": 47200
    },
    {
      "epoch": 3.252423846524101,
      "grad_norm": 0.19233918190002441,
      "learning_rate": 2.9681778327917893e-05,
      "loss": 0.0251,
      "step": 47300
    },
    {
      "epoch": 3.25930000687616,
      "grad_norm": 0.25863558053970337,
      "learning_rate": 2.963879863152647e-05,
      "loss": 0.0241,
      "step": 47400
    },
    {
      "epoch": 3.26617616722822,
      "grad_norm": 0.1893516182899475,
      "learning_rate": 2.9595818935135044e-05,
      "loss": 0.0238,
      "step": 47500
    },
    {
      "epoch": 3.273052327580279,
      "grad_norm": 0.3159900903701782,
      "learning_rate": 2.9552839238743618e-05,
      "loss": 0.0245,
      "step": 47600
    },
    {
      "epoch": 3.2799284879323385,
      "grad_norm": 0.39456334710121155,
      "learning_rate": 2.9509859542352192e-05,
      "loss": 0.0249,
      "step": 47700
    },
    {
      "epoch": 3.286804648284398,
      "grad_norm": 0.1024714782834053,
      "learning_rate": 2.9467309642924685e-05,
      "loss": 0.0282,
      "step": 47800
    },
    {
      "epoch": 3.2936808086364575,
      "grad_norm": 0.30639803409576416,
      "learning_rate": 2.942432994653326e-05,
      "loss": 0.0255,
      "step": 47900
    },
    {
      "epoch": 3.300556968988517,
      "grad_norm": 0.29214897751808167,
      "learning_rate": 2.9381350250141836e-05,
      "loss": 0.0255,
      "step": 48000
    },
    {
      "epoch": 3.307433129340576,
      "grad_norm": 0.26890790462493896,
      "learning_rate": 2.933837055375041e-05,
      "loss": 0.0274,
      "step": 48100
    },
    {
      "epoch": 3.314309289692636,
      "grad_norm": 0.4951225519180298,
      "learning_rate": 2.9295390857358984e-05,
      "loss": 0.0289,
      "step": 48200
    },
    {
      "epoch": 3.321185450044695,
      "grad_norm": 0.16707073152065277,
      "learning_rate": 2.9252411160967558e-05,
      "loss": 0.0253,
      "step": 48300
    },
    {
      "epoch": 3.3280616103967544,
      "grad_norm": 0.25991764664649963,
      "learning_rate": 2.9209431464576138e-05,
      "loss": 0.0231,
      "step": 48400
    },
    {
      "epoch": 3.3349377707488137,
      "grad_norm": 0.2178533524274826,
      "learning_rate": 2.916645176818471e-05,
      "loss": 0.027,
      "step": 48500
    },
    {
      "epoch": 3.3418139311008734,
      "grad_norm": 0.30666929483413696,
      "learning_rate": 2.9123472071793283e-05,
      "loss": 0.0248,
      "step": 48600
    },
    {
      "epoch": 3.3486900914529327,
      "grad_norm": 0.22759731113910675,
      "learning_rate": 2.9080492375401863e-05,
      "loss": 0.0247,
      "step": 48700
    },
    {
      "epoch": 3.355566251804992,
      "grad_norm": 0.21557900309562683,
      "learning_rate": 2.9037512679010437e-05,
      "loss": 0.0205,
      "step": 48800
    },
    {
      "epoch": 3.3624424121570513,
      "grad_norm": 0.21406175196170807,
      "learning_rate": 2.899453298261901e-05,
      "loss": 0.0242,
      "step": 48900
    },
    {
      "epoch": 3.369318572509111,
      "grad_norm": 0.36095473170280457,
      "learning_rate": 2.895155328622759e-05,
      "loss": 0.0245,
      "step": 49000
    },
    {
      "epoch": 3.3761947328611703,
      "grad_norm": 0.21614083647727966,
      "learning_rate": 2.8908573589836162e-05,
      "loss": 0.0236,
      "step": 49100
    },
    {
      "epoch": 3.3830708932132296,
      "grad_norm": 0.21759702265262604,
      "learning_rate": 2.8865593893444736e-05,
      "loss": 0.0252,
      "step": 49200
    },
    {
      "epoch": 3.3899470535652894,
      "grad_norm": 0.27491724491119385,
      "learning_rate": 2.8822614197053317e-05,
      "loss": 0.0255,
      "step": 49300
    },
    {
      "epoch": 3.3968232139173486,
      "grad_norm": 0.223835751414299,
      "learning_rate": 2.877963450066189e-05,
      "loss": 0.0248,
      "step": 49400
    },
    {
      "epoch": 3.403699374269408,
      "grad_norm": 0.33483925461769104,
      "learning_rate": 2.873665480427046e-05,
      "loss": 0.0276,
      "step": 49500
    },
    {
      "epoch": 3.4105755346214672,
      "grad_norm": 0.4984988868236542,
      "learning_rate": 2.8693675107879035e-05,
      "loss": 0.028,
      "step": 49600
    },
    {
      "epoch": 3.417451694973527,
      "grad_norm": 0.1270032376050949,
      "learning_rate": 2.8650695411487616e-05,
      "loss": 0.0235,
      "step": 49700
    },
    {
      "epoch": 3.4243278553255863,
      "grad_norm": 0.16835473477840424,
      "learning_rate": 2.860771571509619e-05,
      "loss": 0.0256,
      "step": 49800
    },
    {
      "epoch": 3.4312040156776455,
      "grad_norm": 0.25365111231803894,
      "learning_rate": 2.8564736018704764e-05,
      "loss": 0.0248,
      "step": 49900
    },
    {
      "epoch": 3.438080176029705,
      "grad_norm": 0.27820953726768494,
      "learning_rate": 2.852175632231334e-05,
      "loss": 0.0234,
      "step": 50000
    },
    {
      "epoch": 3.4449563363817646,
      "grad_norm": 0.14426515996456146,
      "learning_rate": 2.8478776625921915e-05,
      "loss": 0.0246,
      "step": 50100
    },
    {
      "epoch": 3.451832496733824,
      "grad_norm": 0.24194563925266266,
      "learning_rate": 2.843579692953049e-05,
      "loss": 0.0267,
      "step": 50200
    },
    {
      "epoch": 3.458708657085883,
      "grad_norm": 0.15507785975933075,
      "learning_rate": 2.839281723313907e-05,
      "loss": 0.0244,
      "step": 50300
    },
    {
      "epoch": 3.465584817437943,
      "grad_norm": 0.18539193272590637,
      "learning_rate": 2.8349837536747644e-05,
      "loss": 0.0239,
      "step": 50400
    },
    {
      "epoch": 3.472460977790002,
      "grad_norm": 0.19823656976222992,
      "learning_rate": 2.8306857840356214e-05,
      "loss": 0.026,
      "step": 50500
    },
    {
      "epoch": 3.4793371381420615,
      "grad_norm": 0.13981950283050537,
      "learning_rate": 2.8263878143964795e-05,
      "loss": 0.0277,
      "step": 50600
    },
    {
      "epoch": 3.4862132984941208,
      "grad_norm": 0.244024395942688,
      "learning_rate": 2.822089844757337e-05,
      "loss": 0.0258,
      "step": 50700
    },
    {
      "epoch": 3.49308945884618,
      "grad_norm": 0.22432255744934082,
      "learning_rate": 2.8177918751181943e-05,
      "loss": 0.0226,
      "step": 50800
    },
    {
      "epoch": 3.49996561919824,
      "grad_norm": 0.31565797328948975,
      "learning_rate": 2.8134939054790517e-05,
      "loss": 0.0236,
      "step": 50900
    },
    {
      "epoch": 3.506841779550299,
      "grad_norm": 0.13325464725494385,
      "learning_rate": 2.8091959358399094e-05,
      "loss": 0.0269,
      "step": 51000
    },
    {
      "epoch": 3.5137179399023584,
      "grad_norm": 0.3319816291332245,
      "learning_rate": 2.8048979662007668e-05,
      "loss": 0.0262,
      "step": 51100
    },
    {
      "epoch": 3.520594100254418,
      "grad_norm": 0.1829322725534439,
      "learning_rate": 2.800599996561624e-05,
      "loss": 0.0241,
      "step": 51200
    },
    {
      "epoch": 3.5274702606064774,
      "grad_norm": 0.17792338132858276,
      "learning_rate": 2.7963020269224822e-05,
      "loss": 0.0258,
      "step": 51300
    },
    {
      "epoch": 3.5343464209585367,
      "grad_norm": 0.21597188711166382,
      "learning_rate": 2.7920040572833396e-05,
      "loss": 0.025,
      "step": 51400
    },
    {
      "epoch": 3.5412225813105964,
      "grad_norm": 0.190560981631279,
      "learning_rate": 2.7877060876441967e-05,
      "loss": 0.0238,
      "step": 51500
    },
    {
      "epoch": 3.5480987416626557,
      "grad_norm": 0.21825572848320007,
      "learning_rate": 2.7834081180050547e-05,
      "loss": 0.0257,
      "step": 51600
    },
    {
      "epoch": 3.554974902014715,
      "grad_norm": 0.30411890149116516,
      "learning_rate": 2.779110148365912e-05,
      "loss": 0.0248,
      "step": 51700
    },
    {
      "epoch": 3.5618510623667743,
      "grad_norm": 0.2623271942138672,
      "learning_rate": 2.7748121787267695e-05,
      "loss": 0.0288,
      "step": 51800
    },
    {
      "epoch": 3.5687272227188336,
      "grad_norm": 0.10468770563602448,
      "learning_rate": 2.7705142090876273e-05,
      "loss": 0.024,
      "step": 51900
    },
    {
      "epoch": 3.5756033830708933,
      "grad_norm": 0.22876013815402985,
      "learning_rate": 2.7662162394484847e-05,
      "loss": 0.0257,
      "step": 52000
    },
    {
      "epoch": 3.5824795434229526,
      "grad_norm": 0.22068896889686584,
      "learning_rate": 2.761918269809342e-05,
      "loss": 0.0268,
      "step": 52100
    },
    {
      "epoch": 3.589355703775012,
      "grad_norm": 0.280306875705719,
      "learning_rate": 2.7576203001701994e-05,
      "loss": 0.026,
      "step": 52200
    },
    {
      "epoch": 3.5962318641270716,
      "grad_norm": 0.07753556221723557,
      "learning_rate": 2.7533223305310575e-05,
      "loss": 0.025,
      "step": 52300
    },
    {
      "epoch": 3.603108024479131,
      "grad_norm": 0.4071754813194275,
      "learning_rate": 2.749024360891915e-05,
      "loss": 0.0251,
      "step": 52400
    },
    {
      "epoch": 3.60998418483119,
      "grad_norm": 0.08546844124794006,
      "learning_rate": 2.744726391252772e-05,
      "loss": 0.0253,
      "step": 52500
    },
    {
      "epoch": 3.61686034518325,
      "grad_norm": 0.16494905948638916,
      "learning_rate": 2.74042842161363e-05,
      "loss": 0.0275,
      "step": 52600
    },
    {
      "epoch": 3.6237365055353092,
      "grad_norm": 0.21716652810573578,
      "learning_rate": 2.7361304519744874e-05,
      "loss": 0.0252,
      "step": 52700
    },
    {
      "epoch": 3.6306126658873685,
      "grad_norm": 0.2257787138223648,
      "learning_rate": 2.7318324823353448e-05,
      "loss": 0.0285,
      "step": 52800
    },
    {
      "epoch": 3.637488826239428,
      "grad_norm": 0.7818373441696167,
      "learning_rate": 2.7275345126962025e-05,
      "loss": 0.0252,
      "step": 52900
    },
    {
      "epoch": 3.644364986591487,
      "grad_norm": 0.18212975561618805,
      "learning_rate": 2.72323654305706e-05,
      "loss": 0.0216,
      "step": 53000
    },
    {
      "epoch": 3.651241146943547,
      "grad_norm": 0.07740116864442825,
      "learning_rate": 2.7189385734179173e-05,
      "loss": 0.0222,
      "step": 53100
    },
    {
      "epoch": 3.658117307295606,
      "grad_norm": 0.22333990037441254,
      "learning_rate": 2.7146406037787754e-05,
      "loss": 0.0247,
      "step": 53200
    },
    {
      "epoch": 3.6649934676476654,
      "grad_norm": 0.3048054873943329,
      "learning_rate": 2.7103426341396328e-05,
      "loss": 0.0265,
      "step": 53300
    },
    {
      "epoch": 3.671869627999725,
      "grad_norm": 0.3703809976577759,
      "learning_rate": 2.7060446645004898e-05,
      "loss": 0.0244,
      "step": 53400
    },
    {
      "epoch": 3.6787457883517845,
      "grad_norm": 0.48895522952079773,
      "learning_rate": 2.701746694861348e-05,
      "loss": 0.0275,
      "step": 53500
    },
    {
      "epoch": 3.6856219487038437,
      "grad_norm": 0.10819294303655624,
      "learning_rate": 2.6974487252222053e-05,
      "loss": 0.0267,
      "step": 53600
    },
    {
      "epoch": 3.692498109055903,
      "grad_norm": 0.12763603031635284,
      "learning_rate": 2.6931507555830627e-05,
      "loss": 0.0256,
      "step": 53700
    },
    {
      "epoch": 3.6993742694079623,
      "grad_norm": 0.20381730794906616,
      "learning_rate": 2.688895765640312e-05,
      "loss": 0.026,
      "step": 53800
    },
    {
      "epoch": 3.706250429760022,
      "grad_norm": 0.16454879939556122,
      "learning_rate": 2.6845977960011693e-05,
      "loss": 0.0257,
      "step": 53900
    },
    {
      "epoch": 3.7131265901120813,
      "grad_norm": 0.09912768006324768,
      "learning_rate": 2.6802998263620267e-05,
      "loss": 0.0255,
      "step": 54000
    },
    {
      "epoch": 3.7200027504641406,
      "grad_norm": 0.26218876242637634,
      "learning_rate": 2.676044836419276e-05,
      "loss": 0.0257,
      "step": 54100
    },
    {
      "epoch": 3.7268789108162004,
      "grad_norm": 0.24388889968395233,
      "learning_rate": 2.6717468667801333e-05,
      "loss": 0.0226,
      "step": 54200
    },
    {
      "epoch": 3.7337550711682597,
      "grad_norm": 0.2122662216424942,
      "learning_rate": 2.6674488971409904e-05,
      "loss": 0.0254,
      "step": 54300
    },
    {
      "epoch": 3.740631231520319,
      "grad_norm": 0.11037182062864304,
      "learning_rate": 2.6631509275018485e-05,
      "loss": 0.0225,
      "step": 54400
    },
    {
      "epoch": 3.7475073918723787,
      "grad_norm": 0.3383212685585022,
      "learning_rate": 2.658895937559097e-05,
      "loss": 0.0249,
      "step": 54500
    },
    {
      "epoch": 3.754383552224438,
      "grad_norm": 0.23809319734573364,
      "learning_rate": 2.6545979679199544e-05,
      "loss": 0.0222,
      "step": 54600
    },
    {
      "epoch": 3.7612597125764973,
      "grad_norm": 0.42547744512557983,
      "learning_rate": 2.6502999982808125e-05,
      "loss": 0.025,
      "step": 54700
    },
    {
      "epoch": 3.7681358729285566,
      "grad_norm": 0.37246429920196533,
      "learning_rate": 2.64600202864167e-05,
      "loss": 0.0232,
      "step": 54800
    },
    {
      "epoch": 3.775012033280616,
      "grad_norm": 0.14782960712909698,
      "learning_rate": 2.6417040590025273e-05,
      "loss": 0.0264,
      "step": 54900
    },
    {
      "epoch": 3.7818881936326756,
      "grad_norm": 0.18403953313827515,
      "learning_rate": 2.637406089363385e-05,
      "loss": 0.0258,
      "step": 55000
    },
    {
      "epoch": 3.788764353984735,
      "grad_norm": 0.4958202838897705,
      "learning_rate": 2.6331081197242424e-05,
      "loss": 0.0246,
      "step": 55100
    },
    {
      "epoch": 3.795640514336794,
      "grad_norm": 0.24118223786354065,
      "learning_rate": 2.6288101500850998e-05,
      "loss": 0.0268,
      "step": 55200
    },
    {
      "epoch": 3.802516674688854,
      "grad_norm": 0.19901230931282043,
      "learning_rate": 2.624512180445958e-05,
      "loss": 0.0249,
      "step": 55300
    },
    {
      "epoch": 3.809392835040913,
      "grad_norm": 0.3394196033477783,
      "learning_rate": 2.620214210806815e-05,
      "loss": 0.0269,
      "step": 55400
    },
    {
      "epoch": 3.8162689953929725,
      "grad_norm": 0.2505148947238922,
      "learning_rate": 2.6159162411676723e-05,
      "loss": 0.026,
      "step": 55500
    },
    {
      "epoch": 3.823145155745032,
      "grad_norm": 0.2210467904806137,
      "learning_rate": 2.6116182715285297e-05,
      "loss": 0.0272,
      "step": 55600
    },
    {
      "epoch": 3.8300213160970915,
      "grad_norm": 0.2017236202955246,
      "learning_rate": 2.6073203018893877e-05,
      "loss": 0.0243,
      "step": 55700
    },
    {
      "epoch": 3.836897476449151,
      "grad_norm": 0.19999408721923828,
      "learning_rate": 2.603022332250245e-05,
      "loss": 0.0242,
      "step": 55800
    },
    {
      "epoch": 3.84377363680121,
      "grad_norm": 0.23538856208324432,
      "learning_rate": 2.5987243626111025e-05,
      "loss": 0.0265,
      "step": 55900
    },
    {
      "epoch": 3.8506497971532694,
      "grad_norm": 0.2704126536846161,
      "learning_rate": 2.5944263929719603e-05,
      "loss": 0.0263,
      "step": 56000
    },
    {
      "epoch": 3.857525957505329,
      "grad_norm": 0.19504284858703613,
      "learning_rate": 2.5901284233328177e-05,
      "loss": 0.0254,
      "step": 56100
    },
    {
      "epoch": 3.8644021178573884,
      "grad_norm": 0.25939470529556274,
      "learning_rate": 2.585830453693675e-05,
      "loss": 0.0224,
      "step": 56200
    },
    {
      "epoch": 3.8712782782094477,
      "grad_norm": 0.21214105188846588,
      "learning_rate": 2.581532484054533e-05,
      "loss": 0.0266,
      "step": 56300
    },
    {
      "epoch": 3.8781544385615074,
      "grad_norm": 0.20521731674671173,
      "learning_rate": 2.57723451441539e-05,
      "loss": 0.0242,
      "step": 56400
    },
    {
      "epoch": 3.8850305989135667,
      "grad_norm": 0.26516103744506836,
      "learning_rate": 2.5729365447762476e-05,
      "loss": 0.0247,
      "step": 56500
    },
    {
      "epoch": 3.891906759265626,
      "grad_norm": 0.1307520568370819,
      "learning_rate": 2.5686385751371056e-05,
      "loss": 0.0248,
      "step": 56600
    },
    {
      "epoch": 3.8987829196176857,
      "grad_norm": 0.4645947217941284,
      "learning_rate": 2.564340605497963e-05,
      "loss": 0.0247,
      "step": 56700
    },
    {
      "epoch": 3.905659079969745,
      "grad_norm": 0.37368449568748474,
      "learning_rate": 2.5600426358588204e-05,
      "loss": 0.0263,
      "step": 56800
    },
    {
      "epoch": 3.9125352403218043,
      "grad_norm": 0.4509401023387909,
      "learning_rate": 2.5557446662196778e-05,
      "loss": 0.024,
      "step": 56900
    },
    {
      "epoch": 3.9194114006738636,
      "grad_norm": 0.2961105406284332,
      "learning_rate": 2.5514466965805355e-05,
      "loss": 0.0254,
      "step": 57000
    },
    {
      "epoch": 3.926287561025923,
      "grad_norm": 0.333247572183609,
      "learning_rate": 2.5471917066377844e-05,
      "loss": 0.0243,
      "step": 57100
    },
    {
      "epoch": 3.9331637213779826,
      "grad_norm": 0.12234723567962646,
      "learning_rate": 2.542893736998642e-05,
      "loss": 0.0242,
      "step": 57200
    },
    {
      "epoch": 3.940039881730042,
      "grad_norm": 0.1367064118385315,
      "learning_rate": 2.5385957673594996e-05,
      "loss": 0.0239,
      "step": 57300
    },
    {
      "epoch": 3.9469160420821012,
      "grad_norm": 0.36827272176742554,
      "learning_rate": 2.534297797720357e-05,
      "loss": 0.023,
      "step": 57400
    },
    {
      "epoch": 3.953792202434161,
      "grad_norm": 0.1839693784713745,
      "learning_rate": 2.5299998280812147e-05,
      "loss": 0.0238,
      "step": 57500
    },
    {
      "epoch": 3.9606683627862203,
      "grad_norm": 0.1375299096107483,
      "learning_rate": 2.525701858442072e-05,
      "loss": 0.0226,
      "step": 57600
    },
    {
      "epoch": 3.9675445231382795,
      "grad_norm": 0.2708596885204315,
      "learning_rate": 2.5214038888029295e-05,
      "loss": 0.0244,
      "step": 57700
    },
    {
      "epoch": 3.974420683490339,
      "grad_norm": 0.3432334363460541,
      "learning_rate": 2.517105919163787e-05,
      "loss": 0.0233,
      "step": 57800
    },
    {
      "epoch": 3.9812968438423986,
      "grad_norm": 0.44257739186286926,
      "learning_rate": 2.512807949524645e-05,
      "loss": 0.0241,
      "step": 57900
    },
    {
      "epoch": 3.988173004194458,
      "grad_norm": 0.20064327120780945,
      "learning_rate": 2.5085099798855023e-05,
      "loss": 0.0245,
      "step": 58000
    },
    {
      "epoch": 3.995049164546517,
      "grad_norm": 0.34785741567611694,
      "learning_rate": 2.5042549899427516e-05,
      "loss": 0.0242,
      "step": 58100
    },
    {
      "epoch": 4.0,
      "eval_accuracy_macro_0.5": 0.9882822036743164,
      "eval_accuracy_micro_0.5": 0.9882822036743164,
      "eval_accuracy_weighted_0.5": 0.9865732192993164,
      "eval_f1_macro_0.5": 0.8526087403297424,
      "eval_f1_macro_0.6": 0.8455312848091125,
      "eval_f1_macro_0.7": 0.8307217359542847,
      "eval_f1_macro_0.8": 0.7372260093688965,
      "eval_f1_micro_0.5": 0.84943026304245,
      "eval_f1_micro_0.6": 0.8438851237297058,
      "eval_f1_micro_0.7": 0.830756425857544,
      "eval_f1_micro_0.8": 0.805493950843811,
      "eval_f1_micro_0.9": 0.7442486882209778,
      "eval_f1_weighted_0.5": 0.8474903106689453,
      "eval_f1_weighted_0.6": 0.8399991989135742,
      "eval_f1_weighted_0.7": 0.824242115020752,
      "eval_f1_weighted_0.8": 0.7240098118782043,
      "eval_loss": 0.024204209446907043,
      "eval_runtime": 440.5955,
      "eval_samples_per_second": 65.904,
      "eval_steps_per_second": 8.239,
      "step": 58172
    },
    {
      "epoch": 4.001925324898576,
      "grad_norm": 0.14952632784843445,
      "learning_rate": 2.499957020303609e-05,
      "loss": 0.023,
      "step": 58200
    },
    {
      "epoch": 4.008801485250636,
      "grad_norm": 0.32473063468933105,
      "learning_rate": 2.495659050664466e-05,
      "loss": 0.0228,
      "step": 58300
    },
    {
      "epoch": 4.015677645602695,
      "grad_norm": 0.3127984404563904,
      "learning_rate": 2.4913610810253237e-05,
      "loss": 0.0218,
      "step": 58400
    },
    {
      "epoch": 4.022553805954755,
      "grad_norm": 0.3519718647003174,
      "learning_rate": 2.4870631113861815e-05,
      "loss": 0.0236,
      "step": 58500
    },
    {
      "epoch": 4.0294299663068145,
      "grad_norm": 0.12735188007354736,
      "learning_rate": 2.482765141747039e-05,
      "loss": 0.0211,
      "step": 58600
    },
    {
      "epoch": 4.036306126658873,
      "grad_norm": 0.4314698576927185,
      "learning_rate": 2.4784671721078966e-05,
      "loss": 0.0222,
      "step": 58700
    },
    {
      "epoch": 4.043182287010933,
      "grad_norm": 0.2735160291194916,
      "learning_rate": 2.4741692024687536e-05,
      "loss": 0.0217,
      "step": 58800
    },
    {
      "epoch": 4.050058447362993,
      "grad_norm": 0.33918648958206177,
      "learning_rate": 2.4698712328296114e-05,
      "loss": 0.023,
      "step": 58900
    },
    {
      "epoch": 4.056934607715052,
      "grad_norm": 0.12411510199308395,
      "learning_rate": 2.465573263190469e-05,
      "loss": 0.022,
      "step": 59000
    },
    {
      "epoch": 4.063810768067111,
      "grad_norm": 0.458804726600647,
      "learning_rate": 2.4612752935513265e-05,
      "loss": 0.025,
      "step": 59100
    },
    {
      "epoch": 4.070686928419171,
      "grad_norm": 0.25572535395622253,
      "learning_rate": 2.4569773239121842e-05,
      "loss": 0.0234,
      "step": 59200
    },
    {
      "epoch": 4.07756308877123,
      "grad_norm": 0.26818540692329407,
      "learning_rate": 2.4526793542730413e-05,
      "loss": 0.0256,
      "step": 59300
    },
    {
      "epoch": 4.08443924912329,
      "grad_norm": 0.23112380504608154,
      "learning_rate": 2.448381384633899e-05,
      "loss": 0.024,
      "step": 59400
    },
    {
      "epoch": 4.0913154094753486,
      "grad_norm": 0.08220183104276657,
      "learning_rate": 2.4440834149947567e-05,
      "loss": 0.0217,
      "step": 59500
    },
    {
      "epoch": 4.098191569827408,
      "grad_norm": 0.19623857736587524,
      "learning_rate": 2.439785445355614e-05,
      "loss": 0.0234,
      "step": 59600
    },
    {
      "epoch": 4.105067730179468,
      "grad_norm": 0.2031394988298416,
      "learning_rate": 2.435487475716472e-05,
      "loss": 0.0257,
      "step": 59700
    },
    {
      "epoch": 4.111943890531527,
      "grad_norm": 0.16559059917926788,
      "learning_rate": 2.4311895060773292e-05,
      "loss": 0.0242,
      "step": 59800
    },
    {
      "epoch": 4.118820050883587,
      "grad_norm": 0.255948543548584,
      "learning_rate": 2.4268915364381866e-05,
      "loss": 0.0248,
      "step": 59900
    },
    {
      "epoch": 4.125696211235646,
      "grad_norm": 0.34718066453933716,
      "learning_rate": 2.4225935667990444e-05,
      "loss": 0.0239,
      "step": 60000
    },
    {
      "epoch": 4.132572371587705,
      "grad_norm": 0.20343828201293945,
      "learning_rate": 2.4182955971599017e-05,
      "loss": 0.021,
      "step": 60100
    },
    {
      "epoch": 4.139448531939765,
      "grad_norm": 0.2877691388130188,
      "learning_rate": 2.413997627520759e-05,
      "loss": 0.0236,
      "step": 60200
    },
    {
      "epoch": 4.146324692291825,
      "grad_norm": 0.31919291615486145,
      "learning_rate": 2.409699657881617e-05,
      "loss": 0.0235,
      "step": 60300
    },
    {
      "epoch": 4.1532008526438835,
      "grad_norm": 0.30475112795829773,
      "learning_rate": 2.4054016882424743e-05,
      "loss": 0.0208,
      "step": 60400
    },
    {
      "epoch": 4.160077012995943,
      "grad_norm": 0.10239232331514359,
      "learning_rate": 2.401103718603332e-05,
      "loss": 0.0222,
      "step": 60500
    },
    {
      "epoch": 4.166953173348002,
      "grad_norm": 0.4037829041481018,
      "learning_rate": 2.3968057489641894e-05,
      "loss": 0.0222,
      "step": 60600
    },
    {
      "epoch": 4.173829333700062,
      "grad_norm": 0.4450301229953766,
      "learning_rate": 2.3925077793250468e-05,
      "loss": 0.0237,
      "step": 60700
    },
    {
      "epoch": 4.1807054940521216,
      "grad_norm": 0.3590048551559448,
      "learning_rate": 2.3882098096859045e-05,
      "loss": 0.0245,
      "step": 60800
    },
    {
      "epoch": 4.18758165440418,
      "grad_norm": 0.22308313846588135,
      "learning_rate": 2.383911840046762e-05,
      "loss": 0.0233,
      "step": 60900
    },
    {
      "epoch": 4.19445781475624,
      "grad_norm": 0.38812485337257385,
      "learning_rate": 2.3796138704076196e-05,
      "loss": 0.0228,
      "step": 61000
    },
    {
      "epoch": 4.2013339751083,
      "grad_norm": 0.11120603233575821,
      "learning_rate": 2.3753588804648685e-05,
      "loss": 0.0237,
      "step": 61100
    },
    {
      "epoch": 4.208210135460359,
      "grad_norm": 0.23091775178909302,
      "learning_rate": 2.3710609108257263e-05,
      "loss": 0.0239,
      "step": 61200
    },
    {
      "epoch": 4.2150862958124184,
      "grad_norm": 0.18205752968788147,
      "learning_rate": 2.3667629411865836e-05,
      "loss": 0.0236,
      "step": 61300
    },
    {
      "epoch": 4.221962456164478,
      "grad_norm": 0.25438517332077026,
      "learning_rate": 2.362464971547441e-05,
      "loss": 0.0232,
      "step": 61400
    },
    {
      "epoch": 4.228838616516537,
      "grad_norm": 0.25256818532943726,
      "learning_rate": 2.3581670019082984e-05,
      "loss": 0.0224,
      "step": 61500
    },
    {
      "epoch": 4.235714776868597,
      "grad_norm": 0.211380735039711,
      "learning_rate": 2.353869032269156e-05,
      "loss": 0.0251,
      "step": 61600
    },
    {
      "epoch": 4.242590937220656,
      "grad_norm": 0.15792876482009888,
      "learning_rate": 2.349571062630014e-05,
      "loss": 0.022,
      "step": 61700
    },
    {
      "epoch": 4.249467097572715,
      "grad_norm": 0.29246795177459717,
      "learning_rate": 2.3452730929908713e-05,
      "loss": 0.0206,
      "step": 61800
    },
    {
      "epoch": 4.256343257924775,
      "grad_norm": 0.09580068290233612,
      "learning_rate": 2.3409751233517287e-05,
      "loss": 0.0259,
      "step": 61900
    },
    {
      "epoch": 4.263219418276834,
      "grad_norm": 0.3226964473724365,
      "learning_rate": 2.336677153712586e-05,
      "loss": 0.0238,
      "step": 62000
    },
    {
      "epoch": 4.270095578628894,
      "grad_norm": 0.1518169641494751,
      "learning_rate": 2.3323791840734438e-05,
      "loss": 0.0232,
      "step": 62100
    },
    {
      "epoch": 4.276971738980953,
      "grad_norm": 0.4967963993549347,
      "learning_rate": 2.3280812144343015e-05,
      "loss": 0.0222,
      "step": 62200
    },
    {
      "epoch": 4.283847899333012,
      "grad_norm": 0.17980143427848816,
      "learning_rate": 2.323783244795159e-05,
      "loss": 0.0251,
      "step": 62300
    },
    {
      "epoch": 4.290724059685072,
      "grad_norm": 0.19488179683685303,
      "learning_rate": 2.3194852751560163e-05,
      "loss": 0.0237,
      "step": 62400
    },
    {
      "epoch": 4.297600220037131,
      "grad_norm": 0.2302660197019577,
      "learning_rate": 2.315187305516874e-05,
      "loss": 0.0248,
      "step": 62500
    },
    {
      "epoch": 4.304476380389191,
      "grad_norm": 0.17765311896800995,
      "learning_rate": 2.3108893358777314e-05,
      "loss": 0.024,
      "step": 62600
    },
    {
      "epoch": 4.31135254074125,
      "grad_norm": 0.16009756922721863,
      "learning_rate": 2.306591366238589e-05,
      "loss": 0.0243,
      "step": 62700
    },
    {
      "epoch": 4.318228701093309,
      "grad_norm": 0.1282348334789276,
      "learning_rate": 2.3022933965994465e-05,
      "loss": 0.0216,
      "step": 62800
    },
    {
      "epoch": 4.325104861445369,
      "grad_norm": 0.3084467649459839,
      "learning_rate": 2.297995426960304e-05,
      "loss": 0.0244,
      "step": 62900
    },
    {
      "epoch": 4.331981021797429,
      "grad_norm": 0.1758844405412674,
      "learning_rate": 2.2936974573211617e-05,
      "loss": 0.0236,
      "step": 63000
    },
    {
      "epoch": 4.3388571821494875,
      "grad_norm": 0.41368353366851807,
      "learning_rate": 2.289399487682019e-05,
      "loss": 0.0232,
      "step": 63100
    },
    {
      "epoch": 4.345733342501547,
      "grad_norm": 0.25133731961250305,
      "learning_rate": 2.2851015180428768e-05,
      "loss": 0.024,
      "step": 63200
    },
    {
      "epoch": 4.352609502853607,
      "grad_norm": 0.16246014833450317,
      "learning_rate": 2.2808035484037342e-05,
      "loss": 0.0232,
      "step": 63300
    },
    {
      "epoch": 4.359485663205666,
      "grad_norm": 0.28010886907577515,
      "learning_rate": 2.2765055787645916e-05,
      "loss": 0.0218,
      "step": 63400
    },
    {
      "epoch": 4.3663618235577255,
      "grad_norm": 0.2882217466831207,
      "learning_rate": 2.2722076091254493e-05,
      "loss": 0.0239,
      "step": 63500
    },
    {
      "epoch": 4.373237983909785,
      "grad_norm": 0.17849381268024445,
      "learning_rate": 2.2679096394863067e-05,
      "loss": 0.0247,
      "step": 63600
    },
    {
      "epoch": 4.380114144261844,
      "grad_norm": 0.09081112593412399,
      "learning_rate": 2.2636116698471644e-05,
      "loss": 0.0241,
      "step": 63700
    },
    {
      "epoch": 4.386990304613904,
      "grad_norm": 0.536060631275177,
      "learning_rate": 2.2593137002080218e-05,
      "loss": 0.023,
      "step": 63800
    },
    {
      "epoch": 4.393866464965963,
      "grad_norm": 0.19755399227142334,
      "learning_rate": 2.2550157305688792e-05,
      "loss": 0.0251,
      "step": 63900
    },
    {
      "epoch": 4.400742625318022,
      "grad_norm": 0.32015180587768555,
      "learning_rate": 2.250717760929737e-05,
      "loss": 0.0243,
      "step": 64000
    },
    {
      "epoch": 4.407618785670082,
      "grad_norm": 0.24902848899364471,
      "learning_rate": 2.2464197912905943e-05,
      "loss": 0.0235,
      "step": 64100
    },
    {
      "epoch": 4.414494946022141,
      "grad_norm": 0.08285932242870331,
      "learning_rate": 2.242121821651452e-05,
      "loss": 0.0216,
      "step": 64200
    },
    {
      "epoch": 4.421371106374201,
      "grad_norm": 0.11580686271190643,
      "learning_rate": 2.2378238520123094e-05,
      "loss": 0.0253,
      "step": 64300
    },
    {
      "epoch": 4.4282472667262605,
      "grad_norm": 0.41048040986061096,
      "learning_rate": 2.233525882373167e-05,
      "loss": 0.0238,
      "step": 64400
    },
    {
      "epoch": 4.435123427078319,
      "grad_norm": 0.4075697362422943,
      "learning_rate": 2.2292279127340246e-05,
      "loss": 0.0228,
      "step": 64500
    },
    {
      "epoch": 4.441999587430379,
      "grad_norm": 0.12034405022859573,
      "learning_rate": 2.224929943094882e-05,
      "loss": 0.0236,
      "step": 64600
    },
    {
      "epoch": 4.448875747782438,
      "grad_norm": 0.2521055340766907,
      "learning_rate": 2.2206319734557397e-05,
      "loss": 0.0227,
      "step": 64700
    },
    {
      "epoch": 4.455751908134498,
      "grad_norm": 0.17013956606388092,
      "learning_rate": 2.216334003816597e-05,
      "loss": 0.0228,
      "step": 64800
    },
    {
      "epoch": 4.462628068486557,
      "grad_norm": 0.2231730967760086,
      "learning_rate": 2.2120360341774545e-05,
      "loss": 0.0243,
      "step": 64900
    },
    {
      "epoch": 4.469504228838616,
      "grad_norm": 0.13776202499866486,
      "learning_rate": 2.2077380645383122e-05,
      "loss": 0.0227,
      "step": 65000
    },
    {
      "epoch": 4.476380389190676,
      "grad_norm": 0.16238868236541748,
      "learning_rate": 2.20344009489917e-05,
      "loss": 0.0235,
      "step": 65100
    },
    {
      "epoch": 4.483256549542736,
      "grad_norm": 0.30405130982398987,
      "learning_rate": 2.1991421252600273e-05,
      "loss": 0.0216,
      "step": 65200
    },
    {
      "epoch": 4.4901327098947945,
      "grad_norm": 0.27077141404151917,
      "learning_rate": 2.1948441556208847e-05,
      "loss": 0.0226,
      "step": 65300
    },
    {
      "epoch": 4.497008870246854,
      "grad_norm": 0.11324993520975113,
      "learning_rate": 2.190546185981742e-05,
      "loss": 0.0243,
      "step": 65400
    },
    {
      "epoch": 4.503885030598914,
      "grad_norm": 0.290007621049881,
      "learning_rate": 2.1862482163426e-05,
      "loss": 0.0229,
      "step": 65500
    },
    {
      "epoch": 4.510761190950973,
      "grad_norm": 0.3584131896495819,
      "learning_rate": 2.1819502467034576e-05,
      "loss": 0.0252,
      "step": 65600
    },
    {
      "epoch": 4.517637351303033,
      "grad_norm": 0.29650503396987915,
      "learning_rate": 2.177652277064315e-05,
      "loss": 0.024,
      "step": 65700
    },
    {
      "epoch": 4.524513511655091,
      "grad_norm": 0.2733291685581207,
      "learning_rate": 2.1733543074251724e-05,
      "loss": 0.0244,
      "step": 65800
    },
    {
      "epoch": 4.531389672007151,
      "grad_norm": 0.27961498498916626,
      "learning_rate": 2.1690563377860297e-05,
      "loss": 0.0246,
      "step": 65900
    },
    {
      "epoch": 4.538265832359211,
      "grad_norm": 0.4456273317337036,
      "learning_rate": 2.1648013478432786e-05,
      "loss": 0.0252,
      "step": 66000
    },
    {
      "epoch": 4.54514199271127,
      "grad_norm": 0.21924957633018494,
      "learning_rate": 2.1605033782041364e-05,
      "loss": 0.024,
      "step": 66100
    },
    {
      "epoch": 4.5520181530633295,
      "grad_norm": 0.27242159843444824,
      "learning_rate": 2.156205408564994e-05,
      "loss": 0.0209,
      "step": 66200
    },
    {
      "epoch": 4.558894313415389,
      "grad_norm": 0.2926216423511505,
      "learning_rate": 2.1519074389258515e-05,
      "loss": 0.0232,
      "step": 66300
    },
    {
      "epoch": 4.565770473767448,
      "grad_norm": 0.4274778664112091,
      "learning_rate": 2.1476094692867092e-05,
      "loss": 0.0216,
      "step": 66400
    },
    {
      "epoch": 4.572646634119508,
      "grad_norm": 0.3251742422580719,
      "learning_rate": 2.1433114996475666e-05,
      "loss": 0.0254,
      "step": 66500
    },
    {
      "epoch": 4.579522794471567,
      "grad_norm": 0.16069523990154266,
      "learning_rate": 2.139013530008424e-05,
      "loss": 0.0235,
      "step": 66600
    },
    {
      "epoch": 4.586398954823626,
      "grad_norm": 0.165919691324234,
      "learning_rate": 2.1347155603692817e-05,
      "loss": 0.0221,
      "step": 66700
    },
    {
      "epoch": 4.593275115175686,
      "grad_norm": 0.3964635133743286,
      "learning_rate": 2.130417590730139e-05,
      "loss": 0.0236,
      "step": 66800
    },
    {
      "epoch": 4.600151275527745,
      "grad_norm": 0.21538859605789185,
      "learning_rate": 2.126119621090997e-05,
      "loss": 0.0265,
      "step": 66900
    },
    {
      "epoch": 4.607027435879805,
      "grad_norm": 0.16930542886257172,
      "learning_rate": 2.1218216514518543e-05,
      "loss": 0.0238,
      "step": 67000
    },
    {
      "epoch": 4.613903596231864,
      "grad_norm": 0.08986023813486099,
      "learning_rate": 2.1175236818127116e-05,
      "loss": 0.0206,
      "step": 67100
    },
    {
      "epoch": 4.620779756583923,
      "grad_norm": 0.32317662239074707,
      "learning_rate": 2.1132257121735694e-05,
      "loss": 0.0212,
      "step": 67200
    },
    {
      "epoch": 4.627655916935983,
      "grad_norm": 0.27747729420661926,
      "learning_rate": 2.1089277425344268e-05,
      "loss": 0.0232,
      "step": 67300
    },
    {
      "epoch": 4.634532077288043,
      "grad_norm": 0.2904289662837982,
      "learning_rate": 2.1046297728952845e-05,
      "loss": 0.0221,
      "step": 67400
    },
    {
      "epoch": 4.641408237640102,
      "grad_norm": 0.18158265948295593,
      "learning_rate": 2.100331803256142e-05,
      "loss": 0.024,
      "step": 67500
    },
    {
      "epoch": 4.648284397992161,
      "grad_norm": 0.25038084387779236,
      "learning_rate": 2.0960338336169993e-05,
      "loss": 0.0239,
      "step": 67600
    },
    {
      "epoch": 4.655160558344221,
      "grad_norm": 0.3003167510032654,
      "learning_rate": 2.091735863977857e-05,
      "loss": 0.024,
      "step": 67700
    },
    {
      "epoch": 4.66203671869628,
      "grad_norm": 0.2872496545314789,
      "learning_rate": 2.0874378943387147e-05,
      "loss": 0.0228,
      "step": 67800
    },
    {
      "epoch": 4.66891287904834,
      "grad_norm": 0.2112288624048233,
      "learning_rate": 2.083139924699572e-05,
      "loss": 0.0214,
      "step": 67900
    },
    {
      "epoch": 4.6757890394003985,
      "grad_norm": 0.16351480782032013,
      "learning_rate": 2.0788419550604295e-05,
      "loss": 0.023,
      "step": 68000
    },
    {
      "epoch": 4.682665199752458,
      "grad_norm": 0.22584985196590424,
      "learning_rate": 2.074543985421287e-05,
      "loss": 0.0235,
      "step": 68100
    },
    {
      "epoch": 4.689541360104518,
      "grad_norm": 0.196958526968956,
      "learning_rate": 2.0702460157821446e-05,
      "loss": 0.0215,
      "step": 68200
    },
    {
      "epoch": 4.696417520456577,
      "grad_norm": 0.3138054311275482,
      "learning_rate": 2.0659480461430024e-05,
      "loss": 0.023,
      "step": 68300
    },
    {
      "epoch": 4.7032936808086365,
      "grad_norm": 0.3427133858203888,
      "learning_rate": 2.0616500765038598e-05,
      "loss": 0.0217,
      "step": 68400
    },
    {
      "epoch": 4.710169841160695,
      "grad_norm": 0.2718716561794281,
      "learning_rate": 2.057352106864717e-05,
      "loss": 0.0228,
      "step": 68500
    },
    {
      "epoch": 4.717046001512755,
      "grad_norm": 0.2210289090871811,
      "learning_rate": 2.0530541372255745e-05,
      "loss": 0.0222,
      "step": 68600
    },
    {
      "epoch": 4.723922161864815,
      "grad_norm": 0.18591703474521637,
      "learning_rate": 2.0487561675864323e-05,
      "loss": 0.0226,
      "step": 68700
    },
    {
      "epoch": 4.730798322216874,
      "grad_norm": 0.22788400948047638,
      "learning_rate": 2.04445819794729e-05,
      "loss": 0.0242,
      "step": 68800
    },
    {
      "epoch": 4.737674482568933,
      "grad_norm": 0.3239564001560211,
      "learning_rate": 2.0401602283081474e-05,
      "loss": 0.0239,
      "step": 68900
    },
    {
      "epoch": 4.744550642920993,
      "grad_norm": 0.06149750575423241,
      "learning_rate": 2.0358622586690048e-05,
      "loss": 0.0224,
      "step": 69000
    },
    {
      "epoch": 4.751426803273052,
      "grad_norm": 0.23343294858932495,
      "learning_rate": 2.0316072687262537e-05,
      "loss": 0.0241,
      "step": 69100
    },
    {
      "epoch": 4.758302963625112,
      "grad_norm": 0.3284369707107544,
      "learning_rate": 2.0273092990871114e-05,
      "loss": 0.0246,
      "step": 69200
    },
    {
      "epoch": 4.7651791239771715,
      "grad_norm": 0.18939797580242157,
      "learning_rate": 2.0230113294479688e-05,
      "loss": 0.0239,
      "step": 69300
    },
    {
      "epoch": 4.77205528432923,
      "grad_norm": 0.23569725453853607,
      "learning_rate": 2.0187133598088265e-05,
      "loss": 0.0243,
      "step": 69400
    },
    {
      "epoch": 4.77893144468129,
      "grad_norm": 0.10995485633611679,
      "learning_rate": 2.014415390169684e-05,
      "loss": 0.0237,
      "step": 69500
    },
    {
      "epoch": 4.78580760503335,
      "grad_norm": 0.22780609130859375,
      "learning_rate": 2.0101174205305413e-05,
      "loss": 0.0239,
      "step": 69600
    },
    {
      "epoch": 4.792683765385409,
      "grad_norm": 0.17432448267936707,
      "learning_rate": 2.005819450891399e-05,
      "loss": 0.0224,
      "step": 69700
    },
    {
      "epoch": 4.799559925737468,
      "grad_norm": 0.27431759238243103,
      "learning_rate": 2.0015214812522564e-05,
      "loss": 0.0217,
      "step": 69800
    },
    {
      "epoch": 4.806436086089528,
      "grad_norm": 0.1648912876844406,
      "learning_rate": 1.9972235116131142e-05,
      "loss": 0.0249,
      "step": 69900
    },
    {
      "epoch": 4.813312246441587,
      "grad_norm": 0.16086778044700623,
      "learning_rate": 1.9929255419739716e-05,
      "loss": 0.023,
      "step": 70000
    },
    {
      "epoch": 4.820188406793647,
      "grad_norm": 0.2459898591041565,
      "learning_rate": 1.988627572334829e-05,
      "loss": 0.0226,
      "step": 70100
    },
    {
      "epoch": 4.8270645671457055,
      "grad_norm": 0.2476809024810791,
      "learning_rate": 1.9843296026956867e-05,
      "loss": 0.0234,
      "step": 70200
    },
    {
      "epoch": 4.833940727497765,
      "grad_norm": 0.5263009667396545,
      "learning_rate": 1.980031633056544e-05,
      "loss": 0.0228,
      "step": 70300
    },
    {
      "epoch": 4.840816887849825,
      "grad_norm": 0.1822296679019928,
      "learning_rate": 1.9757336634174018e-05,
      "loss": 0.0223,
      "step": 70400
    },
    {
      "epoch": 4.847693048201884,
      "grad_norm": 0.2402925193309784,
      "learning_rate": 1.9714356937782595e-05,
      "loss": 0.0216,
      "step": 70500
    },
    {
      "epoch": 4.854569208553944,
      "grad_norm": 0.12496855109930038,
      "learning_rate": 1.9671377241391166e-05,
      "loss": 0.0233,
      "step": 70600
    },
    {
      "epoch": 4.861445368906002,
      "grad_norm": 0.2002830058336258,
      "learning_rate": 1.9628397544999743e-05,
      "loss": 0.0239,
      "step": 70700
    },
    {
      "epoch": 4.868321529258062,
      "grad_norm": 0.12928614020347595,
      "learning_rate": 1.9585417848608317e-05,
      "loss": 0.0233,
      "step": 70800
    },
    {
      "epoch": 4.875197689610122,
      "grad_norm": 0.2207636684179306,
      "learning_rate": 1.9542438152216894e-05,
      "loss": 0.0203,
      "step": 70900
    },
    {
      "epoch": 4.882073849962181,
      "grad_norm": 0.3000093698501587,
      "learning_rate": 1.9499458455825472e-05,
      "loss": 0.0213,
      "step": 71000
    },
    {
      "epoch": 4.8889500103142405,
      "grad_norm": 0.1761038601398468,
      "learning_rate": 1.9456478759434042e-05,
      "loss": 0.0229,
      "step": 71100
    },
    {
      "epoch": 4.8958261706663,
      "grad_norm": 0.12143334746360779,
      "learning_rate": 1.941349906304262e-05,
      "loss": 0.0232,
      "step": 71200
    },
    {
      "epoch": 4.902702331018359,
      "grad_norm": 0.15564994513988495,
      "learning_rate": 1.9370519366651193e-05,
      "loss": 0.0254,
      "step": 71300
    },
    {
      "epoch": 4.909578491370419,
      "grad_norm": 0.33025696873664856,
      "learning_rate": 1.932753967025977e-05,
      "loss": 0.0228,
      "step": 71400
    },
    {
      "epoch": 4.9164546517224785,
      "grad_norm": 0.1223139688372612,
      "learning_rate": 1.9284559973868345e-05,
      "loss": 0.0225,
      "step": 71500
    },
    {
      "epoch": 4.923330812074537,
      "grad_norm": 0.07161195576190948,
      "learning_rate": 1.924158027747692e-05,
      "loss": 0.0219,
      "step": 71600
    },
    {
      "epoch": 4.930206972426597,
      "grad_norm": 0.19606085121631622,
      "learning_rate": 1.9198600581085496e-05,
      "loss": 0.0228,
      "step": 71700
    },
    {
      "epoch": 4.937083132778657,
      "grad_norm": 0.2514873743057251,
      "learning_rate": 1.9155620884694073e-05,
      "loss": 0.0235,
      "step": 71800
    },
    {
      "epoch": 4.943959293130716,
      "grad_norm": 0.17769379913806915,
      "learning_rate": 1.9112641188302647e-05,
      "loss": 0.025,
      "step": 71900
    },
    {
      "epoch": 4.950835453482775,
      "grad_norm": 0.2385929822921753,
      "learning_rate": 1.906966149191122e-05,
      "loss": 0.0231,
      "step": 72000
    },
    {
      "epoch": 4.957711613834834,
      "grad_norm": 0.45365750789642334,
      "learning_rate": 1.9026681795519795e-05,
      "loss": 0.0229,
      "step": 72100
    },
    {
      "epoch": 4.964587774186894,
      "grad_norm": 0.3453947901725769,
      "learning_rate": 1.8983702099128372e-05,
      "loss": 0.0236,
      "step": 72200
    },
    {
      "epoch": 4.971463934538954,
      "grad_norm": 0.40915101766586304,
      "learning_rate": 1.894072240273695e-05,
      "loss": 0.0226,
      "step": 72300
    },
    {
      "epoch": 4.978340094891013,
      "grad_norm": 0.1980808824300766,
      "learning_rate": 1.8897742706345523e-05,
      "loss": 0.0212,
      "step": 72400
    },
    {
      "epoch": 4.985216255243072,
      "grad_norm": 0.9392777681350708,
      "learning_rate": 1.8854763009954097e-05,
      "loss": 0.0241,
      "step": 72500
    },
    {
      "epoch": 4.992092415595132,
      "grad_norm": 0.19690817594528198,
      "learning_rate": 1.881178331356267e-05,
      "loss": 0.0204,
      "step": 72600
    },
    {
      "epoch": 4.998968575947191,
      "grad_norm": 0.4024337828159332,
      "learning_rate": 1.876880361717125e-05,
      "loss": 0.0221,
      "step": 72700
    },
    {
      "epoch": 5.0,
      "eval_accuracy_macro_0.5": 0.9887148141860962,
      "eval_accuracy_micro_0.5": 0.9887148141860962,
      "eval_accuracy_weighted_0.5": 0.9870644211769104,
      "eval_f1_macro_0.5": 0.8587987422943115,
      "eval_f1_macro_0.6": 0.8530189394950867,
      "eval_f1_macro_0.7": 0.8401708006858826,
      "eval_f1_macro_0.8": 0.7480399012565613,
      "eval_f1_micro_0.5": 0.8552057147026062,
      "eval_f1_micro_0.6": 0.8503098487854004,
      "eval_f1_micro_0.7": 0.8386209607124329,
      "eval_f1_micro_0.8": 0.8128550052642822,
      "eval_f1_micro_0.9": 0.7525371313095093,
      "eval_f1_weighted_0.5": 0.8535730242729187,
      "eval_f1_weighted_0.6": 0.8469099998474121,
      "eval_f1_weighted_0.7": 0.8330411911010742,
      "eval_f1_weighted_0.8": 0.7341554164886475,
      "eval_loss": 0.023188922554254532,
      "eval_runtime": 440.6274,
      "eval_samples_per_second": 65.899,
      "eval_steps_per_second": 8.238,
      "step": 72715
    },
    {
      "epoch": 5.005844736299251,
      "grad_norm": 0.23811592161655426,
      "learning_rate": 1.8726253717743738e-05,
      "loss": 0.0244,
      "step": 72800
    },
    {
      "epoch": 5.0127208966513095,
      "grad_norm": 0.5130419731140137,
      "learning_rate": 1.8683274021352315e-05,
      "loss": 0.0228,
      "step": 72900
    },
    {
      "epoch": 5.019597057003369,
      "grad_norm": 0.2931928336620331,
      "learning_rate": 1.864029432496089e-05,
      "loss": 0.0203,
      "step": 73000
    },
    {
      "epoch": 5.026473217355429,
      "grad_norm": 0.21952110528945923,
      "learning_rate": 1.8597314628569466e-05,
      "loss": 0.0218,
      "step": 73100
    },
    {
      "epoch": 5.033349377707488,
      "grad_norm": 0.18862587213516235,
      "learning_rate": 1.855433493217804e-05,
      "loss": 0.0209,
      "step": 73200
    },
    {
      "epoch": 5.0402255380595475,
      "grad_norm": 0.2715516984462738,
      "learning_rate": 1.8511355235786614e-05,
      "loss": 0.0208,
      "step": 73300
    },
    {
      "epoch": 5.047101698411607,
      "grad_norm": 0.2556914985179901,
      "learning_rate": 1.846837553939519e-05,
      "loss": 0.0219,
      "step": 73400
    },
    {
      "epoch": 5.053977858763666,
      "grad_norm": 0.20648235082626343,
      "learning_rate": 1.8425395843003765e-05,
      "loss": 0.0218,
      "step": 73500
    },
    {
      "epoch": 5.060854019115726,
      "grad_norm": 0.2856210470199585,
      "learning_rate": 1.8382416146612342e-05,
      "loss": 0.0217,
      "step": 73600
    },
    {
      "epoch": 5.067730179467786,
      "grad_norm": 0.1273268759250641,
      "learning_rate": 1.8339436450220916e-05,
      "loss": 0.0219,
      "step": 73700
    },
    {
      "epoch": 5.074606339819844,
      "grad_norm": 0.04963346943259239,
      "learning_rate": 1.829645675382949e-05,
      "loss": 0.0221,
      "step": 73800
    },
    {
      "epoch": 5.081482500171904,
      "grad_norm": 0.16056808829307556,
      "learning_rate": 1.8253477057438068e-05,
      "loss": 0.0227,
      "step": 73900
    },
    {
      "epoch": 5.088358660523963,
      "grad_norm": 0.2999182939529419,
      "learning_rate": 1.821049736104664e-05,
      "loss": 0.021,
      "step": 74000
    },
    {
      "epoch": 5.095234820876023,
      "grad_norm": 0.08917775005102158,
      "learning_rate": 1.816751766465522e-05,
      "loss": 0.0225,
      "step": 74100
    },
    {
      "epoch": 5.1021109812280825,
      "grad_norm": 0.22793011367321014,
      "learning_rate": 1.8124537968263793e-05,
      "loss": 0.0228,
      "step": 74200
    },
    {
      "epoch": 5.108987141580141,
      "grad_norm": 0.5534698367118835,
      "learning_rate": 1.8081558271872367e-05,
      "loss": 0.0215,
      "step": 74300
    },
    {
      "epoch": 5.115863301932201,
      "grad_norm": 0.13547088205814362,
      "learning_rate": 1.8038578575480944e-05,
      "loss": 0.0224,
      "step": 74400
    },
    {
      "epoch": 5.122739462284261,
      "grad_norm": 0.44747817516326904,
      "learning_rate": 1.799559887908952e-05,
      "loss": 0.0233,
      "step": 74500
    },
    {
      "epoch": 5.12961562263632,
      "grad_norm": 0.24807316064834595,
      "learning_rate": 1.7952619182698095e-05,
      "loss": 0.021,
      "step": 74600
    },
    {
      "epoch": 5.136491782988379,
      "grad_norm": 0.23156173527240753,
      "learning_rate": 1.790963948630667e-05,
      "loss": 0.0237,
      "step": 74700
    },
    {
      "epoch": 5.143367943340439,
      "grad_norm": 0.5515781044960022,
      "learning_rate": 1.7866659789915243e-05,
      "loss": 0.0229,
      "step": 74800
    },
    {
      "epoch": 5.150244103692498,
      "grad_norm": 0.22765128314495087,
      "learning_rate": 1.782368009352382e-05,
      "loss": 0.0213,
      "step": 74900
    },
    {
      "epoch": 5.157120264044558,
      "grad_norm": 0.2712191939353943,
      "learning_rate": 1.7780700397132398e-05,
      "loss": 0.0226,
      "step": 75000
    },
    {
      "epoch": 5.1639964243966165,
      "grad_norm": 0.44483330845832825,
      "learning_rate": 1.773772070074097e-05,
      "loss": 0.0204,
      "step": 75100
    },
    {
      "epoch": 5.170872584748676,
      "grad_norm": 0.3280285596847534,
      "learning_rate": 1.7694741004349545e-05,
      "loss": 0.0224,
      "step": 75200
    },
    {
      "epoch": 5.177748745100736,
      "grad_norm": 0.3200596272945404,
      "learning_rate": 1.765176130795812e-05,
      "loss": 0.023,
      "step": 75300
    },
    {
      "epoch": 5.184624905452795,
      "grad_norm": 0.1993112862110138,
      "learning_rate": 1.760921140853061e-05,
      "loss": 0.0232,
      "step": 75400
    },
    {
      "epoch": 5.191501065804855,
      "grad_norm": 0.14668382704257965,
      "learning_rate": 1.7566231712139186e-05,
      "loss": 0.022,
      "step": 75500
    },
    {
      "epoch": 5.198377226156914,
      "grad_norm": 0.2521490454673767,
      "learning_rate": 1.7523252015747763e-05,
      "loss": 0.0233,
      "step": 75600
    },
    {
      "epoch": 5.205253386508973,
      "grad_norm": 0.5629492998123169,
      "learning_rate": 1.7480272319356337e-05,
      "loss": 0.0205,
      "step": 75700
    },
    {
      "epoch": 5.212129546861033,
      "grad_norm": 0.12828639149665833,
      "learning_rate": 1.7437292622964914e-05,
      "loss": 0.0208,
      "step": 75800
    },
    {
      "epoch": 5.219005707213093,
      "grad_norm": 0.2575492560863495,
      "learning_rate": 1.7394312926573488e-05,
      "loss": 0.024,
      "step": 75900
    },
    {
      "epoch": 5.2258818675651515,
      "grad_norm": 0.5708778500556946,
      "learning_rate": 1.7351333230182062e-05,
      "loss": 0.0233,
      "step": 76000
    },
    {
      "epoch": 5.232758027917211,
      "grad_norm": 0.15035992860794067,
      "learning_rate": 1.730835353379064e-05,
      "loss": 0.0256,
      "step": 76100
    },
    {
      "epoch": 5.23963418826927,
      "grad_norm": 0.3958849310874939,
      "learning_rate": 1.7265373837399213e-05,
      "loss": 0.0213,
      "step": 76200
    },
    {
      "epoch": 5.24651034862133,
      "grad_norm": 0.24388322234153748,
      "learning_rate": 1.722239414100779e-05,
      "loss": 0.0226,
      "step": 76300
    },
    {
      "epoch": 5.2533865089733895,
      "grad_norm": 0.26212480664253235,
      "learning_rate": 1.7179414444616364e-05,
      "loss": 0.024,
      "step": 76400
    },
    {
      "epoch": 5.260262669325448,
      "grad_norm": 0.265082985162735,
      "learning_rate": 1.7136434748224938e-05,
      "loss": 0.0202,
      "step": 76500
    },
    {
      "epoch": 5.267138829677508,
      "grad_norm": 0.2047102451324463,
      "learning_rate": 1.7093455051833516e-05,
      "loss": 0.0244,
      "step": 76600
    },
    {
      "epoch": 5.274014990029568,
      "grad_norm": 0.28388601541519165,
      "learning_rate": 1.705047535544209e-05,
      "loss": 0.0213,
      "step": 76700
    },
    {
      "epoch": 5.280891150381627,
      "grad_norm": 0.26807570457458496,
      "learning_rate": 1.7007495659050667e-05,
      "loss": 0.0204,
      "step": 76800
    },
    {
      "epoch": 5.287767310733686,
      "grad_norm": 0.279754638671875,
      "learning_rate": 1.696451596265924e-05,
      "loss": 0.0209,
      "step": 76900
    },
    {
      "epoch": 5.294643471085745,
      "grad_norm": 0.19389644265174866,
      "learning_rate": 1.6921536266267815e-05,
      "loss": 0.0224,
      "step": 77000
    },
    {
      "epoch": 5.301519631437805,
      "grad_norm": 0.3434811532497406,
      "learning_rate": 1.6878556569876392e-05,
      "loss": 0.0244,
      "step": 77100
    },
    {
      "epoch": 5.308395791789865,
      "grad_norm": 0.19357067346572876,
      "learning_rate": 1.683557687348497e-05,
      "loss": 0.0211,
      "step": 77200
    },
    {
      "epoch": 5.315271952141924,
      "grad_norm": 0.2835357189178467,
      "learning_rate": 1.679259717709354e-05,
      "loss": 0.0218,
      "step": 77300
    },
    {
      "epoch": 5.322148112493983,
      "grad_norm": 0.18621067702770233,
      "learning_rate": 1.6749617480702117e-05,
      "loss": 0.0221,
      "step": 77400
    },
    {
      "epoch": 5.329024272846043,
      "grad_norm": 0.3048560619354248,
      "learning_rate": 1.670663778431069e-05,
      "loss": 0.0216,
      "step": 77500
    },
    {
      "epoch": 5.335900433198102,
      "grad_norm": 0.23590749502182007,
      "learning_rate": 1.666408788488318e-05,
      "loss": 0.0208,
      "step": 77600
    },
    {
      "epoch": 5.342776593550162,
      "grad_norm": 0.33824485540390015,
      "learning_rate": 1.6621108188491757e-05,
      "loss": 0.0235,
      "step": 77700
    },
    {
      "epoch": 5.349652753902221,
      "grad_norm": 0.35689154267311096,
      "learning_rate": 1.6578128492100335e-05,
      "loss": 0.0227,
      "step": 77800
    },
    {
      "epoch": 5.35652891425428,
      "grad_norm": 0.33690258860588074,
      "learning_rate": 1.653514879570891e-05,
      "loss": 0.0225,
      "step": 77900
    },
    {
      "epoch": 5.36340507460634,
      "grad_norm": 0.42722710967063904,
      "learning_rate": 1.6492169099317482e-05,
      "loss": 0.0213,
      "step": 78000
    },
    {
      "epoch": 5.370281234958399,
      "grad_norm": 0.14579610526561737,
      "learning_rate": 1.6449189402926056e-05,
      "loss": 0.0225,
      "step": 78100
    },
    {
      "epoch": 5.3771573953104586,
      "grad_norm": 0.06904087215662003,
      "learning_rate": 1.6406209706534634e-05,
      "loss": 0.0215,
      "step": 78200
    },
    {
      "epoch": 5.384033555662518,
      "grad_norm": 0.2322298288345337,
      "learning_rate": 1.636323001014321e-05,
      "loss": 0.0197,
      "step": 78300
    },
    {
      "epoch": 5.390909716014577,
      "grad_norm": 0.14332154393196106,
      "learning_rate": 1.63206801107157e-05,
      "loss": 0.0207,
      "step": 78400
    },
    {
      "epoch": 5.397785876366637,
      "grad_norm": 0.2216014862060547,
      "learning_rate": 1.6277700414324274e-05,
      "loss": 0.023,
      "step": 78500
    },
    {
      "epoch": 5.404662036718697,
      "grad_norm": 0.23081186413764954,
      "learning_rate": 1.623472071793285e-05,
      "loss": 0.0205,
      "step": 78600
    },
    {
      "epoch": 5.4115381970707555,
      "grad_norm": 0.28205734491348267,
      "learning_rate": 1.6191741021541422e-05,
      "loss": 0.0222,
      "step": 78700
    },
    {
      "epoch": 5.418414357422815,
      "grad_norm": 0.28087496757507324,
      "learning_rate": 1.614876132515e-05,
      "loss": 0.0219,
      "step": 78800
    },
    {
      "epoch": 5.425290517774875,
      "grad_norm": 0.2750902771949768,
      "learning_rate": 1.6105781628758576e-05,
      "loss": 0.0204,
      "step": 78900
    },
    {
      "epoch": 5.432166678126934,
      "grad_norm": 0.18803612887859344,
      "learning_rate": 1.606280193236715e-05,
      "loss": 0.0199,
      "step": 79000
    },
    {
      "epoch": 5.4390428384789935,
      "grad_norm": 0.24929304420948029,
      "learning_rate": 1.6019822235975728e-05,
      "loss": 0.0222,
      "step": 79100
    },
    {
      "epoch": 5.445918998831052,
      "grad_norm": 0.43785592913627625,
      "learning_rate": 1.59768425395843e-05,
      "loss": 0.0234,
      "step": 79200
    },
    {
      "epoch": 5.452795159183112,
      "grad_norm": 0.32369592785835266,
      "learning_rate": 1.5933862843192875e-05,
      "loss": 0.0229,
      "step": 79300
    },
    {
      "epoch": 5.459671319535172,
      "grad_norm": 0.11982443183660507,
      "learning_rate": 1.5890883146801453e-05,
      "loss": 0.0213,
      "step": 79400
    },
    {
      "epoch": 5.466547479887231,
      "grad_norm": 0.2279636710882187,
      "learning_rate": 1.5847903450410027e-05,
      "loss": 0.0196,
      "step": 79500
    },
    {
      "epoch": 5.47342364023929,
      "grad_norm": 0.32239577174186707,
      "learning_rate": 1.5804923754018604e-05,
      "loss": 0.0222,
      "step": 79600
    },
    {
      "epoch": 5.48029980059135,
      "grad_norm": 0.3538508713245392,
      "learning_rate": 1.5761944057627178e-05,
      "loss": 0.0197,
      "step": 79700
    },
    {
      "epoch": 5.487175960943409,
      "grad_norm": 0.19708402454853058,
      "learning_rate": 1.571896436123575e-05,
      "loss": 0.0207,
      "step": 79800
    },
    {
      "epoch": 5.494052121295469,
      "grad_norm": 0.14331312477588654,
      "learning_rate": 1.567598466484433e-05,
      "loss": 0.021,
      "step": 79900
    },
    {
      "epoch": 5.5009282816475285,
      "grad_norm": 0.3824508786201477,
      "learning_rate": 1.5633004968452903e-05,
      "loss": 0.0199,
      "step": 80000
    },
    {
      "epoch": 5.507804441999587,
      "grad_norm": 0.2537510395050049,
      "learning_rate": 1.559002527206148e-05,
      "loss": 0.0205,
      "step": 80100
    },
    {
      "epoch": 5.514680602351647,
      "grad_norm": 0.2278304100036621,
      "learning_rate": 1.5547045575670054e-05,
      "loss": 0.0207,
      "step": 80200
    },
    {
      "epoch": 5.521556762703706,
      "grad_norm": 0.3153022825717926,
      "learning_rate": 1.5504065879278628e-05,
      "loss": 0.0219,
      "step": 80300
    },
    {
      "epoch": 5.528432923055766,
      "grad_norm": 0.15634092688560486,
      "learning_rate": 1.5461086182887205e-05,
      "loss": 0.0228,
      "step": 80400
    },
    {
      "epoch": 5.535309083407825,
      "grad_norm": 0.24825944006443024,
      "learning_rate": 1.5418106486495783e-05,
      "loss": 0.022,
      "step": 80500
    },
    {
      "epoch": 5.542185243759884,
      "grad_norm": 0.19372473657131195,
      "learning_rate": 1.5375126790104357e-05,
      "loss": 0.0213,
      "step": 80600
    },
    {
      "epoch": 5.549061404111944,
      "grad_norm": 0.23028051853179932,
      "learning_rate": 1.533214709371293e-05,
      "loss": 0.0226,
      "step": 80700
    },
    {
      "epoch": 5.555937564464004,
      "grad_norm": 0.26435163617134094,
      "learning_rate": 1.5289167397321504e-05,
      "loss": 0.0223,
      "step": 80800
    },
    {
      "epoch": 5.5628137248160625,
      "grad_norm": 0.22815971076488495,
      "learning_rate": 1.5246187700930082e-05,
      "loss": 0.0257,
      "step": 80900
    },
    {
      "epoch": 5.569689885168122,
      "grad_norm": 0.2360520213842392,
      "learning_rate": 1.5203208004538657e-05,
      "loss": 0.0222,
      "step": 81000
    },
    {
      "epoch": 5.576566045520181,
      "grad_norm": 0.1991698294878006,
      "learning_rate": 1.5160658105111148e-05,
      "loss": 0.0236,
      "step": 81100
    },
    {
      "epoch": 5.583442205872241,
      "grad_norm": 0.37076106667518616,
      "learning_rate": 1.511767840871972e-05,
      "loss": 0.0235,
      "step": 81200
    },
    {
      "epoch": 5.590318366224301,
      "grad_norm": 0.2308669537305832,
      "learning_rate": 1.5074698712328298e-05,
      "loss": 0.0249,
      "step": 81300
    },
    {
      "epoch": 5.597194526576359,
      "grad_norm": 0.20119935274124146,
      "learning_rate": 1.5031719015936871e-05,
      "loss": 0.0225,
      "step": 81400
    },
    {
      "epoch": 5.604070686928419,
      "grad_norm": 0.33379554748535156,
      "learning_rate": 1.4988739319545447e-05,
      "loss": 0.0219,
      "step": 81500
    },
    {
      "epoch": 5.610946847280479,
      "grad_norm": 0.5333099961280823,
      "learning_rate": 1.4945759623154024e-05,
      "loss": 0.0213,
      "step": 81600
    },
    {
      "epoch": 5.617823007632538,
      "grad_norm": 0.23458552360534668,
      "learning_rate": 1.4902779926762597e-05,
      "loss": 0.0228,
      "step": 81700
    },
    {
      "epoch": 5.6246991679845975,
      "grad_norm": 0.2720974087715149,
      "learning_rate": 1.4859800230371174e-05,
      "loss": 0.0226,
      "step": 81800
    },
    {
      "epoch": 5.631575328336657,
      "grad_norm": 0.2546917498111725,
      "learning_rate": 1.481682053397975e-05,
      "loss": 0.024,
      "step": 81900
    },
    {
      "epoch": 5.638451488688716,
      "grad_norm": 0.3270987868309021,
      "learning_rate": 1.4773840837588323e-05,
      "loss": 0.0223,
      "step": 82000
    },
    {
      "epoch": 5.645327649040776,
      "grad_norm": 0.2859383225440979,
      "learning_rate": 1.47308611411969e-05,
      "loss": 0.0221,
      "step": 82100
    },
    {
      "epoch": 5.6522038093928355,
      "grad_norm": 0.22977732121944427,
      "learning_rate": 1.4687881444805473e-05,
      "loss": 0.0243,
      "step": 82200
    },
    {
      "epoch": 5.659079969744894,
      "grad_norm": 0.3288167715072632,
      "learning_rate": 1.464490174841405e-05,
      "loss": 0.022,
      "step": 82300
    },
    {
      "epoch": 5.665956130096954,
      "grad_norm": 0.20462511479854584,
      "learning_rate": 1.4601922052022626e-05,
      "loss": 0.0198,
      "step": 82400
    },
    {
      "epoch": 5.672832290449013,
      "grad_norm": 0.23440609872341156,
      "learning_rate": 1.45589423556312e-05,
      "loss": 0.0209,
      "step": 82500
    },
    {
      "epoch": 5.679708450801073,
      "grad_norm": 0.2785097658634186,
      "learning_rate": 1.4515962659239777e-05,
      "loss": 0.024,
      "step": 82600
    },
    {
      "epoch": 5.686584611153132,
      "grad_norm": 0.12236451357603073,
      "learning_rate": 1.447298296284835e-05,
      "loss": 0.0212,
      "step": 82700
    },
    {
      "epoch": 5.693460771505191,
      "grad_norm": 0.3422027826309204,
      "learning_rate": 1.4430003266456927e-05,
      "loss": 0.0208,
      "step": 82800
    },
    {
      "epoch": 5.700336931857251,
      "grad_norm": 0.08044872432947159,
      "learning_rate": 1.4387023570065502e-05,
      "loss": 0.0218,
      "step": 82900
    },
    {
      "epoch": 5.70721309220931,
      "grad_norm": 0.12110082060098648,
      "learning_rate": 1.4344043873674076e-05,
      "loss": 0.0226,
      "step": 83000
    },
    {
      "epoch": 5.71408925256137,
      "grad_norm": 0.29862841963768005,
      "learning_rate": 1.4301064177282653e-05,
      "loss": 0.0226,
      "step": 83100
    },
    {
      "epoch": 5.720965412913429,
      "grad_norm": 0.5285475254058838,
      "learning_rate": 1.4258084480891229e-05,
      "loss": 0.024,
      "step": 83200
    },
    {
      "epoch": 5.727841573265488,
      "grad_norm": 0.377767413854599,
      "learning_rate": 1.4215104784499803e-05,
      "loss": 0.0202,
      "step": 83300
    },
    {
      "epoch": 5.734717733617548,
      "grad_norm": 0.2373805195093155,
      "learning_rate": 1.4172125088108378e-05,
      "loss": 0.0201,
      "step": 83400
    },
    {
      "epoch": 5.741593893969608,
      "grad_norm": 0.5479780435562134,
      "learning_rate": 1.4129145391716952e-05,
      "loss": 0.0206,
      "step": 83500
    },
    {
      "epoch": 5.7484700543216665,
      "grad_norm": 0.25949621200561523,
      "learning_rate": 1.4086595492289441e-05,
      "loss": 0.0199,
      "step": 83600
    },
    {
      "epoch": 5.755346214673726,
      "grad_norm": 0.2939172387123108,
      "learning_rate": 1.4043615795898019e-05,
      "loss": 0.022,
      "step": 83700
    },
    {
      "epoch": 5.762222375025786,
      "grad_norm": 0.09897586703300476,
      "learning_rate": 1.4000636099506594e-05,
      "loss": 0.0228,
      "step": 83800
    },
    {
      "epoch": 5.769098535377845,
      "grad_norm": 0.2468339204788208,
      "learning_rate": 1.3957656403115168e-05,
      "loss": 0.022,
      "step": 83900
    },
    {
      "epoch": 5.7759746957299045,
      "grad_norm": 0.15068140625953674,
      "learning_rate": 1.3914676706723746e-05,
      "loss": 0.0212,
      "step": 84000
    },
    {
      "epoch": 5.782850856081964,
      "grad_norm": 0.18769216537475586,
      "learning_rate": 1.3871697010332318e-05,
      "loss": 0.0232,
      "step": 84100
    },
    {
      "epoch": 5.789727016434023,
      "grad_norm": 0.26274973154067993,
      "learning_rate": 1.3828717313940895e-05,
      "loss": 0.0227,
      "step": 84200
    },
    {
      "epoch": 5.796603176786083,
      "grad_norm": 0.21969404816627502,
      "learning_rate": 1.378573761754947e-05,
      "loss": 0.022,
      "step": 84300
    },
    {
      "epoch": 5.803479337138142,
      "grad_norm": 0.16090284287929535,
      "learning_rate": 1.3742757921158045e-05,
      "loss": 0.0199,
      "step": 84400
    },
    {
      "epoch": 5.810355497490201,
      "grad_norm": 0.24627135694026947,
      "learning_rate": 1.3699778224766622e-05,
      "loss": 0.0218,
      "step": 84500
    },
    {
      "epoch": 5.817231657842261,
      "grad_norm": 0.15500353276729584,
      "learning_rate": 1.3656798528375197e-05,
      "loss": 0.0202,
      "step": 84600
    },
    {
      "epoch": 5.82410781819432,
      "grad_norm": 0.3666105270385742,
      "learning_rate": 1.3613818831983771e-05,
      "loss": 0.0234,
      "step": 84700
    },
    {
      "epoch": 5.83098397854638,
      "grad_norm": 0.37270650267601013,
      "learning_rate": 1.3570839135592347e-05,
      "loss": 0.0245,
      "step": 84800
    },
    {
      "epoch": 5.8378601388984395,
      "grad_norm": 0.22615844011306763,
      "learning_rate": 1.3528289236164838e-05,
      "loss": 0.0216,
      "step": 84900
    },
    {
      "epoch": 5.844736299250498,
      "grad_norm": 0.2725626528263092,
      "learning_rate": 1.3485309539773412e-05,
      "loss": 0.0205,
      "step": 85000
    },
    {
      "epoch": 5.851612459602558,
      "grad_norm": 0.3186171352863312,
      "learning_rate": 1.3442329843381987e-05,
      "loss": 0.0193,
      "step": 85100
    },
    {
      "epoch": 5.858488619954617,
      "grad_norm": 0.14484253525733948,
      "learning_rate": 1.3399350146990563e-05,
      "loss": 0.0212,
      "step": 85200
    },
    {
      "epoch": 5.865364780306677,
      "grad_norm": 0.41374441981315613,
      "learning_rate": 1.3356370450599137e-05,
      "loss": 0.0224,
      "step": 85300
    },
    {
      "epoch": 5.872240940658736,
      "grad_norm": 0.1603335589170456,
      "learning_rate": 1.3313390754207714e-05,
      "loss": 0.021,
      "step": 85400
    },
    {
      "epoch": 5.879117101010795,
      "grad_norm": 0.12235182523727417,
      "learning_rate": 1.3270411057816286e-05,
      "loss": 0.0216,
      "step": 85500
    },
    {
      "epoch": 5.885993261362855,
      "grad_norm": 0.10482893884181976,
      "learning_rate": 1.3227431361424864e-05,
      "loss": 0.0181,
      "step": 85600
    },
    {
      "epoch": 5.892869421714915,
      "grad_norm": 0.15376751124858856,
      "learning_rate": 1.318445166503344e-05,
      "loss": 0.0193,
      "step": 85700
    },
    {
      "epoch": 5.8997455820669735,
      "grad_norm": 0.3044152557849884,
      "learning_rate": 1.3141471968642013e-05,
      "loss": 0.0227,
      "step": 85800
    },
    {
      "epoch": 5.906621742419033,
      "grad_norm": 0.16026654839515686,
      "learning_rate": 1.309849227225059e-05,
      "loss": 0.0216,
      "step": 85900
    },
    {
      "epoch": 5.913497902771093,
      "grad_norm": 0.2639457583427429,
      "learning_rate": 1.3055512575859163e-05,
      "loss": 0.0219,
      "step": 86000
    },
    {
      "epoch": 5.920374063123152,
      "grad_norm": 0.234812393784523,
      "learning_rate": 1.301253287946774e-05,
      "loss": 0.0218,
      "step": 86100
    },
    {
      "epoch": 5.927250223475212,
      "grad_norm": 0.24581138789653778,
      "learning_rate": 1.2969553183076316e-05,
      "loss": 0.0184,
      "step": 86200
    },
    {
      "epoch": 5.934126383827271,
      "grad_norm": 0.1033787801861763,
      "learning_rate": 1.292657348668489e-05,
      "loss": 0.0197,
      "step": 86300
    },
    {
      "epoch": 5.94100254417933,
      "grad_norm": 0.41219595074653625,
      "learning_rate": 1.2883593790293467e-05,
      "loss": 0.0205,
      "step": 86400
    },
    {
      "epoch": 5.94787870453139,
      "grad_norm": 0.5672101974487305,
      "learning_rate": 1.2840614093902042e-05,
      "loss": 0.0188,
      "step": 86500
    },
    {
      "epoch": 5.954754864883449,
      "grad_norm": 0.3236794173717499,
      "learning_rate": 1.2797634397510616e-05,
      "loss": 0.02,
      "step": 86600
    },
    {
      "epoch": 5.9616310252355085,
      "grad_norm": 0.16669787466526031,
      "learning_rate": 1.2754654701119192e-05,
      "loss": 0.0195,
      "step": 86700
    },
    {
      "epoch": 5.968507185587568,
      "grad_norm": 0.351014643907547,
      "learning_rate": 1.2711675004727766e-05,
      "loss": 0.0221,
      "step": 86800
    },
    {
      "epoch": 5.975383345939627,
      "grad_norm": 0.1789889633655548,
      "learning_rate": 1.2668695308336343e-05,
      "loss": 0.0238,
      "step": 86900
    },
    {
      "epoch": 5.982259506291687,
      "grad_norm": 0.21734464168548584,
      "learning_rate": 1.2625715611944919e-05,
      "loss": 0.0207,
      "step": 87000
    },
    {
      "epoch": 5.989135666643746,
      "grad_norm": 0.14006707072257996,
      "learning_rate": 1.2582735915553493e-05,
      "loss": 0.021,
      "step": 87100
    },
    {
      "epoch": 5.996011826995805,
      "grad_norm": 0.10724497586488724,
      "learning_rate": 1.2539756219162068e-05,
      "loss": 0.0229,
      "step": 87200
    },
    {
      "epoch": 6.0,
      "eval_accuracy_macro_0.5": 0.9891990423202515,
      "eval_accuracy_micro_0.5": 0.9891991019248962,
      "eval_accuracy_weighted_0.5": 0.9876059293746948,
      "eval_f1_macro_0.5": 0.8654891848564148,
      "eval_f1_macro_0.6": 0.8598933219909668,
      "eval_f1_macro_0.7": 0.8479480743408203,
      "eval_f1_macro_0.8": 0.7637233734130859,
      "eval_f1_micro_0.5": 0.8616601824760437,
      "eval_f1_micro_0.6": 0.8573257923126221,
      "eval_f1_micro_0.7": 0.8464946746826172,
      "eval_f1_micro_0.8": 0.8228117823600769,
      "eval_f1_micro_0.9": 0.7680807113647461,
      "eval_f1_weighted_0.5": 0.8603485822677612,
      "eval_f1_weighted_0.6": 0.8544443845748901,
      "eval_f1_weighted_0.7": 0.8415367007255554,
      "eval_f1_weighted_0.8": 0.752076268196106,
      "eval_loss": 0.022167865186929703,
      "eval_runtime": 440.8783,
      "eval_samples_per_second": 65.862,
      "eval_steps_per_second": 8.234,
      "step": 87258
    },
    {
      "epoch": 6.002887987347865,
      "grad_norm": 0.26359060406684875,
      "learning_rate": 1.2496776522770644e-05,
      "loss": 0.0235,
      "step": 87300
    },
    {
      "epoch": 6.009764147699924,
      "grad_norm": 0.18267245590686798,
      "learning_rate": 1.245379682637922e-05,
      "loss": 0.0208,
      "step": 87400
    },
    {
      "epoch": 6.016640308051984,
      "grad_norm": 0.2587678134441376,
      "learning_rate": 1.2410817129987793e-05,
      "loss": 0.021,
      "step": 87500
    },
    {
      "epoch": 6.023516468404043,
      "grad_norm": 0.06506524235010147,
      "learning_rate": 1.236783743359637e-05,
      "loss": 0.0205,
      "step": 87600
    },
    {
      "epoch": 6.030392628756102,
      "grad_norm": 0.2768877446651459,
      "learning_rate": 1.2324857737204945e-05,
      "loss": 0.0212,
      "step": 87700
    },
    {
      "epoch": 6.037268789108162,
      "grad_norm": 0.4118593633174896,
      "learning_rate": 1.228187804081352e-05,
      "loss": 0.0194,
      "step": 87800
    },
    {
      "epoch": 6.044144949460222,
      "grad_norm": 0.19273678958415985,
      "learning_rate": 1.2238898344422096e-05,
      "loss": 0.0202,
      "step": 87900
    },
    {
      "epoch": 6.051021109812281,
      "grad_norm": 0.14198577404022217,
      "learning_rate": 1.2195918648030671e-05,
      "loss": 0.0192,
      "step": 88000
    },
    {
      "epoch": 6.05789727016434,
      "grad_norm": 0.15108124911785126,
      "learning_rate": 1.2152938951639247e-05,
      "loss": 0.0206,
      "step": 88100
    },
    {
      "epoch": 6.0647734305164,
      "grad_norm": 0.42788705229759216,
      "learning_rate": 1.2109959255247821e-05,
      "loss": 0.0209,
      "step": 88200
    },
    {
      "epoch": 6.071649590868459,
      "grad_norm": 0.21929708123207092,
      "learning_rate": 1.2066979558856396e-05,
      "loss": 0.0201,
      "step": 88300
    },
    {
      "epoch": 6.078525751220519,
      "grad_norm": 0.18150551617145538,
      "learning_rate": 1.2023999862464972e-05,
      "loss": 0.0212,
      "step": 88400
    },
    {
      "epoch": 6.0854019115725775,
      "grad_norm": 0.037220537662506104,
      "learning_rate": 1.1981020166073548e-05,
      "loss": 0.0189,
      "step": 88500
    },
    {
      "epoch": 6.092278071924637,
      "grad_norm": 0.09959650039672852,
      "learning_rate": 1.1938040469682123e-05,
      "loss": 0.0197,
      "step": 88600
    },
    {
      "epoch": 6.099154232276697,
      "grad_norm": 0.25026625394821167,
      "learning_rate": 1.1895060773290697e-05,
      "loss": 0.0224,
      "step": 88700
    },
    {
      "epoch": 6.106030392628756,
      "grad_norm": 0.3981481194496155,
      "learning_rate": 1.1852081076899273e-05,
      "loss": 0.0212,
      "step": 88800
    },
    {
      "epoch": 6.1129065529808155,
      "grad_norm": 0.1989743858575821,
      "learning_rate": 1.1809101380507848e-05,
      "loss": 0.0205,
      "step": 88900
    },
    {
      "epoch": 6.119782713332875,
      "grad_norm": 0.20416277647018433,
      "learning_rate": 1.1766121684116424e-05,
      "loss": 0.0214,
      "step": 89000
    },
    {
      "epoch": 6.126658873684934,
      "grad_norm": 0.10417933017015457,
      "learning_rate": 1.1723141987725e-05,
      "loss": 0.0211,
      "step": 89100
    },
    {
      "epoch": 6.133535034036994,
      "grad_norm": 0.23409095406532288,
      "learning_rate": 1.1680162291333574e-05,
      "loss": 0.0216,
      "step": 89200
    },
    {
      "epoch": 6.140411194389053,
      "grad_norm": 0.30515071749687195,
      "learning_rate": 1.163718259494215e-05,
      "loss": 0.0207,
      "step": 89300
    },
    {
      "epoch": 6.147287354741112,
      "grad_norm": 0.21724049746990204,
      "learning_rate": 1.1594202898550725e-05,
      "loss": 0.0193,
      "step": 89400
    },
    {
      "epoch": 6.154163515093172,
      "grad_norm": 0.1826334297657013,
      "learning_rate": 1.15512232021593e-05,
      "loss": 0.0215,
      "step": 89500
    },
    {
      "epoch": 6.161039675445231,
      "grad_norm": 0.40035754442214966,
      "learning_rate": 1.1508243505767876e-05,
      "loss": 0.0218,
      "step": 89600
    },
    {
      "epoch": 6.167915835797291,
      "grad_norm": 0.15485870838165283,
      "learning_rate": 1.1465263809376452e-05,
      "loss": 0.0197,
      "step": 89700
    },
    {
      "epoch": 6.1747919961493505,
      "grad_norm": 0.13878914713859558,
      "learning_rate": 1.1422284112985027e-05,
      "loss": 0.0213,
      "step": 89800
    },
    {
      "epoch": 6.181668156501409,
      "grad_norm": 0.47613853216171265,
      "learning_rate": 1.1379734213557516e-05,
      "loss": 0.021,
      "step": 89900
    },
    {
      "epoch": 6.188544316853469,
      "grad_norm": 0.4143339991569519,
      "learning_rate": 1.1336754517166092e-05,
      "loss": 0.0201,
      "step": 90000
    },
    {
      "epoch": 6.195420477205529,
      "grad_norm": 0.21595530211925507,
      "learning_rate": 1.1293774820774666e-05,
      "loss": 0.0218,
      "step": 90100
    },
    {
      "epoch": 6.202296637557588,
      "grad_norm": 0.16146467626094818,
      "learning_rate": 1.1250795124383241e-05,
      "loss": 0.0228,
      "step": 90200
    },
    {
      "epoch": 6.209172797909647,
      "grad_norm": 0.3178112506866455,
      "learning_rate": 1.1207815427991817e-05,
      "loss": 0.0209,
      "step": 90300
    },
    {
      "epoch": 6.216048958261707,
      "grad_norm": 0.5481624603271484,
      "learning_rate": 1.1164835731600393e-05,
      "loss": 0.0202,
      "step": 90400
    },
    {
      "epoch": 6.222925118613766,
      "grad_norm": 0.10492860525846481,
      "learning_rate": 1.1121856035208968e-05,
      "loss": 0.0198,
      "step": 90500
    },
    {
      "epoch": 6.229801278965826,
      "grad_norm": 0.16527678072452545,
      "learning_rate": 1.1078876338817542e-05,
      "loss": 0.0188,
      "step": 90600
    },
    {
      "epoch": 6.2366774393178845,
      "grad_norm": 0.3053494691848755,
      "learning_rate": 1.103589664242612e-05,
      "loss": 0.02,
      "step": 90700
    },
    {
      "epoch": 6.243553599669944,
      "grad_norm": 0.34641435742378235,
      "learning_rate": 1.0992916946034693e-05,
      "loss": 0.0218,
      "step": 90800
    },
    {
      "epoch": 6.250429760022004,
      "grad_norm": 0.18875668942928314,
      "learning_rate": 1.0949937249643269e-05,
      "loss": 0.0218,
      "step": 90900
    },
    {
      "epoch": 6.257305920374063,
      "grad_norm": 0.2972770035266876,
      "learning_rate": 1.0906957553251844e-05,
      "loss": 0.02,
      "step": 91000
    },
    {
      "epoch": 6.264182080726123,
      "grad_norm": 0.09354525059461594,
      "learning_rate": 1.086397785686042e-05,
      "loss": 0.0235,
      "step": 91100
    },
    {
      "epoch": 6.271058241078182,
      "grad_norm": 0.14107739925384521,
      "learning_rate": 1.0820998160468996e-05,
      "loss": 0.0214,
      "step": 91200
    },
    {
      "epoch": 6.277934401430241,
      "grad_norm": 0.19168873131275177,
      "learning_rate": 1.077801846407757e-05,
      "loss": 0.0209,
      "step": 91300
    },
    {
      "epoch": 6.284810561782301,
      "grad_norm": 0.1936815083026886,
      "learning_rate": 1.0735038767686145e-05,
      "loss": 0.0235,
      "step": 91400
    },
    {
      "epoch": 6.29168672213436,
      "grad_norm": 0.2201520949602127,
      "learning_rate": 1.069205907129472e-05,
      "loss": 0.0218,
      "step": 91500
    },
    {
      "epoch": 6.2985628824864195,
      "grad_norm": 0.5920156836509705,
      "learning_rate": 1.0649079374903296e-05,
      "loss": 0.0192,
      "step": 91600
    },
    {
      "epoch": 6.305439042838479,
      "grad_norm": 0.18581445515155792,
      "learning_rate": 1.0606099678511872e-05,
      "loss": 0.019,
      "step": 91700
    },
    {
      "epoch": 6.312315203190538,
      "grad_norm": 0.24145689606666565,
      "learning_rate": 1.0563119982120446e-05,
      "loss": 0.0216,
      "step": 91800
    },
    {
      "epoch": 6.319191363542598,
      "grad_norm": 0.0925571471452713,
      "learning_rate": 1.0520140285729022e-05,
      "loss": 0.0221,
      "step": 91900
    },
    {
      "epoch": 6.3260675238946575,
      "grad_norm": 0.11112572252750397,
      "learning_rate": 1.0477160589337597e-05,
      "loss": 0.023,
      "step": 92000
    },
    {
      "epoch": 6.332943684246716,
      "grad_norm": 0.1656968593597412,
      "learning_rate": 1.0434180892946173e-05,
      "loss": 0.02,
      "step": 92100
    },
    {
      "epoch": 6.339819844598776,
      "grad_norm": 0.1259322315454483,
      "learning_rate": 1.0391201196554748e-05,
      "loss": 0.0225,
      "step": 92200
    },
    {
      "epoch": 6.346696004950836,
      "grad_norm": 0.2661113142967224,
      "learning_rate": 1.0348221500163322e-05,
      "loss": 0.0213,
      "step": 92300
    },
    {
      "epoch": 6.353572165302895,
      "grad_norm": 0.17910070717334747,
      "learning_rate": 1.03052418037719e-05,
      "loss": 0.0192,
      "step": 92400
    },
    {
      "epoch": 6.360448325654954,
      "grad_norm": 0.09513574093580246,
      "learning_rate": 1.0262691904344387e-05,
      "loss": 0.022,
      "step": 92500
    },
    {
      "epoch": 6.367324486007013,
      "grad_norm": 0.44708317518234253,
      "learning_rate": 1.0219712207952964e-05,
      "loss": 0.0204,
      "step": 92600
    },
    {
      "epoch": 6.374200646359073,
      "grad_norm": 0.21995647251605988,
      "learning_rate": 1.0176732511561538e-05,
      "loss": 0.0222,
      "step": 92700
    },
    {
      "epoch": 6.381076806711133,
      "grad_norm": 0.12320559471845627,
      "learning_rate": 1.0133752815170114e-05,
      "loss": 0.0214,
      "step": 92800
    },
    {
      "epoch": 6.387952967063192,
      "grad_norm": 0.1638452410697937,
      "learning_rate": 1.009077311877869e-05,
      "loss": 0.0205,
      "step": 92900
    },
    {
      "epoch": 6.394829127415251,
      "grad_norm": 0.21197426319122314,
      "learning_rate": 1.0047793422387265e-05,
      "loss": 0.0198,
      "step": 93000
    },
    {
      "epoch": 6.401705287767311,
      "grad_norm": 0.37383216619491577,
      "learning_rate": 1.000481372599584e-05,
      "loss": 0.0211,
      "step": 93100
    },
    {
      "epoch": 6.40858144811937,
      "grad_norm": 0.18668881058692932,
      "learning_rate": 9.961834029604414e-06,
      "loss": 0.0229,
      "step": 93200
    },
    {
      "epoch": 6.41545760847143,
      "grad_norm": 0.21414999663829803,
      "learning_rate": 9.91885433321299e-06,
      "loss": 0.0192,
      "step": 93300
    },
    {
      "epoch": 6.4223337688234885,
      "grad_norm": 0.35938045382499695,
      "learning_rate": 9.875874636821567e-06,
      "loss": 0.0189,
      "step": 93400
    },
    {
      "epoch": 6.429209929175548,
      "grad_norm": 0.20097775757312775,
      "learning_rate": 9.832894940430141e-06,
      "loss": 0.0197,
      "step": 93500
    },
    {
      "epoch": 6.436086089527608,
      "grad_norm": 0.2262982726097107,
      "learning_rate": 9.789915244038717e-06,
      "loss": 0.0184,
      "step": 93600
    },
    {
      "epoch": 6.442962249879667,
      "grad_norm": 0.14784035086631775,
      "learning_rate": 9.74693554764729e-06,
      "loss": 0.0217,
      "step": 93700
    },
    {
      "epoch": 6.4498384102317265,
      "grad_norm": 0.2536853849887848,
      "learning_rate": 9.703955851255868e-06,
      "loss": 0.0202,
      "step": 93800
    },
    {
      "epoch": 6.456714570583786,
      "grad_norm": 0.17874231934547424,
      "learning_rate": 9.660976154864442e-06,
      "loss": 0.0191,
      "step": 93900
    },
    {
      "epoch": 6.463590730935845,
      "grad_norm": 0.1996489316225052,
      "learning_rate": 9.617996458473018e-06,
      "loss": 0.0208,
      "step": 94000
    },
    {
      "epoch": 6.470466891287905,
      "grad_norm": 0.13552513718605042,
      "learning_rate": 9.575016762081593e-06,
      "loss": 0.0203,
      "step": 94100
    },
    {
      "epoch": 6.477343051639965,
      "grad_norm": 0.3326413333415985,
      "learning_rate": 9.532037065690167e-06,
      "loss": 0.0207,
      "step": 94200
    },
    {
      "epoch": 6.4842192119920234,
      "grad_norm": 0.13226807117462158,
      "learning_rate": 9.489057369298744e-06,
      "loss": 0.0229,
      "step": 94300
    },
    {
      "epoch": 6.491095372344083,
      "grad_norm": 0.26486074924468994,
      "learning_rate": 9.446077672907318e-06,
      "loss": 0.0188,
      "step": 94400
    },
    {
      "epoch": 6.497971532696143,
      "grad_norm": 0.6462195515632629,
      "learning_rate": 9.403097976515894e-06,
      "loss": 0.0211,
      "step": 94500
    },
    {
      "epoch": 6.504847693048202,
      "grad_norm": 0.0941297635436058,
      "learning_rate": 9.36011828012447e-06,
      "loss": 0.0198,
      "step": 94600
    },
    {
      "epoch": 6.5117238534002615,
      "grad_norm": 0.1316578984260559,
      "learning_rate": 9.317138583733045e-06,
      "loss": 0.0206,
      "step": 94700
    },
    {
      "epoch": 6.51860001375232,
      "grad_norm": 0.16452044248580933,
      "learning_rate": 9.27415888734162e-06,
      "loss": 0.0202,
      "step": 94800
    },
    {
      "epoch": 6.52547617410438,
      "grad_norm": 0.25294074416160583,
      "learning_rate": 9.231179190950195e-06,
      "loss": 0.0182,
      "step": 94900
    },
    {
      "epoch": 6.53235233445644,
      "grad_norm": 0.48749735951423645,
      "learning_rate": 9.18819949455877e-06,
      "loss": 0.0217,
      "step": 95000
    },
    {
      "epoch": 6.539228494808499,
      "grad_norm": 0.08084514737129211,
      "learning_rate": 9.145219798167348e-06,
      "loss": 0.0198,
      "step": 95100
    },
    {
      "epoch": 6.546104655160558,
      "grad_norm": 0.6604889631271362,
      "learning_rate": 9.102240101775922e-06,
      "loss": 0.0223,
      "step": 95200
    },
    {
      "epoch": 6.552980815512618,
      "grad_norm": 0.2095632255077362,
      "learning_rate": 9.059260405384497e-06,
      "loss": 0.0208,
      "step": 95300
    },
    {
      "epoch": 6.559856975864677,
      "grad_norm": 0.1431705504655838,
      "learning_rate": 9.016280708993071e-06,
      "loss": 0.0204,
      "step": 95400
    },
    {
      "epoch": 6.566733136216737,
      "grad_norm": 0.1140713021159172,
      "learning_rate": 8.973301012601647e-06,
      "loss": 0.0213,
      "step": 95500
    },
    {
      "epoch": 6.573609296568796,
      "grad_norm": 0.22832712531089783,
      "learning_rate": 8.930321316210224e-06,
      "loss": 0.0207,
      "step": 95600
    },
    {
      "epoch": 6.580485456920855,
      "grad_norm": 0.2225223034620285,
      "learning_rate": 8.887341619818798e-06,
      "loss": 0.0212,
      "step": 95700
    },
    {
      "epoch": 6.587361617272915,
      "grad_norm": 0.24943052232265472,
      "learning_rate": 8.844361923427373e-06,
      "loss": 0.0208,
      "step": 95800
    },
    {
      "epoch": 6.594237777624974,
      "grad_norm": 0.2703506052494049,
      "learning_rate": 8.801382227035947e-06,
      "loss": 0.0214,
      "step": 95900
    },
    {
      "epoch": 6.601113937977034,
      "grad_norm": 0.3292466700077057,
      "learning_rate": 8.758402530644525e-06,
      "loss": 0.0208,
      "step": 96000
    },
    {
      "epoch": 6.607990098329093,
      "grad_norm": 0.13571476936340332,
      "learning_rate": 8.715422834253099e-06,
      "loss": 0.0196,
      "step": 96100
    },
    {
      "epoch": 6.614866258681152,
      "grad_norm": 0.28138500452041626,
      "learning_rate": 8.672443137861674e-06,
      "loss": 0.0208,
      "step": 96200
    },
    {
      "epoch": 6.621742419033212,
      "grad_norm": 0.20542529225349426,
      "learning_rate": 8.62946344147025e-06,
      "loss": 0.0207,
      "step": 96300
    },
    {
      "epoch": 6.628618579385272,
      "grad_norm": 0.14451339840888977,
      "learning_rate": 8.586483745078825e-06,
      "loss": 0.0205,
      "step": 96400
    },
    {
      "epoch": 6.6354947397373305,
      "grad_norm": 0.24738004803657532,
      "learning_rate": 8.543504048687401e-06,
      "loss": 0.0199,
      "step": 96500
    },
    {
      "epoch": 6.64237090008939,
      "grad_norm": 0.4551432430744171,
      "learning_rate": 8.500524352295975e-06,
      "loss": 0.0205,
      "step": 96600
    },
    {
      "epoch": 6.64924706044145,
      "grad_norm": 0.1700829267501831,
      "learning_rate": 8.45754465590455e-06,
      "loss": 0.0216,
      "step": 96700
    },
    {
      "epoch": 6.656123220793509,
      "grad_norm": 0.2084406167268753,
      "learning_rate": 8.414564959513128e-06,
      "loss": 0.0198,
      "step": 96800
    },
    {
      "epoch": 6.662999381145569,
      "grad_norm": 0.3426310122013092,
      "learning_rate": 8.371585263121702e-06,
      "loss": 0.0184,
      "step": 96900
    },
    {
      "epoch": 6.669875541497627,
      "grad_norm": 0.27648240327835083,
      "learning_rate": 8.328605566730277e-06,
      "loss": 0.0214,
      "step": 97000
    },
    {
      "epoch": 6.676751701849687,
      "grad_norm": 0.5481230020523071,
      "learning_rate": 8.285625870338851e-06,
      "loss": 0.0218,
      "step": 97100
    },
    {
      "epoch": 6.683627862201747,
      "grad_norm": 0.43627652525901794,
      "learning_rate": 8.242646173947427e-06,
      "loss": 0.0213,
      "step": 97200
    },
    {
      "epoch": 6.690504022553806,
      "grad_norm": 0.21728596091270447,
      "learning_rate": 8.199666477556004e-06,
      "loss": 0.0205,
      "step": 97300
    },
    {
      "epoch": 6.6973801829058655,
      "grad_norm": 0.37998127937316895,
      "learning_rate": 8.156686781164578e-06,
      "loss": 0.022,
      "step": 97400
    },
    {
      "epoch": 6.704256343257924,
      "grad_norm": 0.24558033049106598,
      "learning_rate": 8.113707084773154e-06,
      "loss": 0.0221,
      "step": 97500
    },
    {
      "epoch": 6.711132503609984,
      "grad_norm": 0.23325538635253906,
      "learning_rate": 8.070727388381728e-06,
      "loss": 0.0221,
      "step": 97600
    },
    {
      "epoch": 6.718008663962044,
      "grad_norm": 0.3646883964538574,
      "learning_rate": 8.027747691990305e-06,
      "loss": 0.0185,
      "step": 97700
    },
    {
      "epoch": 6.724884824314103,
      "grad_norm": 0.2643032968044281,
      "learning_rate": 7.98476799559888e-06,
      "loss": 0.021,
      "step": 97800
    },
    {
      "epoch": 6.731760984666162,
      "grad_norm": 0.4909314513206482,
      "learning_rate": 7.941788299207454e-06,
      "loss": 0.0185,
      "step": 97900
    },
    {
      "epoch": 6.738637145018222,
      "grad_norm": 0.15681831538677216,
      "learning_rate": 7.89880860281603e-06,
      "loss": 0.0202,
      "step": 98000
    },
    {
      "epoch": 6.745513305370281,
      "grad_norm": 0.3683374226093292,
      "learning_rate": 7.855828906424606e-06,
      "loss": 0.0195,
      "step": 98100
    },
    {
      "epoch": 6.752389465722341,
      "grad_norm": 0.19942642748355865,
      "learning_rate": 7.812849210033181e-06,
      "loss": 0.0208,
      "step": 98200
    },
    {
      "epoch": 6.7592656260744,
      "grad_norm": 0.07003454864025116,
      "learning_rate": 7.769869513641755e-06,
      "loss": 0.0192,
      "step": 98300
    },
    {
      "epoch": 6.766141786426459,
      "grad_norm": 0.2740873098373413,
      "learning_rate": 7.72688981725033e-06,
      "loss": 0.0196,
      "step": 98400
    },
    {
      "epoch": 6.773017946778519,
      "grad_norm": 0.21473199129104614,
      "learning_rate": 7.683910120858906e-06,
      "loss": 0.0195,
      "step": 98500
    },
    {
      "epoch": 6.779894107130579,
      "grad_norm": 0.16405470669269562,
      "learning_rate": 7.640930424467482e-06,
      "loss": 0.0211,
      "step": 98600
    },
    {
      "epoch": 6.786770267482638,
      "grad_norm": 0.27041226625442505,
      "learning_rate": 7.5979507280760575e-06,
      "loss": 0.0218,
      "step": 98700
    },
    {
      "epoch": 6.793646427834697,
      "grad_norm": 0.17988140881061554,
      "learning_rate": 7.554971031684632e-06,
      "loss": 0.0199,
      "step": 98800
    },
    {
      "epoch": 6.800522588186756,
      "grad_norm": 0.27230679988861084,
      "learning_rate": 7.511991335293207e-06,
      "loss": 0.0205,
      "step": 98900
    },
    {
      "epoch": 6.807398748538816,
      "grad_norm": 0.27784624695777893,
      "learning_rate": 7.4690116389017835e-06,
      "loss": 0.0211,
      "step": 99000
    },
    {
      "epoch": 6.814274908890876,
      "grad_norm": 0.22965851426124573,
      "learning_rate": 7.426031942510358e-06,
      "loss": 0.019,
      "step": 99100
    },
    {
      "epoch": 6.8211510692429345,
      "grad_norm": 0.23514008522033691,
      "learning_rate": 7.383052246118934e-06,
      "loss": 0.0194,
      "step": 99200
    },
    {
      "epoch": 6.828027229594994,
      "grad_norm": 0.6230529546737671,
      "learning_rate": 7.340072549727509e-06,
      "loss": 0.0206,
      "step": 99300
    },
    {
      "epoch": 6.834903389947054,
      "grad_norm": 0.48812511563301086,
      "learning_rate": 7.297092853336085e-06,
      "loss": 0.0203,
      "step": 99400
    },
    {
      "epoch": 6.841779550299113,
      "grad_norm": 0.3496878743171692,
      "learning_rate": 7.25411315694466e-06,
      "loss": 0.0219,
      "step": 99500
    },
    {
      "epoch": 6.8486557106511725,
      "grad_norm": 0.23457105457782745,
      "learning_rate": 7.211133460553235e-06,
      "loss": 0.0212,
      "step": 99600
    },
    {
      "epoch": 6.855531871003231,
      "grad_norm": 0.1870705485343933,
      "learning_rate": 7.16815376416181e-06,
      "loss": 0.021,
      "step": 99700
    },
    {
      "epoch": 6.862408031355291,
      "grad_norm": 0.11581388860940933,
      "learning_rate": 7.125174067770387e-06,
      "loss": 0.0209,
      "step": 99800
    },
    {
      "epoch": 6.869284191707351,
      "grad_norm": 0.28700679540634155,
      "learning_rate": 7.082624168342875e-06,
      "loss": 0.0198,
      "step": 99900
    },
    {
      "epoch": 6.87616035205941,
      "grad_norm": 0.3790753483772278,
      "learning_rate": 7.039644471951451e-06,
      "loss": 0.0215,
      "step": 100000
    },
    {
      "epoch": 6.883036512411469,
      "grad_norm": 0.30576851963996887,
      "learning_rate": 6.996664775560026e-06,
      "loss": 0.0223,
      "step": 100100
    },
    {
      "epoch": 6.889912672763529,
      "grad_norm": 0.18920953571796417,
      "learning_rate": 6.953685079168601e-06,
      "loss": 0.0201,
      "step": 100200
    },
    {
      "epoch": 6.896788833115588,
      "grad_norm": 0.14576300978660583,
      "learning_rate": 6.910705382777176e-06,
      "loss": 0.0196,
      "step": 100300
    },
    {
      "epoch": 6.903664993467648,
      "grad_norm": 0.6401411890983582,
      "learning_rate": 6.867725686385752e-06,
      "loss": 0.0196,
      "step": 100400
    },
    {
      "epoch": 6.9105411538197075,
      "grad_norm": 0.22433170676231384,
      "learning_rate": 6.824745989994328e-06,
      "loss": 0.0204,
      "step": 100500
    },
    {
      "epoch": 6.917417314171766,
      "grad_norm": 0.5415365695953369,
      "learning_rate": 6.781766293602902e-06,
      "loss": 0.0227,
      "step": 100600
    },
    {
      "epoch": 6.924293474523826,
      "grad_norm": 0.18363498151302338,
      "learning_rate": 6.738786597211477e-06,
      "loss": 0.0215,
      "step": 100700
    },
    {
      "epoch": 6.931169634875886,
      "grad_norm": 0.12396221607923508,
      "learning_rate": 6.695806900820054e-06,
      "loss": 0.0211,
      "step": 100800
    },
    {
      "epoch": 6.938045795227945,
      "grad_norm": 0.2591172754764557,
      "learning_rate": 6.652827204428628e-06,
      "loss": 0.0202,
      "step": 100900
    },
    {
      "epoch": 6.944921955580004,
      "grad_norm": 0.46122244000434875,
      "learning_rate": 6.609847508037203e-06,
      "loss": 0.0203,
      "step": 101000
    },
    {
      "epoch": 6.951798115932063,
      "grad_norm": 0.1264268457889557,
      "learning_rate": 6.566867811645779e-06,
      "loss": 0.0206,
      "step": 101100
    },
    {
      "epoch": 6.958674276284123,
      "grad_norm": 0.25009429454803467,
      "learning_rate": 6.5238881152543535e-06,
      "loss": 0.0204,
      "step": 101200
    },
    {
      "epoch": 6.965550436636183,
      "grad_norm": 0.24896341562271118,
      "learning_rate": 6.48090841886293e-06,
      "loss": 0.0235,
      "step": 101300
    },
    {
      "epoch": 6.9724265969882415,
      "grad_norm": 0.22611315548419952,
      "learning_rate": 6.437928722471505e-06,
      "loss": 0.0217,
      "step": 101400
    },
    {
      "epoch": 6.979302757340301,
      "grad_norm": 0.22629566490650177,
      "learning_rate": 6.395378823043995e-06,
      "loss": 0.0201,
      "step": 101500
    },
    {
      "epoch": 6.98617891769236,
      "grad_norm": 0.24626560509204865,
      "learning_rate": 6.352399126652569e-06,
      "loss": 0.0212,
      "step": 101600
    },
    {
      "epoch": 6.99305507804442,
      "grad_norm": 0.10641992092132568,
      "learning_rate": 6.309419430261144e-06,
      "loss": 0.0212,
      "step": 101700
    },
    {
      "epoch": 6.99993123839648,
      "grad_norm": 0.265617698431015,
      "learning_rate": 6.266439733869721e-06,
      "loss": 0.02,
      "step": 101800
    },
    {
      "epoch": 7.0,
      "eval_accuracy_macro_0.5": 0.9893024563789368,
      "eval_accuracy_micro_0.5": 0.9893024563789368,
      "eval_accuracy_weighted_0.5": 0.9877306222915649,
      "eval_f1_macro_0.5": 0.8681378364562988,
      "eval_f1_macro_0.6": 0.8647153377532959,
      "eval_f1_macro_0.7": 0.8537989854812622,
      "eval_f1_macro_0.8": 0.7782591581344604,
      "eval_f1_micro_0.5": 0.8638840913772583,
      "eval_f1_micro_0.6": 0.8616219162940979,
      "eval_f1_micro_0.7": 0.85139000415802,
      "eval_f1_micro_0.8": 0.830488383769989,
      "eval_f1_micro_0.9": 0.7793546915054321,
      "eval_f1_weighted_0.5": 0.8629751205444336,
      "eval_f1_weighted_0.6": 0.8592805862426758,
      "eval_f1_weighted_0.7": 0.8471388816833496,
      "eval_f1_weighted_0.8": 0.765220046043396,
      "eval_loss": 0.021929381415247917,
      "eval_runtime": 440.9142,
      "eval_samples_per_second": 65.856,
      "eval_steps_per_second": 8.233,
      "step": 101801
    }
  ],
  "logging_steps": 100,
  "max_steps": 116344,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.632341695912557e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
