{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "c7e0viLwhWR_",
        "outputId": "b2e667c3-add2-425a-9ea3-2eee22da95f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/VINITI_Text_Classification/datasets"
      ],
      "metadata": {
        "id": "VJfz7wUfje5O"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ."
      ],
      "metadata": {
        "id": "9xv5rMr8jJyx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -b model_testing"
      ],
      "metadata": {
        "id": "wp50kjPDjQOk",
        "outputId": "3b6a74b1-b831-4af3-83c8-87641d7f8120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Switched to a new branch 'model_testing'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"goralex02@yandex.ru\""
      ],
      "metadata": {
        "id": "7zy9pTerjuBj"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"goralex02\""
      ],
      "metadata": {
        "id": "EH2bOK0NjzGV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"initial commit\""
      ],
      "metadata": {
        "id": "REH6Chlfjo-A",
        "outputId": "19c1502e-15cb-461f-efe4-27181b88244b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[model_testing 13ec6fd] initial commit\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1231223"
      ],
      "metadata": {
        "id": "fI0PWdWgkj9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push https://goralex02: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@github.com/vvzunin/VINITI_Text_Classification.git model_testing"
      ],
      "metadata": {
        "id": "ERiLFcSdkcta",
        "outputId": "2ac00566-f947-49f0-f998-faeed52063a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 7, done.\n",
            "Counting objects:  14% (1/7)\rCounting objects:  28% (2/7)\rCounting objects:  42% (3/7)\rCounting objects:  57% (4/7)\rCounting objects:  71% (5/7)\rCounting objects:  85% (6/7)\rCounting objects: 100% (7/7)\rCounting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:  25% (1/4)\rCompressing objects:  50% (2/4)\rCompressing objects:  75% (3/4)\rCompressing objects: 100% (4/4)\rCompressing objects: 100% (4/4), done.\n",
            "Writing objects:  25% (1/4)\rWriting objects:  50% (2/4)\rWriting objects:  75% (3/4)\rWriting objects: 100% (4/4)\rWriting objects: 100% (4/4), 358 bytes | 358.00 KiB/s, done.\n",
            "Total 4 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/vvzunin/VINITI_Text_Classification.git\n",
            "   131caa9..13ec6fd  model_testing -> model_testing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push https://<username>:<token>@github.com/<username>/<repository>.git <branch_name>"
      ],
      "metadata": {
        "id": "9pt_h6Iykd5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push --set-upstream origin model_testing"
      ],
      "metadata": {
        "id": "1IxhRgtlj38x",
        "outputId": "8af6bdd4-24ed-48cf-ede4-53d8c8e413b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 59, done.\n",
            "Counting objects:   1% (1/57)\rCounting objects:   3% (2/57)\rCounting objects:   5% (3/57)\rCounting objects:   7% (4/57)\rCounting objects:   8% (5/57)\rCounting objects:  10% (6/57)\rCounting objects:  12% (7/57)\rCounting objects:  14% (8/57)\rCounting objects:  15% (9/57)\rCounting objects:  17% (10/57)\rCounting objects:  19% (11/57)\rCounting objects:  21% (12/57)\rCounting objects:  22% (13/57)\rCounting objects:  24% (14/57)\rCounting objects:  26% (15/57)\rCounting objects:  28% (16/57)\rCounting objects:  29% (17/57)\rCounting objects:  31% (18/57)\rCounting objects:  33% (19/57)\rCounting objects:  35% (20/57)\rCounting objects:  36% (21/57)\rCounting objects:  38% (22/57)\rCounting objects:  40% (23/57)\rCounting objects:  42% (24/57)\rCounting objects:  43% (25/57)\rCounting objects:  45% (26/57)\rCounting objects:  47% (27/57)\rCounting objects:  49% (28/57)\rCounting objects:  50% (29/57)\rCounting objects:  52% (30/57)\rCounting objects:  54% (31/57)\rCounting objects:  56% (32/57)\rCounting objects:  57% (33/57)\rCounting objects:  59% (34/57)\rCounting objects:  61% (35/57)\rCounting objects:  63% (36/57)\rCounting objects:  64% (37/57)\rCounting objects:  66% (38/57)\rCounting objects:  68% (39/57)\rCounting objects:  70% (40/57)\rCounting objects:  71% (41/57)\rCounting objects:  73% (42/57)\rCounting objects:  75% (43/57)\rCounting objects:  77% (44/57)\rCounting objects:  78% (45/57)\rCounting objects:  80% (46/57)\rCounting objects:  82% (47/57)\rCounting objects:  84% (48/57)\rCounting objects:  85% (49/57)\rCounting objects:  87% (50/57)\rCounting objects:  89% (51/57)\rCounting objects:  91% (52/57)\rCounting objects:  92% (53/57)\rCounting objects:  94% (54/57)\rCounting objects:  96% (55/57)\rCounting objects:  98% (56/57)\rCounting objects: 100% (57/57)\rCounting objects: 100% (57/57), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:   5% (1/19)\rCompressing objects:  10% (2/19)\rCompressing objects:  15% (3/19)\rCompressing objects:  21% (4/19)\rCompressing objects:  26% (5/19)\rCompressing objects:  31% (6/19)\rCompressing objects:  36% (7/19)\rCompressing objects:  42% (8/19)\rCompressing objects:  47% (9/19)\rCompressing objects:  52% (10/19)\rCompressing objects:  57% (11/19)\rCompressing objects:  63% (12/19)\rCompressing objects:  68% (13/19)\rCompressing objects:  73% (14/19)\rCompressing objects:  78% (15/19)\rCompressing objects:  84% (16/19)\rCompressing objects:  89% (17/19)\rCompressing objects:  94% (18/19)\rCompressing objects: 100% (19/19)\rCompressing objects: 100% (19/19), done.\n",
            "Writing objects:   2% (1/41)\rWriting objects:   4% (2/41)\rWriting objects:   7% (3/41)\rWriting objects:   9% (4/41)\rWriting objects:  12% (5/41)\rWriting objects:  14% (6/41)\rWriting objects:  17% (7/41)\rWriting objects:  19% (8/41)\rWriting objects:  21% (9/41)\rWriting objects:  24% (10/41)\rWriting objects:  26% (11/41)\rWriting objects:  29% (12/41)\rWriting objects:  31% (13/41)\rWriting objects:  34% (14/41)\rWriting objects:  36% (15/41)\rWriting objects:  46% (19/41)\rWriting objects:  48% (20/41)\rWriting objects:  51% (21/41)\rWriting objects:  56% (23/41)\rWriting objects:  60% (25/41)\rWriting objects:  63% (26/41)\rWriting objects:  68% (28/41)\rWriting objects:  73% (30/41)\rWriting objects:  75% (31/41)\rWriting objects:  80% (33/41)\rWriting objects:  85% (35/41)\rWriting objects:  87% (36/41)\rWriting objects:  92% (38/41)\rWriting objects:  95% (39/41)\rWriting objects:  97% (40/41)\rWriting objects: 100% (41/41)\rWriting objects: 100% (41/41), 154.79 KiB | 77.39 MiB/s, done.\n",
            "Total 41 (delta 28), reused 33 (delta 22), pack-reused 0\n",
            "remote: Resolving deltas: 100% (28/28), completed with 6 local objects.\u001b[K\n",
            "remote: \n",
            "remote: Create a pull request for 'model_testing' on GitHub by visiting:\u001b[K\n",
            "remote:      https://github.com/vvzunin/VINITI_Text_Classification/pull/new/model_testing\u001b[K\n",
            "remote: \n",
            "To https://github.com/vvzunin/VINITI_Text_Classification.git\n",
            " * [new branch]      model_testing -> model_testing\n",
            "Branch 'model_testing' set up to track remote branch 'model_testing' from 'origin'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/datasets /content/VINITI_Text_Classification/"
      ],
      "metadata": {
        "id": "l-uE-7UviGeX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/datasets"
      ],
      "metadata": {
        "id": "SOJcsoKnh5vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/VINITI_Text_Classification"
      ],
      "metadata": {
        "id": "0eTpTjjfh10e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://goralex02: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@github.com/vvzunin/VINITI_Text_Classification.git"
      ],
      "metadata": {
        "id": "b45ewv2I-s9e",
        "outputId": "d7e6aee9-cab0-40b0-a75d-1a6c67ec9bfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VINITI_Text_Classification'...\n",
            "remote: Enumerating objects: 516, done.\u001b[K\n",
            "remote: Counting objects: 100% (126/126), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 516 (delta 78), reused 96 (delta 58), pack-reused 390 (from 1)\u001b[K\n",
            "Receiving objects: 100% (516/516), 45.96 MiB | 7.48 MiB/s, done.\n",
            "Resolving deltas: 100% (208/208), done.\n",
            "Updating files: 100% (159/159), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/VINITI_Text_Classification/src/"
      ],
      "metadata": {
        "id": "EJN_RNNA-0G8",
        "outputId": "c8aae76f-8ad5-4125-da28-7375915d0817",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VINITI_Text_Classification/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics pyignite"
      ],
      "metadata": {
        "id": "PUVJUL_5-4Ra",
        "outputId": "c267b3cf-81ef-4058-9807-f8b4fd0641f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/927.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m921.6/927.3 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.7/145.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "id": "8rT6qh8I_ZJk",
        "outputId": "0908818f-4497-4166-9a5a-eed1aa33d48f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/485.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-ignite\n"
      ],
      "metadata": {
        "id": "qpzi5vyY_kLB",
        "outputId": "c9bf3870-abac-4ece-c5d4-d425f51e194d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.5.1-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: torch<3,>=1.3 in /usr/local/lib/python3.11/dist-packages (from pytorch-ignite) (2.5.1+cu124)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytorch-ignite) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.3->pytorch-ignite) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (3.0.2)\n",
            "Downloading pytorch_ignite-0.5.1-py3-none-any.whl (312 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/312.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m307.2/312.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.7/312.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ignite"
                ]
              },
              "id": "2800e7d028af4c108d749208820038ad"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5EmA8ril-orB"
      },
      "outputs": [],
      "source": [
        "from train import get_grnti1_2_BERT_dataframes, get_grnti1_BERT_dataframes, prepair_datasets,\\\n",
        "prepair_model, prepair_compute_metrics, save_parameters, CustomTrainer, test_predictons,\\\n",
        "prepair_test_dataset, get_grnti1_BERT_dataframes\n",
        "from peft import PeftConfig, PeftModel\n",
        "\n",
        "from prediction import prepair_data_level2\n",
        "from prediction import prepair_model as prepair_model_test\n",
        "from prediction import prepair_dataset, make_predictions\n",
        "from transformers import TrainingArguments\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_wdfJEeF-orC"
      },
      "outputs": [],
      "source": [
        "SEED = 12345\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM3rvJK--orC"
      },
      "source": [
        "### Train level 1 correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iOsmwKYk-orD"
      },
      "outputs": [],
      "source": [
        "def clear_text(text):\n",
        "    # Удалить формулы внутри $$...$$\n",
        "    text = re.sub(r'\\$\\$.*?\\$\\$', '', text, flags=re.DOTALL)\n",
        "    # Удалить формулы внутри $...$\n",
        "    text = re.sub(r'\\$.*?\\$', '', text, flags=re.DOTALL)\n",
        "    # Удалить формулы внутри \\[...\\] или \\(...\\)\n",
        "    text = re.sub(r'\\\\\\[.*?\\\\\\]', '', text, flags=re.DOTALL)\n",
        "    # Удалить окружения формул (\\begin{...}...\\end{...})\n",
        "    text = re.sub(r'\\\\begin\\{.*?\\}.*?\\\\end\\{.*?\\}', '', text, flags=re.DOTALL)\n",
        "    # Ссылки\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    # Удаляем элементы в скобках <>\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    # Перенос строки\n",
        "    text = re.sub('\\n', '', text)\n",
        "    # Число посреди слова\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AZMs6Bwj-orE"
      },
      "outputs": [],
      "source": [
        "max_number_tokens = 512\n",
        "pre_trained_model_name ='cointegrated/rubert-tiny2'\n",
        "r = 16\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nDj4avdQ-orE"
      },
      "outputs": [],
      "source": [
        "base_name = \"alexander_cointegrated_rubert-tiny2/\"\n",
        "number_of_delteted_values = 15\n",
        "minimal_number_of_elements_RGNTI2 = 1\n",
        "minimal_number_of_words = 10\n",
        "\n",
        "path_info_before_save = base_name + f\"data_info_from_bert_level1/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vV6O25Zy-orE"
      },
      "outputs": [],
      "source": [
        "epoch= 16\n",
        "batch_size=8\n",
        "weight_decay = 1e-6\n",
        "warmup_steps = 10\n",
        "fp16 = True\n",
        "optim = \"adamw_bnb_8bit\"\n",
        "dir_name = base_name + f\"model bert lora level 1/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "IBNmkX7C-orE",
        "outputId": "a1bb0b63-2b42-48b6-8d0a-bb88f988a482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../datasets/base/ru/raw/train_ru.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b852b64fcd7f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_info_before_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_info_before_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m df, df_test, n_classes, n_classes2 = get_grnti1_BERT_dataframes(\"../datasets/base/ru/raw\", \n\u001b[0m\u001b[1;32m      4\u001b[0m                                             \u001b[0mnumber_of_delteted_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_delteted_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 \u001b[0mminimal_number_of_elements_RGNTI2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimal_number_of_elements_RGNTI2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/VINITI_Text_Classification/src/train.py\u001b[0m in \u001b[0;36mget_grnti1_BERT_dataframes\u001b[0;34m(file_path, number_of_delteted_values, minimal_number_of_elements_RGNTI2, minimal_number_of_words, dir_name, change_codes, grnti_folder)\u001b[0m\n\u001b[1;32m     33\u001b[0m                                  grnti_folder = \"\"):\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/train_ru.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cp1251'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RGNTI'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\d+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Пропускаем строки без класса\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/test_ru.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cp1251'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'skip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#error_bad_lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datasets/base/ru/raw/train_ru.csv'"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(path_info_before_save):\n",
        "    os.makedirs(path_info_before_save)\n",
        "df, df_test, n_classes, n_classes2 = get_grnti1_BERT_dataframes(\"../datasets/base/ru/raw\",\n",
        "                                            number_of_delteted_values=number_of_delteted_values,\n",
        "                                minimal_number_of_elements_RGNTI2=minimal_number_of_elements_RGNTI2,\n",
        "                                minimal_number_of_words=minimal_number_of_words,\n",
        "                                dir_name=path_info_before_save, grnti_folder=\"grnti_dicts_level1_v2/\",\n",
        "                                change_codes=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ATzWprM-orE",
        "outputId": "78380830-70bc-48c8-b693-715f62571632"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(285159, 13)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfjPlCDX-orF",
        "outputId": "caaccbb3-3e0b-4872-e629-13102081629e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "n_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8CQLYdw-orF"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcSIkfB2-orF"
      },
      "outputs": [],
      "source": [
        "# target_count = pd.Series((np.concatenate(df['target'].values))).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHwgivrL-orF"
      },
      "outputs": [],
      "source": [
        "# target_count.values/ sum(target_count.values).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CKoCava-orF",
        "outputId": "6be1b399-1d1e-40b9-82f6-b407adafa19c",
        "colab": {
          "referenced_widgets": [
            "d5f57a915cc744768ba52a9c3b5f065f"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5f57a915cc744768ba52a9c3b5f065f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/285159 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df['text'] = df['text'].progress_apply(clear_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DIql3px-orF",
        "outputId": "1bc02b12-8d34-40be-a7ad-24893e61b772",
        "colab": {
          "referenced_widgets": [
            "d2d900f82c26491cb7e8100eab9a8228"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2d900f82c26491cb7e8100eab9a8228",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/166183 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_test['text'] = df_test['text'].progress_apply(clear_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wGvQp4J-orG",
        "outputId": "6affacd9-ce44-40d1-fad4-9f8e5405779e",
        "colab": {
          "referenced_widgets": [
            "130c166b0ac94ad38baa43728b6bc135",
            "447a08432ac748398c05ef7d229d5c57",
            "6cc96cac2ea945669e53d5a3e38cf9c9"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Веса для кажого класса:  tensor([1.3164, 1.2443, 1.5663, 0.6472, 3.6027, 0.2040, 3.0185, 1.4897, 3.1646,\n",
            "        0.8802, 1.2860, 2.2852, 0.4165, 0.3968, 1.1249, 0.3536, 1.9390, 0.7354,\n",
            "        1.8193, 0.3115, 0.8897, 0.2691, 0.6810, 0.6133, 0.6533, 0.7356, 2.0284,\n",
            "        0.7524, 1.9058, 3.0932, 1.1319, 3.0083], dtype=torch.float64)\n",
            "Подготовка тренировочных данных:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "130c166b0ac94ad38baa43728b6bc135",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/228152 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Подготовка валидационных данных:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "447a08432ac748398c05ef7d229d5c57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/57007 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Подготовка тестовых данных:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cc96cac2ea945669e53d5a3e38cf9c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/166183 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_dataset, validation_dataset, test_dataset,\\\n",
        "tokenizer, collate_fn, class_weights = prepair_datasets(df, df_test,\n",
        "                                                        n_classes,\n",
        "                                                        level = '',\n",
        "                                                        max_number_tokens=max_number_tokens,\n",
        "                                                        pre_trained_model_name=pre_trained_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQDHhP2h-orG",
        "outputId": "0ed03c2d-92ba-4125-8077-1ac54070fccc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "n_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h_4sBgr-orG",
        "outputId": "df2044fb-b3cf-4c98-f193-4a5fb5351044"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=32, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = prepair_model(n_classes=n_classes,\n",
        "                      pre_trained_model_name=pre_trained_model_name,\n",
        "                        r=r, lora_alpha=lora_alpha,\n",
        "                        lora_dropout=lora_dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH43AWdE-orG"
      },
      "outputs": [],
      "source": [
        "model.to(\"cuda\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-7Pwm8_-orG"
      },
      "outputs": [],
      "source": [
        "save_parameters(dir_name= dir_name,\n",
        "                number_of_delteted_values = number_of_delteted_values,\n",
        "                minimal_number_of_elements_RGNTI2= minimal_number_of_elements_RGNTI2,\n",
        "                minimal_number_of_words = minimal_number_of_words,\n",
        "                max_number_tokens= max_number_tokens,\n",
        "                pre_trained_model_name= pre_trained_model_name,\n",
        "                r=r,\n",
        "                lora_alpha= lora_alpha, lora_dropout = lora_dropout,\n",
        "                epoch= epoch,\n",
        "                batch_size= batch_size,\n",
        "                weight_decay= weight_decay,\n",
        "                warmup_steps= warmup_steps,\n",
        "                fp16=fp16,\n",
        "                optim= optim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IzFPQfw-orG"
      },
      "outputs": [],
      "source": [
        "compute_metrics = prepair_compute_metrics(n_classes=n_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RG5kNqeb-orG"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=dir_name,\n",
        "    num_train_epochs=epoch,\n",
        "    warmup_steps=warmup_steps,\n",
        "    logging_dir=dir_name,\n",
        "    weight_decay=weight_decay,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy= \"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps = 100,\n",
        "    load_best_model_at_end=True,\n",
        "    save_total_limit=2,\n",
        "    report_to='tensorboard',\n",
        "    overwrite_output_dir = False,\n",
        "    save_safetensors = False,\n",
        "    fp16=fp16,\n",
        "    optim = optim,\n",
        "    per_device_train_batch_size= batch_size,\n",
        "    per_device_eval_batch_size= batch_size,\n",
        "    group_by_length=True,\n",
        "    dataloader_num_workers = 4,\n",
        "    metric_for_best_model=\"eval_f1_weighted_0.5\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvPm--XT-orH"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.remove_columns(\"text\")\n",
        "validation_dataset = validation_dataset.remove_columns([\"text\", \"__index_level_0__\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFPKcLhV-orH"
      },
      "outputs": [],
      "source": [
        "# train_dataset = train_dataset.remove_columns(\"text\")\n",
        "# validation_dataset = train_dataset.remove_columns([\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2w5j0Go-orH"
      },
      "outputs": [],
      "source": [
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    data_collator = collate_fn,\n",
        "    tokenizer = tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    class_weights=class_weights,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZx1riXj-orH",
        "outputId": "bf3181b0-8fc1-4cec-a819-63b6db955f62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "     num_rows: 228152\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "     num_rows: 57007\n",
              " }))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_dataset, validation_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgJjuevJ-orH",
        "outputId": "8b8f0a4f-e84e-4b98-f3d4-a5fef27b52dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.3164, 1.2443, 1.5663, 0.6472, 3.6027, 0.2040, 3.0185, 1.4897, 3.1646,\n",
              "        0.8802, 1.2860, 2.2852, 0.4165, 0.3968, 1.1249, 0.3536, 1.9390, 0.7354,\n",
              "        1.8193, 0.3115, 0.8897, 0.2691, 0.6810, 0.6133, 0.6533, 0.7356, 2.0284,\n",
              "        0.7524, 1.9058, 3.0932, 1.1319, 3.0083], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwh9vDu4-orH",
        "outputId": "174a2985-a58a-41fd-8069-b73176e47bf0",
        "colab": {
          "referenced_widgets": [
            "5967fbae087c4276acc22918e8138eab"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5967fbae087c4276acc22918e8138eab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/456304 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\victo\\git_Work_VINITI_2024\\my_venv_cuda\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3068, 'grad_norm': 0.20824149250984192, 'learning_rate': 4.999013793738248e-05, 'epoch': 0.0}\n",
            "{'loss': 0.1372, 'grad_norm': 0.2998579442501068, 'learning_rate': 4.997918009002968e-05, 'epoch': 0.01}\n",
            "{'loss': 0.1442, 'grad_norm': 0.3274669647216797, 'learning_rate': 4.996822224267687e-05, 'epoch': 0.01}\n",
            "{'loss': 0.1421, 'grad_norm': 0.43005266785621643, 'learning_rate': 4.995726439532407e-05, 'epoch': 0.01}\n",
            "{'loss': 0.1437, 'grad_norm': 0.2345583140850067, 'learning_rate': 4.9946306547971265e-05, 'epoch': 0.02}\n",
            "{'loss': 0.1384, 'grad_norm': 0.48987090587615967, 'learning_rate': 4.9935348700618465e-05, 'epoch': 0.02}\n",
            "{'loss': 0.1362, 'grad_norm': 0.22708456218242645, 'learning_rate': 4.9924390853265665e-05, 'epoch': 0.02}\n",
            "{'loss': 0.1411, 'grad_norm': 0.33843299746513367, 'learning_rate': 4.991343300591286e-05, 'epoch': 0.03}\n",
            "{'loss': 0.1401, 'grad_norm': 0.3988945484161377, 'learning_rate': 4.990247515856005e-05, 'epoch': 0.03}\n",
            "{'loss': 0.1533, 'grad_norm': 0.35992690920829773, 'learning_rate': 4.9891517311207245e-05, 'epoch': 0.04}\n",
            "{'loss': 0.1491, 'grad_norm': 0.5430982708930969, 'learning_rate': 4.9880559463854445e-05, 'epoch': 0.04}\n",
            "{'loss': 0.1417, 'grad_norm': 0.23481817543506622, 'learning_rate': 4.9869601616501645e-05, 'epoch': 0.04}\n",
            "{'loss': 0.145, 'grad_norm': 0.24959544837474823, 'learning_rate': 4.985864376914884e-05, 'epoch': 0.05}\n",
            "{'loss': 0.1448, 'grad_norm': 0.42085233330726624, 'learning_rate': 4.984768592179604e-05, 'epoch': 0.05}\n",
            "{'loss': 0.1431, 'grad_norm': 0.37311986088752747, 'learning_rate': 4.983672807444323e-05, 'epoch': 0.05}\n",
            "{'loss': 0.1461, 'grad_norm': 0.38239896297454834, 'learning_rate': 4.982577022709043e-05, 'epoch': 0.06}\n",
            "{'loss': 0.1462, 'grad_norm': 0.44762513041496277, 'learning_rate': 4.981481237973763e-05, 'epoch': 0.06}\n",
            "{'loss': 0.1413, 'grad_norm': 0.5336182713508606, 'learning_rate': 4.9803854532384826e-05, 'epoch': 0.06}\n",
            "{'loss': 0.1341, 'grad_norm': 0.4403776228427887, 'learning_rate': 4.979289668503202e-05, 'epoch': 0.07}\n",
            "{'loss': 0.1402, 'grad_norm': 0.49675437808036804, 'learning_rate': 4.978193883767922e-05, 'epoch': 0.07}\n",
            "{'loss': 0.1367, 'grad_norm': 0.38153862953186035, 'learning_rate': 4.977098099032641e-05, 'epoch': 0.07}\n",
            "{'loss': 0.1467, 'grad_norm': 0.47480425238609314, 'learning_rate': 4.976002314297361e-05, 'epoch': 0.08}\n",
            "{'loss': 0.1439, 'grad_norm': 0.5219434499740601, 'learning_rate': 4.9749065295620806e-05, 'epoch': 0.08}\n",
            "{'loss': 0.1457, 'grad_norm': 0.27784463763237, 'learning_rate': 4.9738107448268006e-05, 'epoch': 0.08}\n",
            "{'loss': 0.14, 'grad_norm': 0.24269066751003265, 'learning_rate': 4.97271496009152e-05, 'epoch': 0.09}\n",
            "{'loss': 0.1506, 'grad_norm': 0.37668755650520325, 'learning_rate': 4.97161917535624e-05, 'epoch': 0.09}\n"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Xg4ADsT-orH"
      },
      "outputs": [],
      "source": [
        "trainer.model.save_pretrained(dir_name + \"bert_peft_level1_no_lora\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWfn0MgK-orH"
      },
      "outputs": [],
      "source": [
        "# trainer.save_model(\"bert_peft_level1_v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXTlun0J-orI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xcaTArJ-orI"
      },
      "source": [
        "### Тest level 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSgscLCs-orI"
      },
      "outputs": [],
      "source": [
        "test_dataset = test_dataset.remove_columns([\"text\", \"__index_level_0__\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYGMgTmr-orI",
        "outputId": "5c3e2856-b66c-4fc6-90ad-3314fe268b26",
        "colab": {
          "referenced_widgets": [
            "c8106d1f2734498993e43968db46530c"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8106d1f2734498993e43968db46530c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20773 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "predict_res = trainer.predict(test_dataset=test_dataset).predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqCqicHX-orI"
      },
      "outputs": [],
      "source": [
        "with open(dir_name + \"trainer_predictions_level1_no_lora.npy\", 'wb') as f:\n",
        "    np.save(f, predict_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBUYyaMv-orI"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "with open(dir_name + \"trainer_predictions_level1_no_lora.npy\", 'rb') as f:\n",
        "\n",
        "    prediction1_experiment = np.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-62yIEBF-orI"
      },
      "outputs": [],
      "source": [
        "def sigmoid_array(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsnDQjaO-orJ"
      },
      "outputs": [],
      "source": [
        "label_test = np.vstack(df_test[\"target_coded\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCMXrQRs-orJ",
        "outputId": "c3320b1e-7664-4c04-f052-155cafb99516"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [00:30<00:00,  1.67s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cтатистика количества пркдсказываемых классов при заданном threshold:\n",
            "Среднее число предсказываемых классов для одной статьи, для которой получено предсказание tensor(1.3064)\n",
            "Минимальное число предсказываемых классов для одной статьи, для которой получено предсказание tensor(1)\n",
            "Максимальное число предсказываемых классов для одной статьи, для которой получено предсказание tensor(7)\n",
            "Доля статей c пустым ответом классификатора (Empty): 0.039763393367552635\n",
            "recall_micro_list threshold: [tensor(0.9242), tensor(0.9018), tensor(0.8821), tensor(0.8629), tensor(0.8449), tensor(0.8268), tensor(0.8088), tensor(0.7910), tensor(0.7728), tensor(0.7538), tensor(0.7335), tensor(0.7102), tensor(0.6843), tensor(0.6551), tensor(0.6200), tensor(0.5740), tensor(0.5092), tensor(0.3970)]\n",
            "recall_macro_list threshold: [tensor(0.9141), tensor(0.8916), tensor(0.8723), tensor(0.8540), tensor(0.8370), tensor(0.8199), tensor(0.8030), tensor(0.7862), tensor(0.7693), tensor(0.7516), tensor(0.7331), tensor(0.7112), tensor(0.6878), tensor(0.6609), tensor(0.6291), tensor(0.5872), tensor(0.5294), tensor(0.4337)]\n",
            "recall_wighted_list threshold: [tensor(0.9242), tensor(0.9018), tensor(0.8821), tensor(0.8629), tensor(0.8449), tensor(0.8268), tensor(0.8088), tensor(0.7910), tensor(0.7728), tensor(0.7538), tensor(0.7335), tensor(0.7102), tensor(0.6843), tensor(0.6551), tensor(0.6200), tensor(0.5740), tensor(0.5092), tensor(0.3970)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [00:00<00:00, 91.03it/s]\n",
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "100%|██████████| 3/3 [00:06<00:00,  2.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество отказов от классификации (Reject) tensor(0)\n",
            "Доля отказов от классификации (Reject) tensor(0.)\n",
            "f1_top_k_macro [0.73 0.69 0.59]\n",
            "f1_top_k_maicro [0.76 0.68 0.56]\n",
            "f1_top_k_weighted [0.74 0.69 0.59]\n",
            "precision_top_k_macro [0.85 0.59 0.45]\n",
            "precision_top_k_maicro [0.87 0.56 0.4 ]\n",
            "precision_top_k_weighted [0.86 0.58 0.44]\n",
            "recall_top_k_macro: tensor([0.6724, 0.8581, 0.9210])\n",
            "recall_top_k_micro: tensor([0.6710, 0.8686, 0.9309])\n",
            "recall_top_k_weighted: tensor([0.6710, 0.8686, 0.9309])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_predictons(sigmoid_array(prediction1_experiment), label_test, path_info_before_save, 36,\n",
        "                level=1,\n",
        "                grnti_path=\"grnti_dicts_level1/\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}