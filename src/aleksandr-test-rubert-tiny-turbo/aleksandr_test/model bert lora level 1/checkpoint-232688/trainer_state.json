{
  "best_metric": 0.7244248390197754,
  "best_model_checkpoint": "aleksandr_test/model bert lora level 1/checkpoint-232688",
  "epoch": 16.0,
  "eval_steps": 500,
  "global_step": 232688,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00687616035205941,
      "grad_norm": 0.14245177805423737,
      "learning_rate": 4.998065996785257e-05,
      "loss": 0.1312,
      "step": 100
    },
    {
      "epoch": 0.01375232070411882,
      "grad_norm": 0.14233900606632233,
      "learning_rate": 4.995917104324431e-05,
      "loss": 0.1311,
      "step": 200
    },
    {
      "epoch": 0.02062848105617823,
      "grad_norm": 0.1379518210887909,
      "learning_rate": 4.993768211863606e-05,
      "loss": 0.1275,
      "step": 300
    },
    {
      "epoch": 0.02750464140823764,
      "grad_norm": 0.1451869159936905,
      "learning_rate": 4.99161931940278e-05,
      "loss": 0.126,
      "step": 400
    },
    {
      "epoch": 0.03438080176029705,
      "grad_norm": 0.12502595782279968,
      "learning_rate": 4.989470426941954e-05,
      "loss": 0.1214,
      "step": 500
    },
    {
      "epoch": 0.04125696211235646,
      "grad_norm": 0.11411546915769577,
      "learning_rate": 4.987321534481129e-05,
      "loss": 0.1221,
      "step": 600
    },
    {
      "epoch": 0.04813312246441587,
      "grad_norm": 0.12971466779708862,
      "learning_rate": 4.985172642020303e-05,
      "loss": 0.1208,
      "step": 700
    },
    {
      "epoch": 0.05500928281647528,
      "grad_norm": 0.13217681646347046,
      "learning_rate": 4.983023749559477e-05,
      "loss": 0.1156,
      "step": 800
    },
    {
      "epoch": 0.06188544316853469,
      "grad_norm": 0.10598713159561157,
      "learning_rate": 4.980874857098652e-05,
      "loss": 0.1143,
      "step": 900
    },
    {
      "epoch": 0.0687616035205941,
      "grad_norm": 0.15486884117126465,
      "learning_rate": 4.978725964637826e-05,
      "loss": 0.1118,
      "step": 1000
    },
    {
      "epoch": 0.07563776387265352,
      "grad_norm": 0.18916268646717072,
      "learning_rate": 4.9765770721769997e-05,
      "loss": 0.112,
      "step": 1100
    },
    {
      "epoch": 0.08251392422471292,
      "grad_norm": 0.15045525133609772,
      "learning_rate": 4.974428179716175e-05,
      "loss": 0.1081,
      "step": 1200
    },
    {
      "epoch": 0.08939008457677233,
      "grad_norm": 0.14763975143432617,
      "learning_rate": 4.972279287255348e-05,
      "loss": 0.1088,
      "step": 1300
    },
    {
      "epoch": 0.09626624492883173,
      "grad_norm": 0.12695638835430145,
      "learning_rate": 4.970130394794523e-05,
      "loss": 0.1064,
      "step": 1400
    },
    {
      "epoch": 0.10314240528089115,
      "grad_norm": 0.12130734324455261,
      "learning_rate": 4.967981502333697e-05,
      "loss": 0.1035,
      "step": 1500
    },
    {
      "epoch": 0.11001856563295057,
      "grad_norm": 0.14720547199249268,
      "learning_rate": 4.965832609872872e-05,
      "loss": 0.1006,
      "step": 1600
    },
    {
      "epoch": 0.11689472598500997,
      "grad_norm": 0.12178587168455124,
      "learning_rate": 4.9636837174120457e-05,
      "loss": 0.1018,
      "step": 1700
    },
    {
      "epoch": 0.12377088633706938,
      "grad_norm": 0.1431836634874344,
      "learning_rate": 4.961534824951221e-05,
      "loss": 0.1006,
      "step": 1800
    },
    {
      "epoch": 0.1306470466891288,
      "grad_norm": 0.1497138887643814,
      "learning_rate": 4.959385932490394e-05,
      "loss": 0.0963,
      "step": 1900
    },
    {
      "epoch": 0.1375232070411882,
      "grad_norm": 0.11985687166452408,
      "learning_rate": 4.9572370400295693e-05,
      "loss": 0.0954,
      "step": 2000
    },
    {
      "epoch": 0.1443993673932476,
      "grad_norm": 0.1718652993440628,
      "learning_rate": 4.955088147568743e-05,
      "loss": 0.0938,
      "step": 2100
    },
    {
      "epoch": 0.15127552774530703,
      "grad_norm": 0.12000565975904465,
      "learning_rate": 4.952939255107917e-05,
      "loss": 0.0924,
      "step": 2200
    },
    {
      "epoch": 0.15815168809736643,
      "grad_norm": 0.15812304615974426,
      "learning_rate": 4.950790362647092e-05,
      "loss": 0.095,
      "step": 2300
    },
    {
      "epoch": 0.16502784844942583,
      "grad_norm": 0.13185207545757294,
      "learning_rate": 4.948641470186266e-05,
      "loss": 0.0932,
      "step": 2400
    },
    {
      "epoch": 0.17190400880148526,
      "grad_norm": 0.11893412470817566,
      "learning_rate": 4.94649257772544e-05,
      "loss": 0.0887,
      "step": 2500
    },
    {
      "epoch": 0.17878016915354467,
      "grad_norm": 0.15785780549049377,
      "learning_rate": 4.944343685264615e-05,
      "loss": 0.0933,
      "step": 2600
    },
    {
      "epoch": 0.18565632950560407,
      "grad_norm": 0.1553335040807724,
      "learning_rate": 4.942194792803789e-05,
      "loss": 0.09,
      "step": 2700
    },
    {
      "epoch": 0.19253248985766347,
      "grad_norm": 0.1120338961482048,
      "learning_rate": 4.940045900342963e-05,
      "loss": 0.0888,
      "step": 2800
    },
    {
      "epoch": 0.1994086502097229,
      "grad_norm": 0.15688596665859222,
      "learning_rate": 4.937897007882138e-05,
      "loss": 0.087,
      "step": 2900
    },
    {
      "epoch": 0.2062848105617823,
      "grad_norm": 0.11618169397115707,
      "learning_rate": 4.935748115421312e-05,
      "loss": 0.0888,
      "step": 3000
    },
    {
      "epoch": 0.2131609709138417,
      "grad_norm": 0.1816655695438385,
      "learning_rate": 4.933599222960486e-05,
      "loss": 0.0892,
      "step": 3100
    },
    {
      "epoch": 0.22003713126590113,
      "grad_norm": 0.13431274890899658,
      "learning_rate": 4.931450330499661e-05,
      "loss": 0.0896,
      "step": 3200
    },
    {
      "epoch": 0.22691329161796053,
      "grad_norm": 0.17057892680168152,
      "learning_rate": 4.929301438038835e-05,
      "loss": 0.0852,
      "step": 3300
    },
    {
      "epoch": 0.23378945197001993,
      "grad_norm": 0.1777985543012619,
      "learning_rate": 4.927152545578009e-05,
      "loss": 0.0869,
      "step": 3400
    },
    {
      "epoch": 0.24066561232207936,
      "grad_norm": 0.12038704752922058,
      "learning_rate": 4.925003653117184e-05,
      "loss": 0.0853,
      "step": 3500
    },
    {
      "epoch": 0.24754177267413877,
      "grad_norm": 0.26965951919555664,
      "learning_rate": 4.922854760656358e-05,
      "loss": 0.0853,
      "step": 3600
    },
    {
      "epoch": 0.2544179330261982,
      "grad_norm": 0.16828389465808868,
      "learning_rate": 4.920705868195532e-05,
      "loss": 0.0827,
      "step": 3700
    },
    {
      "epoch": 0.2612940933782576,
      "grad_norm": 0.1566825807094574,
      "learning_rate": 4.918556975734707e-05,
      "loss": 0.0843,
      "step": 3800
    },
    {
      "epoch": 0.268170253730317,
      "grad_norm": 0.17712725698947906,
      "learning_rate": 4.916408083273881e-05,
      "loss": 0.0853,
      "step": 3900
    },
    {
      "epoch": 0.2750464140823764,
      "grad_norm": 0.14096978306770325,
      "learning_rate": 4.914259190813055e-05,
      "loss": 0.0813,
      "step": 4000
    },
    {
      "epoch": 0.2819225744344358,
      "grad_norm": 0.13010674715042114,
      "learning_rate": 4.91211029835223e-05,
      "loss": 0.0816,
      "step": 4100
    },
    {
      "epoch": 0.2887987347864952,
      "grad_norm": 0.15538202226161957,
      "learning_rate": 4.909961405891404e-05,
      "loss": 0.0798,
      "step": 4200
    },
    {
      "epoch": 0.2956748951385546,
      "grad_norm": 0.18912574648857117,
      "learning_rate": 4.907812513430578e-05,
      "loss": 0.0801,
      "step": 4300
    },
    {
      "epoch": 0.30255105549061406,
      "grad_norm": 0.15182697772979736,
      "learning_rate": 4.905663620969753e-05,
      "loss": 0.0783,
      "step": 4400
    },
    {
      "epoch": 0.30942721584267346,
      "grad_norm": 0.11915576457977295,
      "learning_rate": 4.903514728508927e-05,
      "loss": 0.08,
      "step": 4500
    },
    {
      "epoch": 0.31630337619473287,
      "grad_norm": 0.1596294790506363,
      "learning_rate": 4.901365836048101e-05,
      "loss": 0.0786,
      "step": 4600
    },
    {
      "epoch": 0.32317953654679227,
      "grad_norm": 0.12052798271179199,
      "learning_rate": 4.899216943587276e-05,
      "loss": 0.0786,
      "step": 4700
    },
    {
      "epoch": 0.33005569689885167,
      "grad_norm": 0.12792029976844788,
      "learning_rate": 4.897068051126449e-05,
      "loss": 0.0789,
      "step": 4800
    },
    {
      "epoch": 0.33693185725091107,
      "grad_norm": 0.13296008110046387,
      "learning_rate": 4.894919158665624e-05,
      "loss": 0.0791,
      "step": 4900
    },
    {
      "epoch": 0.34380801760297053,
      "grad_norm": 0.1749974936246872,
      "learning_rate": 4.892770266204798e-05,
      "loss": 0.0775,
      "step": 5000
    },
    {
      "epoch": 0.35068417795502993,
      "grad_norm": 0.13961189985275269,
      "learning_rate": 4.890621373743973e-05,
      "loss": 0.0772,
      "step": 5100
    },
    {
      "epoch": 0.35756033830708933,
      "grad_norm": 0.1263960599899292,
      "learning_rate": 4.8884724812831467e-05,
      "loss": 0.0777,
      "step": 5200
    },
    {
      "epoch": 0.36443649865914873,
      "grad_norm": 0.1280885934829712,
      "learning_rate": 4.886323588822322e-05,
      "loss": 0.0781,
      "step": 5300
    },
    {
      "epoch": 0.37131265901120813,
      "grad_norm": 0.14357005059719086,
      "learning_rate": 4.884174696361495e-05,
      "loss": 0.0779,
      "step": 5400
    },
    {
      "epoch": 0.37818881936326754,
      "grad_norm": 0.17073622345924377,
      "learning_rate": 4.88202580390067e-05,
      "loss": 0.0762,
      "step": 5500
    },
    {
      "epoch": 0.38506497971532694,
      "grad_norm": 0.14909063279628754,
      "learning_rate": 4.879876911439844e-05,
      "loss": 0.0754,
      "step": 5600
    },
    {
      "epoch": 0.3919411400673864,
      "grad_norm": 0.1109931468963623,
      "learning_rate": 4.877728018979018e-05,
      "loss": 0.0747,
      "step": 5700
    },
    {
      "epoch": 0.3988173004194458,
      "grad_norm": 0.18208350241184235,
      "learning_rate": 4.8755791265181927e-05,
      "loss": 0.0794,
      "step": 5800
    },
    {
      "epoch": 0.4056934607715052,
      "grad_norm": 0.1337856650352478,
      "learning_rate": 4.873430234057367e-05,
      "loss": 0.0782,
      "step": 5900
    },
    {
      "epoch": 0.4125696211235646,
      "grad_norm": 0.12421585619449615,
      "learning_rate": 4.871281341596541e-05,
      "loss": 0.0758,
      "step": 6000
    },
    {
      "epoch": 0.419445781475624,
      "grad_norm": 0.12754632532596588,
      "learning_rate": 4.8691324491357157e-05,
      "loss": 0.0734,
      "step": 6100
    },
    {
      "epoch": 0.4263219418276834,
      "grad_norm": 0.1102571114897728,
      "learning_rate": 4.86698355667489e-05,
      "loss": 0.0729,
      "step": 6200
    },
    {
      "epoch": 0.4331981021797428,
      "grad_norm": 0.1453288495540619,
      "learning_rate": 4.864834664214064e-05,
      "loss": 0.0722,
      "step": 6300
    },
    {
      "epoch": 0.44007426253180226,
      "grad_norm": 0.13295875489711761,
      "learning_rate": 4.8626857717532387e-05,
      "loss": 0.0737,
      "step": 6400
    },
    {
      "epoch": 0.44695042288386166,
      "grad_norm": 0.18449483811855316,
      "learning_rate": 4.860536879292413e-05,
      "loss": 0.0732,
      "step": 6500
    },
    {
      "epoch": 0.45382658323592107,
      "grad_norm": 0.12199516594409943,
      "learning_rate": 4.858387986831587e-05,
      "loss": 0.074,
      "step": 6600
    },
    {
      "epoch": 0.46070274358798047,
      "grad_norm": 0.13691593706607819,
      "learning_rate": 4.8562390943707617e-05,
      "loss": 0.0735,
      "step": 6700
    },
    {
      "epoch": 0.46757890394003987,
      "grad_norm": 0.22361136972904205,
      "learning_rate": 4.854090201909936e-05,
      "loss": 0.076,
      "step": 6800
    },
    {
      "epoch": 0.47445506429209927,
      "grad_norm": 0.15251563489437103,
      "learning_rate": 4.85194130944911e-05,
      "loss": 0.0738,
      "step": 6900
    },
    {
      "epoch": 0.48133122464415873,
      "grad_norm": 0.1591244488954544,
      "learning_rate": 4.8497924169882847e-05,
      "loss": 0.0724,
      "step": 7000
    },
    {
      "epoch": 0.48820738499621813,
      "grad_norm": 0.13747648894786835,
      "learning_rate": 4.847643524527459e-05,
      "loss": 0.071,
      "step": 7100
    },
    {
      "epoch": 0.49508354534827753,
      "grad_norm": 0.19359247386455536,
      "learning_rate": 4.845494632066633e-05,
      "loss": 0.0721,
      "step": 7200
    },
    {
      "epoch": 0.5019597057003369,
      "grad_norm": 0.13430412113666534,
      "learning_rate": 4.8433457396058077e-05,
      "loss": 0.0704,
      "step": 7300
    },
    {
      "epoch": 0.5088358660523964,
      "grad_norm": 0.1726778745651245,
      "learning_rate": 4.841196847144981e-05,
      "loss": 0.0706,
      "step": 7400
    },
    {
      "epoch": 0.5157120264044558,
      "grad_norm": 0.17104879021644592,
      "learning_rate": 4.839047954684156e-05,
      "loss": 0.0702,
      "step": 7500
    },
    {
      "epoch": 0.5225881867565152,
      "grad_norm": 0.11830586940050125,
      "learning_rate": 4.83689906222333e-05,
      "loss": 0.0741,
      "step": 7600
    },
    {
      "epoch": 0.5294643471085746,
      "grad_norm": 0.2057632952928543,
      "learning_rate": 4.834750169762505e-05,
      "loss": 0.0723,
      "step": 7700
    },
    {
      "epoch": 0.536340507460634,
      "grad_norm": 0.12151633203029633,
      "learning_rate": 4.8326012773016786e-05,
      "loss": 0.0741,
      "step": 7800
    },
    {
      "epoch": 0.5432166678126934,
      "grad_norm": 0.1261398047208786,
      "learning_rate": 4.8304523848408537e-05,
      "loss": 0.0714,
      "step": 7900
    },
    {
      "epoch": 0.5500928281647528,
      "grad_norm": 0.18375077843666077,
      "learning_rate": 4.828303492380027e-05,
      "loss": 0.0699,
      "step": 8000
    },
    {
      "epoch": 0.5569689885168122,
      "grad_norm": 0.12201228737831116,
      "learning_rate": 4.826154599919202e-05,
      "loss": 0.0689,
      "step": 8100
    },
    {
      "epoch": 0.5638451488688716,
      "grad_norm": 0.16694237291812897,
      "learning_rate": 4.824005707458376e-05,
      "loss": 0.0707,
      "step": 8200
    },
    {
      "epoch": 0.570721309220931,
      "grad_norm": 0.18223343789577484,
      "learning_rate": 4.821856814997551e-05,
      "loss": 0.0709,
      "step": 8300
    },
    {
      "epoch": 0.5775974695729904,
      "grad_norm": 0.17764435708522797,
      "learning_rate": 4.8197079225367246e-05,
      "loss": 0.0699,
      "step": 8400
    },
    {
      "epoch": 0.5844736299250498,
      "grad_norm": 0.14582222700119019,
      "learning_rate": 4.8175590300758997e-05,
      "loss": 0.0724,
      "step": 8500
    },
    {
      "epoch": 0.5913497902771092,
      "grad_norm": 0.11432255804538727,
      "learning_rate": 4.815410137615073e-05,
      "loss": 0.0711,
      "step": 8600
    },
    {
      "epoch": 0.5982259506291687,
      "grad_norm": 0.10560883581638336,
      "learning_rate": 4.8132612451542476e-05,
      "loss": 0.0687,
      "step": 8700
    },
    {
      "epoch": 0.6051021109812281,
      "grad_norm": 0.16819460690021515,
      "learning_rate": 4.811112352693422e-05,
      "loss": 0.0693,
      "step": 8800
    },
    {
      "epoch": 0.6119782713332875,
      "grad_norm": 0.13893379271030426,
      "learning_rate": 4.808963460232596e-05,
      "loss": 0.0711,
      "step": 8900
    },
    {
      "epoch": 0.6188544316853469,
      "grad_norm": 0.15368762612342834,
      "learning_rate": 4.8068145677717706e-05,
      "loss": 0.069,
      "step": 9000
    },
    {
      "epoch": 0.6257305920374063,
      "grad_norm": 0.21082359552383423,
      "learning_rate": 4.804665675310945e-05,
      "loss": 0.0697,
      "step": 9100
    },
    {
      "epoch": 0.6326067523894657,
      "grad_norm": 0.13193482160568237,
      "learning_rate": 4.802516782850119e-05,
      "loss": 0.071,
      "step": 9200
    },
    {
      "epoch": 0.6394829127415251,
      "grad_norm": 0.13006757199764252,
      "learning_rate": 4.8003678903892936e-05,
      "loss": 0.0699,
      "step": 9300
    },
    {
      "epoch": 0.6463590730935845,
      "grad_norm": 0.15486577153205872,
      "learning_rate": 4.798218997928468e-05,
      "loss": 0.0653,
      "step": 9400
    },
    {
      "epoch": 0.6532352334456439,
      "grad_norm": 0.08687736839056015,
      "learning_rate": 4.796070105467642e-05,
      "loss": 0.0687,
      "step": 9500
    },
    {
      "epoch": 0.6601113937977033,
      "grad_norm": 0.14394523203372955,
      "learning_rate": 4.7939212130068166e-05,
      "loss": 0.0687,
      "step": 9600
    },
    {
      "epoch": 0.6669875541497627,
      "grad_norm": 0.13077889382839203,
      "learning_rate": 4.791772320545991e-05,
      "loss": 0.0671,
      "step": 9700
    },
    {
      "epoch": 0.6738637145018221,
      "grad_norm": 0.19686053693294525,
      "learning_rate": 4.789623428085165e-05,
      "loss": 0.0666,
      "step": 9800
    },
    {
      "epoch": 0.6807398748538815,
      "grad_norm": 0.2453332096338272,
      "learning_rate": 4.7874745356243396e-05,
      "loss": 0.0673,
      "step": 9900
    },
    {
      "epoch": 0.6876160352059411,
      "grad_norm": 0.10376937687397003,
      "learning_rate": 4.785325643163513e-05,
      "loss": 0.068,
      "step": 10000
    },
    {
      "epoch": 0.6944921955580005,
      "grad_norm": 0.16201432049274445,
      "learning_rate": 4.783176750702688e-05,
      "loss": 0.0698,
      "step": 10100
    },
    {
      "epoch": 0.7013683559100599,
      "grad_norm": 0.1897381991147995,
      "learning_rate": 4.781027858241862e-05,
      "loss": 0.0676,
      "step": 10200
    },
    {
      "epoch": 0.7082445162621193,
      "grad_norm": 0.16066773235797882,
      "learning_rate": 4.778878965781037e-05,
      "loss": 0.0664,
      "step": 10300
    },
    {
      "epoch": 0.7151206766141787,
      "grad_norm": 0.09678545594215393,
      "learning_rate": 4.7767300733202106e-05,
      "loss": 0.0659,
      "step": 10400
    },
    {
      "epoch": 0.7219968369662381,
      "grad_norm": 0.13257862627506256,
      "learning_rate": 4.7745811808593856e-05,
      "loss": 0.0673,
      "step": 10500
    },
    {
      "epoch": 0.7288729973182975,
      "grad_norm": 0.17281116545200348,
      "learning_rate": 4.772432288398559e-05,
      "loss": 0.0685,
      "step": 10600
    },
    {
      "epoch": 0.7357491576703569,
      "grad_norm": 0.17251251637935638,
      "learning_rate": 4.770283395937734e-05,
      "loss": 0.0645,
      "step": 10700
    },
    {
      "epoch": 0.7426253180224163,
      "grad_norm": 0.17014673352241516,
      "learning_rate": 4.768134503476908e-05,
      "loss": 0.0684,
      "step": 10800
    },
    {
      "epoch": 0.7495014783744757,
      "grad_norm": 0.15027858316898346,
      "learning_rate": 4.765985611016083e-05,
      "loss": 0.0693,
      "step": 10900
    },
    {
      "epoch": 0.7563776387265351,
      "grad_norm": 0.18049338459968567,
      "learning_rate": 4.7638367185552566e-05,
      "loss": 0.0662,
      "step": 11000
    },
    {
      "epoch": 0.7632537990785945,
      "grad_norm": 0.1334935575723648,
      "learning_rate": 4.7616878260944316e-05,
      "loss": 0.0647,
      "step": 11100
    },
    {
      "epoch": 0.7701299594306539,
      "grad_norm": 0.13136501610279083,
      "learning_rate": 4.759538933633605e-05,
      "loss": 0.0656,
      "step": 11200
    },
    {
      "epoch": 0.7770061197827133,
      "grad_norm": 0.15551623702049255,
      "learning_rate": 4.7573900411727796e-05,
      "loss": 0.0655,
      "step": 11300
    },
    {
      "epoch": 0.7838822801347728,
      "grad_norm": 0.13409730792045593,
      "learning_rate": 4.755241148711954e-05,
      "loss": 0.0676,
      "step": 11400
    },
    {
      "epoch": 0.7907584404868322,
      "grad_norm": 0.10427150130271912,
      "learning_rate": 4.753092256251128e-05,
      "loss": 0.0649,
      "step": 11500
    },
    {
      "epoch": 0.7976346008388916,
      "grad_norm": 0.13510659337043762,
      "learning_rate": 4.7509433637903026e-05,
      "loss": 0.0686,
      "step": 11600
    },
    {
      "epoch": 0.804510761190951,
      "grad_norm": 0.11763744801282883,
      "learning_rate": 4.748794471329477e-05,
      "loss": 0.0665,
      "step": 11700
    },
    {
      "epoch": 0.8113869215430104,
      "grad_norm": 0.09754003584384918,
      "learning_rate": 4.746645578868651e-05,
      "loss": 0.0645,
      "step": 11800
    },
    {
      "epoch": 0.8182630818950698,
      "grad_norm": 0.15936864912509918,
      "learning_rate": 4.7444966864078256e-05,
      "loss": 0.0649,
      "step": 11900
    },
    {
      "epoch": 0.8251392422471292,
      "grad_norm": 0.21692289412021637,
      "learning_rate": 4.742347793947e-05,
      "loss": 0.0662,
      "step": 12000
    },
    {
      "epoch": 0.8320154025991886,
      "grad_norm": 0.1305203139781952,
      "learning_rate": 4.740198901486174e-05,
      "loss": 0.0654,
      "step": 12100
    },
    {
      "epoch": 0.838891562951248,
      "grad_norm": 0.10738392919301987,
      "learning_rate": 4.7380500090253486e-05,
      "loss": 0.0634,
      "step": 12200
    },
    {
      "epoch": 0.8457677233033074,
      "grad_norm": 0.19060584902763367,
      "learning_rate": 4.735901116564523e-05,
      "loss": 0.0607,
      "step": 12300
    },
    {
      "epoch": 0.8526438836553668,
      "grad_norm": 0.16694974899291992,
      "learning_rate": 4.733773713028305e-05,
      "loss": 0.0632,
      "step": 12400
    },
    {
      "epoch": 0.8595200440074262,
      "grad_norm": 0.12726175785064697,
      "learning_rate": 4.7316248205674796e-05,
      "loss": 0.065,
      "step": 12500
    },
    {
      "epoch": 0.8663962043594856,
      "grad_norm": 0.1775330752134323,
      "learning_rate": 4.729475928106654e-05,
      "loss": 0.0658,
      "step": 12600
    },
    {
      "epoch": 0.8732723647115451,
      "grad_norm": 0.11906415224075317,
      "learning_rate": 4.727327035645828e-05,
      "loss": 0.0668,
      "step": 12700
    },
    {
      "epoch": 0.8801485250636045,
      "grad_norm": 0.12666618824005127,
      "learning_rate": 4.7251781431850026e-05,
      "loss": 0.0667,
      "step": 12800
    },
    {
      "epoch": 0.8870246854156639,
      "grad_norm": 0.1887475550174713,
      "learning_rate": 4.723029250724177e-05,
      "loss": 0.0673,
      "step": 12900
    },
    {
      "epoch": 0.8939008457677233,
      "grad_norm": 0.16512273252010345,
      "learning_rate": 4.720880358263351e-05,
      "loss": 0.0666,
      "step": 13000
    },
    {
      "epoch": 0.9007770061197827,
      "grad_norm": 0.1387740820646286,
      "learning_rate": 4.7187314658025256e-05,
      "loss": 0.0651,
      "step": 13100
    },
    {
      "epoch": 0.9076531664718421,
      "grad_norm": 0.12853746116161346,
      "learning_rate": 4.7165825733417e-05,
      "loss": 0.0649,
      "step": 13200
    },
    {
      "epoch": 0.9145293268239015,
      "grad_norm": 0.12944552302360535,
      "learning_rate": 4.714433680880874e-05,
      "loss": 0.0664,
      "step": 13300
    },
    {
      "epoch": 0.9214054871759609,
      "grad_norm": 0.13434116542339325,
      "learning_rate": 4.7122847884200486e-05,
      "loss": 0.0621,
      "step": 13400
    },
    {
      "epoch": 0.9282816475280203,
      "grad_norm": 0.10372629761695862,
      "learning_rate": 4.710135895959223e-05,
      "loss": 0.0634,
      "step": 13500
    },
    {
      "epoch": 0.9351578078800797,
      "grad_norm": 0.17850321531295776,
      "learning_rate": 4.707987003498397e-05,
      "loss": 0.0646,
      "step": 13600
    },
    {
      "epoch": 0.9420339682321391,
      "grad_norm": 0.10726543515920639,
      "learning_rate": 4.7058381110375716e-05,
      "loss": 0.0632,
      "step": 13700
    },
    {
      "epoch": 0.9489101285841985,
      "grad_norm": 0.1375053972005844,
      "learning_rate": 4.703689218576746e-05,
      "loss": 0.0661,
      "step": 13800
    },
    {
      "epoch": 0.9557862889362579,
      "grad_norm": 0.13695402443408966,
      "learning_rate": 4.70154032611592e-05,
      "loss": 0.0642,
      "step": 13900
    },
    {
      "epoch": 0.9626624492883175,
      "grad_norm": 0.11672509461641312,
      "learning_rate": 4.699391433655094e-05,
      "loss": 0.0656,
      "step": 14000
    },
    {
      "epoch": 0.9695386096403769,
      "grad_norm": 0.1527048796415329,
      "learning_rate": 4.697242541194269e-05,
      "loss": 0.0656,
      "step": 14100
    },
    {
      "epoch": 0.9764147699924363,
      "grad_norm": 0.16092544794082642,
      "learning_rate": 4.6950936487334426e-05,
      "loss": 0.0636,
      "step": 14200
    },
    {
      "epoch": 0.9832909303444957,
      "grad_norm": 0.1659597009420395,
      "learning_rate": 4.6929447562726176e-05,
      "loss": 0.0612,
      "step": 14300
    },
    {
      "epoch": 0.9901670906965551,
      "grad_norm": 0.14653299748897552,
      "learning_rate": 4.690795863811791e-05,
      "loss": 0.0615,
      "step": 14400
    },
    {
      "epoch": 0.9970432510486145,
      "grad_norm": 0.19462800025939941,
      "learning_rate": 4.688646971350966e-05,
      "loss": 0.0641,
      "step": 14500
    },
    {
      "epoch": 1.0,
      "eval_accuracy_macro_0.5": 0.9719162583351135,
      "eval_accuracy_micro_0.5": 0.9719161987304688,
      "eval_accuracy_weighted_0.5": 0.9685781002044678,
      "eval_f1_macro_0.5": 0.5242588520050049,
      "eval_f1_macro_0.6": 0.451604425907135,
      "eval_f1_macro_0.7": 0.3698628544807434,
      "eval_f1_macro_0.8": 0.11504317820072174,
      "eval_f1_micro_0.5": 0.563636064529419,
      "eval_f1_micro_0.6": 0.4999628961086273,
      "eval_f1_micro_0.7": 0.41583874821662903,
      "eval_f1_micro_0.8": 0.2982550859451294,
      "eval_f1_micro_0.9": 0.12729467451572418,
      "eval_f1_weighted_0.5": 0.5265694260597229,
      "eval_f1_weighted_0.6": 0.45027023553848267,
      "eval_f1_weighted_0.7": 0.3628070056438446,
      "eval_f1_weighted_0.8": 0.11024250835180283,
      "eval_loss": 0.060312848538160324,
      "eval_runtime": 62.7174,
      "eval_samples_per_second": 462.981,
      "eval_steps_per_second": 57.879,
      "step": 14543
    },
    {
      "epoch": 1.0039194114006738,
      "grad_norm": 0.18561036884784698,
      "learning_rate": 4.6865195678147486e-05,
      "loss": 0.0629,
      "step": 14600
    },
    {
      "epoch": 1.0107955717527333,
      "grad_norm": 0.08789987117052078,
      "learning_rate": 4.684370675353923e-05,
      "loss": 0.063,
      "step": 14700
    },
    {
      "epoch": 1.0176717321047928,
      "grad_norm": 0.15085147321224213,
      "learning_rate": 4.682221782893097e-05,
      "loss": 0.0603,
      "step": 14800
    },
    {
      "epoch": 1.024547892456852,
      "grad_norm": 0.1417045146226883,
      "learning_rate": 4.6800728904322716e-05,
      "loss": 0.0633,
      "step": 14900
    },
    {
      "epoch": 1.0314240528089116,
      "grad_norm": 0.15977922081947327,
      "learning_rate": 4.677923997971446e-05,
      "loss": 0.0647,
      "step": 15000
    },
    {
      "epoch": 1.0383002131609709,
      "grad_norm": 0.13352914154529572,
      "learning_rate": 4.67577510551062e-05,
      "loss": 0.0639,
      "step": 15100
    },
    {
      "epoch": 1.0451763735130304,
      "grad_norm": 0.0894329845905304,
      "learning_rate": 4.6736262130497946e-05,
      "loss": 0.0584,
      "step": 15200
    },
    {
      "epoch": 1.0520525338650897,
      "grad_norm": 0.10866065323352814,
      "learning_rate": 4.671477320588969e-05,
      "loss": 0.0628,
      "step": 15300
    },
    {
      "epoch": 1.0589286942171492,
      "grad_norm": 0.13361740112304688,
      "learning_rate": 4.669328428128143e-05,
      "loss": 0.0649,
      "step": 15400
    },
    {
      "epoch": 1.0658048545692085,
      "grad_norm": 0.10153702646493912,
      "learning_rate": 4.667179535667317e-05,
      "loss": 0.061,
      "step": 15500
    },
    {
      "epoch": 1.072681014921268,
      "grad_norm": 0.14690634608268738,
      "learning_rate": 4.665030643206492e-05,
      "loss": 0.0596,
      "step": 15600
    },
    {
      "epoch": 1.0795571752733273,
      "grad_norm": 0.11801764369010925,
      "learning_rate": 4.6628817507456656e-05,
      "loss": 0.0634,
      "step": 15700
    },
    {
      "epoch": 1.0864333356253868,
      "grad_norm": 0.1503959447145462,
      "learning_rate": 4.6607328582848406e-05,
      "loss": 0.0641,
      "step": 15800
    },
    {
      "epoch": 1.0933094959774463,
      "grad_norm": 0.14267593622207642,
      "learning_rate": 4.658583965824014e-05,
      "loss": 0.0631,
      "step": 15900
    },
    {
      "epoch": 1.1001856563295056,
      "grad_norm": 0.11700153350830078,
      "learning_rate": 4.656435073363189e-05,
      "loss": 0.0623,
      "step": 16000
    },
    {
      "epoch": 1.1070618166815651,
      "grad_norm": 0.12057390809059143,
      "learning_rate": 4.654286180902363e-05,
      "loss": 0.0592,
      "step": 16100
    },
    {
      "epoch": 1.1139379770336244,
      "grad_norm": 0.17301516234874725,
      "learning_rate": 4.652137288441538e-05,
      "loss": 0.0592,
      "step": 16200
    },
    {
      "epoch": 1.120814137385684,
      "grad_norm": 0.26014769077301025,
      "learning_rate": 4.6499883959807116e-05,
      "loss": 0.0614,
      "step": 16300
    },
    {
      "epoch": 1.1276902977377432,
      "grad_norm": 0.1578907072544098,
      "learning_rate": 4.6478395035198866e-05,
      "loss": 0.0609,
      "step": 16400
    },
    {
      "epoch": 1.1345664580898027,
      "grad_norm": 0.14873702824115753,
      "learning_rate": 4.64569061105906e-05,
      "loss": 0.0614,
      "step": 16500
    },
    {
      "epoch": 1.141442618441862,
      "grad_norm": 0.12434900552034378,
      "learning_rate": 4.643541718598235e-05,
      "loss": 0.0631,
      "step": 16600
    },
    {
      "epoch": 1.1483187787939215,
      "grad_norm": 0.1648232489824295,
      "learning_rate": 4.641414315062017e-05,
      "loss": 0.0618,
      "step": 16700
    },
    {
      "epoch": 1.1551949391459808,
      "grad_norm": 0.15275326371192932,
      "learning_rate": 4.639265422601192e-05,
      "loss": 0.0614,
      "step": 16800
    },
    {
      "epoch": 1.1620710994980403,
      "grad_norm": 0.18500801920890808,
      "learning_rate": 4.6371165301403655e-05,
      "loss": 0.0624,
      "step": 16900
    },
    {
      "epoch": 1.1689472598500996,
      "grad_norm": 0.11512777954339981,
      "learning_rate": 4.6349676376795406e-05,
      "loss": 0.0627,
      "step": 17000
    },
    {
      "epoch": 1.1758234202021591,
      "grad_norm": 0.15941697359085083,
      "learning_rate": 4.632818745218714e-05,
      "loss": 0.0615,
      "step": 17100
    },
    {
      "epoch": 1.1826995805542184,
      "grad_norm": 0.13540683686733246,
      "learning_rate": 4.630669852757889e-05,
      "loss": 0.0626,
      "step": 17200
    },
    {
      "epoch": 1.189575740906278,
      "grad_norm": 0.11957690119743347,
      "learning_rate": 4.628520960297063e-05,
      "loss": 0.0637,
      "step": 17300
    },
    {
      "epoch": 1.1964519012583374,
      "grad_norm": 0.1832312047481537,
      "learning_rate": 4.626372067836238e-05,
      "loss": 0.0621,
      "step": 17400
    },
    {
      "epoch": 1.2033280616103967,
      "grad_norm": 0.1815967559814453,
      "learning_rate": 4.6242231753754115e-05,
      "loss": 0.0621,
      "step": 17500
    },
    {
      "epoch": 1.2102042219624563,
      "grad_norm": 0.11082156002521515,
      "learning_rate": 4.622074282914586e-05,
      "loss": 0.063,
      "step": 17600
    },
    {
      "epoch": 1.2170803823145155,
      "grad_norm": 0.12054935842752457,
      "learning_rate": 4.61992539045376e-05,
      "loss": 0.0641,
      "step": 17700
    },
    {
      "epoch": 1.223956542666575,
      "grad_norm": 0.11701001971960068,
      "learning_rate": 4.6177764979929345e-05,
      "loss": 0.061,
      "step": 17800
    },
    {
      "epoch": 1.2308327030186343,
      "grad_norm": 0.18509317934513092,
      "learning_rate": 4.615627605532109e-05,
      "loss": 0.0614,
      "step": 17900
    },
    {
      "epoch": 1.2377088633706939,
      "grad_norm": 0.1320369988679886,
      "learning_rate": 4.613478713071283e-05,
      "loss": 0.0615,
      "step": 18000
    },
    {
      "epoch": 1.2445850237227531,
      "grad_norm": 0.10728218406438828,
      "learning_rate": 4.6113298206104575e-05,
      "loss": 0.0608,
      "step": 18100
    },
    {
      "epoch": 1.2514611840748127,
      "grad_norm": 0.1947406828403473,
      "learning_rate": 4.609180928149632e-05,
      "loss": 0.0618,
      "step": 18200
    },
    {
      "epoch": 1.258337344426872,
      "grad_norm": 0.12969879806041718,
      "learning_rate": 4.607032035688806e-05,
      "loss": 0.0596,
      "step": 18300
    },
    {
      "epoch": 1.2652135047789315,
      "grad_norm": 0.15108510851860046,
      "learning_rate": 4.6048831432279805e-05,
      "loss": 0.0591,
      "step": 18400
    },
    {
      "epoch": 1.272089665130991,
      "grad_norm": 0.13900740444660187,
      "learning_rate": 4.602734250767155e-05,
      "loss": 0.0612,
      "step": 18500
    },
    {
      "epoch": 1.2789658254830503,
      "grad_norm": 0.21121534705162048,
      "learning_rate": 4.600585358306329e-05,
      "loss": 0.0587,
      "step": 18600
    },
    {
      "epoch": 1.2858419858351096,
      "grad_norm": 0.15896624326705933,
      "learning_rate": 4.5984579547701115e-05,
      "loss": 0.0565,
      "step": 18700
    },
    {
      "epoch": 1.292718146187169,
      "grad_norm": 0.12707945704460144,
      "learning_rate": 4.596309062309286e-05,
      "loss": 0.0624,
      "step": 18800
    },
    {
      "epoch": 1.2995943065392286,
      "grad_norm": 0.16854560375213623,
      "learning_rate": 4.59416016984846e-05,
      "loss": 0.0592,
      "step": 18900
    },
    {
      "epoch": 1.3064704668912879,
      "grad_norm": 0.1229599118232727,
      "learning_rate": 4.5920112773876345e-05,
      "loss": 0.0589,
      "step": 19000
    },
    {
      "epoch": 1.3133466272433474,
      "grad_norm": 0.12455899268388748,
      "learning_rate": 4.589862384926809e-05,
      "loss": 0.0603,
      "step": 19100
    },
    {
      "epoch": 1.3202227875954067,
      "grad_norm": 0.13789242506027222,
      "learning_rate": 4.587713492465983e-05,
      "loss": 0.0631,
      "step": 19200
    },
    {
      "epoch": 1.3270989479474662,
      "grad_norm": 0.14030025899410248,
      "learning_rate": 4.5855646000051575e-05,
      "loss": 0.0613,
      "step": 19300
    },
    {
      "epoch": 1.3339751082995255,
      "grad_norm": 0.10750013589859009,
      "learning_rate": 4.583415707544332e-05,
      "loss": 0.0588,
      "step": 19400
    },
    {
      "epoch": 1.340851268651585,
      "grad_norm": 0.13683564960956573,
      "learning_rate": 4.581266815083506e-05,
      "loss": 0.0622,
      "step": 19500
    },
    {
      "epoch": 1.3477274290036443,
      "grad_norm": 0.16252334415912628,
      "learning_rate": 4.5791179226226805e-05,
      "loss": 0.0589,
      "step": 19600
    },
    {
      "epoch": 1.3546035893557038,
      "grad_norm": 0.1638317108154297,
      "learning_rate": 4.576969030161855e-05,
      "loss": 0.0608,
      "step": 19700
    },
    {
      "epoch": 1.361479749707763,
      "grad_norm": 0.12792636454105377,
      "learning_rate": 4.574820137701029e-05,
      "loss": 0.0595,
      "step": 19800
    },
    {
      "epoch": 1.3683559100598226,
      "grad_norm": 0.14552763104438782,
      "learning_rate": 4.5726712452402035e-05,
      "loss": 0.0602,
      "step": 19900
    },
    {
      "epoch": 1.3752320704118821,
      "grad_norm": 0.09474284946918488,
      "learning_rate": 4.570522352779378e-05,
      "loss": 0.0589,
      "step": 20000
    },
    {
      "epoch": 1.3821082307639414,
      "grad_norm": 0.11430029571056366,
      "learning_rate": 4.5683734603185515e-05,
      "loss": 0.0587,
      "step": 20100
    },
    {
      "epoch": 1.3889843911160007,
      "grad_norm": 0.16300635039806366,
      "learning_rate": 4.5662245678577265e-05,
      "loss": 0.061,
      "step": 20200
    },
    {
      "epoch": 1.3958605514680602,
      "grad_norm": 0.09058317542076111,
      "learning_rate": 4.5640756753969e-05,
      "loss": 0.0596,
      "step": 20300
    },
    {
      "epoch": 1.4027367118201197,
      "grad_norm": 0.14843381941318512,
      "learning_rate": 4.561926782936075e-05,
      "loss": 0.0623,
      "step": 20400
    },
    {
      "epoch": 1.409612872172179,
      "grad_norm": 0.12845221161842346,
      "learning_rate": 4.559777890475249e-05,
      "loss": 0.0599,
      "step": 20500
    },
    {
      "epoch": 1.4164890325242385,
      "grad_norm": 0.13090859353542328,
      "learning_rate": 4.557628998014424e-05,
      "loss": 0.0579,
      "step": 20600
    },
    {
      "epoch": 1.4233651928762978,
      "grad_norm": 0.1696285754442215,
      "learning_rate": 4.5554801055535975e-05,
      "loss": 0.062,
      "step": 20700
    },
    {
      "epoch": 1.4302413532283573,
      "grad_norm": 0.09314149618148804,
      "learning_rate": 4.5533527020173805e-05,
      "loss": 0.0576,
      "step": 20800
    },
    {
      "epoch": 1.4371175135804166,
      "grad_norm": 0.11578653007745743,
      "learning_rate": 4.551203809556555e-05,
      "loss": 0.0608,
      "step": 20900
    },
    {
      "epoch": 1.4439936739324761,
      "grad_norm": 0.13601484894752502,
      "learning_rate": 4.549054917095729e-05,
      "loss": 0.0609,
      "step": 21000
    },
    {
      "epoch": 1.4508698342845356,
      "grad_norm": 0.11775793135166168,
      "learning_rate": 4.5469060246349035e-05,
      "loss": 0.0609,
      "step": 21100
    },
    {
      "epoch": 1.457745994636595,
      "grad_norm": 0.1038656234741211,
      "learning_rate": 4.544757132174078e-05,
      "loss": 0.0588,
      "step": 21200
    },
    {
      "epoch": 1.4646221549886542,
      "grad_norm": 0.17264625430107117,
      "learning_rate": 4.542608239713252e-05,
      "loss": 0.0595,
      "step": 21300
    },
    {
      "epoch": 1.4714983153407137,
      "grad_norm": 0.1651032716035843,
      "learning_rate": 4.5404593472524265e-05,
      "loss": 0.057,
      "step": 21400
    },
    {
      "epoch": 1.4783744756927732,
      "grad_norm": 0.1707875281572342,
      "learning_rate": 4.538310454791601e-05,
      "loss": 0.0612,
      "step": 21500
    },
    {
      "epoch": 1.4852506360448325,
      "grad_norm": 0.19930891692638397,
      "learning_rate": 4.536161562330775e-05,
      "loss": 0.0598,
      "step": 21600
    },
    {
      "epoch": 1.492126796396892,
      "grad_norm": 0.14502879977226257,
      "learning_rate": 4.5340126698699495e-05,
      "loss": 0.0607,
      "step": 21700
    },
    {
      "epoch": 1.4990029567489513,
      "grad_norm": 0.16280394792556763,
      "learning_rate": 4.531863777409124e-05,
      "loss": 0.0579,
      "step": 21800
    },
    {
      "epoch": 1.5058791171010109,
      "grad_norm": 0.09372202306985855,
      "learning_rate": 4.529714884948298e-05,
      "loss": 0.0585,
      "step": 21900
    },
    {
      "epoch": 1.5127552774530701,
      "grad_norm": 0.14959758520126343,
      "learning_rate": 4.527565992487472e-05,
      "loss": 0.0596,
      "step": 22000
    },
    {
      "epoch": 1.5196314378051297,
      "grad_norm": 0.1783323734998703,
      "learning_rate": 4.525417100026647e-05,
      "loss": 0.0586,
      "step": 22100
    },
    {
      "epoch": 1.5265075981571892,
      "grad_norm": 0.12907738983631134,
      "learning_rate": 4.5232682075658205e-05,
      "loss": 0.0569,
      "step": 22200
    },
    {
      "epoch": 1.5333837585092485,
      "grad_norm": 0.16275161504745483,
      "learning_rate": 4.5211193151049955e-05,
      "loss": 0.0592,
      "step": 22300
    },
    {
      "epoch": 1.5402599188613078,
      "grad_norm": 0.139784574508667,
      "learning_rate": 4.518970422644169e-05,
      "loss": 0.0621,
      "step": 22400
    },
    {
      "epoch": 1.5471360792133673,
      "grad_norm": 0.10672333836555481,
      "learning_rate": 4.516821530183344e-05,
      "loss": 0.0578,
      "step": 22500
    },
    {
      "epoch": 1.5540122395654268,
      "grad_norm": 0.2029070258140564,
      "learning_rate": 4.514672637722518e-05,
      "loss": 0.0572,
      "step": 22600
    },
    {
      "epoch": 1.560888399917486,
      "grad_norm": 0.15941770374774933,
      "learning_rate": 4.512523745261693e-05,
      "loss": 0.0595,
      "step": 22700
    },
    {
      "epoch": 1.5677645602695454,
      "grad_norm": 0.10613507032394409,
      "learning_rate": 4.5103748528008665e-05,
      "loss": 0.0586,
      "step": 22800
    },
    {
      "epoch": 1.5746407206216049,
      "grad_norm": 0.14142948389053345,
      "learning_rate": 4.5082259603400415e-05,
      "loss": 0.0612,
      "step": 22900
    },
    {
      "epoch": 1.5815168809736644,
      "grad_norm": 0.2241935431957245,
      "learning_rate": 4.506077067879215e-05,
      "loss": 0.0584,
      "step": 23000
    },
    {
      "epoch": 1.5883930413257237,
      "grad_norm": 0.1899787187576294,
      "learning_rate": 4.50392817541839e-05,
      "loss": 0.0567,
      "step": 23100
    },
    {
      "epoch": 1.595269201677783,
      "grad_norm": 0.09498473256826401,
      "learning_rate": 4.501779282957564e-05,
      "loss": 0.0577,
      "step": 23200
    },
    {
      "epoch": 1.6021453620298427,
      "grad_norm": 0.13601191341876984,
      "learning_rate": 4.499630390496738e-05,
      "loss": 0.0595,
      "step": 23300
    },
    {
      "epoch": 1.609021522381902,
      "grad_norm": 0.25440481305122375,
      "learning_rate": 4.4974814980359125e-05,
      "loss": 0.0574,
      "step": 23400
    },
    {
      "epoch": 1.6158976827339613,
      "grad_norm": 0.16485224664211273,
      "learning_rate": 4.4953540944996955e-05,
      "loss": 0.0602,
      "step": 23500
    },
    {
      "epoch": 1.6227738430860208,
      "grad_norm": 0.18927279114723206,
      "learning_rate": 4.493205202038869e-05,
      "loss": 0.0582,
      "step": 23600
    },
    {
      "epoch": 1.6296500034380803,
      "grad_norm": 0.16477768123149872,
      "learning_rate": 4.491056309578044e-05,
      "loss": 0.0596,
      "step": 23700
    },
    {
      "epoch": 1.6365261637901396,
      "grad_norm": 0.1301891952753067,
      "learning_rate": 4.488907417117218e-05,
      "loss": 0.0579,
      "step": 23800
    },
    {
      "epoch": 1.643402324142199,
      "grad_norm": 0.13297848403453827,
      "learning_rate": 4.486758524656393e-05,
      "loss": 0.0599,
      "step": 23900
    },
    {
      "epoch": 1.6502784844942584,
      "grad_norm": 0.13968127965927124,
      "learning_rate": 4.4846096321955665e-05,
      "loss": 0.0596,
      "step": 24000
    },
    {
      "epoch": 1.657154644846318,
      "grad_norm": 0.11314328759908676,
      "learning_rate": 4.482460739734741e-05,
      "loss": 0.0611,
      "step": 24100
    },
    {
      "epoch": 1.6640308051983772,
      "grad_norm": 0.2233412116765976,
      "learning_rate": 4.480311847273915e-05,
      "loss": 0.0585,
      "step": 24200
    },
    {
      "epoch": 1.6709069655504365,
      "grad_norm": 0.18297956883907318,
      "learning_rate": 4.4781629548130895e-05,
      "loss": 0.0559,
      "step": 24300
    },
    {
      "epoch": 1.677783125902496,
      "grad_norm": 0.20188677310943604,
      "learning_rate": 4.476014062352264e-05,
      "loss": 0.0573,
      "step": 24400
    },
    {
      "epoch": 1.6846592862545555,
      "grad_norm": 0.11186802387237549,
      "learning_rate": 4.473865169891438e-05,
      "loss": 0.0581,
      "step": 24500
    },
    {
      "epoch": 1.6915354466066148,
      "grad_norm": 0.11775188148021698,
      "learning_rate": 4.4717162774306125e-05,
      "loss": 0.0601,
      "step": 24600
    },
    {
      "epoch": 1.6984116069586743,
      "grad_norm": 0.15736305713653564,
      "learning_rate": 4.469567384969787e-05,
      "loss": 0.0569,
      "step": 24700
    },
    {
      "epoch": 1.7052877673107338,
      "grad_norm": 0.144308403134346,
      "learning_rate": 4.467418492508961e-05,
      "loss": 0.06,
      "step": 24800
    },
    {
      "epoch": 1.7121639276627931,
      "grad_norm": 0.1991116851568222,
      "learning_rate": 4.4652696000481355e-05,
      "loss": 0.0569,
      "step": 24900
    },
    {
      "epoch": 1.7190400880148524,
      "grad_norm": 0.10747607052326202,
      "learning_rate": 4.46312070758731e-05,
      "loss": 0.0575,
      "step": 25000
    },
    {
      "epoch": 1.725916248366912,
      "grad_norm": 0.15786150097846985,
      "learning_rate": 4.460971815126484e-05,
      "loss": 0.0607,
      "step": 25100
    },
    {
      "epoch": 1.7327924087189714,
      "grad_norm": 0.15465696156024933,
      "learning_rate": 4.4588229226656585e-05,
      "loss": 0.0594,
      "step": 25200
    },
    {
      "epoch": 1.7396685690710307,
      "grad_norm": 0.1571720540523529,
      "learning_rate": 4.456674030204833e-05,
      "loss": 0.0551,
      "step": 25300
    },
    {
      "epoch": 1.74654472942309,
      "grad_norm": 0.16631002724170685,
      "learning_rate": 4.4545251377440064e-05,
      "loss": 0.0547,
      "step": 25400
    },
    {
      "epoch": 1.7534208897751495,
      "grad_norm": 0.23815947771072388,
      "learning_rate": 4.4523762452831815e-05,
      "loss": 0.0566,
      "step": 25500
    },
    {
      "epoch": 1.760297050127209,
      "grad_norm": 0.11583011597394943,
      "learning_rate": 4.450248841746964e-05,
      "loss": 0.0576,
      "step": 25600
    },
    {
      "epoch": 1.7671732104792683,
      "grad_norm": 0.16682516038417816,
      "learning_rate": 4.448099949286138e-05,
      "loss": 0.0577,
      "step": 25700
    },
    {
      "epoch": 1.7740493708313276,
      "grad_norm": 0.14152759313583374,
      "learning_rate": 4.4459510568253124e-05,
      "loss": 0.0618,
      "step": 25800
    },
    {
      "epoch": 1.7809255311833871,
      "grad_norm": 0.20719145238399506,
      "learning_rate": 4.443802164364487e-05,
      "loss": 0.0598,
      "step": 25900
    },
    {
      "epoch": 1.7878016915354467,
      "grad_norm": 0.12225319445133209,
      "learning_rate": 4.441653271903661e-05,
      "loss": 0.0562,
      "step": 26000
    },
    {
      "epoch": 1.794677851887506,
      "grad_norm": 0.10573127865791321,
      "learning_rate": 4.4395043794428354e-05,
      "loss": 0.0588,
      "step": 26100
    },
    {
      "epoch": 1.8015540122395655,
      "grad_norm": 0.16339834034442902,
      "learning_rate": 4.43735548698201e-05,
      "loss": 0.0567,
      "step": 26200
    },
    {
      "epoch": 1.808430172591625,
      "grad_norm": 0.14993681013584137,
      "learning_rate": 4.435206594521184e-05,
      "loss": 0.0575,
      "step": 26300
    },
    {
      "epoch": 1.8153063329436843,
      "grad_norm": 0.13573616743087769,
      "learning_rate": 4.433057702060358e-05,
      "loss": 0.0585,
      "step": 26400
    },
    {
      "epoch": 1.8221824932957436,
      "grad_norm": 0.13061363995075226,
      "learning_rate": 4.430908809599533e-05,
      "loss": 0.0619,
      "step": 26500
    },
    {
      "epoch": 1.829058653647803,
      "grad_norm": 0.13129930198192596,
      "learning_rate": 4.4287599171387064e-05,
      "loss": 0.0583,
      "step": 26600
    },
    {
      "epoch": 1.8359348139998626,
      "grad_norm": 0.1296645700931549,
      "learning_rate": 4.4266110246778814e-05,
      "loss": 0.0575,
      "step": 26700
    },
    {
      "epoch": 1.8428109743519219,
      "grad_norm": 0.11252712458372116,
      "learning_rate": 4.424462132217055e-05,
      "loss": 0.0585,
      "step": 26800
    },
    {
      "epoch": 1.8496871347039812,
      "grad_norm": 0.17125315964221954,
      "learning_rate": 4.42231323975623e-05,
      "loss": 0.0554,
      "step": 26900
    },
    {
      "epoch": 1.8565632950560407,
      "grad_norm": 0.11581545323133469,
      "learning_rate": 4.420164347295404e-05,
      "loss": 0.0561,
      "step": 27000
    },
    {
      "epoch": 1.8634394554081002,
      "grad_norm": 0.22251999378204346,
      "learning_rate": 4.418015454834579e-05,
      "loss": 0.0566,
      "step": 27100
    },
    {
      "epoch": 1.8703156157601595,
      "grad_norm": 0.16678717732429504,
      "learning_rate": 4.4158665623737524e-05,
      "loss": 0.0592,
      "step": 27200
    },
    {
      "epoch": 1.877191776112219,
      "grad_norm": 0.11732064932584763,
      "learning_rate": 4.4137176699129274e-05,
      "loss": 0.0598,
      "step": 27300
    },
    {
      "epoch": 1.8840679364642785,
      "grad_norm": 0.14956383407115936,
      "learning_rate": 4.411568777452101e-05,
      "loss": 0.0567,
      "step": 27400
    },
    {
      "epoch": 1.8909440968163378,
      "grad_norm": 0.12361247837543488,
      "learning_rate": 4.4094198849912754e-05,
      "loss": 0.0559,
      "step": 27500
    },
    {
      "epoch": 1.897820257168397,
      "grad_norm": 0.17703570425510406,
      "learning_rate": 4.40727099253045e-05,
      "loss": 0.0563,
      "step": 27600
    },
    {
      "epoch": 1.9046964175204566,
      "grad_norm": 0.1546093225479126,
      "learning_rate": 4.405143588994233e-05,
      "loss": 0.0584,
      "step": 27700
    },
    {
      "epoch": 1.911572577872516,
      "grad_norm": 0.1421288400888443,
      "learning_rate": 4.402994696533407e-05,
      "loss": 0.0568,
      "step": 27800
    },
    {
      "epoch": 1.9184487382245754,
      "grad_norm": 0.0876075029373169,
      "learning_rate": 4.4008458040725814e-05,
      "loss": 0.0587,
      "step": 27900
    },
    {
      "epoch": 1.9253248985766347,
      "grad_norm": 0.0984877273440361,
      "learning_rate": 4.398696911611756e-05,
      "loss": 0.057,
      "step": 28000
    },
    {
      "epoch": 1.9322010589286942,
      "grad_norm": 0.22683419287204742,
      "learning_rate": 4.39654801915093e-05,
      "loss": 0.0545,
      "step": 28100
    },
    {
      "epoch": 1.9390772192807537,
      "grad_norm": 0.20297585427761078,
      "learning_rate": 4.3943991266901044e-05,
      "loss": 0.0638,
      "step": 28200
    },
    {
      "epoch": 1.945953379632813,
      "grad_norm": 0.12125448882579803,
      "learning_rate": 4.392250234229278e-05,
      "loss": 0.0556,
      "step": 28300
    },
    {
      "epoch": 1.9528295399848723,
      "grad_norm": 0.09261982887983322,
      "learning_rate": 4.390101341768453e-05,
      "loss": 0.0575,
      "step": 28400
    },
    {
      "epoch": 1.9597057003369318,
      "grad_norm": 0.19909462332725525,
      "learning_rate": 4.387952449307627e-05,
      "loss": 0.0556,
      "step": 28500
    },
    {
      "epoch": 1.9665818606889913,
      "grad_norm": 0.10955324023962021,
      "learning_rate": 4.385803556846802e-05,
      "loss": 0.0579,
      "step": 28600
    },
    {
      "epoch": 1.9734580210410506,
      "grad_norm": 0.12342257797718048,
      "learning_rate": 4.3836546643859754e-05,
      "loss": 0.0557,
      "step": 28700
    },
    {
      "epoch": 1.9803341813931101,
      "grad_norm": 0.09319538623094559,
      "learning_rate": 4.3815057719251504e-05,
      "loss": 0.0584,
      "step": 28800
    },
    {
      "epoch": 1.9872103417451696,
      "grad_norm": 0.10753704607486725,
      "learning_rate": 4.379356879464324e-05,
      "loss": 0.0579,
      "step": 28900
    },
    {
      "epoch": 1.994086502097229,
      "grad_norm": 0.08124065399169922,
      "learning_rate": 4.377207987003499e-05,
      "loss": 0.0569,
      "step": 29000
    },
    {
      "epoch": 2.0,
      "eval_accuracy_macro_0.5": 0.9747133255004883,
      "eval_accuracy_micro_0.5": 0.9747133255004883,
      "eval_accuracy_weighted_0.5": 0.9716349244117737,
      "eval_f1_macro_0.5": 0.6044784784317017,
      "eval_f1_macro_0.6": 0.5489615797996521,
      "eval_f1_macro_0.7": 0.4814218282699585,
      "eval_f1_macro_0.8": 0.2326355278491974,
      "eval_f1_micro_0.5": 0.6285804510116577,
      "eval_f1_micro_0.6": 0.5841532945632935,
      "eval_f1_micro_0.7": 0.5216493010520935,
      "eval_f1_micro_0.8": 0.42113959789276123,
      "eval_f1_micro_0.9": 0.25611376762390137,
      "eval_f1_weighted_0.5": 0.6049007177352905,
      "eval_f1_weighted_0.6": 0.5492568016052246,
      "eval_f1_weighted_0.7": 0.4788679778575897,
      "eval_f1_weighted_0.8": 0.2239130735397339,
      "eval_loss": 0.05349012464284897,
      "eval_runtime": 62.5085,
      "eval_samples_per_second": 464.529,
      "eval_steps_per_second": 58.072,
      "step": 29086
    },
    {
      "epoch": 2.000962662449288,
      "grad_norm": 0.2015068680047989,
      "learning_rate": 4.375059094542673e-05,
      "loss": 0.056,
      "step": 29100
    },
    {
      "epoch": 2.0078388228013475,
      "grad_norm": 0.14710985124111176,
      "learning_rate": 4.372910202081848e-05,
      "loss": 0.0587,
      "step": 29200
    },
    {
      "epoch": 2.0147149831534072,
      "grad_norm": 0.12250818312168121,
      "learning_rate": 4.3707613096210214e-05,
      "loss": 0.0582,
      "step": 29300
    },
    {
      "epoch": 2.0215911435054665,
      "grad_norm": 0.1724538654088974,
      "learning_rate": 4.3686124171601964e-05,
      "loss": 0.0584,
      "step": 29400
    },
    {
      "epoch": 2.028467303857526,
      "grad_norm": 0.17482787370681763,
      "learning_rate": 4.36646352469937e-05,
      "loss": 0.0566,
      "step": 29500
    },
    {
      "epoch": 2.0353434642095856,
      "grad_norm": 0.09627149254083633,
      "learning_rate": 4.3643146322385444e-05,
      "loss": 0.0536,
      "step": 29600
    },
    {
      "epoch": 2.042219624561645,
      "grad_norm": 0.15708065032958984,
      "learning_rate": 4.362165739777719e-05,
      "loss": 0.0573,
      "step": 29700
    },
    {
      "epoch": 2.049095784913704,
      "grad_norm": 0.11035023629665375,
      "learning_rate": 4.360016847316893e-05,
      "loss": 0.0568,
      "step": 29800
    },
    {
      "epoch": 2.0559719452657634,
      "grad_norm": 0.12731094658374786,
      "learning_rate": 4.3578894437806754e-05,
      "loss": 0.0561,
      "step": 29900
    },
    {
      "epoch": 2.062848105617823,
      "grad_norm": 0.1261240839958191,
      "learning_rate": 4.3557405513198504e-05,
      "loss": 0.0545,
      "step": 30000
    },
    {
      "epoch": 2.0697242659698825,
      "grad_norm": 0.13272163271903992,
      "learning_rate": 4.353591658859024e-05,
      "loss": 0.0573,
      "step": 30100
    },
    {
      "epoch": 2.0766004263219418,
      "grad_norm": 0.14692789316177368,
      "learning_rate": 4.351442766398199e-05,
      "loss": 0.0566,
      "step": 30200
    },
    {
      "epoch": 2.083476586674001,
      "grad_norm": 0.18436208367347717,
      "learning_rate": 4.349293873937373e-05,
      "loss": 0.0556,
      "step": 30300
    },
    {
      "epoch": 2.0903527470260608,
      "grad_norm": 0.18137362599372864,
      "learning_rate": 4.347144981476548e-05,
      "loss": 0.0573,
      "step": 30400
    },
    {
      "epoch": 2.09722890737812,
      "grad_norm": 0.110625259578228,
      "learning_rate": 4.3449960890157214e-05,
      "loss": 0.0577,
      "step": 30500
    },
    {
      "epoch": 2.1041050677301794,
      "grad_norm": 0.20737969875335693,
      "learning_rate": 4.342847196554896e-05,
      "loss": 0.0569,
      "step": 30600
    },
    {
      "epoch": 2.110981228082239,
      "grad_norm": 0.21188518404960632,
      "learning_rate": 4.34069830409407e-05,
      "loss": 0.0597,
      "step": 30700
    },
    {
      "epoch": 2.1178573884342984,
      "grad_norm": 0.11842110008001328,
      "learning_rate": 4.3385494116332444e-05,
      "loss": 0.0562,
      "step": 30800
    },
    {
      "epoch": 2.1247335487863577,
      "grad_norm": 0.17476226389408112,
      "learning_rate": 4.336400519172419e-05,
      "loss": 0.0577,
      "step": 30900
    },
    {
      "epoch": 2.131609709138417,
      "grad_norm": 0.12054000794887543,
      "learning_rate": 4.334251626711593e-05,
      "loss": 0.0563,
      "step": 31000
    },
    {
      "epoch": 2.1384858694904767,
      "grad_norm": 0.14696741104125977,
      "learning_rate": 4.3321027342507674e-05,
      "loss": 0.0577,
      "step": 31100
    },
    {
      "epoch": 2.145362029842536,
      "grad_norm": 0.2100348025560379,
      "learning_rate": 4.329953841789942e-05,
      "loss": 0.0561,
      "step": 31200
    },
    {
      "epoch": 2.1522381901945953,
      "grad_norm": 0.10152504593133926,
      "learning_rate": 4.327804949329116e-05,
      "loss": 0.0557,
      "step": 31300
    },
    {
      "epoch": 2.1591143505466546,
      "grad_norm": 0.10209069401025772,
      "learning_rate": 4.3256560568682904e-05,
      "loss": 0.0555,
      "step": 31400
    },
    {
      "epoch": 2.1659905108987143,
      "grad_norm": 0.17573182284832,
      "learning_rate": 4.323507164407465e-05,
      "loss": 0.0562,
      "step": 31500
    },
    {
      "epoch": 2.1728666712507736,
      "grad_norm": 0.12209489941596985,
      "learning_rate": 4.321358271946639e-05,
      "loss": 0.0576,
      "step": 31600
    },
    {
      "epoch": 2.179742831602833,
      "grad_norm": 0.1200978010892868,
      "learning_rate": 4.319209379485813e-05,
      "loss": 0.0547,
      "step": 31700
    },
    {
      "epoch": 2.1866189919548926,
      "grad_norm": 0.1456613689661026,
      "learning_rate": 4.317060487024988e-05,
      "loss": 0.0512,
      "step": 31800
    },
    {
      "epoch": 2.193495152306952,
      "grad_norm": 0.20268695056438446,
      "learning_rate": 4.31493308348877e-05,
      "loss": 0.0557,
      "step": 31900
    },
    {
      "epoch": 2.200371312659011,
      "grad_norm": 0.11544252932071686,
      "learning_rate": 4.312784191027944e-05,
      "loss": 0.0553,
      "step": 32000
    },
    {
      "epoch": 2.2072474730110705,
      "grad_norm": 0.0825614482164383,
      "learning_rate": 4.310635298567119e-05,
      "loss": 0.0549,
      "step": 32100
    },
    {
      "epoch": 2.2141236333631302,
      "grad_norm": 0.2148859202861786,
      "learning_rate": 4.308486406106293e-05,
      "loss": 0.0586,
      "step": 32200
    },
    {
      "epoch": 2.2209997937151895,
      "grad_norm": 0.10464167594909668,
      "learning_rate": 4.3063375136454673e-05,
      "loss": 0.0542,
      "step": 32300
    },
    {
      "epoch": 2.227875954067249,
      "grad_norm": 0.15425564348697662,
      "learning_rate": 4.304188621184642e-05,
      "loss": 0.0529,
      "step": 32400
    },
    {
      "epoch": 2.234752114419308,
      "grad_norm": 0.17262360453605652,
      "learning_rate": 4.302039728723816e-05,
      "loss": 0.0578,
      "step": 32500
    },
    {
      "epoch": 2.241628274771368,
      "grad_norm": 0.2816697359085083,
      "learning_rate": 4.2998908362629903e-05,
      "loss": 0.0551,
      "step": 32600
    },
    {
      "epoch": 2.248504435123427,
      "grad_norm": 0.17173197865486145,
      "learning_rate": 4.297741943802164e-05,
      "loss": 0.0564,
      "step": 32700
    },
    {
      "epoch": 2.2553805954754864,
      "grad_norm": 0.10831622779369354,
      "learning_rate": 4.295593051341339e-05,
      "loss": 0.0548,
      "step": 32800
    },
    {
      "epoch": 2.2622567558275457,
      "grad_norm": 0.17200212180614471,
      "learning_rate": 4.293444158880513e-05,
      "loss": 0.055,
      "step": 32900
    },
    {
      "epoch": 2.2691329161796054,
      "grad_norm": 0.19405131042003632,
      "learning_rate": 4.291295266419688e-05,
      "loss": 0.0565,
      "step": 33000
    },
    {
      "epoch": 2.2760090765316647,
      "grad_norm": 0.13816164433956146,
      "learning_rate": 4.289146373958861e-05,
      "loss": 0.0557,
      "step": 33100
    },
    {
      "epoch": 2.282885236883724,
      "grad_norm": 0.19912497699260712,
      "learning_rate": 4.2869974814980363e-05,
      "loss": 0.0576,
      "step": 33200
    },
    {
      "epoch": 2.2897613972357833,
      "grad_norm": 0.11190956830978394,
      "learning_rate": 4.28484858903721e-05,
      "loss": 0.0557,
      "step": 33300
    },
    {
      "epoch": 2.296637557587843,
      "grad_norm": 0.16523364186286926,
      "learning_rate": 4.282699696576385e-05,
      "loss": 0.0581,
      "step": 33400
    },
    {
      "epoch": 2.3035137179399023,
      "grad_norm": 0.17486853897571564,
      "learning_rate": 4.280550804115559e-05,
      "loss": 0.0572,
      "step": 33500
    },
    {
      "epoch": 2.3103898782919616,
      "grad_norm": 0.17325225472450256,
      "learning_rate": 4.278401911654734e-05,
      "loss": 0.0554,
      "step": 33600
    },
    {
      "epoch": 2.3172660386440214,
      "grad_norm": 0.15779262781143188,
      "learning_rate": 4.276253019193907e-05,
      "loss": 0.0556,
      "step": 33700
    },
    {
      "epoch": 2.3241421989960807,
      "grad_norm": 0.11122725903987885,
      "learning_rate": 4.2741041267330823e-05,
      "loss": 0.0517,
      "step": 33800
    },
    {
      "epoch": 2.33101835934814,
      "grad_norm": 0.1150493249297142,
      "learning_rate": 4.271955234272256e-05,
      "loss": 0.056,
      "step": 33900
    },
    {
      "epoch": 2.3378945197001992,
      "grad_norm": 0.14637017250061035,
      "learning_rate": 4.26980634181143e-05,
      "loss": 0.055,
      "step": 34000
    },
    {
      "epoch": 2.344770680052259,
      "grad_norm": 0.1765146702528,
      "learning_rate": 4.267678938275213e-05,
      "loss": 0.058,
      "step": 34100
    },
    {
      "epoch": 2.3516468404043183,
      "grad_norm": 0.13666492700576782,
      "learning_rate": 4.2655300458143876e-05,
      "loss": 0.0566,
      "step": 34200
    },
    {
      "epoch": 2.3585230007563776,
      "grad_norm": 0.2013663500547409,
      "learning_rate": 4.263381153353562e-05,
      "loss": 0.0543,
      "step": 34300
    },
    {
      "epoch": 2.365399161108437,
      "grad_norm": 0.21367818117141724,
      "learning_rate": 4.261232260892736e-05,
      "loss": 0.0522,
      "step": 34400
    },
    {
      "epoch": 2.3722753214604966,
      "grad_norm": 0.09848380088806152,
      "learning_rate": 4.2590833684319106e-05,
      "loss": 0.0571,
      "step": 34500
    },
    {
      "epoch": 2.379151481812556,
      "grad_norm": 0.2991507351398468,
      "learning_rate": 4.256934475971085e-05,
      "loss": 0.0565,
      "step": 34600
    },
    {
      "epoch": 2.386027642164615,
      "grad_norm": 0.13308702409267426,
      "learning_rate": 4.254785583510259e-05,
      "loss": 0.0568,
      "step": 34700
    },
    {
      "epoch": 2.392903802516675,
      "grad_norm": 0.18740233778953552,
      "learning_rate": 4.252636691049433e-05,
      "loss": 0.0537,
      "step": 34800
    },
    {
      "epoch": 2.399779962868734,
      "grad_norm": 0.20366691052913666,
      "learning_rate": 4.250487798588608e-05,
      "loss": 0.0525,
      "step": 34900
    },
    {
      "epoch": 2.4066561232207935,
      "grad_norm": 0.16790880262851715,
      "learning_rate": 4.24836039505239e-05,
      "loss": 0.0575,
      "step": 35000
    },
    {
      "epoch": 2.4135322835728528,
      "grad_norm": 0.1662392020225525,
      "learning_rate": 4.2462115025915646e-05,
      "loss": 0.0519,
      "step": 35100
    },
    {
      "epoch": 2.4204084439249125,
      "grad_norm": 0.18773296475410461,
      "learning_rate": 4.244062610130739e-05,
      "loss": 0.0554,
      "step": 35200
    },
    {
      "epoch": 2.427284604276972,
      "grad_norm": 0.1692305952310562,
      "learning_rate": 4.241913717669913e-05,
      "loss": 0.0567,
      "step": 35300
    },
    {
      "epoch": 2.434160764629031,
      "grad_norm": 0.10861466079950333,
      "learning_rate": 4.2397648252090876e-05,
      "loss": 0.0537,
      "step": 35400
    },
    {
      "epoch": 2.4410369249810904,
      "grad_norm": 0.11309222131967545,
      "learning_rate": 4.237615932748262e-05,
      "loss": 0.0572,
      "step": 35500
    },
    {
      "epoch": 2.44791308533315,
      "grad_norm": 0.12252569198608398,
      "learning_rate": 4.2354670402874356e-05,
      "loss": 0.0564,
      "step": 35600
    },
    {
      "epoch": 2.4547892456852094,
      "grad_norm": 0.15709447860717773,
      "learning_rate": 4.2333181478266106e-05,
      "loss": 0.0529,
      "step": 35700
    },
    {
      "epoch": 2.4616654060372687,
      "grad_norm": 0.19253654778003693,
      "learning_rate": 4.231169255365784e-05,
      "loss": 0.0551,
      "step": 35800
    },
    {
      "epoch": 2.4685415663893284,
      "grad_norm": 0.15585914254188538,
      "learning_rate": 4.229020362904959e-05,
      "loss": 0.051,
      "step": 35900
    },
    {
      "epoch": 2.4754177267413877,
      "grad_norm": 0.13988637924194336,
      "learning_rate": 4.226871470444133e-05,
      "loss": 0.0531,
      "step": 36000
    },
    {
      "epoch": 2.482293887093447,
      "grad_norm": 0.21146871149539948,
      "learning_rate": 4.224722577983308e-05,
      "loss": 0.0547,
      "step": 36100
    },
    {
      "epoch": 2.4891700474455063,
      "grad_norm": 0.14198532700538635,
      "learning_rate": 4.2225736855224816e-05,
      "loss": 0.0582,
      "step": 36200
    },
    {
      "epoch": 2.496046207797566,
      "grad_norm": 0.13050557672977448,
      "learning_rate": 4.2204247930616566e-05,
      "loss": 0.0552,
      "step": 36300
    },
    {
      "epoch": 2.5029223681496253,
      "grad_norm": 0.10359486192464828,
      "learning_rate": 4.21827590060083e-05,
      "loss": 0.0535,
      "step": 36400
    },
    {
      "epoch": 2.5097985285016846,
      "grad_norm": 0.15516409277915955,
      "learning_rate": 4.216127008140005e-05,
      "loss": 0.0552,
      "step": 36500
    },
    {
      "epoch": 2.516674688853744,
      "grad_norm": 0.1283477544784546,
      "learning_rate": 4.213978115679179e-05,
      "loss": 0.0563,
      "step": 36600
    },
    {
      "epoch": 2.5235508492058036,
      "grad_norm": 0.18622586131095886,
      "learning_rate": 4.211829223218354e-05,
      "loss": 0.0566,
      "step": 36700
    },
    {
      "epoch": 2.530427009557863,
      "grad_norm": 0.26241981983184814,
      "learning_rate": 4.2096803307575276e-05,
      "loss": 0.0556,
      "step": 36800
    },
    {
      "epoch": 2.537303169909922,
      "grad_norm": 0.24191118776798248,
      "learning_rate": 4.207531438296702e-05,
      "loss": 0.0557,
      "step": 36900
    },
    {
      "epoch": 2.544179330261982,
      "grad_norm": 0.17739474773406982,
      "learning_rate": 4.205382545835876e-05,
      "loss": 0.0554,
      "step": 37000
    },
    {
      "epoch": 2.5510554906140412,
      "grad_norm": 0.14203236997127533,
      "learning_rate": 4.2032336533750506e-05,
      "loss": 0.0545,
      "step": 37100
    },
    {
      "epoch": 2.5579316509661005,
      "grad_norm": 0.09215987473726273,
      "learning_rate": 4.201084760914225e-05,
      "loss": 0.0538,
      "step": 37200
    },
    {
      "epoch": 2.56480781131816,
      "grad_norm": 0.18823958933353424,
      "learning_rate": 4.198935868453399e-05,
      "loss": 0.0556,
      "step": 37300
    },
    {
      "epoch": 2.571683971670219,
      "grad_norm": 0.12054398655891418,
      "learning_rate": 4.1967869759925736e-05,
      "loss": 0.0534,
      "step": 37400
    },
    {
      "epoch": 2.578560132022279,
      "grad_norm": 0.15682414174079895,
      "learning_rate": 4.194638083531748e-05,
      "loss": 0.0581,
      "step": 37500
    },
    {
      "epoch": 2.585436292374338,
      "grad_norm": 0.16375328600406647,
      "learning_rate": 4.192489191070922e-05,
      "loss": 0.0536,
      "step": 37600
    },
    {
      "epoch": 2.5923124527263974,
      "grad_norm": 0.13299055397510529,
      "learning_rate": 4.1903402986100966e-05,
      "loss": 0.0568,
      "step": 37700
    },
    {
      "epoch": 2.599188613078457,
      "grad_norm": 0.11451390385627747,
      "learning_rate": 4.188191406149271e-05,
      "loss": 0.054,
      "step": 37800
    },
    {
      "epoch": 2.6060647734305165,
      "grad_norm": 0.17387928068637848,
      "learning_rate": 4.186042513688445e-05,
      "loss": 0.0525,
      "step": 37900
    },
    {
      "epoch": 2.6129409337825757,
      "grad_norm": 0.14541898667812347,
      "learning_rate": 4.1838936212276196e-05,
      "loss": 0.0547,
      "step": 38000
    },
    {
      "epoch": 2.6198170941346355,
      "grad_norm": 0.17781944572925568,
      "learning_rate": 4.181744728766794e-05,
      "loss": 0.0536,
      "step": 38100
    },
    {
      "epoch": 2.6266932544866948,
      "grad_norm": 0.11553977429866791,
      "learning_rate": 4.1795958363059676e-05,
      "loss": 0.0523,
      "step": 38200
    },
    {
      "epoch": 2.633569414838754,
      "grad_norm": 0.17697621881961823,
      "learning_rate": 4.1774469438451426e-05,
      "loss": 0.0558,
      "step": 38300
    },
    {
      "epoch": 2.6404455751908134,
      "grad_norm": 0.08786670118570328,
      "learning_rate": 4.175298051384316e-05,
      "loss": 0.0511,
      "step": 38400
    },
    {
      "epoch": 2.6473217355428726,
      "grad_norm": 0.17723821103572845,
      "learning_rate": 4.173149158923491e-05,
      "loss": 0.0548,
      "step": 38500
    },
    {
      "epoch": 2.6541978958949324,
      "grad_norm": 0.11796227842569351,
      "learning_rate": 4.171000266462665e-05,
      "loss": 0.05,
      "step": 38600
    },
    {
      "epoch": 2.6610740562469917,
      "grad_norm": 0.11289376765489578,
      "learning_rate": 4.16885137400184e-05,
      "loss": 0.055,
      "step": 38700
    },
    {
      "epoch": 2.667950216599051,
      "grad_norm": 0.16889886558055878,
      "learning_rate": 4.1667024815410136e-05,
      "loss": 0.0564,
      "step": 38800
    },
    {
      "epoch": 2.6748263769511107,
      "grad_norm": 0.22976472973823547,
      "learning_rate": 4.1645535890801886e-05,
      "loss": 0.052,
      "step": 38900
    },
    {
      "epoch": 2.68170253730317,
      "grad_norm": 0.10132929682731628,
      "learning_rate": 4.162404696619362e-05,
      "loss": 0.0533,
      "step": 39000
    },
    {
      "epoch": 2.6885786976552293,
      "grad_norm": 0.14509275555610657,
      "learning_rate": 4.160255804158537e-05,
      "loss": 0.0537,
      "step": 39100
    },
    {
      "epoch": 2.6954548580072886,
      "grad_norm": 0.10908699780702591,
      "learning_rate": 4.158106911697711e-05,
      "loss": 0.0525,
      "step": 39200
    },
    {
      "epoch": 2.7023310183593483,
      "grad_norm": 0.11668701469898224,
      "learning_rate": 4.155979508161494e-05,
      "loss": 0.0545,
      "step": 39300
    },
    {
      "epoch": 2.7092071787114076,
      "grad_norm": 0.1556086540222168,
      "learning_rate": 4.1538306157006676e-05,
      "loss": 0.0544,
      "step": 39400
    },
    {
      "epoch": 2.716083339063467,
      "grad_norm": 0.13110984861850739,
      "learning_rate": 4.1516817232398426e-05,
      "loss": 0.0518,
      "step": 39500
    },
    {
      "epoch": 2.722959499415526,
      "grad_norm": 0.17235785722732544,
      "learning_rate": 4.149532830779016e-05,
      "loss": 0.0539,
      "step": 39600
    },
    {
      "epoch": 2.729835659767586,
      "grad_norm": 0.11562386900186539,
      "learning_rate": 4.147383938318191e-05,
      "loss": 0.0542,
      "step": 39700
    },
    {
      "epoch": 2.736711820119645,
      "grad_norm": 0.16107092797756195,
      "learning_rate": 4.145235045857365e-05,
      "loss": 0.057,
      "step": 39800
    },
    {
      "epoch": 2.7435879804717045,
      "grad_norm": 0.10022195428609848,
      "learning_rate": 4.14308615339654e-05,
      "loss": 0.0525,
      "step": 39900
    },
    {
      "epoch": 2.7504641408237642,
      "grad_norm": 0.11839652806520462,
      "learning_rate": 4.1409372609357136e-05,
      "loss": 0.0547,
      "step": 40000
    },
    {
      "epoch": 2.7573403011758235,
      "grad_norm": 0.134243905544281,
      "learning_rate": 4.1387883684748886e-05,
      "loss": 0.0546,
      "step": 40100
    },
    {
      "epoch": 2.764216461527883,
      "grad_norm": 0.08499258011579514,
      "learning_rate": 4.136639476014062e-05,
      "loss": 0.0511,
      "step": 40200
    },
    {
      "epoch": 2.771092621879942,
      "grad_norm": 0.18111945688724518,
      "learning_rate": 4.1344905835532366e-05,
      "loss": 0.0557,
      "step": 40300
    },
    {
      "epoch": 2.7779687822320014,
      "grad_norm": 0.12571033835411072,
      "learning_rate": 4.132341691092411e-05,
      "loss": 0.054,
      "step": 40400
    },
    {
      "epoch": 2.784844942584061,
      "grad_norm": 0.18318124115467072,
      "learning_rate": 4.130192798631585e-05,
      "loss": 0.057,
      "step": 40500
    },
    {
      "epoch": 2.7917211029361204,
      "grad_norm": 0.10369835048913956,
      "learning_rate": 4.1280439061707596e-05,
      "loss": 0.0561,
      "step": 40600
    },
    {
      "epoch": 2.7985972632881797,
      "grad_norm": 0.12221542000770569,
      "learning_rate": 4.125895013709934e-05,
      "loss": 0.0542,
      "step": 40700
    },
    {
      "epoch": 2.8054734236402394,
      "grad_norm": 0.18425287306308746,
      "learning_rate": 4.123746121249108e-05,
      "loss": 0.0523,
      "step": 40800
    },
    {
      "epoch": 2.8123495839922987,
      "grad_norm": 0.10720765590667725,
      "learning_rate": 4.1215972287882826e-05,
      "loss": 0.0535,
      "step": 40900
    },
    {
      "epoch": 2.819225744344358,
      "grad_norm": 0.22171492874622345,
      "learning_rate": 4.119448336327457e-05,
      "loss": 0.0533,
      "step": 41000
    },
    {
      "epoch": 2.8261019046964178,
      "grad_norm": 0.1573985368013382,
      "learning_rate": 4.117299443866631e-05,
      "loss": 0.0527,
      "step": 41100
    },
    {
      "epoch": 2.832978065048477,
      "grad_norm": 0.15677838027477264,
      "learning_rate": 4.1151505514058056e-05,
      "loss": 0.0549,
      "step": 41200
    },
    {
      "epoch": 2.8398542254005363,
      "grad_norm": 0.1485208123922348,
      "learning_rate": 4.113023147869588e-05,
      "loss": 0.0508,
      "step": 41300
    },
    {
      "epoch": 2.8467303857525956,
      "grad_norm": 0.1319456845521927,
      "learning_rate": 4.110874255408763e-05,
      "loss": 0.0551,
      "step": 41400
    },
    {
      "epoch": 2.853606546104655,
      "grad_norm": 0.13277529180049896,
      "learning_rate": 4.1087253629479365e-05,
      "loss": 0.0501,
      "step": 41500
    },
    {
      "epoch": 2.8604827064567147,
      "grad_norm": 0.16844290494918823,
      "learning_rate": 4.1065764704871116e-05,
      "loss": 0.0552,
      "step": 41600
    },
    {
      "epoch": 2.867358866808774,
      "grad_norm": 0.10386936366558075,
      "learning_rate": 4.104427578026285e-05,
      "loss": 0.0542,
      "step": 41700
    },
    {
      "epoch": 2.8742350271608332,
      "grad_norm": 0.18326665461063385,
      "learning_rate": 4.10227868556546e-05,
      "loss": 0.0505,
      "step": 41800
    },
    {
      "epoch": 2.881111187512893,
      "grad_norm": 0.25205060839653015,
      "learning_rate": 4.100129793104634e-05,
      "loss": 0.0541,
      "step": 41900
    },
    {
      "epoch": 2.8879873478649523,
      "grad_norm": 0.13636821508407593,
      "learning_rate": 4.097980900643809e-05,
      "loss": 0.0548,
      "step": 42000
    },
    {
      "epoch": 2.8948635082170115,
      "grad_norm": 0.18406283855438232,
      "learning_rate": 4.0958320081829825e-05,
      "loss": 0.0551,
      "step": 42100
    },
    {
      "epoch": 2.9017396685690713,
      "grad_norm": 0.18755657970905304,
      "learning_rate": 4.0936831157221576e-05,
      "loss": 0.0518,
      "step": 42200
    },
    {
      "epoch": 2.9086158289211306,
      "grad_norm": 0.16796189546585083,
      "learning_rate": 4.091534223261331e-05,
      "loss": 0.0515,
      "step": 42300
    },
    {
      "epoch": 2.91549198927319,
      "grad_norm": 0.1384829580783844,
      "learning_rate": 4.0893853308005055e-05,
      "loss": 0.051,
      "step": 42400
    },
    {
      "epoch": 2.922368149625249,
      "grad_norm": 0.09395983815193176,
      "learning_rate": 4.08723643833968e-05,
      "loss": 0.0544,
      "step": 42500
    },
    {
      "epoch": 2.9292443099773084,
      "grad_norm": 0.14899015426635742,
      "learning_rate": 4.085087545878854e-05,
      "loss": 0.0552,
      "step": 42600
    },
    {
      "epoch": 2.936120470329368,
      "grad_norm": 0.14550679922103882,
      "learning_rate": 4.0829386534180285e-05,
      "loss": 0.0542,
      "step": 42700
    },
    {
      "epoch": 2.9429966306814275,
      "grad_norm": 0.09067992866039276,
      "learning_rate": 4.080789760957203e-05,
      "loss": 0.0516,
      "step": 42800
    },
    {
      "epoch": 2.9498727910334868,
      "grad_norm": 0.13607947528362274,
      "learning_rate": 4.078640868496377e-05,
      "loss": 0.0545,
      "step": 42900
    },
    {
      "epoch": 2.9567489513855465,
      "grad_norm": 0.14774514734745026,
      "learning_rate": 4.0764919760355515e-05,
      "loss": 0.057,
      "step": 43000
    },
    {
      "epoch": 2.963625111737606,
      "grad_norm": 0.086532361805439,
      "learning_rate": 4.074343083574726e-05,
      "loss": 0.0525,
      "step": 43100
    },
    {
      "epoch": 2.970501272089665,
      "grad_norm": 0.11789631098508835,
      "learning_rate": 4.0721941911139e-05,
      "loss": 0.0545,
      "step": 43200
    },
    {
      "epoch": 2.977377432441725,
      "grad_norm": 0.11365556716918945,
      "learning_rate": 4.0700452986530745e-05,
      "loss": 0.0519,
      "step": 43300
    },
    {
      "epoch": 2.984253592793784,
      "grad_norm": 0.14735010266304016,
      "learning_rate": 4.067917895116857e-05,
      "loss": 0.0524,
      "step": 43400
    },
    {
      "epoch": 2.9911297531458434,
      "grad_norm": 0.17661994695663452,
      "learning_rate": 4.065769002656031e-05,
      "loss": 0.0535,
      "step": 43500
    },
    {
      "epoch": 2.9980059134979027,
      "grad_norm": 0.16290320456027985,
      "learning_rate": 4.0636201101952055e-05,
      "loss": 0.0549,
      "step": 43600
    },
    {
      "epoch": 3.0,
      "eval_accuracy_macro_0.5": 0.9761220216751099,
      "eval_accuracy_micro_0.5": 0.9761220812797546,
      "eval_accuracy_weighted_0.5": 0.9731444716453552,
      "eval_f1_macro_0.5": 0.6463382244110107,
      "eval_f1_macro_0.6": 0.6013634204864502,
      "eval_f1_macro_0.7": 0.5386607646942139,
      "eval_f1_macro_0.8": 0.3076084554195404,
      "eval_f1_micro_0.5": 0.6598598957061768,
      "eval_f1_micro_0.6": 0.624825656414032,
      "eval_f1_micro_0.7": 0.5717728137969971,
      "eval_f1_micro_0.8": 0.4875621795654297,
      "eval_f1_micro_0.9": 0.33751797676086426,
      "eval_f1_weighted_0.5": 0.6421816945075989,
      "eval_f1_weighted_0.6": 0.5969181060791016,
      "eval_f1_weighted_0.7": 0.5337964296340942,
      "eval_f1_weighted_0.8": 0.29739776253700256,
      "eval_loss": 0.050199128687381744,
      "eval_runtime": 62.7761,
      "eval_samples_per_second": 462.549,
      "eval_steps_per_second": 57.825,
      "step": 43629
    },
    {
      "epoch": 3.004882073849962,
      "grad_norm": 0.14251302182674408,
      "learning_rate": 4.06147121773438e-05,
      "loss": 0.0544,
      "step": 43700
    },
    {
      "epoch": 3.0117582342020217,
      "grad_norm": 0.19438104331493378,
      "learning_rate": 4.059322325273554e-05,
      "loss": 0.0533,
      "step": 43800
    },
    {
      "epoch": 3.018634394554081,
      "grad_norm": 0.2706410884857178,
      "learning_rate": 4.0571734328127285e-05,
      "loss": 0.0526,
      "step": 43900
    },
    {
      "epoch": 3.0255105549061403,
      "grad_norm": 0.11358880996704102,
      "learning_rate": 4.055024540351903e-05,
      "loss": 0.0548,
      "step": 44000
    },
    {
      "epoch": 3.0323867152582,
      "grad_norm": 0.18464148044586182,
      "learning_rate": 4.052875647891077e-05,
      "loss": 0.0525,
      "step": 44100
    },
    {
      "epoch": 3.0392628756102593,
      "grad_norm": 0.17616808414459229,
      "learning_rate": 4.0507267554302515e-05,
      "loss": 0.0547,
      "step": 44200
    },
    {
      "epoch": 3.0461390359623186,
      "grad_norm": 0.1600044220685959,
      "learning_rate": 4.048577862969426e-05,
      "loss": 0.0517,
      "step": 44300
    },
    {
      "epoch": 3.053015196314378,
      "grad_norm": 0.1718231588602066,
      "learning_rate": 4.0464289705086e-05,
      "loss": 0.0537,
      "step": 44400
    },
    {
      "epoch": 3.0598913566664376,
      "grad_norm": 0.135597825050354,
      "learning_rate": 4.0442800780477745e-05,
      "loss": 0.0526,
      "step": 44500
    },
    {
      "epoch": 3.066767517018497,
      "grad_norm": 0.13561870157718658,
      "learning_rate": 4.042131185586949e-05,
      "loss": 0.0511,
      "step": 44600
    },
    {
      "epoch": 3.073643677370556,
      "grad_norm": 0.2626335024833679,
      "learning_rate": 4.0399822931261225e-05,
      "loss": 0.0541,
      "step": 44700
    },
    {
      "epoch": 3.0805198377226155,
      "grad_norm": 0.16591666638851166,
      "learning_rate": 4.0378334006652975e-05,
      "loss": 0.0516,
      "step": 44800
    },
    {
      "epoch": 3.0873959980746752,
      "grad_norm": 0.09658503532409668,
      "learning_rate": 4.035684508204471e-05,
      "loss": 0.0528,
      "step": 44900
    },
    {
      "epoch": 3.0942721584267345,
      "grad_norm": 0.18207965791225433,
      "learning_rate": 4.033535615743646e-05,
      "loss": 0.0548,
      "step": 45000
    },
    {
      "epoch": 3.101148318778794,
      "grad_norm": 0.14120769500732422,
      "learning_rate": 4.03138672328282e-05,
      "loss": 0.0518,
      "step": 45100
    },
    {
      "epoch": 3.1080244791308536,
      "grad_norm": 0.1084880605340004,
      "learning_rate": 4.029237830821995e-05,
      "loss": 0.053,
      "step": 45200
    },
    {
      "epoch": 3.114900639482913,
      "grad_norm": 0.15533669292926788,
      "learning_rate": 4.0270889383611685e-05,
      "loss": 0.0537,
      "step": 45300
    },
    {
      "epoch": 3.121776799834972,
      "grad_norm": 0.14741332828998566,
      "learning_rate": 4.0249615348249515e-05,
      "loss": 0.0527,
      "step": 45400
    },
    {
      "epoch": 3.1286529601870314,
      "grad_norm": 0.19412659108638763,
      "learning_rate": 4.022812642364125e-05,
      "loss": 0.0544,
      "step": 45500
    },
    {
      "epoch": 3.135529120539091,
      "grad_norm": 0.12344898283481598,
      "learning_rate": 4.0206637499033e-05,
      "loss": 0.0544,
      "step": 45600
    },
    {
      "epoch": 3.1424052808911505,
      "grad_norm": 0.07507273554801941,
      "learning_rate": 4.018514857442474e-05,
      "loss": 0.0514,
      "step": 45700
    },
    {
      "epoch": 3.1492814412432097,
      "grad_norm": 0.1883375197649002,
      "learning_rate": 4.016365964981649e-05,
      "loss": 0.0526,
      "step": 45800
    },
    {
      "epoch": 3.156157601595269,
      "grad_norm": 0.1439252346754074,
      "learning_rate": 4.0142170725208225e-05,
      "loss": 0.0526,
      "step": 45900
    },
    {
      "epoch": 3.1630337619473288,
      "grad_norm": 0.13199801743030548,
      "learning_rate": 4.0120681800599975e-05,
      "loss": 0.0528,
      "step": 46000
    },
    {
      "epoch": 3.169909922299388,
      "grad_norm": 0.14696818590164185,
      "learning_rate": 4.009919287599171e-05,
      "loss": 0.0545,
      "step": 46100
    },
    {
      "epoch": 3.1767860826514474,
      "grad_norm": 0.11061383038759232,
      "learning_rate": 4.007770395138346e-05,
      "loss": 0.051,
      "step": 46200
    },
    {
      "epoch": 3.1836622430035066,
      "grad_norm": 0.13934586942195892,
      "learning_rate": 4.00562150267752e-05,
      "loss": 0.0535,
      "step": 46300
    },
    {
      "epoch": 3.1905384033555664,
      "grad_norm": 0.19330626726150513,
      "learning_rate": 4.003472610216695e-05,
      "loss": 0.0506,
      "step": 46400
    },
    {
      "epoch": 3.1974145637076257,
      "grad_norm": 0.17771819233894348,
      "learning_rate": 4.0013237177558685e-05,
      "loss": 0.0529,
      "step": 46500
    },
    {
      "epoch": 3.204290724059685,
      "grad_norm": 0.15506963431835175,
      "learning_rate": 3.9991748252950435e-05,
      "loss": 0.0539,
      "step": 46600
    },
    {
      "epoch": 3.2111668844117442,
      "grad_norm": 0.09935854375362396,
      "learning_rate": 3.997025932834217e-05,
      "loss": 0.0539,
      "step": 46700
    },
    {
      "epoch": 3.218043044763804,
      "grad_norm": 0.1790647953748703,
      "learning_rate": 3.9948770403733915e-05,
      "loss": 0.053,
      "step": 46800
    },
    {
      "epoch": 3.2249192051158633,
      "grad_norm": 0.17527347803115845,
      "learning_rate": 3.992728147912566e-05,
      "loss": 0.0544,
      "step": 46900
    },
    {
      "epoch": 3.2317953654679226,
      "grad_norm": 0.23556722700595856,
      "learning_rate": 3.99057925545174e-05,
      "loss": 0.055,
      "step": 47000
    },
    {
      "epoch": 3.2386715258199823,
      "grad_norm": 0.2035091519355774,
      "learning_rate": 3.9884303629909145e-05,
      "loss": 0.0546,
      "step": 47100
    },
    {
      "epoch": 3.2455476861720416,
      "grad_norm": 0.16680724918842316,
      "learning_rate": 3.986281470530089e-05,
      "loss": 0.0533,
      "step": 47200
    },
    {
      "epoch": 3.252423846524101,
      "grad_norm": 0.18505802750587463,
      "learning_rate": 3.984132578069263e-05,
      "loss": 0.0526,
      "step": 47300
    },
    {
      "epoch": 3.25930000687616,
      "grad_norm": 0.1513855904340744,
      "learning_rate": 3.9819836856084375e-05,
      "loss": 0.0527,
      "step": 47400
    },
    {
      "epoch": 3.26617616722822,
      "grad_norm": 0.13022135198116302,
      "learning_rate": 3.979834793147612e-05,
      "loss": 0.0491,
      "step": 47500
    },
    {
      "epoch": 3.273052327580279,
      "grad_norm": 0.07641206681728363,
      "learning_rate": 3.977685900686786e-05,
      "loss": 0.0546,
      "step": 47600
    },
    {
      "epoch": 3.2799284879323385,
      "grad_norm": 0.2534351944923401,
      "learning_rate": 3.975558497150569e-05,
      "loss": 0.05,
      "step": 47700
    },
    {
      "epoch": 3.286804648284398,
      "grad_norm": 0.15655012428760529,
      "learning_rate": 3.973409604689743e-05,
      "loss": 0.0522,
      "step": 47800
    },
    {
      "epoch": 3.2936808086364575,
      "grad_norm": 0.1755714863538742,
      "learning_rate": 3.971260712228918e-05,
      "loss": 0.0515,
      "step": 47900
    },
    {
      "epoch": 3.300556968988517,
      "grad_norm": 0.11700046062469482,
      "learning_rate": 3.9691118197680915e-05,
      "loss": 0.0552,
      "step": 48000
    },
    {
      "epoch": 3.307433129340576,
      "grad_norm": 0.1691252589225769,
      "learning_rate": 3.9669629273072665e-05,
      "loss": 0.0551,
      "step": 48100
    },
    {
      "epoch": 3.314309289692636,
      "grad_norm": 0.2882348299026489,
      "learning_rate": 3.96481403484644e-05,
      "loss": 0.0527,
      "step": 48200
    },
    {
      "epoch": 3.321185450044695,
      "grad_norm": 0.16794107854366302,
      "learning_rate": 3.962665142385615e-05,
      "loss": 0.0499,
      "step": 48300
    },
    {
      "epoch": 3.3280616103967544,
      "grad_norm": 0.1630326211452484,
      "learning_rate": 3.960516249924789e-05,
      "loss": 0.052,
      "step": 48400
    },
    {
      "epoch": 3.3349377707488137,
      "grad_norm": 0.10137853026390076,
      "learning_rate": 3.958367357463964e-05,
      "loss": 0.0525,
      "step": 48500
    },
    {
      "epoch": 3.3418139311008734,
      "grad_norm": 0.15201103687286377,
      "learning_rate": 3.9562184650031375e-05,
      "loss": 0.0549,
      "step": 48600
    },
    {
      "epoch": 3.3486900914529327,
      "grad_norm": 0.09824050962924957,
      "learning_rate": 3.9540695725423125e-05,
      "loss": 0.0527,
      "step": 48700
    },
    {
      "epoch": 3.355566251804992,
      "grad_norm": 0.09053714573383331,
      "learning_rate": 3.951920680081486e-05,
      "loss": 0.0496,
      "step": 48800
    },
    {
      "epoch": 3.3624424121570513,
      "grad_norm": 0.1705183982849121,
      "learning_rate": 3.9497717876206605e-05,
      "loss": 0.0506,
      "step": 48900
    },
    {
      "epoch": 3.369318572509111,
      "grad_norm": 0.18626205623149872,
      "learning_rate": 3.947622895159835e-05,
      "loss": 0.0538,
      "step": 49000
    },
    {
      "epoch": 3.3761947328611703,
      "grad_norm": 0.16875185072422028,
      "learning_rate": 3.945474002699009e-05,
      "loss": 0.0531,
      "step": 49100
    },
    {
      "epoch": 3.3830708932132296,
      "grad_norm": 0.1318284124135971,
      "learning_rate": 3.9433251102381835e-05,
      "loss": 0.0501,
      "step": 49200
    },
    {
      "epoch": 3.3899470535652894,
      "grad_norm": 0.1053614392876625,
      "learning_rate": 3.941176217777358e-05,
      "loss": 0.0516,
      "step": 49300
    },
    {
      "epoch": 3.3968232139173486,
      "grad_norm": 0.13861727714538574,
      "learning_rate": 3.939027325316532e-05,
      "loss": 0.0532,
      "step": 49400
    },
    {
      "epoch": 3.403699374269408,
      "grad_norm": 0.15364564955234528,
      "learning_rate": 3.9368784328557065e-05,
      "loss": 0.0514,
      "step": 49500
    },
    {
      "epoch": 3.4105755346214672,
      "grad_norm": 0.2021990418434143,
      "learning_rate": 3.934729540394881e-05,
      "loss": 0.0534,
      "step": 49600
    },
    {
      "epoch": 3.417451694973527,
      "grad_norm": 0.1662241369485855,
      "learning_rate": 3.932580647934055e-05,
      "loss": 0.0509,
      "step": 49700
    },
    {
      "epoch": 3.4243278553255863,
      "grad_norm": 0.27079981565475464,
      "learning_rate": 3.9304532443978374e-05,
      "loss": 0.0537,
      "step": 49800
    },
    {
      "epoch": 3.4312040156776455,
      "grad_norm": 0.24217920005321503,
      "learning_rate": 3.928304351937012e-05,
      "loss": 0.0537,
      "step": 49900
    },
    {
      "epoch": 3.438080176029705,
      "grad_norm": 0.18492616713047028,
      "learning_rate": 3.926155459476186e-05,
      "loss": 0.051,
      "step": 50000
    },
    {
      "epoch": 3.4449563363817646,
      "grad_norm": 0.16820620000362396,
      "learning_rate": 3.9240065670153604e-05,
      "loss": 0.0508,
      "step": 50100
    },
    {
      "epoch": 3.451832496733824,
      "grad_norm": 0.18873783946037292,
      "learning_rate": 3.921857674554535e-05,
      "loss": 0.0521,
      "step": 50200
    },
    {
      "epoch": 3.458708657085883,
      "grad_norm": 0.1765349954366684,
      "learning_rate": 3.919708782093709e-05,
      "loss": 0.0528,
      "step": 50300
    },
    {
      "epoch": 3.465584817437943,
      "grad_norm": 0.17483878135681152,
      "learning_rate": 3.9175598896328834e-05,
      "loss": 0.0555,
      "step": 50400
    },
    {
      "epoch": 3.472460977790002,
      "grad_norm": 0.1349223405122757,
      "learning_rate": 3.915410997172058e-05,
      "loss": 0.0526,
      "step": 50500
    },
    {
      "epoch": 3.4793371381420615,
      "grad_norm": 0.16345176100730896,
      "learning_rate": 3.913262104711232e-05,
      "loss": 0.0521,
      "step": 50600
    },
    {
      "epoch": 3.4862132984941208,
      "grad_norm": 0.10047850757837296,
      "learning_rate": 3.9111132122504064e-05,
      "loss": 0.0553,
      "step": 50700
    },
    {
      "epoch": 3.49308945884618,
      "grad_norm": 0.13955038785934448,
      "learning_rate": 3.908964319789581e-05,
      "loss": 0.0514,
      "step": 50800
    },
    {
      "epoch": 3.49996561919824,
      "grad_norm": 0.13656437397003174,
      "learning_rate": 3.906815427328755e-05,
      "loss": 0.0533,
      "step": 50900
    },
    {
      "epoch": 3.506841779550299,
      "grad_norm": 0.1290580928325653,
      "learning_rate": 3.904666534867929e-05,
      "loss": 0.0508,
      "step": 51000
    },
    {
      "epoch": 3.5137179399023584,
      "grad_norm": 0.1316090226173401,
      "learning_rate": 3.902517642407104e-05,
      "loss": 0.052,
      "step": 51100
    },
    {
      "epoch": 3.520594100254418,
      "grad_norm": 0.18250150978565216,
      "learning_rate": 3.9003687499462774e-05,
      "loss": 0.0536,
      "step": 51200
    },
    {
      "epoch": 3.5274702606064774,
      "grad_norm": 0.15859892964363098,
      "learning_rate": 3.8982198574854524e-05,
      "loss": 0.0538,
      "step": 51300
    },
    {
      "epoch": 3.5343464209585367,
      "grad_norm": 0.12213633954524994,
      "learning_rate": 3.896070965024626e-05,
      "loss": 0.0506,
      "step": 51400
    },
    {
      "epoch": 3.5412225813105964,
      "grad_norm": 0.24854296445846558,
      "learning_rate": 3.893922072563801e-05,
      "loss": 0.0517,
      "step": 51500
    },
    {
      "epoch": 3.5480987416626557,
      "grad_norm": 0.1795700192451477,
      "learning_rate": 3.891773180102975e-05,
      "loss": 0.0554,
      "step": 51600
    },
    {
      "epoch": 3.554974902014715,
      "grad_norm": 0.16487011313438416,
      "learning_rate": 3.88962428764215e-05,
      "loss": 0.0552,
      "step": 51700
    },
    {
      "epoch": 3.5618510623667743,
      "grad_norm": 0.16777543723583221,
      "learning_rate": 3.8874753951813234e-05,
      "loss": 0.0525,
      "step": 51800
    },
    {
      "epoch": 3.5687272227188336,
      "grad_norm": 0.12677060067653656,
      "learning_rate": 3.8853479916451064e-05,
      "loss": 0.0528,
      "step": 51900
    },
    {
      "epoch": 3.5756033830708933,
      "grad_norm": 0.13131597638130188,
      "learning_rate": 3.88319909918428e-05,
      "loss": 0.051,
      "step": 52000
    },
    {
      "epoch": 3.5824795434229526,
      "grad_norm": 0.1312263309955597,
      "learning_rate": 3.881050206723455e-05,
      "loss": 0.053,
      "step": 52100
    },
    {
      "epoch": 3.589355703775012,
      "grad_norm": 0.23419930040836334,
      "learning_rate": 3.878901314262629e-05,
      "loss": 0.0525,
      "step": 52200
    },
    {
      "epoch": 3.5962318641270716,
      "grad_norm": 0.23855674266815186,
      "learning_rate": 3.876752421801804e-05,
      "loss": 0.0526,
      "step": 52300
    },
    {
      "epoch": 3.603108024479131,
      "grad_norm": 0.11428453773260117,
      "learning_rate": 3.8746035293409774e-05,
      "loss": 0.0524,
      "step": 52400
    },
    {
      "epoch": 3.60998418483119,
      "grad_norm": 0.1497580111026764,
      "learning_rate": 3.8724546368801524e-05,
      "loss": 0.0546,
      "step": 52500
    },
    {
      "epoch": 3.61686034518325,
      "grad_norm": 0.14433343708515167,
      "learning_rate": 3.870305744419326e-05,
      "loss": 0.0508,
      "step": 52600
    },
    {
      "epoch": 3.6237365055353092,
      "grad_norm": 0.16494904458522797,
      "learning_rate": 3.868156851958501e-05,
      "loss": 0.048,
      "step": 52700
    },
    {
      "epoch": 3.6306126658873685,
      "grad_norm": 0.1009729653596878,
      "learning_rate": 3.866007959497675e-05,
      "loss": 0.0544,
      "step": 52800
    },
    {
      "epoch": 3.637488826239428,
      "grad_norm": 0.1309482604265213,
      "learning_rate": 3.86385906703685e-05,
      "loss": 0.0517,
      "step": 52900
    },
    {
      "epoch": 3.644364986591487,
      "grad_norm": 0.11763926595449448,
      "learning_rate": 3.8617101745760234e-05,
      "loss": 0.0542,
      "step": 53000
    },
    {
      "epoch": 3.651241146943547,
      "grad_norm": 0.12172619998455048,
      "learning_rate": 3.859561282115198e-05,
      "loss": 0.0506,
      "step": 53100
    },
    {
      "epoch": 3.658117307295606,
      "grad_norm": 0.19863389432430267,
      "learning_rate": 3.857412389654372e-05,
      "loss": 0.0517,
      "step": 53200
    },
    {
      "epoch": 3.6649934676476654,
      "grad_norm": 0.16570821404457092,
      "learning_rate": 3.8552634971935464e-05,
      "loss": 0.0515,
      "step": 53300
    },
    {
      "epoch": 3.671869627999725,
      "grad_norm": 0.19437874853610992,
      "learning_rate": 3.853114604732721e-05,
      "loss": 0.0505,
      "step": 53400
    },
    {
      "epoch": 3.6787457883517845,
      "grad_norm": 0.11382671445608139,
      "learning_rate": 3.850965712271895e-05,
      "loss": 0.0519,
      "step": 53500
    },
    {
      "epoch": 3.6856219487038437,
      "grad_norm": 0.14552825689315796,
      "learning_rate": 3.8488168198110694e-05,
      "loss": 0.0495,
      "step": 53600
    },
    {
      "epoch": 3.692498109055903,
      "grad_norm": 0.12493253499269485,
      "learning_rate": 3.846667927350244e-05,
      "loss": 0.0509,
      "step": 53700
    },
    {
      "epoch": 3.6993742694079623,
      "grad_norm": 0.09847544878721237,
      "learning_rate": 3.844519034889418e-05,
      "loss": 0.0542,
      "step": 53800
    },
    {
      "epoch": 3.706250429760022,
      "grad_norm": 0.20671822130680084,
      "learning_rate": 3.842391631353201e-05,
      "loss": 0.0521,
      "step": 53900
    },
    {
      "epoch": 3.7131265901120813,
      "grad_norm": 0.2974126636981964,
      "learning_rate": 3.8402427388923754e-05,
      "loss": 0.0539,
      "step": 54000
    },
    {
      "epoch": 3.7200027504641406,
      "grad_norm": 0.130321204662323,
      "learning_rate": 3.838093846431549e-05,
      "loss": 0.0497,
      "step": 54100
    },
    {
      "epoch": 3.7268789108162004,
      "grad_norm": 0.15610484778881073,
      "learning_rate": 3.835944953970724e-05,
      "loss": 0.0502,
      "step": 54200
    },
    {
      "epoch": 3.7337550711682597,
      "grad_norm": 0.12724240124225616,
      "learning_rate": 3.833796061509898e-05,
      "loss": 0.0514,
      "step": 54300
    },
    {
      "epoch": 3.740631231520319,
      "grad_norm": 0.12789225578308105,
      "learning_rate": 3.831647169049073e-05,
      "loss": 0.0492,
      "step": 54400
    },
    {
      "epoch": 3.7475073918723787,
      "grad_norm": 0.14911101758480072,
      "learning_rate": 3.8294982765882464e-05,
      "loss": 0.0534,
      "step": 54500
    },
    {
      "epoch": 3.754383552224438,
      "grad_norm": 0.12725427746772766,
      "learning_rate": 3.8273493841274214e-05,
      "loss": 0.0501,
      "step": 54600
    },
    {
      "epoch": 3.7612597125764973,
      "grad_norm": 0.17494966089725494,
      "learning_rate": 3.825200491666595e-05,
      "loss": 0.0514,
      "step": 54700
    },
    {
      "epoch": 3.7681358729285566,
      "grad_norm": 0.16574956476688385,
      "learning_rate": 3.82305159920577e-05,
      "loss": 0.0522,
      "step": 54800
    },
    {
      "epoch": 3.775012033280616,
      "grad_norm": 0.13646797835826874,
      "learning_rate": 3.820902706744944e-05,
      "loss": 0.0479,
      "step": 54900
    },
    {
      "epoch": 3.7818881936326756,
      "grad_norm": 0.12380538135766983,
      "learning_rate": 3.818753814284119e-05,
      "loss": 0.0508,
      "step": 55000
    },
    {
      "epoch": 3.788764353984735,
      "grad_norm": 0.1309281587600708,
      "learning_rate": 3.8166049218232924e-05,
      "loss": 0.0518,
      "step": 55100
    },
    {
      "epoch": 3.795640514336794,
      "grad_norm": 0.0852176696062088,
      "learning_rate": 3.8144560293624674e-05,
      "loss": 0.0524,
      "step": 55200
    },
    {
      "epoch": 3.802516674688854,
      "grad_norm": 0.10752599686384201,
      "learning_rate": 3.812307136901641e-05,
      "loss": 0.0522,
      "step": 55300
    },
    {
      "epoch": 3.809392835040913,
      "grad_norm": 0.13172315061092377,
      "learning_rate": 3.8101582444408154e-05,
      "loss": 0.053,
      "step": 55400
    },
    {
      "epoch": 3.8162689953929725,
      "grad_norm": 0.16982655227184296,
      "learning_rate": 3.80800935197999e-05,
      "loss": 0.0532,
      "step": 55500
    },
    {
      "epoch": 3.823145155745032,
      "grad_norm": 0.17513440549373627,
      "learning_rate": 3.805860459519164e-05,
      "loss": 0.0534,
      "step": 55600
    },
    {
      "epoch": 3.8300213160970915,
      "grad_norm": 0.15694139897823334,
      "learning_rate": 3.8037115670583384e-05,
      "loss": 0.0509,
      "step": 55700
    },
    {
      "epoch": 3.836897476449151,
      "grad_norm": 0.14794987440109253,
      "learning_rate": 3.801562674597513e-05,
      "loss": 0.0485,
      "step": 55800
    },
    {
      "epoch": 3.84377363680121,
      "grad_norm": 0.2672375738620758,
      "learning_rate": 3.799413782136687e-05,
      "loss": 0.0478,
      "step": 55900
    },
    {
      "epoch": 3.8506497971532694,
      "grad_norm": 0.18566475808620453,
      "learning_rate": 3.79728637860047e-05,
      "loss": 0.0505,
      "step": 56000
    },
    {
      "epoch": 3.857525957505329,
      "grad_norm": 0.18531879782676697,
      "learning_rate": 3.795137486139644e-05,
      "loss": 0.0519,
      "step": 56100
    },
    {
      "epoch": 3.8644021178573884,
      "grad_norm": 0.2019948810338974,
      "learning_rate": 3.792988593678818e-05,
      "loss": 0.0522,
      "step": 56200
    },
    {
      "epoch": 3.8712782782094477,
      "grad_norm": 0.24083629250526428,
      "learning_rate": 3.7908397012179923e-05,
      "loss": 0.0519,
      "step": 56300
    },
    {
      "epoch": 3.8781544385615074,
      "grad_norm": 0.09052088111639023,
      "learning_rate": 3.788690808757167e-05,
      "loss": 0.049,
      "step": 56400
    },
    {
      "epoch": 3.8850305989135667,
      "grad_norm": 0.17039310932159424,
      "learning_rate": 3.786541916296341e-05,
      "loss": 0.0487,
      "step": 56500
    },
    {
      "epoch": 3.891906759265626,
      "grad_norm": 0.1533495932817459,
      "learning_rate": 3.7843930238355153e-05,
      "loss": 0.0544,
      "step": 56600
    },
    {
      "epoch": 3.8987829196176857,
      "grad_norm": 0.1442711353302002,
      "learning_rate": 3.78224413137469e-05,
      "loss": 0.0518,
      "step": 56700
    },
    {
      "epoch": 3.905659079969745,
      "grad_norm": 0.1794932633638382,
      "learning_rate": 3.780095238913864e-05,
      "loss": 0.0527,
      "step": 56800
    },
    {
      "epoch": 3.9125352403218043,
      "grad_norm": 0.1605965495109558,
      "learning_rate": 3.7779463464530383e-05,
      "loss": 0.0539,
      "step": 56900
    },
    {
      "epoch": 3.9194114006738636,
      "grad_norm": 0.15130621194839478,
      "learning_rate": 3.775797453992213e-05,
      "loss": 0.0478,
      "step": 57000
    },
    {
      "epoch": 3.926287561025923,
      "grad_norm": 0.15162277221679688,
      "learning_rate": 3.773648561531387e-05,
      "loss": 0.0518,
      "step": 57100
    },
    {
      "epoch": 3.9331637213779826,
      "grad_norm": 0.14176569879055023,
      "learning_rate": 3.7714996690705613e-05,
      "loss": 0.0528,
      "step": 57200
    },
    {
      "epoch": 3.940039881730042,
      "grad_norm": 0.16639360785484314,
      "learning_rate": 3.769350776609736e-05,
      "loss": 0.049,
      "step": 57300
    },
    {
      "epoch": 3.9469160420821012,
      "grad_norm": 0.1671019196510315,
      "learning_rate": 3.76720188414891e-05,
      "loss": 0.0497,
      "step": 57400
    },
    {
      "epoch": 3.953792202434161,
      "grad_norm": 0.1283215433359146,
      "learning_rate": 3.765052991688084e-05,
      "loss": 0.0514,
      "step": 57500
    },
    {
      "epoch": 3.9606683627862203,
      "grad_norm": 0.18452785909175873,
      "learning_rate": 3.762904099227259e-05,
      "loss": 0.0502,
      "step": 57600
    },
    {
      "epoch": 3.9675445231382795,
      "grad_norm": 0.22003139555454254,
      "learning_rate": 3.760755206766432e-05,
      "loss": 0.0503,
      "step": 57700
    },
    {
      "epoch": 3.974420683490339,
      "grad_norm": 0.18846207857131958,
      "learning_rate": 3.7586063143056073e-05,
      "loss": 0.0522,
      "step": 57800
    },
    {
      "epoch": 3.9812968438423986,
      "grad_norm": 0.16173264384269714,
      "learning_rate": 3.756457421844781e-05,
      "loss": 0.0492,
      "step": 57900
    },
    {
      "epoch": 3.988173004194458,
      "grad_norm": 0.09535633772611618,
      "learning_rate": 3.754308529383956e-05,
      "loss": 0.0492,
      "step": 58000
    },
    {
      "epoch": 3.995049164546517,
      "grad_norm": 0.20796456933021545,
      "learning_rate": 3.752181125847738e-05,
      "loss": 0.0521,
      "step": 58100
    },
    {
      "epoch": 4.0,
      "eval_accuracy_macro_0.5": 0.9770939350128174,
      "eval_accuracy_micro_0.5": 0.9770938754081726,
      "eval_accuracy_weighted_0.5": 0.9742618799209595,
      "eval_f1_macro_0.5": 0.6725471019744873,
      "eval_f1_macro_0.6": 0.6353512406349182,
      "eval_f1_macro_0.7": 0.5809637308120728,
      "eval_f1_macro_0.8": 0.35931098461151123,
      "eval_f1_micro_0.5": 0.6825084090232849,
      "eval_f1_micro_0.6": 0.6531389355659485,
      "eval_f1_micro_0.7": 0.6076434254646301,
      "eval_f1_micro_0.8": 0.5314371585845947,
      "eval_f1_micro_0.9": 0.3870234489440918,
      "eval_f1_weighted_0.5": 0.6693304777145386,
      "eval_f1_weighted_0.6": 0.6312174797058105,
      "eval_f1_weighted_0.7": 0.576155960559845,
      "eval_f1_weighted_0.8": 0.34565019607543945,
      "eval_loss": 0.04834230616688728,
      "eval_runtime": 62.902,
      "eval_samples_per_second": 461.623,
      "eval_steps_per_second": 57.709,
      "step": 58172
    },
    {
      "epoch": 4.001925324898576,
      "grad_norm": 0.133810356259346,
      "learning_rate": 3.7500322333869126e-05,
      "loss": 0.0513,
      "step": 58200
    },
    {
      "epoch": 4.008801485250636,
      "grad_norm": 0.14938096702098846,
      "learning_rate": 3.747883340926086e-05,
      "loss": 0.0511,
      "step": 58300
    },
    {
      "epoch": 4.015677645602695,
      "grad_norm": 0.14406004548072815,
      "learning_rate": 3.745734448465261e-05,
      "loss": 0.0511,
      "step": 58400
    },
    {
      "epoch": 4.022553805954755,
      "grad_norm": 0.06683545559644699,
      "learning_rate": 3.743585556004435e-05,
      "loss": 0.0555,
      "step": 58500
    },
    {
      "epoch": 4.0294299663068145,
      "grad_norm": 0.15949520468711853,
      "learning_rate": 3.74143666354361e-05,
      "loss": 0.0483,
      "step": 58600
    },
    {
      "epoch": 4.036306126658873,
      "grad_norm": 0.10993576794862747,
      "learning_rate": 3.7392877710827836e-05,
      "loss": 0.0506,
      "step": 58700
    },
    {
      "epoch": 4.043182287010933,
      "grad_norm": 0.12054933607578278,
      "learning_rate": 3.7371388786219586e-05,
      "loss": 0.0503,
      "step": 58800
    },
    {
      "epoch": 4.050058447362993,
      "grad_norm": 0.15504072606563568,
      "learning_rate": 3.734989986161132e-05,
      "loss": 0.0509,
      "step": 58900
    },
    {
      "epoch": 4.056934607715052,
      "grad_norm": 0.1272393763065338,
      "learning_rate": 3.732841093700307e-05,
      "loss": 0.0515,
      "step": 59000
    },
    {
      "epoch": 4.063810768067111,
      "grad_norm": 0.10193829238414764,
      "learning_rate": 3.730692201239481e-05,
      "loss": 0.0494,
      "step": 59100
    },
    {
      "epoch": 4.070686928419171,
      "grad_norm": 0.140699103474617,
      "learning_rate": 3.728543308778656e-05,
      "loss": 0.0516,
      "step": 59200
    },
    {
      "epoch": 4.07756308877123,
      "grad_norm": 0.2187952846288681,
      "learning_rate": 3.7263944163178296e-05,
      "loss": 0.0498,
      "step": 59300
    },
    {
      "epoch": 4.08443924912329,
      "grad_norm": 0.13708537817001343,
      "learning_rate": 3.7242455238570046e-05,
      "loss": 0.052,
      "step": 59400
    },
    {
      "epoch": 4.0913154094753486,
      "grad_norm": 0.13017240166664124,
      "learning_rate": 3.722096631396178e-05,
      "loss": 0.0493,
      "step": 59500
    },
    {
      "epoch": 4.098191569827408,
      "grad_norm": 0.10388081520795822,
      "learning_rate": 3.7199477389353526e-05,
      "loss": 0.0538,
      "step": 59600
    },
    {
      "epoch": 4.105067730179468,
      "grad_norm": 0.16056592762470245,
      "learning_rate": 3.717798846474527e-05,
      "loss": 0.0492,
      "step": 59700
    },
    {
      "epoch": 4.111943890531527,
      "grad_norm": 0.16876256465911865,
      "learning_rate": 3.715649954013701e-05,
      "loss": 0.0547,
      "step": 59800
    },
    {
      "epoch": 4.118820050883587,
      "grad_norm": 0.12115185707807541,
      "learning_rate": 3.7135010615528756e-05,
      "loss": 0.0513,
      "step": 59900
    },
    {
      "epoch": 4.125696211235646,
      "grad_norm": 0.13006141781806946,
      "learning_rate": 3.71135216909205e-05,
      "loss": 0.0512,
      "step": 60000
    },
    {
      "epoch": 4.132572371587705,
      "grad_norm": 0.13570410013198853,
      "learning_rate": 3.709203276631224e-05,
      "loss": 0.0508,
      "step": 60100
    },
    {
      "epoch": 4.139448531939765,
      "grad_norm": 0.1185213252902031,
      "learning_rate": 3.7070543841703986e-05,
      "loss": 0.0487,
      "step": 60200
    },
    {
      "epoch": 4.146324692291825,
      "grad_norm": 0.1622881293296814,
      "learning_rate": 3.704905491709573e-05,
      "loss": 0.0495,
      "step": 60300
    },
    {
      "epoch": 4.1532008526438835,
      "grad_norm": 0.21340838074684143,
      "learning_rate": 3.702756599248747e-05,
      "loss": 0.0512,
      "step": 60400
    },
    {
      "epoch": 4.160077012995943,
      "grad_norm": 0.13680027425289154,
      "learning_rate": 3.70062919571253e-05,
      "loss": 0.0513,
      "step": 60500
    },
    {
      "epoch": 4.166953173348002,
      "grad_norm": 0.12270736694335938,
      "learning_rate": 3.698480303251704e-05,
      "loss": 0.0483,
      "step": 60600
    },
    {
      "epoch": 4.173829333700062,
      "grad_norm": 0.14563903212547302,
      "learning_rate": 3.696331410790879e-05,
      "loss": 0.0484,
      "step": 60700
    },
    {
      "epoch": 4.1807054940521216,
      "grad_norm": 0.2047850638628006,
      "learning_rate": 3.6941825183300526e-05,
      "loss": 0.0501,
      "step": 60800
    },
    {
      "epoch": 4.18758165440418,
      "grad_norm": 0.170771986246109,
      "learning_rate": 3.6920336258692276e-05,
      "loss": 0.0526,
      "step": 60900
    },
    {
      "epoch": 4.19445781475624,
      "grad_norm": 0.1779286116361618,
      "learning_rate": 3.689884733408401e-05,
      "loss": 0.051,
      "step": 61000
    },
    {
      "epoch": 4.2013339751083,
      "grad_norm": 0.07720472663640976,
      "learning_rate": 3.687735840947576e-05,
      "loss": 0.0513,
      "step": 61100
    },
    {
      "epoch": 4.208210135460359,
      "grad_norm": 0.1811184138059616,
      "learning_rate": 3.68558694848675e-05,
      "loss": 0.0508,
      "step": 61200
    },
    {
      "epoch": 4.2150862958124184,
      "grad_norm": 0.1628207266330719,
      "learning_rate": 3.683438056025925e-05,
      "loss": 0.0483,
      "step": 61300
    },
    {
      "epoch": 4.221962456164478,
      "grad_norm": 0.12238848954439163,
      "learning_rate": 3.6812891635650986e-05,
      "loss": 0.051,
      "step": 61400
    },
    {
      "epoch": 4.228838616516537,
      "grad_norm": 0.20807050168514252,
      "learning_rate": 3.6791402711042736e-05,
      "loss": 0.0503,
      "step": 61500
    },
    {
      "epoch": 4.235714776868597,
      "grad_norm": 0.14425979554653168,
      "learning_rate": 3.676991378643447e-05,
      "loss": 0.0536,
      "step": 61600
    },
    {
      "epoch": 4.242590937220656,
      "grad_norm": 0.22581033408641815,
      "learning_rate": 3.6748424861826216e-05,
      "loss": 0.0508,
      "step": 61700
    },
    {
      "epoch": 4.249467097572715,
      "grad_norm": 0.1649523675441742,
      "learning_rate": 3.672693593721796e-05,
      "loss": 0.05,
      "step": 61800
    },
    {
      "epoch": 4.256343257924775,
      "grad_norm": 0.15406666696071625,
      "learning_rate": 3.67054470126097e-05,
      "loss": 0.052,
      "step": 61900
    },
    {
      "epoch": 4.263219418276834,
      "grad_norm": 0.11081624031066895,
      "learning_rate": 3.6683958088001446e-05,
      "loss": 0.0551,
      "step": 62000
    },
    {
      "epoch": 4.270095578628894,
      "grad_norm": 0.21754847466945648,
      "learning_rate": 3.666246916339319e-05,
      "loss": 0.0503,
      "step": 62100
    },
    {
      "epoch": 4.276971738980953,
      "grad_norm": 0.13147053122520447,
      "learning_rate": 3.664098023878493e-05,
      "loss": 0.0475,
      "step": 62200
    },
    {
      "epoch": 4.283847899333012,
      "grad_norm": 0.13632924854755402,
      "learning_rate": 3.6619491314176676e-05,
      "loss": 0.0503,
      "step": 62300
    },
    {
      "epoch": 4.290724059685072,
      "grad_norm": 0.1427181214094162,
      "learning_rate": 3.659800238956842e-05,
      "loss": 0.0516,
      "step": 62400
    },
    {
      "epoch": 4.297600220037131,
      "grad_norm": 0.07341683655977249,
      "learning_rate": 3.657651346496016e-05,
      "loss": 0.0481,
      "step": 62500
    },
    {
      "epoch": 4.304476380389191,
      "grad_norm": 0.14672037959098816,
      "learning_rate": 3.6555239429597986e-05,
      "loss": 0.0525,
      "step": 62600
    },
    {
      "epoch": 4.31135254074125,
      "grad_norm": 0.18433281779289246,
      "learning_rate": 3.653375050498973e-05,
      "loss": 0.0511,
      "step": 62700
    },
    {
      "epoch": 4.318228701093309,
      "grad_norm": 0.12606947124004364,
      "learning_rate": 3.651226158038147e-05,
      "loss": 0.0507,
      "step": 62800
    },
    {
      "epoch": 4.325104861445369,
      "grad_norm": 0.14818862080574036,
      "learning_rate": 3.6490772655773216e-05,
      "loss": 0.0492,
      "step": 62900
    },
    {
      "epoch": 4.331981021797429,
      "grad_norm": 0.1208372637629509,
      "learning_rate": 3.646928373116496e-05,
      "loss": 0.05,
      "step": 63000
    },
    {
      "epoch": 4.3388571821494875,
      "grad_norm": 0.12471012771129608,
      "learning_rate": 3.64477948065567e-05,
      "loss": 0.0502,
      "step": 63100
    },
    {
      "epoch": 4.345733342501547,
      "grad_norm": 0.20895513892173767,
      "learning_rate": 3.6426305881948446e-05,
      "loss": 0.0513,
      "step": 63200
    },
    {
      "epoch": 4.352609502853607,
      "grad_norm": 0.1919969916343689,
      "learning_rate": 3.640481695734019e-05,
      "loss": 0.0481,
      "step": 63300
    },
    {
      "epoch": 4.359485663205666,
      "grad_norm": 0.23530961573123932,
      "learning_rate": 3.638332803273193e-05,
      "loss": 0.0502,
      "step": 63400
    },
    {
      "epoch": 4.3663618235577255,
      "grad_norm": 0.251803994178772,
      "learning_rate": 3.6361839108123676e-05,
      "loss": 0.051,
      "step": 63500
    },
    {
      "epoch": 4.373237983909785,
      "grad_norm": 0.26120811700820923,
      "learning_rate": 3.634035018351542e-05,
      "loss": 0.0546,
      "step": 63600
    },
    {
      "epoch": 4.380114144261844,
      "grad_norm": 0.1664675623178482,
      "learning_rate": 3.631886125890716e-05,
      "loss": 0.0538,
      "step": 63700
    },
    {
      "epoch": 4.386990304613904,
      "grad_norm": 0.25094664096832275,
      "learning_rate": 3.62973723342989e-05,
      "loss": 0.0511,
      "step": 63800
    },
    {
      "epoch": 4.393866464965963,
      "grad_norm": 0.14210163056850433,
      "learning_rate": 3.627588340969065e-05,
      "loss": 0.0508,
      "step": 63900
    },
    {
      "epoch": 4.400742625318022,
      "grad_norm": 0.17121680080890656,
      "learning_rate": 3.6254394485082386e-05,
      "loss": 0.0501,
      "step": 64000
    },
    {
      "epoch": 4.407618785670082,
      "grad_norm": 0.11660328507423401,
      "learning_rate": 3.6232905560474136e-05,
      "loss": 0.0481,
      "step": 64100
    },
    {
      "epoch": 4.414494946022141,
      "grad_norm": 0.18125800788402557,
      "learning_rate": 3.621141663586587e-05,
      "loss": 0.0509,
      "step": 64200
    },
    {
      "epoch": 4.421371106374201,
      "grad_norm": 0.17595174908638,
      "learning_rate": 3.618992771125762e-05,
      "loss": 0.0529,
      "step": 64300
    },
    {
      "epoch": 4.4282472667262605,
      "grad_norm": 0.13907216489315033,
      "learning_rate": 3.616843878664936e-05,
      "loss": 0.0489,
      "step": 64400
    },
    {
      "epoch": 4.435123427078319,
      "grad_norm": 0.13167987763881683,
      "learning_rate": 3.614694986204111e-05,
      "loss": 0.0499,
      "step": 64500
    },
    {
      "epoch": 4.441999587430379,
      "grad_norm": 0.28559932112693787,
      "learning_rate": 3.612567582667893e-05,
      "loss": 0.0487,
      "step": 64600
    },
    {
      "epoch": 4.448875747782438,
      "grad_norm": 0.15624234080314636,
      "learning_rate": 3.6104186902070676e-05,
      "loss": 0.0493,
      "step": 64700
    },
    {
      "epoch": 4.455751908134498,
      "grad_norm": 0.15317565202713013,
      "learning_rate": 3.608269797746241e-05,
      "loss": 0.0503,
      "step": 64800
    },
    {
      "epoch": 4.462628068486557,
      "grad_norm": 0.266327440738678,
      "learning_rate": 3.606120905285416e-05,
      "loss": 0.051,
      "step": 64900
    },
    {
      "epoch": 4.469504228838616,
      "grad_norm": 0.1860257089138031,
      "learning_rate": 3.60397201282459e-05,
      "loss": 0.0491,
      "step": 65000
    },
    {
      "epoch": 4.476380389190676,
      "grad_norm": 0.1773332953453064,
      "learning_rate": 3.601823120363765e-05,
      "loss": 0.0518,
      "step": 65100
    },
    {
      "epoch": 4.483256549542736,
      "grad_norm": 0.20010286569595337,
      "learning_rate": 3.5996742279029385e-05,
      "loss": 0.0512,
      "step": 65200
    },
    {
      "epoch": 4.4901327098947945,
      "grad_norm": 0.13875937461853027,
      "learning_rate": 3.5975253354421136e-05,
      "loss": 0.0511,
      "step": 65300
    },
    {
      "epoch": 4.497008870246854,
      "grad_norm": 0.1987772285938263,
      "learning_rate": 3.595376442981287e-05,
      "loss": 0.0495,
      "step": 65400
    },
    {
      "epoch": 4.503885030598914,
      "grad_norm": 0.1228734627366066,
      "learning_rate": 3.593227550520462e-05,
      "loss": 0.051,
      "step": 65500
    },
    {
      "epoch": 4.510761190950973,
      "grad_norm": 0.2316194474697113,
      "learning_rate": 3.591078658059636e-05,
      "loss": 0.0505,
      "step": 65600
    },
    {
      "epoch": 4.517637351303033,
      "grad_norm": 0.18089891970157623,
      "learning_rate": 3.588929765598811e-05,
      "loss": 0.0518,
      "step": 65700
    },
    {
      "epoch": 4.524513511655091,
      "grad_norm": 0.1656656563282013,
      "learning_rate": 3.5867808731379845e-05,
      "loss": 0.0505,
      "step": 65800
    },
    {
      "epoch": 4.531389672007151,
      "grad_norm": 0.14557991921901703,
      "learning_rate": 3.5846319806771596e-05,
      "loss": 0.0481,
      "step": 65900
    },
    {
      "epoch": 4.538265832359211,
      "grad_norm": 0.11577475816011429,
      "learning_rate": 3.582483088216333e-05,
      "loss": 0.0486,
      "step": 66000
    },
    {
      "epoch": 4.54514199271127,
      "grad_norm": 0.2292284369468689,
      "learning_rate": 3.5803341957555075e-05,
      "loss": 0.0521,
      "step": 66100
    },
    {
      "epoch": 4.5520181530633295,
      "grad_norm": 0.15493755042552948,
      "learning_rate": 3.578185303294682e-05,
      "loss": 0.0523,
      "step": 66200
    },
    {
      "epoch": 4.558894313415389,
      "grad_norm": 0.13797025382518768,
      "learning_rate": 3.576036410833856e-05,
      "loss": 0.0509,
      "step": 66300
    },
    {
      "epoch": 4.565770473767448,
      "grad_norm": 0.17872534692287445,
      "learning_rate": 3.5738875183730305e-05,
      "loss": 0.0501,
      "step": 66400
    },
    {
      "epoch": 4.572646634119508,
      "grad_norm": 0.21553388237953186,
      "learning_rate": 3.571738625912205e-05,
      "loss": 0.0493,
      "step": 66500
    },
    {
      "epoch": 4.579522794471567,
      "grad_norm": 0.13834580779075623,
      "learning_rate": 3.569589733451379e-05,
      "loss": 0.0497,
      "step": 66600
    },
    {
      "epoch": 4.586398954823626,
      "grad_norm": 0.21933399140834808,
      "learning_rate": 3.567462329915162e-05,
      "loss": 0.0497,
      "step": 66700
    },
    {
      "epoch": 4.593275115175686,
      "grad_norm": 0.17860758304595947,
      "learning_rate": 3.5653134374543365e-05,
      "loss": 0.0513,
      "step": 66800
    },
    {
      "epoch": 4.600151275527745,
      "grad_norm": 0.1467457413673401,
      "learning_rate": 3.56316454499351e-05,
      "loss": 0.0495,
      "step": 66900
    },
    {
      "epoch": 4.607027435879805,
      "grad_norm": 0.25744521617889404,
      "learning_rate": 3.561015652532685e-05,
      "loss": 0.0492,
      "step": 67000
    },
    {
      "epoch": 4.613903596231864,
      "grad_norm": 0.16467836499214172,
      "learning_rate": 3.558866760071859e-05,
      "loss": 0.0517,
      "step": 67100
    },
    {
      "epoch": 4.620779756583923,
      "grad_norm": 0.16026610136032104,
      "learning_rate": 3.556717867611034e-05,
      "loss": 0.0503,
      "step": 67200
    },
    {
      "epoch": 4.627655916935983,
      "grad_norm": 0.13422131538391113,
      "learning_rate": 3.5545689751502075e-05,
      "loss": 0.0509,
      "step": 67300
    },
    {
      "epoch": 4.634532077288043,
      "grad_norm": 0.1865978240966797,
      "learning_rate": 3.5524200826893825e-05,
      "loss": 0.0512,
      "step": 67400
    },
    {
      "epoch": 4.641408237640102,
      "grad_norm": 0.2195253223180771,
      "learning_rate": 3.550271190228556e-05,
      "loss": 0.0488,
      "step": 67500
    },
    {
      "epoch": 4.648284397992161,
      "grad_norm": 0.09912558645009995,
      "learning_rate": 3.548122297767731e-05,
      "loss": 0.0489,
      "step": 67600
    },
    {
      "epoch": 4.655160558344221,
      "grad_norm": 0.2573586106300354,
      "learning_rate": 3.545973405306905e-05,
      "loss": 0.0494,
      "step": 67700
    },
    {
      "epoch": 4.66203671869628,
      "grad_norm": 0.16328079998493195,
      "learning_rate": 3.54382451284608e-05,
      "loss": 0.0501,
      "step": 67800
    },
    {
      "epoch": 4.66891287904834,
      "grad_norm": 0.21197302639484406,
      "learning_rate": 3.5416756203852535e-05,
      "loss": 0.0522,
      "step": 67900
    },
    {
      "epoch": 4.6757890394003985,
      "grad_norm": 0.21736450493335724,
      "learning_rate": 3.539526727924428e-05,
      "loss": 0.0499,
      "step": 68000
    },
    {
      "epoch": 4.682665199752458,
      "grad_norm": 0.1117681935429573,
      "learning_rate": 3.537377835463602e-05,
      "loss": 0.0515,
      "step": 68100
    },
    {
      "epoch": 4.689541360104518,
      "grad_norm": 0.1444932222366333,
      "learning_rate": 3.5352289430027765e-05,
      "loss": 0.0479,
      "step": 68200
    },
    {
      "epoch": 4.696417520456577,
      "grad_norm": 0.15248598158359528,
      "learning_rate": 3.533080050541951e-05,
      "loss": 0.0493,
      "step": 68300
    },
    {
      "epoch": 4.7032936808086365,
      "grad_norm": 0.1725781261920929,
      "learning_rate": 3.530931158081125e-05,
      "loss": 0.0497,
      "step": 68400
    },
    {
      "epoch": 4.710169841160695,
      "grad_norm": 0.14180541038513184,
      "learning_rate": 3.5287822656202995e-05,
      "loss": 0.0503,
      "step": 68500
    },
    {
      "epoch": 4.717046001512755,
      "grad_norm": 0.13986647129058838,
      "learning_rate": 3.526633373159474e-05,
      "loss": 0.0472,
      "step": 68600
    },
    {
      "epoch": 4.723922161864815,
      "grad_norm": 0.09412065148353577,
      "learning_rate": 3.524484480698648e-05,
      "loss": 0.0499,
      "step": 68700
    },
    {
      "epoch": 4.730798322216874,
      "grad_norm": 0.1653861105442047,
      "learning_rate": 3.5223355882378225e-05,
      "loss": 0.0501,
      "step": 68800
    },
    {
      "epoch": 4.737674482568933,
      "grad_norm": 0.14885208010673523,
      "learning_rate": 3.520208184701605e-05,
      "loss": 0.0475,
      "step": 68900
    },
    {
      "epoch": 4.744550642920993,
      "grad_norm": 0.17335684597492218,
      "learning_rate": 3.518059292240779e-05,
      "loss": 0.0499,
      "step": 69000
    },
    {
      "epoch": 4.751426803273052,
      "grad_norm": 0.11618622392416,
      "learning_rate": 3.5159103997799535e-05,
      "loss": 0.0474,
      "step": 69100
    },
    {
      "epoch": 4.758302963625112,
      "grad_norm": 0.14482343196868896,
      "learning_rate": 3.513761507319128e-05,
      "loss": 0.0494,
      "step": 69200
    },
    {
      "epoch": 4.7651791239771715,
      "grad_norm": 0.12548357248306274,
      "learning_rate": 3.511612614858302e-05,
      "loss": 0.0502,
      "step": 69300
    },
    {
      "epoch": 4.77205528432923,
      "grad_norm": 0.19763925671577454,
      "learning_rate": 3.5094637223974765e-05,
      "loss": 0.05,
      "step": 69400
    },
    {
      "epoch": 4.77893144468129,
      "grad_norm": 0.15213409066200256,
      "learning_rate": 3.507314829936651e-05,
      "loss": 0.0516,
      "step": 69500
    },
    {
      "epoch": 4.78580760503335,
      "grad_norm": 0.1708369106054306,
      "learning_rate": 3.505165937475825e-05,
      "loss": 0.0491,
      "step": 69600
    },
    {
      "epoch": 4.792683765385409,
      "grad_norm": 0.09707766771316528,
      "learning_rate": 3.5030170450149995e-05,
      "loss": 0.0495,
      "step": 69700
    },
    {
      "epoch": 4.799559925737468,
      "grad_norm": 0.15652918815612793,
      "learning_rate": 3.500868152554174e-05,
      "loss": 0.0474,
      "step": 69800
    },
    {
      "epoch": 4.806436086089528,
      "grad_norm": 0.16882698237895966,
      "learning_rate": 3.498719260093348e-05,
      "loss": 0.051,
      "step": 69900
    },
    {
      "epoch": 4.813312246441587,
      "grad_norm": 0.27756965160369873,
      "learning_rate": 3.4965703676325225e-05,
      "loss": 0.0504,
      "step": 70000
    },
    {
      "epoch": 4.820188406793647,
      "grad_norm": 0.19492289423942566,
      "learning_rate": 3.494421475171697e-05,
      "loss": 0.0494,
      "step": 70100
    },
    {
      "epoch": 4.8270645671457055,
      "grad_norm": 0.17864076793193817,
      "learning_rate": 3.492272582710871e-05,
      "loss": 0.0512,
      "step": 70200
    },
    {
      "epoch": 4.833940727497765,
      "grad_norm": 0.17570187151432037,
      "learning_rate": 3.490123690250045e-05,
      "loss": 0.0505,
      "step": 70300
    },
    {
      "epoch": 4.840816887849825,
      "grad_norm": 0.14299482107162476,
      "learning_rate": 3.48797479778922e-05,
      "loss": 0.0471,
      "step": 70400
    },
    {
      "epoch": 4.847693048201884,
      "grad_norm": 0.19616757333278656,
      "learning_rate": 3.4858259053283935e-05,
      "loss": 0.054,
      "step": 70500
    },
    {
      "epoch": 4.854569208553944,
      "grad_norm": 0.0786808580160141,
      "learning_rate": 3.4836770128675685e-05,
      "loss": 0.0528,
      "step": 70600
    },
    {
      "epoch": 4.861445368906002,
      "grad_norm": 0.21841566264629364,
      "learning_rate": 3.481528120406742e-05,
      "loss": 0.052,
      "step": 70700
    },
    {
      "epoch": 4.868321529258062,
      "grad_norm": 0.21127071976661682,
      "learning_rate": 3.479379227945917e-05,
      "loss": 0.0463,
      "step": 70800
    },
    {
      "epoch": 4.875197689610122,
      "grad_norm": 0.1176450327038765,
      "learning_rate": 3.4772518244096995e-05,
      "loss": 0.0506,
      "step": 70900
    },
    {
      "epoch": 4.882073849962181,
      "grad_norm": 0.10390985757112503,
      "learning_rate": 3.475102931948874e-05,
      "loss": 0.0523,
      "step": 71000
    },
    {
      "epoch": 4.8889500103142405,
      "grad_norm": 0.21099123358726501,
      "learning_rate": 3.4729540394880475e-05,
      "loss": 0.0481,
      "step": 71100
    },
    {
      "epoch": 4.8958261706663,
      "grad_norm": 0.09716341644525528,
      "learning_rate": 3.4708051470272225e-05,
      "loss": 0.0537,
      "step": 71200
    },
    {
      "epoch": 4.902702331018359,
      "grad_norm": 0.18684068322181702,
      "learning_rate": 3.468656254566396e-05,
      "loss": 0.0527,
      "step": 71300
    },
    {
      "epoch": 4.909578491370419,
      "grad_norm": 0.16042539477348328,
      "learning_rate": 3.466507362105571e-05,
      "loss": 0.0482,
      "step": 71400
    },
    {
      "epoch": 4.9164546517224785,
      "grad_norm": 0.15939956903457642,
      "learning_rate": 3.464358469644745e-05,
      "loss": 0.0495,
      "step": 71500
    },
    {
      "epoch": 4.923330812074537,
      "grad_norm": 0.2123432606458664,
      "learning_rate": 3.46220957718392e-05,
      "loss": 0.052,
      "step": 71600
    },
    {
      "epoch": 4.930206972426597,
      "grad_norm": 0.1841231733560562,
      "learning_rate": 3.4600606847230935e-05,
      "loss": 0.0511,
      "step": 71700
    },
    {
      "epoch": 4.937083132778657,
      "grad_norm": 0.20420920848846436,
      "learning_rate": 3.4579117922622685e-05,
      "loss": 0.0509,
      "step": 71800
    },
    {
      "epoch": 4.943959293130716,
      "grad_norm": 0.2004980593919754,
      "learning_rate": 3.455762899801442e-05,
      "loss": 0.0493,
      "step": 71900
    },
    {
      "epoch": 4.950835453482775,
      "grad_norm": 0.09073447436094284,
      "learning_rate": 3.453614007340617e-05,
      "loss": 0.0492,
      "step": 72000
    },
    {
      "epoch": 4.957711613834834,
      "grad_norm": 0.24298927187919617,
      "learning_rate": 3.451465114879791e-05,
      "loss": 0.0476,
      "step": 72100
    },
    {
      "epoch": 4.964587774186894,
      "grad_norm": 0.1152191311120987,
      "learning_rate": 3.449316222418966e-05,
      "loss": 0.0499,
      "step": 72200
    },
    {
      "epoch": 4.971463934538954,
      "grad_norm": 0.12162233144044876,
      "learning_rate": 3.4471673299581395e-05,
      "loss": 0.0486,
      "step": 72300
    },
    {
      "epoch": 4.978340094891013,
      "grad_norm": 0.2171221822500229,
      "learning_rate": 3.445018437497314e-05,
      "loss": 0.0474,
      "step": 72400
    },
    {
      "epoch": 4.985216255243072,
      "grad_norm": 0.15565401315689087,
      "learning_rate": 3.442869545036488e-05,
      "loss": 0.0511,
      "step": 72500
    },
    {
      "epoch": 4.992092415595132,
      "grad_norm": 0.2510625720024109,
      "learning_rate": 3.4407206525756625e-05,
      "loss": 0.0501,
      "step": 72600
    },
    {
      "epoch": 4.998968575947191,
      "grad_norm": 0.22459129989147186,
      "learning_rate": 3.438571760114837e-05,
      "loss": 0.0503,
      "step": 72700
    },
    {
      "epoch": 5.0,
      "eval_accuracy_macro_0.5": 0.9777503609657288,
      "eval_accuracy_micro_0.5": 0.9777503609657288,
      "eval_accuracy_weighted_0.5": 0.9749751687049866,
      "eval_f1_macro_0.5": 0.6852817535400391,
      "eval_f1_macro_0.6": 0.6519308090209961,
      "eval_f1_macro_0.7": 0.6026504635810852,
      "eval_f1_macro_0.8": 0.3906247317790985,
      "eval_f1_micro_0.5": 0.694198727607727,
      "eval_f1_micro_0.6": 0.6683556437492371,
      "eval_f1_micro_0.7": 0.6266565918922424,
      "eval_f1_micro_0.8": 0.5542096495628357,
      "eval_f1_micro_0.9": 0.4190216362476349,
      "eval_f1_weighted_0.5": 0.6827059984207153,
      "eval_f1_weighted_0.6": 0.6488823890686035,
      "eval_f1_weighted_0.7": 0.5976901054382324,
      "eval_f1_weighted_0.8": 0.37717488408088684,
      "eval_loss": 0.046776898205280304,
      "eval_runtime": 62.9073,
      "eval_samples_per_second": 461.584,
      "eval_steps_per_second": 57.704,
      "step": 72715
    },
    {
      "epoch": 5.005844736299251,
      "grad_norm": 0.13123735785484314,
      "learning_rate": 3.436422867654011e-05,
      "loss": 0.05,
      "step": 72800
    },
    {
      "epoch": 5.0127208966513095,
      "grad_norm": 0.16097845137119293,
      "learning_rate": 3.4342739751931855e-05,
      "loss": 0.047,
      "step": 72900
    },
    {
      "epoch": 5.019597057003369,
      "grad_norm": 0.1806558072566986,
      "learning_rate": 3.43212508273236e-05,
      "loss": 0.0485,
      "step": 73000
    },
    {
      "epoch": 5.026473217355429,
      "grad_norm": 0.17444176971912384,
      "learning_rate": 3.429997679196143e-05,
      "loss": 0.0519,
      "step": 73100
    },
    {
      "epoch": 5.033349377707488,
      "grad_norm": 0.16284054517745972,
      "learning_rate": 3.4278487867353164e-05,
      "loss": 0.0494,
      "step": 73200
    },
    {
      "epoch": 5.0402255380595475,
      "grad_norm": 0.2440710812807083,
      "learning_rate": 3.4256998942744914e-05,
      "loss": 0.0454,
      "step": 73300
    },
    {
      "epoch": 5.047101698411607,
      "grad_norm": 0.14046089351177216,
      "learning_rate": 3.423551001813665e-05,
      "loss": 0.0481,
      "step": 73400
    },
    {
      "epoch": 5.053977858763666,
      "grad_norm": 0.1695546954870224,
      "learning_rate": 3.42140210935284e-05,
      "loss": 0.0485,
      "step": 73500
    },
    {
      "epoch": 5.060854019115726,
      "grad_norm": 0.18056997656822205,
      "learning_rate": 3.419253216892014e-05,
      "loss": 0.0518,
      "step": 73600
    },
    {
      "epoch": 5.067730179467786,
      "grad_norm": 0.17920105159282684,
      "learning_rate": 3.417104324431189e-05,
      "loss": 0.0503,
      "step": 73700
    },
    {
      "epoch": 5.074606339819844,
      "grad_norm": 0.16265764832496643,
      "learning_rate": 3.4149554319703624e-05,
      "loss": 0.0504,
      "step": 73800
    },
    {
      "epoch": 5.081482500171904,
      "grad_norm": 0.238305002450943,
      "learning_rate": 3.4128065395095374e-05,
      "loss": 0.0496,
      "step": 73900
    },
    {
      "epoch": 5.088358660523963,
      "grad_norm": 0.10819635540246964,
      "learning_rate": 3.410657647048711e-05,
      "loss": 0.05,
      "step": 74000
    },
    {
      "epoch": 5.095234820876023,
      "grad_norm": 0.1743188351392746,
      "learning_rate": 3.4085087545878854e-05,
      "loss": 0.0497,
      "step": 74100
    },
    {
      "epoch": 5.1021109812280825,
      "grad_norm": 0.16468806564807892,
      "learning_rate": 3.40635986212706e-05,
      "loss": 0.0477,
      "step": 74200
    },
    {
      "epoch": 5.108987141580141,
      "grad_norm": 0.0786236822605133,
      "learning_rate": 3.404210969666234e-05,
      "loss": 0.0491,
      "step": 74300
    },
    {
      "epoch": 5.115863301932201,
      "grad_norm": 0.12271910905838013,
      "learning_rate": 3.4020620772054084e-05,
      "loss": 0.0504,
      "step": 74400
    },
    {
      "epoch": 5.122739462284261,
      "grad_norm": 0.20500893890857697,
      "learning_rate": 3.399913184744583e-05,
      "loss": 0.0501,
      "step": 74500
    },
    {
      "epoch": 5.12961562263632,
      "grad_norm": 0.12975573539733887,
      "learning_rate": 3.397764292283757e-05,
      "loss": 0.0495,
      "step": 74600
    },
    {
      "epoch": 5.136491782988379,
      "grad_norm": 0.21004840731620789,
      "learning_rate": 3.3956153998229314e-05,
      "loss": 0.0466,
      "step": 74700
    },
    {
      "epoch": 5.143367943340439,
      "grad_norm": 0.2684237062931061,
      "learning_rate": 3.393466507362106e-05,
      "loss": 0.0504,
      "step": 74800
    },
    {
      "epoch": 5.150244103692498,
      "grad_norm": 0.2639438509941101,
      "learning_rate": 3.39131761490128e-05,
      "loss": 0.0476,
      "step": 74900
    },
    {
      "epoch": 5.157120264044558,
      "grad_norm": 0.2971176207065582,
      "learning_rate": 3.3891687224404544e-05,
      "loss": 0.049,
      "step": 75000
    },
    {
      "epoch": 5.1639964243966165,
      "grad_norm": 0.14734536409378052,
      "learning_rate": 3.3870413189042374e-05,
      "loss": 0.0497,
      "step": 75100
    },
    {
      "epoch": 5.170872584748676,
      "grad_norm": 0.23303601145744324,
      "learning_rate": 3.384892426443411e-05,
      "loss": 0.0484,
      "step": 75200
    },
    {
      "epoch": 5.177748745100736,
      "grad_norm": 0.1704632192850113,
      "learning_rate": 3.382743533982586e-05,
      "loss": 0.0472,
      "step": 75300
    },
    {
      "epoch": 5.184624905452795,
      "grad_norm": 0.1411939561367035,
      "learning_rate": 3.38059464152176e-05,
      "loss": 0.0508,
      "step": 75400
    },
    {
      "epoch": 5.191501065804855,
      "grad_norm": 0.16087988018989563,
      "learning_rate": 3.378445749060934e-05,
      "loss": 0.0508,
      "step": 75500
    },
    {
      "epoch": 5.198377226156914,
      "grad_norm": 0.1314753293991089,
      "learning_rate": 3.3762968566001084e-05,
      "loss": 0.046,
      "step": 75600
    },
    {
      "epoch": 5.205253386508973,
      "grad_norm": 0.10217059403657913,
      "learning_rate": 3.374147964139283e-05,
      "loss": 0.05,
      "step": 75700
    },
    {
      "epoch": 5.212129546861033,
      "grad_norm": 0.16623544692993164,
      "learning_rate": 3.371999071678457e-05,
      "loss": 0.0479,
      "step": 75800
    },
    {
      "epoch": 5.219005707213093,
      "grad_norm": 0.15821531414985657,
      "learning_rate": 3.3698501792176314e-05,
      "loss": 0.049,
      "step": 75900
    },
    {
      "epoch": 5.2258818675651515,
      "grad_norm": 0.1632879078388214,
      "learning_rate": 3.367701286756806e-05,
      "loss": 0.049,
      "step": 76000
    },
    {
      "epoch": 5.232758027917211,
      "grad_norm": 0.13253556191921234,
      "learning_rate": 3.36555239429598e-05,
      "loss": 0.0493,
      "step": 76100
    },
    {
      "epoch": 5.23963418826927,
      "grad_norm": 0.18195606768131256,
      "learning_rate": 3.3634035018351544e-05,
      "loss": 0.0517,
      "step": 76200
    },
    {
      "epoch": 5.24651034862133,
      "grad_norm": 0.266137033700943,
      "learning_rate": 3.361254609374329e-05,
      "loss": 0.0491,
      "step": 76300
    },
    {
      "epoch": 5.2533865089733895,
      "grad_norm": 0.18155518174171448,
      "learning_rate": 3.359105716913503e-05,
      "loss": 0.0497,
      "step": 76400
    },
    {
      "epoch": 5.260262669325448,
      "grad_norm": 0.09786371141672134,
      "learning_rate": 3.3569568244526774e-05,
      "loss": 0.0513,
      "step": 76500
    },
    {
      "epoch": 5.267138829677508,
      "grad_norm": 0.1599580943584442,
      "learning_rate": 3.354807931991852e-05,
      "loss": 0.0496,
      "step": 76600
    },
    {
      "epoch": 5.274014990029568,
      "grad_norm": 0.09968839585781097,
      "learning_rate": 3.352659039531026e-05,
      "loss": 0.0474,
      "step": 76700
    },
    {
      "epoch": 5.280891150381627,
      "grad_norm": 0.08670184761285782,
      "learning_rate": 3.3505101470702e-05,
      "loss": 0.0484,
      "step": 76800
    },
    {
      "epoch": 5.287767310733686,
      "grad_norm": 0.12361901998519897,
      "learning_rate": 3.348361254609375e-05,
      "loss": 0.0497,
      "step": 76900
    },
    {
      "epoch": 5.294643471085745,
      "grad_norm": 0.16813547909259796,
      "learning_rate": 3.3462123621485484e-05,
      "loss": 0.0483,
      "step": 77000
    },
    {
      "epoch": 5.301519631437805,
      "grad_norm": 0.17940618097782135,
      "learning_rate": 3.3440849586123314e-05,
      "loss": 0.0526,
      "step": 77100
    },
    {
      "epoch": 5.308395791789865,
      "grad_norm": 0.1041039526462555,
      "learning_rate": 3.341936066151506e-05,
      "loss": 0.0477,
      "step": 77200
    },
    {
      "epoch": 5.315271952141924,
      "grad_norm": 0.1295384019613266,
      "learning_rate": 3.33978717369068e-05,
      "loss": 0.0494,
      "step": 77300
    },
    {
      "epoch": 5.322148112493983,
      "grad_norm": 0.1431550532579422,
      "learning_rate": 3.3376382812298544e-05,
      "loss": 0.0489,
      "step": 77400
    },
    {
      "epoch": 5.329024272846043,
      "grad_norm": 0.19294698536396027,
      "learning_rate": 3.335489388769029e-05,
      "loss": 0.0455,
      "step": 77500
    },
    {
      "epoch": 5.335900433198102,
      "grad_norm": 0.1626666784286499,
      "learning_rate": 3.3333404963082024e-05,
      "loss": 0.0514,
      "step": 77600
    },
    {
      "epoch": 5.342776593550162,
      "grad_norm": 0.16648346185684204,
      "learning_rate": 3.3311916038473774e-05,
      "loss": 0.0489,
      "step": 77700
    },
    {
      "epoch": 5.349652753902221,
      "grad_norm": 0.09463698416948318,
      "learning_rate": 3.329042711386551e-05,
      "loss": 0.0484,
      "step": 77800
    },
    {
      "epoch": 5.35652891425428,
      "grad_norm": 0.21197977662086487,
      "learning_rate": 3.326893818925726e-05,
      "loss": 0.0471,
      "step": 77900
    },
    {
      "epoch": 5.36340507460634,
      "grad_norm": 0.12788096070289612,
      "learning_rate": 3.3247449264649e-05,
      "loss": 0.0513,
      "step": 78000
    },
    {
      "epoch": 5.370281234958399,
      "grad_norm": 0.2227642685174942,
      "learning_rate": 3.322596034004075e-05,
      "loss": 0.0505,
      "step": 78100
    },
    {
      "epoch": 5.3771573953104586,
      "grad_norm": 0.1618935912847519,
      "learning_rate": 3.3204471415432484e-05,
      "loss": 0.0483,
      "step": 78200
    },
    {
      "epoch": 5.384033555662518,
      "grad_norm": 0.13688020408153534,
      "learning_rate": 3.3182982490824234e-05,
      "loss": 0.0487,
      "step": 78300
    },
    {
      "epoch": 5.390909716014577,
      "grad_norm": 0.20243807137012482,
      "learning_rate": 3.316149356621597e-05,
      "loss": 0.0497,
      "step": 78400
    },
    {
      "epoch": 5.397785876366637,
      "grad_norm": 0.2787456810474396,
      "learning_rate": 3.314000464160772e-05,
      "loss": 0.0513,
      "step": 78500
    },
    {
      "epoch": 5.404662036718697,
      "grad_norm": 0.17992009222507477,
      "learning_rate": 3.311851571699946e-05,
      "loss": 0.0511,
      "step": 78600
    },
    {
      "epoch": 5.4115381970707555,
      "grad_norm": 0.1637716144323349,
      "learning_rate": 3.309702679239121e-05,
      "loss": 0.0483,
      "step": 78700
    },
    {
      "epoch": 5.418414357422815,
      "grad_norm": 0.15980316698551178,
      "learning_rate": 3.3075537867782944e-05,
      "loss": 0.0474,
      "step": 78800
    },
    {
      "epoch": 5.425290517774875,
      "grad_norm": 0.17818161845207214,
      "learning_rate": 3.305404894317469e-05,
      "loss": 0.0481,
      "step": 78900
    },
    {
      "epoch": 5.432166678126934,
      "grad_norm": 0.1609116494655609,
      "learning_rate": 3.303256001856643e-05,
      "loss": 0.0495,
      "step": 79000
    },
    {
      "epoch": 5.4390428384789935,
      "grad_norm": 0.14017733931541443,
      "learning_rate": 3.301128598320426e-05,
      "loss": 0.0463,
      "step": 79100
    },
    {
      "epoch": 5.445918998831052,
      "grad_norm": 0.13987386226654053,
      "learning_rate": 3.2989797058596003e-05,
      "loss": 0.0491,
      "step": 79200
    },
    {
      "epoch": 5.452795159183112,
      "grad_norm": 0.10820408910512924,
      "learning_rate": 3.296830813398775e-05,
      "loss": 0.0478,
      "step": 79300
    },
    {
      "epoch": 5.459671319535172,
      "grad_norm": 0.1675352156162262,
      "learning_rate": 3.294681920937949e-05,
      "loss": 0.0471,
      "step": 79400
    },
    {
      "epoch": 5.466547479887231,
      "grad_norm": 0.19470833241939545,
      "learning_rate": 3.2925330284771233e-05,
      "loss": 0.0496,
      "step": 79500
    },
    {
      "epoch": 5.47342364023929,
      "grad_norm": 0.1031639501452446,
      "learning_rate": 3.290384136016298e-05,
      "loss": 0.0505,
      "step": 79600
    },
    {
      "epoch": 5.48029980059135,
      "grad_norm": 0.09979646652936935,
      "learning_rate": 3.2882352435554713e-05,
      "loss": 0.0474,
      "step": 79700
    },
    {
      "epoch": 5.487175960943409,
      "grad_norm": 0.15312565863132477,
      "learning_rate": 3.2860863510946464e-05,
      "loss": 0.0506,
      "step": 79800
    },
    {
      "epoch": 5.494052121295469,
      "grad_norm": 0.17171427607536316,
      "learning_rate": 3.28393745863382e-05,
      "loss": 0.0465,
      "step": 79900
    },
    {
      "epoch": 5.5009282816475285,
      "grad_norm": 0.13996531069278717,
      "learning_rate": 3.281788566172995e-05,
      "loss": 0.0485,
      "step": 80000
    },
    {
      "epoch": 5.507804441999587,
      "grad_norm": 0.15565338730812073,
      "learning_rate": 3.279639673712169e-05,
      "loss": 0.0478,
      "step": 80100
    },
    {
      "epoch": 5.514680602351647,
      "grad_norm": 0.16506698727607727,
      "learning_rate": 3.277490781251344e-05,
      "loss": 0.0497,
      "step": 80200
    },
    {
      "epoch": 5.521556762703706,
      "grad_norm": 0.0954643189907074,
      "learning_rate": 3.2753418887905173e-05,
      "loss": 0.0454,
      "step": 80300
    },
    {
      "epoch": 5.528432923055766,
      "grad_norm": 0.14785167574882507,
      "learning_rate": 3.273192996329692e-05,
      "loss": 0.0496,
      "step": 80400
    },
    {
      "epoch": 5.535309083407825,
      "grad_norm": 0.13524897396564484,
      "learning_rate": 3.271044103868866e-05,
      "loss": 0.0493,
      "step": 80500
    },
    {
      "epoch": 5.542185243759884,
      "grad_norm": 0.12055736035108566,
      "learning_rate": 3.2688952114080403e-05,
      "loss": 0.0492,
      "step": 80600
    },
    {
      "epoch": 5.549061404111944,
      "grad_norm": 0.1682366579771042,
      "learning_rate": 3.266746318947215e-05,
      "loss": 0.048,
      "step": 80700
    },
    {
      "epoch": 5.555937564464004,
      "grad_norm": 0.1493786871433258,
      "learning_rate": 3.264597426486389e-05,
      "loss": 0.0491,
      "step": 80800
    },
    {
      "epoch": 5.5628137248160625,
      "grad_norm": 0.29977813363075256,
      "learning_rate": 3.2624485340255633e-05,
      "loss": 0.0478,
      "step": 80900
    },
    {
      "epoch": 5.569689885168122,
      "grad_norm": 0.1514895260334015,
      "learning_rate": 3.260299641564738e-05,
      "loss": 0.05,
      "step": 81000
    },
    {
      "epoch": 5.576566045520181,
      "grad_norm": 0.18819424510002136,
      "learning_rate": 3.25817223802852e-05,
      "loss": 0.0504,
      "step": 81100
    },
    {
      "epoch": 5.583442205872241,
      "grad_norm": 0.21589861810207367,
      "learning_rate": 3.256023345567695e-05,
      "loss": 0.0475,
      "step": 81200
    },
    {
      "epoch": 5.590318366224301,
      "grad_norm": 0.21431738138198853,
      "learning_rate": 3.2538744531068686e-05,
      "loss": 0.0499,
      "step": 81300
    },
    {
      "epoch": 5.597194526576359,
      "grad_norm": 0.15512536466121674,
      "learning_rate": 3.2517255606460437e-05,
      "loss": 0.0487,
      "step": 81400
    },
    {
      "epoch": 5.604070686928419,
      "grad_norm": 0.1614675521850586,
      "learning_rate": 3.249576668185217e-05,
      "loss": 0.0467,
      "step": 81500
    },
    {
      "epoch": 5.610946847280479,
      "grad_norm": 0.10162089020013809,
      "learning_rate": 3.247427775724392e-05,
      "loss": 0.0487,
      "step": 81600
    },
    {
      "epoch": 5.617823007632538,
      "grad_norm": 0.25258737802505493,
      "learning_rate": 3.245278883263566e-05,
      "loss": 0.0487,
      "step": 81700
    },
    {
      "epoch": 5.6246991679845975,
      "grad_norm": 0.12878283858299255,
      "learning_rate": 3.24312999080274e-05,
      "loss": 0.0502,
      "step": 81800
    },
    {
      "epoch": 5.631575328336657,
      "grad_norm": 0.2419169694185257,
      "learning_rate": 3.2409810983419146e-05,
      "loss": 0.0515,
      "step": 81900
    },
    {
      "epoch": 5.638451488688716,
      "grad_norm": 0.17636656761169434,
      "learning_rate": 3.238832205881089e-05,
      "loss": 0.0519,
      "step": 82000
    },
    {
      "epoch": 5.645327649040776,
      "grad_norm": 0.12417662888765335,
      "learning_rate": 3.236683313420263e-05,
      "loss": 0.0456,
      "step": 82100
    },
    {
      "epoch": 5.6522038093928355,
      "grad_norm": 0.20472168922424316,
      "learning_rate": 3.2345344209594376e-05,
      "loss": 0.0495,
      "step": 82200
    },
    {
      "epoch": 5.659079969744894,
      "grad_norm": 0.1564408838748932,
      "learning_rate": 3.232385528498612e-05,
      "loss": 0.0478,
      "step": 82300
    },
    {
      "epoch": 5.665956130096954,
      "grad_norm": 0.11580726504325867,
      "learning_rate": 3.230236636037786e-05,
      "loss": 0.0473,
      "step": 82400
    },
    {
      "epoch": 5.672832290449013,
      "grad_norm": 0.10718496143817902,
      "learning_rate": 3.2280877435769606e-05,
      "loss": 0.0487,
      "step": 82500
    },
    {
      "epoch": 5.679708450801073,
      "grad_norm": 0.20328478515148163,
      "learning_rate": 3.225938851116135e-05,
      "loss": 0.0513,
      "step": 82600
    },
    {
      "epoch": 5.686584611153132,
      "grad_norm": 0.16675248742103577,
      "learning_rate": 3.223789958655309e-05,
      "loss": 0.0499,
      "step": 82700
    },
    {
      "epoch": 5.693460771505191,
      "grad_norm": 0.15910887718200684,
      "learning_rate": 3.2216410661944836e-05,
      "loss": 0.0508,
      "step": 82800
    },
    {
      "epoch": 5.700336931857251,
      "grad_norm": 0.12872003018856049,
      "learning_rate": 3.219492173733658e-05,
      "loss": 0.0466,
      "step": 82900
    },
    {
      "epoch": 5.70721309220931,
      "grad_norm": 0.08886408060789108,
      "learning_rate": 3.217343281272832e-05,
      "loss": 0.0483,
      "step": 83000
    },
    {
      "epoch": 5.71408925256137,
      "grad_norm": 0.1786462515592575,
      "learning_rate": 3.2152158777366146e-05,
      "loss": 0.0485,
      "step": 83100
    },
    {
      "epoch": 5.720965412913429,
      "grad_norm": 0.20568814873695374,
      "learning_rate": 3.213066985275789e-05,
      "loss": 0.0517,
      "step": 83200
    },
    {
      "epoch": 5.727841573265488,
      "grad_norm": 0.24945968389511108,
      "learning_rate": 3.210918092814963e-05,
      "loss": 0.05,
      "step": 83300
    },
    {
      "epoch": 5.734717733617548,
      "grad_norm": 0.1924261599779129,
      "learning_rate": 3.2087692003541376e-05,
      "loss": 0.0481,
      "step": 83400
    },
    {
      "epoch": 5.741593893969608,
      "grad_norm": 0.2517811059951782,
      "learning_rate": 3.206620307893312e-05,
      "loss": 0.0529,
      "step": 83500
    },
    {
      "epoch": 5.7484700543216665,
      "grad_norm": 0.19076775014400482,
      "learning_rate": 3.204471415432486e-05,
      "loss": 0.049,
      "step": 83600
    },
    {
      "epoch": 5.755346214673726,
      "grad_norm": 0.17428995668888092,
      "learning_rate": 3.2023225229716606e-05,
      "loss": 0.05,
      "step": 83700
    },
    {
      "epoch": 5.762222375025786,
      "grad_norm": 0.17523591220378876,
      "learning_rate": 3.200173630510835e-05,
      "loss": 0.0481,
      "step": 83800
    },
    {
      "epoch": 5.769098535377845,
      "grad_norm": 0.16063281893730164,
      "learning_rate": 3.1980247380500086e-05,
      "loss": 0.0478,
      "step": 83900
    },
    {
      "epoch": 5.7759746957299045,
      "grad_norm": 0.13092166185379028,
      "learning_rate": 3.1958758455891836e-05,
      "loss": 0.049,
      "step": 84000
    },
    {
      "epoch": 5.782850856081964,
      "grad_norm": 0.18551117181777954,
      "learning_rate": 3.193726953128357e-05,
      "loss": 0.0492,
      "step": 84100
    },
    {
      "epoch": 5.789727016434023,
      "grad_norm": 0.16937805712223053,
      "learning_rate": 3.191578060667532e-05,
      "loss": 0.0481,
      "step": 84200
    },
    {
      "epoch": 5.796603176786083,
      "grad_norm": 0.24416381120681763,
      "learning_rate": 3.189429168206706e-05,
      "loss": 0.0512,
      "step": 84300
    },
    {
      "epoch": 5.803479337138142,
      "grad_norm": 0.2348964810371399,
      "learning_rate": 3.187280275745881e-05,
      "loss": 0.0502,
      "step": 84400
    },
    {
      "epoch": 5.810355497490201,
      "grad_norm": 0.1527559906244278,
      "learning_rate": 3.1851313832850546e-05,
      "loss": 0.0514,
      "step": 84500
    },
    {
      "epoch": 5.817231657842261,
      "grad_norm": 0.13503146171569824,
      "learning_rate": 3.1829824908242296e-05,
      "loss": 0.0495,
      "step": 84600
    },
    {
      "epoch": 5.82410781819432,
      "grad_norm": 0.2244940847158432,
      "learning_rate": 3.180833598363403e-05,
      "loss": 0.0488,
      "step": 84700
    },
    {
      "epoch": 5.83098397854638,
      "grad_norm": 0.0822923555970192,
      "learning_rate": 3.178684705902578e-05,
      "loss": 0.0497,
      "step": 84800
    },
    {
      "epoch": 5.8378601388984395,
      "grad_norm": 0.1261335015296936,
      "learning_rate": 3.176535813441752e-05,
      "loss": 0.051,
      "step": 84900
    },
    {
      "epoch": 5.844736299250498,
      "grad_norm": 0.1302529275417328,
      "learning_rate": 3.174386920980927e-05,
      "loss": 0.0484,
      "step": 85000
    },
    {
      "epoch": 5.851612459602558,
      "grad_norm": 0.14720061421394348,
      "learning_rate": 3.1722380285201006e-05,
      "loss": 0.0484,
      "step": 85100
    },
    {
      "epoch": 5.858488619954617,
      "grad_norm": 0.22244371473789215,
      "learning_rate": 3.170089136059275e-05,
      "loss": 0.0472,
      "step": 85200
    },
    {
      "epoch": 5.865364780306677,
      "grad_norm": 0.22315940260887146,
      "learning_rate": 3.167940243598449e-05,
      "loss": 0.0459,
      "step": 85300
    },
    {
      "epoch": 5.872240940658736,
      "grad_norm": 0.10586085170507431,
      "learning_rate": 3.1657913511376236e-05,
      "loss": 0.0488,
      "step": 85400
    },
    {
      "epoch": 5.879117101010795,
      "grad_norm": 0.17721790075302124,
      "learning_rate": 3.163642458676798e-05,
      "loss": 0.05,
      "step": 85500
    },
    {
      "epoch": 5.885993261362855,
      "grad_norm": 0.2261047512292862,
      "learning_rate": 3.161493566215972e-05,
      "loss": 0.0479,
      "step": 85600
    },
    {
      "epoch": 5.892869421714915,
      "grad_norm": 0.1410580277442932,
      "learning_rate": 3.1593446737551466e-05,
      "loss": 0.0505,
      "step": 85700
    },
    {
      "epoch": 5.8997455820669735,
      "grad_norm": 0.17756028473377228,
      "learning_rate": 3.157195781294321e-05,
      "loss": 0.0498,
      "step": 85800
    },
    {
      "epoch": 5.906621742419033,
      "grad_norm": 0.1840410977602005,
      "learning_rate": 3.155046888833495e-05,
      "loss": 0.0489,
      "step": 85900
    },
    {
      "epoch": 5.913497902771093,
      "grad_norm": 0.2071218639612198,
      "learning_rate": 3.1528979963726696e-05,
      "loss": 0.0462,
      "step": 86000
    },
    {
      "epoch": 5.920374063123152,
      "grad_norm": 0.2217910885810852,
      "learning_rate": 3.150749103911844e-05,
      "loss": 0.0485,
      "step": 86100
    },
    {
      "epoch": 5.927250223475212,
      "grad_norm": 0.12407325208187103,
      "learning_rate": 3.148600211451018e-05,
      "loss": 0.046,
      "step": 86200
    },
    {
      "epoch": 5.934126383827271,
      "grad_norm": 0.17749080061912537,
      "learning_rate": 3.1464513189901926e-05,
      "loss": 0.0479,
      "step": 86300
    },
    {
      "epoch": 5.94100254417933,
      "grad_norm": 0.18545803427696228,
      "learning_rate": 3.144302426529367e-05,
      "loss": 0.0494,
      "step": 86400
    },
    {
      "epoch": 5.94787870453139,
      "grad_norm": 0.11871004104614258,
      "learning_rate": 3.142153534068541e-05,
      "loss": 0.0506,
      "step": 86500
    },
    {
      "epoch": 5.954754864883449,
      "grad_norm": 0.13642413914203644,
      "learning_rate": 3.1400046416077156e-05,
      "loss": 0.0493,
      "step": 86600
    },
    {
      "epoch": 5.9616310252355085,
      "grad_norm": 0.1426500380039215,
      "learning_rate": 3.13785574914689e-05,
      "loss": 0.0491,
      "step": 86700
    },
    {
      "epoch": 5.968507185587568,
      "grad_norm": 0.1505429595708847,
      "learning_rate": 3.135706856686064e-05,
      "loss": 0.0501,
      "step": 86800
    },
    {
      "epoch": 5.975383345939627,
      "grad_norm": 0.22424806654453278,
      "learning_rate": 3.1335579642252386e-05,
      "loss": 0.0533,
      "step": 86900
    },
    {
      "epoch": 5.982259506291687,
      "grad_norm": 0.1767161339521408,
      "learning_rate": 3.131409071764413e-05,
      "loss": 0.0445,
      "step": 87000
    },
    {
      "epoch": 5.989135666643746,
      "grad_norm": 0.07827026396989822,
      "learning_rate": 3.129281668228195e-05,
      "loss": 0.0503,
      "step": 87100
    },
    {
      "epoch": 5.996011826995805,
      "grad_norm": 0.3109932243824005,
      "learning_rate": 3.1271327757673696e-05,
      "loss": 0.0471,
      "step": 87200
    },
    {
      "epoch": 6.0,
      "eval_accuracy_macro_0.5": 0.9782798290252686,
      "eval_accuracy_micro_0.5": 0.9782798886299133,
      "eval_accuracy_weighted_0.5": 0.975551962852478,
      "eval_f1_macro_0.5": 0.694513201713562,
      "eval_f1_macro_0.6": 0.6649091839790344,
      "eval_f1_macro_0.7": 0.6172538995742798,
      "eval_f1_macro_0.8": 0.40545979142189026,
      "eval_f1_micro_0.5": 0.7015997767448425,
      "eval_f1_micro_0.6": 0.677790641784668,
      "eval_f1_micro_0.7": 0.6375017166137695,
      "eval_f1_micro_0.8": 0.567854106426239,
      "eval_f1_micro_0.9": 0.4352053999900818,
      "eval_f1_weighted_0.5": 0.6910644173622131,
      "eval_f1_weighted_0.6": 0.6600255370140076,
      "eval_f1_weighted_0.7": 0.6107403635978699,
      "eval_f1_weighted_0.8": 0.3918077051639557,
      "eval_loss": 0.045380543917417526,
      "eval_runtime": 62.5753,
      "eval_samples_per_second": 464.033,
      "eval_steps_per_second": 58.01,
      "step": 87258
    },
    {
      "epoch": 6.002887987347865,
      "grad_norm": 0.13785415887832642,
      "learning_rate": 3.124983883306544e-05,
      "loss": 0.0483,
      "step": 87300
    },
    {
      "epoch": 6.009764147699924,
      "grad_norm": 0.10656284540891647,
      "learning_rate": 3.122856479770326e-05,
      "loss": 0.0491,
      "step": 87400
    },
    {
      "epoch": 6.016640308051984,
      "grad_norm": 0.2306617647409439,
      "learning_rate": 3.120707587309501e-05,
      "loss": 0.0468,
      "step": 87500
    },
    {
      "epoch": 6.023516468404043,
      "grad_norm": 0.3652637004852295,
      "learning_rate": 3.118558694848675e-05,
      "loss": 0.0495,
      "step": 87600
    },
    {
      "epoch": 6.030392628756102,
      "grad_norm": 0.30204641819000244,
      "learning_rate": 3.11640980238785e-05,
      "loss": 0.052,
      "step": 87700
    },
    {
      "epoch": 6.037268789108162,
      "grad_norm": 0.16889704763889313,
      "learning_rate": 3.1142609099270236e-05,
      "loss": 0.0459,
      "step": 87800
    },
    {
      "epoch": 6.044144949460222,
      "grad_norm": 0.12066581100225449,
      "learning_rate": 3.1121120174661986e-05,
      "loss": 0.0513,
      "step": 87900
    },
    {
      "epoch": 6.051021109812281,
      "grad_norm": 0.2097468078136444,
      "learning_rate": 3.109963125005372e-05,
      "loss": 0.046,
      "step": 88000
    },
    {
      "epoch": 6.05789727016434,
      "grad_norm": 0.2847727835178375,
      "learning_rate": 3.107814232544547e-05,
      "loss": 0.0446,
      "step": 88100
    },
    {
      "epoch": 6.0647734305164,
      "grad_norm": 0.2026485651731491,
      "learning_rate": 3.105665340083721e-05,
      "loss": 0.05,
      "step": 88200
    },
    {
      "epoch": 6.071649590868459,
      "grad_norm": 0.11842594295740128,
      "learning_rate": 3.103516447622895e-05,
      "loss": 0.0467,
      "step": 88300
    },
    {
      "epoch": 6.078525751220519,
      "grad_norm": 0.19427843391895294,
      "learning_rate": 3.1013675551620696e-05,
      "loss": 0.0489,
      "step": 88400
    },
    {
      "epoch": 6.0854019115725775,
      "grad_norm": 0.22772924602031708,
      "learning_rate": 3.099218662701244e-05,
      "loss": 0.0516,
      "step": 88500
    },
    {
      "epoch": 6.092278071924637,
      "grad_norm": 0.22736793756484985,
      "learning_rate": 3.097069770240418e-05,
      "loss": 0.0507,
      "step": 88600
    },
    {
      "epoch": 6.099154232276697,
      "grad_norm": 0.12425965070724487,
      "learning_rate": 3.0949208777795926e-05,
      "loss": 0.0469,
      "step": 88700
    },
    {
      "epoch": 6.106030392628756,
      "grad_norm": 0.20706956088542938,
      "learning_rate": 3.092771985318767e-05,
      "loss": 0.0495,
      "step": 88800
    },
    {
      "epoch": 6.1129065529808155,
      "grad_norm": 0.1020161584019661,
      "learning_rate": 3.090623092857941e-05,
      "loss": 0.0475,
      "step": 88900
    },
    {
      "epoch": 6.119782713332875,
      "grad_norm": 0.16867795586585999,
      "learning_rate": 3.0884742003971156e-05,
      "loss": 0.0483,
      "step": 89000
    },
    {
      "epoch": 6.126658873684934,
      "grad_norm": 0.20399214327335358,
      "learning_rate": 3.08632530793629e-05,
      "loss": 0.0502,
      "step": 89100
    },
    {
      "epoch": 6.133535034036994,
      "grad_norm": 0.23570682108402252,
      "learning_rate": 3.084176415475464e-05,
      "loss": 0.0494,
      "step": 89200
    },
    {
      "epoch": 6.140411194389053,
      "grad_norm": 0.1676529347896576,
      "learning_rate": 3.0820275230146386e-05,
      "loss": 0.0456,
      "step": 89300
    },
    {
      "epoch": 6.147287354741112,
      "grad_norm": 0.18061867356300354,
      "learning_rate": 3.079878630553813e-05,
      "loss": 0.048,
      "step": 89400
    },
    {
      "epoch": 6.154163515093172,
      "grad_norm": 0.2935883402824402,
      "learning_rate": 3.077729738092987e-05,
      "loss": 0.047,
      "step": 89500
    },
    {
      "epoch": 6.161039675445231,
      "grad_norm": 0.165174201130867,
      "learning_rate": 3.075580845632161e-05,
      "loss": 0.0495,
      "step": 89600
    },
    {
      "epoch": 6.167915835797291,
      "grad_norm": 0.18484199047088623,
      "learning_rate": 3.073453442095944e-05,
      "loss": 0.0485,
      "step": 89700
    },
    {
      "epoch": 6.1747919961493505,
      "grad_norm": 0.11972985416650772,
      "learning_rate": 3.071304549635118e-05,
      "loss": 0.0494,
      "step": 89800
    },
    {
      "epoch": 6.181668156501409,
      "grad_norm": 0.3518296480178833,
      "learning_rate": 3.0691556571742925e-05,
      "loss": 0.0492,
      "step": 89900
    },
    {
      "epoch": 6.188544316853469,
      "grad_norm": 0.14238062500953674,
      "learning_rate": 3.067006764713467e-05,
      "loss": 0.0484,
      "step": 90000
    },
    {
      "epoch": 6.195420477205529,
      "grad_norm": 0.24817277491092682,
      "learning_rate": 3.064857872252641e-05,
      "loss": 0.0492,
      "step": 90100
    },
    {
      "epoch": 6.202296637557588,
      "grad_norm": 0.1708298623561859,
      "learning_rate": 3.0627089797918155e-05,
      "loss": 0.0484,
      "step": 90200
    },
    {
      "epoch": 6.209172797909647,
      "grad_norm": 0.14297255873680115,
      "learning_rate": 3.06056008733099e-05,
      "loss": 0.0469,
      "step": 90300
    },
    {
      "epoch": 6.216048958261707,
      "grad_norm": 0.16602298617362976,
      "learning_rate": 3.0584111948701635e-05,
      "loss": 0.0473,
      "step": 90400
    },
    {
      "epoch": 6.222925118613766,
      "grad_norm": 0.10071047395467758,
      "learning_rate": 3.0562623024093385e-05,
      "loss": 0.05,
      "step": 90500
    },
    {
      "epoch": 6.229801278965826,
      "grad_norm": 0.19642950594425201,
      "learning_rate": 3.054113409948512e-05,
      "loss": 0.0452,
      "step": 90600
    },
    {
      "epoch": 6.2366774393178845,
      "grad_norm": 0.18850143253803253,
      "learning_rate": 3.051964517487687e-05,
      "loss": 0.0473,
      "step": 90700
    },
    {
      "epoch": 6.243553599669944,
      "grad_norm": 0.2142632007598877,
      "learning_rate": 3.0498156250268612e-05,
      "loss": 0.049,
      "step": 90800
    },
    {
      "epoch": 6.250429760022004,
      "grad_norm": 0.21436339616775513,
      "learning_rate": 3.047666732566036e-05,
      "loss": 0.0458,
      "step": 90900
    },
    {
      "epoch": 6.257305920374063,
      "grad_norm": 0.07310792058706284,
      "learning_rate": 3.04551784010521e-05,
      "loss": 0.0487,
      "step": 91000
    },
    {
      "epoch": 6.264182080726123,
      "grad_norm": 0.16281263530254364,
      "learning_rate": 3.0433689476443845e-05,
      "loss": 0.0503,
      "step": 91100
    },
    {
      "epoch": 6.271058241078182,
      "grad_norm": 0.1807307004928589,
      "learning_rate": 3.0412200551835585e-05,
      "loss": 0.049,
      "step": 91200
    },
    {
      "epoch": 6.277934401430241,
      "grad_norm": 0.1913813352584839,
      "learning_rate": 3.0390711627227332e-05,
      "loss": 0.0461,
      "step": 91300
    },
    {
      "epoch": 6.284810561782301,
      "grad_norm": 0.21211667358875275,
      "learning_rate": 3.0369222702619072e-05,
      "loss": 0.0498,
      "step": 91400
    },
    {
      "epoch": 6.29168672213436,
      "grad_norm": 0.1932845413684845,
      "learning_rate": 3.034773377801082e-05,
      "loss": 0.0488,
      "step": 91500
    },
    {
      "epoch": 6.2985628824864195,
      "grad_norm": 0.12322985380887985,
      "learning_rate": 3.032624485340256e-05,
      "loss": 0.0468,
      "step": 91600
    },
    {
      "epoch": 6.305439042838479,
      "grad_norm": 0.22001014649868011,
      "learning_rate": 3.03047559287943e-05,
      "loss": 0.0476,
      "step": 91700
    },
    {
      "epoch": 6.312315203190538,
      "grad_norm": 0.14705835282802582,
      "learning_rate": 3.0283267004186045e-05,
      "loss": 0.0499,
      "step": 91800
    },
    {
      "epoch": 6.319191363542598,
      "grad_norm": 0.12483258545398712,
      "learning_rate": 3.0261778079577785e-05,
      "loss": 0.0484,
      "step": 91900
    },
    {
      "epoch": 6.3260675238946575,
      "grad_norm": 0.15999478101730347,
      "learning_rate": 3.0240289154969532e-05,
      "loss": 0.0473,
      "step": 92000
    },
    {
      "epoch": 6.332943684246716,
      "grad_norm": 0.16522328555583954,
      "learning_rate": 3.0218800230361272e-05,
      "loss": 0.0458,
      "step": 92100
    },
    {
      "epoch": 6.339819844598776,
      "grad_norm": 0.2625117599964142,
      "learning_rate": 3.019731130575302e-05,
      "loss": 0.0473,
      "step": 92200
    },
    {
      "epoch": 6.346696004950836,
      "grad_norm": 0.2400376945734024,
      "learning_rate": 3.017582238114476e-05,
      "loss": 0.0491,
      "step": 92300
    },
    {
      "epoch": 6.353572165302895,
      "grad_norm": 0.21135331690311432,
      "learning_rate": 3.0154548345782585e-05,
      "loss": 0.0478,
      "step": 92400
    },
    {
      "epoch": 6.360448325654954,
      "grad_norm": 0.14622963964939117,
      "learning_rate": 3.0133059421174325e-05,
      "loss": 0.0524,
      "step": 92500
    },
    {
      "epoch": 6.367324486007013,
      "grad_norm": 0.141640305519104,
      "learning_rate": 3.011157049656607e-05,
      "loss": 0.047,
      "step": 92600
    },
    {
      "epoch": 6.374200646359073,
      "grad_norm": 0.17719939351081848,
      "learning_rate": 3.009008157195781e-05,
      "loss": 0.0481,
      "step": 92700
    },
    {
      "epoch": 6.381076806711133,
      "grad_norm": 0.17752070724964142,
      "learning_rate": 3.006859264734956e-05,
      "loss": 0.0478,
      "step": 92800
    },
    {
      "epoch": 6.387952967063192,
      "grad_norm": 0.16874173283576965,
      "learning_rate": 3.0047103722741298e-05,
      "loss": 0.0479,
      "step": 92900
    },
    {
      "epoch": 6.394829127415251,
      "grad_norm": 0.14978110790252686,
      "learning_rate": 3.0025614798133045e-05,
      "loss": 0.0478,
      "step": 93000
    },
    {
      "epoch": 6.401705287767311,
      "grad_norm": 0.14851196110248566,
      "learning_rate": 3.0004125873524785e-05,
      "loss": 0.0465,
      "step": 93100
    },
    {
      "epoch": 6.40858144811937,
      "grad_norm": 0.15218371152877808,
      "learning_rate": 2.998263694891653e-05,
      "loss": 0.047,
      "step": 93200
    },
    {
      "epoch": 6.41545760847143,
      "grad_norm": 0.21194133162498474,
      "learning_rate": 2.996114802430827e-05,
      "loss": 0.0475,
      "step": 93300
    },
    {
      "epoch": 6.4223337688234885,
      "grad_norm": 0.11784368008375168,
      "learning_rate": 2.993965909970002e-05,
      "loss": 0.0469,
      "step": 93400
    },
    {
      "epoch": 6.429209929175548,
      "grad_norm": 0.13435983657836914,
      "learning_rate": 2.9918170175091758e-05,
      "loss": 0.0473,
      "step": 93500
    },
    {
      "epoch": 6.436086089527608,
      "grad_norm": 0.18443119525909424,
      "learning_rate": 2.9896681250483505e-05,
      "loss": 0.0496,
      "step": 93600
    },
    {
      "epoch": 6.442962249879667,
      "grad_norm": 0.1020626500248909,
      "learning_rate": 2.9875192325875245e-05,
      "loss": 0.0447,
      "step": 93700
    },
    {
      "epoch": 6.4498384102317265,
      "grad_norm": 0.15834984183311462,
      "learning_rate": 2.9853703401266985e-05,
      "loss": 0.0463,
      "step": 93800
    },
    {
      "epoch": 6.456714570583786,
      "grad_norm": 0.18853847682476044,
      "learning_rate": 2.983221447665873e-05,
      "loss": 0.0493,
      "step": 93900
    },
    {
      "epoch": 6.463590730935845,
      "grad_norm": 0.16308850049972534,
      "learning_rate": 2.981072555205047e-05,
      "loss": 0.0441,
      "step": 94000
    },
    {
      "epoch": 6.470466891287905,
      "grad_norm": 0.25412216782569885,
      "learning_rate": 2.9789236627442218e-05,
      "loss": 0.0504,
      "step": 94100
    },
    {
      "epoch": 6.477343051639965,
      "grad_norm": 0.20561523735523224,
      "learning_rate": 2.9767747702833958e-05,
      "loss": 0.0476,
      "step": 94200
    },
    {
      "epoch": 6.4842192119920234,
      "grad_norm": 0.15480098128318787,
      "learning_rate": 2.9746258778225705e-05,
      "loss": 0.0455,
      "step": 94300
    },
    {
      "epoch": 6.491095372344083,
      "grad_norm": 0.1649465411901474,
      "learning_rate": 2.9724769853617445e-05,
      "loss": 0.0484,
      "step": 94400
    },
    {
      "epoch": 6.497971532696143,
      "grad_norm": 0.18812969326972961,
      "learning_rate": 2.970328092900919e-05,
      "loss": 0.0465,
      "step": 94500
    },
    {
      "epoch": 6.504847693048202,
      "grad_norm": 0.20780105888843536,
      "learning_rate": 2.968179200440093e-05,
      "loss": 0.0472,
      "step": 94600
    },
    {
      "epoch": 6.5117238534002615,
      "grad_norm": 0.11521940678358078,
      "learning_rate": 2.9660303079792678e-05,
      "loss": 0.0455,
      "step": 94700
    },
    {
      "epoch": 6.51860001375232,
      "grad_norm": 0.13940134644508362,
      "learning_rate": 2.9638814155184418e-05,
      "loss": 0.0493,
      "step": 94800
    },
    {
      "epoch": 6.52547617410438,
      "grad_norm": 0.1674746423959732,
      "learning_rate": 2.9617325230576165e-05,
      "loss": 0.0443,
      "step": 94900
    },
    {
      "epoch": 6.53235233445644,
      "grad_norm": 0.21820737421512604,
      "learning_rate": 2.9595836305967905e-05,
      "loss": 0.0479,
      "step": 95000
    },
    {
      "epoch": 6.539228494808499,
      "grad_norm": 0.08680180460214615,
      "learning_rate": 2.9574347381359645e-05,
      "loss": 0.0465,
      "step": 95100
    },
    {
      "epoch": 6.546104655160558,
      "grad_norm": 0.19634667038917542,
      "learning_rate": 2.955285845675139e-05,
      "loss": 0.0509,
      "step": 95200
    },
    {
      "epoch": 6.552980815512618,
      "grad_norm": 0.11213206499814987,
      "learning_rate": 2.953136953214313e-05,
      "loss": 0.0476,
      "step": 95300
    },
    {
      "epoch": 6.559856975864677,
      "grad_norm": 0.16166189312934875,
      "learning_rate": 2.9509880607534878e-05,
      "loss": 0.045,
      "step": 95400
    },
    {
      "epoch": 6.566733136216737,
      "grad_norm": 0.14173008501529694,
      "learning_rate": 2.9488391682926618e-05,
      "loss": 0.0453,
      "step": 95500
    },
    {
      "epoch": 6.573609296568796,
      "grad_norm": 0.22521112859249115,
      "learning_rate": 2.9466902758318365e-05,
      "loss": 0.0484,
      "step": 95600
    },
    {
      "epoch": 6.580485456920855,
      "grad_norm": 0.15517184138298035,
      "learning_rate": 2.9445413833710105e-05,
      "loss": 0.0515,
      "step": 95700
    },
    {
      "epoch": 6.587361617272915,
      "grad_norm": 0.16236111521720886,
      "learning_rate": 2.942392490910185e-05,
      "loss": 0.0485,
      "step": 95800
    },
    {
      "epoch": 6.594237777624974,
      "grad_norm": 0.18366816639900208,
      "learning_rate": 2.940243598449359e-05,
      "loss": 0.0479,
      "step": 95900
    },
    {
      "epoch": 6.601113937977034,
      "grad_norm": 0.13891029357910156,
      "learning_rate": 2.9380947059885338e-05,
      "loss": 0.0462,
      "step": 96000
    },
    {
      "epoch": 6.607990098329093,
      "grad_norm": 0.1779058426618576,
      "learning_rate": 2.9359458135277078e-05,
      "loss": 0.0478,
      "step": 96100
    },
    {
      "epoch": 6.614866258681152,
      "grad_norm": 0.14003528654575348,
      "learning_rate": 2.9337969210668825e-05,
      "loss": 0.0476,
      "step": 96200
    },
    {
      "epoch": 6.621742419033212,
      "grad_norm": 0.23597419261932373,
      "learning_rate": 2.9316480286060565e-05,
      "loss": 0.0484,
      "step": 96300
    },
    {
      "epoch": 6.628618579385272,
      "grad_norm": 0.16827279329299927,
      "learning_rate": 2.929520625069839e-05,
      "loss": 0.0476,
      "step": 96400
    },
    {
      "epoch": 6.6354947397373305,
      "grad_norm": 0.16049279272556305,
      "learning_rate": 2.9273717326090135e-05,
      "loss": 0.0442,
      "step": 96500
    },
    {
      "epoch": 6.64237090008939,
      "grad_norm": 0.1160866841673851,
      "learning_rate": 2.9252228401481878e-05,
      "loss": 0.0483,
      "step": 96600
    },
    {
      "epoch": 6.64924706044145,
      "grad_norm": 0.12224575132131577,
      "learning_rate": 2.923073947687362e-05,
      "loss": 0.0459,
      "step": 96700
    },
    {
      "epoch": 6.656123220793509,
      "grad_norm": 0.21046212315559387,
      "learning_rate": 2.9209250552265365e-05,
      "loss": 0.05,
      "step": 96800
    },
    {
      "epoch": 6.662999381145569,
      "grad_norm": 0.21840260922908783,
      "learning_rate": 2.9187761627657108e-05,
      "loss": 0.0487,
      "step": 96900
    },
    {
      "epoch": 6.669875541497627,
      "grad_norm": 0.20103666186332703,
      "learning_rate": 2.916627270304885e-05,
      "loss": 0.0503,
      "step": 97000
    },
    {
      "epoch": 6.676751701849687,
      "grad_norm": 0.20603877305984497,
      "learning_rate": 2.9144783778440595e-05,
      "loss": 0.0506,
      "step": 97100
    },
    {
      "epoch": 6.683627862201747,
      "grad_norm": 0.12499155104160309,
      "learning_rate": 2.9123294853832335e-05,
      "loss": 0.0463,
      "step": 97200
    },
    {
      "epoch": 6.690504022553806,
      "grad_norm": 0.20171600580215454,
      "learning_rate": 2.910180592922408e-05,
      "loss": 0.0471,
      "step": 97300
    },
    {
      "epoch": 6.6973801829058655,
      "grad_norm": 0.2724630832672119,
      "learning_rate": 2.908031700461582e-05,
      "loss": 0.048,
      "step": 97400
    },
    {
      "epoch": 6.704256343257924,
      "grad_norm": 0.11993875354528427,
      "learning_rate": 2.9058828080007568e-05,
      "loss": 0.0464,
      "step": 97500
    },
    {
      "epoch": 6.711132503609984,
      "grad_norm": 0.16583581268787384,
      "learning_rate": 2.9037339155399308e-05,
      "loss": 0.0458,
      "step": 97600
    },
    {
      "epoch": 6.718008663962044,
      "grad_norm": 0.10768216848373413,
      "learning_rate": 2.901585023079105e-05,
      "loss": 0.0497,
      "step": 97700
    },
    {
      "epoch": 6.724884824314103,
      "grad_norm": 0.22577404975891113,
      "learning_rate": 2.8994361306182795e-05,
      "loss": 0.0498,
      "step": 97800
    },
    {
      "epoch": 6.731760984666162,
      "grad_norm": 0.18755240738391876,
      "learning_rate": 2.8972872381574538e-05,
      "loss": 0.049,
      "step": 97900
    },
    {
      "epoch": 6.738637145018222,
      "grad_norm": 0.2441687434911728,
      "learning_rate": 2.895138345696628e-05,
      "loss": 0.0463,
      "step": 98000
    },
    {
      "epoch": 6.745513305370281,
      "grad_norm": 0.18072281777858734,
      "learning_rate": 2.8929894532358025e-05,
      "loss": 0.0473,
      "step": 98100
    },
    {
      "epoch": 6.752389465722341,
      "grad_norm": 0.13958555459976196,
      "learning_rate": 2.8908405607749768e-05,
      "loss": 0.0465,
      "step": 98200
    },
    {
      "epoch": 6.7592656260744,
      "grad_norm": 0.20807965099811554,
      "learning_rate": 2.888691668314151e-05,
      "loss": 0.0489,
      "step": 98300
    },
    {
      "epoch": 6.766141786426459,
      "grad_norm": 0.1218605786561966,
      "learning_rate": 2.8865427758533255e-05,
      "loss": 0.0473,
      "step": 98400
    },
    {
      "epoch": 6.773017946778519,
      "grad_norm": 0.1591944545507431,
      "learning_rate": 2.884415372317108e-05,
      "loss": 0.0508,
      "step": 98500
    },
    {
      "epoch": 6.779894107130579,
      "grad_norm": 0.17791496217250824,
      "learning_rate": 2.882266479856282e-05,
      "loss": 0.0484,
      "step": 98600
    },
    {
      "epoch": 6.786770267482638,
      "grad_norm": 0.16998225450515747,
      "learning_rate": 2.8801175873954568e-05,
      "loss": 0.0477,
      "step": 98700
    },
    {
      "epoch": 6.793646427834697,
      "grad_norm": 0.16390252113342285,
      "learning_rate": 2.8779686949346308e-05,
      "loss": 0.048,
      "step": 98800
    },
    {
      "epoch": 6.800522588186756,
      "grad_norm": 0.1906343698501587,
      "learning_rate": 2.8758198024738054e-05,
      "loss": 0.0483,
      "step": 98900
    },
    {
      "epoch": 6.807398748538816,
      "grad_norm": 0.12811490893363953,
      "learning_rate": 2.8736709100129794e-05,
      "loss": 0.0466,
      "step": 99000
    },
    {
      "epoch": 6.814274908890876,
      "grad_norm": 0.12281633913516998,
      "learning_rate": 2.871522017552154e-05,
      "loss": 0.0479,
      "step": 99100
    },
    {
      "epoch": 6.8211510692429345,
      "grad_norm": 0.1514177918434143,
      "learning_rate": 2.869373125091328e-05,
      "loss": 0.0503,
      "step": 99200
    },
    {
      "epoch": 6.828027229594994,
      "grad_norm": 0.2439294308423996,
      "learning_rate": 2.867224232630502e-05,
      "loss": 0.0463,
      "step": 99300
    },
    {
      "epoch": 6.834903389947054,
      "grad_norm": 0.11104905605316162,
      "learning_rate": 2.8650753401696768e-05,
      "loss": 0.0502,
      "step": 99400
    },
    {
      "epoch": 6.841779550299113,
      "grad_norm": 0.19314852356910706,
      "learning_rate": 2.8629264477088508e-05,
      "loss": 0.0494,
      "step": 99500
    },
    {
      "epoch": 6.8486557106511725,
      "grad_norm": 0.19265443086624146,
      "learning_rate": 2.8607775552480254e-05,
      "loss": 0.0471,
      "step": 99600
    },
    {
      "epoch": 6.855531871003231,
      "grad_norm": 0.140358105301857,
      "learning_rate": 2.8586286627871994e-05,
      "loss": 0.0468,
      "step": 99700
    },
    {
      "epoch": 6.862408031355291,
      "grad_norm": 0.1432778686285019,
      "learning_rate": 2.856479770326374e-05,
      "loss": 0.0471,
      "step": 99800
    },
    {
      "epoch": 6.869284191707351,
      "grad_norm": 0.1847027838230133,
      "learning_rate": 2.854330877865548e-05,
      "loss": 0.0481,
      "step": 99900
    },
    {
      "epoch": 6.87616035205941,
      "grad_norm": 0.26236802339553833,
      "learning_rate": 2.8521819854047228e-05,
      "loss": 0.0472,
      "step": 100000
    },
    {
      "epoch": 6.883036512411469,
      "grad_norm": 0.20487041771411896,
      "learning_rate": 2.8500330929438968e-05,
      "loss": 0.0499,
      "step": 100100
    },
    {
      "epoch": 6.889912672763529,
      "grad_norm": 0.22167283296585083,
      "learning_rate": 2.8478842004830714e-05,
      "loss": 0.0489,
      "step": 100200
    },
    {
      "epoch": 6.896788833115588,
      "grad_norm": 0.11522506922483444,
      "learning_rate": 2.8457353080222454e-05,
      "loss": 0.0474,
      "step": 100300
    },
    {
      "epoch": 6.903664993467648,
      "grad_norm": 0.263670951128006,
      "learning_rate": 2.84358641556142e-05,
      "loss": 0.049,
      "step": 100400
    },
    {
      "epoch": 6.9105411538197075,
      "grad_norm": 0.15361319482326508,
      "learning_rate": 2.841459012025202e-05,
      "loss": 0.0483,
      "step": 100500
    },
    {
      "epoch": 6.917417314171766,
      "grad_norm": 0.17130400240421295,
      "learning_rate": 2.8393101195643767e-05,
      "loss": 0.0464,
      "step": 100600
    },
    {
      "epoch": 6.924293474523826,
      "grad_norm": 0.13572676479816437,
      "learning_rate": 2.8371612271035507e-05,
      "loss": 0.0474,
      "step": 100700
    },
    {
      "epoch": 6.931169634875886,
      "grad_norm": 0.1347210705280304,
      "learning_rate": 2.8350123346427254e-05,
      "loss": 0.049,
      "step": 100800
    },
    {
      "epoch": 6.938045795227945,
      "grad_norm": 0.23398157954216003,
      "learning_rate": 2.8328634421818994e-05,
      "loss": 0.05,
      "step": 100900
    },
    {
      "epoch": 6.944921955580004,
      "grad_norm": 0.19021987915039062,
      "learning_rate": 2.830714549721074e-05,
      "loss": 0.0509,
      "step": 101000
    },
    {
      "epoch": 6.951798115932063,
      "grad_norm": 0.1029643639922142,
      "learning_rate": 2.828565657260248e-05,
      "loss": 0.0453,
      "step": 101100
    },
    {
      "epoch": 6.958674276284123,
      "grad_norm": 0.30572864413261414,
      "learning_rate": 2.8264167647994227e-05,
      "loss": 0.0492,
      "step": 101200
    },
    {
      "epoch": 6.965550436636183,
      "grad_norm": 0.14895597100257874,
      "learning_rate": 2.8242678723385967e-05,
      "loss": 0.048,
      "step": 101300
    },
    {
      "epoch": 6.9724265969882415,
      "grad_norm": 0.19839489459991455,
      "learning_rate": 2.8221189798777714e-05,
      "loss": 0.0466,
      "step": 101400
    },
    {
      "epoch": 6.979302757340301,
      "grad_norm": 0.19495218992233276,
      "learning_rate": 2.8199700874169454e-05,
      "loss": 0.0498,
      "step": 101500
    },
    {
      "epoch": 6.98617891769236,
      "grad_norm": 0.16528405249118805,
      "learning_rate": 2.8178211949561194e-05,
      "loss": 0.0449,
      "step": 101600
    },
    {
      "epoch": 6.99305507804442,
      "grad_norm": 0.13383601605892181,
      "learning_rate": 2.815672302495294e-05,
      "loss": 0.049,
      "step": 101700
    },
    {
      "epoch": 6.99993123839648,
      "grad_norm": 0.21195057034492493,
      "learning_rate": 2.813523410034468e-05,
      "loss": 0.0445,
      "step": 101800
    },
    {
      "epoch": 7.0,
      "eval_accuracy_macro_0.5": 0.9786339402198792,
      "eval_accuracy_micro_0.5": 0.9786339402198792,
      "eval_accuracy_weighted_0.5": 0.9759628176689148,
      "eval_f1_macro_0.5": 0.7019660472869873,
      "eval_f1_macro_0.6": 0.6756061315536499,
      "eval_f1_macro_0.7": 0.6302829384803772,
      "eval_f1_macro_0.8": 0.42606741189956665,
      "eval_f1_micro_0.5": 0.7092711925506592,
      "eval_f1_micro_0.6": 0.6876972317695618,
      "eval_f1_micro_0.7": 0.649317741394043,
      "eval_f1_micro_0.8": 0.5843756794929504,
      "eval_f1_micro_0.9": 0.4526574909687042,
      "eval_f1_weighted_0.5": 0.6995193362236023,
      "eval_f1_weighted_0.6": 0.6713457107543945,
      "eval_f1_weighted_0.7": 0.6249242424964905,
      "eval_f1_weighted_0.8": 0.4112388789653778,
      "eval_loss": 0.044799260795116425,
      "eval_runtime": 62.6763,
      "eval_samples_per_second": 463.285,
      "eval_steps_per_second": 57.917,
      "step": 101801
    },
    {
      "epoch": 7.006807398748538,
      "grad_norm": 0.13082966208457947,
      "learning_rate": 2.8113745175736427e-05,
      "loss": 0.0465,
      "step": 101900
    },
    {
      "epoch": 7.013683559100598,
      "grad_norm": 0.10594213008880615,
      "learning_rate": 2.8092256251128167e-05,
      "loss": 0.0456,
      "step": 102000
    },
    {
      "epoch": 7.020559719452658,
      "grad_norm": 0.21661417186260223,
      "learning_rate": 2.8070767326519914e-05,
      "loss": 0.0514,
      "step": 102100
    },
    {
      "epoch": 7.027435879804717,
      "grad_norm": 0.26450473070144653,
      "learning_rate": 2.8049278401911654e-05,
      "loss": 0.0481,
      "step": 102200
    },
    {
      "epoch": 7.0343120401567765,
      "grad_norm": 0.15760056674480438,
      "learning_rate": 2.80277894773034e-05,
      "loss": 0.0462,
      "step": 102300
    },
    {
      "epoch": 7.041188200508836,
      "grad_norm": 0.15005479753017426,
      "learning_rate": 2.800630055269514e-05,
      "loss": 0.0453,
      "step": 102400
    },
    {
      "epoch": 7.048064360860895,
      "grad_norm": 0.17223937809467316,
      "learning_rate": 2.7985026517332967e-05,
      "loss": 0.0463,
      "step": 102500
    },
    {
      "epoch": 7.054940521212955,
      "grad_norm": 0.08615574985742569,
      "learning_rate": 2.796353759272471e-05,
      "loss": 0.0463,
      "step": 102600
    },
    {
      "epoch": 7.0618166815650145,
      "grad_norm": 0.1374061405658722,
      "learning_rate": 2.7942048668116454e-05,
      "loss": 0.0506,
      "step": 102700
    },
    {
      "epoch": 7.068692841917073,
      "grad_norm": 0.10596764087677002,
      "learning_rate": 2.7920559743508197e-05,
      "loss": 0.0471,
      "step": 102800
    },
    {
      "epoch": 7.075569002269133,
      "grad_norm": 0.14450977742671967,
      "learning_rate": 2.789907081889994e-05,
      "loss": 0.0461,
      "step": 102900
    },
    {
      "epoch": 7.082445162621192,
      "grad_norm": 0.12063116580247879,
      "learning_rate": 2.7877581894291684e-05,
      "loss": 0.0467,
      "step": 103000
    },
    {
      "epoch": 7.089321322973252,
      "grad_norm": 0.17114420235157013,
      "learning_rate": 2.7856092969683427e-05,
      "loss": 0.0455,
      "step": 103100
    },
    {
      "epoch": 7.096197483325311,
      "grad_norm": 0.10626910626888275,
      "learning_rate": 2.783460404507517e-05,
      "loss": 0.0496,
      "step": 103200
    },
    {
      "epoch": 7.10307364367737,
      "grad_norm": 0.14712169766426086,
      "learning_rate": 2.7813115120466914e-05,
      "loss": 0.0473,
      "step": 103300
    },
    {
      "epoch": 7.10994980402943,
      "grad_norm": 0.20409728586673737,
      "learning_rate": 2.7791626195858657e-05,
      "loss": 0.046,
      "step": 103400
    },
    {
      "epoch": 7.11682596438149,
      "grad_norm": 0.29844847321510315,
      "learning_rate": 2.77701372712504e-05,
      "loss": 0.0481,
      "step": 103500
    },
    {
      "epoch": 7.123702124733549,
      "grad_norm": 0.28175878524780273,
      "learning_rate": 2.7748648346642144e-05,
      "loss": 0.0475,
      "step": 103600
    },
    {
      "epoch": 7.130578285085608,
      "grad_norm": 0.2417801022529602,
      "learning_rate": 2.7727159422033884e-05,
      "loss": 0.0472,
      "step": 103700
    },
    {
      "epoch": 7.137454445437667,
      "grad_norm": 0.10325894504785538,
      "learning_rate": 2.770567049742563e-05,
      "loss": 0.0467,
      "step": 103800
    },
    {
      "epoch": 7.144330605789727,
      "grad_norm": 0.2032528519630432,
      "learning_rate": 2.768418157281737e-05,
      "loss": 0.0463,
      "step": 103900
    },
    {
      "epoch": 7.151206766141787,
      "grad_norm": 0.1745433658361435,
      "learning_rate": 2.7662692648209114e-05,
      "loss": 0.046,
      "step": 104000
    },
    {
      "epoch": 7.1580829264938455,
      "grad_norm": 0.192905455827713,
      "learning_rate": 2.7641203723600857e-05,
      "loss": 0.0472,
      "step": 104100
    },
    {
      "epoch": 7.164959086845905,
      "grad_norm": 0.1387706995010376,
      "learning_rate": 2.76197147989926e-05,
      "loss": 0.0476,
      "step": 104200
    },
    {
      "epoch": 7.171835247197965,
      "grad_norm": 0.22171980142593384,
      "learning_rate": 2.7598225874384344e-05,
      "loss": 0.0486,
      "step": 104300
    },
    {
      "epoch": 7.178711407550024,
      "grad_norm": 0.19945058226585388,
      "learning_rate": 2.7576736949776087e-05,
      "loss": 0.046,
      "step": 104400
    },
    {
      "epoch": 7.1855875679020835,
      "grad_norm": 0.16152901947498322,
      "learning_rate": 2.755524802516783e-05,
      "loss": 0.0516,
      "step": 104500
    },
    {
      "epoch": 7.192463728254143,
      "grad_norm": 0.16778625547885895,
      "learning_rate": 2.7533973989805657e-05,
      "loss": 0.0472,
      "step": 104600
    },
    {
      "epoch": 7.199339888606202,
      "grad_norm": 0.26966792345046997,
      "learning_rate": 2.7512485065197397e-05,
      "loss": 0.0503,
      "step": 104700
    },
    {
      "epoch": 7.206216048958262,
      "grad_norm": 0.23949790000915527,
      "learning_rate": 2.7490996140589143e-05,
      "loss": 0.0524,
      "step": 104800
    },
    {
      "epoch": 7.213092209310321,
      "grad_norm": 0.1708802729845047,
      "learning_rate": 2.7469507215980883e-05,
      "loss": 0.0462,
      "step": 104900
    },
    {
      "epoch": 7.21996836966238,
      "grad_norm": 0.29540151357650757,
      "learning_rate": 2.744801829137263e-05,
      "loss": 0.0478,
      "step": 105000
    },
    {
      "epoch": 7.22684453001444,
      "grad_norm": 0.14970114827156067,
      "learning_rate": 2.742652936676437e-05,
      "loss": 0.0487,
      "step": 105100
    },
    {
      "epoch": 7.233720690366499,
      "grad_norm": 0.16783088445663452,
      "learning_rate": 2.7405040442156117e-05,
      "loss": 0.0501,
      "step": 105200
    },
    {
      "epoch": 7.240596850718559,
      "grad_norm": 0.2509339153766632,
      "learning_rate": 2.7383551517547857e-05,
      "loss": 0.048,
      "step": 105300
    },
    {
      "epoch": 7.2474730110706185,
      "grad_norm": 0.19580359756946564,
      "learning_rate": 2.7362062592939603e-05,
      "loss": 0.047,
      "step": 105400
    },
    {
      "epoch": 7.254349171422677,
      "grad_norm": 0.11706030368804932,
      "learning_rate": 2.7340573668331343e-05,
      "loss": 0.0511,
      "step": 105500
    },
    {
      "epoch": 7.261225331774737,
      "grad_norm": 0.32400980591773987,
      "learning_rate": 2.731908474372309e-05,
      "loss": 0.0436,
      "step": 105600
    },
    {
      "epoch": 7.268101492126797,
      "grad_norm": 0.10480468720197678,
      "learning_rate": 2.729759581911483e-05,
      "loss": 0.0498,
      "step": 105700
    },
    {
      "epoch": 7.274977652478856,
      "grad_norm": 0.18132315576076508,
      "learning_rate": 2.727610689450657e-05,
      "loss": 0.0476,
      "step": 105800
    },
    {
      "epoch": 7.281853812830915,
      "grad_norm": 0.1309627741575241,
      "learning_rate": 2.7254617969898317e-05,
      "loss": 0.0464,
      "step": 105900
    },
    {
      "epoch": 7.288729973182974,
      "grad_norm": 0.14096060395240784,
      "learning_rate": 2.7233129045290057e-05,
      "loss": 0.0461,
      "step": 106000
    },
    {
      "epoch": 7.295606133535034,
      "grad_norm": 0.1360417902469635,
      "learning_rate": 2.7211640120681803e-05,
      "loss": 0.0467,
      "step": 106100
    },
    {
      "epoch": 7.302482293887094,
      "grad_norm": 0.3116138279438019,
      "learning_rate": 2.7190151196073543e-05,
      "loss": 0.0474,
      "step": 106200
    },
    {
      "epoch": 7.3093584542391525,
      "grad_norm": 0.2179105281829834,
      "learning_rate": 2.716866227146529e-05,
      "loss": 0.0472,
      "step": 106300
    },
    {
      "epoch": 7.316234614591212,
      "grad_norm": 0.13377654552459717,
      "learning_rate": 2.714717334685703e-05,
      "loss": 0.0471,
      "step": 106400
    },
    {
      "epoch": 7.323110774943272,
      "grad_norm": 0.1138218343257904,
      "learning_rate": 2.7125684422248777e-05,
      "loss": 0.0481,
      "step": 106500
    },
    {
      "epoch": 7.329986935295331,
      "grad_norm": 0.17058134078979492,
      "learning_rate": 2.7104410386886596e-05,
      "loss": 0.0439,
      "step": 106600
    },
    {
      "epoch": 7.336863095647391,
      "grad_norm": 0.17816095054149628,
      "learning_rate": 2.7082921462278343e-05,
      "loss": 0.0469,
      "step": 106700
    },
    {
      "epoch": 7.34373925599945,
      "grad_norm": 0.188883438706398,
      "learning_rate": 2.7061432537670083e-05,
      "loss": 0.0463,
      "step": 106800
    },
    {
      "epoch": 7.350615416351509,
      "grad_norm": 0.18401087820529938,
      "learning_rate": 2.703994361306183e-05,
      "loss": 0.0468,
      "step": 106900
    },
    {
      "epoch": 7.357491576703569,
      "grad_norm": 0.19484111666679382,
      "learning_rate": 2.701845468845357e-05,
      "loss": 0.0478,
      "step": 107000
    },
    {
      "epoch": 7.364367737055628,
      "grad_norm": 0.08865068852901459,
      "learning_rate": 2.6996965763845316e-05,
      "loss": 0.046,
      "step": 107100
    },
    {
      "epoch": 7.3712438974076875,
      "grad_norm": 0.24645216763019562,
      "learning_rate": 2.6975476839237056e-05,
      "loss": 0.048,
      "step": 107200
    },
    {
      "epoch": 7.378120057759747,
      "grad_norm": 0.20325762033462524,
      "learning_rate": 2.6953987914628803e-05,
      "loss": 0.0456,
      "step": 107300
    },
    {
      "epoch": 7.384996218111806,
      "grad_norm": 0.232833132147789,
      "learning_rate": 2.6932498990020543e-05,
      "loss": 0.0499,
      "step": 107400
    },
    {
      "epoch": 7.391872378463866,
      "grad_norm": 0.1674581617116928,
      "learning_rate": 2.691101006541229e-05,
      "loss": 0.0495,
      "step": 107500
    },
    {
      "epoch": 7.3987485388159255,
      "grad_norm": 0.12035678327083588,
      "learning_rate": 2.688952114080403e-05,
      "loss": 0.0476,
      "step": 107600
    },
    {
      "epoch": 7.405624699167984,
      "grad_norm": 0.1638081818819046,
      "learning_rate": 2.6868032216195776e-05,
      "loss": 0.0466,
      "step": 107700
    },
    {
      "epoch": 7.412500859520044,
      "grad_norm": 0.12476623058319092,
      "learning_rate": 2.6846543291587516e-05,
      "loss": 0.0485,
      "step": 107800
    },
    {
      "epoch": 7.419377019872103,
      "grad_norm": 0.13335023820400238,
      "learning_rate": 2.6825054366979256e-05,
      "loss": 0.0466,
      "step": 107900
    },
    {
      "epoch": 7.426253180224163,
      "grad_norm": 0.1575089544057846,
      "learning_rate": 2.6803565442371003e-05,
      "loss": 0.0504,
      "step": 108000
    },
    {
      "epoch": 7.433129340576222,
      "grad_norm": 0.27182772755622864,
      "learning_rate": 2.6782076517762743e-05,
      "loss": 0.0446,
      "step": 108100
    },
    {
      "epoch": 7.440005500928281,
      "grad_norm": 0.16478338837623596,
      "learning_rate": 2.676058759315449e-05,
      "loss": 0.0459,
      "step": 108200
    },
    {
      "epoch": 7.446881661280341,
      "grad_norm": 0.2847647964954376,
      "learning_rate": 2.673909866854623e-05,
      "loss": 0.0456,
      "step": 108300
    },
    {
      "epoch": 7.453757821632401,
      "grad_norm": 0.15578213334083557,
      "learning_rate": 2.6717609743937976e-05,
      "loss": 0.0467,
      "step": 108400
    },
    {
      "epoch": 7.46063398198446,
      "grad_norm": 0.19312605261802673,
      "learning_rate": 2.6696120819329716e-05,
      "loss": 0.0467,
      "step": 108500
    },
    {
      "epoch": 7.467510142336519,
      "grad_norm": 0.17958058416843414,
      "learning_rate": 2.6675061673213626e-05,
      "loss": 0.0484,
      "step": 108600
    },
    {
      "epoch": 7.474386302688579,
      "grad_norm": 0.2356192022562027,
      "learning_rate": 2.6653572748605373e-05,
      "loss": 0.0507,
      "step": 108700
    },
    {
      "epoch": 7.481262463040638,
      "grad_norm": 0.22691485285758972,
      "learning_rate": 2.6632083823997113e-05,
      "loss": 0.0445,
      "step": 108800
    },
    {
      "epoch": 7.488138623392698,
      "grad_norm": 0.1800512820482254,
      "learning_rate": 2.661059489938886e-05,
      "loss": 0.0471,
      "step": 108900
    },
    {
      "epoch": 7.495014783744757,
      "grad_norm": 0.11200816184282303,
      "learning_rate": 2.65891059747806e-05,
      "loss": 0.0461,
      "step": 109000
    },
    {
      "epoch": 7.501890944096816,
      "grad_norm": 0.1435309797525406,
      "learning_rate": 2.6567617050172343e-05,
      "loss": 0.0498,
      "step": 109100
    },
    {
      "epoch": 7.508767104448876,
      "grad_norm": 0.21856538951396942,
      "learning_rate": 2.6546128125564086e-05,
      "loss": 0.048,
      "step": 109200
    },
    {
      "epoch": 7.515643264800935,
      "grad_norm": 0.12954820692539215,
      "learning_rate": 2.652463920095583e-05,
      "loss": 0.0485,
      "step": 109300
    },
    {
      "epoch": 7.5225194251529945,
      "grad_norm": 0.2167404294013977,
      "learning_rate": 2.6503150276347573e-05,
      "loss": 0.0465,
      "step": 109400
    },
    {
      "epoch": 7.529395585505054,
      "grad_norm": 0.10274451971054077,
      "learning_rate": 2.6481661351739316e-05,
      "loss": 0.0476,
      "step": 109500
    },
    {
      "epoch": 7.536271745857113,
      "grad_norm": 0.16675330698490143,
      "learning_rate": 2.646017242713106e-05,
      "loss": 0.0478,
      "step": 109600
    },
    {
      "epoch": 7.543147906209173,
      "grad_norm": 0.14712674915790558,
      "learning_rate": 2.64386835025228e-05,
      "loss": 0.0437,
      "step": 109700
    },
    {
      "epoch": 7.550024066561233,
      "grad_norm": 0.31213682889938354,
      "learning_rate": 2.6417194577914546e-05,
      "loss": 0.0482,
      "step": 109800
    },
    {
      "epoch": 7.556900226913291,
      "grad_norm": 0.12114162743091583,
      "learning_rate": 2.6395705653306286e-05,
      "loss": 0.0455,
      "step": 109900
    },
    {
      "epoch": 7.563776387265351,
      "grad_norm": 0.12223454564809799,
      "learning_rate": 2.6374216728698033e-05,
      "loss": 0.0493,
      "step": 110000
    },
    {
      "epoch": 7.57065254761741,
      "grad_norm": 0.1228070855140686,
      "learning_rate": 2.6352727804089773e-05,
      "loss": 0.0469,
      "step": 110100
    },
    {
      "epoch": 7.57752870796947,
      "grad_norm": 0.20679520070552826,
      "learning_rate": 2.633123887948152e-05,
      "loss": 0.0462,
      "step": 110200
    },
    {
      "epoch": 7.5844048683215295,
      "grad_norm": 0.1900874525308609,
      "learning_rate": 2.630974995487326e-05,
      "loss": 0.0495,
      "step": 110300
    },
    {
      "epoch": 7.591281028673588,
      "grad_norm": 0.23537041246891022,
      "learning_rate": 2.6288261030265006e-05,
      "loss": 0.0442,
      "step": 110400
    },
    {
      "epoch": 7.598157189025648,
      "grad_norm": 0.09374489635229111,
      "learning_rate": 2.6266772105656746e-05,
      "loss": 0.048,
      "step": 110500
    },
    {
      "epoch": 7.605033349377708,
      "grad_norm": 0.18568357825279236,
      "learning_rate": 2.6245283181048493e-05,
      "loss": 0.047,
      "step": 110600
    },
    {
      "epoch": 7.611909509729767,
      "grad_norm": 0.18785534799098969,
      "learning_rate": 2.6223794256440233e-05,
      "loss": 0.047,
      "step": 110700
    },
    {
      "epoch": 7.618785670081826,
      "grad_norm": 0.14397430419921875,
      "learning_rate": 2.620230533183198e-05,
      "loss": 0.0492,
      "step": 110800
    },
    {
      "epoch": 7.625661830433886,
      "grad_norm": 0.18080346286296844,
      "learning_rate": 2.618081640722372e-05,
      "loss": 0.0475,
      "step": 110900
    },
    {
      "epoch": 7.632537990785945,
      "grad_norm": 0.19557161629199982,
      "learning_rate": 2.615932748261546e-05,
      "loss": 0.0486,
      "step": 111000
    },
    {
      "epoch": 7.639414151138005,
      "grad_norm": 0.13691848516464233,
      "learning_rate": 2.6137838558007206e-05,
      "loss": 0.0456,
      "step": 111100
    },
    {
      "epoch": 7.646290311490064,
      "grad_norm": 0.1490350365638733,
      "learning_rate": 2.6116349633398946e-05,
      "loss": 0.0487,
      "step": 111200
    },
    {
      "epoch": 7.653166471842123,
      "grad_norm": 0.21782054007053375,
      "learning_rate": 2.6094860708790693e-05,
      "loss": 0.0452,
      "step": 111300
    },
    {
      "epoch": 7.660042632194183,
      "grad_norm": 0.10913524031639099,
      "learning_rate": 2.6073371784182433e-05,
      "loss": 0.0505,
      "step": 111400
    },
    {
      "epoch": 7.666918792546242,
      "grad_norm": 0.21756857633590698,
      "learning_rate": 2.605188285957418e-05,
      "loss": 0.0418,
      "step": 111500
    },
    {
      "epoch": 7.673794952898302,
      "grad_norm": 0.1259063333272934,
      "learning_rate": 2.603039393496592e-05,
      "loss": 0.0487,
      "step": 111600
    },
    {
      "epoch": 7.680671113250361,
      "grad_norm": 0.2252429723739624,
      "learning_rate": 2.6008905010357666e-05,
      "loss": 0.0485,
      "step": 111700
    },
    {
      "epoch": 7.68754727360242,
      "grad_norm": 0.1775754690170288,
      "learning_rate": 2.5987416085749406e-05,
      "loss": 0.0481,
      "step": 111800
    },
    {
      "epoch": 7.69442343395448,
      "grad_norm": 0.1733144372701645,
      "learning_rate": 2.5965927161141153e-05,
      "loss": 0.0488,
      "step": 111900
    },
    {
      "epoch": 7.701299594306539,
      "grad_norm": 0.2418947070837021,
      "learning_rate": 2.5944438236532893e-05,
      "loss": 0.0475,
      "step": 112000
    },
    {
      "epoch": 7.7081757546585985,
      "grad_norm": 0.15769846737384796,
      "learning_rate": 2.592294931192464e-05,
      "loss": 0.0463,
      "step": 112100
    },
    {
      "epoch": 7.715051915010658,
      "grad_norm": 0.11711112409830093,
      "learning_rate": 2.590146038731638e-05,
      "loss": 0.0492,
      "step": 112200
    },
    {
      "epoch": 7.721928075362717,
      "grad_norm": 0.23022699356079102,
      "learning_rate": 2.587997146270812e-05,
      "loss": 0.0458,
      "step": 112300
    },
    {
      "epoch": 7.728804235714777,
      "grad_norm": 0.08284393697977066,
      "learning_rate": 2.5858482538099866e-05,
      "loss": 0.0481,
      "step": 112400
    },
    {
      "epoch": 7.7356803960668366,
      "grad_norm": 0.19303812086582184,
      "learning_rate": 2.5836993613491606e-05,
      "loss": 0.0466,
      "step": 112500
    },
    {
      "epoch": 7.742556556418895,
      "grad_norm": 0.13077887892723083,
      "learning_rate": 2.5815719578129432e-05,
      "loss": 0.0463,
      "step": 112600
    },
    {
      "epoch": 7.749432716770955,
      "grad_norm": 0.2247336357831955,
      "learning_rate": 2.579423065352118e-05,
      "loss": 0.0448,
      "step": 112700
    },
    {
      "epoch": 7.756308877123015,
      "grad_norm": 0.16984114050865173,
      "learning_rate": 2.577274172891292e-05,
      "loss": 0.0449,
      "step": 112800
    },
    {
      "epoch": 7.763185037475074,
      "grad_norm": 0.08684943616390228,
      "learning_rate": 2.5751252804304666e-05,
      "loss": 0.0481,
      "step": 112900
    },
    {
      "epoch": 7.7700611978271334,
      "grad_norm": 0.12072840332984924,
      "learning_rate": 2.5729763879696406e-05,
      "loss": 0.0474,
      "step": 113000
    },
    {
      "epoch": 7.776937358179193,
      "grad_norm": 0.1574958711862564,
      "learning_rate": 2.5708274955088146e-05,
      "loss": 0.0445,
      "step": 113100
    },
    {
      "epoch": 7.783813518531252,
      "grad_norm": 0.13756176829338074,
      "learning_rate": 2.5686786030479892e-05,
      "loss": 0.0479,
      "step": 113200
    },
    {
      "epoch": 7.790689678883312,
      "grad_norm": 0.1376602053642273,
      "learning_rate": 2.5665297105871632e-05,
      "loss": 0.046,
      "step": 113300
    },
    {
      "epoch": 7.797565839235371,
      "grad_norm": 0.1554252803325653,
      "learning_rate": 2.564380818126338e-05,
      "loss": 0.0456,
      "step": 113400
    },
    {
      "epoch": 7.80444199958743,
      "grad_norm": 0.33548134565353394,
      "learning_rate": 2.562231925665512e-05,
      "loss": 0.0455,
      "step": 113500
    },
    {
      "epoch": 7.81131815993949,
      "grad_norm": 0.14426258206367493,
      "learning_rate": 2.5600830332046866e-05,
      "loss": 0.0493,
      "step": 113600
    },
    {
      "epoch": 7.818194320291549,
      "grad_norm": 0.2541208565235138,
      "learning_rate": 2.5579341407438606e-05,
      "loss": 0.0444,
      "step": 113700
    },
    {
      "epoch": 7.825070480643609,
      "grad_norm": 0.21448694169521332,
      "learning_rate": 2.5557852482830352e-05,
      "loss": 0.0463,
      "step": 113800
    },
    {
      "epoch": 7.831946640995668,
      "grad_norm": 0.17858363687992096,
      "learning_rate": 2.5536363558222092e-05,
      "loss": 0.0456,
      "step": 113900
    },
    {
      "epoch": 7.838822801347727,
      "grad_norm": 0.2414616495370865,
      "learning_rate": 2.551487463361384e-05,
      "loss": 0.0467,
      "step": 114000
    },
    {
      "epoch": 7.845698961699787,
      "grad_norm": 0.17769765853881836,
      "learning_rate": 2.549338570900558e-05,
      "loss": 0.0478,
      "step": 114100
    },
    {
      "epoch": 7.852575122051846,
      "grad_norm": 0.1328130066394806,
      "learning_rate": 2.5471896784397326e-05,
      "loss": 0.0466,
      "step": 114200
    },
    {
      "epoch": 7.859451282403906,
      "grad_norm": 0.266446053981781,
      "learning_rate": 2.5450407859789066e-05,
      "loss": 0.0484,
      "step": 114300
    },
    {
      "epoch": 7.866327442755965,
      "grad_norm": 0.21514053642749786,
      "learning_rate": 2.5428918935180805e-05,
      "loss": 0.045,
      "step": 114400
    },
    {
      "epoch": 7.873203603108024,
      "grad_norm": 0.3484307825565338,
      "learning_rate": 2.5407430010572552e-05,
      "loss": 0.0512,
      "step": 114500
    },
    {
      "epoch": 7.880079763460084,
      "grad_norm": 0.13730597496032715,
      "learning_rate": 2.538615597521038e-05,
      "loss": 0.0464,
      "step": 114600
    },
    {
      "epoch": 7.886955923812144,
      "grad_norm": 0.0923125222325325,
      "learning_rate": 2.536466705060212e-05,
      "loss": 0.0476,
      "step": 114700
    },
    {
      "epoch": 7.8938320841642025,
      "grad_norm": 0.20921030640602112,
      "learning_rate": 2.5343178125993865e-05,
      "loss": 0.044,
      "step": 114800
    },
    {
      "epoch": 7.900708244516262,
      "grad_norm": 0.18630853295326233,
      "learning_rate": 2.5321689201385605e-05,
      "loss": 0.0502,
      "step": 114900
    },
    {
      "epoch": 7.907584404868322,
      "grad_norm": 0.2560465633869171,
      "learning_rate": 2.5300200276777352e-05,
      "loss": 0.0475,
      "step": 115000
    },
    {
      "epoch": 7.914460565220381,
      "grad_norm": 0.15321463346481323,
      "learning_rate": 2.5278711352169092e-05,
      "loss": 0.0476,
      "step": 115100
    },
    {
      "epoch": 7.9213367255724405,
      "grad_norm": 0.1988256722688675,
      "learning_rate": 2.5257222427560835e-05,
      "loss": 0.0485,
      "step": 115200
    },
    {
      "epoch": 7.9282128859245,
      "grad_norm": 0.15259550511837006,
      "learning_rate": 2.523573350295258e-05,
      "loss": 0.0458,
      "step": 115300
    },
    {
      "epoch": 7.935089046276559,
      "grad_norm": 0.21314960718154907,
      "learning_rate": 2.5214244578344322e-05,
      "loss": 0.0434,
      "step": 115400
    },
    {
      "epoch": 7.941965206628619,
      "grad_norm": 0.11439536511898041,
      "learning_rate": 2.5192755653736065e-05,
      "loss": 0.0492,
      "step": 115500
    },
    {
      "epoch": 7.948841366980678,
      "grad_norm": 0.18395669758319855,
      "learning_rate": 2.5171481618373892e-05,
      "loss": 0.0477,
      "step": 115600
    },
    {
      "epoch": 7.955717527332737,
      "grad_norm": 0.16858690977096558,
      "learning_rate": 2.5149992693765635e-05,
      "loss": 0.0483,
      "step": 115700
    },
    {
      "epoch": 7.962593687684797,
      "grad_norm": 0.18301790952682495,
      "learning_rate": 2.512850376915738e-05,
      "loss": 0.0483,
      "step": 115800
    },
    {
      "epoch": 7.969469848036856,
      "grad_norm": 0.10804954171180725,
      "learning_rate": 2.5107014844549122e-05,
      "loss": 0.0433,
      "step": 115900
    },
    {
      "epoch": 7.976346008388916,
      "grad_norm": 0.14983873069286346,
      "learning_rate": 2.508552591994086e-05,
      "loss": 0.0461,
      "step": 116000
    },
    {
      "epoch": 7.983222168740975,
      "grad_norm": 0.15302985906600952,
      "learning_rate": 2.506403699533261e-05,
      "loss": 0.0451,
      "step": 116100
    },
    {
      "epoch": 7.990098329093034,
      "grad_norm": 0.14359042048454285,
      "learning_rate": 2.504254807072435e-05,
      "loss": 0.048,
      "step": 116200
    },
    {
      "epoch": 7.996974489445094,
      "grad_norm": 0.2717386484146118,
      "learning_rate": 2.5021059146116095e-05,
      "loss": 0.0452,
      "step": 116300
    },
    {
      "epoch": 8.0,
      "eval_accuracy_macro_0.5": 0.9791795611381531,
      "eval_accuracy_micro_0.5": 0.9791795611381531,
      "eval_accuracy_weighted_0.5": 0.9765734076499939,
      "eval_f1_macro_0.5": 0.7091383337974548,
      "eval_f1_macro_0.6": 0.6817946434020996,
      "eval_f1_macro_0.7": 0.6378555297851562,
      "eval_f1_macro_0.8": 0.43635934591293335,
      "eval_f1_micro_0.5": 0.7156755924224854,
      "eval_f1_micro_0.6": 0.6933010220527649,
      "eval_f1_micro_0.7": 0.6547145843505859,
      "eval_f1_micro_0.8": 0.5898529887199402,
      "eval_f1_micro_0.9": 0.46309176087379456,
      "eval_f1_weighted_0.5": 0.7062316536903381,
      "eval_f1_weighted_0.6": 0.6770024299621582,
      "eval_f1_weighted_0.7": 0.6311350464820862,
      "eval_f1_weighted_0.8": 0.42194387316703796,
      "eval_loss": 0.04362121969461441,
      "eval_runtime": 63.2111,
      "eval_samples_per_second": 459.365,
      "eval_steps_per_second": 57.427,
      "step": 116344
    },
    {
      "epoch": 8.003850649797153,
      "grad_norm": 0.3883031904697418,
      "learning_rate": 2.499957022150784e-05,
      "loss": 0.0458,
      "step": 116400
    },
    {
      "epoch": 8.010726810149214,
      "grad_norm": 0.15171197056770325,
      "learning_rate": 2.4978081296899582e-05,
      "loss": 0.049,
      "step": 116500
    },
    {
      "epoch": 8.017602970501272,
      "grad_norm": 0.10325693339109421,
      "learning_rate": 2.4956592372291325e-05,
      "loss": 0.0509,
      "step": 116600
    },
    {
      "epoch": 8.024479130853331,
      "grad_norm": 0.21013253927230835,
      "learning_rate": 2.4935103447683065e-05,
      "loss": 0.0459,
      "step": 116700
    },
    {
      "epoch": 8.03135529120539,
      "grad_norm": 0.1566343754529953,
      "learning_rate": 2.491361452307481e-05,
      "loss": 0.0487,
      "step": 116800
    },
    {
      "epoch": 8.03823145155745,
      "grad_norm": 0.2380363792181015,
      "learning_rate": 2.489212559846655e-05,
      "loss": 0.0454,
      "step": 116900
    },
    {
      "epoch": 8.04510761190951,
      "grad_norm": 0.10262398421764374,
      "learning_rate": 2.4870636673858295e-05,
      "loss": 0.0454,
      "step": 117000
    },
    {
      "epoch": 8.051983772261568,
      "grad_norm": 0.08928678929805756,
      "learning_rate": 2.484914774925004e-05,
      "loss": 0.0453,
      "step": 117100
    },
    {
      "epoch": 8.058859932613629,
      "grad_norm": 0.1468639075756073,
      "learning_rate": 2.482765882464178e-05,
      "loss": 0.045,
      "step": 117200
    },
    {
      "epoch": 8.065736092965688,
      "grad_norm": 0.12671194970607758,
      "learning_rate": 2.4806169900033525e-05,
      "loss": 0.046,
      "step": 117300
    },
    {
      "epoch": 8.072612253317747,
      "grad_norm": 0.21139486134052277,
      "learning_rate": 2.478468097542527e-05,
      "loss": 0.0454,
      "step": 117400
    },
    {
      "epoch": 8.079488413669807,
      "grad_norm": 0.1696605682373047,
      "learning_rate": 2.476319205081701e-05,
      "loss": 0.0476,
      "step": 117500
    },
    {
      "epoch": 8.086364574021866,
      "grad_norm": 0.24295279383659363,
      "learning_rate": 2.4741703126208755e-05,
      "loss": 0.0448,
      "step": 117600
    },
    {
      "epoch": 8.093240734373925,
      "grad_norm": 0.18265549838542938,
      "learning_rate": 2.4720429090846578e-05,
      "loss": 0.0457,
      "step": 117700
    },
    {
      "epoch": 8.100116894725986,
      "grad_norm": 0.17006853222846985,
      "learning_rate": 2.469894016623832e-05,
      "loss": 0.0476,
      "step": 117800
    },
    {
      "epoch": 8.106993055078044,
      "grad_norm": 0.1167948916554451,
      "learning_rate": 2.4677451241630065e-05,
      "loss": 0.0501,
      "step": 117900
    },
    {
      "epoch": 8.113869215430103,
      "grad_norm": 0.18746709823608398,
      "learning_rate": 2.4655962317021808e-05,
      "loss": 0.0452,
      "step": 118000
    },
    {
      "epoch": 8.120745375782164,
      "grad_norm": 0.17912065982818604,
      "learning_rate": 2.463447339241355e-05,
      "loss": 0.0481,
      "step": 118100
    },
    {
      "epoch": 8.127621536134223,
      "grad_norm": 0.08903234452009201,
      "learning_rate": 2.4612984467805295e-05,
      "loss": 0.0488,
      "step": 118200
    },
    {
      "epoch": 8.134497696486282,
      "grad_norm": 0.13377806544303894,
      "learning_rate": 2.4591495543197038e-05,
      "loss": 0.047,
      "step": 118300
    },
    {
      "epoch": 8.141373856838342,
      "grad_norm": 0.10994423925876617,
      "learning_rate": 2.457000661858878e-05,
      "loss": 0.0475,
      "step": 118400
    },
    {
      "epoch": 8.148250017190401,
      "grad_norm": 0.20997031033039093,
      "learning_rate": 2.4548517693980525e-05,
      "loss": 0.0508,
      "step": 118500
    },
    {
      "epoch": 8.15512617754246,
      "grad_norm": 0.24179421365261078,
      "learning_rate": 2.4527028769372268e-05,
      "loss": 0.0438,
      "step": 118600
    },
    {
      "epoch": 8.16200233789452,
      "grad_norm": 0.22018621861934662,
      "learning_rate": 2.450553984476401e-05,
      "loss": 0.0458,
      "step": 118700
    },
    {
      "epoch": 8.16887849824658,
      "grad_norm": 0.23377947509288788,
      "learning_rate": 2.448405092015575e-05,
      "loss": 0.0494,
      "step": 118800
    },
    {
      "epoch": 8.175754658598638,
      "grad_norm": 0.18525275588035583,
      "learning_rate": 2.4462561995547495e-05,
      "loss": 0.0476,
      "step": 118900
    },
    {
      "epoch": 8.182630818950697,
      "grad_norm": 0.10712961107492447,
      "learning_rate": 2.4441073070939238e-05,
      "loss": 0.0452,
      "step": 119000
    },
    {
      "epoch": 8.189506979302758,
      "grad_norm": 0.13898512721061707,
      "learning_rate": 2.441958414633098e-05,
      "loss": 0.0481,
      "step": 119100
    },
    {
      "epoch": 8.196383139654817,
      "grad_norm": 0.11879934370517731,
      "learning_rate": 2.4398095221722725e-05,
      "loss": 0.0462,
      "step": 119200
    },
    {
      "epoch": 8.203259300006875,
      "grad_norm": 0.13352665305137634,
      "learning_rate": 2.4376606297114468e-05,
      "loss": 0.0467,
      "step": 119300
    },
    {
      "epoch": 8.210135460358936,
      "grad_norm": 0.1425401121377945,
      "learning_rate": 2.435511737250621e-05,
      "loss": 0.0458,
      "step": 119400
    },
    {
      "epoch": 8.217011620710995,
      "grad_norm": 0.20401230454444885,
      "learning_rate": 2.4333628447897955e-05,
      "loss": 0.049,
      "step": 119500
    },
    {
      "epoch": 8.223887781063054,
      "grad_norm": 0.22017714381217957,
      "learning_rate": 2.4312139523289698e-05,
      "loss": 0.0485,
      "step": 119600
    },
    {
      "epoch": 8.230763941415114,
      "grad_norm": 0.1416248232126236,
      "learning_rate": 2.429065059868144e-05,
      "loss": 0.0445,
      "step": 119700
    },
    {
      "epoch": 8.237640101767173,
      "grad_norm": 0.05741144344210625,
      "learning_rate": 2.4269161674073185e-05,
      "loss": 0.0448,
      "step": 119800
    },
    {
      "epoch": 8.244516262119232,
      "grad_norm": 0.2598976194858551,
      "learning_rate": 2.4247672749464928e-05,
      "loss": 0.0424,
      "step": 119900
    },
    {
      "epoch": 8.251392422471293,
      "grad_norm": 0.15847860276699066,
      "learning_rate": 2.422618382485667e-05,
      "loss": 0.0503,
      "step": 120000
    },
    {
      "epoch": 8.258268582823352,
      "grad_norm": 0.07282419502735138,
      "learning_rate": 2.420469490024841e-05,
      "loss": 0.0454,
      "step": 120100
    },
    {
      "epoch": 8.26514474317541,
      "grad_norm": 0.13371115922927856,
      "learning_rate": 2.4183205975640155e-05,
      "loss": 0.0453,
      "step": 120200
    },
    {
      "epoch": 8.272020903527471,
      "grad_norm": 0.19346173107624054,
      "learning_rate": 2.4161717051031898e-05,
      "loss": 0.0472,
      "step": 120300
    },
    {
      "epoch": 8.27889706387953,
      "grad_norm": 0.10399024188518524,
      "learning_rate": 2.414022812642364e-05,
      "loss": 0.0428,
      "step": 120400
    },
    {
      "epoch": 8.285773224231589,
      "grad_norm": 0.12504661083221436,
      "learning_rate": 2.4118954091061468e-05,
      "loss": 0.0478,
      "step": 120500
    },
    {
      "epoch": 8.29264938458365,
      "grad_norm": 0.26637592911720276,
      "learning_rate": 2.409746516645321e-05,
      "loss": 0.0481,
      "step": 120600
    },
    {
      "epoch": 8.299525544935708,
      "grad_norm": 0.17554871737957,
      "learning_rate": 2.4075976241844954e-05,
      "loss": 0.0469,
      "step": 120700
    },
    {
      "epoch": 8.306401705287767,
      "grad_norm": 0.29039376974105835,
      "learning_rate": 2.4054487317236698e-05,
      "loss": 0.0463,
      "step": 120800
    },
    {
      "epoch": 8.313277865639826,
      "grad_norm": 0.1528547704219818,
      "learning_rate": 2.4032998392628438e-05,
      "loss": 0.0498,
      "step": 120900
    },
    {
      "epoch": 8.320154025991886,
      "grad_norm": 0.14673687517642975,
      "learning_rate": 2.401150946802018e-05,
      "loss": 0.0489,
      "step": 121000
    },
    {
      "epoch": 8.327030186343945,
      "grad_norm": 0.12656305730342865,
      "learning_rate": 2.3990020543411924e-05,
      "loss": 0.0461,
      "step": 121100
    },
    {
      "epoch": 8.333906346696004,
      "grad_norm": 0.21318642795085907,
      "learning_rate": 2.3968531618803668e-05,
      "loss": 0.0455,
      "step": 121200
    },
    {
      "epoch": 8.340782507048065,
      "grad_norm": 0.22482402622699738,
      "learning_rate": 2.394704269419541e-05,
      "loss": 0.0441,
      "step": 121300
    },
    {
      "epoch": 8.347658667400124,
      "grad_norm": 0.22503496706485748,
      "learning_rate": 2.3925553769587154e-05,
      "loss": 0.0491,
      "step": 121400
    },
    {
      "epoch": 8.354534827752182,
      "grad_norm": 0.11177996546030045,
      "learning_rate": 2.3904064844978898e-05,
      "loss": 0.0474,
      "step": 121500
    },
    {
      "epoch": 8.361410988104243,
      "grad_norm": 0.11414194852113724,
      "learning_rate": 2.388257592037064e-05,
      "loss": 0.0436,
      "step": 121600
    },
    {
      "epoch": 8.368287148456302,
      "grad_norm": 0.153022900223732,
      "learning_rate": 2.3861086995762384e-05,
      "loss": 0.0454,
      "step": 121700
    },
    {
      "epoch": 8.37516330880836,
      "grad_norm": 0.10030769556760788,
      "learning_rate": 2.3839598071154128e-05,
      "loss": 0.0468,
      "step": 121800
    },
    {
      "epoch": 8.382039469160421,
      "grad_norm": 0.19727107882499695,
      "learning_rate": 2.381810914654587e-05,
      "loss": 0.0483,
      "step": 121900
    },
    {
      "epoch": 8.38891562951248,
      "grad_norm": 0.1935489922761917,
      "learning_rate": 2.3796620221937614e-05,
      "loss": 0.0433,
      "step": 122000
    },
    {
      "epoch": 8.39579178986454,
      "grad_norm": 0.24765309691429138,
      "learning_rate": 2.3775131297329358e-05,
      "loss": 0.047,
      "step": 122100
    },
    {
      "epoch": 8.4026679502166,
      "grad_norm": 0.15108899772167206,
      "learning_rate": 2.37536423727211e-05,
      "loss": 0.0462,
      "step": 122200
    },
    {
      "epoch": 8.409544110568659,
      "grad_norm": 0.11698941886425018,
      "learning_rate": 2.3732153448112844e-05,
      "loss": 0.0476,
      "step": 122300
    },
    {
      "epoch": 8.416420270920717,
      "grad_norm": 0.21949443221092224,
      "learning_rate": 2.3710664523504588e-05,
      "loss": 0.0422,
      "step": 122400
    },
    {
      "epoch": 8.423296431272778,
      "grad_norm": 0.14142629504203796,
      "learning_rate": 2.3689175598896328e-05,
      "loss": 0.0463,
      "step": 122500
    },
    {
      "epoch": 8.430172591624837,
      "grad_norm": 0.1434049904346466,
      "learning_rate": 2.366768667428807e-05,
      "loss": 0.0478,
      "step": 122600
    },
    {
      "epoch": 8.437048751976896,
      "grad_norm": 0.17376644909381866,
      "learning_rate": 2.3646197749679814e-05,
      "loss": 0.0478,
      "step": 122700
    },
    {
      "epoch": 8.443924912328956,
      "grad_norm": 0.2347191423177719,
      "learning_rate": 2.3624708825071558e-05,
      "loss": 0.0469,
      "step": 122800
    },
    {
      "epoch": 8.450801072681015,
      "grad_norm": 0.1672535389661789,
      "learning_rate": 2.36032199004633e-05,
      "loss": 0.0482,
      "step": 122900
    },
    {
      "epoch": 8.457677233033074,
      "grad_norm": 0.1790105700492859,
      "learning_rate": 2.3581730975855044e-05,
      "loss": 0.0453,
      "step": 123000
    },
    {
      "epoch": 8.464553393385133,
      "grad_norm": 0.10950320214033127,
      "learning_rate": 2.3560242051246788e-05,
      "loss": 0.0479,
      "step": 123100
    },
    {
      "epoch": 8.471429553737194,
      "grad_norm": 0.11637663841247559,
      "learning_rate": 2.353875312663853e-05,
      "loss": 0.0467,
      "step": 123200
    },
    {
      "epoch": 8.478305714089252,
      "grad_norm": 0.09599614888429642,
      "learning_rate": 2.3517264202030274e-05,
      "loss": 0.0448,
      "step": 123300
    },
    {
      "epoch": 8.485181874441311,
      "grad_norm": 0.1577756106853485,
      "learning_rate": 2.3495775277422018e-05,
      "loss": 0.045,
      "step": 123400
    },
    {
      "epoch": 8.492058034793372,
      "grad_norm": 0.20188571512699127,
      "learning_rate": 2.347428635281376e-05,
      "loss": 0.0451,
      "step": 123500
    },
    {
      "epoch": 8.49893419514543,
      "grad_norm": 0.18685941398143768,
      "learning_rate": 2.3452797428205504e-05,
      "loss": 0.0454,
      "step": 123600
    },
    {
      "epoch": 8.50581035549749,
      "grad_norm": 0.14643505215644836,
      "learning_rate": 2.3431308503597248e-05,
      "loss": 0.0442,
      "step": 123700
    },
    {
      "epoch": 8.51268651584955,
      "grad_norm": 0.2518877685070038,
      "learning_rate": 2.340981957898899e-05,
      "loss": 0.0502,
      "step": 123800
    },
    {
      "epoch": 8.519562676201609,
      "grad_norm": 0.12923887372016907,
      "learning_rate": 2.3388330654380734e-05,
      "loss": 0.0466,
      "step": 123900
    },
    {
      "epoch": 8.526438836553668,
      "grad_norm": 0.26298487186431885,
      "learning_rate": 2.3366841729772478e-05,
      "loss": 0.046,
      "step": 124000
    },
    {
      "epoch": 8.533314996905728,
      "grad_norm": 0.0777653157711029,
      "learning_rate": 2.334535280516422e-05,
      "loss": 0.0455,
      "step": 124100
    },
    {
      "epoch": 8.540191157257787,
      "grad_norm": 0.16635164618492126,
      "learning_rate": 2.3323863880555964e-05,
      "loss": 0.0443,
      "step": 124200
    },
    {
      "epoch": 8.547067317609846,
      "grad_norm": 0.13648566603660583,
      "learning_rate": 2.3302374955947708e-05,
      "loss": 0.046,
      "step": 124300
    },
    {
      "epoch": 8.553943477961907,
      "grad_norm": 0.20021572709083557,
      "learning_rate": 2.328088603133945e-05,
      "loss": 0.0434,
      "step": 124400
    },
    {
      "epoch": 8.560819638313966,
      "grad_norm": 0.11192688345909119,
      "learning_rate": 2.3259611995977274e-05,
      "loss": 0.044,
      "step": 124500
    },
    {
      "epoch": 8.567695798666024,
      "grad_norm": 0.14165689051151276,
      "learning_rate": 2.3238123071369017e-05,
      "loss": 0.0456,
      "step": 124600
    },
    {
      "epoch": 8.574571959018085,
      "grad_norm": 0.2366306483745575,
      "learning_rate": 2.321663414676076e-05,
      "loss": 0.0458,
      "step": 124700
    },
    {
      "epoch": 8.581448119370144,
      "grad_norm": 0.12280306965112686,
      "learning_rate": 2.3195145222152504e-05,
      "loss": 0.0473,
      "step": 124800
    },
    {
      "epoch": 8.588324279722203,
      "grad_norm": 0.18643689155578613,
      "learning_rate": 2.3173656297544247e-05,
      "loss": 0.0457,
      "step": 124900
    },
    {
      "epoch": 8.595200440074262,
      "grad_norm": 0.1473185122013092,
      "learning_rate": 2.315216737293599e-05,
      "loss": 0.0494,
      "step": 125000
    },
    {
      "epoch": 8.602076600426322,
      "grad_norm": 0.14596059918403625,
      "learning_rate": 2.3130678448327734e-05,
      "loss": 0.0464,
      "step": 125100
    },
    {
      "epoch": 8.608952760778381,
      "grad_norm": 0.1469254195690155,
      "learning_rate": 2.3109189523719477e-05,
      "loss": 0.0471,
      "step": 125200
    },
    {
      "epoch": 8.61582892113044,
      "grad_norm": 0.18425332009792328,
      "learning_rate": 2.308770059911122e-05,
      "loss": 0.0453,
      "step": 125300
    },
    {
      "epoch": 8.6227050814825,
      "grad_norm": 0.2929280996322632,
      "learning_rate": 2.3066211674502964e-05,
      "loss": 0.0491,
      "step": 125400
    },
    {
      "epoch": 8.62958124183456,
      "grad_norm": 0.19892340898513794,
      "learning_rate": 2.3044722749894707e-05,
      "loss": 0.0458,
      "step": 125500
    },
    {
      "epoch": 8.636457402186618,
      "grad_norm": 0.20429359376430511,
      "learning_rate": 2.3023233825286447e-05,
      "loss": 0.0474,
      "step": 125600
    },
    {
      "epoch": 8.643333562538679,
      "grad_norm": 0.25218015909194946,
      "learning_rate": 2.300174490067819e-05,
      "loss": 0.0483,
      "step": 125700
    },
    {
      "epoch": 8.650209722890738,
      "grad_norm": 0.19161547720432281,
      "learning_rate": 2.2980255976069934e-05,
      "loss": 0.0448,
      "step": 125800
    },
    {
      "epoch": 8.657085883242797,
      "grad_norm": 0.16267499327659607,
      "learning_rate": 2.2958767051461677e-05,
      "loss": 0.0473,
      "step": 125900
    },
    {
      "epoch": 8.663962043594857,
      "grad_norm": 0.11855807155370712,
      "learning_rate": 2.293727812685342e-05,
      "loss": 0.0463,
      "step": 126000
    },
    {
      "epoch": 8.670838203946916,
      "grad_norm": 0.16414813697338104,
      "learning_rate": 2.2915789202245164e-05,
      "loss": 0.0448,
      "step": 126100
    },
    {
      "epoch": 8.677714364298975,
      "grad_norm": 0.22243322432041168,
      "learning_rate": 2.2894300277636907e-05,
      "loss": 0.0454,
      "step": 126200
    },
    {
      "epoch": 8.684590524651036,
      "grad_norm": 0.17794039845466614,
      "learning_rate": 2.287281135302865e-05,
      "loss": 0.0464,
      "step": 126300
    },
    {
      "epoch": 8.691466685003094,
      "grad_norm": 0.3161318600177765,
      "learning_rate": 2.2851322428420394e-05,
      "loss": 0.0481,
      "step": 126400
    },
    {
      "epoch": 8.698342845355153,
      "grad_norm": 0.15154653787612915,
      "learning_rate": 2.2829833503812137e-05,
      "loss": 0.049,
      "step": 126500
    },
    {
      "epoch": 8.705219005707214,
      "grad_norm": 0.23560373485088348,
      "learning_rate": 2.280834457920388e-05,
      "loss": 0.0445,
      "step": 126600
    },
    {
      "epoch": 8.712095166059273,
      "grad_norm": 0.1169588714838028,
      "learning_rate": 2.2787070543841704e-05,
      "loss": 0.0448,
      "step": 126700
    },
    {
      "epoch": 8.718971326411332,
      "grad_norm": 0.11667201668024063,
      "learning_rate": 2.2765581619233447e-05,
      "loss": 0.0453,
      "step": 126800
    },
    {
      "epoch": 8.725847486763392,
      "grad_norm": 0.1269325166940689,
      "learning_rate": 2.274409269462519e-05,
      "loss": 0.0454,
      "step": 126900
    },
    {
      "epoch": 8.732723647115451,
      "grad_norm": 0.1968708336353302,
      "learning_rate": 2.2722818659263017e-05,
      "loss": 0.052,
      "step": 127000
    },
    {
      "epoch": 8.73959980746751,
      "grad_norm": 0.16994278132915497,
      "learning_rate": 2.270132973465476e-05,
      "loss": 0.0438,
      "step": 127100
    },
    {
      "epoch": 8.74647596781957,
      "grad_norm": 0.2094152867794037,
      "learning_rate": 2.2679840810046504e-05,
      "loss": 0.0487,
      "step": 127200
    },
    {
      "epoch": 8.75335212817163,
      "grad_norm": 0.14347043633460999,
      "learning_rate": 2.2658351885438243e-05,
      "loss": 0.0465,
      "step": 127300
    },
    {
      "epoch": 8.760228288523688,
      "grad_norm": 0.1600981056690216,
      "learning_rate": 2.2636862960829987e-05,
      "loss": 0.0474,
      "step": 127400
    },
    {
      "epoch": 8.767104448875747,
      "grad_norm": 0.20656223595142365,
      "learning_rate": 2.261537403622173e-05,
      "loss": 0.0452,
      "step": 127500
    },
    {
      "epoch": 8.773980609227808,
      "grad_norm": 0.13221478462219238,
      "learning_rate": 2.2593885111613473e-05,
      "loss": 0.0485,
      "step": 127600
    },
    {
      "epoch": 8.780856769579866,
      "grad_norm": 0.14401963353157043,
      "learning_rate": 2.2572396187005217e-05,
      "loss": 0.0488,
      "step": 127700
    },
    {
      "epoch": 8.787732929931925,
      "grad_norm": 0.18271633982658386,
      "learning_rate": 2.255090726239696e-05,
      "loss": 0.0482,
      "step": 127800
    },
    {
      "epoch": 8.794609090283986,
      "grad_norm": 0.16720134019851685,
      "learning_rate": 2.2529418337788703e-05,
      "loss": 0.0455,
      "step": 127900
    },
    {
      "epoch": 8.801485250636045,
      "grad_norm": 0.2094048112630844,
      "learning_rate": 2.2507929413180447e-05,
      "loss": 0.0446,
      "step": 128000
    },
    {
      "epoch": 8.808361410988104,
      "grad_norm": 0.1069711446762085,
      "learning_rate": 2.248644048857219e-05,
      "loss": 0.0462,
      "step": 128100
    },
    {
      "epoch": 8.815237571340164,
      "grad_norm": 0.22063058614730835,
      "learning_rate": 2.2464951563963933e-05,
      "loss": 0.0452,
      "step": 128200
    },
    {
      "epoch": 8.822113731692223,
      "grad_norm": 0.17253932356834412,
      "learning_rate": 2.2443462639355677e-05,
      "loss": 0.0493,
      "step": 128300
    },
    {
      "epoch": 8.828989892044282,
      "grad_norm": 0.214054673910141,
      "learning_rate": 2.242197371474742e-05,
      "loss": 0.0447,
      "step": 128400
    },
    {
      "epoch": 8.835866052396343,
      "grad_norm": 0.14068280160427094,
      "learning_rate": 2.2400484790139163e-05,
      "loss": 0.0474,
      "step": 128500
    },
    {
      "epoch": 8.842742212748401,
      "grad_norm": 0.11865478754043579,
      "learning_rate": 2.2378995865530907e-05,
      "loss": 0.0437,
      "step": 128600
    },
    {
      "epoch": 8.84961837310046,
      "grad_norm": 0.10414842516183853,
      "learning_rate": 2.2357506940922647e-05,
      "loss": 0.0468,
      "step": 128700
    },
    {
      "epoch": 8.856494533452521,
      "grad_norm": 0.15122748911380768,
      "learning_rate": 2.233601801631439e-05,
      "loss": 0.0467,
      "step": 128800
    },
    {
      "epoch": 8.86337069380458,
      "grad_norm": 0.09873919934034348,
      "learning_rate": 2.2314529091706133e-05,
      "loss": 0.0445,
      "step": 128900
    },
    {
      "epoch": 8.870246854156639,
      "grad_norm": 0.22258949279785156,
      "learning_rate": 2.2293040167097877e-05,
      "loss": 0.0452,
      "step": 129000
    },
    {
      "epoch": 8.877123014508697,
      "grad_norm": 0.18035924434661865,
      "learning_rate": 2.227155124248962e-05,
      "loss": 0.0487,
      "step": 129100
    },
    {
      "epoch": 8.883999174860758,
      "grad_norm": 0.2357456237077713,
      "learning_rate": 2.2250062317881363e-05,
      "loss": 0.0456,
      "step": 129200
    },
    {
      "epoch": 8.890875335212817,
      "grad_norm": 0.1561465859413147,
      "learning_rate": 2.2228573393273107e-05,
      "loss": 0.0455,
      "step": 129300
    },
    {
      "epoch": 8.897751495564876,
      "grad_norm": 0.2512297034263611,
      "learning_rate": 2.220708446866485e-05,
      "loss": 0.0451,
      "step": 129400
    },
    {
      "epoch": 8.904627655916936,
      "grad_norm": 0.1280367523431778,
      "learning_rate": 2.2185595544056593e-05,
      "loss": 0.0445,
      "step": 129500
    },
    {
      "epoch": 8.911503816268995,
      "grad_norm": 0.19194559752941132,
      "learning_rate": 2.2164106619448337e-05,
      "loss": 0.0468,
      "step": 129600
    },
    {
      "epoch": 8.918379976621054,
      "grad_norm": 0.11496354639530182,
      "learning_rate": 2.214261769484008e-05,
      "loss": 0.0438,
      "step": 129700
    },
    {
      "epoch": 8.925256136973115,
      "grad_norm": 0.21531976759433746,
      "learning_rate": 2.2121343659477907e-05,
      "loss": 0.0477,
      "step": 129800
    },
    {
      "epoch": 8.932132297325174,
      "grad_norm": 0.23087041079998016,
      "learning_rate": 2.209985473486965e-05,
      "loss": 0.0454,
      "step": 129900
    },
    {
      "epoch": 8.939008457677232,
      "grad_norm": 0.09459324181079865,
      "learning_rate": 2.2078365810261393e-05,
      "loss": 0.0461,
      "step": 130000
    },
    {
      "epoch": 8.945884618029293,
      "grad_norm": 0.1840638518333435,
      "learning_rate": 2.2056876885653137e-05,
      "loss": 0.0484,
      "step": 130100
    },
    {
      "epoch": 8.952760778381352,
      "grad_norm": 0.23132139444351196,
      "learning_rate": 2.203538796104488e-05,
      "loss": 0.0446,
      "step": 130200
    },
    {
      "epoch": 8.95963693873341,
      "grad_norm": 0.16085706651210785,
      "learning_rate": 2.2013899036436623e-05,
      "loss": 0.0468,
      "step": 130300
    },
    {
      "epoch": 8.966513099085471,
      "grad_norm": 0.15283435583114624,
      "learning_rate": 2.1992410111828367e-05,
      "loss": 0.0457,
      "step": 130400
    },
    {
      "epoch": 8.97338925943753,
      "grad_norm": 0.15608735382556915,
      "learning_rate": 2.197092118722011e-05,
      "loss": 0.0443,
      "step": 130500
    },
    {
      "epoch": 8.980265419789589,
      "grad_norm": 0.16481265425682068,
      "learning_rate": 2.1949432262611853e-05,
      "loss": 0.0478,
      "step": 130600
    },
    {
      "epoch": 8.98714158014165,
      "grad_norm": 0.19064733386039734,
      "learning_rate": 2.1927943338003597e-05,
      "loss": 0.0453,
      "step": 130700
    },
    {
      "epoch": 8.994017740493709,
      "grad_norm": 0.1181027889251709,
      "learning_rate": 2.1906454413395336e-05,
      "loss": 0.0454,
      "step": 130800
    },
    {
      "epoch": 9.0,
      "eval_accuracy_macro_0.5": 0.9794292449951172,
      "eval_accuracy_micro_0.5": 0.9794292449951172,
      "eval_accuracy_weighted_0.5": 0.9768471121788025,
      "eval_f1_macro_0.5": 0.7111266851425171,
      "eval_f1_macro_0.6": 0.6853954792022705,
      "eval_f1_macro_0.7": 0.6421341896057129,
      "eval_f1_macro_0.8": 0.44558385014533997,
      "eval_f1_micro_0.5": 0.7188621759414673,
      "eval_f1_micro_0.6": 0.6981662511825562,
      "eval_f1_micro_0.7": 0.6601069569587708,
      "eval_f1_micro_0.8": 0.5964504480361938,
      "eval_f1_micro_0.9": 0.472555547952652,
      "eval_f1_weighted_0.5": 0.7092931270599365,
      "eval_f1_weighted_0.6": 0.6822820901870728,
      "eval_f1_weighted_0.7": 0.6371080875396729,
      "eval_f1_weighted_0.8": 0.432388573884964,
      "eval_loss": 0.04285283014178276,
      "eval_runtime": 63.0398,
      "eval_samples_per_second": 460.614,
      "eval_steps_per_second": 57.583,
      "step": 130887
    },
    {
      "epoch": 9.000893900845767,
      "grad_norm": 0.21756944060325623,
      "learning_rate": 2.188496548878708e-05,
      "loss": 0.046,
      "step": 130900
    },
    {
      "epoch": 9.007770061197828,
      "grad_norm": 0.14177584648132324,
      "learning_rate": 2.1863476564178823e-05,
      "loss": 0.0472,
      "step": 131000
    },
    {
      "epoch": 9.014646221549887,
      "grad_norm": 0.18814319372177124,
      "learning_rate": 2.1841987639570566e-05,
      "loss": 0.0467,
      "step": 131100
    },
    {
      "epoch": 9.021522381901946,
      "grad_norm": 0.21669542789459229,
      "learning_rate": 2.182049871496231e-05,
      "loss": 0.0461,
      "step": 131200
    },
    {
      "epoch": 9.028398542254005,
      "grad_norm": 0.12566883862018585,
      "learning_rate": 2.1799009790354053e-05,
      "loss": 0.0499,
      "step": 131300
    },
    {
      "epoch": 9.035274702606065,
      "grad_norm": 0.16069374978542328,
      "learning_rate": 2.1777520865745796e-05,
      "loss": 0.0471,
      "step": 131400
    },
    {
      "epoch": 9.042150862958124,
      "grad_norm": 0.11817611008882523,
      "learning_rate": 2.175603194113754e-05,
      "loss": 0.0447,
      "step": 131500
    },
    {
      "epoch": 9.049027023310183,
      "grad_norm": 0.1183537095785141,
      "learning_rate": 2.1734543016529283e-05,
      "loss": 0.0443,
      "step": 131600
    },
    {
      "epoch": 9.055903183662243,
      "grad_norm": 0.1070471853017807,
      "learning_rate": 2.1713054091921026e-05,
      "loss": 0.0449,
      "step": 131700
    },
    {
      "epoch": 9.062779344014302,
      "grad_norm": 0.10030767321586609,
      "learning_rate": 2.169156516731277e-05,
      "loss": 0.0453,
      "step": 131800
    },
    {
      "epoch": 9.069655504366361,
      "grad_norm": 0.1635330319404602,
      "learning_rate": 2.1670076242704513e-05,
      "loss": 0.0476,
      "step": 131900
    },
    {
      "epoch": 9.076531664718422,
      "grad_norm": 0.10985813289880753,
      "learning_rate": 2.1648587318096253e-05,
      "loss": 0.0464,
      "step": 132000
    },
    {
      "epoch": 9.08340782507048,
      "grad_norm": 0.17295412719249725,
      "learning_rate": 2.1627098393487996e-05,
      "loss": 0.0463,
      "step": 132100
    },
    {
      "epoch": 9.09028398542254,
      "grad_norm": 0.24532930552959442,
      "learning_rate": 2.1605824358125823e-05,
      "loss": 0.0423,
      "step": 132200
    },
    {
      "epoch": 9.0971601457746,
      "grad_norm": 0.13723286986351013,
      "learning_rate": 2.1584335433517566e-05,
      "loss": 0.0439,
      "step": 132300
    },
    {
      "epoch": 9.104036306126659,
      "grad_norm": 0.20889757573604584,
      "learning_rate": 2.156284650890931e-05,
      "loss": 0.0462,
      "step": 132400
    },
    {
      "epoch": 9.110912466478718,
      "grad_norm": 0.20567023754119873,
      "learning_rate": 2.1541357584301053e-05,
      "loss": 0.0443,
      "step": 132500
    },
    {
      "epoch": 9.117788626830778,
      "grad_norm": 0.1869433969259262,
      "learning_rate": 2.1519868659692796e-05,
      "loss": 0.0456,
      "step": 132600
    },
    {
      "epoch": 9.124664787182837,
      "grad_norm": 0.19148696959018707,
      "learning_rate": 2.149837973508454e-05,
      "loss": 0.0445,
      "step": 132700
    },
    {
      "epoch": 9.131540947534896,
      "grad_norm": 0.13449710607528687,
      "learning_rate": 2.1476890810476283e-05,
      "loss": 0.044,
      "step": 132800
    },
    {
      "epoch": 9.138417107886957,
      "grad_norm": 0.1627386063337326,
      "learning_rate": 2.1455401885868023e-05,
      "loss": 0.0468,
      "step": 132900
    },
    {
      "epoch": 9.145293268239016,
      "grad_norm": 0.14055828750133514,
      "learning_rate": 2.1433912961259766e-05,
      "loss": 0.0455,
      "step": 133000
    },
    {
      "epoch": 9.152169428591074,
      "grad_norm": 0.1825256496667862,
      "learning_rate": 2.141242403665151e-05,
      "loss": 0.0475,
      "step": 133100
    },
    {
      "epoch": 9.159045588943133,
      "grad_norm": 0.1659494787454605,
      "learning_rate": 2.1390935112043253e-05,
      "loss": 0.0456,
      "step": 133200
    },
    {
      "epoch": 9.165921749295194,
      "grad_norm": 0.18425650894641876,
      "learning_rate": 2.1369446187434996e-05,
      "loss": 0.0459,
      "step": 133300
    },
    {
      "epoch": 9.172797909647253,
      "grad_norm": 0.15885064005851746,
      "learning_rate": 2.134795726282674e-05,
      "loss": 0.0464,
      "step": 133400
    },
    {
      "epoch": 9.179674069999312,
      "grad_norm": 0.12184606492519379,
      "learning_rate": 2.1326468338218483e-05,
      "loss": 0.0471,
      "step": 133500
    },
    {
      "epoch": 9.186550230351372,
      "grad_norm": 0.14558103680610657,
      "learning_rate": 2.1304979413610226e-05,
      "loss": 0.0457,
      "step": 133600
    },
    {
      "epoch": 9.193426390703431,
      "grad_norm": 0.2169557809829712,
      "learning_rate": 2.128349048900197e-05,
      "loss": 0.0482,
      "step": 133700
    },
    {
      "epoch": 9.20030255105549,
      "grad_norm": 0.10269325226545334,
      "learning_rate": 2.1262001564393713e-05,
      "loss": 0.0447,
      "step": 133800
    },
    {
      "epoch": 9.20717871140755,
      "grad_norm": 0.1656985729932785,
      "learning_rate": 2.1240512639785456e-05,
      "loss": 0.0465,
      "step": 133900
    },
    {
      "epoch": 9.21405487175961,
      "grad_norm": 0.15740224719047546,
      "learning_rate": 2.12190237151772e-05,
      "loss": 0.047,
      "step": 134000
    },
    {
      "epoch": 9.220931032111668,
      "grad_norm": 0.16935798525810242,
      "learning_rate": 2.1197534790568943e-05,
      "loss": 0.0455,
      "step": 134100
    },
    {
      "epoch": 9.227807192463729,
      "grad_norm": 0.10165084898471832,
      "learning_rate": 2.1176045865960683e-05,
      "loss": 0.0448,
      "step": 134200
    },
    {
      "epoch": 9.234683352815788,
      "grad_norm": 0.11276088654994965,
      "learning_rate": 2.1154556941352426e-05,
      "loss": 0.0456,
      "step": 134300
    },
    {
      "epoch": 9.241559513167847,
      "grad_norm": 0.10227838158607483,
      "learning_rate": 2.113306801674417e-05,
      "loss": 0.0453,
      "step": 134400
    },
    {
      "epoch": 9.248435673519907,
      "grad_norm": 0.13527512550354004,
      "learning_rate": 2.1111793981381996e-05,
      "loss": 0.048,
      "step": 134500
    },
    {
      "epoch": 9.255311833871966,
      "grad_norm": 0.1891174465417862,
      "learning_rate": 2.109030505677374e-05,
      "loss": 0.0477,
      "step": 134600
    },
    {
      "epoch": 9.262187994224025,
      "grad_norm": 0.12883998453617096,
      "learning_rate": 2.1068816132165483e-05,
      "loss": 0.0454,
      "step": 134700
    },
    {
      "epoch": 9.269064154576085,
      "grad_norm": 0.24796579778194427,
      "learning_rate": 2.1047327207557226e-05,
      "loss": 0.0459,
      "step": 134800
    },
    {
      "epoch": 9.275940314928144,
      "grad_norm": 0.2278260439634323,
      "learning_rate": 2.102583828294897e-05,
      "loss": 0.0453,
      "step": 134900
    },
    {
      "epoch": 9.282816475280203,
      "grad_norm": 0.19203504920005798,
      "learning_rate": 2.100434935834071e-05,
      "loss": 0.0441,
      "step": 135000
    },
    {
      "epoch": 9.289692635632264,
      "grad_norm": 0.17214684188365936,
      "learning_rate": 2.0982860433732453e-05,
      "loss": 0.0463,
      "step": 135100
    },
    {
      "epoch": 9.296568795984323,
      "grad_norm": 0.19845226407051086,
      "learning_rate": 2.0961371509124196e-05,
      "loss": 0.0419,
      "step": 135200
    },
    {
      "epoch": 9.303444956336381,
      "grad_norm": 0.15433453023433685,
      "learning_rate": 2.093988258451594e-05,
      "loss": 0.045,
      "step": 135300
    },
    {
      "epoch": 9.310321116688442,
      "grad_norm": 0.12135926634073257,
      "learning_rate": 2.0918393659907683e-05,
      "loss": 0.0454,
      "step": 135400
    },
    {
      "epoch": 9.317197277040501,
      "grad_norm": 0.16021914780139923,
      "learning_rate": 2.0896904735299426e-05,
      "loss": 0.0457,
      "step": 135500
    },
    {
      "epoch": 9.32407343739256,
      "grad_norm": 0.16947677731513977,
      "learning_rate": 2.087541581069117e-05,
      "loss": 0.046,
      "step": 135600
    },
    {
      "epoch": 9.330949597744619,
      "grad_norm": 0.0878462940454483,
      "learning_rate": 2.0853926886082913e-05,
      "loss": 0.0447,
      "step": 135700
    },
    {
      "epoch": 9.33782575809668,
      "grad_norm": 0.16014401614665985,
      "learning_rate": 2.0832437961474656e-05,
      "loss": 0.0478,
      "step": 135800
    },
    {
      "epoch": 9.344701918448738,
      "grad_norm": 0.16494525969028473,
      "learning_rate": 2.08109490368664e-05,
      "loss": 0.0443,
      "step": 135900
    },
    {
      "epoch": 9.351578078800797,
      "grad_norm": 0.1247202530503273,
      "learning_rate": 2.0789460112258143e-05,
      "loss": 0.047,
      "step": 136000
    },
    {
      "epoch": 9.358454239152858,
      "grad_norm": 0.14237801730632782,
      "learning_rate": 2.0767971187649886e-05,
      "loss": 0.0432,
      "step": 136100
    },
    {
      "epoch": 9.365330399504916,
      "grad_norm": 0.13243819773197174,
      "learning_rate": 2.074648226304163e-05,
      "loss": 0.0493,
      "step": 136200
    },
    {
      "epoch": 9.372206559856975,
      "grad_norm": 0.3082040846347809,
      "learning_rate": 2.0724993338433373e-05,
      "loss": 0.0453,
      "step": 136300
    },
    {
      "epoch": 9.379082720209036,
      "grad_norm": 0.16106507182121277,
      "learning_rate": 2.0703504413825116e-05,
      "loss": 0.0456,
      "step": 136400
    },
    {
      "epoch": 9.385958880561095,
      "grad_norm": 0.12744925916194916,
      "learning_rate": 2.068201548921686e-05,
      "loss": 0.0443,
      "step": 136500
    },
    {
      "epoch": 9.392835040913154,
      "grad_norm": 0.19239425659179688,
      "learning_rate": 2.0660526564608603e-05,
      "loss": 0.0484,
      "step": 136600
    },
    {
      "epoch": 9.399711201265214,
      "grad_norm": 0.1806071698665619,
      "learning_rate": 2.0639037640000346e-05,
      "loss": 0.0485,
      "step": 136700
    },
    {
      "epoch": 9.406587361617273,
      "grad_norm": 0.214988574385643,
      "learning_rate": 2.061754871539209e-05,
      "loss": 0.0452,
      "step": 136800
    },
    {
      "epoch": 9.413463521969332,
      "grad_norm": 0.18606281280517578,
      "learning_rate": 2.0596059790783833e-05,
      "loss": 0.0472,
      "step": 136900
    },
    {
      "epoch": 9.420339682321393,
      "grad_norm": 0.19559983909130096,
      "learning_rate": 2.0574570866175576e-05,
      "loss": 0.0445,
      "step": 137000
    },
    {
      "epoch": 9.427215842673451,
      "grad_norm": 0.20672640204429626,
      "learning_rate": 2.055308194156732e-05,
      "loss": 0.0472,
      "step": 137100
    },
    {
      "epoch": 9.43409200302551,
      "grad_norm": 0.1560719609260559,
      "learning_rate": 2.0531593016959063e-05,
      "loss": 0.0443,
      "step": 137200
    },
    {
      "epoch": 9.440968163377569,
      "grad_norm": 0.22063933312892914,
      "learning_rate": 2.0510104092350806e-05,
      "loss": 0.0427,
      "step": 137300
    },
    {
      "epoch": 9.44784432372963,
      "grad_norm": 0.11245561391115189,
      "learning_rate": 2.048861516774255e-05,
      "loss": 0.0476,
      "step": 137400
    },
    {
      "epoch": 9.454720484081689,
      "grad_norm": 0.2778865396976471,
      "learning_rate": 2.0467126243134293e-05,
      "loss": 0.0444,
      "step": 137500
    },
    {
      "epoch": 9.461596644433747,
      "grad_norm": 0.11213336139917374,
      "learning_rate": 2.0445637318526032e-05,
      "loss": 0.0484,
      "step": 137600
    },
    {
      "epoch": 9.468472804785808,
      "grad_norm": 0.23485781252384186,
      "learning_rate": 2.0424148393917776e-05,
      "loss": 0.0463,
      "step": 137700
    },
    {
      "epoch": 9.475348965137867,
      "grad_norm": 0.2125731259584427,
      "learning_rate": 2.040265946930952e-05,
      "loss": 0.049,
      "step": 137800
    },
    {
      "epoch": 9.482225125489926,
      "grad_norm": 0.26313695311546326,
      "learning_rate": 2.0381170544701262e-05,
      "loss": 0.0489,
      "step": 137900
    },
    {
      "epoch": 9.489101285841986,
      "grad_norm": 0.15836241841316223,
      "learning_rate": 2.0359681620093006e-05,
      "loss": 0.0464,
      "step": 138000
    },
    {
      "epoch": 9.495977446194045,
      "grad_norm": 0.11854530870914459,
      "learning_rate": 2.0338407584730832e-05,
      "loss": 0.0439,
      "step": 138100
    },
    {
      "epoch": 9.502853606546104,
      "grad_norm": 0.11143074929714203,
      "learning_rate": 2.0316918660122576e-05,
      "loss": 0.0452,
      "step": 138200
    },
    {
      "epoch": 9.509729766898165,
      "grad_norm": 0.3507610559463501,
      "learning_rate": 2.029542973551432e-05,
      "loss": 0.0443,
      "step": 138300
    },
    {
      "epoch": 9.516605927250223,
      "grad_norm": 0.23490047454833984,
      "learning_rate": 2.0273940810906062e-05,
      "loss": 0.0484,
      "step": 138400
    },
    {
      "epoch": 9.523482087602282,
      "grad_norm": 0.2602831721305847,
      "learning_rate": 2.0252451886297802e-05,
      "loss": 0.0451,
      "step": 138500
    },
    {
      "epoch": 9.530358247954343,
      "grad_norm": 0.1566409170627594,
      "learning_rate": 2.0230962961689546e-05,
      "loss": 0.0444,
      "step": 138600
    },
    {
      "epoch": 9.537234408306402,
      "grad_norm": 0.12895730137825012,
      "learning_rate": 2.020947403708129e-05,
      "loss": 0.0461,
      "step": 138700
    },
    {
      "epoch": 9.54411056865846,
      "grad_norm": 0.15499836206436157,
      "learning_rate": 2.0187985112473032e-05,
      "loss": 0.0456,
      "step": 138800
    },
    {
      "epoch": 9.550986729010521,
      "grad_norm": 0.20395900309085846,
      "learning_rate": 2.0166496187864776e-05,
      "loss": 0.0465,
      "step": 138900
    },
    {
      "epoch": 9.55786288936258,
      "grad_norm": 0.21215735375881195,
      "learning_rate": 2.014500726325652e-05,
      "loss": 0.0481,
      "step": 139000
    },
    {
      "epoch": 9.564739049714639,
      "grad_norm": 0.12014111131429672,
      "learning_rate": 2.0123518338648262e-05,
      "loss": 0.0479,
      "step": 139100
    },
    {
      "epoch": 9.5716152100667,
      "grad_norm": 0.12869995832443237,
      "learning_rate": 2.0102029414040006e-05,
      "loss": 0.0447,
      "step": 139200
    },
    {
      "epoch": 9.578491370418758,
      "grad_norm": 0.13617704808712006,
      "learning_rate": 2.008054048943175e-05,
      "loss": 0.0467,
      "step": 139300
    },
    {
      "epoch": 9.585367530770817,
      "grad_norm": 0.07996970415115356,
      "learning_rate": 2.0059051564823492e-05,
      "loss": 0.0482,
      "step": 139400
    },
    {
      "epoch": 9.592243691122878,
      "grad_norm": 0.19518552720546722,
      "learning_rate": 2.0037562640215236e-05,
      "loss": 0.0463,
      "step": 139500
    },
    {
      "epoch": 9.599119851474937,
      "grad_norm": 0.16447946429252625,
      "learning_rate": 2.001607371560698e-05,
      "loss": 0.0463,
      "step": 139600
    },
    {
      "epoch": 9.605996011826996,
      "grad_norm": 0.11784633249044418,
      "learning_rate": 1.999458479099872e-05,
      "loss": 0.0463,
      "step": 139700
    },
    {
      "epoch": 9.612872172179054,
      "grad_norm": 0.10167715698480606,
      "learning_rate": 1.9973095866390462e-05,
      "loss": 0.0495,
      "step": 139800
    },
    {
      "epoch": 9.619748332531115,
      "grad_norm": 0.18807107210159302,
      "learning_rate": 1.9951606941782205e-05,
      "loss": 0.0446,
      "step": 139900
    },
    {
      "epoch": 9.626624492883174,
      "grad_norm": 0.24962081015110016,
      "learning_rate": 1.993011801717395e-05,
      "loss": 0.0434,
      "step": 140000
    },
    {
      "epoch": 9.633500653235233,
      "grad_norm": 0.11155830323696136,
      "learning_rate": 1.9908843981811775e-05,
      "loss": 0.0417,
      "step": 140100
    },
    {
      "epoch": 9.640376813587293,
      "grad_norm": 0.11247316002845764,
      "learning_rate": 1.988735505720352e-05,
      "loss": 0.0474,
      "step": 140200
    },
    {
      "epoch": 9.647252973939352,
      "grad_norm": 0.2064315527677536,
      "learning_rate": 1.9865866132595262e-05,
      "loss": 0.0437,
      "step": 140300
    },
    {
      "epoch": 9.654129134291411,
      "grad_norm": 0.21556387841701508,
      "learning_rate": 1.9844377207987005e-05,
      "loss": 0.0445,
      "step": 140400
    },
    {
      "epoch": 9.661005294643472,
      "grad_norm": 0.23198413848876953,
      "learning_rate": 1.982288828337875e-05,
      "loss": 0.0444,
      "step": 140500
    },
    {
      "epoch": 9.66788145499553,
      "grad_norm": 0.13925980031490326,
      "learning_rate": 1.980139935877049e-05,
      "loss": 0.0437,
      "step": 140600
    },
    {
      "epoch": 9.67475761534759,
      "grad_norm": 0.14200663566589355,
      "learning_rate": 1.9779910434162232e-05,
      "loss": 0.0459,
      "step": 140700
    },
    {
      "epoch": 9.68163377569965,
      "grad_norm": 0.1648121476173401,
      "learning_rate": 1.9758421509553975e-05,
      "loss": 0.0445,
      "step": 140800
    },
    {
      "epoch": 9.688509936051709,
      "grad_norm": 0.15696702897548676,
      "learning_rate": 1.973693258494572e-05,
      "loss": 0.0505,
      "step": 140900
    },
    {
      "epoch": 9.695386096403768,
      "grad_norm": 0.12014127522706985,
      "learning_rate": 1.9715443660337462e-05,
      "loss": 0.047,
      "step": 141000
    },
    {
      "epoch": 9.702262256755828,
      "grad_norm": 0.1678227335214615,
      "learning_rate": 1.9693954735729205e-05,
      "loss": 0.0485,
      "step": 141100
    },
    {
      "epoch": 9.709138417107887,
      "grad_norm": 0.16157715022563934,
      "learning_rate": 1.967246581112095e-05,
      "loss": 0.045,
      "step": 141200
    },
    {
      "epoch": 9.716014577459946,
      "grad_norm": 0.144845113158226,
      "learning_rate": 1.9650976886512692e-05,
      "loss": 0.0438,
      "step": 141300
    },
    {
      "epoch": 9.722890737812005,
      "grad_norm": 0.1336669921875,
      "learning_rate": 1.9629487961904435e-05,
      "loss": 0.043,
      "step": 141400
    },
    {
      "epoch": 9.729766898164065,
      "grad_norm": 0.11182764917612076,
      "learning_rate": 1.960799903729618e-05,
      "loss": 0.0467,
      "step": 141500
    },
    {
      "epoch": 9.736643058516124,
      "grad_norm": 0.17415377497673035,
      "learning_rate": 1.9586510112687922e-05,
      "loss": 0.0459,
      "step": 141600
    },
    {
      "epoch": 9.743519218868183,
      "grad_norm": 0.18015125393867493,
      "learning_rate": 1.9565021188079665e-05,
      "loss": 0.0435,
      "step": 141700
    },
    {
      "epoch": 9.750395379220244,
      "grad_norm": 0.21577470004558563,
      "learning_rate": 1.954353226347141e-05,
      "loss": 0.046,
      "step": 141800
    },
    {
      "epoch": 9.757271539572303,
      "grad_norm": 0.1354803740978241,
      "learning_rate": 1.952204333886315e-05,
      "loss": 0.049,
      "step": 141900
    },
    {
      "epoch": 9.764147699924361,
      "grad_norm": 0.17940957844257355,
      "learning_rate": 1.9500554414254892e-05,
      "loss": 0.0496,
      "step": 142000
    },
    {
      "epoch": 9.771023860276422,
      "grad_norm": 0.14051377773284912,
      "learning_rate": 1.9479065489646635e-05,
      "loss": 0.0463,
      "step": 142100
    },
    {
      "epoch": 9.777900020628481,
      "grad_norm": 0.21707670390605927,
      "learning_rate": 1.945757656503838e-05,
      "loss": 0.0441,
      "step": 142200
    },
    {
      "epoch": 9.78477618098054,
      "grad_norm": 0.23688088357448578,
      "learning_rate": 1.9436087640430122e-05,
      "loss": 0.044,
      "step": 142300
    },
    {
      "epoch": 9.7916523413326,
      "grad_norm": 0.2010791301727295,
      "learning_rate": 1.9414598715821865e-05,
      "loss": 0.0456,
      "step": 142400
    },
    {
      "epoch": 9.79852850168466,
      "grad_norm": 0.09783327579498291,
      "learning_rate": 1.939310979121361e-05,
      "loss": 0.047,
      "step": 142500
    },
    {
      "epoch": 9.805404662036718,
      "grad_norm": 0.20366396009922028,
      "learning_rate": 1.9371620866605352e-05,
      "loss": 0.0445,
      "step": 142600
    },
    {
      "epoch": 9.812280822388779,
      "grad_norm": 0.18357634544372559,
      "learning_rate": 1.9350131941997095e-05,
      "loss": 0.0467,
      "step": 142700
    },
    {
      "epoch": 9.819156982740838,
      "grad_norm": 0.18582215905189514,
      "learning_rate": 1.932864301738884e-05,
      "loss": 0.0465,
      "step": 142800
    },
    {
      "epoch": 9.826033143092896,
      "grad_norm": 0.1208958700299263,
      "learning_rate": 1.9307154092780582e-05,
      "loss": 0.0441,
      "step": 142900
    },
    {
      "epoch": 9.832909303444957,
      "grad_norm": 0.12092330306768417,
      "learning_rate": 1.9285665168172325e-05,
      "loss": 0.0462,
      "step": 143000
    },
    {
      "epoch": 9.839785463797016,
      "grad_norm": 0.10213146358728409,
      "learning_rate": 1.926417624356407e-05,
      "loss": 0.0492,
      "step": 143100
    },
    {
      "epoch": 9.846661624149075,
      "grad_norm": 0.1540227085351944,
      "learning_rate": 1.924268731895581e-05,
      "loss": 0.0473,
      "step": 143200
    },
    {
      "epoch": 9.853537784501135,
      "grad_norm": 0.11183393001556396,
      "learning_rate": 1.9221198394347552e-05,
      "loss": 0.0435,
      "step": 143300
    },
    {
      "epoch": 9.860413944853194,
      "grad_norm": 0.13576146960258484,
      "learning_rate": 1.9199709469739295e-05,
      "loss": 0.0465,
      "step": 143400
    },
    {
      "epoch": 9.867290105205253,
      "grad_norm": 0.2780858874320984,
      "learning_rate": 1.917822054513104e-05,
      "loss": 0.0454,
      "step": 143500
    },
    {
      "epoch": 9.874166265557314,
      "grad_norm": 0.13295474648475647,
      "learning_rate": 1.9156731620522782e-05,
      "loss": 0.0462,
      "step": 143600
    },
    {
      "epoch": 9.881042425909373,
      "grad_norm": 0.23111948370933533,
      "learning_rate": 1.9135242695914525e-05,
      "loss": 0.0462,
      "step": 143700
    },
    {
      "epoch": 9.887918586261431,
      "grad_norm": 0.22305609285831451,
      "learning_rate": 1.911375377130627e-05,
      "loss": 0.0457,
      "step": 143800
    },
    {
      "epoch": 9.89479474661349,
      "grad_norm": 0.24518659710884094,
      "learning_rate": 1.9092264846698012e-05,
      "loss": 0.0455,
      "step": 143900
    },
    {
      "epoch": 9.90167090696555,
      "grad_norm": 0.19172608852386475,
      "learning_rate": 1.9070775922089755e-05,
      "loss": 0.0419,
      "step": 144000
    },
    {
      "epoch": 9.90854706731761,
      "grad_norm": 0.14454101026058197,
      "learning_rate": 1.904950188672758e-05,
      "loss": 0.0483,
      "step": 144100
    },
    {
      "epoch": 9.915423227669669,
      "grad_norm": 0.16790729761123657,
      "learning_rate": 1.9028012962119325e-05,
      "loss": 0.0442,
      "step": 144200
    },
    {
      "epoch": 9.92229938802173,
      "grad_norm": 0.1305898129940033,
      "learning_rate": 1.9006524037511068e-05,
      "loss": 0.0456,
      "step": 144300
    },
    {
      "epoch": 9.929175548373788,
      "grad_norm": 0.22399969398975372,
      "learning_rate": 1.898503511290281e-05,
      "loss": 0.046,
      "step": 144400
    },
    {
      "epoch": 9.936051708725847,
      "grad_norm": 0.17464900016784668,
      "learning_rate": 1.8963546188294555e-05,
      "loss": 0.043,
      "step": 144500
    },
    {
      "epoch": 9.942927869077907,
      "grad_norm": 0.17910653352737427,
      "learning_rate": 1.8942057263686298e-05,
      "loss": 0.0471,
      "step": 144600
    },
    {
      "epoch": 9.949804029429966,
      "grad_norm": 0.32181766629219055,
      "learning_rate": 1.892056833907804e-05,
      "loss": 0.0485,
      "step": 144700
    },
    {
      "epoch": 9.956680189782025,
      "grad_norm": 0.1960059404373169,
      "learning_rate": 1.8899079414469785e-05,
      "loss": 0.0462,
      "step": 144800
    },
    {
      "epoch": 9.963556350134086,
      "grad_norm": 0.19742366671562195,
      "learning_rate": 1.8877590489861528e-05,
      "loss": 0.0438,
      "step": 144900
    },
    {
      "epoch": 9.970432510486145,
      "grad_norm": 0.2307727038860321,
      "learning_rate": 1.885610156525327e-05,
      "loss": 0.0457,
      "step": 145000
    },
    {
      "epoch": 9.977308670838203,
      "grad_norm": 0.1869209110736847,
      "learning_rate": 1.8834612640645015e-05,
      "loss": 0.0462,
      "step": 145100
    },
    {
      "epoch": 9.984184831190264,
      "grad_norm": 0.24411574006080627,
      "learning_rate": 1.8813123716036758e-05,
      "loss": 0.0473,
      "step": 145200
    },
    {
      "epoch": 9.991060991542323,
      "grad_norm": 0.13943623006343842,
      "learning_rate": 1.8791634791428498e-05,
      "loss": 0.0467,
      "step": 145300
    },
    {
      "epoch": 9.997937151894382,
      "grad_norm": 0.1256507784128189,
      "learning_rate": 1.877014586682024e-05,
      "loss": 0.0451,
      "step": 145400
    },
    {
      "epoch": 10.0,
      "eval_accuracy_macro_0.5": 0.9794389605522156,
      "eval_accuracy_micro_0.5": 0.9794389605522156,
      "eval_accuracy_weighted_0.5": 0.9768562316894531,
      "eval_f1_macro_0.5": 0.7160917520523071,
      "eval_f1_macro_0.6": 0.6921256184577942,
      "eval_f1_macro_0.7": 0.6519594192504883,
      "eval_f1_macro_0.8": 0.46045640110969543,
      "eval_f1_micro_0.5": 0.7216516137123108,
      "eval_f1_micro_0.6": 0.7022194266319275,
      "eval_f1_micro_0.7": 0.6667444705963135,
      "eval_f1_micro_0.8": 0.6055082082748413,
      "eval_f1_micro_0.9": 0.48622509837150574,
      "eval_f1_weighted_0.5": 0.7132136821746826,
      "eval_f1_weighted_0.6": 0.6874576807022095,
      "eval_f1_weighted_0.7": 0.6445703506469727,
      "eval_f1_weighted_0.8": 0.4429134428501129,
      "eval_loss": 0.04280928522348404,
      "eval_runtime": 62.7326,
      "eval_samples_per_second": 462.87,
      "eval_steps_per_second": 57.865,
      "step": 145430
    },
    {
      "epoch": 10.004813312246442,
      "grad_norm": 0.10636713355779648,
      "learning_rate": 1.8748656942211985e-05,
      "loss": 0.0425,
      "step": 145500
    },
    {
      "epoch": 10.011689472598501,
      "grad_norm": 0.18007391691207886,
      "learning_rate": 1.8727168017603728e-05,
      "loss": 0.0475,
      "step": 145600
    },
    {
      "epoch": 10.01856563295056,
      "grad_norm": 0.14414997398853302,
      "learning_rate": 1.870567909299547e-05,
      "loss": 0.0437,
      "step": 145700
    },
    {
      "epoch": 10.025441793302619,
      "grad_norm": 0.20919667184352875,
      "learning_rate": 1.8684190168387215e-05,
      "loss": 0.0462,
      "step": 145800
    },
    {
      "epoch": 10.03231795365468,
      "grad_norm": 0.08618507534265518,
      "learning_rate": 1.8662701243778958e-05,
      "loss": 0.044,
      "step": 145900
    },
    {
      "epoch": 10.039194114006738,
      "grad_norm": 0.18564677238464355,
      "learning_rate": 1.86412123191707e-05,
      "loss": 0.042,
      "step": 146000
    },
    {
      "epoch": 10.046070274358797,
      "grad_norm": 0.11554620414972305,
      "learning_rate": 1.8619723394562445e-05,
      "loss": 0.0502,
      "step": 146100
    },
    {
      "epoch": 10.052946434710858,
      "grad_norm": 0.21354208886623383,
      "learning_rate": 1.8598449359200268e-05,
      "loss": 0.0462,
      "step": 146200
    },
    {
      "epoch": 10.059822595062917,
      "grad_norm": 0.20367686450481415,
      "learning_rate": 1.857696043459201e-05,
      "loss": 0.0441,
      "step": 146300
    },
    {
      "epoch": 10.066698755414976,
      "grad_norm": 0.13407717645168304,
      "learning_rate": 1.8555471509983755e-05,
      "loss": 0.0475,
      "step": 146400
    },
    {
      "epoch": 10.073574915767036,
      "grad_norm": 0.15653546154499054,
      "learning_rate": 1.8533982585375498e-05,
      "loss": 0.0475,
      "step": 146500
    },
    {
      "epoch": 10.080451076119095,
      "grad_norm": 0.11058396100997925,
      "learning_rate": 1.851249366076724e-05,
      "loss": 0.0468,
      "step": 146600
    },
    {
      "epoch": 10.087327236471154,
      "grad_norm": 0.2203960418701172,
      "learning_rate": 1.8491219625405068e-05,
      "loss": 0.0463,
      "step": 146700
    },
    {
      "epoch": 10.094203396823215,
      "grad_norm": 0.25382035970687866,
      "learning_rate": 1.846973070079681e-05,
      "loss": 0.045,
      "step": 146800
    },
    {
      "epoch": 10.101079557175273,
      "grad_norm": 0.11529124528169632,
      "learning_rate": 1.8448241776188554e-05,
      "loss": 0.0462,
      "step": 146900
    },
    {
      "epoch": 10.107955717527332,
      "grad_norm": 0.26252079010009766,
      "learning_rate": 1.8426752851580294e-05,
      "loss": 0.0467,
      "step": 147000
    },
    {
      "epoch": 10.114831877879393,
      "grad_norm": 0.17884550988674164,
      "learning_rate": 1.8405263926972038e-05,
      "loss": 0.0448,
      "step": 147100
    },
    {
      "epoch": 10.121708038231452,
      "grad_norm": 0.2142060101032257,
      "learning_rate": 1.838377500236378e-05,
      "loss": 0.0474,
      "step": 147200
    },
    {
      "epoch": 10.12858419858351,
      "grad_norm": 0.17639416456222534,
      "learning_rate": 1.8362286077755524e-05,
      "loss": 0.0467,
      "step": 147300
    },
    {
      "epoch": 10.135460358935571,
      "grad_norm": 0.15425805747509003,
      "learning_rate": 1.8340797153147268e-05,
      "loss": 0.0447,
      "step": 147400
    },
    {
      "epoch": 10.14233651928763,
      "grad_norm": 0.22544993460178375,
      "learning_rate": 1.831930822853901e-05,
      "loss": 0.0456,
      "step": 147500
    },
    {
      "epoch": 10.149212679639689,
      "grad_norm": 0.10038908571004868,
      "learning_rate": 1.8297819303930754e-05,
      "loss": 0.0439,
      "step": 147600
    },
    {
      "epoch": 10.15608883999175,
      "grad_norm": 0.0904989168047905,
      "learning_rate": 1.8276330379322498e-05,
      "loss": 0.0431,
      "step": 147700
    },
    {
      "epoch": 10.162965000343808,
      "grad_norm": 0.11990916728973389,
      "learning_rate": 1.825484145471424e-05,
      "loss": 0.044,
      "step": 147800
    },
    {
      "epoch": 10.169841160695867,
      "grad_norm": 0.15767213702201843,
      "learning_rate": 1.8233352530105984e-05,
      "loss": 0.0465,
      "step": 147900
    },
    {
      "epoch": 10.176717321047926,
      "grad_norm": 0.15924401581287384,
      "learning_rate": 1.8211863605497728e-05,
      "loss": 0.0436,
      "step": 148000
    },
    {
      "epoch": 10.183593481399987,
      "grad_norm": 0.21534419059753418,
      "learning_rate": 1.819037468088947e-05,
      "loss": 0.046,
      "step": 148100
    },
    {
      "epoch": 10.190469641752046,
      "grad_norm": 0.15612618625164032,
      "learning_rate": 1.8168885756281214e-05,
      "loss": 0.0448,
      "step": 148200
    },
    {
      "epoch": 10.197345802104104,
      "grad_norm": 0.23707905411720276,
      "learning_rate": 1.8147396831672954e-05,
      "loss": 0.0456,
      "step": 148300
    },
    {
      "epoch": 10.204221962456165,
      "grad_norm": 0.23187090456485748,
      "learning_rate": 1.8125907907064698e-05,
      "loss": 0.0485,
      "step": 148400
    },
    {
      "epoch": 10.211098122808224,
      "grad_norm": 0.13544961810112,
      "learning_rate": 1.810441898245644e-05,
      "loss": 0.0424,
      "step": 148500
    },
    {
      "epoch": 10.217974283160283,
      "grad_norm": 0.166371151804924,
      "learning_rate": 1.8082930057848184e-05,
      "loss": 0.0449,
      "step": 148600
    },
    {
      "epoch": 10.224850443512343,
      "grad_norm": 0.21108044683933258,
      "learning_rate": 1.8061441133239928e-05,
      "loss": 0.0451,
      "step": 148700
    },
    {
      "epoch": 10.231726603864402,
      "grad_norm": 0.12032913416624069,
      "learning_rate": 1.803995220863167e-05,
      "loss": 0.0452,
      "step": 148800
    },
    {
      "epoch": 10.238602764216461,
      "grad_norm": 0.1485009491443634,
      "learning_rate": 1.8018463284023414e-05,
      "loss": 0.0431,
      "step": 148900
    },
    {
      "epoch": 10.245478924568522,
      "grad_norm": 0.1576121300458908,
      "learning_rate": 1.7996974359415158e-05,
      "loss": 0.0443,
      "step": 149000
    },
    {
      "epoch": 10.25235508492058,
      "grad_norm": 0.12400554120540619,
      "learning_rate": 1.79754854348069e-05,
      "loss": 0.0475,
      "step": 149100
    },
    {
      "epoch": 10.25923124527264,
      "grad_norm": 0.12481667101383209,
      "learning_rate": 1.7953996510198644e-05,
      "loss": 0.0444,
      "step": 149200
    },
    {
      "epoch": 10.2661074056247,
      "grad_norm": 0.2002401053905487,
      "learning_rate": 1.7932507585590388e-05,
      "loss": 0.0445,
      "step": 149300
    },
    {
      "epoch": 10.272983565976759,
      "grad_norm": 0.1662035882472992,
      "learning_rate": 1.791101866098213e-05,
      "loss": 0.047,
      "step": 149400
    },
    {
      "epoch": 10.279859726328818,
      "grad_norm": 0.127184197306633,
      "learning_rate": 1.7889529736373874e-05,
      "loss": 0.0474,
      "step": 149500
    },
    {
      "epoch": 10.286735886680878,
      "grad_norm": 0.1792757660150528,
      "learning_rate": 1.7868040811765614e-05,
      "loss": 0.0459,
      "step": 149600
    },
    {
      "epoch": 10.293612047032937,
      "grad_norm": 0.09898975491523743,
      "learning_rate": 1.7846551887157358e-05,
      "loss": 0.0453,
      "step": 149700
    },
    {
      "epoch": 10.300488207384996,
      "grad_norm": 0.20566628873348236,
      "learning_rate": 1.78250629625491e-05,
      "loss": 0.045,
      "step": 149800
    },
    {
      "epoch": 10.307364367737055,
      "grad_norm": 0.1945614516735077,
      "learning_rate": 1.7803574037940844e-05,
      "loss": 0.0453,
      "step": 149900
    },
    {
      "epoch": 10.314240528089115,
      "grad_norm": 0.15404494106769562,
      "learning_rate": 1.7782085113332588e-05,
      "loss": 0.0475,
      "step": 150000
    },
    {
      "epoch": 10.321116688441174,
      "grad_norm": 0.1392216980457306,
      "learning_rate": 1.776059618872433e-05,
      "loss": 0.0443,
      "step": 150100
    },
    {
      "epoch": 10.327992848793233,
      "grad_norm": 0.1458226889371872,
      "learning_rate": 1.7739107264116074e-05,
      "loss": 0.0436,
      "step": 150200
    },
    {
      "epoch": 10.334869009145294,
      "grad_norm": 0.12091989815235138,
      "learning_rate": 1.77178332287539e-05,
      "loss": 0.0459,
      "step": 150300
    },
    {
      "epoch": 10.341745169497353,
      "grad_norm": 0.19425609707832336,
      "learning_rate": 1.7696344304145644e-05,
      "loss": 0.045,
      "step": 150400
    },
    {
      "epoch": 10.348621329849411,
      "grad_norm": 0.20695708692073822,
      "learning_rate": 1.7674855379537387e-05,
      "loss": 0.0467,
      "step": 150500
    },
    {
      "epoch": 10.355497490201472,
      "grad_norm": 0.16009636223316193,
      "learning_rate": 1.765336645492913e-05,
      "loss": 0.0441,
      "step": 150600
    },
    {
      "epoch": 10.36237365055353,
      "grad_norm": 0.2050907164812088,
      "learning_rate": 1.7631877530320874e-05,
      "loss": 0.0429,
      "step": 150700
    },
    {
      "epoch": 10.36924981090559,
      "grad_norm": 0.22044937312602997,
      "learning_rate": 1.7610388605712617e-05,
      "loss": 0.0458,
      "step": 150800
    },
    {
      "epoch": 10.37612597125765,
      "grad_norm": 0.18259155750274658,
      "learning_rate": 1.758889968110436e-05,
      "loss": 0.0446,
      "step": 150900
    },
    {
      "epoch": 10.38300213160971,
      "grad_norm": 0.09099974483251572,
      "learning_rate": 1.7567410756496104e-05,
      "loss": 0.0451,
      "step": 151000
    },
    {
      "epoch": 10.389878291961768,
      "grad_norm": 0.1804785579442978,
      "learning_rate": 1.7545921831887847e-05,
      "loss": 0.0451,
      "step": 151100
    },
    {
      "epoch": 10.396754452313829,
      "grad_norm": 0.14830784499645233,
      "learning_rate": 1.752443290727959e-05,
      "loss": 0.0483,
      "step": 151200
    },
    {
      "epoch": 10.403630612665888,
      "grad_norm": 0.1459602266550064,
      "learning_rate": 1.7502943982671334e-05,
      "loss": 0.0456,
      "step": 151300
    },
    {
      "epoch": 10.410506773017946,
      "grad_norm": 0.17618568241596222,
      "learning_rate": 1.7481455058063077e-05,
      "loss": 0.0442,
      "step": 151400
    },
    {
      "epoch": 10.417382933370007,
      "grad_norm": 0.1165202409029007,
      "learning_rate": 1.745996613345482e-05,
      "loss": 0.0465,
      "step": 151500
    },
    {
      "epoch": 10.424259093722066,
      "grad_norm": 0.1638948619365692,
      "learning_rate": 1.7438477208846564e-05,
      "loss": 0.0457,
      "step": 151600
    },
    {
      "epoch": 10.431135254074125,
      "grad_norm": 0.17668288946151733,
      "learning_rate": 1.7416988284238304e-05,
      "loss": 0.0497,
      "step": 151700
    },
    {
      "epoch": 10.438011414426185,
      "grad_norm": 0.11409429460763931,
      "learning_rate": 1.7395499359630047e-05,
      "loss": 0.0444,
      "step": 151800
    },
    {
      "epoch": 10.444887574778244,
      "grad_norm": 0.2647498846054077,
      "learning_rate": 1.737401043502179e-05,
      "loss": 0.0457,
      "step": 151900
    },
    {
      "epoch": 10.451763735130303,
      "grad_norm": 0.12292536348104477,
      "learning_rate": 1.7352521510413534e-05,
      "loss": 0.0471,
      "step": 152000
    },
    {
      "epoch": 10.458639895482362,
      "grad_norm": 0.18913108110427856,
      "learning_rate": 1.7331032585805277e-05,
      "loss": 0.0438,
      "step": 152100
    },
    {
      "epoch": 10.465516055834422,
      "grad_norm": 0.1598554253578186,
      "learning_rate": 1.730954366119702e-05,
      "loss": 0.044,
      "step": 152200
    },
    {
      "epoch": 10.472392216186481,
      "grad_norm": 0.22402770817279816,
      "learning_rate": 1.7288054736588764e-05,
      "loss": 0.048,
      "step": 152300
    },
    {
      "epoch": 10.47926837653854,
      "grad_norm": 0.18943265080451965,
      "learning_rate": 1.7266565811980507e-05,
      "loss": 0.0443,
      "step": 152400
    },
    {
      "epoch": 10.4861445368906,
      "grad_norm": 0.1379387229681015,
      "learning_rate": 1.724507688737225e-05,
      "loss": 0.0447,
      "step": 152500
    },
    {
      "epoch": 10.49302069724266,
      "grad_norm": 0.11444154381752014,
      "learning_rate": 1.7223587962763994e-05,
      "loss": 0.0439,
      "step": 152600
    },
    {
      "epoch": 10.499896857594718,
      "grad_norm": 0.18670803308486938,
      "learning_rate": 1.7202099038155737e-05,
      "loss": 0.048,
      "step": 152700
    },
    {
      "epoch": 10.506773017946779,
      "grad_norm": 0.23272103071212769,
      "learning_rate": 1.718061011354748e-05,
      "loss": 0.0456,
      "step": 152800
    },
    {
      "epoch": 10.513649178298838,
      "grad_norm": 0.12743236124515533,
      "learning_rate": 1.7159121188939224e-05,
      "loss": 0.0441,
      "step": 152900
    },
    {
      "epoch": 10.520525338650897,
      "grad_norm": 0.2097492814064026,
      "learning_rate": 1.7137632264330964e-05,
      "loss": 0.0447,
      "step": 153000
    },
    {
      "epoch": 10.527401499002957,
      "grad_norm": 0.10942297428846359,
      "learning_rate": 1.7116143339722707e-05,
      "loss": 0.045,
      "step": 153100
    },
    {
      "epoch": 10.534277659355016,
      "grad_norm": 0.11314547806978226,
      "learning_rate": 1.709465441511445e-05,
      "loss": 0.0454,
      "step": 153200
    },
    {
      "epoch": 10.541153819707075,
      "grad_norm": 0.5187712907791138,
      "learning_rate": 1.7073165490506194e-05,
      "loss": 0.0457,
      "step": 153300
    },
    {
      "epoch": 10.548029980059136,
      "grad_norm": 0.22290076315402985,
      "learning_rate": 1.7051676565897937e-05,
      "loss": 0.0457,
      "step": 153400
    },
    {
      "epoch": 10.554906140411195,
      "grad_norm": 0.184647798538208,
      "learning_rate": 1.703018764128968e-05,
      "loss": 0.047,
      "step": 153500
    },
    {
      "epoch": 10.561782300763253,
      "grad_norm": 0.14194662868976593,
      "learning_rate": 1.7008698716681424e-05,
      "loss": 0.0494,
      "step": 153600
    },
    {
      "epoch": 10.568658461115314,
      "grad_norm": 0.16502729058265686,
      "learning_rate": 1.6987209792073167e-05,
      "loss": 0.0474,
      "step": 153700
    },
    {
      "epoch": 10.575534621467373,
      "grad_norm": 0.16607242822647095,
      "learning_rate": 1.696572086746491e-05,
      "loss": 0.046,
      "step": 153800
    },
    {
      "epoch": 10.582410781819432,
      "grad_norm": 0.1346442550420761,
      "learning_rate": 1.6944231942856654e-05,
      "loss": 0.0432,
      "step": 153900
    },
    {
      "epoch": 10.58928694217149,
      "grad_norm": 0.17038848996162415,
      "learning_rate": 1.6922743018248397e-05,
      "loss": 0.0449,
      "step": 154000
    },
    {
      "epoch": 10.596163102523551,
      "grad_norm": 0.16225112974643707,
      "learning_rate": 1.690125409364014e-05,
      "loss": 0.0467,
      "step": 154100
    },
    {
      "epoch": 10.60303926287561,
      "grad_norm": 0.3561718165874481,
      "learning_rate": 1.6879765169031884e-05,
      "loss": 0.0448,
      "step": 154200
    },
    {
      "epoch": 10.609915423227669,
      "grad_norm": 0.17184993624687195,
      "learning_rate": 1.6858491133669707e-05,
      "loss": 0.044,
      "step": 154300
    },
    {
      "epoch": 10.61679158357973,
      "grad_norm": 0.11632835119962692,
      "learning_rate": 1.683700220906145e-05,
      "loss": 0.0477,
      "step": 154400
    },
    {
      "epoch": 10.623667743931788,
      "grad_norm": 0.1477220058441162,
      "learning_rate": 1.6815513284453194e-05,
      "loss": 0.0459,
      "step": 154500
    },
    {
      "epoch": 10.630543904283847,
      "grad_norm": 0.13730187714099884,
      "learning_rate": 1.6794024359844937e-05,
      "loss": 0.0469,
      "step": 154600
    },
    {
      "epoch": 10.637420064635908,
      "grad_norm": 0.19379927217960358,
      "learning_rate": 1.677253543523668e-05,
      "loss": 0.0473,
      "step": 154700
    },
    {
      "epoch": 10.644296224987967,
      "grad_norm": 0.19836246967315674,
      "learning_rate": 1.6751046510628424e-05,
      "loss": 0.0439,
      "step": 154800
    },
    {
      "epoch": 10.651172385340026,
      "grad_norm": 0.2196420282125473,
      "learning_rate": 1.6729557586020167e-05,
      "loss": 0.0495,
      "step": 154900
    },
    {
      "epoch": 10.658048545692086,
      "grad_norm": 0.10855447500944138,
      "learning_rate": 1.670806866141191e-05,
      "loss": 0.0468,
      "step": 155000
    },
    {
      "epoch": 10.664924706044145,
      "grad_norm": 0.11754760146141052,
      "learning_rate": 1.668657973680365e-05,
      "loss": 0.0468,
      "step": 155100
    },
    {
      "epoch": 10.671800866396204,
      "grad_norm": 0.1322656273841858,
      "learning_rate": 1.6665305701441477e-05,
      "loss": 0.0476,
      "step": 155200
    },
    {
      "epoch": 10.678677026748264,
      "grad_norm": 0.12127519398927689,
      "learning_rate": 1.664381677683322e-05,
      "loss": 0.0448,
      "step": 155300
    },
    {
      "epoch": 10.685553187100323,
      "grad_norm": 0.2058664858341217,
      "learning_rate": 1.6622327852224963e-05,
      "loss": 0.0449,
      "step": 155400
    },
    {
      "epoch": 10.692429347452382,
      "grad_norm": 0.20334993302822113,
      "learning_rate": 1.6600838927616707e-05,
      "loss": 0.0449,
      "step": 155500
    },
    {
      "epoch": 10.699305507804443,
      "grad_norm": 0.18613073229789734,
      "learning_rate": 1.657935000300845e-05,
      "loss": 0.0434,
      "step": 155600
    },
    {
      "epoch": 10.706181668156502,
      "grad_norm": 0.1572057455778122,
      "learning_rate": 1.6557861078400193e-05,
      "loss": 0.0487,
      "step": 155700
    },
    {
      "epoch": 10.71305782850856,
      "grad_norm": 0.20551912486553192,
      "learning_rate": 1.6536372153791937e-05,
      "loss": 0.048,
      "step": 155800
    },
    {
      "epoch": 10.719933988860621,
      "grad_norm": 0.12896865606307983,
      "learning_rate": 1.651488322918368e-05,
      "loss": 0.0463,
      "step": 155900
    },
    {
      "epoch": 10.72681014921268,
      "grad_norm": 0.1167517825961113,
      "learning_rate": 1.649339430457542e-05,
      "loss": 0.0404,
      "step": 156000
    },
    {
      "epoch": 10.733686309564739,
      "grad_norm": 0.2714051902294159,
      "learning_rate": 1.6471905379967163e-05,
      "loss": 0.0453,
      "step": 156100
    },
    {
      "epoch": 10.740562469916798,
      "grad_norm": 0.288469523191452,
      "learning_rate": 1.6450416455358907e-05,
      "loss": 0.0433,
      "step": 156200
    },
    {
      "epoch": 10.747438630268858,
      "grad_norm": 0.19165171682834625,
      "learning_rate": 1.642892753075065e-05,
      "loss": 0.0438,
      "step": 156300
    },
    {
      "epoch": 10.754314790620917,
      "grad_norm": 0.2775353193283081,
      "learning_rate": 1.6407438606142393e-05,
      "loss": 0.0467,
      "step": 156400
    },
    {
      "epoch": 10.761190950972976,
      "grad_norm": 0.18650248646736145,
      "learning_rate": 1.6385949681534137e-05,
      "loss": 0.0441,
      "step": 156500
    },
    {
      "epoch": 10.768067111325037,
      "grad_norm": 0.15677890181541443,
      "learning_rate": 1.636446075692588e-05,
      "loss": 0.0449,
      "step": 156600
    },
    {
      "epoch": 10.774943271677095,
      "grad_norm": 0.0682392492890358,
      "learning_rate": 1.6342971832317623e-05,
      "loss": 0.0425,
      "step": 156700
    },
    {
      "epoch": 10.781819432029154,
      "grad_norm": 0.2165088951587677,
      "learning_rate": 1.6321482907709367e-05,
      "loss": 0.0461,
      "step": 156800
    },
    {
      "epoch": 10.788695592381215,
      "grad_norm": 0.1392335742712021,
      "learning_rate": 1.629999398310111e-05,
      "loss": 0.0437,
      "step": 156900
    },
    {
      "epoch": 10.795571752733274,
      "grad_norm": 0.13601046800613403,
      "learning_rate": 1.6278505058492853e-05,
      "loss": 0.0444,
      "step": 157000
    },
    {
      "epoch": 10.802447913085333,
      "grad_norm": 0.17112073302268982,
      "learning_rate": 1.6257016133884597e-05,
      "loss": 0.0455,
      "step": 157100
    },
    {
      "epoch": 10.809324073437393,
      "grad_norm": 0.2054964005947113,
      "learning_rate": 1.623552720927634e-05,
      "loss": 0.0439,
      "step": 157200
    },
    {
      "epoch": 10.816200233789452,
      "grad_norm": 0.13761921226978302,
      "learning_rate": 1.621403828466808e-05,
      "loss": 0.0438,
      "step": 157300
    },
    {
      "epoch": 10.823076394141511,
      "grad_norm": 0.17935249209403992,
      "learning_rate": 1.6192549360059823e-05,
      "loss": 0.046,
      "step": 157400
    },
    {
      "epoch": 10.829952554493572,
      "grad_norm": 0.19425833225250244,
      "learning_rate": 1.6171060435451567e-05,
      "loss": 0.0487,
      "step": 157500
    },
    {
      "epoch": 10.83682871484563,
      "grad_norm": 0.15941868722438812,
      "learning_rate": 1.614957151084331e-05,
      "loss": 0.0463,
      "step": 157600
    },
    {
      "epoch": 10.84370487519769,
      "grad_norm": 0.22642917931079865,
      "learning_rate": 1.6128082586235053e-05,
      "loss": 0.048,
      "step": 157700
    },
    {
      "epoch": 10.85058103554975,
      "grad_norm": 0.2753627300262451,
      "learning_rate": 1.6106808550872883e-05,
      "loss": 0.0488,
      "step": 157800
    },
    {
      "epoch": 10.857457195901809,
      "grad_norm": 0.14862824976444244,
      "learning_rate": 1.6085319626264626e-05,
      "loss": 0.0453,
      "step": 157900
    },
    {
      "epoch": 10.864333356253868,
      "grad_norm": 0.22389653325080872,
      "learning_rate": 1.606383070165637e-05,
      "loss": 0.047,
      "step": 158000
    },
    {
      "epoch": 10.871209516605926,
      "grad_norm": 0.1666840761899948,
      "learning_rate": 1.604234177704811e-05,
      "loss": 0.0462,
      "step": 158100
    },
    {
      "epoch": 10.878085676957987,
      "grad_norm": 0.23901617527008057,
      "learning_rate": 1.6020852852439853e-05,
      "loss": 0.0447,
      "step": 158200
    },
    {
      "epoch": 10.884961837310046,
      "grad_norm": 0.14175483584403992,
      "learning_rate": 1.5999363927831596e-05,
      "loss": 0.0475,
      "step": 158300
    },
    {
      "epoch": 10.891837997662105,
      "grad_norm": 0.16866755485534668,
      "learning_rate": 1.597787500322334e-05,
      "loss": 0.0456,
      "step": 158400
    },
    {
      "epoch": 10.898714158014165,
      "grad_norm": 0.11030567437410355,
      "learning_rate": 1.5956386078615083e-05,
      "loss": 0.0446,
      "step": 158500
    },
    {
      "epoch": 10.905590318366224,
      "grad_norm": 0.19619828462600708,
      "learning_rate": 1.5934897154006826e-05,
      "loss": 0.0414,
      "step": 158600
    },
    {
      "epoch": 10.912466478718283,
      "grad_norm": 0.23161807656288147,
      "learning_rate": 1.591340822939857e-05,
      "loss": 0.0425,
      "step": 158700
    },
    {
      "epoch": 10.919342639070344,
      "grad_norm": 0.30201733112335205,
      "learning_rate": 1.5891919304790313e-05,
      "loss": 0.0463,
      "step": 158800
    },
    {
      "epoch": 10.926218799422402,
      "grad_norm": 0.1773938238620758,
      "learning_rate": 1.5870430380182056e-05,
      "loss": 0.0457,
      "step": 158900
    },
    {
      "epoch": 10.933094959774461,
      "grad_norm": 0.21952295303344727,
      "learning_rate": 1.58489414555738e-05,
      "loss": 0.0426,
      "step": 159000
    },
    {
      "epoch": 10.939971120126522,
      "grad_norm": 0.1710096001625061,
      "learning_rate": 1.5827452530965543e-05,
      "loss": 0.0424,
      "step": 159100
    },
    {
      "epoch": 10.94684728047858,
      "grad_norm": 0.2098095566034317,
      "learning_rate": 1.5805963606357286e-05,
      "loss": 0.0452,
      "step": 159200
    },
    {
      "epoch": 10.95372344083064,
      "grad_norm": 0.23871758580207825,
      "learning_rate": 1.578447468174903e-05,
      "loss": 0.0466,
      "step": 159300
    },
    {
      "epoch": 10.9605996011827,
      "grad_norm": 0.16587743163108826,
      "learning_rate": 1.576298575714077e-05,
      "loss": 0.0469,
      "step": 159400
    },
    {
      "epoch": 10.96747576153476,
      "grad_norm": 0.2539333999156952,
      "learning_rate": 1.5741496832532513e-05,
      "loss": 0.0482,
      "step": 159500
    },
    {
      "epoch": 10.974351921886818,
      "grad_norm": 0.20879562199115753,
      "learning_rate": 1.5720007907924256e-05,
      "loss": 0.0475,
      "step": 159600
    },
    {
      "epoch": 10.981228082238879,
      "grad_norm": 0.19705413281917572,
      "learning_rate": 1.5698518983316e-05,
      "loss": 0.0438,
      "step": 159700
    },
    {
      "epoch": 10.988104242590937,
      "grad_norm": 0.12575986981391907,
      "learning_rate": 1.5677030058707743e-05,
      "loss": 0.0472,
      "step": 159800
    },
    {
      "epoch": 10.994980402942996,
      "grad_norm": 0.14361220598220825,
      "learning_rate": 1.5655541134099486e-05,
      "loss": 0.0448,
      "step": 159900
    },
    {
      "epoch": 11.0,
      "eval_accuracy_macro_0.5": 0.9796519875526428,
      "eval_accuracy_micro_0.5": 0.9796520471572876,
      "eval_accuracy_weighted_0.5": 0.9770797491073608,
      "eval_f1_macro_0.5": 0.7194892764091492,
      "eval_f1_macro_0.6": 0.6952572464942932,
      "eval_f1_macro_0.7": 0.6564675569534302,
      "eval_f1_macro_0.8": 0.468047171831131,
      "eval_f1_micro_0.5": 0.7249770760536194,
      "eval_f1_micro_0.6": 0.7058567404747009,
      "eval_f1_micro_0.7": 0.6715825200080872,
      "eval_f1_micro_0.8": 0.6121871471405029,
      "eval_f1_micro_0.9": 0.49345049262046814,
      "eval_f1_weighted_0.5": 0.7166329622268677,
      "eval_f1_weighted_0.6": 0.6910253763198853,
      "eval_f1_weighted_0.7": 0.6495038866996765,
      "eval_f1_weighted_0.8": 0.4519514739513397,
      "eval_loss": 0.04228635132312775,
      "eval_runtime": 63.7638,
      "eval_samples_per_second": 455.384,
      "eval_steps_per_second": 56.929,
      "step": 159973
    },
    {
      "epoch": 11.001856563295057,
      "grad_norm": 0.09979026764631271,
      "learning_rate": 1.563405220949123e-05,
      "loss": 0.046,
      "step": 160000
    },
    {
      "epoch": 11.008732723647116,
      "grad_norm": 0.16012175381183624,
      "learning_rate": 1.5612563284882973e-05,
      "loss": 0.0465,
      "step": 160100
    },
    {
      "epoch": 11.015608883999175,
      "grad_norm": 0.1294591724872589,
      "learning_rate": 1.5591074360274716e-05,
      "loss": 0.0451,
      "step": 160200
    },
    {
      "epoch": 11.022485044351233,
      "grad_norm": 0.07713329046964645,
      "learning_rate": 1.556958543566646e-05,
      "loss": 0.0468,
      "step": 160300
    },
    {
      "epoch": 11.029361204703294,
      "grad_norm": 0.18882808089256287,
      "learning_rate": 1.5548311400304283e-05,
      "loss": 0.0478,
      "step": 160400
    },
    {
      "epoch": 11.036237365055353,
      "grad_norm": 0.17335166037082672,
      "learning_rate": 1.5526822475696026e-05,
      "loss": 0.0432,
      "step": 160500
    },
    {
      "epoch": 11.043113525407412,
      "grad_norm": 0.18256735801696777,
      "learning_rate": 1.550533355108777e-05,
      "loss": 0.0469,
      "step": 160600
    },
    {
      "epoch": 11.049989685759472,
      "grad_norm": 0.17589567601680756,
      "learning_rate": 1.5483844626479513e-05,
      "loss": 0.0457,
      "step": 160700
    },
    {
      "epoch": 11.056865846111531,
      "grad_norm": 0.2019171267747879,
      "learning_rate": 1.5462355701871256e-05,
      "loss": 0.0428,
      "step": 160800
    },
    {
      "epoch": 11.06374200646359,
      "grad_norm": 0.18565092980861664,
      "learning_rate": 1.5440866777263e-05,
      "loss": 0.0426,
      "step": 160900
    },
    {
      "epoch": 11.07061816681565,
      "grad_norm": 0.13673153519630432,
      "learning_rate": 1.5419377852654743e-05,
      "loss": 0.0449,
      "step": 161000
    },
    {
      "epoch": 11.07749432716771,
      "grad_norm": 0.189447820186615,
      "learning_rate": 1.5397888928046486e-05,
      "loss": 0.044,
      "step": 161100
    },
    {
      "epoch": 11.084370487519768,
      "grad_norm": 0.1871223747730255,
      "learning_rate": 1.537640000343823e-05,
      "loss": 0.044,
      "step": 161200
    },
    {
      "epoch": 11.091246647871829,
      "grad_norm": 0.1462664157152176,
      "learning_rate": 1.5354911078829973e-05,
      "loss": 0.0437,
      "step": 161300
    },
    {
      "epoch": 11.098122808223888,
      "grad_norm": 0.06214334815740585,
      "learning_rate": 1.5333422154221716e-05,
      "loss": 0.0422,
      "step": 161400
    },
    {
      "epoch": 11.104998968575947,
      "grad_norm": 0.16318437457084656,
      "learning_rate": 1.531193322961346e-05,
      "loss": 0.046,
      "step": 161500
    },
    {
      "epoch": 11.111875128928007,
      "grad_norm": 0.13215674459934235,
      "learning_rate": 1.52904443050052e-05,
      "loss": 0.046,
      "step": 161600
    },
    {
      "epoch": 11.118751289280066,
      "grad_norm": 0.14144660532474518,
      "learning_rate": 1.5268955380396943e-05,
      "loss": 0.0447,
      "step": 161700
    },
    {
      "epoch": 11.125627449632125,
      "grad_norm": 0.16480709612369537,
      "learning_rate": 1.5247466455788686e-05,
      "loss": 0.046,
      "step": 161800
    },
    {
      "epoch": 11.132503609984186,
      "grad_norm": 0.2173173576593399,
      "learning_rate": 1.522597753118043e-05,
      "loss": 0.0427,
      "step": 161900
    },
    {
      "epoch": 11.139379770336244,
      "grad_norm": 0.1188691183924675,
      "learning_rate": 1.5204488606572173e-05,
      "loss": 0.0457,
      "step": 162000
    },
    {
      "epoch": 11.146255930688303,
      "grad_norm": 0.20779432356357574,
      "learning_rate": 1.5182999681963916e-05,
      "loss": 0.0445,
      "step": 162100
    },
    {
      "epoch": 11.153132091040362,
      "grad_norm": 0.17867955565452576,
      "learning_rate": 1.516151075735566e-05,
      "loss": 0.0454,
      "step": 162200
    },
    {
      "epoch": 11.160008251392423,
      "grad_norm": 0.23488470911979675,
      "learning_rate": 1.5140021832747403e-05,
      "loss": 0.0445,
      "step": 162300
    },
    {
      "epoch": 11.166884411744482,
      "grad_norm": 0.2192053347826004,
      "learning_rate": 1.5118532908139146e-05,
      "loss": 0.046,
      "step": 162400
    },
    {
      "epoch": 11.17376057209654,
      "grad_norm": 0.12292049825191498,
      "learning_rate": 1.509704398353089e-05,
      "loss": 0.0449,
      "step": 162500
    },
    {
      "epoch": 11.180636732448601,
      "grad_norm": 0.14204491674900055,
      "learning_rate": 1.5075555058922633e-05,
      "loss": 0.0422,
      "step": 162600
    },
    {
      "epoch": 11.18751289280066,
      "grad_norm": 0.27461934089660645,
      "learning_rate": 1.5054066134314376e-05,
      "loss": 0.0482,
      "step": 162700
    },
    {
      "epoch": 11.194389053152719,
      "grad_norm": 0.19017097353935242,
      "learning_rate": 1.5032577209706116e-05,
      "loss": 0.0498,
      "step": 162800
    },
    {
      "epoch": 11.20126521350478,
      "grad_norm": 0.17553235590457916,
      "learning_rate": 1.501108828509786e-05,
      "loss": 0.0436,
      "step": 162900
    },
    {
      "epoch": 11.208141373856838,
      "grad_norm": 0.22361218929290771,
      "learning_rate": 1.4989599360489603e-05,
      "loss": 0.0444,
      "step": 163000
    },
    {
      "epoch": 11.215017534208897,
      "grad_norm": 0.27246129512786865,
      "learning_rate": 1.4968110435881346e-05,
      "loss": 0.0479,
      "step": 163100
    },
    {
      "epoch": 11.221893694560958,
      "grad_norm": 0.19737301766872406,
      "learning_rate": 1.494662151127309e-05,
      "loss": 0.0433,
      "step": 163200
    },
    {
      "epoch": 11.228769854913017,
      "grad_norm": 0.1700669378042221,
      "learning_rate": 1.4925132586664833e-05,
      "loss": 0.0447,
      "step": 163300
    },
    {
      "epoch": 11.235646015265075,
      "grad_norm": 0.22267095744609833,
      "learning_rate": 1.4903643662056576e-05,
      "loss": 0.0422,
      "step": 163400
    },
    {
      "epoch": 11.242522175617136,
      "grad_norm": 0.18649859726428986,
      "learning_rate": 1.4882369626694404e-05,
      "loss": 0.0449,
      "step": 163500
    },
    {
      "epoch": 11.249398335969195,
      "grad_norm": 0.22316639125347137,
      "learning_rate": 1.4860880702086147e-05,
      "loss": 0.044,
      "step": 163600
    },
    {
      "epoch": 11.256274496321254,
      "grad_norm": 0.1354523003101349,
      "learning_rate": 1.4839391777477887e-05,
      "loss": 0.046,
      "step": 163700
    },
    {
      "epoch": 11.263150656673314,
      "grad_norm": 0.19070537388324738,
      "learning_rate": 1.481790285286963e-05,
      "loss": 0.0468,
      "step": 163800
    },
    {
      "epoch": 11.270026817025373,
      "grad_norm": 0.16948169469833374,
      "learning_rate": 1.4796413928261374e-05,
      "loss": 0.0423,
      "step": 163900
    },
    {
      "epoch": 11.276902977377432,
      "grad_norm": 0.1772979199886322,
      "learning_rate": 1.4774925003653117e-05,
      "loss": 0.043,
      "step": 164000
    },
    {
      "epoch": 11.283779137729493,
      "grad_norm": 0.14365747570991516,
      "learning_rate": 1.475343607904486e-05,
      "loss": 0.0461,
      "step": 164100
    },
    {
      "epoch": 11.290655298081552,
      "grad_norm": 0.1813942939043045,
      "learning_rate": 1.4731947154436604e-05,
      "loss": 0.047,
      "step": 164200
    },
    {
      "epoch": 11.29753145843361,
      "grad_norm": 0.1689443439245224,
      "learning_rate": 1.4710458229828347e-05,
      "loss": 0.0428,
      "step": 164300
    },
    {
      "epoch": 11.30440761878567,
      "grad_norm": 0.1580430567264557,
      "learning_rate": 1.468896930522009e-05,
      "loss": 0.0462,
      "step": 164400
    },
    {
      "epoch": 11.31128377913773,
      "grad_norm": 0.2123381644487381,
      "learning_rate": 1.4667480380611834e-05,
      "loss": 0.0432,
      "step": 164500
    },
    {
      "epoch": 11.318159939489789,
      "grad_norm": 0.21234673261642456,
      "learning_rate": 1.4645991456003577e-05,
      "loss": 0.0444,
      "step": 164600
    },
    {
      "epoch": 11.325036099841848,
      "grad_norm": 0.16265256702899933,
      "learning_rate": 1.462450253139532e-05,
      "loss": 0.0447,
      "step": 164700
    },
    {
      "epoch": 11.331912260193908,
      "grad_norm": 0.18572092056274414,
      "learning_rate": 1.4603013606787064e-05,
      "loss": 0.0469,
      "step": 164800
    },
    {
      "epoch": 11.338788420545967,
      "grad_norm": 0.15682515501976013,
      "learning_rate": 1.4581524682178807e-05,
      "loss": 0.0457,
      "step": 164900
    },
    {
      "epoch": 11.345664580898026,
      "grad_norm": 0.24560032784938812,
      "learning_rate": 1.4560035757570547e-05,
      "loss": 0.047,
      "step": 165000
    },
    {
      "epoch": 11.352540741250086,
      "grad_norm": 0.172549307346344,
      "learning_rate": 1.453854683296229e-05,
      "loss": 0.0469,
      "step": 165100
    },
    {
      "epoch": 11.359416901602145,
      "grad_norm": 0.2715139091014862,
      "learning_rate": 1.4517057908354034e-05,
      "loss": 0.0446,
      "step": 165200
    },
    {
      "epoch": 11.366293061954204,
      "grad_norm": 0.26597875356674194,
      "learning_rate": 1.4495568983745777e-05,
      "loss": 0.0456,
      "step": 165300
    },
    {
      "epoch": 11.373169222306265,
      "grad_norm": 0.20776453614234924,
      "learning_rate": 1.447408005913752e-05,
      "loss": 0.0466,
      "step": 165400
    },
    {
      "epoch": 11.380045382658324,
      "grad_norm": 0.18157033622264862,
      "learning_rate": 1.4452591134529264e-05,
      "loss": 0.047,
      "step": 165500
    },
    {
      "epoch": 11.386921543010383,
      "grad_norm": 0.1513713300228119,
      "learning_rate": 1.4431102209921007e-05,
      "loss": 0.0463,
      "step": 165600
    },
    {
      "epoch": 11.393797703362443,
      "grad_norm": 0.2137528508901596,
      "learning_rate": 1.440961328531275e-05,
      "loss": 0.0465,
      "step": 165700
    },
    {
      "epoch": 11.400673863714502,
      "grad_norm": 0.1416718065738678,
      "learning_rate": 1.4388124360704494e-05,
      "loss": 0.0456,
      "step": 165800
    },
    {
      "epoch": 11.40755002406656,
      "grad_norm": 0.155491903424263,
      "learning_rate": 1.4366635436096237e-05,
      "loss": 0.0431,
      "step": 165900
    },
    {
      "epoch": 11.414426184418621,
      "grad_norm": 0.1781749576330185,
      "learning_rate": 1.434514651148798e-05,
      "loss": 0.0437,
      "step": 166000
    },
    {
      "epoch": 11.42130234477068,
      "grad_norm": 0.246739462018013,
      "learning_rate": 1.4323657586879724e-05,
      "loss": 0.0438,
      "step": 166100
    },
    {
      "epoch": 11.42817850512274,
      "grad_norm": 0.20747770369052887,
      "learning_rate": 1.4302168662271467e-05,
      "loss": 0.0442,
      "step": 166200
    },
    {
      "epoch": 11.435054665474798,
      "grad_norm": 0.17395499348640442,
      "learning_rate": 1.4280679737663207e-05,
      "loss": 0.0447,
      "step": 166300
    },
    {
      "epoch": 11.441930825826859,
      "grad_norm": 0.19762666523456573,
      "learning_rate": 1.4259405702301035e-05,
      "loss": 0.0463,
      "step": 166400
    },
    {
      "epoch": 11.448806986178917,
      "grad_norm": 0.19930018484592438,
      "learning_rate": 1.4237916777692779e-05,
      "loss": 0.0443,
      "step": 166500
    },
    {
      "epoch": 11.455683146530976,
      "grad_norm": 0.16772666573524475,
      "learning_rate": 1.4216427853084522e-05,
      "loss": 0.0453,
      "step": 166600
    },
    {
      "epoch": 11.462559306883037,
      "grad_norm": 0.2853337526321411,
      "learning_rate": 1.4194938928476265e-05,
      "loss": 0.0479,
      "step": 166700
    },
    {
      "epoch": 11.469435467235096,
      "grad_norm": 0.2891950309276581,
      "learning_rate": 1.4173450003868007e-05,
      "loss": 0.0473,
      "step": 166800
    },
    {
      "epoch": 11.476311627587155,
      "grad_norm": 0.14373722672462463,
      "learning_rate": 1.415196107925975e-05,
      "loss": 0.0442,
      "step": 166900
    },
    {
      "epoch": 11.483187787939215,
      "grad_norm": 0.21238724887371063,
      "learning_rate": 1.4130472154651494e-05,
      "loss": 0.0431,
      "step": 167000
    },
    {
      "epoch": 11.490063948291274,
      "grad_norm": 0.17016564309597015,
      "learning_rate": 1.4108983230043235e-05,
      "loss": 0.0458,
      "step": 167100
    },
    {
      "epoch": 11.496940108643333,
      "grad_norm": 0.168129101395607,
      "learning_rate": 1.4087494305434979e-05,
      "loss": 0.0457,
      "step": 167200
    },
    {
      "epoch": 11.503816268995394,
      "grad_norm": 0.2276320606470108,
      "learning_rate": 1.4066005380826722e-05,
      "loss": 0.045,
      "step": 167300
    },
    {
      "epoch": 11.510692429347452,
      "grad_norm": 0.16809874773025513,
      "learning_rate": 1.4044516456218465e-05,
      "loss": 0.0438,
      "step": 167400
    },
    {
      "epoch": 11.517568589699511,
      "grad_norm": 0.23810142278671265,
      "learning_rate": 1.4023027531610209e-05,
      "loss": 0.047,
      "step": 167500
    },
    {
      "epoch": 11.524444750051572,
      "grad_norm": 0.2016472965478897,
      "learning_rate": 1.4001538607001952e-05,
      "loss": 0.0466,
      "step": 167600
    },
    {
      "epoch": 11.53132091040363,
      "grad_norm": 0.16376174986362457,
      "learning_rate": 1.3980049682393695e-05,
      "loss": 0.0482,
      "step": 167700
    },
    {
      "epoch": 11.53819707075569,
      "grad_norm": 0.2166191041469574,
      "learning_rate": 1.3958560757785439e-05,
      "loss": 0.0439,
      "step": 167800
    },
    {
      "epoch": 11.54507323110775,
      "grad_norm": 0.12339958548545837,
      "learning_rate": 1.3937071833177182e-05,
      "loss": 0.0459,
      "step": 167900
    },
    {
      "epoch": 11.551949391459809,
      "grad_norm": 0.14375920593738556,
      "learning_rate": 1.3915582908568925e-05,
      "loss": 0.044,
      "step": 168000
    },
    {
      "epoch": 11.558825551811868,
      "grad_norm": 0.28219959139823914,
      "learning_rate": 1.3894093983960669e-05,
      "loss": 0.0496,
      "step": 168100
    },
    {
      "epoch": 11.565701712163929,
      "grad_norm": 0.14116154611110687,
      "learning_rate": 1.3872605059352412e-05,
      "loss": 0.0475,
      "step": 168200
    },
    {
      "epoch": 11.572577872515987,
      "grad_norm": 0.1346534788608551,
      "learning_rate": 1.3851116134744155e-05,
      "loss": 0.0447,
      "step": 168300
    },
    {
      "epoch": 11.579454032868046,
      "grad_norm": 0.22777287662029266,
      "learning_rate": 1.3829627210135895e-05,
      "loss": 0.0464,
      "step": 168400
    },
    {
      "epoch": 11.586330193220107,
      "grad_norm": 0.1456792950630188,
      "learning_rate": 1.3808138285527639e-05,
      "loss": 0.0471,
      "step": 168500
    },
    {
      "epoch": 11.593206353572166,
      "grad_norm": 0.18218547105789185,
      "learning_rate": 1.3786649360919382e-05,
      "loss": 0.0435,
      "step": 168600
    },
    {
      "epoch": 11.600082513924225,
      "grad_norm": 0.15611986815929413,
      "learning_rate": 1.3765160436311125e-05,
      "loss": 0.0436,
      "step": 168700
    },
    {
      "epoch": 11.606958674276283,
      "grad_norm": 0.308411180973053,
      "learning_rate": 1.3743671511702869e-05,
      "loss": 0.0418,
      "step": 168800
    },
    {
      "epoch": 11.613834834628344,
      "grad_norm": 0.16630353033542633,
      "learning_rate": 1.3722182587094612e-05,
      "loss": 0.0472,
      "step": 168900
    },
    {
      "epoch": 11.620710994980403,
      "grad_norm": 0.1468147188425064,
      "learning_rate": 1.3700693662486355e-05,
      "loss": 0.0455,
      "step": 169000
    },
    {
      "epoch": 11.627587155332462,
      "grad_norm": 0.22474534809589386,
      "learning_rate": 1.3679204737878099e-05,
      "loss": 0.049,
      "step": 169100
    },
    {
      "epoch": 11.634463315684522,
      "grad_norm": 0.2423555850982666,
      "learning_rate": 1.3657715813269842e-05,
      "loss": 0.0419,
      "step": 169200
    },
    {
      "epoch": 11.641339476036581,
      "grad_norm": 0.13631084561347961,
      "learning_rate": 1.3636226888661585e-05,
      "loss": 0.0444,
      "step": 169300
    },
    {
      "epoch": 11.64821563638864,
      "grad_norm": 0.15891727805137634,
      "learning_rate": 1.3614737964053329e-05,
      "loss": 0.0452,
      "step": 169400
    },
    {
      "epoch": 11.6550917967407,
      "grad_norm": 0.2533692717552185,
      "learning_rate": 1.3593249039445072e-05,
      "loss": 0.0412,
      "step": 169500
    },
    {
      "epoch": 11.66196795709276,
      "grad_norm": 0.15701481699943542,
      "learning_rate": 1.3571760114836815e-05,
      "loss": 0.043,
      "step": 169600
    },
    {
      "epoch": 11.668844117444818,
      "grad_norm": 0.13413546979427338,
      "learning_rate": 1.3550271190228555e-05,
      "loss": 0.0458,
      "step": 169700
    },
    {
      "epoch": 11.675720277796879,
      "grad_norm": 0.12361400574445724,
      "learning_rate": 1.3528782265620299e-05,
      "loss": 0.0468,
      "step": 169800
    },
    {
      "epoch": 11.682596438148938,
      "grad_norm": 0.14919205009937286,
      "learning_rate": 1.3507293341012042e-05,
      "loss": 0.0437,
      "step": 169900
    },
    {
      "epoch": 11.689472598500997,
      "grad_norm": 0.1656678020954132,
      "learning_rate": 1.3486019305649868e-05,
      "loss": 0.0443,
      "step": 170000
    },
    {
      "epoch": 11.696348758853057,
      "grad_norm": 0.13161176443099976,
      "learning_rate": 1.3464530381041612e-05,
      "loss": 0.0448,
      "step": 170100
    },
    {
      "epoch": 11.703224919205116,
      "grad_norm": 0.13527515530586243,
      "learning_rate": 1.3443041456433355e-05,
      "loss": 0.0447,
      "step": 170200
    },
    {
      "epoch": 11.710101079557175,
      "grad_norm": 0.22317637503147125,
      "learning_rate": 1.3421552531825098e-05,
      "loss": 0.0446,
      "step": 170300
    },
    {
      "epoch": 11.716977239909234,
      "grad_norm": 0.14170894026756287,
      "learning_rate": 1.3400063607216842e-05,
      "loss": 0.0468,
      "step": 170400
    },
    {
      "epoch": 11.723853400261294,
      "grad_norm": 0.22057178616523743,
      "learning_rate": 1.3378574682608583e-05,
      "loss": 0.0441,
      "step": 170500
    },
    {
      "epoch": 11.730729560613353,
      "grad_norm": 0.23135095834732056,
      "learning_rate": 1.3357085758000327e-05,
      "loss": 0.0467,
      "step": 170600
    },
    {
      "epoch": 11.737605720965412,
      "grad_norm": 0.1784808486700058,
      "learning_rate": 1.333559683339207e-05,
      "loss": 0.0442,
      "step": 170700
    },
    {
      "epoch": 11.744481881317473,
      "grad_norm": 0.1539037525653839,
      "learning_rate": 1.3314107908783813e-05,
      "loss": 0.0465,
      "step": 170800
    },
    {
      "epoch": 11.751358041669532,
      "grad_norm": 0.14648257195949554,
      "learning_rate": 1.3292618984175557e-05,
      "loss": 0.0432,
      "step": 170900
    },
    {
      "epoch": 11.75823420202159,
      "grad_norm": 0.13257625699043274,
      "learning_rate": 1.32711300595673e-05,
      "loss": 0.044,
      "step": 171000
    },
    {
      "epoch": 11.765110362373651,
      "grad_norm": 0.16935613751411438,
      "learning_rate": 1.3249641134959043e-05,
      "loss": 0.0419,
      "step": 171100
    },
    {
      "epoch": 11.77198652272571,
      "grad_norm": 0.11655762046575546,
      "learning_rate": 1.3228152210350787e-05,
      "loss": 0.0425,
      "step": 171200
    },
    {
      "epoch": 11.778862683077769,
      "grad_norm": 0.12830854952335358,
      "learning_rate": 1.320666328574253e-05,
      "loss": 0.0433,
      "step": 171300
    },
    {
      "epoch": 11.78573884342983,
      "grad_norm": 0.2544994354248047,
      "learning_rate": 1.3185174361134273e-05,
      "loss": 0.0446,
      "step": 171400
    },
    {
      "epoch": 11.792615003781888,
      "grad_norm": 0.15610875189304352,
      "learning_rate": 1.3163685436526017e-05,
      "loss": 0.0432,
      "step": 171500
    },
    {
      "epoch": 11.799491164133947,
      "grad_norm": 0.254178524017334,
      "learning_rate": 1.314219651191776e-05,
      "loss": 0.0457,
      "step": 171600
    },
    {
      "epoch": 11.806367324486008,
      "grad_norm": 0.15403904020786285,
      "learning_rate": 1.3120707587309502e-05,
      "loss": 0.0446,
      "step": 171700
    },
    {
      "epoch": 11.813243484838067,
      "grad_norm": 0.12108223140239716,
      "learning_rate": 1.3099218662701243e-05,
      "loss": 0.0426,
      "step": 171800
    },
    {
      "epoch": 11.820119645190125,
      "grad_norm": 0.19190266728401184,
      "learning_rate": 1.3077729738092987e-05,
      "loss": 0.046,
      "step": 171900
    },
    {
      "epoch": 11.826995805542186,
      "grad_norm": 0.20117081701755524,
      "learning_rate": 1.305624081348473e-05,
      "loss": 0.0449,
      "step": 172000
    },
    {
      "epoch": 11.833871965894245,
      "grad_norm": 0.15493862330913544,
      "learning_rate": 1.3034751888876473e-05,
      "loss": 0.0467,
      "step": 172100
    },
    {
      "epoch": 11.840748126246304,
      "grad_norm": 0.20353731513023376,
      "learning_rate": 1.3013262964268217e-05,
      "loss": 0.0456,
      "step": 172200
    },
    {
      "epoch": 11.847624286598364,
      "grad_norm": 0.13607192039489746,
      "learning_rate": 1.2991988928906043e-05,
      "loss": 0.0471,
      "step": 172300
    },
    {
      "epoch": 11.854500446950423,
      "grad_norm": 0.17804956436157227,
      "learning_rate": 1.2970500004297786e-05,
      "loss": 0.0447,
      "step": 172400
    },
    {
      "epoch": 11.861376607302482,
      "grad_norm": 0.16921290755271912,
      "learning_rate": 1.294901107968953e-05,
      "loss": 0.0448,
      "step": 172500
    },
    {
      "epoch": 11.868252767654543,
      "grad_norm": 0.12885542213916779,
      "learning_rate": 1.2927522155081273e-05,
      "loss": 0.0493,
      "step": 172600
    },
    {
      "epoch": 11.875128928006601,
      "grad_norm": 0.22474166750907898,
      "learning_rate": 1.2906033230473013e-05,
      "loss": 0.0455,
      "step": 172700
    },
    {
      "epoch": 11.88200508835866,
      "grad_norm": 0.13502198457717896,
      "learning_rate": 1.2884544305864756e-05,
      "loss": 0.0444,
      "step": 172800
    },
    {
      "epoch": 11.88888124871072,
      "grad_norm": 0.24131031334400177,
      "learning_rate": 1.28630553812565e-05,
      "loss": 0.0453,
      "step": 172900
    },
    {
      "epoch": 11.89575740906278,
      "grad_norm": 0.1325674206018448,
      "learning_rate": 1.2841566456648243e-05,
      "loss": 0.0463,
      "step": 173000
    },
    {
      "epoch": 11.902633569414839,
      "grad_norm": 0.2633790969848633,
      "learning_rate": 1.2820077532039986e-05,
      "loss": 0.0438,
      "step": 173100
    },
    {
      "epoch": 11.909509729766897,
      "grad_norm": 0.08677370101213455,
      "learning_rate": 1.279858860743173e-05,
      "loss": 0.0448,
      "step": 173200
    },
    {
      "epoch": 11.916385890118958,
      "grad_norm": 0.17251887917518616,
      "learning_rate": 1.2777099682823473e-05,
      "loss": 0.0462,
      "step": 173300
    },
    {
      "epoch": 11.923262050471017,
      "grad_norm": 0.1026187613606453,
      "learning_rate": 1.2755610758215216e-05,
      "loss": 0.0452,
      "step": 173400
    },
    {
      "epoch": 11.930138210823076,
      "grad_norm": 0.12681937217712402,
      "learning_rate": 1.273412183360696e-05,
      "loss": 0.0446,
      "step": 173500
    },
    {
      "epoch": 11.937014371175136,
      "grad_norm": 0.1392437219619751,
      "learning_rate": 1.2712632908998703e-05,
      "loss": 0.0451,
      "step": 173600
    },
    {
      "epoch": 11.943890531527195,
      "grad_norm": 0.12446308135986328,
      "learning_rate": 1.2691143984390446e-05,
      "loss": 0.046,
      "step": 173700
    },
    {
      "epoch": 11.950766691879254,
      "grad_norm": 0.19239138066768646,
      "learning_rate": 1.266965505978219e-05,
      "loss": 0.0474,
      "step": 173800
    },
    {
      "epoch": 11.957642852231315,
      "grad_norm": 0.17619112133979797,
      "learning_rate": 1.2648166135173933e-05,
      "loss": 0.0489,
      "step": 173900
    },
    {
      "epoch": 11.964519012583374,
      "grad_norm": 0.08389494568109512,
      "learning_rate": 1.2626677210565673e-05,
      "loss": 0.0452,
      "step": 174000
    },
    {
      "epoch": 11.971395172935432,
      "grad_norm": 0.22257424890995026,
      "learning_rate": 1.2605188285957416e-05,
      "loss": 0.0467,
      "step": 174100
    },
    {
      "epoch": 11.978271333287493,
      "grad_norm": 0.1205352172255516,
      "learning_rate": 1.258369936134916e-05,
      "loss": 0.045,
      "step": 174200
    },
    {
      "epoch": 11.985147493639552,
      "grad_norm": 0.12498369067907333,
      "learning_rate": 1.2562210436740903e-05,
      "loss": 0.0475,
      "step": 174300
    },
    {
      "epoch": 11.99202365399161,
      "grad_norm": 0.17551949620246887,
      "learning_rate": 1.2540721512132646e-05,
      "loss": 0.0468,
      "step": 174400
    },
    {
      "epoch": 11.99889981434367,
      "grad_norm": 0.14803828299045563,
      "learning_rate": 1.251923258752439e-05,
      "loss": 0.0447,
      "step": 174500
    },
    {
      "epoch": 12.0,
      "eval_accuracy_macro_0.5": 0.9799598455429077,
      "eval_accuracy_micro_0.5": 0.9799598455429077,
      "eval_accuracy_weighted_0.5": 0.9773991107940674,
      "eval_f1_macro_0.5": 0.7236922383308411,
      "eval_f1_macro_0.6": 0.6996080875396729,
      "eval_f1_macro_0.7": 0.6599546670913696,
      "eval_f1_macro_0.8": 0.4656144380569458,
      "eval_f1_micro_0.5": 0.7277193665504456,
      "eval_f1_micro_0.6": 0.7080336213111877,
      "eval_f1_micro_0.7": 0.6732082962989807,
      "eval_f1_micro_0.8": 0.6112428903579712,
      "eval_f1_micro_0.9": 0.4909505844116211,
      "eval_f1_weighted_0.5": 0.7199094295501709,
      "eval_f1_weighted_0.6": 0.6942621469497681,
      "eval_f1_weighted_0.7": 0.6523920893669128,
      "eval_f1_weighted_0.8": 0.45011937618255615,
      "eval_loss": 0.041637521237134933,
      "eval_runtime": 63.0292,
      "eval_samples_per_second": 460.691,
      "eval_steps_per_second": 57.592,
      "step": 174516
    },
    {
      "epoch": 12.00577597469573,
      "grad_norm": 0.2902321219444275,
      "learning_rate": 1.2497743662916133e-05,
      "loss": 0.0463,
      "step": 174600
    },
    {
      "epoch": 12.012652135047789,
      "grad_norm": 0.14023742079734802,
      "learning_rate": 1.247646962755396e-05,
      "loss": 0.0426,
      "step": 174700
    },
    {
      "epoch": 12.019528295399848,
      "grad_norm": 0.22597166895866394,
      "learning_rate": 1.2454980702945703e-05,
      "loss": 0.0426,
      "step": 174800
    },
    {
      "epoch": 12.026404455751909,
      "grad_norm": 0.16151371598243713,
      "learning_rate": 1.2433491778337446e-05,
      "loss": 0.0443,
      "step": 174900
    },
    {
      "epoch": 12.033280616103967,
      "grad_norm": 0.13769887387752533,
      "learning_rate": 1.241200285372919e-05,
      "loss": 0.0448,
      "step": 175000
    },
    {
      "epoch": 12.040156776456026,
      "grad_norm": 0.1686013787984848,
      "learning_rate": 1.2390513929120931e-05,
      "loss": 0.0459,
      "step": 175100
    },
    {
      "epoch": 12.047032936808087,
      "grad_norm": 0.16278164088726044,
      "learning_rate": 1.2369025004512674e-05,
      "loss": 0.0474,
      "step": 175200
    },
    {
      "epoch": 12.053909097160146,
      "grad_norm": 0.14135202765464783,
      "learning_rate": 1.2347536079904418e-05,
      "loss": 0.0451,
      "step": 175300
    },
    {
      "epoch": 12.060785257512205,
      "grad_norm": 0.1493130475282669,
      "learning_rate": 1.2326047155296161e-05,
      "loss": 0.0432,
      "step": 175400
    },
    {
      "epoch": 12.067661417864265,
      "grad_norm": 0.20957161486148834,
      "learning_rate": 1.2304558230687904e-05,
      "loss": 0.0431,
      "step": 175500
    },
    {
      "epoch": 12.074537578216324,
      "grad_norm": 0.2998672425746918,
      "learning_rate": 1.2283069306079648e-05,
      "loss": 0.0465,
      "step": 175600
    },
    {
      "epoch": 12.081413738568383,
      "grad_norm": 0.11916549503803253,
      "learning_rate": 1.2261580381471391e-05,
      "loss": 0.042,
      "step": 175700
    },
    {
      "epoch": 12.088289898920443,
      "grad_norm": 0.2379383146762848,
      "learning_rate": 1.2240091456863133e-05,
      "loss": 0.043,
      "step": 175800
    },
    {
      "epoch": 12.095166059272502,
      "grad_norm": 0.19119080901145935,
      "learning_rate": 1.2218602532254876e-05,
      "loss": 0.046,
      "step": 175900
    },
    {
      "epoch": 12.102042219624561,
      "grad_norm": 0.20823681354522705,
      "learning_rate": 1.219711360764662e-05,
      "loss": 0.0445,
      "step": 176000
    },
    {
      "epoch": 12.108918379976622,
      "grad_norm": 0.14894837141036987,
      "learning_rate": 1.2175624683038363e-05,
      "loss": 0.044,
      "step": 176100
    },
    {
      "epoch": 12.11579454032868,
      "grad_norm": 0.27872493863105774,
      "learning_rate": 1.2154135758430106e-05,
      "loss": 0.0493,
      "step": 176200
    },
    {
      "epoch": 12.12267070068074,
      "grad_norm": 0.15640570223331451,
      "learning_rate": 1.213264683382185e-05,
      "loss": 0.0472,
      "step": 176300
    },
    {
      "epoch": 12.1295468610328,
      "grad_norm": 0.20304755866527557,
      "learning_rate": 1.2111157909213591e-05,
      "loss": 0.0438,
      "step": 176400
    },
    {
      "epoch": 12.136423021384859,
      "grad_norm": 0.14459747076034546,
      "learning_rate": 1.2089668984605334e-05,
      "loss": 0.0431,
      "step": 176500
    },
    {
      "epoch": 12.143299181736918,
      "grad_norm": 0.1646127998828888,
      "learning_rate": 1.2068180059997078e-05,
      "loss": 0.0442,
      "step": 176600
    },
    {
      "epoch": 12.150175342088977,
      "grad_norm": 0.1033700481057167,
      "learning_rate": 1.2046691135388821e-05,
      "loss": 0.0423,
      "step": 176700
    },
    {
      "epoch": 12.157051502441037,
      "grad_norm": 0.16507041454315186,
      "learning_rate": 1.2025202210780564e-05,
      "loss": 0.0421,
      "step": 176800
    },
    {
      "epoch": 12.163927662793096,
      "grad_norm": 0.18198734521865845,
      "learning_rate": 1.2003713286172308e-05,
      "loss": 0.0445,
      "step": 176900
    },
    {
      "epoch": 12.170803823145155,
      "grad_norm": 0.1620447188615799,
      "learning_rate": 1.1982439250810132e-05,
      "loss": 0.0453,
      "step": 177000
    },
    {
      "epoch": 12.177679983497216,
      "grad_norm": 0.18173061311244965,
      "learning_rate": 1.1960950326201876e-05,
      "loss": 0.0448,
      "step": 177100
    },
    {
      "epoch": 12.184556143849274,
      "grad_norm": 0.15030628442764282,
      "learning_rate": 1.193946140159362e-05,
      "loss": 0.0461,
      "step": 177200
    },
    {
      "epoch": 12.191432304201333,
      "grad_norm": 0.15791335701942444,
      "learning_rate": 1.1917972476985363e-05,
      "loss": 0.046,
      "step": 177300
    },
    {
      "epoch": 12.198308464553394,
      "grad_norm": 0.147867813706398,
      "learning_rate": 1.1896483552377106e-05,
      "loss": 0.0429,
      "step": 177400
    },
    {
      "epoch": 12.205184624905453,
      "grad_norm": 0.23169909417629242,
      "learning_rate": 1.187499462776885e-05,
      "loss": 0.0447,
      "step": 177500
    },
    {
      "epoch": 12.212060785257512,
      "grad_norm": 0.18037377297878265,
      "learning_rate": 1.1853505703160593e-05,
      "loss": 0.0462,
      "step": 177600
    },
    {
      "epoch": 12.218936945609572,
      "grad_norm": 0.24941858649253845,
      "learning_rate": 1.1832016778552336e-05,
      "loss": 0.0433,
      "step": 177700
    },
    {
      "epoch": 12.225813105961631,
      "grad_norm": 0.25175461173057556,
      "learning_rate": 1.181052785394408e-05,
      "loss": 0.0471,
      "step": 177800
    },
    {
      "epoch": 12.23268926631369,
      "grad_norm": 0.11952347308397293,
      "learning_rate": 1.178903892933582e-05,
      "loss": 0.046,
      "step": 177900
    },
    {
      "epoch": 12.23956542666575,
      "grad_norm": 0.20264945924282074,
      "learning_rate": 1.1767550004727564e-05,
      "loss": 0.0452,
      "step": 178000
    },
    {
      "epoch": 12.24644158701781,
      "grad_norm": 0.3638281524181366,
      "learning_rate": 1.1746061080119307e-05,
      "loss": 0.0415,
      "step": 178100
    },
    {
      "epoch": 12.253317747369868,
      "grad_norm": 0.22573477029800415,
      "learning_rate": 1.172457215551105e-05,
      "loss": 0.0465,
      "step": 178200
    },
    {
      "epoch": 12.260193907721929,
      "grad_norm": 0.17748747766017914,
      "learning_rate": 1.1703083230902794e-05,
      "loss": 0.0471,
      "step": 178300
    },
    {
      "epoch": 12.267070068073988,
      "grad_norm": 0.14546622335910797,
      "learning_rate": 1.1681594306294537e-05,
      "loss": 0.0453,
      "step": 178400
    },
    {
      "epoch": 12.273946228426047,
      "grad_norm": 0.1511380970478058,
      "learning_rate": 1.166010538168628e-05,
      "loss": 0.0441,
      "step": 178500
    },
    {
      "epoch": 12.280822388778105,
      "grad_norm": 0.1503669172525406,
      "learning_rate": 1.1638616457078022e-05,
      "loss": 0.0465,
      "step": 178600
    },
    {
      "epoch": 12.287698549130166,
      "grad_norm": 0.12546122074127197,
      "learning_rate": 1.1617127532469766e-05,
      "loss": 0.0417,
      "step": 178700
    },
    {
      "epoch": 12.294574709482225,
      "grad_norm": 0.14150020480155945,
      "learning_rate": 1.1595638607861509e-05,
      "loss": 0.0452,
      "step": 178800
    },
    {
      "epoch": 12.301450869834284,
      "grad_norm": 0.16316398978233337,
      "learning_rate": 1.1574149683253252e-05,
      "loss": 0.0447,
      "step": 178900
    },
    {
      "epoch": 12.308327030186344,
      "grad_norm": 0.3305317163467407,
      "learning_rate": 1.1552660758644996e-05,
      "loss": 0.0462,
      "step": 179000
    },
    {
      "epoch": 12.315203190538403,
      "grad_norm": 0.1235671117901802,
      "learning_rate": 1.1531171834036739e-05,
      "loss": 0.0412,
      "step": 179100
    },
    {
      "epoch": 12.322079350890462,
      "grad_norm": 0.1465495526790619,
      "learning_rate": 1.150968290942848e-05,
      "loss": 0.045,
      "step": 179200
    },
    {
      "epoch": 12.328955511242523,
      "grad_norm": 0.25934654474258423,
      "learning_rate": 1.1488193984820224e-05,
      "loss": 0.0427,
      "step": 179300
    },
    {
      "epoch": 12.335831671594581,
      "grad_norm": 0.10012054443359375,
      "learning_rate": 1.1466705060211967e-05,
      "loss": 0.0452,
      "step": 179400
    },
    {
      "epoch": 12.34270783194664,
      "grad_norm": 0.14425042271614075,
      "learning_rate": 1.144521613560371e-05,
      "loss": 0.0436,
      "step": 179500
    },
    {
      "epoch": 12.349583992298701,
      "grad_norm": 0.17339782416820526,
      "learning_rate": 1.1423727210995454e-05,
      "loss": 0.0426,
      "step": 179600
    },
    {
      "epoch": 12.35646015265076,
      "grad_norm": 0.21044041216373444,
      "learning_rate": 1.1402238286387197e-05,
      "loss": 0.0495,
      "step": 179700
    },
    {
      "epoch": 12.363336313002819,
      "grad_norm": 0.30211520195007324,
      "learning_rate": 1.1380749361778939e-05,
      "loss": 0.0455,
      "step": 179800
    },
    {
      "epoch": 12.37021247335488,
      "grad_norm": 0.1616230458021164,
      "learning_rate": 1.1359260437170682e-05,
      "loss": 0.0457,
      "step": 179900
    },
    {
      "epoch": 12.377088633706938,
      "grad_norm": 0.16213931143283844,
      "learning_rate": 1.1337771512562426e-05,
      "loss": 0.0466,
      "step": 180000
    },
    {
      "epoch": 12.383964794058997,
      "grad_norm": 0.19183878600597382,
      "learning_rate": 1.1316282587954169e-05,
      "loss": 0.0446,
      "step": 180100
    },
    {
      "epoch": 12.390840954411058,
      "grad_norm": 0.21550202369689941,
      "learning_rate": 1.1294793663345912e-05,
      "loss": 0.0468,
      "step": 180200
    },
    {
      "epoch": 12.397717114763116,
      "grad_norm": 0.2227296531200409,
      "learning_rate": 1.1273304738737656e-05,
      "loss": 0.0456,
      "step": 180300
    },
    {
      "epoch": 12.404593275115175,
      "grad_norm": 0.25071486830711365,
      "learning_rate": 1.1251815814129399e-05,
      "loss": 0.0443,
      "step": 180400
    },
    {
      "epoch": 12.411469435467236,
      "grad_norm": 0.2296656370162964,
      "learning_rate": 1.123032688952114e-05,
      "loss": 0.0458,
      "step": 180500
    },
    {
      "epoch": 12.418345595819295,
      "grad_norm": 0.14541202783584595,
      "learning_rate": 1.1208837964912884e-05,
      "loss": 0.0441,
      "step": 180600
    },
    {
      "epoch": 12.425221756171354,
      "grad_norm": 0.14188598096370697,
      "learning_rate": 1.1187349040304627e-05,
      "loss": 0.0433,
      "step": 180700
    },
    {
      "epoch": 12.432097916523414,
      "grad_norm": 0.21219392120838165,
      "learning_rate": 1.116586011569637e-05,
      "loss": 0.0432,
      "step": 180800
    },
    {
      "epoch": 12.438974076875473,
      "grad_norm": 0.1768767237663269,
      "learning_rate": 1.1144371191088114e-05,
      "loss": 0.0408,
      "step": 180900
    },
    {
      "epoch": 12.445850237227532,
      "grad_norm": 0.17377004027366638,
      "learning_rate": 1.1122882266479857e-05,
      "loss": 0.0422,
      "step": 181000
    },
    {
      "epoch": 12.45272639757959,
      "grad_norm": 0.1692434847354889,
      "learning_rate": 1.1101608231117682e-05,
      "loss": 0.0455,
      "step": 181100
    },
    {
      "epoch": 12.459602557931651,
      "grad_norm": 0.08509042114019394,
      "learning_rate": 1.1080119306509425e-05,
      "loss": 0.0479,
      "step": 181200
    },
    {
      "epoch": 12.46647871828371,
      "grad_norm": 0.30095502734184265,
      "learning_rate": 1.1058630381901169e-05,
      "loss": 0.0462,
      "step": 181300
    },
    {
      "epoch": 12.473354878635769,
      "grad_norm": 0.24055540561676025,
      "learning_rate": 1.1037141457292912e-05,
      "loss": 0.0461,
      "step": 181400
    },
    {
      "epoch": 12.48023103898783,
      "grad_norm": 0.19107899069786072,
      "learning_rate": 1.1015652532684655e-05,
      "loss": 0.0452,
      "step": 181500
    },
    {
      "epoch": 12.487107199339889,
      "grad_norm": 0.11444596946239471,
      "learning_rate": 1.0994163608076397e-05,
      "loss": 0.0435,
      "step": 181600
    },
    {
      "epoch": 12.493983359691947,
      "grad_norm": 0.1928986757993698,
      "learning_rate": 1.097267468346814e-05,
      "loss": 0.0443,
      "step": 181700
    },
    {
      "epoch": 12.500859520044008,
      "grad_norm": 0.23819129168987274,
      "learning_rate": 1.0951185758859884e-05,
      "loss": 0.0473,
      "step": 181800
    },
    {
      "epoch": 12.507735680396067,
      "grad_norm": 0.21966569125652313,
      "learning_rate": 1.0929696834251627e-05,
      "loss": 0.0465,
      "step": 181900
    },
    {
      "epoch": 12.514611840748126,
      "grad_norm": 0.1318325251340866,
      "learning_rate": 1.0908422798889454e-05,
      "loss": 0.0467,
      "step": 182000
    },
    {
      "epoch": 12.521488001100186,
      "grad_norm": 0.1934838593006134,
      "learning_rate": 1.0886933874281197e-05,
      "loss": 0.0452,
      "step": 182100
    },
    {
      "epoch": 12.528364161452245,
      "grad_norm": 0.19101250171661377,
      "learning_rate": 1.0865444949672939e-05,
      "loss": 0.0434,
      "step": 182200
    },
    {
      "epoch": 12.535240321804304,
      "grad_norm": 0.13317985832691193,
      "learning_rate": 1.0843956025064682e-05,
      "loss": 0.047,
      "step": 182300
    },
    {
      "epoch": 12.542116482156365,
      "grad_norm": 0.14060653746128082,
      "learning_rate": 1.0822467100456425e-05,
      "loss": 0.0415,
      "step": 182400
    },
    {
      "epoch": 12.548992642508424,
      "grad_norm": 0.18995986878871918,
      "learning_rate": 1.0800978175848169e-05,
      "loss": 0.0453,
      "step": 182500
    },
    {
      "epoch": 12.555868802860482,
      "grad_norm": 0.19451066851615906,
      "learning_rate": 1.0779489251239912e-05,
      "loss": 0.0451,
      "step": 182600
    },
    {
      "epoch": 12.562744963212541,
      "grad_norm": 0.1669352501630783,
      "learning_rate": 1.0758000326631655e-05,
      "loss": 0.0435,
      "step": 182700
    },
    {
      "epoch": 12.569621123564602,
      "grad_norm": 0.212210550904274,
      "learning_rate": 1.0736511402023397e-05,
      "loss": 0.0459,
      "step": 182800
    },
    {
      "epoch": 12.57649728391666,
      "grad_norm": 0.1512811779975891,
      "learning_rate": 1.071502247741514e-05,
      "loss": 0.0429,
      "step": 182900
    },
    {
      "epoch": 12.58337344426872,
      "grad_norm": 0.22183671593666077,
      "learning_rate": 1.0693533552806884e-05,
      "loss": 0.0463,
      "step": 183000
    },
    {
      "epoch": 12.59024960462078,
      "grad_norm": 0.13677945733070374,
      "learning_rate": 1.0672044628198627e-05,
      "loss": 0.0481,
      "step": 183100
    },
    {
      "epoch": 12.597125764972839,
      "grad_norm": 0.14025579392910004,
      "learning_rate": 1.065055570359037e-05,
      "loss": 0.0454,
      "step": 183200
    },
    {
      "epoch": 12.604001925324898,
      "grad_norm": 0.09770827740430832,
      "learning_rate": 1.0629066778982114e-05,
      "loss": 0.0428,
      "step": 183300
    },
    {
      "epoch": 12.610878085676958,
      "grad_norm": 0.17890852689743042,
      "learning_rate": 1.0607577854373857e-05,
      "loss": 0.0458,
      "step": 183400
    },
    {
      "epoch": 12.617754246029017,
      "grad_norm": 0.4044343829154968,
      "learning_rate": 1.0586088929765598e-05,
      "loss": 0.0464,
      "step": 183500
    },
    {
      "epoch": 12.624630406381076,
      "grad_norm": 0.16490542888641357,
      "learning_rate": 1.0564600005157342e-05,
      "loss": 0.0451,
      "step": 183600
    },
    {
      "epoch": 12.631506566733137,
      "grad_norm": 0.26425454020500183,
      "learning_rate": 1.0543111080549085e-05,
      "loss": 0.0466,
      "step": 183700
    },
    {
      "epoch": 12.638382727085196,
      "grad_norm": 0.24020150303840637,
      "learning_rate": 1.0521622155940828e-05,
      "loss": 0.0423,
      "step": 183800
    },
    {
      "epoch": 12.645258887437254,
      "grad_norm": 0.188960000872612,
      "learning_rate": 1.0500133231332572e-05,
      "loss": 0.0465,
      "step": 183900
    },
    {
      "epoch": 12.652135047789315,
      "grad_norm": 0.16664975881576538,
      "learning_rate": 1.0478644306724315e-05,
      "loss": 0.0468,
      "step": 184000
    },
    {
      "epoch": 12.659011208141374,
      "grad_norm": 0.16559655964374542,
      "learning_rate": 1.0457155382116057e-05,
      "loss": 0.0422,
      "step": 184100
    },
    {
      "epoch": 12.665887368493433,
      "grad_norm": 0.19131770730018616,
      "learning_rate": 1.04356664575078e-05,
      "loss": 0.0465,
      "step": 184200
    },
    {
      "epoch": 12.672763528845493,
      "grad_norm": 0.09522470086812973,
      "learning_rate": 1.0414177532899543e-05,
      "loss": 0.0439,
      "step": 184300
    },
    {
      "epoch": 12.679639689197552,
      "grad_norm": 0.20157089829444885,
      "learning_rate": 1.0392688608291287e-05,
      "loss": 0.0449,
      "step": 184400
    },
    {
      "epoch": 12.686515849549611,
      "grad_norm": 0.12297847867012024,
      "learning_rate": 1.037119968368303e-05,
      "loss": 0.0431,
      "step": 184500
    },
    {
      "epoch": 12.693392009901672,
      "grad_norm": 0.24977678060531616,
      "learning_rate": 1.0349710759074773e-05,
      "loss": 0.0463,
      "step": 184600
    },
    {
      "epoch": 12.70026817025373,
      "grad_norm": 0.20501847565174103,
      "learning_rate": 1.0328221834466517e-05,
      "loss": 0.0441,
      "step": 184700
    },
    {
      "epoch": 12.70714433060579,
      "grad_norm": 0.23341844975948334,
      "learning_rate": 1.0306732909858258e-05,
      "loss": 0.0442,
      "step": 184800
    },
    {
      "epoch": 12.71402049095785,
      "grad_norm": 0.17138728499412537,
      "learning_rate": 1.0285243985250002e-05,
      "loss": 0.043,
      "step": 184900
    },
    {
      "epoch": 12.720896651309909,
      "grad_norm": 0.19559894502162933,
      "learning_rate": 1.0263969949887828e-05,
      "loss": 0.0458,
      "step": 185000
    },
    {
      "epoch": 12.727772811661968,
      "grad_norm": 0.1912282407283783,
      "learning_rate": 1.0242481025279572e-05,
      "loss": 0.0444,
      "step": 185100
    },
    {
      "epoch": 12.734648972014027,
      "grad_norm": 0.2483566403388977,
      "learning_rate": 1.0220992100671315e-05,
      "loss": 0.045,
      "step": 185200
    },
    {
      "epoch": 12.741525132366087,
      "grad_norm": 0.1888355165719986,
      "learning_rate": 1.0199503176063058e-05,
      "loss": 0.0462,
      "step": 185300
    },
    {
      "epoch": 12.748401292718146,
      "grad_norm": 0.15042459964752197,
      "learning_rate": 1.0178014251454802e-05,
      "loss": 0.0467,
      "step": 185400
    },
    {
      "epoch": 12.755277453070205,
      "grad_norm": 0.1281648874282837,
      "learning_rate": 1.0156525326846545e-05,
      "loss": 0.0481,
      "step": 185500
    },
    {
      "epoch": 12.762153613422266,
      "grad_norm": 0.08933993428945541,
      "learning_rate": 1.0135036402238287e-05,
      "loss": 0.042,
      "step": 185600
    },
    {
      "epoch": 12.769029773774324,
      "grad_norm": 0.16385002434253693,
      "learning_rate": 1.011354747763003e-05,
      "loss": 0.0454,
      "step": 185700
    },
    {
      "epoch": 12.775905934126383,
      "grad_norm": 0.17875611782073975,
      "learning_rate": 1.0092058553021773e-05,
      "loss": 0.0461,
      "step": 185800
    },
    {
      "epoch": 12.782782094478444,
      "grad_norm": 0.16703365743160248,
      "learning_rate": 1.0070569628413517e-05,
      "loss": 0.0456,
      "step": 185900
    },
    {
      "epoch": 12.789658254830503,
      "grad_norm": 0.1687103658914566,
      "learning_rate": 1.004908070380526e-05,
      "loss": 0.044,
      "step": 186000
    },
    {
      "epoch": 12.796534415182562,
      "grad_norm": 0.23892781138420105,
      "learning_rate": 1.0027591779197003e-05,
      "loss": 0.0454,
      "step": 186100
    },
    {
      "epoch": 12.803410575534622,
      "grad_norm": 0.23262695968151093,
      "learning_rate": 1.0006102854588747e-05,
      "loss": 0.0494,
      "step": 186200
    },
    {
      "epoch": 12.810286735886681,
      "grad_norm": 0.1285109519958496,
      "learning_rate": 9.984613929980488e-06,
      "loss": 0.045,
      "step": 186300
    },
    {
      "epoch": 12.81716289623874,
      "grad_norm": 0.19428347051143646,
      "learning_rate": 9.963125005372232e-06,
      "loss": 0.0473,
      "step": 186400
    },
    {
      "epoch": 12.8240390565908,
      "grad_norm": 0.21887248754501343,
      "learning_rate": 9.941636080763975e-06,
      "loss": 0.0447,
      "step": 186500
    },
    {
      "epoch": 12.83091521694286,
      "grad_norm": 0.22606749832630157,
      "learning_rate": 9.920147156155718e-06,
      "loss": 0.0459,
      "step": 186600
    },
    {
      "epoch": 12.837791377294918,
      "grad_norm": 0.2756780982017517,
      "learning_rate": 9.898658231547462e-06,
      "loss": 0.0446,
      "step": 186700
    },
    {
      "epoch": 12.844667537646977,
      "grad_norm": 0.11606195569038391,
      "learning_rate": 9.877169306939205e-06,
      "loss": 0.0455,
      "step": 186800
    },
    {
      "epoch": 12.851543697999038,
      "grad_norm": 0.14499646425247192,
      "learning_rate": 9.855680382330946e-06,
      "loss": 0.0425,
      "step": 186900
    },
    {
      "epoch": 12.858419858351096,
      "grad_norm": 0.16336609423160553,
      "learning_rate": 9.83419145772269e-06,
      "loss": 0.0452,
      "step": 187000
    },
    {
      "epoch": 12.865296018703155,
      "grad_norm": 0.131553515791893,
      "learning_rate": 9.812702533114433e-06,
      "loss": 0.0437,
      "step": 187100
    },
    {
      "epoch": 12.872172179055216,
      "grad_norm": 0.15733829140663147,
      "learning_rate": 9.791213608506176e-06,
      "loss": 0.0449,
      "step": 187200
    },
    {
      "epoch": 12.879048339407275,
      "grad_norm": 0.27596315741539,
      "learning_rate": 9.76972468389792e-06,
      "loss": 0.0475,
      "step": 187300
    },
    {
      "epoch": 12.885924499759334,
      "grad_norm": 0.16569668054580688,
      "learning_rate": 9.748235759289663e-06,
      "loss": 0.046,
      "step": 187400
    },
    {
      "epoch": 12.892800660111394,
      "grad_norm": 0.16817857325077057,
      "learning_rate": 9.726961723927488e-06,
      "loss": 0.0409,
      "step": 187500
    },
    {
      "epoch": 12.899676820463453,
      "grad_norm": 0.17014671862125397,
      "learning_rate": 9.705472799319231e-06,
      "loss": 0.0449,
      "step": 187600
    },
    {
      "epoch": 12.906552980815512,
      "grad_norm": 0.19976674020290375,
      "learning_rate": 9.683983874710975e-06,
      "loss": 0.0431,
      "step": 187700
    },
    {
      "epoch": 12.913429141167573,
      "grad_norm": 0.12587568163871765,
      "learning_rate": 9.662494950102716e-06,
      "loss": 0.0463,
      "step": 187800
    },
    {
      "epoch": 12.920305301519631,
      "grad_norm": 0.3414795994758606,
      "learning_rate": 9.64100602549446e-06,
      "loss": 0.0431,
      "step": 187900
    },
    {
      "epoch": 12.92718146187169,
      "grad_norm": 0.19327931106090546,
      "learning_rate": 9.619517100886203e-06,
      "loss": 0.0456,
      "step": 188000
    },
    {
      "epoch": 12.93405762222375,
      "grad_norm": 0.16812251508235931,
      "learning_rate": 9.598028176277946e-06,
      "loss": 0.044,
      "step": 188100
    },
    {
      "epoch": 12.94093378257581,
      "grad_norm": 0.17798054218292236,
      "learning_rate": 9.57653925166969e-06,
      "loss": 0.0413,
      "step": 188200
    },
    {
      "epoch": 12.947809942927869,
      "grad_norm": 0.1786045879125595,
      "learning_rate": 9.555050327061433e-06,
      "loss": 0.0432,
      "step": 188300
    },
    {
      "epoch": 12.95468610327993,
      "grad_norm": 0.17806600034236908,
      "learning_rate": 9.533561402453176e-06,
      "loss": 0.0445,
      "step": 188400
    },
    {
      "epoch": 12.961562263631988,
      "grad_norm": 0.08667866885662079,
      "learning_rate": 9.51207247784492e-06,
      "loss": 0.0437,
      "step": 188500
    },
    {
      "epoch": 12.968438423984047,
      "grad_norm": 0.09288059920072556,
      "learning_rate": 9.490583553236663e-06,
      "loss": 0.047,
      "step": 188600
    },
    {
      "epoch": 12.975314584336108,
      "grad_norm": 0.14137285947799683,
      "learning_rate": 9.469094628628406e-06,
      "loss": 0.0442,
      "step": 188700
    },
    {
      "epoch": 12.982190744688166,
      "grad_norm": 0.19463856518268585,
      "learning_rate": 9.44760570402015e-06,
      "loss": 0.0439,
      "step": 188800
    },
    {
      "epoch": 12.989066905040225,
      "grad_norm": 0.16988475620746613,
      "learning_rate": 9.426116779411893e-06,
      "loss": 0.0459,
      "step": 188900
    },
    {
      "epoch": 12.995943065392286,
      "grad_norm": 0.21653680503368378,
      "learning_rate": 9.404627854803635e-06,
      "loss": 0.046,
      "step": 189000
    },
    {
      "epoch": 13.0,
      "eval_accuracy_macro_0.5": 0.9799565672874451,
      "eval_accuracy_micro_0.5": 0.9799566268920898,
      "eval_accuracy_weighted_0.5": 0.9774065613746643,
      "eval_f1_macro_0.5": 0.7251436710357666,
      "eval_f1_macro_0.6": 0.7019418478012085,
      "eval_f1_macro_0.7": 0.6640273928642273,
      "eval_f1_macro_0.8": 0.47385159134864807,
      "eval_f1_micro_0.5": 0.7297187447547913,
      "eval_f1_micro_0.6": 0.7111448645591736,
      "eval_f1_micro_0.7": 0.6779963970184326,
      "eval_f1_micro_0.8": 0.6187596917152405,
      "eval_f1_micro_0.9": 0.5000795125961304,
      "eval_f1_weighted_0.5": 0.721881628036499,
      "eval_f1_weighted_0.6": 0.6972395181655884,
      "eval_f1_weighted_0.7": 0.6571299433708191,
      "eval_f1_weighted_0.8": 0.4592546224594116,
      "eval_loss": 0.04165935888886452,
      "eval_runtime": 63.5376,
      "eval_samples_per_second": 457.005,
      "eval_steps_per_second": 57.132,
      "step": 189059
    },
    {
      "epoch": 13.002819225744345,
      "grad_norm": 0.1603340059518814,
      "learning_rate": 9.383138930195378e-06,
      "loss": 0.0452,
      "step": 189100
    },
    {
      "epoch": 13.009695386096404,
      "grad_norm": 0.24430310726165771,
      "learning_rate": 9.361650005587121e-06,
      "loss": 0.047,
      "step": 189200
    },
    {
      "epoch": 13.016571546448462,
      "grad_norm": 0.1805465668439865,
      "learning_rate": 9.340161080978865e-06,
      "loss": 0.0462,
      "step": 189300
    },
    {
      "epoch": 13.023447706800523,
      "grad_norm": 0.1634935587644577,
      "learning_rate": 9.318672156370608e-06,
      "loss": 0.0445,
      "step": 189400
    },
    {
      "epoch": 13.030323867152582,
      "grad_norm": 0.14719367027282715,
      "learning_rate": 9.297183231762351e-06,
      "loss": 0.046,
      "step": 189500
    },
    {
      "epoch": 13.03720002750464,
      "grad_norm": 0.19620385766029358,
      "learning_rate": 9.275694307154095e-06,
      "loss": 0.0437,
      "step": 189600
    },
    {
      "epoch": 13.044076187856701,
      "grad_norm": 0.16156713664531708,
      "learning_rate": 9.254205382545836e-06,
      "loss": 0.0442,
      "step": 189700
    },
    {
      "epoch": 13.05095234820876,
      "grad_norm": 0.19071055948734283,
      "learning_rate": 9.23271645793758e-06,
      "loss": 0.0443,
      "step": 189800
    },
    {
      "epoch": 13.057828508560819,
      "grad_norm": 0.17020389437675476,
      "learning_rate": 9.211227533329323e-06,
      "loss": 0.0474,
      "step": 189900
    },
    {
      "epoch": 13.06470466891288,
      "grad_norm": 0.23447230458259583,
      "learning_rate": 9.189738608721066e-06,
      "loss": 0.0447,
      "step": 190000
    },
    {
      "epoch": 13.071580829264938,
      "grad_norm": 0.18646302819252014,
      "learning_rate": 9.16824968411281e-06,
      "loss": 0.0447,
      "step": 190100
    },
    {
      "epoch": 13.078456989616997,
      "grad_norm": 0.18873760104179382,
      "learning_rate": 9.146760759504553e-06,
      "loss": 0.0454,
      "step": 190200
    },
    {
      "epoch": 13.085333149969058,
      "grad_norm": 0.18518859148025513,
      "learning_rate": 9.125271834896294e-06,
      "loss": 0.049,
      "step": 190300
    },
    {
      "epoch": 13.092209310321117,
      "grad_norm": 0.17707720398902893,
      "learning_rate": 9.103782910288038e-06,
      "loss": 0.0419,
      "step": 190400
    },
    {
      "epoch": 13.099085470673176,
      "grad_norm": 0.20881910622119904,
      "learning_rate": 9.082293985679781e-06,
      "loss": 0.0433,
      "step": 190500
    },
    {
      "epoch": 13.105961631025236,
      "grad_norm": 0.13373883068561554,
      "learning_rate": 9.060805061071524e-06,
      "loss": 0.0452,
      "step": 190600
    },
    {
      "epoch": 13.112837791377295,
      "grad_norm": 0.20618467032909393,
      "learning_rate": 9.039316136463268e-06,
      "loss": 0.0424,
      "step": 190700
    },
    {
      "epoch": 13.119713951729354,
      "grad_norm": 0.1607738882303238,
      "learning_rate": 9.017827211855011e-06,
      "loss": 0.0419,
      "step": 190800
    },
    {
      "epoch": 13.126590112081415,
      "grad_norm": 0.12142888456583023,
      "learning_rate": 8.996338287246753e-06,
      "loss": 0.0437,
      "step": 190900
    },
    {
      "epoch": 13.133466272433473,
      "grad_norm": 0.22646689414978027,
      "learning_rate": 8.974849362638496e-06,
      "loss": 0.0439,
      "step": 191000
    },
    {
      "epoch": 13.140342432785532,
      "grad_norm": 0.25815677642822266,
      "learning_rate": 8.95336043803024e-06,
      "loss": 0.0438,
      "step": 191100
    },
    {
      "epoch": 13.147218593137591,
      "grad_norm": 0.23703548312187195,
      "learning_rate": 8.931871513421983e-06,
      "loss": 0.0482,
      "step": 191200
    },
    {
      "epoch": 13.154094753489652,
      "grad_norm": 0.18874885141849518,
      "learning_rate": 8.910382588813726e-06,
      "loss": 0.0447,
      "step": 191300
    },
    {
      "epoch": 13.16097091384171,
      "grad_norm": 0.1431129425764084,
      "learning_rate": 8.88889366420547e-06,
      "loss": 0.0432,
      "step": 191400
    },
    {
      "epoch": 13.16784707419377,
      "grad_norm": 0.17448166012763977,
      "learning_rate": 8.867619628843294e-06,
      "loss": 0.0409,
      "step": 191500
    },
    {
      "epoch": 13.17472323454583,
      "grad_norm": 0.150725319981575,
      "learning_rate": 8.846130704235038e-06,
      "loss": 0.0459,
      "step": 191600
    },
    {
      "epoch": 13.181599394897889,
      "grad_norm": 0.3372326195240021,
      "learning_rate": 8.824641779626781e-06,
      "loss": 0.0426,
      "step": 191700
    },
    {
      "epoch": 13.188475555249948,
      "grad_norm": 0.22772270441055298,
      "learning_rate": 8.803152855018523e-06,
      "loss": 0.0446,
      "step": 191800
    },
    {
      "epoch": 13.195351715602008,
      "grad_norm": 0.24767827987670898,
      "learning_rate": 8.781663930410266e-06,
      "loss": 0.0459,
      "step": 191900
    },
    {
      "epoch": 13.202227875954067,
      "grad_norm": 0.17626039683818817,
      "learning_rate": 8.76017500580201e-06,
      "loss": 0.0441,
      "step": 192000
    },
    {
      "epoch": 13.209104036306126,
      "grad_norm": 0.1824723333120346,
      "learning_rate": 8.738686081193753e-06,
      "loss": 0.0448,
      "step": 192100
    },
    {
      "epoch": 13.215980196658187,
      "grad_norm": 0.248967707157135,
      "learning_rate": 8.717197156585496e-06,
      "loss": 0.0469,
      "step": 192200
    },
    {
      "epoch": 13.222856357010246,
      "grad_norm": 0.22312268614768982,
      "learning_rate": 8.69570823197724e-06,
      "loss": 0.0452,
      "step": 192300
    },
    {
      "epoch": 13.229732517362304,
      "grad_norm": 0.1213938444852829,
      "learning_rate": 8.674219307368983e-06,
      "loss": 0.0472,
      "step": 192400
    },
    {
      "epoch": 13.236608677714365,
      "grad_norm": 0.2279626876115799,
      "learning_rate": 8.652730382760726e-06,
      "loss": 0.0455,
      "step": 192500
    },
    {
      "epoch": 13.243484838066424,
      "grad_norm": 0.1703433245420456,
      "learning_rate": 8.63124145815247e-06,
      "loss": 0.0449,
      "step": 192600
    },
    {
      "epoch": 13.250360998418483,
      "grad_norm": 0.1482653170824051,
      "learning_rate": 8.609752533544213e-06,
      "loss": 0.0443,
      "step": 192700
    },
    {
      "epoch": 13.257237158770543,
      "grad_norm": 0.20098209381103516,
      "learning_rate": 8.588263608935954e-06,
      "loss": 0.0477,
      "step": 192800
    },
    {
      "epoch": 13.264113319122602,
      "grad_norm": 0.17819851636886597,
      "learning_rate": 8.566774684327698e-06,
      "loss": 0.0435,
      "step": 192900
    },
    {
      "epoch": 13.270989479474661,
      "grad_norm": 0.10373924672603607,
      "learning_rate": 8.54528575971944e-06,
      "loss": 0.0465,
      "step": 193000
    },
    {
      "epoch": 13.277865639826722,
      "grad_norm": 0.13255615532398224,
      "learning_rate": 8.523796835111184e-06,
      "loss": 0.0427,
      "step": 193100
    },
    {
      "epoch": 13.28474180017878,
      "grad_norm": 0.24639566242694855,
      "learning_rate": 8.502307910502928e-06,
      "loss": 0.0445,
      "step": 193200
    },
    {
      "epoch": 13.29161796053084,
      "grad_norm": 0.10949728637933731,
      "learning_rate": 8.48081898589467e-06,
      "loss": 0.0452,
      "step": 193300
    },
    {
      "epoch": 13.298494120882898,
      "grad_norm": 0.15124011039733887,
      "learning_rate": 8.459330061286414e-06,
      "loss": 0.0486,
      "step": 193400
    },
    {
      "epoch": 13.305370281234959,
      "grad_norm": 0.21117177605628967,
      "learning_rate": 8.438056025924239e-06,
      "loss": 0.0426,
      "step": 193500
    },
    {
      "epoch": 13.312246441587018,
      "grad_norm": 0.16202059388160706,
      "learning_rate": 8.416781990562064e-06,
      "loss": 0.0435,
      "step": 193600
    },
    {
      "epoch": 13.319122601939076,
      "grad_norm": 0.18219305574893951,
      "learning_rate": 8.395293065953807e-06,
      "loss": 0.0434,
      "step": 193700
    },
    {
      "epoch": 13.325998762291137,
      "grad_norm": 0.23342350125312805,
      "learning_rate": 8.37380414134555e-06,
      "loss": 0.0436,
      "step": 193800
    },
    {
      "epoch": 13.332874922643196,
      "grad_norm": 0.18023069202899933,
      "learning_rate": 8.352315216737294e-06,
      "loss": 0.045,
      "step": 193900
    },
    {
      "epoch": 13.339751082995255,
      "grad_norm": 0.3149353861808777,
      "learning_rate": 8.330826292129037e-06,
      "loss": 0.0462,
      "step": 194000
    },
    {
      "epoch": 13.346627243347315,
      "grad_norm": 0.12534409761428833,
      "learning_rate": 8.30933736752078e-06,
      "loss": 0.0499,
      "step": 194100
    },
    {
      "epoch": 13.353503403699374,
      "grad_norm": 0.17412658035755157,
      "learning_rate": 8.287848442912522e-06,
      "loss": 0.0441,
      "step": 194200
    },
    {
      "epoch": 13.360379564051433,
      "grad_norm": 0.16739819943904877,
      "learning_rate": 8.266359518304265e-06,
      "loss": 0.047,
      "step": 194300
    },
    {
      "epoch": 13.367255724403494,
      "grad_norm": 0.2941853106021881,
      "learning_rate": 8.244870593696009e-06,
      "loss": 0.0428,
      "step": 194400
    },
    {
      "epoch": 13.374131884755553,
      "grad_norm": 0.323100209236145,
      "learning_rate": 8.223381669087752e-06,
      "loss": 0.0448,
      "step": 194500
    },
    {
      "epoch": 13.381008045107611,
      "grad_norm": 0.1605994701385498,
      "learning_rate": 8.201892744479495e-06,
      "loss": 0.0427,
      "step": 194600
    },
    {
      "epoch": 13.387884205459672,
      "grad_norm": 0.1414005607366562,
      "learning_rate": 8.180403819871239e-06,
      "loss": 0.0456,
      "step": 194700
    },
    {
      "epoch": 13.394760365811731,
      "grad_norm": 0.15769284963607788,
      "learning_rate": 8.158914895262982e-06,
      "loss": 0.0447,
      "step": 194800
    },
    {
      "epoch": 13.40163652616379,
      "grad_norm": 0.17605701088905334,
      "learning_rate": 8.137425970654725e-06,
      "loss": 0.0435,
      "step": 194900
    },
    {
      "epoch": 13.40851268651585,
      "grad_norm": 0.12379155308008194,
      "learning_rate": 8.115937046046469e-06,
      "loss": 0.0456,
      "step": 195000
    },
    {
      "epoch": 13.41538884686791,
      "grad_norm": 0.18219667673110962,
      "learning_rate": 8.094448121438212e-06,
      "loss": 0.0429,
      "step": 195100
    },
    {
      "epoch": 13.422265007219968,
      "grad_norm": 0.16384562849998474,
      "learning_rate": 8.072959196829955e-06,
      "loss": 0.0427,
      "step": 195200
    },
    {
      "epoch": 13.429141167572027,
      "grad_norm": 0.132401242852211,
      "learning_rate": 8.051470272221697e-06,
      "loss": 0.0453,
      "step": 195300
    },
    {
      "epoch": 13.436017327924088,
      "grad_norm": 0.16179731488227844,
      "learning_rate": 8.02998134761344e-06,
      "loss": 0.0443,
      "step": 195400
    },
    {
      "epoch": 13.442893488276146,
      "grad_norm": 0.21554207801818848,
      "learning_rate": 8.008492423005184e-06,
      "loss": 0.0443,
      "step": 195500
    },
    {
      "epoch": 13.449769648628205,
      "grad_norm": 0.1447729468345642,
      "learning_rate": 7.987003498396927e-06,
      "loss": 0.0445,
      "step": 195600
    },
    {
      "epoch": 13.456645808980266,
      "grad_norm": 0.15280982851982117,
      "learning_rate": 7.96551457378867e-06,
      "loss": 0.0406,
      "step": 195700
    },
    {
      "epoch": 13.463521969332325,
      "grad_norm": 0.23454371094703674,
      "learning_rate": 7.944025649180414e-06,
      "loss": 0.0433,
      "step": 195800
    },
    {
      "epoch": 13.470398129684384,
      "grad_norm": 0.16380463540554047,
      "learning_rate": 7.922536724572157e-06,
      "loss": 0.0434,
      "step": 195900
    },
    {
      "epoch": 13.477274290036444,
      "grad_norm": 0.15801604092121124,
      "learning_rate": 7.9010477999639e-06,
      "loss": 0.0446,
      "step": 196000
    },
    {
      "epoch": 13.484150450388503,
      "grad_norm": 0.23798710107803345,
      "learning_rate": 7.879558875355642e-06,
      "loss": 0.0467,
      "step": 196100
    },
    {
      "epoch": 13.491026610740562,
      "grad_norm": 0.1928601861000061,
      "learning_rate": 7.858069950747385e-06,
      "loss": 0.0448,
      "step": 196200
    },
    {
      "epoch": 13.497902771092622,
      "grad_norm": 0.16987036168575287,
      "learning_rate": 7.836581026139129e-06,
      "loss": 0.0413,
      "step": 196300
    },
    {
      "epoch": 13.504778931444681,
      "grad_norm": 0.1889842003583908,
      "learning_rate": 7.815092101530872e-06,
      "loss": 0.0438,
      "step": 196400
    },
    {
      "epoch": 13.51165509179674,
      "grad_norm": 0.24939927458763123,
      "learning_rate": 7.793603176922615e-06,
      "loss": 0.0437,
      "step": 196500
    },
    {
      "epoch": 13.5185312521488,
      "grad_norm": 0.3623114228248596,
      "learning_rate": 7.772114252314359e-06,
      "loss": 0.0442,
      "step": 196600
    },
    {
      "epoch": 13.52540741250086,
      "grad_norm": 0.14960023760795593,
      "learning_rate": 7.7506253277061e-06,
      "loss": 0.0457,
      "step": 196700
    },
    {
      "epoch": 13.532283572852918,
      "grad_norm": 0.18934735655784607,
      "learning_rate": 7.729136403097844e-06,
      "loss": 0.044,
      "step": 196800
    },
    {
      "epoch": 13.53915973320498,
      "grad_norm": 0.2563861012458801,
      "learning_rate": 7.707647478489587e-06,
      "loss": 0.0468,
      "step": 196900
    },
    {
      "epoch": 13.546035893557038,
      "grad_norm": 0.1618894338607788,
      "learning_rate": 7.68615855388133e-06,
      "loss": 0.0478,
      "step": 197000
    },
    {
      "epoch": 13.552912053909097,
      "grad_norm": 0.16147521138191223,
      "learning_rate": 7.664669629273074e-06,
      "loss": 0.0418,
      "step": 197100
    },
    {
      "epoch": 13.559788214261157,
      "grad_norm": 0.16510339081287384,
      "learning_rate": 7.643180704664817e-06,
      "loss": 0.0435,
      "step": 197200
    },
    {
      "epoch": 13.566664374613216,
      "grad_norm": 0.13312877714633942,
      "learning_rate": 7.62169178005656e-06,
      "loss": 0.0451,
      "step": 197300
    },
    {
      "epoch": 13.573540534965275,
      "grad_norm": 0.2270234227180481,
      "learning_rate": 7.600202855448302e-06,
      "loss": 0.041,
      "step": 197400
    },
    {
      "epoch": 13.580416695317334,
      "grad_norm": 0.16057917475700378,
      "learning_rate": 7.578713930840045e-06,
      "loss": 0.046,
      "step": 197500
    },
    {
      "epoch": 13.587292855669395,
      "grad_norm": 0.25324565172195435,
      "learning_rate": 7.557439895477871e-06,
      "loss": 0.0454,
      "step": 197600
    },
    {
      "epoch": 13.594169016021453,
      "grad_norm": 0.17075641453266144,
      "learning_rate": 7.535950970869614e-06,
      "loss": 0.0466,
      "step": 197700
    },
    {
      "epoch": 13.601045176373512,
      "grad_norm": 0.238014355301857,
      "learning_rate": 7.5144620462613575e-06,
      "loss": 0.0446,
      "step": 197800
    },
    {
      "epoch": 13.607921336725573,
      "grad_norm": 0.1453365981578827,
      "learning_rate": 7.492973121653101e-06,
      "loss": 0.0422,
      "step": 197900
    },
    {
      "epoch": 13.614797497077632,
      "grad_norm": 0.17118875682353973,
      "learning_rate": 7.471484197044844e-06,
      "loss": 0.0415,
      "step": 198000
    },
    {
      "epoch": 13.62167365742969,
      "grad_norm": 0.15016870200634003,
      "learning_rate": 7.450210161682669e-06,
      "loss": 0.046,
      "step": 198100
    },
    {
      "epoch": 13.628549817781751,
      "grad_norm": 0.1848401129245758,
      "learning_rate": 7.428721237074412e-06,
      "loss": 0.0445,
      "step": 198200
    },
    {
      "epoch": 13.63542597813381,
      "grad_norm": 0.1306324005126953,
      "learning_rate": 7.407232312466156e-06,
      "loss": 0.0449,
      "step": 198300
    },
    {
      "epoch": 13.642302138485869,
      "grad_norm": 0.2552071511745453,
      "learning_rate": 7.385743387857898e-06,
      "loss": 0.0463,
      "step": 198400
    },
    {
      "epoch": 13.64917829883793,
      "grad_norm": 0.19657574594020844,
      "learning_rate": 7.364254463249641e-06,
      "loss": 0.0452,
      "step": 198500
    },
    {
      "epoch": 13.656054459189988,
      "grad_norm": 0.14694805443286896,
      "learning_rate": 7.342765538641385e-06,
      "loss": 0.0415,
      "step": 198600
    },
    {
      "epoch": 13.662930619542047,
      "grad_norm": 0.14119340479373932,
      "learning_rate": 7.321276614033127e-06,
      "loss": 0.046,
      "step": 198700
    },
    {
      "epoch": 13.669806779894108,
      "grad_norm": 0.20963728427886963,
      "learning_rate": 7.2997876894248706e-06,
      "loss": 0.044,
      "step": 198800
    },
    {
      "epoch": 13.676682940246167,
      "grad_norm": 0.15387876331806183,
      "learning_rate": 7.278298764816614e-06,
      "loss": 0.047,
      "step": 198900
    },
    {
      "epoch": 13.683559100598226,
      "grad_norm": 0.1737183928489685,
      "learning_rate": 7.256809840208357e-06,
      "loss": 0.0463,
      "step": 199000
    },
    {
      "epoch": 13.690435260950286,
      "grad_norm": 0.17447629570960999,
      "learning_rate": 7.2353209156001e-06,
      "loss": 0.0451,
      "step": 199100
    },
    {
      "epoch": 13.697311421302345,
      "grad_norm": 0.23616844415664673,
      "learning_rate": 7.213831990991843e-06,
      "loss": 0.0456,
      "step": 199200
    },
    {
      "epoch": 13.704187581654404,
      "grad_norm": 0.169200599193573,
      "learning_rate": 7.192343066383586e-06,
      "loss": 0.0441,
      "step": 199300
    },
    {
      "epoch": 13.711063742006463,
      "grad_norm": 0.17116029560565948,
      "learning_rate": 7.17085414177533e-06,
      "loss": 0.0453,
      "step": 199400
    },
    {
      "epoch": 13.717939902358523,
      "grad_norm": 0.1594490110874176,
      "learning_rate": 7.149365217167073e-06,
      "loss": 0.0439,
      "step": 199500
    },
    {
      "epoch": 13.724816062710582,
      "grad_norm": 0.21564464271068573,
      "learning_rate": 7.127876292558816e-06,
      "loss": 0.0442,
      "step": 199600
    },
    {
      "epoch": 13.731692223062641,
      "grad_norm": 0.19860784709453583,
      "learning_rate": 7.106387367950558e-06,
      "loss": 0.0452,
      "step": 199700
    },
    {
      "epoch": 13.738568383414702,
      "grad_norm": 0.17459867894649506,
      "learning_rate": 7.084898443342301e-06,
      "loss": 0.044,
      "step": 199800
    },
    {
      "epoch": 13.74544454376676,
      "grad_norm": 0.13141365349292755,
      "learning_rate": 7.063409518734045e-06,
      "loss": 0.0453,
      "step": 199900
    },
    {
      "epoch": 13.75232070411882,
      "grad_norm": 0.2113860845565796,
      "learning_rate": 7.041920594125788e-06,
      "loss": 0.0458,
      "step": 200000
    },
    {
      "epoch": 13.75919686447088,
      "grad_norm": 0.17688974738121033,
      "learning_rate": 7.020431669517531e-06,
      "loss": 0.044,
      "step": 200100
    },
    {
      "epoch": 13.766073024822939,
      "grad_norm": 0.1556338369846344,
      "learning_rate": 6.998942744909275e-06,
      "loss": 0.0466,
      "step": 200200
    },
    {
      "epoch": 13.772949185174998,
      "grad_norm": 0.42239463329315186,
      "learning_rate": 6.977453820301018e-06,
      "loss": 0.0442,
      "step": 200300
    },
    {
      "epoch": 13.779825345527058,
      "grad_norm": 0.21951662003993988,
      "learning_rate": 6.95596489569276e-06,
      "loss": 0.0452,
      "step": 200400
    },
    {
      "epoch": 13.786701505879117,
      "grad_norm": 0.22571472823619843,
      "learning_rate": 6.934475971084503e-06,
      "loss": 0.0446,
      "step": 200500
    },
    {
      "epoch": 13.793577666231176,
      "grad_norm": 0.20626986026763916,
      "learning_rate": 6.913201935722329e-06,
      "loss": 0.0444,
      "step": 200600
    },
    {
      "epoch": 13.800453826583237,
      "grad_norm": 0.19496354460716248,
      "learning_rate": 6.891713011114072e-06,
      "loss": 0.043,
      "step": 200700
    },
    {
      "epoch": 13.807329986935295,
      "grad_norm": 0.17384004592895508,
      "learning_rate": 6.870224086505815e-06,
      "loss": 0.0445,
      "step": 200800
    },
    {
      "epoch": 13.814206147287354,
      "grad_norm": 0.20439839363098145,
      "learning_rate": 6.848735161897559e-06,
      "loss": 0.0458,
      "step": 200900
    },
    {
      "epoch": 13.821082307639415,
      "grad_norm": 0.24867822229862213,
      "learning_rate": 6.827246237289302e-06,
      "loss": 0.0464,
      "step": 201000
    },
    {
      "epoch": 13.827958467991474,
      "grad_norm": 0.2921684980392456,
      "learning_rate": 6.805757312681045e-06,
      "loss": 0.0493,
      "step": 201100
    },
    {
      "epoch": 13.834834628343533,
      "grad_norm": 0.1681942492723465,
      "learning_rate": 6.784268388072787e-06,
      "loss": 0.0446,
      "step": 201200
    },
    {
      "epoch": 13.841710788695593,
      "grad_norm": 0.44051608443260193,
      "learning_rate": 6.76277946346453e-06,
      "loss": 0.0455,
      "step": 201300
    },
    {
      "epoch": 13.848586949047652,
      "grad_norm": 0.2373405396938324,
      "learning_rate": 6.7412905388562736e-06,
      "loss": 0.0444,
      "step": 201400
    },
    {
      "epoch": 13.855463109399711,
      "grad_norm": 0.15104492008686066,
      "learning_rate": 6.719801614248017e-06,
      "loss": 0.0445,
      "step": 201500
    },
    {
      "epoch": 13.862339269751772,
      "grad_norm": 0.16823188960552216,
      "learning_rate": 6.69831268963976e-06,
      "loss": 0.0471,
      "step": 201600
    },
    {
      "epoch": 13.86921543010383,
      "grad_norm": 0.1875590980052948,
      "learning_rate": 6.676823765031504e-06,
      "loss": 0.0411,
      "step": 201700
    },
    {
      "epoch": 13.87609159045589,
      "grad_norm": 0.17284013330936432,
      "learning_rate": 6.655334840423247e-06,
      "loss": 0.0449,
      "step": 201800
    },
    {
      "epoch": 13.882967750807948,
      "grad_norm": 0.13469292223453522,
      "learning_rate": 6.6338459158149886e-06,
      "loss": 0.0431,
      "step": 201900
    },
    {
      "epoch": 13.889843911160009,
      "grad_norm": 0.14123082160949707,
      "learning_rate": 6.612356991206732e-06,
      "loss": 0.0454,
      "step": 202000
    },
    {
      "epoch": 13.896720071512068,
      "grad_norm": 0.1556342989206314,
      "learning_rate": 6.590868066598475e-06,
      "loss": 0.0449,
      "step": 202100
    },
    {
      "epoch": 13.903596231864126,
      "grad_norm": 0.31539252400398254,
      "learning_rate": 6.5693791419902186e-06,
      "loss": 0.0411,
      "step": 202200
    },
    {
      "epoch": 13.910472392216187,
      "grad_norm": 0.1691022366285324,
      "learning_rate": 6.547890217381962e-06,
      "loss": 0.0449,
      "step": 202300
    },
    {
      "epoch": 13.917348552568246,
      "grad_norm": 0.10182575136423111,
      "learning_rate": 6.526401292773705e-06,
      "loss": 0.0434,
      "step": 202400
    },
    {
      "epoch": 13.924224712920305,
      "grad_norm": 0.22279083728790283,
      "learning_rate": 6.504912368165447e-06,
      "loss": 0.0446,
      "step": 202500
    },
    {
      "epoch": 13.931100873272365,
      "grad_norm": 0.18358303606510162,
      "learning_rate": 6.48342344355719e-06,
      "loss": 0.0457,
      "step": 202600
    },
    {
      "epoch": 13.937977033624424,
      "grad_norm": 0.24578078091144562,
      "learning_rate": 6.4619345189489335e-06,
      "loss": 0.0466,
      "step": 202700
    },
    {
      "epoch": 13.944853193976483,
      "grad_norm": 0.23313090205192566,
      "learning_rate": 6.440445594340677e-06,
      "loss": 0.0484,
      "step": 202800
    },
    {
      "epoch": 13.951729354328544,
      "grad_norm": 0.13480955362319946,
      "learning_rate": 6.4191715589785025e-06,
      "loss": 0.0436,
      "step": 202900
    },
    {
      "epoch": 13.958605514680603,
      "grad_norm": 0.1064545139670372,
      "learning_rate": 6.397682634370246e-06,
      "loss": 0.0422,
      "step": 203000
    },
    {
      "epoch": 13.965481675032661,
      "grad_norm": 0.07725538313388824,
      "learning_rate": 6.376193709761989e-06,
      "loss": 0.0422,
      "step": 203100
    },
    {
      "epoch": 13.972357835384722,
      "grad_norm": 0.14778897166252136,
      "learning_rate": 6.3547047851537325e-06,
      "loss": 0.0441,
      "step": 203200
    },
    {
      "epoch": 13.97923399573678,
      "grad_norm": 0.14985668659210205,
      "learning_rate": 6.333215860545476e-06,
      "loss": 0.0444,
      "step": 203300
    },
    {
      "epoch": 13.98611015608884,
      "grad_norm": 0.32110095024108887,
      "learning_rate": 6.3117269359372174e-06,
      "loss": 0.0452,
      "step": 203400
    },
    {
      "epoch": 13.992986316440899,
      "grad_norm": 0.2103051096200943,
      "learning_rate": 6.290238011328961e-06,
      "loss": 0.0473,
      "step": 203500
    },
    {
      "epoch": 13.99986247679296,
      "grad_norm": 0.19438667595386505,
      "learning_rate": 6.268749086720704e-06,
      "loss": 0.046,
      "step": 203600
    },
    {
      "epoch": 14.0,
      "eval_accuracy_macro_0.5": 0.9800384640693665,
      "eval_accuracy_micro_0.5": 0.9800384044647217,
      "eval_accuracy_weighted_0.5": 0.9775137901306152,
      "eval_f1_macro_0.5": 0.7266847491264343,
      "eval_f1_macro_0.6": 0.7041913270950317,
      "eval_f1_macro_0.7": 0.6657440662384033,
      "eval_f1_macro_0.8": 0.4791948199272156,
      "eval_f1_micro_0.5": 0.7313207983970642,
      "eval_f1_micro_0.6": 0.7130692601203918,
      "eval_f1_micro_0.7": 0.6796331405639648,
      "eval_f1_micro_0.8": 0.621276319026947,
      "eval_f1_micro_0.9": 0.5048428177833557,
      "eval_f1_weighted_0.5": 0.7234901189804077,
      "eval_f1_weighted_0.6": 0.6992877721786499,
      "eval_f1_weighted_0.7": 0.6586916446685791,
      "eval_f1_weighted_0.8": 0.4638921320438385,
      "eval_loss": 0.04165427386760712,
      "eval_runtime": 63.622,
      "eval_samples_per_second": 456.399,
      "eval_steps_per_second": 57.056,
      "step": 203602
    },
    {
      "epoch": 14.006738637145018,
      "grad_norm": 0.13480521738529205,
      "learning_rate": 6.2472601621124474e-06,
      "loss": 0.0442,
      "step": 203700
    },
    {
      "epoch": 14.013614797497077,
      "grad_norm": 0.25024116039276123,
      "learning_rate": 6.22577123750419e-06,
      "loss": 0.0428,
      "step": 203800
    },
    {
      "epoch": 14.020490957849137,
      "grad_norm": 0.2276294082403183,
      "learning_rate": 6.204282312895933e-06,
      "loss": 0.0434,
      "step": 203900
    },
    {
      "epoch": 14.027367118201196,
      "grad_norm": 0.15108105540275574,
      "learning_rate": 6.182793388287677e-06,
      "loss": 0.0455,
      "step": 204000
    },
    {
      "epoch": 14.034243278553255,
      "grad_norm": 0.24623888731002808,
      "learning_rate": 6.16130446367942e-06,
      "loss": 0.0421,
      "step": 204100
    },
    {
      "epoch": 14.041119438905316,
      "grad_norm": 0.17445866763591766,
      "learning_rate": 6.139815539071163e-06,
      "loss": 0.0448,
      "step": 204200
    },
    {
      "epoch": 14.047995599257375,
      "grad_norm": 0.18287579715251923,
      "learning_rate": 6.118326614462906e-06,
      "loss": 0.043,
      "step": 204300
    },
    {
      "epoch": 14.054871759609433,
      "grad_norm": 0.19438134133815765,
      "learning_rate": 6.096837689854649e-06,
      "loss": 0.042,
      "step": 204400
    },
    {
      "epoch": 14.061747919961494,
      "grad_norm": 0.20032157003879547,
      "learning_rate": 6.075348765246392e-06,
      "loss": 0.0446,
      "step": 204500
    },
    {
      "epoch": 14.068624080313553,
      "grad_norm": 0.19865311682224274,
      "learning_rate": 6.053859840638136e-06,
      "loss": 0.047,
      "step": 204600
    },
    {
      "epoch": 14.075500240665612,
      "grad_norm": 0.16021862626075745,
      "learning_rate": 6.032370916029879e-06,
      "loss": 0.0423,
      "step": 204700
    },
    {
      "epoch": 14.082376401017672,
      "grad_norm": 0.16591762006282806,
      "learning_rate": 6.0108819914216216e-06,
      "loss": 0.0465,
      "step": 204800
    },
    {
      "epoch": 14.089252561369731,
      "grad_norm": 0.09829744696617126,
      "learning_rate": 5.989393066813365e-06,
      "loss": 0.0432,
      "step": 204900
    },
    {
      "epoch": 14.09612872172179,
      "grad_norm": 0.2385939061641693,
      "learning_rate": 5.967904142205108e-06,
      "loss": 0.0406,
      "step": 205000
    },
    {
      "epoch": 14.10300488207385,
      "grad_norm": 0.13003495335578918,
      "learning_rate": 5.946415217596851e-06,
      "loss": 0.0457,
      "step": 205100
    },
    {
      "epoch": 14.10988104242591,
      "grad_norm": 0.131035715341568,
      "learning_rate": 5.925141182234676e-06,
      "loss": 0.046,
      "step": 205200
    },
    {
      "epoch": 14.116757202777968,
      "grad_norm": 0.17251142859458923,
      "learning_rate": 5.90365225762642e-06,
      "loss": 0.0436,
      "step": 205300
    },
    {
      "epoch": 14.123633363130029,
      "grad_norm": 0.21444769203662872,
      "learning_rate": 5.882163333018163e-06,
      "loss": 0.0422,
      "step": 205400
    },
    {
      "epoch": 14.130509523482088,
      "grad_norm": 0.12142866849899292,
      "learning_rate": 5.860674408409906e-06,
      "loss": 0.0443,
      "step": 205500
    },
    {
      "epoch": 14.137385683834147,
      "grad_norm": 0.18600474298000336,
      "learning_rate": 5.839185483801649e-06,
      "loss": 0.0414,
      "step": 205600
    },
    {
      "epoch": 14.144261844186206,
      "grad_norm": 0.2024976909160614,
      "learning_rate": 5.817696559193392e-06,
      "loss": 0.0445,
      "step": 205700
    },
    {
      "epoch": 14.151138004538266,
      "grad_norm": 0.12372783571481705,
      "learning_rate": 5.7962076345851355e-06,
      "loss": 0.0471,
      "step": 205800
    },
    {
      "epoch": 14.158014164890325,
      "grad_norm": 0.14138619601726532,
      "learning_rate": 5.774718709976879e-06,
      "loss": 0.0422,
      "step": 205900
    },
    {
      "epoch": 14.164890325242384,
      "grad_norm": 0.1343005895614624,
      "learning_rate": 5.753229785368621e-06,
      "loss": 0.0433,
      "step": 206000
    },
    {
      "epoch": 14.171766485594445,
      "grad_norm": 0.08621934056282043,
      "learning_rate": 5.731740860760365e-06,
      "loss": 0.0441,
      "step": 206100
    },
    {
      "epoch": 14.178642645946503,
      "grad_norm": 0.2512645721435547,
      "learning_rate": 5.710251936152108e-06,
      "loss": 0.0427,
      "step": 206200
    },
    {
      "epoch": 14.185518806298562,
      "grad_norm": 0.05779767408967018,
      "learning_rate": 5.6887630115438505e-06,
      "loss": 0.0433,
      "step": 206300
    },
    {
      "epoch": 14.192394966650623,
      "grad_norm": 0.17585347592830658,
      "learning_rate": 5.667274086935594e-06,
      "loss": 0.0413,
      "step": 206400
    },
    {
      "epoch": 14.199271127002682,
      "grad_norm": 0.17963184416294098,
      "learning_rate": 5.645785162327337e-06,
      "loss": 0.0417,
      "step": 206500
    },
    {
      "epoch": 14.20614728735474,
      "grad_norm": 0.07305549085140228,
      "learning_rate": 5.62429623771908e-06,
      "loss": 0.0438,
      "step": 206600
    },
    {
      "epoch": 14.213023447706801,
      "grad_norm": 0.18282169103622437,
      "learning_rate": 5.602807313110823e-06,
      "loss": 0.0423,
      "step": 206700
    },
    {
      "epoch": 14.21989960805886,
      "grad_norm": 0.1798965483903885,
      "learning_rate": 5.581318388502566e-06,
      "loss": 0.0464,
      "step": 206800
    },
    {
      "epoch": 14.226775768410919,
      "grad_norm": 0.09987599402666092,
      "learning_rate": 5.559829463894309e-06,
      "loss": 0.0436,
      "step": 206900
    },
    {
      "epoch": 14.23365192876298,
      "grad_norm": 0.1358558088541031,
      "learning_rate": 5.538340539286052e-06,
      "loss": 0.0453,
      "step": 207000
    },
    {
      "epoch": 14.240528089115038,
      "grad_norm": 0.20815259218215942,
      "learning_rate": 5.5168516146777954e-06,
      "loss": 0.0424,
      "step": 207100
    },
    {
      "epoch": 14.247404249467097,
      "grad_norm": 0.13636016845703125,
      "learning_rate": 5.495362690069539e-06,
      "loss": 0.0459,
      "step": 207200
    },
    {
      "epoch": 14.254280409819158,
      "grad_norm": 0.15999405086040497,
      "learning_rate": 5.473873765461281e-06,
      "loss": 0.0461,
      "step": 207300
    },
    {
      "epoch": 14.261156570171217,
      "grad_norm": 0.2570340037345886,
      "learning_rate": 5.452384840853025e-06,
      "loss": 0.0481,
      "step": 207400
    },
    {
      "epoch": 14.268032730523275,
      "grad_norm": 0.15706264972686768,
      "learning_rate": 5.43111080549085e-06,
      "loss": 0.0451,
      "step": 207500
    },
    {
      "epoch": 14.274908890875334,
      "grad_norm": 0.26553967595100403,
      "learning_rate": 5.4096218808825935e-06,
      "loss": 0.046,
      "step": 207600
    },
    {
      "epoch": 14.281785051227395,
      "grad_norm": 0.26575034856796265,
      "learning_rate": 5.388132956274337e-06,
      "loss": 0.0417,
      "step": 207700
    },
    {
      "epoch": 14.288661211579454,
      "grad_norm": 0.24414972960948944,
      "learning_rate": 5.366644031666079e-06,
      "loss": 0.0457,
      "step": 207800
    },
    {
      "epoch": 14.295537371931513,
      "grad_norm": 0.14393261075019836,
      "learning_rate": 5.345155107057823e-06,
      "loss": 0.0435,
      "step": 207900
    },
    {
      "epoch": 14.302413532283573,
      "grad_norm": 0.1857054978609085,
      "learning_rate": 5.323666182449566e-06,
      "loss": 0.0434,
      "step": 208000
    },
    {
      "epoch": 14.309289692635632,
      "grad_norm": 0.15553118288516998,
      "learning_rate": 5.3021772578413085e-06,
      "loss": 0.0441,
      "step": 208100
    },
    {
      "epoch": 14.316165852987691,
      "grad_norm": 0.11631409078836441,
      "learning_rate": 5.280688333233052e-06,
      "loss": 0.0454,
      "step": 208200
    },
    {
      "epoch": 14.323042013339752,
      "grad_norm": 0.19493652880191803,
      "learning_rate": 5.259199408624795e-06,
      "loss": 0.0436,
      "step": 208300
    },
    {
      "epoch": 14.32991817369181,
      "grad_norm": 0.2706919014453888,
      "learning_rate": 5.237710484016538e-06,
      "loss": 0.0428,
      "step": 208400
    },
    {
      "epoch": 14.33679433404387,
      "grad_norm": 0.12116141617298126,
      "learning_rate": 5.216221559408281e-06,
      "loss": 0.0458,
      "step": 208500
    },
    {
      "epoch": 14.34367049439593,
      "grad_norm": 0.1837565004825592,
      "learning_rate": 5.194732634800024e-06,
      "loss": 0.047,
      "step": 208600
    },
    {
      "epoch": 14.350546654747989,
      "grad_norm": 0.13107313215732574,
      "learning_rate": 5.173243710191768e-06,
      "loss": 0.0443,
      "step": 208700
    },
    {
      "epoch": 14.357422815100048,
      "grad_norm": 0.24341876804828644,
      "learning_rate": 5.15175478558351e-06,
      "loss": 0.0436,
      "step": 208800
    },
    {
      "epoch": 14.364298975452108,
      "grad_norm": 0.16020935773849487,
      "learning_rate": 5.1302658609752535e-06,
      "loss": 0.0451,
      "step": 208900
    },
    {
      "epoch": 14.371175135804167,
      "grad_norm": 0.16240482032299042,
      "learning_rate": 5.108776936366997e-06,
      "loss": 0.0468,
      "step": 209000
    },
    {
      "epoch": 14.378051296156226,
      "grad_norm": 0.319281667470932,
      "learning_rate": 5.087288011758739e-06,
      "loss": 0.0438,
      "step": 209100
    },
    {
      "epoch": 14.384927456508287,
      "grad_norm": 0.19022035598754883,
      "learning_rate": 5.065799087150483e-06,
      "loss": 0.0429,
      "step": 209200
    },
    {
      "epoch": 14.391803616860345,
      "grad_norm": 0.20120736956596375,
      "learning_rate": 5.044310162542226e-06,
      "loss": 0.0424,
      "step": 209300
    },
    {
      "epoch": 14.398679777212404,
      "grad_norm": 0.2555646598339081,
      "learning_rate": 5.0228212379339685e-06,
      "loss": 0.0483,
      "step": 209400
    },
    {
      "epoch": 14.405555937564465,
      "grad_norm": 0.25240129232406616,
      "learning_rate": 5.001332313325712e-06,
      "loss": 0.0433,
      "step": 209500
    },
    {
      "epoch": 14.412432097916524,
      "grad_norm": 0.14262759685516357,
      "learning_rate": 4.979843388717455e-06,
      "loss": 0.0448,
      "step": 209600
    },
    {
      "epoch": 14.419308258268583,
      "grad_norm": 0.15311133861541748,
      "learning_rate": 4.9583544641091985e-06,
      "loss": 0.0464,
      "step": 209700
    },
    {
      "epoch": 14.426184418620641,
      "grad_norm": 0.16898871958255768,
      "learning_rate": 4.936865539500942e-06,
      "loss": 0.0452,
      "step": 209800
    },
    {
      "epoch": 14.433060578972702,
      "grad_norm": 0.13740108907222748,
      "learning_rate": 4.915376614892684e-06,
      "loss": 0.047,
      "step": 209900
    },
    {
      "epoch": 14.43993673932476,
      "grad_norm": 0.13273553550243378,
      "learning_rate": 4.893887690284428e-06,
      "loss": 0.0436,
      "step": 210000
    },
    {
      "epoch": 14.44681289967682,
      "grad_norm": 0.193307563662529,
      "learning_rate": 4.872398765676171e-06,
      "loss": 0.0424,
      "step": 210100
    },
    {
      "epoch": 14.45368906002888,
      "grad_norm": 0.21068142354488373,
      "learning_rate": 4.850909841067914e-06,
      "loss": 0.0425,
      "step": 210200
    },
    {
      "epoch": 14.46056522038094,
      "grad_norm": 0.2312011569738388,
      "learning_rate": 4.829420916459658e-06,
      "loss": 0.0442,
      "step": 210300
    },
    {
      "epoch": 14.467441380732998,
      "grad_norm": 0.10028912127017975,
      "learning_rate": 4.8079319918514e-06,
      "loss": 0.0458,
      "step": 210400
    },
    {
      "epoch": 14.474317541085059,
      "grad_norm": 0.15031825006008148,
      "learning_rate": 4.7864430672431434e-06,
      "loss": 0.0454,
      "step": 210500
    },
    {
      "epoch": 14.481193701437117,
      "grad_norm": 0.1316668540239334,
      "learning_rate": 4.765169031880968e-06,
      "loss": 0.0435,
      "step": 210600
    },
    {
      "epoch": 14.488069861789176,
      "grad_norm": 0.14531195163726807,
      "learning_rate": 4.7436801072727115e-06,
      "loss": 0.0434,
      "step": 210700
    },
    {
      "epoch": 14.494946022141237,
      "grad_norm": 0.20081867277622223,
      "learning_rate": 4.722191182664455e-06,
      "loss": 0.0445,
      "step": 210800
    },
    {
      "epoch": 14.501822182493296,
      "grad_norm": 0.17191269993782043,
      "learning_rate": 4.700702258056198e-06,
      "loss": 0.0461,
      "step": 210900
    },
    {
      "epoch": 14.508698342845355,
      "grad_norm": 0.1908278465270996,
      "learning_rate": 4.6792133334479415e-06,
      "loss": 0.0415,
      "step": 211000
    },
    {
      "epoch": 14.515574503197415,
      "grad_norm": 0.11271799355745316,
      "learning_rate": 4.657724408839685e-06,
      "loss": 0.0434,
      "step": 211100
    },
    {
      "epoch": 14.522450663549474,
      "grad_norm": 0.22383958101272583,
      "learning_rate": 4.636235484231427e-06,
      "loss": 0.0472,
      "step": 211200
    },
    {
      "epoch": 14.529326823901533,
      "grad_norm": 0.2347555160522461,
      "learning_rate": 4.614746559623171e-06,
      "loss": 0.045,
      "step": 211300
    },
    {
      "epoch": 14.536202984253594,
      "grad_norm": 0.11922606080770493,
      "learning_rate": 4.593257635014914e-06,
      "loss": 0.0437,
      "step": 211400
    },
    {
      "epoch": 14.543079144605652,
      "grad_norm": 0.1706503927707672,
      "learning_rate": 4.5717687104066565e-06,
      "loss": 0.0441,
      "step": 211500
    },
    {
      "epoch": 14.549955304957711,
      "grad_norm": 0.26564353704452515,
      "learning_rate": 4.5502797857984e-06,
      "loss": 0.0433,
      "step": 211600
    },
    {
      "epoch": 14.55683146530977,
      "grad_norm": 0.22216135263442993,
      "learning_rate": 4.528790861190143e-06,
      "loss": 0.0463,
      "step": 211700
    },
    {
      "epoch": 14.56370762566183,
      "grad_norm": 0.1311931312084198,
      "learning_rate": 4.5073019365818865e-06,
      "loss": 0.0423,
      "step": 211800
    },
    {
      "epoch": 14.57058378601389,
      "grad_norm": 0.13937629759311676,
      "learning_rate": 4.485813011973629e-06,
      "loss": 0.0417,
      "step": 211900
    },
    {
      "epoch": 14.577459946365948,
      "grad_norm": 0.2735096514225006,
      "learning_rate": 4.464324087365372e-06,
      "loss": 0.0475,
      "step": 212000
    },
    {
      "epoch": 14.584336106718009,
      "grad_norm": 0.13844043016433716,
      "learning_rate": 4.442835162757116e-06,
      "loss": 0.0471,
      "step": 212100
    },
    {
      "epoch": 14.591212267070068,
      "grad_norm": 0.07431715726852417,
      "learning_rate": 4.421346238148858e-06,
      "loss": 0.0441,
      "step": 212200
    },
    {
      "epoch": 14.598088427422127,
      "grad_norm": 0.14793923497200012,
      "learning_rate": 4.3998573135406015e-06,
      "loss": 0.0445,
      "step": 212300
    },
    {
      "epoch": 14.604964587774187,
      "grad_norm": 0.10415954142808914,
      "learning_rate": 4.378368388932345e-06,
      "loss": 0.0455,
      "step": 212400
    },
    {
      "epoch": 14.611840748126246,
      "grad_norm": 0.39825525879859924,
      "learning_rate": 4.356879464324087e-06,
      "loss": 0.0468,
      "step": 212500
    },
    {
      "epoch": 14.618716908478305,
      "grad_norm": 0.23948559165000916,
      "learning_rate": 4.335605428961914e-06,
      "loss": 0.043,
      "step": 212600
    },
    {
      "epoch": 14.625593068830366,
      "grad_norm": 0.14406250417232513,
      "learning_rate": 4.314116504353656e-06,
      "loss": 0.0442,
      "step": 212700
    },
    {
      "epoch": 14.632469229182425,
      "grad_norm": 0.17272759974002838,
      "learning_rate": 4.2926275797453996e-06,
      "loss": 0.0462,
      "step": 212800
    },
    {
      "epoch": 14.639345389534483,
      "grad_norm": 0.18534737825393677,
      "learning_rate": 4.271138655137143e-06,
      "loss": 0.0443,
      "step": 212900
    },
    {
      "epoch": 14.646221549886544,
      "grad_norm": 0.12233307957649231,
      "learning_rate": 4.249649730528885e-06,
      "loss": 0.0433,
      "step": 213000
    },
    {
      "epoch": 14.653097710238603,
      "grad_norm": 0.1956137865781784,
      "learning_rate": 4.228160805920629e-06,
      "loss": 0.0447,
      "step": 213100
    },
    {
      "epoch": 14.659973870590662,
      "grad_norm": 0.13730308413505554,
      "learning_rate": 4.206671881312372e-06,
      "loss": 0.0433,
      "step": 213200
    },
    {
      "epoch": 14.666850030942722,
      "grad_norm": 0.16181796789169312,
      "learning_rate": 4.185182956704115e-06,
      "loss": 0.0437,
      "step": 213300
    },
    {
      "epoch": 14.673726191294781,
      "grad_norm": 0.13234592974185944,
      "learning_rate": 4.163694032095858e-06,
      "loss": 0.0417,
      "step": 213400
    },
    {
      "epoch": 14.68060235164684,
      "grad_norm": 0.271968811750412,
      "learning_rate": 4.142205107487601e-06,
      "loss": 0.0458,
      "step": 213500
    },
    {
      "epoch": 14.6874785119989,
      "grad_norm": 0.22838985919952393,
      "learning_rate": 4.1207161828793445e-06,
      "loss": 0.0445,
      "step": 213600
    },
    {
      "epoch": 14.69435467235096,
      "grad_norm": 0.1329660713672638,
      "learning_rate": 4.099227258271087e-06,
      "loss": 0.0452,
      "step": 213700
    },
    {
      "epoch": 14.701230832703018,
      "grad_norm": 0.14952252805233002,
      "learning_rate": 4.07773833366283e-06,
      "loss": 0.0448,
      "step": 213800
    },
    {
      "epoch": 14.708106993055079,
      "grad_norm": 0.1675216406583786,
      "learning_rate": 4.056249409054574e-06,
      "loss": 0.0453,
      "step": 213900
    },
    {
      "epoch": 14.714983153407138,
      "grad_norm": 0.20906347036361694,
      "learning_rate": 4.034760484446316e-06,
      "loss": 0.0424,
      "step": 214000
    },
    {
      "epoch": 14.721859313759197,
      "grad_norm": 0.20464706420898438,
      "learning_rate": 4.0132715598380595e-06,
      "loss": 0.0448,
      "step": 214100
    },
    {
      "epoch": 14.728735474111255,
      "grad_norm": 0.22932954132556915,
      "learning_rate": 3.991782635229803e-06,
      "loss": 0.0432,
      "step": 214200
    },
    {
      "epoch": 14.735611634463316,
      "grad_norm": 0.17213264107704163,
      "learning_rate": 3.970293710621545e-06,
      "loss": 0.0453,
      "step": 214300
    },
    {
      "epoch": 14.742487794815375,
      "grad_norm": 0.1317916214466095,
      "learning_rate": 3.948804786013289e-06,
      "loss": 0.0427,
      "step": 214400
    },
    {
      "epoch": 14.749363955167434,
      "grad_norm": 0.14461959898471832,
      "learning_rate": 3.927315861405032e-06,
      "loss": 0.046,
      "step": 214500
    },
    {
      "epoch": 14.756240115519494,
      "grad_norm": 0.31811457872390747,
      "learning_rate": 3.9058269367967745e-06,
      "loss": 0.0425,
      "step": 214600
    },
    {
      "epoch": 14.763116275871553,
      "grad_norm": 0.14192411303520203,
      "learning_rate": 3.884338012188518e-06,
      "loss": 0.0448,
      "step": 214700
    },
    {
      "epoch": 14.769992436223612,
      "grad_norm": 0.22187724709510803,
      "learning_rate": 3.862849087580261e-06,
      "loss": 0.0454,
      "step": 214800
    },
    {
      "epoch": 14.776868596575673,
      "grad_norm": 0.21461543440818787,
      "learning_rate": 3.8413601629720045e-06,
      "loss": 0.0415,
      "step": 214900
    },
    {
      "epoch": 14.783744756927732,
      "grad_norm": 0.193547323346138,
      "learning_rate": 3.82008612760983e-06,
      "loss": 0.0462,
      "step": 215000
    },
    {
      "epoch": 14.79062091727979,
      "grad_norm": 0.1447940170764923,
      "learning_rate": 3.7985972030015734e-06,
      "loss": 0.0457,
      "step": 215100
    },
    {
      "epoch": 14.797497077631851,
      "grad_norm": 0.1338200569152832,
      "learning_rate": 3.777108278393316e-06,
      "loss": 0.044,
      "step": 215200
    },
    {
      "epoch": 14.80437323798391,
      "grad_norm": 0.11463595926761627,
      "learning_rate": 3.7556193537850592e-06,
      "loss": 0.0471,
      "step": 215300
    },
    {
      "epoch": 14.811249398335969,
      "grad_norm": 0.15132096409797668,
      "learning_rate": 3.7341304291768026e-06,
      "loss": 0.0447,
      "step": 215400
    },
    {
      "epoch": 14.81812555868803,
      "grad_norm": 0.13880126178264618,
      "learning_rate": 3.7126415045685455e-06,
      "loss": 0.0463,
      "step": 215500
    },
    {
      "epoch": 14.825001719040088,
      "grad_norm": 0.19471004605293274,
      "learning_rate": 3.691152579960289e-06,
      "loss": 0.045,
      "step": 215600
    },
    {
      "epoch": 14.831877879392147,
      "grad_norm": 0.30811747908592224,
      "learning_rate": 3.6696636553520317e-06,
      "loss": 0.0432,
      "step": 215700
    },
    {
      "epoch": 14.838754039744206,
      "grad_norm": 0.1787421703338623,
      "learning_rate": 3.6481747307437746e-06,
      "loss": 0.0476,
      "step": 215800
    },
    {
      "epoch": 14.845630200096267,
      "grad_norm": 0.11740116029977798,
      "learning_rate": 3.626685806135518e-06,
      "loss": 0.0462,
      "step": 215900
    },
    {
      "epoch": 14.852506360448325,
      "grad_norm": 0.11271672695875168,
      "learning_rate": 3.6051968815272613e-06,
      "loss": 0.0457,
      "step": 216000
    },
    {
      "epoch": 14.859382520800384,
      "grad_norm": 0.11857465654611588,
      "learning_rate": 3.583707956919004e-06,
      "loss": 0.0425,
      "step": 216100
    },
    {
      "epoch": 14.866258681152445,
      "grad_norm": 0.17867009341716766,
      "learning_rate": 3.562219032310747e-06,
      "loss": 0.0431,
      "step": 216200
    },
    {
      "epoch": 14.873134841504504,
      "grad_norm": 0.18086422979831696,
      "learning_rate": 3.5407301077024905e-06,
      "loss": 0.0459,
      "step": 216300
    },
    {
      "epoch": 14.880011001856563,
      "grad_norm": 0.1717865765094757,
      "learning_rate": 3.519241183094234e-06,
      "loss": 0.0466,
      "step": 216400
    },
    {
      "epoch": 14.886887162208623,
      "grad_norm": 0.11251194775104523,
      "learning_rate": 3.4977522584859763e-06,
      "loss": 0.0448,
      "step": 216500
    },
    {
      "epoch": 14.893763322560682,
      "grad_norm": 0.10943955183029175,
      "learning_rate": 3.4762633338777196e-06,
      "loss": 0.0448,
      "step": 216600
    },
    {
      "epoch": 14.90063948291274,
      "grad_norm": 0.1505511999130249,
      "learning_rate": 3.454774409269463e-06,
      "loss": 0.0447,
      "step": 216700
    },
    {
      "epoch": 14.907515643264801,
      "grad_norm": 0.16836047172546387,
      "learning_rate": 3.4332854846612054e-06,
      "loss": 0.0492,
      "step": 216800
    },
    {
      "epoch": 14.91439180361686,
      "grad_norm": 0.14218002557754517,
      "learning_rate": 3.4117965600529488e-06,
      "loss": 0.0459,
      "step": 216900
    },
    {
      "epoch": 14.92126796396892,
      "grad_norm": 0.16233491897583008,
      "learning_rate": 3.390307635444692e-06,
      "loss": 0.0418,
      "step": 217000
    },
    {
      "epoch": 14.92814412432098,
      "grad_norm": 0.28708615899086,
      "learning_rate": 3.368818710836435e-06,
      "loss": 0.0442,
      "step": 217100
    },
    {
      "epoch": 14.935020284673039,
      "grad_norm": 0.22989146411418915,
      "learning_rate": 3.347329786228178e-06,
      "loss": 0.0423,
      "step": 217200
    },
    {
      "epoch": 14.941896445025098,
      "grad_norm": 0.11940835416316986,
      "learning_rate": 3.3258408616199213e-06,
      "loss": 0.0447,
      "step": 217300
    },
    {
      "epoch": 14.948772605377158,
      "grad_norm": 0.23843437433242798,
      "learning_rate": 3.304351937011664e-06,
      "loss": 0.0475,
      "step": 217400
    },
    {
      "epoch": 14.955648765729217,
      "grad_norm": 0.13094745576381683,
      "learning_rate": 3.2828630124034075e-06,
      "loss": 0.0447,
      "step": 217500
    },
    {
      "epoch": 14.962524926081276,
      "grad_norm": 0.16338814795017242,
      "learning_rate": 3.2615889770412327e-06,
      "loss": 0.0469,
      "step": 217600
    },
    {
      "epoch": 14.969401086433336,
      "grad_norm": 0.30375203490257263,
      "learning_rate": 3.240100052432976e-06,
      "loss": 0.0459,
      "step": 217700
    },
    {
      "epoch": 14.976277246785395,
      "grad_norm": 0.22127637267112732,
      "learning_rate": 3.2186111278247194e-06,
      "loss": 0.0452,
      "step": 217800
    },
    {
      "epoch": 14.983153407137454,
      "grad_norm": 0.2020048052072525,
      "learning_rate": 3.1971222032164627e-06,
      "loss": 0.046,
      "step": 217900
    },
    {
      "epoch": 14.990029567489515,
      "grad_norm": 0.1805771291255951,
      "learning_rate": 3.175633278608205e-06,
      "loss": 0.045,
      "step": 218000
    },
    {
      "epoch": 14.996905727841574,
      "grad_norm": 0.20473933219909668,
      "learning_rate": 3.1541443539999485e-06,
      "loss": 0.0433,
      "step": 218100
    },
    {
      "epoch": 15.0,
      "eval_accuracy_macro_0.5": 0.9801148176193237,
      "eval_accuracy_micro_0.5": 0.9801148176193237,
      "eval_accuracy_weighted_0.5": 0.9775804281234741,
      "eval_f1_macro_0.5": 0.7269926071166992,
      "eval_f1_macro_0.6": 0.7027864456176758,
      "eval_f1_macro_0.7": 0.6651803851127625,
      "eval_f1_macro_0.8": 0.47745054960250854,
      "eval_f1_micro_0.5": 0.7315208911895752,
      "eval_f1_micro_0.6": 0.7121171951293945,
      "eval_f1_micro_0.7": 0.6792471408843994,
      "eval_f1_micro_0.8": 0.6200934052467346,
      "eval_f1_micro_0.9": 0.503767728805542,
      "eval_f1_weighted_0.5": 0.7235735654830933,
      "eval_f1_weighted_0.6": 0.6981284022331238,
      "eval_f1_weighted_0.7": 0.6581466197967529,
      "eval_f1_weighted_0.8": 0.4625018835067749,
      "eval_loss": 0.041396595537662506,
      "eval_runtime": 63.6661,
      "eval_samples_per_second": 456.082,
      "eval_steps_per_second": 57.016,
      "step": 218145
    },
    {
      "epoch": 15.003781888193632,
      "grad_norm": 0.16188225150108337,
      "learning_rate": 3.132655429391692e-06,
      "loss": 0.043,
      "step": 218200
    },
    {
      "epoch": 15.010658048545691,
      "grad_norm": 0.1753290295600891,
      "learning_rate": 3.1111665047834348e-06,
      "loss": 0.0425,
      "step": 218300
    },
    {
      "epoch": 15.017534208897752,
      "grad_norm": 0.14451494812965393,
      "learning_rate": 3.089677580175178e-06,
      "loss": 0.0445,
      "step": 218400
    },
    {
      "epoch": 15.02441036924981,
      "grad_norm": 0.16591361165046692,
      "learning_rate": 3.068188655566921e-06,
      "loss": 0.0454,
      "step": 218500
    },
    {
      "epoch": 15.03128652960187,
      "grad_norm": 0.1353653371334076,
      "learning_rate": 3.0466997309586643e-06,
      "loss": 0.0448,
      "step": 218600
    },
    {
      "epoch": 15.03816268995393,
      "grad_norm": 0.13049638271331787,
      "learning_rate": 3.0252108063504072e-06,
      "loss": 0.0424,
      "step": 218700
    },
    {
      "epoch": 15.045038850305989,
      "grad_norm": 0.17991802096366882,
      "learning_rate": 3.00372188174215e-06,
      "loss": 0.0417,
      "step": 218800
    },
    {
      "epoch": 15.051915010658048,
      "grad_norm": 0.16769403219223022,
      "learning_rate": 2.9822329571338935e-06,
      "loss": 0.0452,
      "step": 218900
    },
    {
      "epoch": 15.058791171010109,
      "grad_norm": 0.09795749932527542,
      "learning_rate": 2.9607440325256364e-06,
      "loss": 0.0464,
      "step": 219000
    },
    {
      "epoch": 15.065667331362167,
      "grad_norm": 0.09443351626396179,
      "learning_rate": 2.9392551079173797e-06,
      "loss": 0.0455,
      "step": 219100
    },
    {
      "epoch": 15.072543491714226,
      "grad_norm": 0.11599704623222351,
      "learning_rate": 2.9177661833091226e-06,
      "loss": 0.0442,
      "step": 219200
    },
    {
      "epoch": 15.079419652066287,
      "grad_norm": 0.17108944058418274,
      "learning_rate": 2.8962772587008656e-06,
      "loss": 0.0407,
      "step": 219300
    },
    {
      "epoch": 15.086295812418346,
      "grad_norm": 0.20364657044410706,
      "learning_rate": 2.874788334092609e-06,
      "loss": 0.0443,
      "step": 219400
    },
    {
      "epoch": 15.093171972770405,
      "grad_norm": 0.12266992777585983,
      "learning_rate": 2.853299409484352e-06,
      "loss": 0.0454,
      "step": 219500
    },
    {
      "epoch": 15.100048133122465,
      "grad_norm": 0.10042118281126022,
      "learning_rate": 2.8318104848760947e-06,
      "loss": 0.0404,
      "step": 219600
    },
    {
      "epoch": 15.106924293474524,
      "grad_norm": 0.10504455119371414,
      "learning_rate": 2.8105364495139207e-06,
      "loss": 0.0434,
      "step": 219700
    },
    {
      "epoch": 15.113800453826583,
      "grad_norm": 0.1565047651529312,
      "learning_rate": 2.789047524905664e-06,
      "loss": 0.044,
      "step": 219800
    },
    {
      "epoch": 15.120676614178644,
      "grad_norm": 0.1086585745215416,
      "learning_rate": 2.767558600297407e-06,
      "loss": 0.0441,
      "step": 219900
    },
    {
      "epoch": 15.127552774530702,
      "grad_norm": 0.15381154417991638,
      "learning_rate": 2.74606967568915e-06,
      "loss": 0.0447,
      "step": 220000
    },
    {
      "epoch": 15.134428934882761,
      "grad_norm": 0.12192486971616745,
      "learning_rate": 2.7245807510808932e-06,
      "loss": 0.0445,
      "step": 220100
    },
    {
      "epoch": 15.14130509523482,
      "grad_norm": 0.12430839240550995,
      "learning_rate": 2.703091826472636e-06,
      "loss": 0.0431,
      "step": 220200
    },
    {
      "epoch": 15.14818125558688,
      "grad_norm": 0.16261649131774902,
      "learning_rate": 2.681602901864379e-06,
      "loss": 0.0424,
      "step": 220300
    },
    {
      "epoch": 15.15505741593894,
      "grad_norm": 0.1880081295967102,
      "learning_rate": 2.6601139772561224e-06,
      "loss": 0.0451,
      "step": 220400
    },
    {
      "epoch": 15.161933576290998,
      "grad_norm": 0.1486048400402069,
      "learning_rate": 2.6386250526478653e-06,
      "loss": 0.043,
      "step": 220500
    },
    {
      "epoch": 15.168809736643059,
      "grad_norm": 0.13420410454273224,
      "learning_rate": 2.6171361280396086e-06,
      "loss": 0.0436,
      "step": 220600
    },
    {
      "epoch": 15.175685896995118,
      "grad_norm": 0.13097548484802246,
      "learning_rate": 2.5956472034313515e-06,
      "loss": 0.0447,
      "step": 220700
    },
    {
      "epoch": 15.182562057347177,
      "grad_norm": 0.11736724525690079,
      "learning_rate": 2.5741582788230944e-06,
      "loss": 0.0452,
      "step": 220800
    },
    {
      "epoch": 15.189438217699237,
      "grad_norm": 0.18726623058319092,
      "learning_rate": 2.5526693542148378e-06,
      "loss": 0.046,
      "step": 220900
    },
    {
      "epoch": 15.196314378051296,
      "grad_norm": 0.14971157908439636,
      "learning_rate": 2.5311804296065807e-06,
      "loss": 0.0453,
      "step": 221000
    },
    {
      "epoch": 15.203190538403355,
      "grad_norm": 0.24752651154994965,
      "learning_rate": 2.509691504998324e-06,
      "loss": 0.0436,
      "step": 221100
    },
    {
      "epoch": 15.210066698755416,
      "grad_norm": 0.38547283411026,
      "learning_rate": 2.4882025803900673e-06,
      "loss": 0.041,
      "step": 221200
    },
    {
      "epoch": 15.216942859107474,
      "grad_norm": 0.12558019161224365,
      "learning_rate": 2.4667136557818103e-06,
      "loss": 0.0452,
      "step": 221300
    },
    {
      "epoch": 15.223819019459533,
      "grad_norm": 0.24279601871967316,
      "learning_rate": 2.4452247311735536e-06,
      "loss": 0.0461,
      "step": 221400
    },
    {
      "epoch": 15.230695179811594,
      "grad_norm": 0.1554771214723587,
      "learning_rate": 2.4237358065652965e-06,
      "loss": 0.0461,
      "step": 221500
    },
    {
      "epoch": 15.237571340163653,
      "grad_norm": 0.13350920379161835,
      "learning_rate": 2.4022468819570394e-06,
      "loss": 0.0433,
      "step": 221600
    },
    {
      "epoch": 15.244447500515712,
      "grad_norm": 0.14913053810596466,
      "learning_rate": 2.3807579573487827e-06,
      "loss": 0.0461,
      "step": 221700
    },
    {
      "epoch": 15.251323660867772,
      "grad_norm": 0.13620246946811676,
      "learning_rate": 2.3592690327405257e-06,
      "loss": 0.0448,
      "step": 221800
    },
    {
      "epoch": 15.258199821219831,
      "grad_norm": 0.20068661868572235,
      "learning_rate": 2.3377801081322686e-06,
      "loss": 0.0436,
      "step": 221900
    },
    {
      "epoch": 15.26507598157189,
      "grad_norm": 0.1268414407968521,
      "learning_rate": 2.316291183524012e-06,
      "loss": 0.0481,
      "step": 222000
    },
    {
      "epoch": 15.27195214192395,
      "grad_norm": 0.15232262015342712,
      "learning_rate": 2.2950171481618375e-06,
      "loss": 0.0432,
      "step": 222100
    },
    {
      "epoch": 15.27882830227601,
      "grad_norm": 0.14549696445465088,
      "learning_rate": 2.273528223553581e-06,
      "loss": 0.0455,
      "step": 222200
    },
    {
      "epoch": 15.285704462628068,
      "grad_norm": 0.08548324555158615,
      "learning_rate": 2.2520392989453237e-06,
      "loss": 0.0459,
      "step": 222300
    },
    {
      "epoch": 15.292580622980127,
      "grad_norm": 0.10757795721292496,
      "learning_rate": 2.230550374337067e-06,
      "loss": 0.046,
      "step": 222400
    },
    {
      "epoch": 15.299456783332188,
      "grad_norm": 0.1271093785762787,
      "learning_rate": 2.20906144972881e-06,
      "loss": 0.0413,
      "step": 222500
    },
    {
      "epoch": 15.306332943684247,
      "grad_norm": 0.12069091945886612,
      "learning_rate": 2.187572525120553e-06,
      "loss": 0.0444,
      "step": 222600
    },
    {
      "epoch": 15.313209104036305,
      "grad_norm": 0.23104828596115112,
      "learning_rate": 2.1660836005122962e-06,
      "loss": 0.0434,
      "step": 222700
    },
    {
      "epoch": 15.320085264388366,
      "grad_norm": 0.10735330730676651,
      "learning_rate": 2.144594675904039e-06,
      "loss": 0.0454,
      "step": 222800
    },
    {
      "epoch": 15.326961424740425,
      "grad_norm": 0.28112515807151794,
      "learning_rate": 2.1231057512957825e-06,
      "loss": 0.0453,
      "step": 222900
    },
    {
      "epoch": 15.333837585092484,
      "grad_norm": 0.14235883951187134,
      "learning_rate": 2.1016168266875254e-06,
      "loss": 0.0429,
      "step": 223000
    },
    {
      "epoch": 15.340713745444544,
      "grad_norm": 0.16943980753421783,
      "learning_rate": 2.0801279020792683e-06,
      "loss": 0.046,
      "step": 223100
    },
    {
      "epoch": 15.347589905796603,
      "grad_norm": 0.06616422533988953,
      "learning_rate": 2.0586389774710116e-06,
      "loss": 0.0451,
      "step": 223200
    },
    {
      "epoch": 15.354466066148662,
      "grad_norm": 0.13373278081417084,
      "learning_rate": 2.0371500528627545e-06,
      "loss": 0.0421,
      "step": 223300
    },
    {
      "epoch": 15.361342226500723,
      "grad_norm": 0.19266003370285034,
      "learning_rate": 2.0156611282544975e-06,
      "loss": 0.0442,
      "step": 223400
    },
    {
      "epoch": 15.368218386852782,
      "grad_norm": 0.21049737930297852,
      "learning_rate": 1.994172203646241e-06,
      "loss": 0.0443,
      "step": 223500
    },
    {
      "epoch": 15.37509454720484,
      "grad_norm": 0.22866468131542206,
      "learning_rate": 1.9726832790379837e-06,
      "loss": 0.0453,
      "step": 223600
    },
    {
      "epoch": 15.381970707556901,
      "grad_norm": 0.30461347103118896,
      "learning_rate": 1.951194354429727e-06,
      "loss": 0.0481,
      "step": 223700
    },
    {
      "epoch": 15.38884686790896,
      "grad_norm": 0.09365390986204147,
      "learning_rate": 1.92970542982147e-06,
      "loss": 0.0466,
      "step": 223800
    },
    {
      "epoch": 15.395723028261019,
      "grad_norm": 0.12847477197647095,
      "learning_rate": 1.9082165052132133e-06,
      "loss": 0.0478,
      "step": 223900
    },
    {
      "epoch": 15.40259918861308,
      "grad_norm": 0.06049644947052002,
      "learning_rate": 1.8867275806049564e-06,
      "loss": 0.0446,
      "step": 224000
    },
    {
      "epoch": 15.409475348965138,
      "grad_norm": 0.16938717663288116,
      "learning_rate": 1.8652386559966993e-06,
      "loss": 0.0473,
      "step": 224100
    },
    {
      "epoch": 15.416351509317197,
      "grad_norm": 0.14785721898078918,
      "learning_rate": 1.8437497313884424e-06,
      "loss": 0.0439,
      "step": 224200
    },
    {
      "epoch": 15.423227669669256,
      "grad_norm": 0.12218683958053589,
      "learning_rate": 1.8222608067801856e-06,
      "loss": 0.0412,
      "step": 224300
    },
    {
      "epoch": 15.430103830021316,
      "grad_norm": 0.18647927045822144,
      "learning_rate": 1.8007718821719287e-06,
      "loss": 0.0434,
      "step": 224400
    },
    {
      "epoch": 15.436979990373375,
      "grad_norm": 0.08043012022972107,
      "learning_rate": 1.779282957563672e-06,
      "loss": 0.0448,
      "step": 224500
    },
    {
      "epoch": 15.443856150725434,
      "grad_norm": 0.20432262122631073,
      "learning_rate": 1.757794032955415e-06,
      "loss": 0.0428,
      "step": 224600
    },
    {
      "epoch": 15.450732311077495,
      "grad_norm": 0.1585131734609604,
      "learning_rate": 1.7363051083471578e-06,
      "loss": 0.0435,
      "step": 224700
    },
    {
      "epoch": 15.457608471429554,
      "grad_norm": 0.17697909474372864,
      "learning_rate": 1.7148161837389012e-06,
      "loss": 0.0443,
      "step": 224800
    },
    {
      "epoch": 15.464484631781612,
      "grad_norm": 0.15468324720859528,
      "learning_rate": 1.693327259130644e-06,
      "loss": 0.0458,
      "step": 224900
    },
    {
      "epoch": 15.471360792133673,
      "grad_norm": 0.1861211210489273,
      "learning_rate": 1.6720532237684699e-06,
      "loss": 0.0424,
      "step": 225000
    },
    {
      "epoch": 15.478236952485732,
      "grad_norm": 0.14021386206150055,
      "learning_rate": 1.6505642991602128e-06,
      "loss": 0.0437,
      "step": 225100
    },
    {
      "epoch": 15.48511311283779,
      "grad_norm": 0.15018944442272186,
      "learning_rate": 1.6290753745519561e-06,
      "loss": 0.0463,
      "step": 225200
    },
    {
      "epoch": 15.491989273189851,
      "grad_norm": 0.12657637894153595,
      "learning_rate": 1.607586449943699e-06,
      "loss": 0.046,
      "step": 225300
    },
    {
      "epoch": 15.49886543354191,
      "grad_norm": 0.14000515639781952,
      "learning_rate": 1.5860975253354422e-06,
      "loss": 0.0405,
      "step": 225400
    },
    {
      "epoch": 15.505741593893969,
      "grad_norm": 0.11159930378198624,
      "learning_rate": 1.5646086007271855e-06,
      "loss": 0.0445,
      "step": 225500
    },
    {
      "epoch": 15.51261775424603,
      "grad_norm": 0.18312078714370728,
      "learning_rate": 1.5431196761189284e-06,
      "loss": 0.0416,
      "step": 225600
    },
    {
      "epoch": 15.519493914598089,
      "grad_norm": 0.21877148747444153,
      "learning_rate": 1.5216307515106715e-06,
      "loss": 0.0435,
      "step": 225700
    },
    {
      "epoch": 15.526370074950147,
      "grad_norm": 0.11396638303995132,
      "learning_rate": 1.5001418269024147e-06,
      "loss": 0.0447,
      "step": 225800
    },
    {
      "epoch": 15.533246235302208,
      "grad_norm": 0.14382554590702057,
      "learning_rate": 1.4786529022941576e-06,
      "loss": 0.0448,
      "step": 225900
    },
    {
      "epoch": 15.540122395654267,
      "grad_norm": 0.12584273517131805,
      "learning_rate": 1.4571639776859007e-06,
      "loss": 0.0443,
      "step": 226000
    },
    {
      "epoch": 15.546998556006326,
      "grad_norm": 0.21008194983005524,
      "learning_rate": 1.4356750530776438e-06,
      "loss": 0.0452,
      "step": 226100
    },
    {
      "epoch": 15.553874716358386,
      "grad_norm": 0.1730901300907135,
      "learning_rate": 1.414186128469387e-06,
      "loss": 0.0442,
      "step": 226200
    },
    {
      "epoch": 15.560750876710445,
      "grad_norm": 0.19948124885559082,
      "learning_rate": 1.39269720386113e-06,
      "loss": 0.0455,
      "step": 226300
    },
    {
      "epoch": 15.567627037062504,
      "grad_norm": 0.12574003636837006,
      "learning_rate": 1.3712082792528732e-06,
      "loss": 0.0435,
      "step": 226400
    },
    {
      "epoch": 15.574503197414563,
      "grad_norm": 0.1801363229751587,
      "learning_rate": 1.3497193546446163e-06,
      "loss": 0.0437,
      "step": 226500
    },
    {
      "epoch": 15.581379357766624,
      "grad_norm": 0.1033920869231224,
      "learning_rate": 1.3282304300363594e-06,
      "loss": 0.0491,
      "step": 226600
    },
    {
      "epoch": 15.588255518118682,
      "grad_norm": 0.14481407403945923,
      "learning_rate": 1.3067415054281023e-06,
      "loss": 0.0443,
      "step": 226700
    },
    {
      "epoch": 15.595131678470741,
      "grad_norm": 0.18472124636173248,
      "learning_rate": 1.2852525808198455e-06,
      "loss": 0.0431,
      "step": 226800
    },
    {
      "epoch": 15.602007838822802,
      "grad_norm": 0.13172516226768494,
      "learning_rate": 1.2637636562115886e-06,
      "loss": 0.0439,
      "step": 226900
    },
    {
      "epoch": 15.60888399917486,
      "grad_norm": 0.1934378743171692,
      "learning_rate": 1.2422747316033317e-06,
      "loss": 0.0439,
      "step": 227000
    },
    {
      "epoch": 15.61576015952692,
      "grad_norm": 0.20298536121845245,
      "learning_rate": 1.2207858069950748e-06,
      "loss": 0.045,
      "step": 227100
    },
    {
      "epoch": 15.62263631987898,
      "grad_norm": 0.26782771944999695,
      "learning_rate": 1.1995117716329004e-06,
      "loss": 0.042,
      "step": 227200
    },
    {
      "epoch": 15.629512480231039,
      "grad_norm": 0.1349184364080429,
      "learning_rate": 1.1780228470246435e-06,
      "loss": 0.0452,
      "step": 227300
    },
    {
      "epoch": 15.636388640583098,
      "grad_norm": 0.17879612743854523,
      "learning_rate": 1.1565339224163867e-06,
      "loss": 0.0415,
      "step": 227400
    },
    {
      "epoch": 15.643264800935158,
      "grad_norm": 0.1731303483247757,
      "learning_rate": 1.1350449978081298e-06,
      "loss": 0.0452,
      "step": 227500
    },
    {
      "epoch": 15.650140961287217,
      "grad_norm": 0.15875472128391266,
      "learning_rate": 1.113556073199873e-06,
      "loss": 0.0419,
      "step": 227600
    },
    {
      "epoch": 15.657017121639276,
      "grad_norm": 0.13867713510990143,
      "learning_rate": 1.092067148591616e-06,
      "loss": 0.0428,
      "step": 227700
    },
    {
      "epoch": 15.663893281991337,
      "grad_norm": 0.14643555879592896,
      "learning_rate": 1.070578223983359e-06,
      "loss": 0.0449,
      "step": 227800
    },
    {
      "epoch": 15.670769442343396,
      "grad_norm": 0.19138933718204498,
      "learning_rate": 1.049089299375102e-06,
      "loss": 0.0445,
      "step": 227900
    },
    {
      "epoch": 15.677645602695454,
      "grad_norm": 0.1552838385105133,
      "learning_rate": 1.0276003747668452e-06,
      "loss": 0.0439,
      "step": 228000
    },
    {
      "epoch": 15.684521763047513,
      "grad_norm": 0.10459684580564499,
      "learning_rate": 1.0061114501585883e-06,
      "loss": 0.0453,
      "step": 228100
    },
    {
      "epoch": 15.691397923399574,
      "grad_norm": 0.16950750350952148,
      "learning_rate": 9.846225255503314e-07,
      "loss": 0.0472,
      "step": 228200
    },
    {
      "epoch": 15.698274083751633,
      "grad_norm": 0.14631535112857819,
      "learning_rate": 9.631336009420745e-07,
      "loss": 0.0463,
      "step": 228300
    },
    {
      "epoch": 15.705150244103692,
      "grad_norm": 0.17228524386882782,
      "learning_rate": 9.416446763338177e-07,
      "loss": 0.045,
      "step": 228400
    },
    {
      "epoch": 15.712026404455752,
      "grad_norm": 0.09838518500328064,
      "learning_rate": 9.201557517255608e-07,
      "loss": 0.0455,
      "step": 228500
    },
    {
      "epoch": 15.718902564807811,
      "grad_norm": 0.14977645874023438,
      "learning_rate": 8.986668271173037e-07,
      "loss": 0.0457,
      "step": 228600
    },
    {
      "epoch": 15.72577872515987,
      "grad_norm": 0.12173260748386383,
      "learning_rate": 8.771779025090468e-07,
      "loss": 0.0448,
      "step": 228700
    },
    {
      "epoch": 15.73265488551193,
      "grad_norm": 0.08233531564474106,
      "learning_rate": 8.556889779007901e-07,
      "loss": 0.0444,
      "step": 228800
    },
    {
      "epoch": 15.73953104586399,
      "grad_norm": 0.10405370593070984,
      "learning_rate": 8.342000532925332e-07,
      "loss": 0.0431,
      "step": 228900
    },
    {
      "epoch": 15.746407206216048,
      "grad_norm": 0.17893046140670776,
      "learning_rate": 8.127111286842761e-07,
      "loss": 0.0444,
      "step": 229000
    },
    {
      "epoch": 15.753283366568109,
      "grad_norm": 0.1510673612356186,
      "learning_rate": 7.912222040760192e-07,
      "loss": 0.0425,
      "step": 229100
    },
    {
      "epoch": 15.760159526920168,
      "grad_norm": 0.16257332265377045,
      "learning_rate": 7.699481687138449e-07,
      "loss": 0.0441,
      "step": 229200
    },
    {
      "epoch": 15.767035687272227,
      "grad_norm": 0.2077736258506775,
      "learning_rate": 7.48459244105588e-07,
      "loss": 0.0458,
      "step": 229300
    },
    {
      "epoch": 15.773911847624287,
      "grad_norm": 0.14614015817642212,
      "learning_rate": 7.269703194973312e-07,
      "loss": 0.0431,
      "step": 229400
    },
    {
      "epoch": 15.780788007976346,
      "grad_norm": 0.15737418830394745,
      "learning_rate": 7.054813948890743e-07,
      "loss": 0.0454,
      "step": 229500
    },
    {
      "epoch": 15.787664168328405,
      "grad_norm": 0.22883297502994537,
      "learning_rate": 6.839924702808173e-07,
      "loss": 0.0438,
      "step": 229600
    },
    {
      "epoch": 15.794540328680466,
      "grad_norm": 0.1223919540643692,
      "learning_rate": 6.625035456725604e-07,
      "loss": 0.0407,
      "step": 229700
    },
    {
      "epoch": 15.801416489032524,
      "grad_norm": 0.1706504076719284,
      "learning_rate": 6.410146210643034e-07,
      "loss": 0.0447,
      "step": 229800
    },
    {
      "epoch": 15.808292649384583,
      "grad_norm": 0.12548841536045074,
      "learning_rate": 6.195256964560467e-07,
      "loss": 0.0397,
      "step": 229900
    },
    {
      "epoch": 15.815168809736644,
      "grad_norm": 0.11828406900167465,
      "learning_rate": 5.980367718477897e-07,
      "loss": 0.0448,
      "step": 230000
    },
    {
      "epoch": 15.822044970088703,
      "grad_norm": 0.17243899405002594,
      "learning_rate": 5.765478472395328e-07,
      "loss": 0.0472,
      "step": 230100
    },
    {
      "epoch": 15.828921130440762,
      "grad_norm": 0.13392411172389984,
      "learning_rate": 5.550589226312758e-07,
      "loss": 0.0466,
      "step": 230200
    },
    {
      "epoch": 15.835797290792822,
      "grad_norm": 0.296560674905777,
      "learning_rate": 5.33569998023019e-07,
      "loss": 0.0423,
      "step": 230300
    },
    {
      "epoch": 15.842673451144881,
      "grad_norm": 0.09278055280447006,
      "learning_rate": 5.120810734147621e-07,
      "loss": 0.0456,
      "step": 230400
    },
    {
      "epoch": 15.84954961149694,
      "grad_norm": 0.23530201613903046,
      "learning_rate": 4.905921488065052e-07,
      "loss": 0.0479,
      "step": 230500
    },
    {
      "epoch": 15.856425771848999,
      "grad_norm": 0.10395461320877075,
      "learning_rate": 4.6910322419824825e-07,
      "loss": 0.0476,
      "step": 230600
    },
    {
      "epoch": 15.86330193220106,
      "grad_norm": 0.13271330296993256,
      "learning_rate": 4.476142995899914e-07,
      "loss": 0.043,
      "step": 230700
    },
    {
      "epoch": 15.870178092553118,
      "grad_norm": 0.10609494894742966,
      "learning_rate": 4.2612537498173445e-07,
      "loss": 0.0469,
      "step": 230800
    },
    {
      "epoch": 15.877054252905177,
      "grad_norm": 0.1699514538049698,
      "learning_rate": 4.0463645037347757e-07,
      "loss": 0.0437,
      "step": 230900
    },
    {
      "epoch": 15.883930413257238,
      "grad_norm": 0.1766170859336853,
      "learning_rate": 3.8314752576522064e-07,
      "loss": 0.0447,
      "step": 231000
    },
    {
      "epoch": 15.890806573609296,
      "grad_norm": 0.13355621695518494,
      "learning_rate": 3.616586011569637e-07,
      "loss": 0.0445,
      "step": 231100
    },
    {
      "epoch": 15.897682733961355,
      "grad_norm": 0.17848490178585052,
      "learning_rate": 3.4016967654870683e-07,
      "loss": 0.0446,
      "step": 231200
    },
    {
      "epoch": 15.904558894313416,
      "grad_norm": 0.17111755907535553,
      "learning_rate": 3.186807519404499e-07,
      "loss": 0.0441,
      "step": 231300
    },
    {
      "epoch": 15.911435054665475,
      "grad_norm": 0.14659857749938965,
      "learning_rate": 2.97191827332193e-07,
      "loss": 0.0411,
      "step": 231400
    },
    {
      "epoch": 15.918311215017534,
      "grad_norm": 0.17710243165493011,
      "learning_rate": 2.757029027239361e-07,
      "loss": 0.042,
      "step": 231500
    },
    {
      "epoch": 15.925187375369594,
      "grad_norm": 0.148124560713768,
      "learning_rate": 2.5421397811567916e-07,
      "loss": 0.0432,
      "step": 231600
    },
    {
      "epoch": 15.932063535721653,
      "grad_norm": 0.16238796710968018,
      "learning_rate": 2.3272505350742228e-07,
      "loss": 0.0441,
      "step": 231700
    },
    {
      "epoch": 15.938939696073712,
      "grad_norm": 0.17665177583694458,
      "learning_rate": 2.1123612889916538e-07,
      "loss": 0.0454,
      "step": 231800
    },
    {
      "epoch": 15.945815856425773,
      "grad_norm": 0.09903399646282196,
      "learning_rate": 1.8974720429090847e-07,
      "loss": 0.0427,
      "step": 231900
    },
    {
      "epoch": 15.952692016777831,
      "grad_norm": 0.17759443819522858,
      "learning_rate": 1.6825827968265157e-07,
      "loss": 0.0433,
      "step": 232000
    },
    {
      "epoch": 15.95956817712989,
      "grad_norm": 0.09267450124025345,
      "learning_rate": 1.4676935507439467e-07,
      "loss": 0.0431,
      "step": 232100
    },
    {
      "epoch": 15.966444337481951,
      "grad_norm": 0.20400694012641907,
      "learning_rate": 1.2549531971222031e-07,
      "loss": 0.0432,
      "step": 232200
    },
    {
      "epoch": 15.97332049783401,
      "grad_norm": 0.11076319217681885,
      "learning_rate": 1.0400639510396342e-07,
      "loss": 0.0441,
      "step": 232300
    },
    {
      "epoch": 15.980196658186069,
      "grad_norm": 0.159896582365036,
      "learning_rate": 8.25174704957065e-08,
      "loss": 0.0463,
      "step": 232400
    },
    {
      "epoch": 15.987072818538127,
      "grad_norm": 0.21381868422031403,
      "learning_rate": 6.10285458874496e-08,
      "loss": 0.0458,
      "step": 232500
    },
    {
      "epoch": 15.993948978890188,
      "grad_norm": 0.18041567504405975,
      "learning_rate": 3.9539621279192704e-08,
      "loss": 0.0475,
      "step": 232600
    },
    {
      "epoch": 16.0,
      "eval_accuracy_macro_0.5": 0.9801158905029297,
      "eval_accuracy_micro_0.5": 0.9801158905029297,
      "eval_accuracy_weighted_0.5": 0.9775919914245605,
      "eval_f1_macro_0.5": 0.7276419401168823,
      "eval_f1_macro_0.6": 0.7046639919281006,
      "eval_f1_macro_0.7": 0.6666282415390015,
      "eval_f1_macro_0.8": 0.4802182912826538,
      "eval_f1_micro_0.5": 0.7321542501449585,
      "eval_f1_micro_0.6": 0.713446319103241,
      "eval_f1_micro_0.7": 0.6803517937660217,
      "eval_f1_micro_0.8": 0.6219969987869263,
      "eval_f1_micro_0.9": 0.5060570240020752,
      "eval_f1_weighted_0.5": 0.7244248390197754,
      "eval_f1_weighted_0.6": 0.6998892426490784,
      "eval_f1_weighted_0.7": 0.6596764326095581,
      "eval_f1_weighted_0.8": 0.4653295576572418,
      "eval_loss": 0.04142699018120766,
      "eval_runtime": 63.3557,
      "eval_samples_per_second": 458.317,
      "eval_steps_per_second": 57.296,
      "step": 232688
    }
  ],
  "logging_steps": 100,
  "max_steps": 232688,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 16,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5564921076124992.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
