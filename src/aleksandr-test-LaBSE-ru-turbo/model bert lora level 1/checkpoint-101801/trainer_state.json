{
  "best_metric": 0.8046387434005737,
  "best_model_checkpoint": "aleksandr-test-LaBSE-ru-turbo/model bert lora level 1/checkpoint-101801",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 101801,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00687616035205941,
      "grad_norm": 0.34946686029434204,
      "learning_rate": 4.996131827324772e-05,
      "loss": 0.3468,
      "step": 100
    },
    {
      "epoch": 0.01375232070411882,
      "grad_norm": 0.24009309709072113,
      "learning_rate": 4.9918338576856295e-05,
      "loss": 0.1395,
      "step": 200
    },
    {
      "epoch": 0.02062848105617823,
      "grad_norm": 0.2177884429693222,
      "learning_rate": 4.9875358880464876e-05,
      "loss": 0.1305,
      "step": 300
    },
    {
      "epoch": 0.02750464140823764,
      "grad_norm": 0.24049262702465057,
      "learning_rate": 4.983237918407345e-05,
      "loss": 0.1245,
      "step": 400
    },
    {
      "epoch": 0.03438080176029705,
      "grad_norm": 0.21169042587280273,
      "learning_rate": 4.978939948768202e-05,
      "loss": 0.1148,
      "step": 500
    },
    {
      "epoch": 0.04125696211235646,
      "grad_norm": 0.22983689606189728,
      "learning_rate": 4.97464197912906e-05,
      "loss": 0.1075,
      "step": 600
    },
    {
      "epoch": 0.04813312246441587,
      "grad_norm": 0.2125282734632492,
      "learning_rate": 4.970344009489917e-05,
      "loss": 0.0994,
      "step": 700
    },
    {
      "epoch": 0.05500928281647528,
      "grad_norm": 0.22270655632019043,
      "learning_rate": 4.9660460398507745e-05,
      "loss": 0.0903,
      "step": 800
    },
    {
      "epoch": 0.06188544316853469,
      "grad_norm": 0.16011282801628113,
      "learning_rate": 4.961748070211632e-05,
      "loss": 0.0875,
      "step": 900
    },
    {
      "epoch": 0.0687616035205941,
      "grad_norm": 0.1799589842557907,
      "learning_rate": 4.95745010057249e-05,
      "loss": 0.0819,
      "step": 1000
    },
    {
      "epoch": 0.07563776387265352,
      "grad_norm": 0.20165881514549255,
      "learning_rate": 4.9531521309333474e-05,
      "loss": 0.0794,
      "step": 1100
    },
    {
      "epoch": 0.08251392422471292,
      "grad_norm": 0.2059279829263687,
      "learning_rate": 4.948854161294205e-05,
      "loss": 0.0746,
      "step": 1200
    },
    {
      "epoch": 0.08939008457677233,
      "grad_norm": 0.17570553719997406,
      "learning_rate": 4.944556191655063e-05,
      "loss": 0.0769,
      "step": 1300
    },
    {
      "epoch": 0.09626624492883173,
      "grad_norm": 0.1727754771709442,
      "learning_rate": 4.94025822201592e-05,
      "loss": 0.0735,
      "step": 1400
    },
    {
      "epoch": 0.10314240528089115,
      "grad_norm": 0.15494628250598907,
      "learning_rate": 4.9359602523767776e-05,
      "loss": 0.0681,
      "step": 1500
    },
    {
      "epoch": 0.11001856563295057,
      "grad_norm": 0.18505792319774628,
      "learning_rate": 4.931662282737635e-05,
      "loss": 0.0669,
      "step": 1600
    },
    {
      "epoch": 0.11689472598500997,
      "grad_norm": 0.13691401481628418,
      "learning_rate": 4.9273643130984924e-05,
      "loss": 0.0689,
      "step": 1700
    },
    {
      "epoch": 0.12377088633706938,
      "grad_norm": 0.1883188635110855,
      "learning_rate": 4.92306634345935e-05,
      "loss": 0.0671,
      "step": 1800
    },
    {
      "epoch": 0.1306470466891288,
      "grad_norm": 0.23869213461875916,
      "learning_rate": 4.918768373820208e-05,
      "loss": 0.0635,
      "step": 1900
    },
    {
      "epoch": 0.1375232070411882,
      "grad_norm": 0.1663789600133896,
      "learning_rate": 4.914470404181065e-05,
      "loss": 0.0634,
      "step": 2000
    },
    {
      "epoch": 0.1443993673932476,
      "grad_norm": 0.28714728355407715,
      "learning_rate": 4.9101724345419226e-05,
      "loss": 0.0621,
      "step": 2100
    },
    {
      "epoch": 0.15127552774530703,
      "grad_norm": 0.15428781509399414,
      "learning_rate": 4.90587446490278e-05,
      "loss": 0.0597,
      "step": 2200
    },
    {
      "epoch": 0.15815168809736643,
      "grad_norm": 0.1976272612810135,
      "learning_rate": 4.901576495263638e-05,
      "loss": 0.0632,
      "step": 2300
    },
    {
      "epoch": 0.16502784844942583,
      "grad_norm": 0.14371272921562195,
      "learning_rate": 4.8972785256244955e-05,
      "loss": 0.0622,
      "step": 2400
    },
    {
      "epoch": 0.17190400880148526,
      "grad_norm": 0.1541982889175415,
      "learning_rate": 4.892980555985353e-05,
      "loss": 0.0589,
      "step": 2500
    },
    {
      "epoch": 0.17878016915354467,
      "grad_norm": 0.23412321507930756,
      "learning_rate": 4.88868258634621e-05,
      "loss": 0.0628,
      "step": 2600
    },
    {
      "epoch": 0.18565632950560407,
      "grad_norm": 0.19383259117603302,
      "learning_rate": 4.8843846167070677e-05,
      "loss": 0.0603,
      "step": 2700
    },
    {
      "epoch": 0.19253248985766347,
      "grad_norm": 0.13959205150604248,
      "learning_rate": 4.880086647067925e-05,
      "loss": 0.059,
      "step": 2800
    },
    {
      "epoch": 0.1994086502097229,
      "grad_norm": 0.21089620888233185,
      "learning_rate": 4.875788677428783e-05,
      "loss": 0.0568,
      "step": 2900
    },
    {
      "epoch": 0.2062848105617823,
      "grad_norm": 0.1560213714838028,
      "learning_rate": 4.8714907077896405e-05,
      "loss": 0.0591,
      "step": 3000
    },
    {
      "epoch": 0.2131609709138417,
      "grad_norm": 0.2138294279575348,
      "learning_rate": 4.867192738150498e-05,
      "loss": 0.0592,
      "step": 3100
    },
    {
      "epoch": 0.22003713126590113,
      "grad_norm": 0.13144858181476593,
      "learning_rate": 4.862894768511356e-05,
      "loss": 0.0616,
      "step": 3200
    },
    {
      "epoch": 0.22691329161796053,
      "grad_norm": 0.13413316011428833,
      "learning_rate": 4.8585967988722134e-05,
      "loss": 0.0555,
      "step": 3300
    },
    {
      "epoch": 0.23378945197001993,
      "grad_norm": 0.22863812744617462,
      "learning_rate": 4.854298829233071e-05,
      "loss": 0.0581,
      "step": 3400
    },
    {
      "epoch": 0.24066561232207936,
      "grad_norm": 0.1590665876865387,
      "learning_rate": 4.850000859593928e-05,
      "loss": 0.0562,
      "step": 3500
    },
    {
      "epoch": 0.24754177267413877,
      "grad_norm": 0.15302525460720062,
      "learning_rate": 4.8457028899547855e-05,
      "loss": 0.0565,
      "step": 3600
    },
    {
      "epoch": 0.2544179330261982,
      "grad_norm": 0.2141747921705246,
      "learning_rate": 4.841404920315643e-05,
      "loss": 0.0555,
      "step": 3700
    },
    {
      "epoch": 0.2612940933782576,
      "grad_norm": 0.23038215935230255,
      "learning_rate": 4.8371069506765e-05,
      "loss": 0.0581,
      "step": 3800
    },
    {
      "epoch": 0.268170253730317,
      "grad_norm": 0.18260051310062408,
      "learning_rate": 4.8328089810373584e-05,
      "loss": 0.0582,
      "step": 3900
    },
    {
      "epoch": 0.2750464140823764,
      "grad_norm": 0.18429996073246002,
      "learning_rate": 4.828511011398216e-05,
      "loss": 0.055,
      "step": 4000
    },
    {
      "epoch": 0.2819225744344358,
      "grad_norm": 0.15036331117153168,
      "learning_rate": 4.824213041759073e-05,
      "loss": 0.0551,
      "step": 4100
    },
    {
      "epoch": 0.2887987347864952,
      "grad_norm": 0.20603245496749878,
      "learning_rate": 4.819915072119931e-05,
      "loss": 0.0536,
      "step": 4200
    },
    {
      "epoch": 0.2956748951385546,
      "grad_norm": 0.18584021925926208,
      "learning_rate": 4.8156171024807886e-05,
      "loss": 0.0549,
      "step": 4300
    },
    {
      "epoch": 0.30255105549061406,
      "grad_norm": 0.16547827422618866,
      "learning_rate": 4.811319132841646e-05,
      "loss": 0.0532,
      "step": 4400
    },
    {
      "epoch": 0.30942721584267346,
      "grad_norm": 0.13505415618419647,
      "learning_rate": 4.8070211632025034e-05,
      "loss": 0.0548,
      "step": 4500
    },
    {
      "epoch": 0.31630337619473287,
      "grad_norm": 0.14959542453289032,
      "learning_rate": 4.802723193563361e-05,
      "loss": 0.0539,
      "step": 4600
    },
    {
      "epoch": 0.32317953654679227,
      "grad_norm": 0.20548325777053833,
      "learning_rate": 4.798425223924218e-05,
      "loss": 0.0525,
      "step": 4700
    },
    {
      "epoch": 0.33005569689885167,
      "grad_norm": 0.137739360332489,
      "learning_rate": 4.7941272542850756e-05,
      "loss": 0.0548,
      "step": 4800
    },
    {
      "epoch": 0.33693185725091107,
      "grad_norm": 0.1634410172700882,
      "learning_rate": 4.7898292846459336e-05,
      "loss": 0.0544,
      "step": 4900
    },
    {
      "epoch": 0.34380801760297053,
      "grad_norm": 0.2064303606748581,
      "learning_rate": 4.785531315006791e-05,
      "loss": 0.0528,
      "step": 5000
    },
    {
      "epoch": 0.35068417795502993,
      "grad_norm": 0.16429950296878815,
      "learning_rate": 4.7812333453676484e-05,
      "loss": 0.0528,
      "step": 5100
    },
    {
      "epoch": 0.35756033830708933,
      "grad_norm": 0.1228741854429245,
      "learning_rate": 4.7769353757285065e-05,
      "loss": 0.0527,
      "step": 5200
    },
    {
      "epoch": 0.36443649865914873,
      "grad_norm": 0.2210167795419693,
      "learning_rate": 4.772637406089364e-05,
      "loss": 0.0529,
      "step": 5300
    },
    {
      "epoch": 0.37131265901120813,
      "grad_norm": 0.1513744592666626,
      "learning_rate": 4.768339436450221e-05,
      "loss": 0.0552,
      "step": 5400
    },
    {
      "epoch": 0.37818881936326754,
      "grad_norm": 0.2724296748638153,
      "learning_rate": 4.764041466811079e-05,
      "loss": 0.0511,
      "step": 5500
    },
    {
      "epoch": 0.38506497971532694,
      "grad_norm": 0.2790237069129944,
      "learning_rate": 4.759743497171936e-05,
      "loss": 0.0511,
      "step": 5600
    },
    {
      "epoch": 0.3919411400673864,
      "grad_norm": 0.16935758292675018,
      "learning_rate": 4.7554455275327935e-05,
      "loss": 0.0525,
      "step": 5700
    },
    {
      "epoch": 0.3988173004194458,
      "grad_norm": 0.21359805762767792,
      "learning_rate": 4.7511475578936515e-05,
      "loss": 0.055,
      "step": 5800
    },
    {
      "epoch": 0.4056934607715052,
      "grad_norm": 0.11982110142707825,
      "learning_rate": 4.746849588254509e-05,
      "loss": 0.0543,
      "step": 5900
    },
    {
      "epoch": 0.4125696211235646,
      "grad_norm": 0.16483132541179657,
      "learning_rate": 4.742551618615366e-05,
      "loss": 0.0534,
      "step": 6000
    },
    {
      "epoch": 0.419445781475624,
      "grad_norm": 0.1364760845899582,
      "learning_rate": 4.738253648976224e-05,
      "loss": 0.0501,
      "step": 6100
    },
    {
      "epoch": 0.4263219418276834,
      "grad_norm": 0.10638830065727234,
      "learning_rate": 4.733955679337082e-05,
      "loss": 0.051,
      "step": 6200
    },
    {
      "epoch": 0.4331981021797428,
      "grad_norm": 0.17535825073719025,
      "learning_rate": 4.72970068939433e-05,
      "loss": 0.0488,
      "step": 6300
    },
    {
      "epoch": 0.44007426253180226,
      "grad_norm": 0.1327630579471588,
      "learning_rate": 4.725402719755188e-05,
      "loss": 0.0517,
      "step": 6400
    },
    {
      "epoch": 0.44695042288386166,
      "grad_norm": 0.2300945222377777,
      "learning_rate": 4.7211047501160455e-05,
      "loss": 0.0518,
      "step": 6500
    },
    {
      "epoch": 0.45382658323592107,
      "grad_norm": 0.14976444840431213,
      "learning_rate": 4.716806780476903e-05,
      "loss": 0.0501,
      "step": 6600
    },
    {
      "epoch": 0.46070274358798047,
      "grad_norm": 0.09724943339824677,
      "learning_rate": 4.71250881083776e-05,
      "loss": 0.0512,
      "step": 6700
    },
    {
      "epoch": 0.46757890394003987,
      "grad_norm": 0.2071859985589981,
      "learning_rate": 4.708210841198618e-05,
      "loss": 0.0527,
      "step": 6800
    },
    {
      "epoch": 0.47445506429209927,
      "grad_norm": 0.20816712081432343,
      "learning_rate": 4.703912871559476e-05,
      "loss": 0.0495,
      "step": 6900
    },
    {
      "epoch": 0.48133122464415873,
      "grad_norm": 0.20145627856254578,
      "learning_rate": 4.699614901920333e-05,
      "loss": 0.0509,
      "step": 7000
    },
    {
      "epoch": 0.48820738499621813,
      "grad_norm": 0.23986437916755676,
      "learning_rate": 4.6953169322811905e-05,
      "loss": 0.0493,
      "step": 7100
    },
    {
      "epoch": 0.49508354534827753,
      "grad_norm": 0.1744905412197113,
      "learning_rate": 4.691018962642048e-05,
      "loss": 0.052,
      "step": 7200
    },
    {
      "epoch": 0.5019597057003369,
      "grad_norm": 0.14811857044696808,
      "learning_rate": 4.686720993002905e-05,
      "loss": 0.0483,
      "step": 7300
    },
    {
      "epoch": 0.5088358660523964,
      "grad_norm": 0.10321475565433502,
      "learning_rate": 4.682423023363763e-05,
      "loss": 0.0504,
      "step": 7400
    },
    {
      "epoch": 0.5157120264044558,
      "grad_norm": 0.26228058338165283,
      "learning_rate": 4.678125053724621e-05,
      "loss": 0.0469,
      "step": 7500
    },
    {
      "epoch": 0.5225881867565152,
      "grad_norm": 0.16881491243839264,
      "learning_rate": 4.673827084085478e-05,
      "loss": 0.0507,
      "step": 7600
    },
    {
      "epoch": 0.5294643471085746,
      "grad_norm": 0.2774968445301056,
      "learning_rate": 4.669529114446336e-05,
      "loss": 0.052,
      "step": 7700
    },
    {
      "epoch": 0.536340507460634,
      "grad_norm": 0.13525576889514923,
      "learning_rate": 4.6652311448071936e-05,
      "loss": 0.0511,
      "step": 7800
    },
    {
      "epoch": 0.5432166678126934,
      "grad_norm": 0.22131405770778656,
      "learning_rate": 4.660933175168051e-05,
      "loss": 0.0493,
      "step": 7900
    },
    {
      "epoch": 0.5500928281647528,
      "grad_norm": 0.08125688135623932,
      "learning_rate": 4.6566352055289084e-05,
      "loss": 0.0482,
      "step": 8000
    },
    {
      "epoch": 0.5569689885168122,
      "grad_norm": 0.16748926043510437,
      "learning_rate": 4.652337235889766e-05,
      "loss": 0.0475,
      "step": 8100
    },
    {
      "epoch": 0.5638451488688716,
      "grad_norm": 0.26321983337402344,
      "learning_rate": 4.648039266250623e-05,
      "loss": 0.0514,
      "step": 8200
    },
    {
      "epoch": 0.570721309220931,
      "grad_norm": 0.1838831603527069,
      "learning_rate": 4.6437412966114805e-05,
      "loss": 0.0501,
      "step": 8300
    },
    {
      "epoch": 0.5775974695729904,
      "grad_norm": 0.29805442690849304,
      "learning_rate": 4.6394433269723386e-05,
      "loss": 0.0501,
      "step": 8400
    },
    {
      "epoch": 0.5844736299250498,
      "grad_norm": 0.20682451128959656,
      "learning_rate": 4.635145357333196e-05,
      "loss": 0.0499,
      "step": 8500
    },
    {
      "epoch": 0.5913497902771092,
      "grad_norm": 0.1527586579322815,
      "learning_rate": 4.6308473876940534e-05,
      "loss": 0.0505,
      "step": 8600
    },
    {
      "epoch": 0.5982259506291687,
      "grad_norm": 0.15104317665100098,
      "learning_rate": 4.6265494180549114e-05,
      "loss": 0.0498,
      "step": 8700
    },
    {
      "epoch": 0.6051021109812281,
      "grad_norm": 0.2513176202774048,
      "learning_rate": 4.622251448415769e-05,
      "loss": 0.0486,
      "step": 8800
    },
    {
      "epoch": 0.6119782713332875,
      "grad_norm": 0.19100314378738403,
      "learning_rate": 4.617953478776626e-05,
      "loss": 0.0508,
      "step": 8900
    },
    {
      "epoch": 0.6188544316853469,
      "grad_norm": 0.24661803245544434,
      "learning_rate": 4.6136555091374836e-05,
      "loss": 0.0482,
      "step": 9000
    },
    {
      "epoch": 0.6257305920374063,
      "grad_norm": 0.24295583367347717,
      "learning_rate": 4.609357539498341e-05,
      "loss": 0.0504,
      "step": 9100
    },
    {
      "epoch": 0.6326067523894657,
      "grad_norm": 0.2700541615486145,
      "learning_rate": 4.6050595698591984e-05,
      "loss": 0.0504,
      "step": 9200
    },
    {
      "epoch": 0.6394829127415251,
      "grad_norm": 0.14878609776496887,
      "learning_rate": 4.6007616002200565e-05,
      "loss": 0.0488,
      "step": 9300
    },
    {
      "epoch": 0.6463590730935845,
      "grad_norm": 0.18851031363010406,
      "learning_rate": 4.596463630580914e-05,
      "loss": 0.0454,
      "step": 9400
    },
    {
      "epoch": 0.6532352334456439,
      "grad_norm": 0.17920970916748047,
      "learning_rate": 4.592165660941771e-05,
      "loss": 0.0497,
      "step": 9500
    },
    {
      "epoch": 0.6601113937977033,
      "grad_norm": 0.14176097512245178,
      "learning_rate": 4.5878676913026286e-05,
      "loss": 0.0488,
      "step": 9600
    },
    {
      "epoch": 0.6669875541497627,
      "grad_norm": 0.12520229816436768,
      "learning_rate": 4.583569721663487e-05,
      "loss": 0.0471,
      "step": 9700
    },
    {
      "epoch": 0.6738637145018221,
      "grad_norm": 0.36559224128723145,
      "learning_rate": 4.579271752024344e-05,
      "loss": 0.0467,
      "step": 9800
    },
    {
      "epoch": 0.6807398748538815,
      "grad_norm": 0.3338730037212372,
      "learning_rate": 4.5749737823852015e-05,
      "loss": 0.0478,
      "step": 9900
    },
    {
      "epoch": 0.6876160352059411,
      "grad_norm": 0.24412931501865387,
      "learning_rate": 4.570675812746059e-05,
      "loss": 0.0475,
      "step": 10000
    },
    {
      "epoch": 0.6944921955580005,
      "grad_norm": 0.2143244743347168,
      "learning_rate": 4.566377843106916e-05,
      "loss": 0.0486,
      "step": 10100
    },
    {
      "epoch": 0.7013683559100599,
      "grad_norm": 0.24489407241344452,
      "learning_rate": 4.562122853164165e-05,
      "loss": 0.047,
      "step": 10200
    },
    {
      "epoch": 0.7082445162621193,
      "grad_norm": 0.24793216586112976,
      "learning_rate": 4.557824883525023e-05,
      "loss": 0.0448,
      "step": 10300
    },
    {
      "epoch": 0.7151206766141787,
      "grad_norm": 0.14928089082241058,
      "learning_rate": 4.5535269138858806e-05,
      "loss": 0.0469,
      "step": 10400
    },
    {
      "epoch": 0.7219968369662381,
      "grad_norm": 0.15465638041496277,
      "learning_rate": 4.549228944246738e-05,
      "loss": 0.0483,
      "step": 10500
    },
    {
      "epoch": 0.7288729973182975,
      "grad_norm": 0.16315115988254547,
      "learning_rate": 4.5449309746075954e-05,
      "loss": 0.0481,
      "step": 10600
    },
    {
      "epoch": 0.7357491576703569,
      "grad_norm": 0.1951863318681717,
      "learning_rate": 4.540633004968453e-05,
      "loss": 0.0447,
      "step": 10700
    },
    {
      "epoch": 0.7426253180224163,
      "grad_norm": 0.17397214472293854,
      "learning_rate": 4.53633503532931e-05,
      "loss": 0.0477,
      "step": 10800
    },
    {
      "epoch": 0.7495014783744757,
      "grad_norm": 0.218242347240448,
      "learning_rate": 4.532037065690168e-05,
      "loss": 0.0478,
      "step": 10900
    },
    {
      "epoch": 0.7563776387265351,
      "grad_norm": 0.28635960817337036,
      "learning_rate": 4.527739096051026e-05,
      "loss": 0.0464,
      "step": 11000
    },
    {
      "epoch": 0.7632537990785945,
      "grad_norm": 0.17192642390727997,
      "learning_rate": 4.523441126411883e-05,
      "loss": 0.0452,
      "step": 11100
    },
    {
      "epoch": 0.7701299594306539,
      "grad_norm": 0.16541741788387299,
      "learning_rate": 4.519143156772741e-05,
      "loss": 0.0473,
      "step": 11200
    },
    {
      "epoch": 0.7770061197827133,
      "grad_norm": 0.15409661829471588,
      "learning_rate": 4.5148451871335985e-05,
      "loss": 0.0476,
      "step": 11300
    },
    {
      "epoch": 0.7838822801347728,
      "grad_norm": 0.2058955430984497,
      "learning_rate": 4.510547217494456e-05,
      "loss": 0.0477,
      "step": 11400
    },
    {
      "epoch": 0.7907584404868322,
      "grad_norm": 0.16855597496032715,
      "learning_rate": 4.506249247855313e-05,
      "loss": 0.045,
      "step": 11500
    },
    {
      "epoch": 0.7976346008388916,
      "grad_norm": 0.18756547570228577,
      "learning_rate": 4.501951278216171e-05,
      "loss": 0.048,
      "step": 11600
    },
    {
      "epoch": 0.804510761190951,
      "grad_norm": 0.17754581570625305,
      "learning_rate": 4.497653308577028e-05,
      "loss": 0.0468,
      "step": 11700
    },
    {
      "epoch": 0.8113869215430104,
      "grad_norm": 0.13422927260398865,
      "learning_rate": 4.4933553389378855e-05,
      "loss": 0.0436,
      "step": 11800
    },
    {
      "epoch": 0.8182630818950698,
      "grad_norm": 0.14135466516017914,
      "learning_rate": 4.4890573692987435e-05,
      "loss": 0.0461,
      "step": 11900
    },
    {
      "epoch": 0.8251392422471292,
      "grad_norm": 0.2744653820991516,
      "learning_rate": 4.484759399659601e-05,
      "loss": 0.0471,
      "step": 12000
    },
    {
      "epoch": 0.8320154025991886,
      "grad_norm": 0.1584012508392334,
      "learning_rate": 4.480461430020458e-05,
      "loss": 0.0461,
      "step": 12100
    },
    {
      "epoch": 0.838891562951248,
      "grad_norm": 0.12141890823841095,
      "learning_rate": 4.4761634603813164e-05,
      "loss": 0.0443,
      "step": 12200
    },
    {
      "epoch": 0.8457677233033074,
      "grad_norm": 0.14987671375274658,
      "learning_rate": 4.471865490742174e-05,
      "loss": 0.0426,
      "step": 12300
    },
    {
      "epoch": 0.8526438836553668,
      "grad_norm": 0.17851907014846802,
      "learning_rate": 4.467567521103031e-05,
      "loss": 0.044,
      "step": 12400
    },
    {
      "epoch": 0.8595200440074262,
      "grad_norm": 0.19212792813777924,
      "learning_rate": 4.46331253116028e-05,
      "loss": 0.0457,
      "step": 12500
    },
    {
      "epoch": 0.8663962043594856,
      "grad_norm": 0.2778560221195221,
      "learning_rate": 4.4590145615211375e-05,
      "loss": 0.0456,
      "step": 12600
    },
    {
      "epoch": 0.8732723647115451,
      "grad_norm": 0.13575433194637299,
      "learning_rate": 4.454716591881995e-05,
      "loss": 0.0458,
      "step": 12700
    },
    {
      "epoch": 0.8801485250636045,
      "grad_norm": 0.16956762969493866,
      "learning_rate": 4.450418622242853e-05,
      "loss": 0.0489,
      "step": 12800
    },
    {
      "epoch": 0.8870246854156639,
      "grad_norm": 0.2760799825191498,
      "learning_rate": 4.44612065260371e-05,
      "loss": 0.0482,
      "step": 12900
    },
    {
      "epoch": 0.8939008457677233,
      "grad_norm": 0.15455104410648346,
      "learning_rate": 4.441822682964568e-05,
      "loss": 0.0466,
      "step": 13000
    },
    {
      "epoch": 0.9007770061197827,
      "grad_norm": 0.32457002997398376,
      "learning_rate": 4.437524713325426e-05,
      "loss": 0.0473,
      "step": 13100
    },
    {
      "epoch": 0.9076531664718421,
      "grad_norm": 0.17783892154693604,
      "learning_rate": 4.433226743686283e-05,
      "loss": 0.0475,
      "step": 13200
    },
    {
      "epoch": 0.9145293268239015,
      "grad_norm": 0.27915194630622864,
      "learning_rate": 4.4289287740471406e-05,
      "loss": 0.0474,
      "step": 13300
    },
    {
      "epoch": 0.9214054871759609,
      "grad_norm": 0.13143205642700195,
      "learning_rate": 4.424630804407997e-05,
      "loss": 0.0412,
      "step": 13400
    },
    {
      "epoch": 0.9282816475280203,
      "grad_norm": 0.16107520461082458,
      "learning_rate": 4.4203328347688553e-05,
      "loss": 0.0444,
      "step": 13500
    },
    {
      "epoch": 0.9351578078800797,
      "grad_norm": 0.22472825646400452,
      "learning_rate": 4.416034865129713e-05,
      "loss": 0.0463,
      "step": 13600
    },
    {
      "epoch": 0.9420339682321391,
      "grad_norm": 0.15756578743457794,
      "learning_rate": 4.41173689549057e-05,
      "loss": 0.0473,
      "step": 13700
    },
    {
      "epoch": 0.9489101285841985,
      "grad_norm": 0.17253725230693817,
      "learning_rate": 4.407438925851428e-05,
      "loss": 0.0461,
      "step": 13800
    },
    {
      "epoch": 0.9557862889362579,
      "grad_norm": 0.1578219085931778,
      "learning_rate": 4.4031409562122856e-05,
      "loss": 0.0449,
      "step": 13900
    },
    {
      "epoch": 0.9626624492883175,
      "grad_norm": 0.14383439719676971,
      "learning_rate": 4.398842986573143e-05,
      "loss": 0.0454,
      "step": 14000
    },
    {
      "epoch": 0.9695386096403769,
      "grad_norm": 0.22653904557228088,
      "learning_rate": 4.394545016934001e-05,
      "loss": 0.0453,
      "step": 14100
    },
    {
      "epoch": 0.9764147699924363,
      "grad_norm": 0.12346214056015015,
      "learning_rate": 4.3902470472948584e-05,
      "loss": 0.0447,
      "step": 14200
    },
    {
      "epoch": 0.9832909303444957,
      "grad_norm": 0.17473945021629333,
      "learning_rate": 4.385949077655716e-05,
      "loss": 0.0429,
      "step": 14300
    },
    {
      "epoch": 0.9901670906965551,
      "grad_norm": 0.21442657709121704,
      "learning_rate": 4.381651108016573e-05,
      "loss": 0.0441,
      "step": 14400
    },
    {
      "epoch": 0.9970432510486145,
      "grad_norm": 0.18493874371051788,
      "learning_rate": 4.3773531383774306e-05,
      "loss": 0.0429,
      "step": 14500
    },
    {
      "epoch": 1.0,
      "eval_accuracy_macro_0.5": 0.9794142246246338,
      "eval_accuracy_micro_0.5": 0.9794142246246338,
      "eval_accuracy_weighted_0.5": 0.9767475128173828,
      "eval_f1_macro_0.5": 0.7125783562660217,
      "eval_f1_macro_0.6": 0.6847949624061584,
      "eval_f1_macro_0.7": 0.6410661935806274,
      "eval_f1_macro_0.8": 0.4382893145084381,
      "eval_f1_micro_0.5": 0.7178428173065186,
      "eval_f1_micro_0.6": 0.6954674124717712,
      "eval_f1_micro_0.7": 0.6571106314659119,
      "eval_f1_micro_0.8": 0.587731122970581,
      "eval_f1_micro_0.9": 0.45806583762168884,
      "eval_f1_weighted_0.5": 0.7080515027046204,
      "eval_f1_weighted_0.6": 0.6795637011528015,
      "eval_f1_weighted_0.7": 0.634045422077179,
      "eval_f1_weighted_0.8": 0.4197764992713928,
      "eval_loss": 0.04235062375664711,
      "eval_runtime": 140.8107,
      "eval_samples_per_second": 206.213,
      "eval_steps_per_second": 25.779,
      "step": 14543
    },
    {
      "epoch": 1.0039194114006738,
      "grad_norm": 0.14013652503490448,
      "learning_rate": 4.373055168738288e-05,
      "loss": 0.0433,
      "step": 14600
    },
    {
      "epoch": 1.0107955717527333,
      "grad_norm": 0.15104170143604279,
      "learning_rate": 4.368757199099146e-05,
      "loss": 0.0426,
      "step": 14700
    },
    {
      "epoch": 1.0176717321047928,
      "grad_norm": 0.15529944002628326,
      "learning_rate": 4.3644592294600035e-05,
      "loss": 0.0432,
      "step": 14800
    },
    {
      "epoch": 1.024547892456852,
      "grad_norm": 0.16936209797859192,
      "learning_rate": 4.360161259820861e-05,
      "loss": 0.0433,
      "step": 14900
    },
    {
      "epoch": 1.0314240528089116,
      "grad_norm": 0.36454564332962036,
      "learning_rate": 4.355863290181718e-05,
      "loss": 0.044,
      "step": 15000
    },
    {
      "epoch": 1.0383002131609709,
      "grad_norm": 0.17371606826782227,
      "learning_rate": 4.351565320542576e-05,
      "loss": 0.0454,
      "step": 15100
    },
    {
      "epoch": 1.0451763735130304,
      "grad_norm": 0.13212041556835175,
      "learning_rate": 4.347267350903434e-05,
      "loss": 0.0405,
      "step": 15200
    },
    {
      "epoch": 1.0520525338650897,
      "grad_norm": 0.19724692404270172,
      "learning_rate": 4.342969381264291e-05,
      "loss": 0.0432,
      "step": 15300
    },
    {
      "epoch": 1.0589286942171492,
      "grad_norm": 0.1689363718032837,
      "learning_rate": 4.3386714116251485e-05,
      "loss": 0.0454,
      "step": 15400
    },
    {
      "epoch": 1.0658048545692085,
      "grad_norm": 0.2227708250284195,
      "learning_rate": 4.334373441986006e-05,
      "loss": 0.0445,
      "step": 15500
    },
    {
      "epoch": 1.072681014921268,
      "grad_norm": 0.11886025965213776,
      "learning_rate": 4.330075472346863e-05,
      "loss": 0.0415,
      "step": 15600
    },
    {
      "epoch": 1.0795571752733273,
      "grad_norm": 0.20708885788917542,
      "learning_rate": 4.3257775027077213e-05,
      "loss": 0.0427,
      "step": 15700
    },
    {
      "epoch": 1.0864333356253868,
      "grad_norm": 0.2496200054883957,
      "learning_rate": 4.321479533068579e-05,
      "loss": 0.0429,
      "step": 15800
    },
    {
      "epoch": 1.0933094959774463,
      "grad_norm": 0.113926462829113,
      "learning_rate": 4.317181563429436e-05,
      "loss": 0.0438,
      "step": 15900
    },
    {
      "epoch": 1.1001856563295056,
      "grad_norm": 0.11096526682376862,
      "learning_rate": 4.312883593790294e-05,
      "loss": 0.0413,
      "step": 16000
    },
    {
      "epoch": 1.1070618166815651,
      "grad_norm": 0.12801288068294525,
      "learning_rate": 4.3085856241511516e-05,
      "loss": 0.0414,
      "step": 16100
    },
    {
      "epoch": 1.1139379770336244,
      "grad_norm": 0.16786910593509674,
      "learning_rate": 4.3043306342084e-05,
      "loss": 0.0396,
      "step": 16200
    },
    {
      "epoch": 1.120814137385684,
      "grad_norm": 0.20037764310836792,
      "learning_rate": 4.300032664569258e-05,
      "loss": 0.0415,
      "step": 16300
    },
    {
      "epoch": 1.1276902977377432,
      "grad_norm": 0.15235313773155212,
      "learning_rate": 4.295734694930115e-05,
      "loss": 0.0421,
      "step": 16400
    },
    {
      "epoch": 1.1345664580898027,
      "grad_norm": 0.2372014969587326,
      "learning_rate": 4.2914367252909727e-05,
      "loss": 0.0442,
      "step": 16500
    },
    {
      "epoch": 1.141442618441862,
      "grad_norm": 0.17491571605205536,
      "learning_rate": 4.287138755651831e-05,
      "loss": 0.044,
      "step": 16600
    },
    {
      "epoch": 1.1483187787939215,
      "grad_norm": 0.18550318479537964,
      "learning_rate": 4.282840786012688e-05,
      "loss": 0.0445,
      "step": 16700
    },
    {
      "epoch": 1.1551949391459808,
      "grad_norm": 0.1666576862335205,
      "learning_rate": 4.2785428163735455e-05,
      "loss": 0.0441,
      "step": 16800
    },
    {
      "epoch": 1.1620710994980403,
      "grad_norm": 0.24206343293190002,
      "learning_rate": 4.274244846734403e-05,
      "loss": 0.0437,
      "step": 16900
    },
    {
      "epoch": 1.1689472598500996,
      "grad_norm": 0.1814618557691574,
      "learning_rate": 4.26994687709526e-05,
      "loss": 0.0421,
      "step": 17000
    },
    {
      "epoch": 1.1758234202021591,
      "grad_norm": 0.15504321455955505,
      "learning_rate": 4.265648907456118e-05,
      "loss": 0.0418,
      "step": 17100
    },
    {
      "epoch": 1.1826995805542184,
      "grad_norm": 0.18476465344429016,
      "learning_rate": 4.261393917513367e-05,
      "loss": 0.0418,
      "step": 17200
    },
    {
      "epoch": 1.189575740906278,
      "grad_norm": 0.15920931100845337,
      "learning_rate": 4.2570959478742247e-05,
      "loss": 0.0454,
      "step": 17300
    },
    {
      "epoch": 1.1964519012583374,
      "grad_norm": 0.15591421723365784,
      "learning_rate": 4.252797978235082e-05,
      "loss": 0.0445,
      "step": 17400
    },
    {
      "epoch": 1.2033280616103967,
      "grad_norm": 0.18090671300888062,
      "learning_rate": 4.2485000085959394e-05,
      "loss": 0.0447,
      "step": 17500
    },
    {
      "epoch": 1.2102042219624563,
      "grad_norm": 0.1226283460855484,
      "learning_rate": 4.244202038956797e-05,
      "loss": 0.0436,
      "step": 17600
    },
    {
      "epoch": 1.2170803823145155,
      "grad_norm": 0.15168322622776031,
      "learning_rate": 4.239904069317654e-05,
      "loss": 0.0457,
      "step": 17700
    },
    {
      "epoch": 1.223956542666575,
      "grad_norm": 0.15286438167095184,
      "learning_rate": 4.2356060996785116e-05,
      "loss": 0.0429,
      "step": 17800
    },
    {
      "epoch": 1.2308327030186343,
      "grad_norm": 0.17947432398796082,
      "learning_rate": 4.23130813003937e-05,
      "loss": 0.042,
      "step": 17900
    },
    {
      "epoch": 1.2377088633706939,
      "grad_norm": 0.12548846006393433,
      "learning_rate": 4.227010160400227e-05,
      "loss": 0.0419,
      "step": 18000
    },
    {
      "epoch": 1.2445850237227531,
      "grad_norm": 0.09379099309444427,
      "learning_rate": 4.2227121907610845e-05,
      "loss": 0.0416,
      "step": 18100
    },
    {
      "epoch": 1.2514611840748127,
      "grad_norm": 0.21725672483444214,
      "learning_rate": 4.2184142211219425e-05,
      "loss": 0.0428,
      "step": 18200
    },
    {
      "epoch": 1.258337344426872,
      "grad_norm": 0.16750170290470123,
      "learning_rate": 4.2141162514828e-05,
      "loss": 0.0421,
      "step": 18300
    },
    {
      "epoch": 1.2652135047789315,
      "grad_norm": 0.16864264011383057,
      "learning_rate": 4.209818281843657e-05,
      "loss": 0.0418,
      "step": 18400
    },
    {
      "epoch": 1.272089665130991,
      "grad_norm": 0.24090200662612915,
      "learning_rate": 4.205520312204515e-05,
      "loss": 0.0442,
      "step": 18500
    },
    {
      "epoch": 1.2789658254830503,
      "grad_norm": 0.15092341601848602,
      "learning_rate": 4.201222342565372e-05,
      "loss": 0.0406,
      "step": 18600
    },
    {
      "epoch": 1.2858419858351096,
      "grad_norm": 0.13371363282203674,
      "learning_rate": 4.1969243729262295e-05,
      "loss": 0.0395,
      "step": 18700
    },
    {
      "epoch": 1.292718146187169,
      "grad_norm": 0.1793101578950882,
      "learning_rate": 4.192626403287087e-05,
      "loss": 0.044,
      "step": 18800
    },
    {
      "epoch": 1.2995943065392286,
      "grad_norm": 0.22710248827934265,
      "learning_rate": 4.188328433647945e-05,
      "loss": 0.0407,
      "step": 18900
    },
    {
      "epoch": 1.3064704668912879,
      "grad_norm": 0.14009913802146912,
      "learning_rate": 4.1840304640088023e-05,
      "loss": 0.0423,
      "step": 19000
    },
    {
      "epoch": 1.3133466272433474,
      "grad_norm": 0.08806080371141434,
      "learning_rate": 4.17973249436966e-05,
      "loss": 0.0414,
      "step": 19100
    },
    {
      "epoch": 1.3202227875954067,
      "grad_norm": 0.21195875108242035,
      "learning_rate": 4.175434524730518e-05,
      "loss": 0.0453,
      "step": 19200
    },
    {
      "epoch": 1.3270989479474662,
      "grad_norm": 0.22442695498466492,
      "learning_rate": 4.171136555091375e-05,
      "loss": 0.0433,
      "step": 19300
    },
    {
      "epoch": 1.3339751082995255,
      "grad_norm": 0.18390008807182312,
      "learning_rate": 4.1668385854522326e-05,
      "loss": 0.0415,
      "step": 19400
    },
    {
      "epoch": 1.340851268651585,
      "grad_norm": 0.1919724941253662,
      "learning_rate": 4.16254061581309e-05,
      "loss": 0.0436,
      "step": 19500
    },
    {
      "epoch": 1.3477274290036443,
      "grad_norm": 0.16047993302345276,
      "learning_rate": 4.1582426461739474e-05,
      "loss": 0.0398,
      "step": 19600
    },
    {
      "epoch": 1.3546035893557038,
      "grad_norm": 0.2790001928806305,
      "learning_rate": 4.153944676534805e-05,
      "loss": 0.0427,
      "step": 19700
    },
    {
      "epoch": 1.361479749707763,
      "grad_norm": 0.20124152302742004,
      "learning_rate": 4.149646706895663e-05,
      "loss": 0.0411,
      "step": 19800
    },
    {
      "epoch": 1.3683559100598226,
      "grad_norm": 0.1644841581583023,
      "learning_rate": 4.14534873725652e-05,
      "loss": 0.0423,
      "step": 19900
    },
    {
      "epoch": 1.3752320704118821,
      "grad_norm": 0.1463608592748642,
      "learning_rate": 4.1410507676173776e-05,
      "loss": 0.0416,
      "step": 20000
    },
    {
      "epoch": 1.3821082307639414,
      "grad_norm": 0.2224486619234085,
      "learning_rate": 4.136752797978235e-05,
      "loss": 0.0412,
      "step": 20100
    },
    {
      "epoch": 1.3889843911160007,
      "grad_norm": 0.20615258812904358,
      "learning_rate": 4.132454828339093e-05,
      "loss": 0.0416,
      "step": 20200
    },
    {
      "epoch": 1.3958605514680602,
      "grad_norm": 0.17806239426136017,
      "learning_rate": 4.1281568586999505e-05,
      "loss": 0.0414,
      "step": 20300
    },
    {
      "epoch": 1.4027367118201197,
      "grad_norm": 0.11668118089437485,
      "learning_rate": 4.123858889060808e-05,
      "loss": 0.0419,
      "step": 20400
    },
    {
      "epoch": 1.409612872172179,
      "grad_norm": 0.14305782318115234,
      "learning_rate": 4.119560919421665e-05,
      "loss": 0.042,
      "step": 20500
    },
    {
      "epoch": 1.4164890325242385,
      "grad_norm": 0.20597878098487854,
      "learning_rate": 4.1152629497825226e-05,
      "loss": 0.0401,
      "step": 20600
    },
    {
      "epoch": 1.4233651928762978,
      "grad_norm": 0.2111658751964569,
      "learning_rate": 4.11096498014338e-05,
      "loss": 0.0425,
      "step": 20700
    },
    {
      "epoch": 1.4302413532283573,
      "grad_norm": 0.10841120034456253,
      "learning_rate": 4.106667010504238e-05,
      "loss": 0.0406,
      "step": 20800
    },
    {
      "epoch": 1.4371175135804166,
      "grad_norm": 0.32450035214424133,
      "learning_rate": 4.1023690408650955e-05,
      "loss": 0.0429,
      "step": 20900
    },
    {
      "epoch": 1.4439936739324761,
      "grad_norm": 0.1771230846643448,
      "learning_rate": 4.098071071225953e-05,
      "loss": 0.0444,
      "step": 21000
    },
    {
      "epoch": 1.4508698342845356,
      "grad_norm": 0.20459146797657013,
      "learning_rate": 4.093773101586811e-05,
      "loss": 0.0431,
      "step": 21100
    },
    {
      "epoch": 1.457745994636595,
      "grad_norm": 0.24019719660282135,
      "learning_rate": 4.089475131947668e-05,
      "loss": 0.0429,
      "step": 21200
    },
    {
      "epoch": 1.4646221549886542,
      "grad_norm": 0.17105631530284882,
      "learning_rate": 4.085177162308526e-05,
      "loss": 0.0423,
      "step": 21300
    },
    {
      "epoch": 1.4714983153407137,
      "grad_norm": 0.261823445558548,
      "learning_rate": 4.080879192669383e-05,
      "loss": 0.0393,
      "step": 21400
    },
    {
      "epoch": 1.4783744756927732,
      "grad_norm": 0.15693870186805725,
      "learning_rate": 4.0765812230302405e-05,
      "loss": 0.0436,
      "step": 21500
    },
    {
      "epoch": 1.4852506360448325,
      "grad_norm": 0.1831698715686798,
      "learning_rate": 4.0723262330874894e-05,
      "loss": 0.0413,
      "step": 21600
    },
    {
      "epoch": 1.492126796396892,
      "grad_norm": 0.1692650467157364,
      "learning_rate": 4.0680282634483475e-05,
      "loss": 0.0434,
      "step": 21700
    },
    {
      "epoch": 1.4990029567489513,
      "grad_norm": 0.14211714267730713,
      "learning_rate": 4.063730293809205e-05,
      "loss": 0.0405,
      "step": 21800
    },
    {
      "epoch": 1.5058791171010109,
      "grad_norm": 0.12555591762065887,
      "learning_rate": 4.059432324170062e-05,
      "loss": 0.0412,
      "step": 21900
    },
    {
      "epoch": 1.5127552774530701,
      "grad_norm": 0.20844875276088715,
      "learning_rate": 4.05513435453092e-05,
      "loss": 0.0407,
      "step": 22000
    },
    {
      "epoch": 1.5196314378051297,
      "grad_norm": 0.19813449680805206,
      "learning_rate": 4.050836384891778e-05,
      "loss": 0.0399,
      "step": 22100
    },
    {
      "epoch": 1.5265075981571892,
      "grad_norm": 0.16567185521125793,
      "learning_rate": 4.0465384152526344e-05,
      "loss": 0.0406,
      "step": 22200
    },
    {
      "epoch": 1.5333837585092485,
      "grad_norm": 0.21355731785297394,
      "learning_rate": 4.042240445613492e-05,
      "loss": 0.0424,
      "step": 22300
    },
    {
      "epoch": 1.5402599188613078,
      "grad_norm": 0.39573606848716736,
      "learning_rate": 4.03794247597435e-05,
      "loss": 0.044,
      "step": 22400
    },
    {
      "epoch": 1.5471360792133673,
      "grad_norm": 0.11644116044044495,
      "learning_rate": 4.033644506335207e-05,
      "loss": 0.0384,
      "step": 22500
    },
    {
      "epoch": 1.5540122395654268,
      "grad_norm": 0.23567961156368256,
      "learning_rate": 4.029346536696065e-05,
      "loss": 0.0409,
      "step": 22600
    },
    {
      "epoch": 1.560888399917486,
      "grad_norm": 0.28634053468704224,
      "learning_rate": 4.025048567056923e-05,
      "loss": 0.0409,
      "step": 22700
    },
    {
      "epoch": 1.5677645602695454,
      "grad_norm": 0.18536217510700226,
      "learning_rate": 4.02075059741778e-05,
      "loss": 0.0427,
      "step": 22800
    },
    {
      "epoch": 1.5746407206216049,
      "grad_norm": 0.22469310462474823,
      "learning_rate": 4.0164526277786375e-05,
      "loss": 0.0409,
      "step": 22900
    },
    {
      "epoch": 1.5815168809736644,
      "grad_norm": 0.15583890676498413,
      "learning_rate": 4.0121546581394956e-05,
      "loss": 0.0403,
      "step": 23000
    },
    {
      "epoch": 1.5883930413257237,
      "grad_norm": 0.15191702544689178,
      "learning_rate": 4.007856688500353e-05,
      "loss": 0.0396,
      "step": 23100
    },
    {
      "epoch": 1.595269201677783,
      "grad_norm": 0.13509942591190338,
      "learning_rate": 4.00355871886121e-05,
      "loss": 0.0373,
      "step": 23200
    },
    {
      "epoch": 1.6021453620298427,
      "grad_norm": 0.17166203260421753,
      "learning_rate": 3.999260749222068e-05,
      "loss": 0.0401,
      "step": 23300
    },
    {
      "epoch": 1.609021522381902,
      "grad_norm": 0.16522827744483948,
      "learning_rate": 3.994962779582925e-05,
      "loss": 0.0387,
      "step": 23400
    },
    {
      "epoch": 1.6158976827339613,
      "grad_norm": 0.35744789242744446,
      "learning_rate": 3.9906648099437826e-05,
      "loss": 0.0422,
      "step": 23500
    },
    {
      "epoch": 1.6227738430860208,
      "grad_norm": 0.15835905075073242,
      "learning_rate": 3.98636684030464e-05,
      "loss": 0.0405,
      "step": 23600
    },
    {
      "epoch": 1.6296500034380803,
      "grad_norm": 0.16886202991008759,
      "learning_rate": 3.982068870665498e-05,
      "loss": 0.0397,
      "step": 23700
    },
    {
      "epoch": 1.6365261637901396,
      "grad_norm": 0.23618584871292114,
      "learning_rate": 3.9777709010263554e-05,
      "loss": 0.0398,
      "step": 23800
    },
    {
      "epoch": 1.643402324142199,
      "grad_norm": 0.2554340064525604,
      "learning_rate": 3.973472931387213e-05,
      "loss": 0.043,
      "step": 23900
    },
    {
      "epoch": 1.6502784844942584,
      "grad_norm": 0.19017763435840607,
      "learning_rate": 3.969174961748071e-05,
      "loss": 0.0417,
      "step": 24000
    },
    {
      "epoch": 1.657154644846318,
      "grad_norm": 0.20918633043766022,
      "learning_rate": 3.964876992108928e-05,
      "loss": 0.0421,
      "step": 24100
    },
    {
      "epoch": 1.6640308051983772,
      "grad_norm": 0.10912332683801651,
      "learning_rate": 3.960579022469785e-05,
      "loss": 0.0399,
      "step": 24200
    },
    {
      "epoch": 1.6709069655504365,
      "grad_norm": 0.19169881939888,
      "learning_rate": 3.956281052830643e-05,
      "loss": 0.0381,
      "step": 24300
    },
    {
      "epoch": 1.677783125902496,
      "grad_norm": 0.19053219258785248,
      "learning_rate": 3.9519830831915004e-05,
      "loss": 0.0407,
      "step": 24400
    },
    {
      "epoch": 1.6846592862545555,
      "grad_norm": 0.18667460978031158,
      "learning_rate": 3.947685113552358e-05,
      "loss": 0.0386,
      "step": 24500
    },
    {
      "epoch": 1.6915354466066148,
      "grad_norm": 0.18922856450080872,
      "learning_rate": 3.943387143913216e-05,
      "loss": 0.0396,
      "step": 24600
    },
    {
      "epoch": 1.6984116069586743,
      "grad_norm": 0.25319480895996094,
      "learning_rate": 3.939089174274073e-05,
      "loss": 0.0419,
      "step": 24700
    },
    {
      "epoch": 1.7052877673107338,
      "grad_norm": 0.18614962697029114,
      "learning_rate": 3.934791204634931e-05,
      "loss": 0.0414,
      "step": 24800
    },
    {
      "epoch": 1.7121639276627931,
      "grad_norm": 0.1543850302696228,
      "learning_rate": 3.930493234995788e-05,
      "loss": 0.0406,
      "step": 24900
    },
    {
      "epoch": 1.7190400880148524,
      "grad_norm": 0.1359282284975052,
      "learning_rate": 3.926195265356646e-05,
      "loss": 0.0399,
      "step": 25000
    },
    {
      "epoch": 1.725916248366912,
      "grad_norm": 0.2621394693851471,
      "learning_rate": 3.9218972957175035e-05,
      "loss": 0.0417,
      "step": 25100
    },
    {
      "epoch": 1.7327924087189714,
      "grad_norm": 0.26815253496170044,
      "learning_rate": 3.91759932607836e-05,
      "loss": 0.0421,
      "step": 25200
    },
    {
      "epoch": 1.7396685690710307,
      "grad_norm": 0.1849096268415451,
      "learning_rate": 3.913301356439218e-05,
      "loss": 0.0387,
      "step": 25300
    },
    {
      "epoch": 1.74654472942309,
      "grad_norm": 0.13157077133655548,
      "learning_rate": 3.909046366496467e-05,
      "loss": 0.0387,
      "step": 25400
    },
    {
      "epoch": 1.7534208897751495,
      "grad_norm": 0.19738250970840454,
      "learning_rate": 3.9047483968573246e-05,
      "loss": 0.0388,
      "step": 25500
    },
    {
      "epoch": 1.760297050127209,
      "grad_norm": 0.19361698627471924,
      "learning_rate": 3.900450427218183e-05,
      "loss": 0.0399,
      "step": 25600
    },
    {
      "epoch": 1.7671732104792683,
      "grad_norm": 0.309450626373291,
      "learning_rate": 3.89615245757904e-05,
      "loss": 0.0422,
      "step": 25700
    },
    {
      "epoch": 1.7740493708313276,
      "grad_norm": 0.16107861697673798,
      "learning_rate": 3.8918544879398975e-05,
      "loss": 0.0433,
      "step": 25800
    },
    {
      "epoch": 1.7809255311833871,
      "grad_norm": 0.16338998079299927,
      "learning_rate": 3.887556518300755e-05,
      "loss": 0.0416,
      "step": 25900
    },
    {
      "epoch": 1.7878016915354467,
      "grad_norm": 0.14908605813980103,
      "learning_rate": 3.883258548661612e-05,
      "loss": 0.0398,
      "step": 26000
    },
    {
      "epoch": 1.794677851887506,
      "grad_norm": 0.22578522562980652,
      "learning_rate": 3.8789605790224696e-05,
      "loss": 0.04,
      "step": 26100
    },
    {
      "epoch": 1.8015540122395655,
      "grad_norm": 0.16384123265743256,
      "learning_rate": 3.874662609383328e-05,
      "loss": 0.0388,
      "step": 26200
    },
    {
      "epoch": 1.808430172591625,
      "grad_norm": 0.15639863908290863,
      "learning_rate": 3.870364639744185e-05,
      "loss": 0.0394,
      "step": 26300
    },
    {
      "epoch": 1.8153063329436843,
      "grad_norm": 0.18659837543964386,
      "learning_rate": 3.8660666701050425e-05,
      "loss": 0.0407,
      "step": 26400
    },
    {
      "epoch": 1.8221824932957436,
      "grad_norm": 0.1521868258714676,
      "learning_rate": 3.8617687004659005e-05,
      "loss": 0.0435,
      "step": 26500
    },
    {
      "epoch": 1.829058653647803,
      "grad_norm": 0.13155028223991394,
      "learning_rate": 3.857470730826758e-05,
      "loss": 0.0422,
      "step": 26600
    },
    {
      "epoch": 1.8359348139998626,
      "grad_norm": 0.18468555808067322,
      "learning_rate": 3.853172761187615e-05,
      "loss": 0.0416,
      "step": 26700
    },
    {
      "epoch": 1.8428109743519219,
      "grad_norm": 0.17542850971221924,
      "learning_rate": 3.848874791548473e-05,
      "loss": 0.0394,
      "step": 26800
    },
    {
      "epoch": 1.8496871347039812,
      "grad_norm": 0.24123544991016388,
      "learning_rate": 3.84457682190933e-05,
      "loss": 0.0404,
      "step": 26900
    },
    {
      "epoch": 1.8565632950560407,
      "grad_norm": 0.15866148471832275,
      "learning_rate": 3.8402788522701875e-05,
      "loss": 0.0396,
      "step": 27000
    },
    {
      "epoch": 1.8634394554081002,
      "grad_norm": 0.15120992064476013,
      "learning_rate": 3.835980882631045e-05,
      "loss": 0.0404,
      "step": 27100
    },
    {
      "epoch": 1.8703156157601595,
      "grad_norm": 0.1958191841840744,
      "learning_rate": 3.831682912991903e-05,
      "loss": 0.0414,
      "step": 27200
    },
    {
      "epoch": 1.877191776112219,
      "grad_norm": 0.16028933227062225,
      "learning_rate": 3.8273849433527604e-05,
      "loss": 0.0406,
      "step": 27300
    },
    {
      "epoch": 1.8840679364642785,
      "grad_norm": 0.1913301646709442,
      "learning_rate": 3.823086973713618e-05,
      "loss": 0.0391,
      "step": 27400
    },
    {
      "epoch": 1.8909440968163378,
      "grad_norm": 0.14250651001930237,
      "learning_rate": 3.818789004074476e-05,
      "loss": 0.0396,
      "step": 27500
    },
    {
      "epoch": 1.897820257168397,
      "grad_norm": 0.22113095223903656,
      "learning_rate": 3.814491034435333e-05,
      "loss": 0.0403,
      "step": 27600
    },
    {
      "epoch": 1.9046964175204566,
      "grad_norm": 0.20645371079444885,
      "learning_rate": 3.8101930647961906e-05,
      "loss": 0.0415,
      "step": 27700
    },
    {
      "epoch": 1.911572577872516,
      "grad_norm": 0.2568794786930084,
      "learning_rate": 3.805895095157048e-05,
      "loss": 0.0405,
      "step": 27800
    },
    {
      "epoch": 1.9184487382245754,
      "grad_norm": 0.18594010174274445,
      "learning_rate": 3.8015971255179054e-05,
      "loss": 0.0431,
      "step": 27900
    },
    {
      "epoch": 1.9253248985766347,
      "grad_norm": 0.2012467086315155,
      "learning_rate": 3.797299155878763e-05,
      "loss": 0.0386,
      "step": 28000
    },
    {
      "epoch": 1.9322010589286942,
      "grad_norm": 0.23324701189994812,
      "learning_rate": 3.79300118623962e-05,
      "loss": 0.039,
      "step": 28100
    },
    {
      "epoch": 1.9390772192807537,
      "grad_norm": 0.1917525976896286,
      "learning_rate": 3.788703216600478e-05,
      "loss": 0.0439,
      "step": 28200
    },
    {
      "epoch": 1.945953379632813,
      "grad_norm": 0.22739854454994202,
      "learning_rate": 3.7844052469613356e-05,
      "loss": 0.0373,
      "step": 28300
    },
    {
      "epoch": 1.9528295399848723,
      "grad_norm": 0.158802330493927,
      "learning_rate": 3.780107277322193e-05,
      "loss": 0.0389,
      "step": 28400
    },
    {
      "epoch": 1.9597057003369318,
      "grad_norm": 0.2284075915813446,
      "learning_rate": 3.775809307683051e-05,
      "loss": 0.0386,
      "step": 28500
    },
    {
      "epoch": 1.9665818606889913,
      "grad_norm": 0.1937025636434555,
      "learning_rate": 3.7715113380439085e-05,
      "loss": 0.0396,
      "step": 28600
    },
    {
      "epoch": 1.9734580210410506,
      "grad_norm": 0.12758763134479523,
      "learning_rate": 3.767213368404766e-05,
      "loss": 0.0389,
      "step": 28700
    },
    {
      "epoch": 1.9803341813931101,
      "grad_norm": 0.1897493451833725,
      "learning_rate": 3.762915398765623e-05,
      "loss": 0.0418,
      "step": 28800
    },
    {
      "epoch": 1.9872103417451696,
      "grad_norm": 0.23266851902008057,
      "learning_rate": 3.7586174291264806e-05,
      "loss": 0.0405,
      "step": 28900
    },
    {
      "epoch": 1.994086502097229,
      "grad_norm": 0.11285828799009323,
      "learning_rate": 3.754319459487338e-05,
      "loss": 0.041,
      "step": 29000
    },
    {
      "epoch": 2.0,
      "eval_accuracy_macro_0.5": 0.9819120764732361,
      "eval_accuracy_micro_0.5": 0.9819120764732361,
      "eval_accuracy_weighted_0.5": 0.9794146418571472,
      "eval_f1_macro_0.5": 0.7553628087043762,
      "eval_f1_macro_0.6": 0.7336955070495605,
      "eval_f1_macro_0.7": 0.6960300803184509,
      "eval_f1_macro_0.8": 0.5211027264595032,
      "eval_f1_micro_0.5": 0.757415235042572,
      "eval_f1_micro_0.6": 0.7402369379997253,
      "eval_f1_micro_0.7": 0.7084648609161377,
      "eval_f1_micro_0.8": 0.6549508571624756,
      "eval_f1_micro_0.9": 0.5470885038375854,
      "eval_f1_weighted_0.5": 0.7504229545593262,
      "eval_f1_weighted_0.6": 0.7288094758987427,
      "eval_f1_weighted_0.7": 0.6910998225212097,
      "eval_f1_weighted_0.8": 0.5116682052612305,
      "eval_loss": 0.037016384303569794,
      "eval_runtime": 133.5805,
      "eval_samples_per_second": 217.375,
      "eval_steps_per_second": 27.175,
      "step": 29086
    },
    {
      "epoch": 2.000962662449288,
      "grad_norm": 0.1328369379043579,
      "learning_rate": 3.7500644695445876e-05,
      "loss": 0.0395,
      "step": 29100
    },
    {
      "epoch": 2.0078388228013475,
      "grad_norm": 0.13785815238952637,
      "learning_rate": 3.745766499905445e-05,
      "loss": 0.0382,
      "step": 29200
    },
    {
      "epoch": 2.0147149831534072,
      "grad_norm": 0.21936103701591492,
      "learning_rate": 3.7414685302663024e-05,
      "loss": 0.0408,
      "step": 29300
    },
    {
      "epoch": 2.0215911435054665,
      "grad_norm": 0.1270023137331009,
      "learning_rate": 3.73717056062716e-05,
      "loss": 0.0419,
      "step": 29400
    },
    {
      "epoch": 2.028467303857526,
      "grad_norm": 0.2662513256072998,
      "learning_rate": 3.732872590988017e-05,
      "loss": 0.0399,
      "step": 29500
    },
    {
      "epoch": 2.0353434642095856,
      "grad_norm": 0.16256321966648102,
      "learning_rate": 3.7285746213488746e-05,
      "loss": 0.0346,
      "step": 29600
    },
    {
      "epoch": 2.042219624561645,
      "grad_norm": 0.14189819991588593,
      "learning_rate": 3.7242766517097326e-05,
      "loss": 0.0394,
      "step": 29700
    },
    {
      "epoch": 2.049095784913704,
      "grad_norm": 0.29059848189353943,
      "learning_rate": 3.71997868207059e-05,
      "loss": 0.0377,
      "step": 29800
    },
    {
      "epoch": 2.0559719452657634,
      "grad_norm": 0.09416559338569641,
      "learning_rate": 3.7156807124314474e-05,
      "loss": 0.0406,
      "step": 29900
    },
    {
      "epoch": 2.062848105617823,
      "grad_norm": 0.1566605418920517,
      "learning_rate": 3.7113827427923055e-05,
      "loss": 0.0364,
      "step": 30000
    },
    {
      "epoch": 2.0697242659698825,
      "grad_norm": 0.21195495128631592,
      "learning_rate": 3.707084773153163e-05,
      "loss": 0.0382,
      "step": 30100
    },
    {
      "epoch": 2.0766004263219418,
      "grad_norm": 0.08033007383346558,
      "learning_rate": 3.702829783210411e-05,
      "loss": 0.0388,
      "step": 30200
    },
    {
      "epoch": 2.083476586674001,
      "grad_norm": 0.24289800226688385,
      "learning_rate": 3.698531813571269e-05,
      "loss": 0.037,
      "step": 30300
    },
    {
      "epoch": 2.0903527470260608,
      "grad_norm": 0.18926352262496948,
      "learning_rate": 3.6942338439321266e-05,
      "loss": 0.0384,
      "step": 30400
    },
    {
      "epoch": 2.09722890737812,
      "grad_norm": 0.22804707288742065,
      "learning_rate": 3.689935874292984e-05,
      "loss": 0.0404,
      "step": 30500
    },
    {
      "epoch": 2.1041050677301794,
      "grad_norm": 0.27178633213043213,
      "learning_rate": 3.685637904653842e-05,
      "loss": 0.0392,
      "step": 30600
    },
    {
      "epoch": 2.110981228082239,
      "grad_norm": 0.15344560146331787,
      "learning_rate": 3.6813399350146994e-05,
      "loss": 0.0421,
      "step": 30700
    },
    {
      "epoch": 2.1178573884342984,
      "grad_norm": 0.13630183041095734,
      "learning_rate": 3.677041965375557e-05,
      "loss": 0.0398,
      "step": 30800
    },
    {
      "epoch": 2.1247335487863577,
      "grad_norm": 0.1751548945903778,
      "learning_rate": 3.672743995736414e-05,
      "loss": 0.0379,
      "step": 30900
    },
    {
      "epoch": 2.131609709138417,
      "grad_norm": 0.18598172068595886,
      "learning_rate": 3.668446026097272e-05,
      "loss": 0.0388,
      "step": 31000
    },
    {
      "epoch": 2.1384858694904767,
      "grad_norm": 0.14885827898979187,
      "learning_rate": 3.664148056458129e-05,
      "loss": 0.0406,
      "step": 31100
    },
    {
      "epoch": 2.145362029842536,
      "grad_norm": 0.15624074637889862,
      "learning_rate": 3.6598500868189864e-05,
      "loss": 0.037,
      "step": 31200
    },
    {
      "epoch": 2.1522381901945953,
      "grad_norm": 0.1828087717294693,
      "learning_rate": 3.6555521171798445e-05,
      "loss": 0.0373,
      "step": 31300
    },
    {
      "epoch": 2.1591143505466546,
      "grad_norm": 0.2616032361984253,
      "learning_rate": 3.651254147540702e-05,
      "loss": 0.0377,
      "step": 31400
    },
    {
      "epoch": 2.1659905108987143,
      "grad_norm": 0.20771373808383942,
      "learning_rate": 3.646956177901559e-05,
      "loss": 0.0372,
      "step": 31500
    },
    {
      "epoch": 2.1728666712507736,
      "grad_norm": 0.14718836545944214,
      "learning_rate": 3.642658208262417e-05,
      "loss": 0.0398,
      "step": 31600
    },
    {
      "epoch": 2.179742831602833,
      "grad_norm": 0.10803758352994919,
      "learning_rate": 3.638360238623275e-05,
      "loss": 0.0381,
      "step": 31700
    },
    {
      "epoch": 2.1866189919548926,
      "grad_norm": 0.20949847996234894,
      "learning_rate": 3.634062268984132e-05,
      "loss": 0.0339,
      "step": 31800
    },
    {
      "epoch": 2.193495152306952,
      "grad_norm": 0.15847137570381165,
      "learning_rate": 3.62976429934499e-05,
      "loss": 0.0375,
      "step": 31900
    },
    {
      "epoch": 2.200371312659011,
      "grad_norm": 0.08927534520626068,
      "learning_rate": 3.6254663297058475e-05,
      "loss": 0.0375,
      "step": 32000
    },
    {
      "epoch": 2.2072474730110705,
      "grad_norm": 0.15201741456985474,
      "learning_rate": 3.621168360066704e-05,
      "loss": 0.0373,
      "step": 32100
    },
    {
      "epoch": 2.2141236333631302,
      "grad_norm": 0.2606908082962036,
      "learning_rate": 3.6168703904275616e-05,
      "loss": 0.0417,
      "step": 32200
    },
    {
      "epoch": 2.2209997937151895,
      "grad_norm": 0.18366293609142303,
      "learning_rate": 3.61257242078842e-05,
      "loss": 0.0375,
      "step": 32300
    },
    {
      "epoch": 2.227875954067249,
      "grad_norm": 0.15931566059589386,
      "learning_rate": 3.608274451149277e-05,
      "loss": 0.0359,
      "step": 32400
    },
    {
      "epoch": 2.234752114419308,
      "grad_norm": 0.2574164569377899,
      "learning_rate": 3.6039764815101345e-05,
      "loss": 0.0378,
      "step": 32500
    },
    {
      "epoch": 2.241628274771368,
      "grad_norm": 0.27226492762565613,
      "learning_rate": 3.5996785118709926e-05,
      "loss": 0.0353,
      "step": 32600
    },
    {
      "epoch": 2.248504435123427,
      "grad_norm": 0.2476149946451187,
      "learning_rate": 3.59538054223185e-05,
      "loss": 0.0392,
      "step": 32700
    },
    {
      "epoch": 2.2553805954754864,
      "grad_norm": 0.1975022554397583,
      "learning_rate": 3.5910825725927074e-05,
      "loss": 0.0382,
      "step": 32800
    },
    {
      "epoch": 2.2622567558275457,
      "grad_norm": 0.1688680201768875,
      "learning_rate": 3.5867846029535654e-05,
      "loss": 0.0359,
      "step": 32900
    },
    {
      "epoch": 2.2691329161796054,
      "grad_norm": 0.23579499125480652,
      "learning_rate": 3.582486633314422e-05,
      "loss": 0.0394,
      "step": 33000
    },
    {
      "epoch": 2.2760090765316647,
      "grad_norm": 0.20943836867809296,
      "learning_rate": 3.5781886636752795e-05,
      "loss": 0.038,
      "step": 33100
    },
    {
      "epoch": 2.282885236883724,
      "grad_norm": 0.16262872517108917,
      "learning_rate": 3.5738906940361376e-05,
      "loss": 0.041,
      "step": 33200
    },
    {
      "epoch": 2.2897613972357833,
      "grad_norm": 0.18499544262886047,
      "learning_rate": 3.569592724396995e-05,
      "loss": 0.04,
      "step": 33300
    },
    {
      "epoch": 2.296637557587843,
      "grad_norm": 0.2290973961353302,
      "learning_rate": 3.5652947547578524e-05,
      "loss": 0.0411,
      "step": 33400
    },
    {
      "epoch": 2.3035137179399023,
      "grad_norm": 0.18718864023685455,
      "learning_rate": 3.56099678511871e-05,
      "loss": 0.0383,
      "step": 33500
    },
    {
      "epoch": 2.3103898782919616,
      "grad_norm": 0.24620144069194794,
      "learning_rate": 3.556698815479568e-05,
      "loss": 0.0402,
      "step": 33600
    },
    {
      "epoch": 2.3172660386440214,
      "grad_norm": 0.21404039859771729,
      "learning_rate": 3.552400845840425e-05,
      "loss": 0.0403,
      "step": 33700
    },
    {
      "epoch": 2.3241421989960807,
      "grad_norm": 0.1925223022699356,
      "learning_rate": 3.5481028762012826e-05,
      "loss": 0.034,
      "step": 33800
    },
    {
      "epoch": 2.33101835934814,
      "grad_norm": 0.19146396219730377,
      "learning_rate": 3.543804906562141e-05,
      "loss": 0.0383,
      "step": 33900
    },
    {
      "epoch": 2.3378945197001992,
      "grad_norm": 0.17000073194503784,
      "learning_rate": 3.5395069369229974e-05,
      "loss": 0.0387,
      "step": 34000
    },
    {
      "epoch": 2.344770680052259,
      "grad_norm": 0.26013901829719543,
      "learning_rate": 3.535208967283855e-05,
      "loss": 0.0407,
      "step": 34100
    },
    {
      "epoch": 2.3516468404043183,
      "grad_norm": 0.16518698632717133,
      "learning_rate": 3.530910997644713e-05,
      "loss": 0.0408,
      "step": 34200
    },
    {
      "epoch": 2.3585230007563776,
      "grad_norm": 0.16381914913654327,
      "learning_rate": 3.52661302800557e-05,
      "loss": 0.036,
      "step": 34300
    },
    {
      "epoch": 2.365399161108437,
      "grad_norm": 0.23248402774333954,
      "learning_rate": 3.5223150583664276e-05,
      "loss": 0.035,
      "step": 34400
    },
    {
      "epoch": 2.3722753214604966,
      "grad_norm": 0.18341553211212158,
      "learning_rate": 3.518017088727286e-05,
      "loss": 0.0397,
      "step": 34500
    },
    {
      "epoch": 2.379151481812556,
      "grad_norm": 0.12151126563549042,
      "learning_rate": 3.513719119088143e-05,
      "loss": 0.0371,
      "step": 34600
    },
    {
      "epoch": 2.386027642164615,
      "grad_norm": 0.17813242971897125,
      "learning_rate": 3.5094211494490005e-05,
      "loss": 0.0392,
      "step": 34700
    },
    {
      "epoch": 2.392903802516675,
      "grad_norm": 0.05084223672747612,
      "learning_rate": 3.505123179809858e-05,
      "loss": 0.0397,
      "step": 34800
    },
    {
      "epoch": 2.399779962868734,
      "grad_norm": 0.1511773020029068,
      "learning_rate": 3.500825210170716e-05,
      "loss": 0.0358,
      "step": 34900
    },
    {
      "epoch": 2.4066561232207935,
      "grad_norm": 0.15389898419380188,
      "learning_rate": 3.496527240531573e-05,
      "loss": 0.041,
      "step": 35000
    },
    {
      "epoch": 2.4135322835728528,
      "grad_norm": 0.13902567327022552,
      "learning_rate": 3.49222927089243e-05,
      "loss": 0.037,
      "step": 35100
    },
    {
      "epoch": 2.4204084439249125,
      "grad_norm": 0.2130761593580246,
      "learning_rate": 3.487931301253288e-05,
      "loss": 0.0371,
      "step": 35200
    },
    {
      "epoch": 2.427284604276972,
      "grad_norm": 0.14470654726028442,
      "learning_rate": 3.4836333316141455e-05,
      "loss": 0.0395,
      "step": 35300
    },
    {
      "epoch": 2.434160764629031,
      "grad_norm": 0.17574995756149292,
      "learning_rate": 3.479335361975003e-05,
      "loss": 0.0363,
      "step": 35400
    },
    {
      "epoch": 2.4410369249810904,
      "grad_norm": 0.21811869740486145,
      "learning_rate": 3.475037392335861e-05,
      "loss": 0.0414,
      "step": 35500
    },
    {
      "epoch": 2.44791308533315,
      "grad_norm": 0.20885835587978363,
      "learning_rate": 3.4707394226967184e-05,
      "loss": 0.0405,
      "step": 35600
    },
    {
      "epoch": 2.4547892456852094,
      "grad_norm": 0.2703278064727783,
      "learning_rate": 3.466441453057576e-05,
      "loss": 0.0369,
      "step": 35700
    },
    {
      "epoch": 2.4616654060372687,
      "grad_norm": 0.24253857135772705,
      "learning_rate": 3.462143483418434e-05,
      "loss": 0.0392,
      "step": 35800
    },
    {
      "epoch": 2.4685415663893284,
      "grad_norm": 0.1390773206949234,
      "learning_rate": 3.457888493475682e-05,
      "loss": 0.0378,
      "step": 35900
    },
    {
      "epoch": 2.4754177267413877,
      "grad_norm": 0.26695477962493896,
      "learning_rate": 3.4535905238365394e-05,
      "loss": 0.036,
      "step": 36000
    },
    {
      "epoch": 2.482293887093447,
      "grad_norm": 0.10168452560901642,
      "learning_rate": 3.4492925541973975e-05,
      "loss": 0.0383,
      "step": 36100
    },
    {
      "epoch": 2.4891700474455063,
      "grad_norm": 0.14589639008045197,
      "learning_rate": 3.444994584558255e-05,
      "loss": 0.0402,
      "step": 36200
    },
    {
      "epoch": 2.496046207797566,
      "grad_norm": 0.14640089869499207,
      "learning_rate": 3.440696614919112e-05,
      "loss": 0.0388,
      "step": 36300
    },
    {
      "epoch": 2.5029223681496253,
      "grad_norm": 0.10055579245090485,
      "learning_rate": 3.4363986452799704e-05,
      "loss": 0.0386,
      "step": 36400
    },
    {
      "epoch": 2.5097985285016846,
      "grad_norm": 0.23090484738349915,
      "learning_rate": 3.432100675640828e-05,
      "loss": 0.038,
      "step": 36500
    },
    {
      "epoch": 2.516674688853744,
      "grad_norm": 0.23077735304832458,
      "learning_rate": 3.427802706001685e-05,
      "loss": 0.0366,
      "step": 36600
    },
    {
      "epoch": 2.5235508492058036,
      "grad_norm": 0.19040964543819427,
      "learning_rate": 3.4235047363625425e-05,
      "loss": 0.0383,
      "step": 36700
    },
    {
      "epoch": 2.530427009557863,
      "grad_norm": 0.1646498590707779,
      "learning_rate": 3.4192067667234e-05,
      "loss": 0.0376,
      "step": 36800
    },
    {
      "epoch": 2.537303169909922,
      "grad_norm": 0.07394932955503464,
      "learning_rate": 3.414908797084257e-05,
      "loss": 0.0373,
      "step": 36900
    },
    {
      "epoch": 2.544179330261982,
      "grad_norm": 0.14642272889614105,
      "learning_rate": 3.410610827445115e-05,
      "loss": 0.0365,
      "step": 37000
    },
    {
      "epoch": 2.5510554906140412,
      "grad_norm": 0.18483050167560577,
      "learning_rate": 3.406312857805973e-05,
      "loss": 0.0381,
      "step": 37100
    },
    {
      "epoch": 2.5579316509661005,
      "grad_norm": 0.18344135582447052,
      "learning_rate": 3.40201488816683e-05,
      "loss": 0.0377,
      "step": 37200
    },
    {
      "epoch": 2.56480781131816,
      "grad_norm": 0.1598997563123703,
      "learning_rate": 3.3977169185276876e-05,
      "loss": 0.0374,
      "step": 37300
    },
    {
      "epoch": 2.571683971670219,
      "grad_norm": 0.18013513088226318,
      "learning_rate": 3.3934189488885456e-05,
      "loss": 0.0365,
      "step": 37400
    },
    {
      "epoch": 2.578560132022279,
      "grad_norm": 0.16331630945205688,
      "learning_rate": 3.389120979249403e-05,
      "loss": 0.0401,
      "step": 37500
    },
    {
      "epoch": 2.585436292374338,
      "grad_norm": 0.23396721482276917,
      "learning_rate": 3.3848230096102604e-05,
      "loss": 0.0368,
      "step": 37600
    },
    {
      "epoch": 2.5923124527263974,
      "grad_norm": 0.1711433231830597,
      "learning_rate": 3.380525039971118e-05,
      "loss": 0.0387,
      "step": 37700
    },
    {
      "epoch": 2.599188613078457,
      "grad_norm": 0.14910101890563965,
      "learning_rate": 3.376227070331975e-05,
      "loss": 0.0382,
      "step": 37800
    },
    {
      "epoch": 2.6060647734305165,
      "grad_norm": 0.1686888188123703,
      "learning_rate": 3.3719291006928326e-05,
      "loss": 0.0356,
      "step": 37900
    },
    {
      "epoch": 2.6129409337825757,
      "grad_norm": 0.24113473296165466,
      "learning_rate": 3.367674110750082e-05,
      "loss": 0.0403,
      "step": 38000
    },
    {
      "epoch": 2.6198170941346355,
      "grad_norm": 0.14475828409194946,
      "learning_rate": 3.3633761411109396e-05,
      "loss": 0.0381,
      "step": 38100
    },
    {
      "epoch": 2.6266932544866948,
      "grad_norm": 0.17808207869529724,
      "learning_rate": 3.359078171471797e-05,
      "loss": 0.0363,
      "step": 38200
    },
    {
      "epoch": 2.633569414838754,
      "grad_norm": 0.2065141499042511,
      "learning_rate": 3.3547802018326543e-05,
      "loss": 0.0389,
      "step": 38300
    },
    {
      "epoch": 2.6404455751908134,
      "grad_norm": 0.042704321444034576,
      "learning_rate": 3.350482232193512e-05,
      "loss": 0.034,
      "step": 38400
    },
    {
      "epoch": 2.6473217355428726,
      "grad_norm": 0.15427741408348083,
      "learning_rate": 3.346184262554369e-05,
      "loss": 0.0392,
      "step": 38500
    },
    {
      "epoch": 2.6541978958949324,
      "grad_norm": 0.23556415736675262,
      "learning_rate": 3.341886292915227e-05,
      "loss": 0.0338,
      "step": 38600
    },
    {
      "epoch": 2.6610740562469917,
      "grad_norm": 0.24150942265987396,
      "learning_rate": 3.3375883232760846e-05,
      "loss": 0.0385,
      "step": 38700
    },
    {
      "epoch": 2.667950216599051,
      "grad_norm": 0.23486833274364471,
      "learning_rate": 3.333290353636942e-05,
      "loss": 0.0401,
      "step": 38800
    },
    {
      "epoch": 2.6748263769511107,
      "grad_norm": 0.15933442115783691,
      "learning_rate": 3.3289923839977994e-05,
      "loss": 0.0345,
      "step": 38900
    },
    {
      "epoch": 2.68170253730317,
      "grad_norm": 0.2497951239347458,
      "learning_rate": 3.3246944143586574e-05,
      "loss": 0.0377,
      "step": 39000
    },
    {
      "epoch": 2.6885786976552293,
      "grad_norm": 0.188405379652977,
      "learning_rate": 3.320396444719515e-05,
      "loss": 0.0359,
      "step": 39100
    },
    {
      "epoch": 2.6954548580072886,
      "grad_norm": 0.24139167368412018,
      "learning_rate": 3.316098475080372e-05,
      "loss": 0.0377,
      "step": 39200
    },
    {
      "epoch": 2.7023310183593483,
      "grad_norm": 0.271266371011734,
      "learning_rate": 3.3118005054412296e-05,
      "loss": 0.0381,
      "step": 39300
    },
    {
      "epoch": 2.7092071787114076,
      "grad_norm": 0.22405724227428436,
      "learning_rate": 3.307502535802087e-05,
      "loss": 0.0384,
      "step": 39400
    },
    {
      "epoch": 2.716083339063467,
      "grad_norm": 0.17167629301548004,
      "learning_rate": 3.3032045661629444e-05,
      "loss": 0.0378,
      "step": 39500
    },
    {
      "epoch": 2.722959499415526,
      "grad_norm": 0.18580010533332825,
      "learning_rate": 3.2989065965238025e-05,
      "loss": 0.0383,
      "step": 39600
    },
    {
      "epoch": 2.729835659767586,
      "grad_norm": 0.19562305510044098,
      "learning_rate": 3.2946516065810514e-05,
      "loss": 0.0362,
      "step": 39700
    },
    {
      "epoch": 2.736711820119645,
      "grad_norm": 0.13870222866535187,
      "learning_rate": 3.290353636941909e-05,
      "loss": 0.0383,
      "step": 39800
    },
    {
      "epoch": 2.7435879804717045,
      "grad_norm": 0.14975136518478394,
      "learning_rate": 3.286055667302766e-05,
      "loss": 0.036,
      "step": 39900
    },
    {
      "epoch": 2.7504641408237642,
      "grad_norm": 0.20676466822624207,
      "learning_rate": 3.2817576976636235e-05,
      "loss": 0.0364,
      "step": 40000
    },
    {
      "epoch": 2.7573403011758235,
      "grad_norm": 0.14525040984153748,
      "learning_rate": 3.277459728024481e-05,
      "loss": 0.0372,
      "step": 40100
    },
    {
      "epoch": 2.764216461527883,
      "grad_norm": 0.17212927341461182,
      "learning_rate": 3.273161758385339e-05,
      "loss": 0.0338,
      "step": 40200
    },
    {
      "epoch": 2.771092621879942,
      "grad_norm": 0.19367636740207672,
      "learning_rate": 3.2688637887461964e-05,
      "loss": 0.0395,
      "step": 40300
    },
    {
      "epoch": 2.7779687822320014,
      "grad_norm": 0.1621217131614685,
      "learning_rate": 3.264565819107054e-05,
      "loss": 0.0386,
      "step": 40400
    },
    {
      "epoch": 2.784844942584061,
      "grad_norm": 0.2565452754497528,
      "learning_rate": 3.260267849467912e-05,
      "loss": 0.0381,
      "step": 40500
    },
    {
      "epoch": 2.7917211029361204,
      "grad_norm": 0.21677862107753754,
      "learning_rate": 3.255969879828769e-05,
      "loss": 0.0401,
      "step": 40600
    },
    {
      "epoch": 2.7985972632881797,
      "grad_norm": 0.1347069889307022,
      "learning_rate": 3.2516719101896266e-05,
      "loss": 0.0362,
      "step": 40700
    },
    {
      "epoch": 2.8054734236402394,
      "grad_norm": 0.11507982015609741,
      "learning_rate": 3.247373940550485e-05,
      "loss": 0.0364,
      "step": 40800
    },
    {
      "epoch": 2.8123495839922987,
      "grad_norm": 0.14847366511821747,
      "learning_rate": 3.243118950607733e-05,
      "loss": 0.0372,
      "step": 40900
    },
    {
      "epoch": 2.819225744344358,
      "grad_norm": 0.08236884325742722,
      "learning_rate": 3.23882098096859e-05,
      "loss": 0.0359,
      "step": 41000
    },
    {
      "epoch": 2.8261019046964178,
      "grad_norm": 0.23055356740951538,
      "learning_rate": 3.2345230113294484e-05,
      "loss": 0.0363,
      "step": 41100
    },
    {
      "epoch": 2.832978065048477,
      "grad_norm": 0.17954447865486145,
      "learning_rate": 3.230225041690306e-05,
      "loss": 0.0379,
      "step": 41200
    },
    {
      "epoch": 2.8398542254005363,
      "grad_norm": 0.21106666326522827,
      "learning_rate": 3.225927072051163e-05,
      "loss": 0.0361,
      "step": 41300
    },
    {
      "epoch": 2.8467303857525956,
      "grad_norm": 0.08008330315351486,
      "learning_rate": 3.221629102412021e-05,
      "loss": 0.0366,
      "step": 41400
    },
    {
      "epoch": 2.853606546104655,
      "grad_norm": 0.1772395819425583,
      "learning_rate": 3.2173311327728786e-05,
      "loss": 0.0348,
      "step": 41500
    },
    {
      "epoch": 2.8604827064567147,
      "grad_norm": 0.1272387057542801,
      "learning_rate": 3.213033163133736e-05,
      "loss": 0.0377,
      "step": 41600
    },
    {
      "epoch": 2.867358866808774,
      "grad_norm": 0.1715615689754486,
      "learning_rate": 3.208735193494593e-05,
      "loss": 0.0355,
      "step": 41700
    },
    {
      "epoch": 2.8742350271608332,
      "grad_norm": 0.2562015652656555,
      "learning_rate": 3.204437223855451e-05,
      "loss": 0.036,
      "step": 41800
    },
    {
      "epoch": 2.881111187512893,
      "grad_norm": 0.13381841778755188,
      "learning_rate": 3.200139254216308e-05,
      "loss": 0.038,
      "step": 41900
    },
    {
      "epoch": 2.8879873478649523,
      "grad_norm": 0.23779533803462982,
      "learning_rate": 3.1958412845771656e-05,
      "loss": 0.0373,
      "step": 42000
    },
    {
      "epoch": 2.8948635082170115,
      "grad_norm": 0.141560360789299,
      "learning_rate": 3.1915433149380237e-05,
      "loss": 0.0385,
      "step": 42100
    },
    {
      "epoch": 2.9017396685690713,
      "grad_norm": 0.16319552063941956,
      "learning_rate": 3.187245345298881e-05,
      "loss": 0.0354,
      "step": 42200
    },
    {
      "epoch": 2.9086158289211306,
      "grad_norm": 0.19247743487358093,
      "learning_rate": 3.1829473756597384e-05,
      "loss": 0.0345,
      "step": 42300
    },
    {
      "epoch": 2.91549198927319,
      "grad_norm": 0.13353121280670166,
      "learning_rate": 3.1786494060205965e-05,
      "loss": 0.0346,
      "step": 42400
    },
    {
      "epoch": 2.922368149625249,
      "grad_norm": 0.07766832411289215,
      "learning_rate": 3.174351436381454e-05,
      "loss": 0.0364,
      "step": 42500
    },
    {
      "epoch": 2.9292443099773084,
      "grad_norm": 0.10900229215621948,
      "learning_rate": 3.170053466742311e-05,
      "loss": 0.0375,
      "step": 42600
    },
    {
      "epoch": 2.936120470329368,
      "grad_norm": 0.11527181416749954,
      "learning_rate": 3.165755497103169e-05,
      "loss": 0.037,
      "step": 42700
    },
    {
      "epoch": 2.9429966306814275,
      "grad_norm": 0.29013654589653015,
      "learning_rate": 3.161457527464026e-05,
      "loss": 0.035,
      "step": 42800
    },
    {
      "epoch": 2.9498727910334868,
      "grad_norm": 0.10195871442556381,
      "learning_rate": 3.1571595578248835e-05,
      "loss": 0.037,
      "step": 42900
    },
    {
      "epoch": 2.9567489513855465,
      "grad_norm": 0.16911494731903076,
      "learning_rate": 3.152861588185741e-05,
      "loss": 0.0381,
      "step": 43000
    },
    {
      "epoch": 2.963625111737606,
      "grad_norm": 0.15181362628936768,
      "learning_rate": 3.148563618546599e-05,
      "loss": 0.0348,
      "step": 43100
    },
    {
      "epoch": 2.970501272089665,
      "grad_norm": 0.13483460247516632,
      "learning_rate": 3.144265648907456e-05,
      "loss": 0.0368,
      "step": 43200
    },
    {
      "epoch": 2.977377432441725,
      "grad_norm": 0.2865747809410095,
      "learning_rate": 3.139967679268314e-05,
      "loss": 0.035,
      "step": 43300
    },
    {
      "epoch": 2.984253592793784,
      "grad_norm": 0.12908843159675598,
      "learning_rate": 3.135669709629172e-05,
      "loss": 0.0355,
      "step": 43400
    },
    {
      "epoch": 2.9911297531458434,
      "grad_norm": 0.12141875922679901,
      "learning_rate": 3.131371739990029e-05,
      "loss": 0.0357,
      "step": 43500
    },
    {
      "epoch": 2.9980059134979027,
      "grad_norm": 0.18451052904129028,
      "learning_rate": 3.1270737703508866e-05,
      "loss": 0.0363,
      "step": 43600
    },
    {
      "epoch": 3.0,
      "eval_accuracy_macro_0.5": 0.9831615686416626,
      "eval_accuracy_micro_0.5": 0.9831615686416626,
      "eval_accuracy_weighted_0.5": 0.9808096885681152,
      "eval_f1_macro_0.5": 0.7759994864463806,
      "eval_f1_macro_0.6": 0.7577366232872009,
      "eval_f1_macro_0.7": 0.7258005142211914,
      "eval_f1_macro_0.8": 0.5633057355880737,
      "eval_f1_micro_0.5": 0.7752076387405396,
      "eval_f1_micro_0.6": 0.7596414089202881,
      "eval_f1_micro_0.7": 0.7316053509712219,
      "eval_f1_micro_0.8": 0.6823685765266418,
      "eval_f1_micro_0.9": 0.5828423500061035,
      "eval_f1_weighted_0.5": 0.7688255906105042,
      "eval_f1_weighted_0.6": 0.7495824098587036,
      "eval_f1_weighted_0.7": 0.7159845232963562,
      "eval_f1_weighted_0.8": 0.5481358766555786,
      "eval_loss": 0.034457381814718246,
      "eval_runtime": 133.6125,
      "eval_samples_per_second": 217.322,
      "eval_steps_per_second": 27.168,
      "step": 43629
    },
    {
      "epoch": 3.004882073849962,
      "grad_norm": 0.21430912613868713,
      "learning_rate": 3.122775800711744e-05,
      "loss": 0.035,
      "step": 43700
    },
    {
      "epoch": 3.0117582342020217,
      "grad_norm": 0.20703987777233124,
      "learning_rate": 3.1184778310726013e-05,
      "loss": 0.0363,
      "step": 43800
    },
    {
      "epoch": 3.018634394554081,
      "grad_norm": 0.17982152104377747,
      "learning_rate": 3.114179861433459e-05,
      "loss": 0.0329,
      "step": 43900
    },
    {
      "epoch": 3.0255105549061403,
      "grad_norm": 0.2954074442386627,
      "learning_rate": 3.109881891794317e-05,
      "loss": 0.039,
      "step": 44000
    },
    {
      "epoch": 3.0323867152582,
      "grad_norm": 0.1042870581150055,
      "learning_rate": 3.105583922155174e-05,
      "loss": 0.0349,
      "step": 44100
    },
    {
      "epoch": 3.0392628756102593,
      "grad_norm": 0.18574701249599457,
      "learning_rate": 3.1012859525160316e-05,
      "loss": 0.0352,
      "step": 44200
    },
    {
      "epoch": 3.0461390359623186,
      "grad_norm": 0.06083785369992256,
      "learning_rate": 3.096987982876889e-05,
      "loss": 0.036,
      "step": 44300
    },
    {
      "epoch": 3.053015196314378,
      "grad_norm": 0.11019293963909149,
      "learning_rate": 3.092690013237747e-05,
      "loss": 0.0353,
      "step": 44400
    },
    {
      "epoch": 3.0598913566664376,
      "grad_norm": 0.17763751745224,
      "learning_rate": 3.0883920435986044e-05,
      "loss": 0.0353,
      "step": 44500
    },
    {
      "epoch": 3.066767517018497,
      "grad_norm": 0.196687251329422,
      "learning_rate": 3.084094073959461e-05,
      "loss": 0.0347,
      "step": 44600
    },
    {
      "epoch": 3.073643677370556,
      "grad_norm": 0.2456476390361786,
      "learning_rate": 3.079796104320319e-05,
      "loss": 0.0377,
      "step": 44700
    },
    {
      "epoch": 3.0805198377226155,
      "grad_norm": 0.11477995663881302,
      "learning_rate": 3.0754981346811766e-05,
      "loss": 0.0357,
      "step": 44800
    },
    {
      "epoch": 3.0873959980746752,
      "grad_norm": 0.18340207636356354,
      "learning_rate": 3.071200165042034e-05,
      "loss": 0.0364,
      "step": 44900
    },
    {
      "epoch": 3.0942721584267345,
      "grad_norm": 0.15353256464004517,
      "learning_rate": 3.066902195402892e-05,
      "loss": 0.038,
      "step": 45000
    },
    {
      "epoch": 3.101148318778794,
      "grad_norm": 0.19112029671669006,
      "learning_rate": 3.0626042257637495e-05,
      "loss": 0.0329,
      "step": 45100
    },
    {
      "epoch": 3.1080244791308536,
      "grad_norm": 0.17890162765979767,
      "learning_rate": 3.058306256124607e-05,
      "loss": 0.0358,
      "step": 45200
    },
    {
      "epoch": 3.114900639482913,
      "grad_norm": 0.3295109272003174,
      "learning_rate": 3.054008286485465e-05,
      "loss": 0.036,
      "step": 45300
    },
    {
      "epoch": 3.121776799834972,
      "grad_norm": 0.18079449236392975,
      "learning_rate": 3.049710316846322e-05,
      "loss": 0.0366,
      "step": 45400
    },
    {
      "epoch": 3.1286529601870314,
      "grad_norm": 0.1858842372894287,
      "learning_rate": 3.0454123472071794e-05,
      "loss": 0.0359,
      "step": 45500
    },
    {
      "epoch": 3.135529120539091,
      "grad_norm": 0.22381284832954407,
      "learning_rate": 3.0411143775680368e-05,
      "loss": 0.0369,
      "step": 45600
    },
    {
      "epoch": 3.1424052808911505,
      "grad_norm": 0.11267394572496414,
      "learning_rate": 3.0368164079288948e-05,
      "loss": 0.0352,
      "step": 45700
    },
    {
      "epoch": 3.1492814412432097,
      "grad_norm": 0.17260083556175232,
      "learning_rate": 3.032518438289752e-05,
      "loss": 0.0349,
      "step": 45800
    },
    {
      "epoch": 3.156157601595269,
      "grad_norm": 0.13287679851055145,
      "learning_rate": 3.0282204686506093e-05,
      "loss": 0.0352,
      "step": 45900
    },
    {
      "epoch": 3.1630337619473288,
      "grad_norm": 0.2282567024230957,
      "learning_rate": 3.0239224990114673e-05,
      "loss": 0.0369,
      "step": 46000
    },
    {
      "epoch": 3.169909922299388,
      "grad_norm": 0.2185405045747757,
      "learning_rate": 3.0196245293723247e-05,
      "loss": 0.0363,
      "step": 46100
    },
    {
      "epoch": 3.1767860826514474,
      "grad_norm": 0.1976642608642578,
      "learning_rate": 3.015326559733182e-05,
      "loss": 0.0346,
      "step": 46200
    },
    {
      "epoch": 3.1836622430035066,
      "grad_norm": 0.1638452112674713,
      "learning_rate": 3.01102859009404e-05,
      "loss": 0.034,
      "step": 46300
    },
    {
      "epoch": 3.1905384033555664,
      "grad_norm": 0.1759481579065323,
      "learning_rate": 3.0067306204548972e-05,
      "loss": 0.0338,
      "step": 46400
    },
    {
      "epoch": 3.1974145637076257,
      "grad_norm": 0.22884179651737213,
      "learning_rate": 3.0024326508157546e-05,
      "loss": 0.0372,
      "step": 46500
    },
    {
      "epoch": 3.204290724059685,
      "grad_norm": 0.11547383666038513,
      "learning_rate": 2.9981346811766127e-05,
      "loss": 0.0367,
      "step": 46600
    },
    {
      "epoch": 3.2111668844117442,
      "grad_norm": 0.1471589207649231,
      "learning_rate": 2.9938367115374697e-05,
      "loss": 0.0348,
      "step": 46700
    },
    {
      "epoch": 3.218043044763804,
      "grad_norm": 0.2182369977235794,
      "learning_rate": 2.989538741898327e-05,
      "loss": 0.0356,
      "step": 46800
    },
    {
      "epoch": 3.2249192051158633,
      "grad_norm": 0.23181308805942535,
      "learning_rate": 2.9852407722591845e-05,
      "loss": 0.0377,
      "step": 46900
    },
    {
      "epoch": 3.2317953654679226,
      "grad_norm": 0.20600587129592896,
      "learning_rate": 2.9809428026200426e-05,
      "loss": 0.0375,
      "step": 47000
    },
    {
      "epoch": 3.2386715258199823,
      "grad_norm": 0.15759502351284027,
      "learning_rate": 2.9766448329809e-05,
      "loss": 0.0351,
      "step": 47100
    },
    {
      "epoch": 3.2455476861720416,
      "grad_norm": 0.18360479176044464,
      "learning_rate": 2.9723468633417574e-05,
      "loss": 0.0364,
      "step": 47200
    },
    {
      "epoch": 3.252423846524101,
      "grad_norm": 0.27454453706741333,
      "learning_rate": 2.968048893702615e-05,
      "loss": 0.0363,
      "step": 47300
    },
    {
      "epoch": 3.25930000687616,
      "grad_norm": 0.20609089732170105,
      "learning_rate": 2.9637509240634725e-05,
      "loss": 0.0342,
      "step": 47400
    },
    {
      "epoch": 3.26617616722822,
      "grad_norm": 0.24425093829631805,
      "learning_rate": 2.95945295442433e-05,
      "loss": 0.0336,
      "step": 47500
    },
    {
      "epoch": 3.273052327580279,
      "grad_norm": 0.18096639215946198,
      "learning_rate": 2.955154984785188e-05,
      "loss": 0.0363,
      "step": 47600
    },
    {
      "epoch": 3.2799284879323385,
      "grad_norm": 0.1828615367412567,
      "learning_rate": 2.950857015146045e-05,
      "loss": 0.0334,
      "step": 47700
    },
    {
      "epoch": 3.286804648284398,
      "grad_norm": 0.1689082533121109,
      "learning_rate": 2.9465590455069024e-05,
      "loss": 0.0345,
      "step": 47800
    },
    {
      "epoch": 3.2936808086364575,
      "grad_norm": 0.3158279061317444,
      "learning_rate": 2.9422610758677605e-05,
      "loss": 0.0353,
      "step": 47900
    },
    {
      "epoch": 3.300556968988517,
      "grad_norm": 0.17443378269672394,
      "learning_rate": 2.937963106228618e-05,
      "loss": 0.0372,
      "step": 48000
    },
    {
      "epoch": 3.307433129340576,
      "grad_norm": 0.14729104936122894,
      "learning_rate": 2.9336651365894753e-05,
      "loss": 0.0388,
      "step": 48100
    },
    {
      "epoch": 3.314309289692636,
      "grad_norm": 0.11557084321975708,
      "learning_rate": 2.9293671669503326e-05,
      "loss": 0.0336,
      "step": 48200
    },
    {
      "epoch": 3.321185450044695,
      "grad_norm": 0.20423543453216553,
      "learning_rate": 2.9250691973111904e-05,
      "loss": 0.0348,
      "step": 48300
    },
    {
      "epoch": 3.3280616103967544,
      "grad_norm": 0.1479543000459671,
      "learning_rate": 2.9207712276720478e-05,
      "loss": 0.0332,
      "step": 48400
    },
    {
      "epoch": 3.3349377707488137,
      "grad_norm": 0.14507995545864105,
      "learning_rate": 2.916473258032905e-05,
      "loss": 0.0375,
      "step": 48500
    },
    {
      "epoch": 3.3418139311008734,
      "grad_norm": 0.19095301628112793,
      "learning_rate": 2.9121752883937632e-05,
      "loss": 0.0356,
      "step": 48600
    },
    {
      "epoch": 3.3486900914529327,
      "grad_norm": 0.16116638481616974,
      "learning_rate": 2.9078773187546203e-05,
      "loss": 0.0369,
      "step": 48700
    },
    {
      "epoch": 3.355566251804992,
      "grad_norm": 0.10893864184617996,
      "learning_rate": 2.9035793491154777e-05,
      "loss": 0.0358,
      "step": 48800
    },
    {
      "epoch": 3.3624424121570513,
      "grad_norm": 0.11297107487916946,
      "learning_rate": 2.8992813794763357e-05,
      "loss": 0.0334,
      "step": 48900
    },
    {
      "epoch": 3.369318572509111,
      "grad_norm": 0.23248998820781708,
      "learning_rate": 2.894983409837193e-05,
      "loss": 0.0367,
      "step": 49000
    },
    {
      "epoch": 3.3761947328611703,
      "grad_norm": 0.13126659393310547,
      "learning_rate": 2.8906854401980505e-05,
      "loss": 0.0365,
      "step": 49100
    },
    {
      "epoch": 3.3830708932132296,
      "grad_norm": 0.051384396851062775,
      "learning_rate": 2.8863874705589083e-05,
      "loss": 0.0329,
      "step": 49200
    },
    {
      "epoch": 3.3899470535652894,
      "grad_norm": 0.13729459047317505,
      "learning_rate": 2.8820895009197656e-05,
      "loss": 0.0347,
      "step": 49300
    },
    {
      "epoch": 3.3968232139173486,
      "grad_norm": 0.11708222329616547,
      "learning_rate": 2.877791531280623e-05,
      "loss": 0.0351,
      "step": 49400
    },
    {
      "epoch": 3.403699374269408,
      "grad_norm": 0.18020373582839966,
      "learning_rate": 2.8734935616414804e-05,
      "loss": 0.0357,
      "step": 49500
    },
    {
      "epoch": 3.4105755346214672,
      "grad_norm": 0.22909647226333618,
      "learning_rate": 2.8691955920023385e-05,
      "loss": 0.0366,
      "step": 49600
    },
    {
      "epoch": 3.417451694973527,
      "grad_norm": 0.1704436093568802,
      "learning_rate": 2.864940602059587e-05,
      "loss": 0.0343,
      "step": 49700
    },
    {
      "epoch": 3.4243278553255863,
      "grad_norm": 0.1694321483373642,
      "learning_rate": 2.8606426324204448e-05,
      "loss": 0.0363,
      "step": 49800
    },
    {
      "epoch": 3.4312040156776455,
      "grad_norm": 0.338866651058197,
      "learning_rate": 2.8563446627813022e-05,
      "loss": 0.0341,
      "step": 49900
    },
    {
      "epoch": 3.438080176029705,
      "grad_norm": 0.2397933006286621,
      "learning_rate": 2.8520466931421596e-05,
      "loss": 0.0347,
      "step": 50000
    },
    {
      "epoch": 3.4449563363817646,
      "grad_norm": 0.13352923095226288,
      "learning_rate": 2.8477487235030176e-05,
      "loss": 0.0344,
      "step": 50100
    },
    {
      "epoch": 3.451832496733824,
      "grad_norm": 0.2780233919620514,
      "learning_rate": 2.843450753863875e-05,
      "loss": 0.0375,
      "step": 50200
    },
    {
      "epoch": 3.458708657085883,
      "grad_norm": 0.25799354910850525,
      "learning_rate": 2.8391527842247324e-05,
      "loss": 0.0358,
      "step": 50300
    },
    {
      "epoch": 3.465584817437943,
      "grad_norm": 0.15224893391132355,
      "learning_rate": 2.8348548145855898e-05,
      "loss": 0.0368,
      "step": 50400
    },
    {
      "epoch": 3.472460977790002,
      "grad_norm": 0.17120105028152466,
      "learning_rate": 2.8305568449464475e-05,
      "loss": 0.0351,
      "step": 50500
    },
    {
      "epoch": 3.4793371381420615,
      "grad_norm": 0.20874586701393127,
      "learning_rate": 2.826258875307305e-05,
      "loss": 0.0351,
      "step": 50600
    },
    {
      "epoch": 3.4862132984941208,
      "grad_norm": 0.1807491034269333,
      "learning_rate": 2.8219609056681623e-05,
      "loss": 0.0396,
      "step": 50700
    },
    {
      "epoch": 3.49308945884618,
      "grad_norm": 0.1765696108341217,
      "learning_rate": 2.81766293602902e-05,
      "loss": 0.0338,
      "step": 50800
    },
    {
      "epoch": 3.49996561919824,
      "grad_norm": 0.17425912618637085,
      "learning_rate": 2.8133649663898775e-05,
      "loss": 0.0369,
      "step": 50900
    },
    {
      "epoch": 3.506841779550299,
      "grad_norm": 0.2169819176197052,
      "learning_rate": 2.8091099764471264e-05,
      "loss": 0.0347,
      "step": 51000
    },
    {
      "epoch": 3.5137179399023584,
      "grad_norm": 0.12141348421573639,
      "learning_rate": 2.804812006807984e-05,
      "loss": 0.035,
      "step": 51100
    },
    {
      "epoch": 3.520594100254418,
      "grad_norm": 0.21593859791755676,
      "learning_rate": 2.8005140371688415e-05,
      "loss": 0.0341,
      "step": 51200
    },
    {
      "epoch": 3.5274702606064774,
      "grad_norm": 0.1592191755771637,
      "learning_rate": 2.796216067529699e-05,
      "loss": 0.0385,
      "step": 51300
    },
    {
      "epoch": 3.5343464209585367,
      "grad_norm": 0.2363646924495697,
      "learning_rate": 2.791918097890557e-05,
      "loss": 0.0343,
      "step": 51400
    },
    {
      "epoch": 3.5412225813105964,
      "grad_norm": 0.19864848256111145,
      "learning_rate": 2.7876201282514143e-05,
      "loss": 0.0344,
      "step": 51500
    },
    {
      "epoch": 3.5480987416626557,
      "grad_norm": 0.1523742526769638,
      "learning_rate": 2.7833221586122714e-05,
      "loss": 0.0374,
      "step": 51600
    },
    {
      "epoch": 3.554974902014715,
      "grad_norm": 0.1409846991300583,
      "learning_rate": 2.7790241889731295e-05,
      "loss": 0.0389,
      "step": 51700
    },
    {
      "epoch": 3.5618510623667743,
      "grad_norm": 0.14453667402267456,
      "learning_rate": 2.774769199030378e-05,
      "loss": 0.0341,
      "step": 51800
    },
    {
      "epoch": 3.5687272227188336,
      "grad_norm": 0.18211612105369568,
      "learning_rate": 2.7704712293912354e-05,
      "loss": 0.0368,
      "step": 51900
    },
    {
      "epoch": 3.5756033830708933,
      "grad_norm": 0.18022194504737854,
      "learning_rate": 2.7661732597520935e-05,
      "loss": 0.0353,
      "step": 52000
    },
    {
      "epoch": 3.5824795434229526,
      "grad_norm": 0.25855833292007446,
      "learning_rate": 2.761918269809342e-05,
      "loss": 0.0371,
      "step": 52100
    },
    {
      "epoch": 3.589355703775012,
      "grad_norm": 0.2664014995098114,
      "learning_rate": 2.7576203001701994e-05,
      "loss": 0.0388,
      "step": 52200
    },
    {
      "epoch": 3.5962318641270716,
      "grad_norm": 0.08723001927137375,
      "learning_rate": 2.7533223305310575e-05,
      "loss": 0.0343,
      "step": 52300
    },
    {
      "epoch": 3.603108024479131,
      "grad_norm": 0.14234820008277893,
      "learning_rate": 2.749024360891915e-05,
      "loss": 0.0354,
      "step": 52400
    },
    {
      "epoch": 3.60998418483119,
      "grad_norm": 0.13975423574447632,
      "learning_rate": 2.744726391252772e-05,
      "loss": 0.0369,
      "step": 52500
    },
    {
      "epoch": 3.61686034518325,
      "grad_norm": 0.16742418706417084,
      "learning_rate": 2.74042842161363e-05,
      "loss": 0.0374,
      "step": 52600
    },
    {
      "epoch": 3.6237365055353092,
      "grad_norm": 0.2558394968509674,
      "learning_rate": 2.7361304519744874e-05,
      "loss": 0.0335,
      "step": 52700
    },
    {
      "epoch": 3.6306126658873685,
      "grad_norm": 0.14172880351543427,
      "learning_rate": 2.7318324823353448e-05,
      "loss": 0.0349,
      "step": 52800
    },
    {
      "epoch": 3.637488826239428,
      "grad_norm": 0.13402199745178223,
      "learning_rate": 2.7275345126962025e-05,
      "loss": 0.0335,
      "step": 52900
    },
    {
      "epoch": 3.644364986591487,
      "grad_norm": 0.16058871150016785,
      "learning_rate": 2.72323654305706e-05,
      "loss": 0.0364,
      "step": 53000
    },
    {
      "epoch": 3.651241146943547,
      "grad_norm": 0.1296338438987732,
      "learning_rate": 2.7189385734179173e-05,
      "loss": 0.0348,
      "step": 53100
    },
    {
      "epoch": 3.658117307295606,
      "grad_norm": 0.23372726142406464,
      "learning_rate": 2.7146406037787754e-05,
      "loss": 0.0331,
      "step": 53200
    },
    {
      "epoch": 3.6649934676476654,
      "grad_norm": 0.15425723791122437,
      "learning_rate": 2.7103426341396328e-05,
      "loss": 0.0363,
      "step": 53300
    },
    {
      "epoch": 3.671869627999725,
      "grad_norm": 0.13509118556976318,
      "learning_rate": 2.7060446645004898e-05,
      "loss": 0.0351,
      "step": 53400
    },
    {
      "epoch": 3.6787457883517845,
      "grad_norm": 0.23985396325588226,
      "learning_rate": 2.701746694861348e-05,
      "loss": 0.0361,
      "step": 53500
    },
    {
      "epoch": 3.6856219487038437,
      "grad_norm": 0.18412794172763824,
      "learning_rate": 2.6974487252222053e-05,
      "loss": 0.035,
      "step": 53600
    },
    {
      "epoch": 3.692498109055903,
      "grad_norm": 0.2676500380039215,
      "learning_rate": 2.6931507555830627e-05,
      "loss": 0.0348,
      "step": 53700
    },
    {
      "epoch": 3.6993742694079623,
      "grad_norm": 0.20780056715011597,
      "learning_rate": 2.68885278594392e-05,
      "loss": 0.0361,
      "step": 53800
    },
    {
      "epoch": 3.706250429760022,
      "grad_norm": 0.19853508472442627,
      "learning_rate": 2.6845548163047778e-05,
      "loss": 0.0355,
      "step": 53900
    },
    {
      "epoch": 3.7131265901120813,
      "grad_norm": 0.1577785611152649,
      "learning_rate": 2.6802568466656352e-05,
      "loss": 0.0364,
      "step": 54000
    },
    {
      "epoch": 3.7200027504641406,
      "grad_norm": 0.15538550913333893,
      "learning_rate": 2.6759588770264926e-05,
      "loss": 0.0347,
      "step": 54100
    },
    {
      "epoch": 3.7268789108162004,
      "grad_norm": 0.1601690649986267,
      "learning_rate": 2.6716609073873506e-05,
      "loss": 0.0331,
      "step": 54200
    },
    {
      "epoch": 3.7337550711682597,
      "grad_norm": 0.11352933198213577,
      "learning_rate": 2.667362937748208e-05,
      "loss": 0.0357,
      "step": 54300
    },
    {
      "epoch": 3.740631231520319,
      "grad_norm": 0.25299564003944397,
      "learning_rate": 2.663064968109065e-05,
      "loss": 0.0342,
      "step": 54400
    },
    {
      "epoch": 3.7475073918723787,
      "grad_norm": 0.088300421833992,
      "learning_rate": 2.658766998469923e-05,
      "loss": 0.0363,
      "step": 54500
    },
    {
      "epoch": 3.754383552224438,
      "grad_norm": 0.10823433846235275,
      "learning_rate": 2.6544690288307805e-05,
      "loss": 0.035,
      "step": 54600
    },
    {
      "epoch": 3.7612597125764973,
      "grad_norm": 0.26562413573265076,
      "learning_rate": 2.650171059191638e-05,
      "loss": 0.0352,
      "step": 54700
    },
    {
      "epoch": 3.7681358729285566,
      "grad_norm": 0.09010659158229828,
      "learning_rate": 2.6458730895524957e-05,
      "loss": 0.0347,
      "step": 54800
    },
    {
      "epoch": 3.775012033280616,
      "grad_norm": 0.17202480137348175,
      "learning_rate": 2.641575119913353e-05,
      "loss": 0.0324,
      "step": 54900
    },
    {
      "epoch": 3.7818881936326756,
      "grad_norm": 0.1853020340204239,
      "learning_rate": 2.6372771502742105e-05,
      "loss": 0.0359,
      "step": 55000
    },
    {
      "epoch": 3.788764353984735,
      "grad_norm": 0.04077088087797165,
      "learning_rate": 2.632979180635068e-05,
      "loss": 0.0341,
      "step": 55100
    },
    {
      "epoch": 3.795640514336794,
      "grad_norm": 0.09725197404623032,
      "learning_rate": 2.628681210995926e-05,
      "loss": 0.0354,
      "step": 55200
    },
    {
      "epoch": 3.802516674688854,
      "grad_norm": 0.15049892663955688,
      "learning_rate": 2.6243832413567833e-05,
      "loss": 0.034,
      "step": 55300
    },
    {
      "epoch": 3.809392835040913,
      "grad_norm": 0.2157244086265564,
      "learning_rate": 2.6200852717176404e-05,
      "loss": 0.0371,
      "step": 55400
    },
    {
      "epoch": 3.8162689953929725,
      "grad_norm": 0.2091638296842575,
      "learning_rate": 2.6157873020784984e-05,
      "loss": 0.0361,
      "step": 55500
    },
    {
      "epoch": 3.823145155745032,
      "grad_norm": 0.20158971846103668,
      "learning_rate": 2.6114893324393558e-05,
      "loss": 0.0367,
      "step": 55600
    },
    {
      "epoch": 3.8300213160970915,
      "grad_norm": 0.16124992072582245,
      "learning_rate": 2.6071913628002132e-05,
      "loss": 0.0343,
      "step": 55700
    },
    {
      "epoch": 3.836897476449151,
      "grad_norm": 0.17593224346637726,
      "learning_rate": 2.602893393161071e-05,
      "loss": 0.032,
      "step": 55800
    },
    {
      "epoch": 3.84377363680121,
      "grad_norm": 0.146103173494339,
      "learning_rate": 2.5985954235219283e-05,
      "loss": 0.0327,
      "step": 55900
    },
    {
      "epoch": 3.8506497971532694,
      "grad_norm": 0.1157873347401619,
      "learning_rate": 2.5942974538827857e-05,
      "loss": 0.0344,
      "step": 56000
    },
    {
      "epoch": 3.857525957505329,
      "grad_norm": 0.24592463672161102,
      "learning_rate": 2.5899994842436438e-05,
      "loss": 0.0352,
      "step": 56100
    },
    {
      "epoch": 3.8644021178573884,
      "grad_norm": 0.1811218559741974,
      "learning_rate": 2.5857444943008924e-05,
      "loss": 0.0367,
      "step": 56200
    },
    {
      "epoch": 3.8712782782094477,
      "grad_norm": 0.11905349045991898,
      "learning_rate": 2.5814465246617497e-05,
      "loss": 0.0355,
      "step": 56300
    },
    {
      "epoch": 3.8781544385615074,
      "grad_norm": 0.14918790757656097,
      "learning_rate": 2.5771485550226078e-05,
      "loss": 0.0341,
      "step": 56400
    },
    {
      "epoch": 3.8850305989135667,
      "grad_norm": 0.26084885001182556,
      "learning_rate": 2.572850585383465e-05,
      "loss": 0.0327,
      "step": 56500
    },
    {
      "epoch": 3.891906759265626,
      "grad_norm": 0.2050085961818695,
      "learning_rate": 2.5685526157443223e-05,
      "loss": 0.0349,
      "step": 56600
    },
    {
      "epoch": 3.8987829196176857,
      "grad_norm": 0.11986557394266129,
      "learning_rate": 2.5642546461051803e-05,
      "loss": 0.0351,
      "step": 56700
    },
    {
      "epoch": 3.905659079969745,
      "grad_norm": 0.15002590417861938,
      "learning_rate": 2.5599566764660377e-05,
      "loss": 0.0376,
      "step": 56800
    },
    {
      "epoch": 3.9125352403218043,
      "grad_norm": 0.25760096311569214,
      "learning_rate": 2.555658706826895e-05,
      "loss": 0.0385,
      "step": 56900
    },
    {
      "epoch": 3.9194114006738636,
      "grad_norm": 0.14307203888893127,
      "learning_rate": 2.5513607371877525e-05,
      "loss": 0.0314,
      "step": 57000
    },
    {
      "epoch": 3.926287561025923,
      "grad_norm": 0.1898571401834488,
      "learning_rate": 2.5470627675486102e-05,
      "loss": 0.0349,
      "step": 57100
    },
    {
      "epoch": 3.9331637213779826,
      "grad_norm": 0.2237950563430786,
      "learning_rate": 2.5427647979094676e-05,
      "loss": 0.0349,
      "step": 57200
    },
    {
      "epoch": 3.940039881730042,
      "grad_norm": 0.3428507149219513,
      "learning_rate": 2.538466828270325e-05,
      "loss": 0.0342,
      "step": 57300
    },
    {
      "epoch": 3.9469160420821012,
      "grad_norm": 0.14297911524772644,
      "learning_rate": 2.534168858631183e-05,
      "loss": 0.0335,
      "step": 57400
    },
    {
      "epoch": 3.953792202434161,
      "grad_norm": 0.20036247372627258,
      "learning_rate": 2.52987088899204e-05,
      "loss": 0.0335,
      "step": 57500
    },
    {
      "epoch": 3.9606683627862203,
      "grad_norm": 0.20989234745502472,
      "learning_rate": 2.5255729193528975e-05,
      "loss": 0.033,
      "step": 57600
    },
    {
      "epoch": 3.9675445231382795,
      "grad_norm": 0.24924013018608093,
      "learning_rate": 2.5212749497137556e-05,
      "loss": 0.0344,
      "step": 57700
    },
    {
      "epoch": 3.974420683490339,
      "grad_norm": 0.28612425923347473,
      "learning_rate": 2.516976980074613e-05,
      "loss": 0.0353,
      "step": 57800
    },
    {
      "epoch": 3.9812968438423986,
      "grad_norm": 0.21917270123958588,
      "learning_rate": 2.5126790104354704e-05,
      "loss": 0.0322,
      "step": 57900
    },
    {
      "epoch": 3.988173004194458,
      "grad_norm": 0.18195323646068573,
      "learning_rate": 2.508381040796328e-05,
      "loss": 0.0324,
      "step": 58000
    },
    {
      "epoch": 3.995049164546517,
      "grad_norm": 0.25028806924819946,
      "learning_rate": 2.5040830711571855e-05,
      "loss": 0.0361,
      "step": 58100
    },
    {
      "epoch": 4.0,
      "eval_accuracy_macro_0.5": 0.9838869571685791,
      "eval_accuracy_micro_0.5": 0.9838869571685791,
      "eval_accuracy_weighted_0.5": 0.9816091060638428,
      "eval_f1_macro_0.5": 0.792719841003418,
      "eval_f1_macro_0.6": 0.7800110578536987,
      "eval_f1_macro_0.7": 0.7553250789642334,
      "eval_f1_macro_0.8": 0.6133295893669128,
      "eval_f1_micro_0.5": 0.7905662655830383,
      "eval_f1_micro_0.6": 0.7804189920425415,
      "eval_f1_micro_0.7": 0.7594956159591675,
      "eval_f1_micro_0.8": 0.7189310193061829,
      "eval_f1_micro_0.9": 0.630993664264679,
      "eval_f1_weighted_0.5": 0.7865186929702759,
      "eval_f1_weighted_0.6": 0.7731924653053284,
      "eval_f1_weighted_0.7": 0.747772216796875,
      "eval_f1_weighted_0.8": 0.6007810831069946,
      "eval_loss": 0.033129606395959854,
      "eval_runtime": 133.5002,
      "eval_samples_per_second": 217.505,
      "eval_steps_per_second": 27.191,
      "step": 58172
    },
    {
      "epoch": 4.001925324898576,
      "grad_norm": 0.1662788838148117,
      "learning_rate": 2.499785101518043e-05,
      "loss": 0.0364,
      "step": 58200
    },
    {
      "epoch": 4.008801485250636,
      "grad_norm": 0.1785542219877243,
      "learning_rate": 2.4954871318789006e-05,
      "loss": 0.0342,
      "step": 58300
    },
    {
      "epoch": 4.015677645602695,
      "grad_norm": 0.16875045001506805,
      "learning_rate": 2.4911891622397583e-05,
      "loss": 0.0346,
      "step": 58400
    },
    {
      "epoch": 4.022553805954755,
      "grad_norm": 0.23746415972709656,
      "learning_rate": 2.4868911926006154e-05,
      "loss": 0.038,
      "step": 58500
    },
    {
      "epoch": 4.0294299663068145,
      "grad_norm": 0.16662460565567017,
      "learning_rate": 2.482593222961473e-05,
      "loss": 0.0305,
      "step": 58600
    },
    {
      "epoch": 4.036306126658873,
      "grad_norm": 0.21623718738555908,
      "learning_rate": 2.4782952533223305e-05,
      "loss": 0.0341,
      "step": 58700
    },
    {
      "epoch": 4.043182287010933,
      "grad_norm": 0.18232347071170807,
      "learning_rate": 2.4739972836831883e-05,
      "loss": 0.0347,
      "step": 58800
    },
    {
      "epoch": 4.050058447362993,
      "grad_norm": 0.12075558304786682,
      "learning_rate": 2.4696993140440456e-05,
      "loss": 0.0334,
      "step": 58900
    },
    {
      "epoch": 4.056934607715052,
      "grad_norm": 0.14145992696285248,
      "learning_rate": 2.465401344404903e-05,
      "loss": 0.0344,
      "step": 59000
    },
    {
      "epoch": 4.063810768067111,
      "grad_norm": 0.1927667111158371,
      "learning_rate": 2.4611033747657608e-05,
      "loss": 0.0345,
      "step": 59100
    },
    {
      "epoch": 4.070686928419171,
      "grad_norm": 0.20596525073051453,
      "learning_rate": 2.456805405126618e-05,
      "loss": 0.0341,
      "step": 59200
    },
    {
      "epoch": 4.07756308877123,
      "grad_norm": 0.33652693033218384,
      "learning_rate": 2.452507435487476e-05,
      "loss": 0.0344,
      "step": 59300
    },
    {
      "epoch": 4.08443924912329,
      "grad_norm": 0.15400810539722443,
      "learning_rate": 2.4482094658483333e-05,
      "loss": 0.034,
      "step": 59400
    },
    {
      "epoch": 4.0913154094753486,
      "grad_norm": 0.1667555719614029,
      "learning_rate": 2.4439114962091907e-05,
      "loss": 0.0325,
      "step": 59500
    },
    {
      "epoch": 4.098191569827408,
      "grad_norm": 0.04656461998820305,
      "learning_rate": 2.4396135265700484e-05,
      "loss": 0.0366,
      "step": 59600
    },
    {
      "epoch": 4.105067730179468,
      "grad_norm": 0.15142351388931274,
      "learning_rate": 2.435315556930906e-05,
      "loss": 0.033,
      "step": 59700
    },
    {
      "epoch": 4.111943890531527,
      "grad_norm": 0.1744154691696167,
      "learning_rate": 2.4310175872917635e-05,
      "loss": 0.0344,
      "step": 59800
    },
    {
      "epoch": 4.118820050883587,
      "grad_norm": 0.11016254872083664,
      "learning_rate": 2.426719617652621e-05,
      "loss": 0.0355,
      "step": 59900
    },
    {
      "epoch": 4.125696211235646,
      "grad_norm": 0.13011443614959717,
      "learning_rate": 2.4224216480134783e-05,
      "loss": 0.0341,
      "step": 60000
    },
    {
      "epoch": 4.132572371587705,
      "grad_norm": 0.19214807450771332,
      "learning_rate": 2.418123678374336e-05,
      "loss": 0.0332,
      "step": 60100
    },
    {
      "epoch": 4.139448531939765,
      "grad_norm": 0.1859477013349533,
      "learning_rate": 2.4138257087351938e-05,
      "loss": 0.0308,
      "step": 60200
    },
    {
      "epoch": 4.146324692291825,
      "grad_norm": 0.156495600938797,
      "learning_rate": 2.409527739096051e-05,
      "loss": 0.0328,
      "step": 60300
    },
    {
      "epoch": 4.1532008526438835,
      "grad_norm": 0.24484051764011383,
      "learning_rate": 2.4052297694569085e-05,
      "loss": 0.035,
      "step": 60400
    },
    {
      "epoch": 4.160077012995943,
      "grad_norm": 0.141842320561409,
      "learning_rate": 2.4009317998177663e-05,
      "loss": 0.0343,
      "step": 60500
    },
    {
      "epoch": 4.166953173348002,
      "grad_norm": 0.15623539686203003,
      "learning_rate": 2.3966338301786237e-05,
      "loss": 0.0342,
      "step": 60600
    },
    {
      "epoch": 4.173829333700062,
      "grad_norm": 0.1761428862810135,
      "learning_rate": 2.3923358605394814e-05,
      "loss": 0.0306,
      "step": 60700
    },
    {
      "epoch": 4.1807054940521216,
      "grad_norm": 0.23753783106803894,
      "learning_rate": 2.3880378909003388e-05,
      "loss": 0.0342,
      "step": 60800
    },
    {
      "epoch": 4.18758165440418,
      "grad_norm": 0.13551409542560577,
      "learning_rate": 2.3837399212611962e-05,
      "loss": 0.0351,
      "step": 60900
    },
    {
      "epoch": 4.19445781475624,
      "grad_norm": 0.17604868113994598,
      "learning_rate": 2.379441951622054e-05,
      "loss": 0.0337,
      "step": 61000
    },
    {
      "epoch": 4.2013339751083,
      "grad_norm": 0.17434857785701752,
      "learning_rate": 2.3751439819829113e-05,
      "loss": 0.0342,
      "step": 61100
    },
    {
      "epoch": 4.208210135460359,
      "grad_norm": 0.22874760627746582,
      "learning_rate": 2.370846012343769e-05,
      "loss": 0.0333,
      "step": 61200
    },
    {
      "epoch": 4.2150862958124184,
      "grad_norm": 0.2241726815700531,
      "learning_rate": 2.3665480427046264e-05,
      "loss": 0.0324,
      "step": 61300
    },
    {
      "epoch": 4.221962456164478,
      "grad_norm": 0.16143973171710968,
      "learning_rate": 2.3622930527618753e-05,
      "loss": 0.033,
      "step": 61400
    },
    {
      "epoch": 4.228838616516537,
      "grad_norm": 0.19472800195217133,
      "learning_rate": 2.357995083122733e-05,
      "loss": 0.0322,
      "step": 61500
    },
    {
      "epoch": 4.235714776868597,
      "grad_norm": 0.18336820602416992,
      "learning_rate": 2.3536971134835904e-05,
      "loss": 0.0363,
      "step": 61600
    },
    {
      "epoch": 4.242590937220656,
      "grad_norm": 0.16668817400932312,
      "learning_rate": 2.349399143844448e-05,
      "loss": 0.036,
      "step": 61700
    },
    {
      "epoch": 4.249467097572715,
      "grad_norm": 0.3116610646247864,
      "learning_rate": 2.3451011742053056e-05,
      "loss": 0.0328,
      "step": 61800
    },
    {
      "epoch": 4.256343257924775,
      "grad_norm": 0.22521629929542542,
      "learning_rate": 2.340803204566163e-05,
      "loss": 0.0327,
      "step": 61900
    },
    {
      "epoch": 4.263219418276834,
      "grad_norm": 0.2735576033592224,
      "learning_rate": 2.3365052349270207e-05,
      "loss": 0.0366,
      "step": 62000
    },
    {
      "epoch": 4.270095578628894,
      "grad_norm": 0.30457374453544617,
      "learning_rate": 2.332207265287878e-05,
      "loss": 0.0346,
      "step": 62100
    },
    {
      "epoch": 4.276971738980953,
      "grad_norm": 0.1422623097896576,
      "learning_rate": 2.3279092956487355e-05,
      "loss": 0.0322,
      "step": 62200
    },
    {
      "epoch": 4.283847899333012,
      "grad_norm": 0.15080033242702484,
      "learning_rate": 2.3236113260095932e-05,
      "loss": 0.0355,
      "step": 62300
    },
    {
      "epoch": 4.290724059685072,
      "grad_norm": 0.26003092527389526,
      "learning_rate": 2.319313356370451e-05,
      "loss": 0.0339,
      "step": 62400
    },
    {
      "epoch": 4.297600220037131,
      "grad_norm": 0.2965206205844879,
      "learning_rate": 2.3150153867313083e-05,
      "loss": 0.0326,
      "step": 62500
    },
    {
      "epoch": 4.304476380389191,
      "grad_norm": 0.31417638063430786,
      "learning_rate": 2.3107174170921657e-05,
      "loss": 0.0356,
      "step": 62600
    },
    {
      "epoch": 4.31135254074125,
      "grad_norm": 0.26059532165527344,
      "learning_rate": 2.306419447453023e-05,
      "loss": 0.0336,
      "step": 62700
    },
    {
      "epoch": 4.318228701093309,
      "grad_norm": 0.2503603398799896,
      "learning_rate": 2.302121477813881e-05,
      "loss": 0.0331,
      "step": 62800
    },
    {
      "epoch": 4.325104861445369,
      "grad_norm": 0.16103370487689972,
      "learning_rate": 2.2978235081747386e-05,
      "loss": 0.0332,
      "step": 62900
    },
    {
      "epoch": 4.331981021797429,
      "grad_norm": 0.2549120783805847,
      "learning_rate": 2.293525538535596e-05,
      "loss": 0.0352,
      "step": 63000
    },
    {
      "epoch": 4.3388571821494875,
      "grad_norm": 0.13018320500850677,
      "learning_rate": 2.2892275688964533e-05,
      "loss": 0.0328,
      "step": 63100
    },
    {
      "epoch": 4.345733342501547,
      "grad_norm": 0.20952880382537842,
      "learning_rate": 2.284929599257311e-05,
      "loss": 0.0345,
      "step": 63200
    },
    {
      "epoch": 4.352609502853607,
      "grad_norm": 0.12683168053627014,
      "learning_rate": 2.2806316296181685e-05,
      "loss": 0.0313,
      "step": 63300
    },
    {
      "epoch": 4.359485663205666,
      "grad_norm": 0.22339724004268646,
      "learning_rate": 2.2763336599790262e-05,
      "loss": 0.0346,
      "step": 63400
    },
    {
      "epoch": 4.3663618235577255,
      "grad_norm": 0.215066060423851,
      "learning_rate": 2.2720356903398836e-05,
      "loss": 0.0339,
      "step": 63500
    },
    {
      "epoch": 4.373237983909785,
      "grad_norm": 0.18986204266548157,
      "learning_rate": 2.267737720700741e-05,
      "loss": 0.0362,
      "step": 63600
    },
    {
      "epoch": 4.380114144261844,
      "grad_norm": 0.14565417170524597,
      "learning_rate": 2.2634397510615987e-05,
      "loss": 0.0373,
      "step": 63700
    },
    {
      "epoch": 4.386990304613904,
      "grad_norm": 0.32610538601875305,
      "learning_rate": 2.259141781422456e-05,
      "loss": 0.0341,
      "step": 63800
    },
    {
      "epoch": 4.393866464965963,
      "grad_norm": 0.17506107687950134,
      "learning_rate": 2.2548438117833138e-05,
      "loss": 0.0336,
      "step": 63900
    },
    {
      "epoch": 4.400742625318022,
      "grad_norm": 0.24897189438343048,
      "learning_rate": 2.2505458421441712e-05,
      "loss": 0.032,
      "step": 64000
    },
    {
      "epoch": 4.407618785670082,
      "grad_norm": 0.19118675589561462,
      "learning_rate": 2.2462478725050286e-05,
      "loss": 0.0323,
      "step": 64100
    },
    {
      "epoch": 4.414494946022141,
      "grad_norm": 0.11488199979066849,
      "learning_rate": 2.2419499028658863e-05,
      "loss": 0.0335,
      "step": 64200
    },
    {
      "epoch": 4.421371106374201,
      "grad_norm": 0.17790426313877106,
      "learning_rate": 2.2376519332267437e-05,
      "loss": 0.0353,
      "step": 64300
    },
    {
      "epoch": 4.4282472667262605,
      "grad_norm": 0.2666556239128113,
      "learning_rate": 2.2333539635876015e-05,
      "loss": 0.0342,
      "step": 64400
    },
    {
      "epoch": 4.435123427078319,
      "grad_norm": 0.1804647594690323,
      "learning_rate": 2.229055993948459e-05,
      "loss": 0.0333,
      "step": 64500
    },
    {
      "epoch": 4.441999587430379,
      "grad_norm": 0.1727118343114853,
      "learning_rate": 2.2247580243093162e-05,
      "loss": 0.0326,
      "step": 64600
    },
    {
      "epoch": 4.448875747782438,
      "grad_norm": 0.24079665541648865,
      "learning_rate": 2.220460054670174e-05,
      "loss": 0.0328,
      "step": 64700
    },
    {
      "epoch": 4.455751908134498,
      "grad_norm": 0.25147193670272827,
      "learning_rate": 2.2161620850310314e-05,
      "loss": 0.0335,
      "step": 64800
    },
    {
      "epoch": 4.462628068486557,
      "grad_norm": 0.0870620608329773,
      "learning_rate": 2.211864115391889e-05,
      "loss": 0.0338,
      "step": 64900
    },
    {
      "epoch": 4.469504228838616,
      "grad_norm": 0.1598840057849884,
      "learning_rate": 2.2075661457527465e-05,
      "loss": 0.0324,
      "step": 65000
    },
    {
      "epoch": 4.476380389190676,
      "grad_norm": 0.216328427195549,
      "learning_rate": 2.203268176113604e-05,
      "loss": 0.0347,
      "step": 65100
    },
    {
      "epoch": 4.483256549542736,
      "grad_norm": 0.1891562044620514,
      "learning_rate": 2.1989702064744616e-05,
      "loss": 0.0352,
      "step": 65200
    },
    {
      "epoch": 4.4901327098947945,
      "grad_norm": 0.21034134924411774,
      "learning_rate": 2.194672236835319e-05,
      "loss": 0.0342,
      "step": 65300
    },
    {
      "epoch": 4.497008870246854,
      "grad_norm": 0.17294646799564362,
      "learning_rate": 2.1903742671961767e-05,
      "loss": 0.0324,
      "step": 65400
    },
    {
      "epoch": 4.503885030598914,
      "grad_norm": 0.19032137095928192,
      "learning_rate": 2.186076297557034e-05,
      "loss": 0.0323,
      "step": 65500
    },
    {
      "epoch": 4.510761190950973,
      "grad_norm": 0.20833514630794525,
      "learning_rate": 2.1817783279178915e-05,
      "loss": 0.033,
      "step": 65600
    },
    {
      "epoch": 4.517637351303033,
      "grad_norm": 0.15489597618579865,
      "learning_rate": 2.1774803582787492e-05,
      "loss": 0.0329,
      "step": 65700
    },
    {
      "epoch": 4.524513511655091,
      "grad_norm": 0.17972087860107422,
      "learning_rate": 2.173182388639607e-05,
      "loss": 0.0322,
      "step": 65800
    },
    {
      "epoch": 4.531389672007151,
      "grad_norm": 0.09635477513074875,
      "learning_rate": 2.1688844190004644e-05,
      "loss": 0.0311,
      "step": 65900
    },
    {
      "epoch": 4.538265832359211,
      "grad_norm": 0.06949886679649353,
      "learning_rate": 2.1646294290577133e-05,
      "loss": 0.0299,
      "step": 66000
    },
    {
      "epoch": 4.54514199271127,
      "grad_norm": 0.23074552416801453,
      "learning_rate": 2.160331459418571e-05,
      "loss": 0.0345,
      "step": 66100
    },
    {
      "epoch": 4.5520181530633295,
      "grad_norm": 0.2031768262386322,
      "learning_rate": 2.156033489779428e-05,
      "loss": 0.0367,
      "step": 66200
    },
    {
      "epoch": 4.558894313415389,
      "grad_norm": 0.14639736711978912,
      "learning_rate": 2.1517355201402858e-05,
      "loss": 0.0337,
      "step": 66300
    },
    {
      "epoch": 4.565770473767448,
      "grad_norm": 0.22199547290802002,
      "learning_rate": 2.1474375505011435e-05,
      "loss": 0.0333,
      "step": 66400
    },
    {
      "epoch": 4.572646634119508,
      "grad_norm": 0.21571151912212372,
      "learning_rate": 2.143139580862001e-05,
      "loss": 0.0341,
      "step": 66500
    },
    {
      "epoch": 4.579522794471567,
      "grad_norm": 0.12515857815742493,
      "learning_rate": 2.1388416112228586e-05,
      "loss": 0.0302,
      "step": 66600
    },
    {
      "epoch": 4.586398954823626,
      "grad_norm": 0.277231901884079,
      "learning_rate": 2.1345436415837157e-05,
      "loss": 0.0323,
      "step": 66700
    },
    {
      "epoch": 4.593275115175686,
      "grad_norm": 0.18201828002929688,
      "learning_rate": 2.1302456719445734e-05,
      "loss": 0.0349,
      "step": 66800
    },
    {
      "epoch": 4.600151275527745,
      "grad_norm": 0.243154376745224,
      "learning_rate": 2.125947702305431e-05,
      "loss": 0.032,
      "step": 66900
    },
    {
      "epoch": 4.607027435879805,
      "grad_norm": 0.3346474766731262,
      "learning_rate": 2.1216497326662885e-05,
      "loss": 0.0334,
      "step": 67000
    },
    {
      "epoch": 4.613903596231864,
      "grad_norm": 0.14588932693004608,
      "learning_rate": 2.1173517630271463e-05,
      "loss": 0.0349,
      "step": 67100
    },
    {
      "epoch": 4.620779756583923,
      "grad_norm": 0.29878881573677063,
      "learning_rate": 2.1130537933880037e-05,
      "loss": 0.0327,
      "step": 67200
    },
    {
      "epoch": 4.627655916935983,
      "grad_norm": 0.2084105759859085,
      "learning_rate": 2.108755823748861e-05,
      "loss": 0.0338,
      "step": 67300
    },
    {
      "epoch": 4.634532077288043,
      "grad_norm": 0.2111458033323288,
      "learning_rate": 2.1044578541097188e-05,
      "loss": 0.0347,
      "step": 67400
    },
    {
      "epoch": 4.641408237640102,
      "grad_norm": 0.15314450860023499,
      "learning_rate": 2.100159884470576e-05,
      "loss": 0.0323,
      "step": 67500
    },
    {
      "epoch": 4.648284397992161,
      "grad_norm": 0.19051888585090637,
      "learning_rate": 2.095861914831434e-05,
      "loss": 0.0328,
      "step": 67600
    },
    {
      "epoch": 4.655160558344221,
      "grad_norm": 0.18176519870758057,
      "learning_rate": 2.0915639451922913e-05,
      "loss": 0.033,
      "step": 67700
    },
    {
      "epoch": 4.66203671869628,
      "grad_norm": 0.10776450484991074,
      "learning_rate": 2.0872659755531487e-05,
      "loss": 0.0328,
      "step": 67800
    },
    {
      "epoch": 4.66891287904834,
      "grad_norm": 0.2621956467628479,
      "learning_rate": 2.0829680059140064e-05,
      "loss": 0.0337,
      "step": 67900
    },
    {
      "epoch": 4.6757890394003985,
      "grad_norm": 0.1515674591064453,
      "learning_rate": 2.0786700362748638e-05,
      "loss": 0.0339,
      "step": 68000
    },
    {
      "epoch": 4.682665199752458,
      "grad_norm": 0.18604953587055206,
      "learning_rate": 2.0743720666357215e-05,
      "loss": 0.0342,
      "step": 68100
    },
    {
      "epoch": 4.689541360104518,
      "grad_norm": 0.16777458786964417,
      "learning_rate": 2.070074096996579e-05,
      "loss": 0.0318,
      "step": 68200
    },
    {
      "epoch": 4.696417520456577,
      "grad_norm": 0.16798532009124756,
      "learning_rate": 2.0657761273574363e-05,
      "loss": 0.0319,
      "step": 68300
    },
    {
      "epoch": 4.7032936808086365,
      "grad_norm": 0.1366761326789856,
      "learning_rate": 2.061478157718294e-05,
      "loss": 0.0351,
      "step": 68400
    },
    {
      "epoch": 4.710169841160695,
      "grad_norm": 0.22680741548538208,
      "learning_rate": 2.057223167775543e-05,
      "loss": 0.0346,
      "step": 68500
    },
    {
      "epoch": 4.717046001512755,
      "grad_norm": 0.14654332399368286,
      "learning_rate": 2.0529251981364003e-05,
      "loss": 0.0327,
      "step": 68600
    },
    {
      "epoch": 4.723922161864815,
      "grad_norm": 0.1757180392742157,
      "learning_rate": 2.048627228497258e-05,
      "loss": 0.0332,
      "step": 68700
    },
    {
      "epoch": 4.730798322216874,
      "grad_norm": 0.11700525879859924,
      "learning_rate": 2.0443292588581155e-05,
      "loss": 0.0306,
      "step": 68800
    },
    {
      "epoch": 4.737674482568933,
      "grad_norm": 0.2424650937318802,
      "learning_rate": 2.040031289218973e-05,
      "loss": 0.0316,
      "step": 68900
    },
    {
      "epoch": 4.744550642920993,
      "grad_norm": 0.14508433640003204,
      "learning_rate": 2.0357333195798306e-05,
      "loss": 0.0322,
      "step": 69000
    },
    {
      "epoch": 4.751426803273052,
      "grad_norm": 0.16611002385616302,
      "learning_rate": 2.0314353499406883e-05,
      "loss": 0.0341,
      "step": 69100
    },
    {
      "epoch": 4.758302963625112,
      "grad_norm": 0.09239938855171204,
      "learning_rate": 2.0271373803015457e-05,
      "loss": 0.0339,
      "step": 69200
    },
    {
      "epoch": 4.7651791239771715,
      "grad_norm": 0.26343703269958496,
      "learning_rate": 2.022839410662403e-05,
      "loss": 0.0331,
      "step": 69300
    },
    {
      "epoch": 4.77205528432923,
      "grad_norm": 0.14856036007404327,
      "learning_rate": 2.0185414410232605e-05,
      "loss": 0.0324,
      "step": 69400
    },
    {
      "epoch": 4.77893144468129,
      "grad_norm": 0.12232036888599396,
      "learning_rate": 2.0142434713841182e-05,
      "loss": 0.034,
      "step": 69500
    },
    {
      "epoch": 4.78580760503335,
      "grad_norm": 0.07275597751140594,
      "learning_rate": 2.009945501744976e-05,
      "loss": 0.0318,
      "step": 69600
    },
    {
      "epoch": 4.792683765385409,
      "grad_norm": 0.24474115669727325,
      "learning_rate": 2.0056475321058333e-05,
      "loss": 0.0356,
      "step": 69700
    },
    {
      "epoch": 4.799559925737468,
      "grad_norm": 0.2802883982658386,
      "learning_rate": 2.0013495624666907e-05,
      "loss": 0.0308,
      "step": 69800
    },
    {
      "epoch": 4.806436086089528,
      "grad_norm": 0.1938326209783554,
      "learning_rate": 1.997051592827548e-05,
      "loss": 0.0353,
      "step": 69900
    },
    {
      "epoch": 4.813312246441587,
      "grad_norm": 0.1473124921321869,
      "learning_rate": 1.992753623188406e-05,
      "loss": 0.0347,
      "step": 70000
    },
    {
      "epoch": 4.820188406793647,
      "grad_norm": 0.19626638293266296,
      "learning_rate": 1.9884556535492636e-05,
      "loss": 0.0328,
      "step": 70100
    },
    {
      "epoch": 4.8270645671457055,
      "grad_norm": 0.26520827412605286,
      "learning_rate": 1.984157683910121e-05,
      "loss": 0.0351,
      "step": 70200
    },
    {
      "epoch": 4.833940727497765,
      "grad_norm": 0.10213208198547363,
      "learning_rate": 1.9798597142709784e-05,
      "loss": 0.0342,
      "step": 70300
    },
    {
      "epoch": 4.840816887849825,
      "grad_norm": 0.18873435258865356,
      "learning_rate": 1.975561744631836e-05,
      "loss": 0.0317,
      "step": 70400
    },
    {
      "epoch": 4.847693048201884,
      "grad_norm": 0.31680023670196533,
      "learning_rate": 1.971306754689085e-05,
      "loss": 0.0374,
      "step": 70500
    },
    {
      "epoch": 4.854569208553944,
      "grad_norm": 0.15515288710594177,
      "learning_rate": 1.9670087850499424e-05,
      "loss": 0.0378,
      "step": 70600
    },
    {
      "epoch": 4.861445368906002,
      "grad_norm": 0.13381575047969818,
      "learning_rate": 1.9627108154108e-05,
      "loss": 0.0334,
      "step": 70700
    },
    {
      "epoch": 4.868321529258062,
      "grad_norm": 0.1613621562719345,
      "learning_rate": 1.9584128457716575e-05,
      "loss": 0.0303,
      "step": 70800
    },
    {
      "epoch": 4.875197689610122,
      "grad_norm": 0.21056810021400452,
      "learning_rate": 1.9541148761325152e-05,
      "loss": 0.0335,
      "step": 70900
    },
    {
      "epoch": 4.882073849962181,
      "grad_norm": 0.1797381341457367,
      "learning_rate": 1.9498169064933726e-05,
      "loss": 0.0373,
      "step": 71000
    },
    {
      "epoch": 4.8889500103142405,
      "grad_norm": 0.15144316852092743,
      "learning_rate": 1.94551893685423e-05,
      "loss": 0.0317,
      "step": 71100
    },
    {
      "epoch": 4.8958261706663,
      "grad_norm": 0.18092958629131317,
      "learning_rate": 1.9412209672150878e-05,
      "loss": 0.0352,
      "step": 71200
    },
    {
      "epoch": 4.902702331018359,
      "grad_norm": 0.20304124057292938,
      "learning_rate": 1.936922997575945e-05,
      "loss": 0.0363,
      "step": 71300
    },
    {
      "epoch": 4.909578491370419,
      "grad_norm": 0.11968424916267395,
      "learning_rate": 1.932625027936803e-05,
      "loss": 0.0325,
      "step": 71400
    },
    {
      "epoch": 4.9164546517224785,
      "grad_norm": 0.1250702142715454,
      "learning_rate": 1.9283270582976603e-05,
      "loss": 0.0336,
      "step": 71500
    },
    {
      "epoch": 4.923330812074537,
      "grad_norm": 0.16815459728240967,
      "learning_rate": 1.9240290886585177e-05,
      "loss": 0.0364,
      "step": 71600
    },
    {
      "epoch": 4.930206972426597,
      "grad_norm": 0.16349314153194427,
      "learning_rate": 1.9197311190193754e-05,
      "loss": 0.0372,
      "step": 71700
    },
    {
      "epoch": 4.937083132778657,
      "grad_norm": 0.20065590739250183,
      "learning_rate": 1.915433149380233e-05,
      "loss": 0.0342,
      "step": 71800
    },
    {
      "epoch": 4.943959293130716,
      "grad_norm": 0.2566744387149811,
      "learning_rate": 1.9111351797410905e-05,
      "loss": 0.034,
      "step": 71900
    },
    {
      "epoch": 4.950835453482775,
      "grad_norm": 0.15232707560062408,
      "learning_rate": 1.9068801897983394e-05,
      "loss": 0.0319,
      "step": 72000
    },
    {
      "epoch": 4.957711613834834,
      "grad_norm": 0.22626297175884247,
      "learning_rate": 1.9025822201591968e-05,
      "loss": 0.0317,
      "step": 72100
    },
    {
      "epoch": 4.964587774186894,
      "grad_norm": 0.2660413384437561,
      "learning_rate": 1.8982842505200542e-05,
      "loss": 0.0339,
      "step": 72200
    },
    {
      "epoch": 4.971463934538954,
      "grad_norm": 0.12668654322624207,
      "learning_rate": 1.893986280880912e-05,
      "loss": 0.0312,
      "step": 72300
    },
    {
      "epoch": 4.978340094891013,
      "grad_norm": 0.36731916666030884,
      "learning_rate": 1.8896883112417697e-05,
      "loss": 0.0327,
      "step": 72400
    },
    {
      "epoch": 4.985216255243072,
      "grad_norm": 0.29070982336997986,
      "learning_rate": 1.885390341602627e-05,
      "loss": 0.0356,
      "step": 72500
    },
    {
      "epoch": 4.992092415595132,
      "grad_norm": 0.13517481088638306,
      "learning_rate": 1.8810923719634844e-05,
      "loss": 0.0326,
      "step": 72600
    },
    {
      "epoch": 4.998968575947191,
      "grad_norm": 0.30464524030685425,
      "learning_rate": 1.8767944023243418e-05,
      "loss": 0.0344,
      "step": 72700
    },
    {
      "epoch": 5.0,
      "eval_accuracy_macro_0.5": 0.9844584465026855,
      "eval_accuracy_micro_0.5": 0.9844583868980408,
      "eval_accuracy_weighted_0.5": 0.9822306632995605,
      "eval_f1_macro_0.5": 0.8002992272377014,
      "eval_f1_macro_0.6": 0.7884661555290222,
      "eval_f1_macro_0.7": 0.7648904919624329,
      "eval_f1_macro_0.8": 0.6289801597595215,
      "eval_f1_micro_0.5": 0.7984704971313477,
      "eval_f1_micro_0.6": 0.7886585593223572,
      "eval_f1_micro_0.7": 0.768463671207428,
      "eval_f1_micro_0.8": 0.7295936942100525,
      "eval_f1_micro_0.9": 0.6452028155326843,
      "eval_f1_weighted_0.5": 0.7949141263961792,
      "eval_f1_weighted_0.6": 0.7822304368019104,
      "eval_f1_weighted_0.7": 0.7580466270446777,
      "eval_f1_weighted_0.8": 0.6171473860740662,
      "eval_loss": 0.03201848268508911,
      "eval_runtime": 133.4483,
      "eval_samples_per_second": 217.59,
      "eval_steps_per_second": 27.202,
      "step": 72715
    },
    {
      "epoch": 5.005844736299251,
      "grad_norm": 0.15696091949939728,
      "learning_rate": 1.8724964326851996e-05,
      "loss": 0.0323,
      "step": 72800
    },
    {
      "epoch": 5.0127208966513095,
      "grad_norm": 0.2534469962120056,
      "learning_rate": 1.8681984630460573e-05,
      "loss": 0.0308,
      "step": 72900
    },
    {
      "epoch": 5.019597057003369,
      "grad_norm": 0.15292450785636902,
      "learning_rate": 1.8639004934069147e-05,
      "loss": 0.0321,
      "step": 73000
    },
    {
      "epoch": 5.026473217355429,
      "grad_norm": 0.1770259439945221,
      "learning_rate": 1.859602523767772e-05,
      "loss": 0.0329,
      "step": 73100
    },
    {
      "epoch": 5.033349377707488,
      "grad_norm": 0.24759796261787415,
      "learning_rate": 1.8553045541286298e-05,
      "loss": 0.0328,
      "step": 73200
    },
    {
      "epoch": 5.0402255380595475,
      "grad_norm": 0.24219092726707458,
      "learning_rate": 1.8510065844894872e-05,
      "loss": 0.0293,
      "step": 73300
    },
    {
      "epoch": 5.047101698411607,
      "grad_norm": 0.18430694937705994,
      "learning_rate": 1.846708614850345e-05,
      "loss": 0.0316,
      "step": 73400
    },
    {
      "epoch": 5.053977858763666,
      "grad_norm": 0.18894535303115845,
      "learning_rate": 1.8424106452112023e-05,
      "loss": 0.0321,
      "step": 73500
    },
    {
      "epoch": 5.060854019115726,
      "grad_norm": 0.2153482288122177,
      "learning_rate": 1.8381556552684512e-05,
      "loss": 0.0341,
      "step": 73600
    },
    {
      "epoch": 5.067730179467786,
      "grad_norm": 0.21578533947467804,
      "learning_rate": 1.833857685629309e-05,
      "loss": 0.034,
      "step": 73700
    },
    {
      "epoch": 5.074606339819844,
      "grad_norm": 0.13020074367523193,
      "learning_rate": 1.8295597159901663e-05,
      "loss": 0.032,
      "step": 73800
    },
    {
      "epoch": 5.081482500171904,
      "grad_norm": 0.2637088894844055,
      "learning_rate": 1.8252617463510237e-05,
      "loss": 0.0332,
      "step": 73900
    },
    {
      "epoch": 5.088358660523963,
      "grad_norm": 0.15682454407215118,
      "learning_rate": 1.8209637767118815e-05,
      "loss": 0.0325,
      "step": 74000
    },
    {
      "epoch": 5.095234820876023,
      "grad_norm": 0.23192711174488068,
      "learning_rate": 1.816665807072739e-05,
      "loss": 0.0322,
      "step": 74100
    },
    {
      "epoch": 5.1021109812280825,
      "grad_norm": 0.25272491574287415,
      "learning_rate": 1.8123678374335966e-05,
      "loss": 0.0331,
      "step": 74200
    },
    {
      "epoch": 5.108987141580141,
      "grad_norm": 0.2530580759048462,
      "learning_rate": 1.808069867794454e-05,
      "loss": 0.0333,
      "step": 74300
    },
    {
      "epoch": 5.115863301932201,
      "grad_norm": 0.1735498309135437,
      "learning_rate": 1.8037718981553114e-05,
      "loss": 0.0323,
      "step": 74400
    },
    {
      "epoch": 5.122739462284261,
      "grad_norm": 0.18543656170368195,
      "learning_rate": 1.799473928516169e-05,
      "loss": 0.0323,
      "step": 74500
    },
    {
      "epoch": 5.12961562263632,
      "grad_norm": 0.11130261421203613,
      "learning_rate": 1.7951759588770265e-05,
      "loss": 0.0328,
      "step": 74600
    },
    {
      "epoch": 5.136491782988379,
      "grad_norm": 0.21795795857906342,
      "learning_rate": 1.7908779892378842e-05,
      "loss": 0.0309,
      "step": 74700
    },
    {
      "epoch": 5.143367943340439,
      "grad_norm": 0.30880358815193176,
      "learning_rate": 1.7865800195987416e-05,
      "loss": 0.0348,
      "step": 74800
    },
    {
      "epoch": 5.150244103692498,
      "grad_norm": 0.07930556684732437,
      "learning_rate": 1.782282049959599e-05,
      "loss": 0.0307,
      "step": 74900
    },
    {
      "epoch": 5.157120264044558,
      "grad_norm": 0.19424040615558624,
      "learning_rate": 1.7779840803204567e-05,
      "loss": 0.0311,
      "step": 75000
    },
    {
      "epoch": 5.1639964243966165,
      "grad_norm": 0.21034057438373566,
      "learning_rate": 1.7736861106813145e-05,
      "loss": 0.0326,
      "step": 75100
    },
    {
      "epoch": 5.170872584748676,
      "grad_norm": 0.11509355902671814,
      "learning_rate": 1.769388141042172e-05,
      "loss": 0.0321,
      "step": 75200
    },
    {
      "epoch": 5.177748745100736,
      "grad_norm": 0.1627257764339447,
      "learning_rate": 1.7650901714030292e-05,
      "loss": 0.0314,
      "step": 75300
    },
    {
      "epoch": 5.184624905452795,
      "grad_norm": 0.1477506309747696,
      "learning_rate": 1.7607922017638866e-05,
      "loss": 0.0338,
      "step": 75400
    },
    {
      "epoch": 5.191501065804855,
      "grad_norm": 0.20425815880298615,
      "learning_rate": 1.7564942321247444e-05,
      "loss": 0.0355,
      "step": 75500
    },
    {
      "epoch": 5.198377226156914,
      "grad_norm": 0.26690447330474854,
      "learning_rate": 1.752196262485602e-05,
      "loss": 0.0297,
      "step": 75600
    },
    {
      "epoch": 5.205253386508973,
      "grad_norm": 0.2931678891181946,
      "learning_rate": 1.7478982928464595e-05,
      "loss": 0.0338,
      "step": 75700
    },
    {
      "epoch": 5.212129546861033,
      "grad_norm": 0.1133149266242981,
      "learning_rate": 1.743600323207317e-05,
      "loss": 0.0328,
      "step": 75800
    },
    {
      "epoch": 5.219005707213093,
      "grad_norm": 0.11550069600343704,
      "learning_rate": 1.7393023535681746e-05,
      "loss": 0.0321,
      "step": 75900
    },
    {
      "epoch": 5.2258818675651515,
      "grad_norm": 0.20340244472026825,
      "learning_rate": 1.735004383929032e-05,
      "loss": 0.0334,
      "step": 76000
    },
    {
      "epoch": 5.232758027917211,
      "grad_norm": 0.13202902674674988,
      "learning_rate": 1.7307064142898897e-05,
      "loss": 0.0316,
      "step": 76100
    },
    {
      "epoch": 5.23963418826927,
      "grad_norm": 0.1390918791294098,
      "learning_rate": 1.726408444650747e-05,
      "loss": 0.0327,
      "step": 76200
    },
    {
      "epoch": 5.24651034862133,
      "grad_norm": 0.20976698398590088,
      "learning_rate": 1.7221104750116045e-05,
      "loss": 0.0324,
      "step": 76300
    },
    {
      "epoch": 5.2533865089733895,
      "grad_norm": 0.09997111558914185,
      "learning_rate": 1.7178125053724622e-05,
      "loss": 0.0329,
      "step": 76400
    },
    {
      "epoch": 5.260262669325448,
      "grad_norm": 0.06397620588541031,
      "learning_rate": 1.7135145357333196e-05,
      "loss": 0.0329,
      "step": 76500
    },
    {
      "epoch": 5.267138829677508,
      "grad_norm": 0.1705218404531479,
      "learning_rate": 1.7092165660941774e-05,
      "loss": 0.0329,
      "step": 76600
    },
    {
      "epoch": 5.274014990029568,
      "grad_norm": 0.1493816077709198,
      "learning_rate": 1.7049185964550347e-05,
      "loss": 0.0314,
      "step": 76700
    },
    {
      "epoch": 5.280891150381627,
      "grad_norm": 0.261342316865921,
      "learning_rate": 1.700620626815892e-05,
      "loss": 0.0322,
      "step": 76800
    },
    {
      "epoch": 5.287767310733686,
      "grad_norm": 0.20049653947353363,
      "learning_rate": 1.69632265717675e-05,
      "loss": 0.0346,
      "step": 76900
    },
    {
      "epoch": 5.294643471085745,
      "grad_norm": 0.16426986455917358,
      "learning_rate": 1.6920246875376073e-05,
      "loss": 0.0324,
      "step": 77000
    },
    {
      "epoch": 5.301519631437805,
      "grad_norm": 0.2790388762950897,
      "learning_rate": 1.687726717898465e-05,
      "loss": 0.0333,
      "step": 77100
    },
    {
      "epoch": 5.308395791789865,
      "grad_norm": 0.14901117980480194,
      "learning_rate": 1.6834287482593224e-05,
      "loss": 0.0314,
      "step": 77200
    },
    {
      "epoch": 5.315271952141924,
      "grad_norm": 0.11501359194517136,
      "learning_rate": 1.6791307786201798e-05,
      "loss": 0.034,
      "step": 77300
    },
    {
      "epoch": 5.322148112493983,
      "grad_norm": 0.18773747980594635,
      "learning_rate": 1.6748328089810375e-05,
      "loss": 0.0319,
      "step": 77400
    },
    {
      "epoch": 5.329024272846043,
      "grad_norm": 0.15519759058952332,
      "learning_rate": 1.670534839341895e-05,
      "loss": 0.0299,
      "step": 77500
    },
    {
      "epoch": 5.335900433198102,
      "grad_norm": 0.27099478244781494,
      "learning_rate": 1.6662368697027526e-05,
      "loss": 0.0369,
      "step": 77600
    },
    {
      "epoch": 5.342776593550162,
      "grad_norm": 0.15103204548358917,
      "learning_rate": 1.66193890006361e-05,
      "loss": 0.0335,
      "step": 77700
    },
    {
      "epoch": 5.349652753902221,
      "grad_norm": 0.15633544325828552,
      "learning_rate": 1.6576409304244674e-05,
      "loss": 0.0324,
      "step": 77800
    },
    {
      "epoch": 5.35652891425428,
      "grad_norm": 0.19040969014167786,
      "learning_rate": 1.653342960785325e-05,
      "loss": 0.0321,
      "step": 77900
    },
    {
      "epoch": 5.36340507460634,
      "grad_norm": 0.33063697814941406,
      "learning_rate": 1.6490449911461825e-05,
      "loss": 0.0349,
      "step": 78000
    },
    {
      "epoch": 5.370281234958399,
      "grad_norm": 0.13473711907863617,
      "learning_rate": 1.6447470215070403e-05,
      "loss": 0.034,
      "step": 78100
    },
    {
      "epoch": 5.3771573953104586,
      "grad_norm": 0.2177337110042572,
      "learning_rate": 1.6404490518678976e-05,
      "loss": 0.0313,
      "step": 78200
    },
    {
      "epoch": 5.384033555662518,
      "grad_norm": 0.23973716795444489,
      "learning_rate": 1.636151082228755e-05,
      "loss": 0.034,
      "step": 78300
    },
    {
      "epoch": 5.390909716014577,
      "grad_norm": 0.2038213163614273,
      "learning_rate": 1.6318531125896128e-05,
      "loss": 0.0341,
      "step": 78400
    },
    {
      "epoch": 5.397785876366637,
      "grad_norm": 0.08498240262269974,
      "learning_rate": 1.6275551429504705e-05,
      "loss": 0.0325,
      "step": 78500
    },
    {
      "epoch": 5.404662036718697,
      "grad_norm": 0.3177170157432556,
      "learning_rate": 1.623257173311328e-05,
      "loss": 0.0341,
      "step": 78600
    },
    {
      "epoch": 5.4115381970707555,
      "grad_norm": 0.27196818590164185,
      "learning_rate": 1.6189592036721853e-05,
      "loss": 0.0315,
      "step": 78700
    },
    {
      "epoch": 5.418414357422815,
      "grad_norm": 0.20788343250751495,
      "learning_rate": 1.6146612340330427e-05,
      "loss": 0.0315,
      "step": 78800
    },
    {
      "epoch": 5.425290517774875,
      "grad_norm": 0.22124449908733368,
      "learning_rate": 1.6103632643939004e-05,
      "loss": 0.0313,
      "step": 78900
    },
    {
      "epoch": 5.432166678126934,
      "grad_norm": 0.1249358057975769,
      "learning_rate": 1.606065294754758e-05,
      "loss": 0.0335,
      "step": 79000
    },
    {
      "epoch": 5.4390428384789935,
      "grad_norm": 0.17939405143260956,
      "learning_rate": 1.6017673251156155e-05,
      "loss": 0.031,
      "step": 79100
    },
    {
      "epoch": 5.445918998831052,
      "grad_norm": 0.13732409477233887,
      "learning_rate": 1.597469355476473e-05,
      "loss": 0.0318,
      "step": 79200
    },
    {
      "epoch": 5.452795159183112,
      "grad_norm": 0.2862655520439148,
      "learning_rate": 1.5931713858373303e-05,
      "loss": 0.0307,
      "step": 79300
    },
    {
      "epoch": 5.459671319535172,
      "grad_norm": 0.10577776283025742,
      "learning_rate": 1.588873416198188e-05,
      "loss": 0.0298,
      "step": 79400
    },
    {
      "epoch": 5.466547479887231,
      "grad_norm": 0.11028667539358139,
      "learning_rate": 1.5845754465590458e-05,
      "loss": 0.0328,
      "step": 79500
    },
    {
      "epoch": 5.47342364023929,
      "grad_norm": 0.12887410819530487,
      "learning_rate": 1.580277476919903e-05,
      "loss": 0.0341,
      "step": 79600
    },
    {
      "epoch": 5.48029980059135,
      "grad_norm": 0.1769019067287445,
      "learning_rate": 1.5759795072807605e-05,
      "loss": 0.0316,
      "step": 79700
    },
    {
      "epoch": 5.487175960943409,
      "grad_norm": 0.17544715106487274,
      "learning_rate": 1.5716815376416183e-05,
      "loss": 0.0332,
      "step": 79800
    },
    {
      "epoch": 5.494052121295469,
      "grad_norm": 0.18515101075172424,
      "learning_rate": 1.5674265476988672e-05,
      "loss": 0.0317,
      "step": 79900
    },
    {
      "epoch": 5.5009282816475285,
      "grad_norm": 0.19374072551727295,
      "learning_rate": 1.5631285780597246e-05,
      "loss": 0.0317,
      "step": 80000
    },
    {
      "epoch": 5.507804441999587,
      "grad_norm": 0.16757339239120483,
      "learning_rate": 1.5588306084205823e-05,
      "loss": 0.031,
      "step": 80100
    },
    {
      "epoch": 5.514680602351647,
      "grad_norm": 0.14569446444511414,
      "learning_rate": 1.5545326387814397e-05,
      "loss": 0.032,
      "step": 80200
    },
    {
      "epoch": 5.521556762703706,
      "grad_norm": 0.22204725444316864,
      "learning_rate": 1.5502346691422974e-05,
      "loss": 0.0298,
      "step": 80300
    },
    {
      "epoch": 5.528432923055766,
      "grad_norm": 0.1306644231081009,
      "learning_rate": 1.5459366995031548e-05,
      "loss": 0.0339,
      "step": 80400
    },
    {
      "epoch": 5.535309083407825,
      "grad_norm": 0.17498603463172913,
      "learning_rate": 1.5416387298640122e-05,
      "loss": 0.0342,
      "step": 80500
    },
    {
      "epoch": 5.542185243759884,
      "grad_norm": 0.19411951303482056,
      "learning_rate": 1.53734076022487e-05,
      "loss": 0.0326,
      "step": 80600
    },
    {
      "epoch": 5.549061404111944,
      "grad_norm": 0.18705697357654572,
      "learning_rate": 1.5330427905857273e-05,
      "loss": 0.0312,
      "step": 80700
    },
    {
      "epoch": 5.555937564464004,
      "grad_norm": 0.11188226193189621,
      "learning_rate": 1.528744820946585e-05,
      "loss": 0.0345,
      "step": 80800
    },
    {
      "epoch": 5.5628137248160625,
      "grad_norm": 0.14938651025295258,
      "learning_rate": 1.5244468513074424e-05,
      "loss": 0.0302,
      "step": 80900
    },
    {
      "epoch": 5.569689885168122,
      "grad_norm": 0.24447815120220184,
      "learning_rate": 1.5201488816682998e-05,
      "loss": 0.0333,
      "step": 81000
    },
    {
      "epoch": 5.576566045520181,
      "grad_norm": 0.15979249775409698,
      "learning_rate": 1.5158509120291576e-05,
      "loss": 0.0331,
      "step": 81100
    },
    {
      "epoch": 5.583442205872241,
      "grad_norm": 0.1614510715007782,
      "learning_rate": 1.5115529423900151e-05,
      "loss": 0.033,
      "step": 81200
    },
    {
      "epoch": 5.590318366224301,
      "grad_norm": 0.15145151317119598,
      "learning_rate": 1.5072549727508725e-05,
      "loss": 0.0331,
      "step": 81300
    },
    {
      "epoch": 5.597194526576359,
      "grad_norm": 0.18538762629032135,
      "learning_rate": 1.5029999828081214e-05,
      "loss": 0.0331,
      "step": 81400
    },
    {
      "epoch": 5.604070686928419,
      "grad_norm": 0.22093525528907776,
      "learning_rate": 1.4987020131689792e-05,
      "loss": 0.031,
      "step": 81500
    },
    {
      "epoch": 5.610946847280479,
      "grad_norm": 0.11542431265115738,
      "learning_rate": 1.4944040435298365e-05,
      "loss": 0.0341,
      "step": 81600
    },
    {
      "epoch": 5.617823007632538,
      "grad_norm": 0.1510399729013443,
      "learning_rate": 1.4901060738906941e-05,
      "loss": 0.0325,
      "step": 81700
    },
    {
      "epoch": 5.6246991679845975,
      "grad_norm": 0.16113291680812836,
      "learning_rate": 1.4858081042515518e-05,
      "loss": 0.0334,
      "step": 81800
    },
    {
      "epoch": 5.631575328336657,
      "grad_norm": 0.3021243214607239,
      "learning_rate": 1.481510134612409e-05,
      "loss": 0.0356,
      "step": 81900
    },
    {
      "epoch": 5.638451488688716,
      "grad_norm": 0.16060549020767212,
      "learning_rate": 1.4772121649732668e-05,
      "loss": 0.0343,
      "step": 82000
    },
    {
      "epoch": 5.645327649040776,
      "grad_norm": 0.1506403237581253,
      "learning_rate": 1.4729141953341242e-05,
      "loss": 0.0311,
      "step": 82100
    },
    {
      "epoch": 5.6522038093928355,
      "grad_norm": 0.30045604705810547,
      "learning_rate": 1.4686162256949817e-05,
      "loss": 0.0337,
      "step": 82200
    },
    {
      "epoch": 5.659079969744894,
      "grad_norm": 0.13174934685230255,
      "learning_rate": 1.4643182560558395e-05,
      "loss": 0.0308,
      "step": 82300
    },
    {
      "epoch": 5.665956130096954,
      "grad_norm": 0.15580135583877563,
      "learning_rate": 1.4600202864166967e-05,
      "loss": 0.0312,
      "step": 82400
    },
    {
      "epoch": 5.672832290449013,
      "grad_norm": 0.1656235158443451,
      "learning_rate": 1.4557223167775544e-05,
      "loss": 0.0329,
      "step": 82500
    },
    {
      "epoch": 5.679708450801073,
      "grad_norm": 0.2183176875114441,
      "learning_rate": 1.451424347138412e-05,
      "loss": 0.0342,
      "step": 82600
    },
    {
      "epoch": 5.686584611153132,
      "grad_norm": 0.28358325362205505,
      "learning_rate": 1.4471263774992694e-05,
      "loss": 0.0313,
      "step": 82700
    },
    {
      "epoch": 5.693460771505191,
      "grad_norm": 0.16824017465114594,
      "learning_rate": 1.442828407860127e-05,
      "loss": 0.0342,
      "step": 82800
    },
    {
      "epoch": 5.700336931857251,
      "grad_norm": 0.06626252084970474,
      "learning_rate": 1.4385304382209843e-05,
      "loss": 0.0305,
      "step": 82900
    },
    {
      "epoch": 5.70721309220931,
      "grad_norm": 0.12546119093894958,
      "learning_rate": 1.434232468581842e-05,
      "loss": 0.0327,
      "step": 83000
    },
    {
      "epoch": 5.71408925256137,
      "grad_norm": 0.12238646298646927,
      "learning_rate": 1.4299344989426996e-05,
      "loss": 0.0316,
      "step": 83100
    },
    {
      "epoch": 5.720965412913429,
      "grad_norm": 0.241071417927742,
      "learning_rate": 1.4256795089999487e-05,
      "loss": 0.0347,
      "step": 83200
    },
    {
      "epoch": 5.727841573265488,
      "grad_norm": 0.1858423352241516,
      "learning_rate": 1.4213815393608059e-05,
      "loss": 0.0352,
      "step": 83300
    },
    {
      "epoch": 5.734717733617548,
      "grad_norm": 0.22079205513000488,
      "learning_rate": 1.4170835697216636e-05,
      "loss": 0.0319,
      "step": 83400
    },
    {
      "epoch": 5.741593893969608,
      "grad_norm": 0.17904408276081085,
      "learning_rate": 1.412785600082521e-05,
      "loss": 0.0358,
      "step": 83500
    },
    {
      "epoch": 5.7484700543216665,
      "grad_norm": 0.2696501612663269,
      "learning_rate": 1.4084876304433786e-05,
      "loss": 0.0327,
      "step": 83600
    },
    {
      "epoch": 5.755346214673726,
      "grad_norm": 0.2715648412704468,
      "learning_rate": 1.4041896608042363e-05,
      "loss": 0.0338,
      "step": 83700
    },
    {
      "epoch": 5.762222375025786,
      "grad_norm": 0.19344663619995117,
      "learning_rate": 1.3998916911650935e-05,
      "loss": 0.0321,
      "step": 83800
    },
    {
      "epoch": 5.769098535377845,
      "grad_norm": 0.185787171125412,
      "learning_rate": 1.3955937215259513e-05,
      "loss": 0.0328,
      "step": 83900
    },
    {
      "epoch": 5.7759746957299045,
      "grad_norm": 0.13150611519813538,
      "learning_rate": 1.3912957518868087e-05,
      "loss": 0.0332,
      "step": 84000
    },
    {
      "epoch": 5.782850856081964,
      "grad_norm": 0.17387646436691284,
      "learning_rate": 1.3869977822476662e-05,
      "loss": 0.0336,
      "step": 84100
    },
    {
      "epoch": 5.789727016434023,
      "grad_norm": 0.24599198997020721,
      "learning_rate": 1.382699812608524e-05,
      "loss": 0.0328,
      "step": 84200
    },
    {
      "epoch": 5.796603176786083,
      "grad_norm": 0.15292567014694214,
      "learning_rate": 1.3784018429693812e-05,
      "loss": 0.0352,
      "step": 84300
    },
    {
      "epoch": 5.803479337138142,
      "grad_norm": 0.1657077968120575,
      "learning_rate": 1.3741038733302389e-05,
      "loss": 0.0335,
      "step": 84400
    },
    {
      "epoch": 5.810355497490201,
      "grad_norm": 0.23809853196144104,
      "learning_rate": 1.3698059036910965e-05,
      "loss": 0.0329,
      "step": 84500
    },
    {
      "epoch": 5.817231657842261,
      "grad_norm": 0.12894536554813385,
      "learning_rate": 1.3655079340519539e-05,
      "loss": 0.0322,
      "step": 84600
    },
    {
      "epoch": 5.82410781819432,
      "grad_norm": 0.276133269071579,
      "learning_rate": 1.3612099644128116e-05,
      "loss": 0.0311,
      "step": 84700
    },
    {
      "epoch": 5.83098397854638,
      "grad_norm": 0.1259980946779251,
      "learning_rate": 1.3569119947736688e-05,
      "loss": 0.0315,
      "step": 84800
    },
    {
      "epoch": 5.8378601388984395,
      "grad_norm": 0.13268333673477173,
      "learning_rate": 1.3526140251345265e-05,
      "loss": 0.0343,
      "step": 84900
    },
    {
      "epoch": 5.844736299250498,
      "grad_norm": 0.20796622335910797,
      "learning_rate": 1.3483160554953841e-05,
      "loss": 0.0335,
      "step": 85000
    },
    {
      "epoch": 5.851612459602558,
      "grad_norm": 0.17919686436653137,
      "learning_rate": 1.3440180858562415e-05,
      "loss": 0.0302,
      "step": 85100
    },
    {
      "epoch": 5.858488619954617,
      "grad_norm": 0.29603561758995056,
      "learning_rate": 1.3397201162170992e-05,
      "loss": 0.0317,
      "step": 85200
    },
    {
      "epoch": 5.865364780306677,
      "grad_norm": 0.12871676683425903,
      "learning_rate": 1.3354221465779564e-05,
      "loss": 0.0318,
      "step": 85300
    },
    {
      "epoch": 5.872240940658736,
      "grad_norm": 0.21935948729515076,
      "learning_rate": 1.3311241769388142e-05,
      "loss": 0.0327,
      "step": 85400
    },
    {
      "epoch": 5.879117101010795,
      "grad_norm": 0.17996959388256073,
      "learning_rate": 1.3268262072996717e-05,
      "loss": 0.0331,
      "step": 85500
    },
    {
      "epoch": 5.885993261362855,
      "grad_norm": 0.13058263063430786,
      "learning_rate": 1.3225282376605291e-05,
      "loss": 0.0322,
      "step": 85600
    },
    {
      "epoch": 5.892869421714915,
      "grad_norm": 0.1893024742603302,
      "learning_rate": 1.3182302680213867e-05,
      "loss": 0.035,
      "step": 85700
    },
    {
      "epoch": 5.8997455820669735,
      "grad_norm": 0.31200721859931946,
      "learning_rate": 1.3139322983822444e-05,
      "loss": 0.0334,
      "step": 85800
    },
    {
      "epoch": 5.906621742419033,
      "grad_norm": 0.12885792553424835,
      "learning_rate": 1.3096343287431018e-05,
      "loss": 0.0311,
      "step": 85900
    },
    {
      "epoch": 5.913497902771093,
      "grad_norm": 0.15892404317855835,
      "learning_rate": 1.3053363591039594e-05,
      "loss": 0.0305,
      "step": 86000
    },
    {
      "epoch": 5.920374063123152,
      "grad_norm": 0.20302249491214752,
      "learning_rate": 1.3010383894648168e-05,
      "loss": 0.0327,
      "step": 86100
    },
    {
      "epoch": 5.927250223475212,
      "grad_norm": 0.1540670394897461,
      "learning_rate": 1.2967404198256743e-05,
      "loss": 0.0312,
      "step": 86200
    },
    {
      "epoch": 5.934126383827271,
      "grad_norm": 0.14462128281593323,
      "learning_rate": 1.292442450186532e-05,
      "loss": 0.0327,
      "step": 86300
    },
    {
      "epoch": 5.94100254417933,
      "grad_norm": 0.1422419548034668,
      "learning_rate": 1.2881444805473894e-05,
      "loss": 0.0327,
      "step": 86400
    },
    {
      "epoch": 5.94787870453139,
      "grad_norm": 0.12783950567245483,
      "learning_rate": 1.283846510908247e-05,
      "loss": 0.0331,
      "step": 86500
    },
    {
      "epoch": 5.954754864883449,
      "grad_norm": 0.10966634750366211,
      "learning_rate": 1.2795485412691047e-05,
      "loss": 0.0305,
      "step": 86600
    },
    {
      "epoch": 5.9616310252355085,
      "grad_norm": 0.1666877120733261,
      "learning_rate": 1.275250571629962e-05,
      "loss": 0.0311,
      "step": 86700
    },
    {
      "epoch": 5.968507185587568,
      "grad_norm": 0.26057660579681396,
      "learning_rate": 1.2709526019908197e-05,
      "loss": 0.0338,
      "step": 86800
    },
    {
      "epoch": 5.975383345939627,
      "grad_norm": 0.24878673255443573,
      "learning_rate": 1.266654632351677e-05,
      "loss": 0.0353,
      "step": 86900
    },
    {
      "epoch": 5.982259506291687,
      "grad_norm": 0.2533237934112549,
      "learning_rate": 1.2623566627125346e-05,
      "loss": 0.0293,
      "step": 87000
    },
    {
      "epoch": 5.989135666643746,
      "grad_norm": 0.28267961740493774,
      "learning_rate": 1.2580586930733924e-05,
      "loss": 0.0354,
      "step": 87100
    },
    {
      "epoch": 5.996011826995805,
      "grad_norm": 0.16140641272068024,
      "learning_rate": 1.2537607234342496e-05,
      "loss": 0.0334,
      "step": 87200
    },
    {
      "epoch": 6.0,
      "eval_accuracy_macro_0.5": 0.9849190711975098,
      "eval_accuracy_micro_0.5": 0.984919011592865,
      "eval_accuracy_weighted_0.5": 0.9827274680137634,
      "eval_f1_macro_0.5": 0.8075882196426392,
      "eval_f1_macro_0.6": 0.795887291431427,
      "eval_f1_macro_0.7": 0.7727782726287842,
      "eval_f1_macro_0.8": 0.6407791972160339,
      "eval_f1_micro_0.5": 0.8044215440750122,
      "eval_f1_micro_0.6": 0.7945165634155273,
      "eval_f1_micro_0.7": 0.7749516367912292,
      "eval_f1_micro_0.8": 0.736233115196228,
      "eval_f1_micro_0.9": 0.6540956497192383,
      "eval_f1_weighted_0.5": 0.8015046715736389,
      "eval_f1_weighted_0.6": 0.7889597415924072,
      "eval_f1_weighted_0.7": 0.7656279802322388,
      "eval_f1_weighted_0.8": 0.6283445954322815,
      "eval_loss": 0.03096751682460308,
      "eval_runtime": 133.415,
      "eval_samples_per_second": 217.644,
      "eval_steps_per_second": 27.208,
      "step": 87258
    },
    {
      "epoch": 6.002887987347865,
      "grad_norm": 0.2697755992412567,
      "learning_rate": 1.2494627537951073e-05,
      "loss": 0.032,
      "step": 87300
    },
    {
      "epoch": 6.009764147699924,
      "grad_norm": 0.1388017237186432,
      "learning_rate": 1.2451647841559649e-05,
      "loss": 0.0311,
      "step": 87400
    },
    {
      "epoch": 6.016640308051984,
      "grad_norm": 0.08997771143913269,
      "learning_rate": 1.2408668145168223e-05,
      "loss": 0.0298,
      "step": 87500
    },
    {
      "epoch": 6.023516468404043,
      "grad_norm": 0.4214416742324829,
      "learning_rate": 1.2365688448776798e-05,
      "loss": 0.0312,
      "step": 87600
    },
    {
      "epoch": 6.030392628756102,
      "grad_norm": 0.19983012974262238,
      "learning_rate": 1.2322708752385374e-05,
      "loss": 0.034,
      "step": 87700
    },
    {
      "epoch": 6.037268789108162,
      "grad_norm": 0.21690572798252106,
      "learning_rate": 1.227972905599395e-05,
      "loss": 0.0299,
      "step": 87800
    },
    {
      "epoch": 6.044144949460222,
      "grad_norm": 0.11273239552974701,
      "learning_rate": 1.2236749359602523e-05,
      "loss": 0.0332,
      "step": 87900
    },
    {
      "epoch": 6.051021109812281,
      "grad_norm": 0.18303434550762177,
      "learning_rate": 1.2193769663211099e-05,
      "loss": 0.0319,
      "step": 88000
    },
    {
      "epoch": 6.05789727016434,
      "grad_norm": 0.1562223881483078,
      "learning_rate": 1.215121976378359e-05,
      "loss": 0.0292,
      "step": 88100
    },
    {
      "epoch": 6.0647734305164,
      "grad_norm": 0.22689731419086456,
      "learning_rate": 1.2108240067392164e-05,
      "loss": 0.0319,
      "step": 88200
    },
    {
      "epoch": 6.071649590868459,
      "grad_norm": 0.10467218607664108,
      "learning_rate": 1.2065260371000741e-05,
      "loss": 0.0301,
      "step": 88300
    },
    {
      "epoch": 6.078525751220519,
      "grad_norm": 0.18527723848819733,
      "learning_rate": 1.2022280674609315e-05,
      "loss": 0.0314,
      "step": 88400
    },
    {
      "epoch": 6.0854019115725775,
      "grad_norm": 0.19774183630943298,
      "learning_rate": 1.197930097821789e-05,
      "loss": 0.0343,
      "step": 88500
    },
    {
      "epoch": 6.092278071924637,
      "grad_norm": 0.2933342158794403,
      "learning_rate": 1.1936321281826464e-05,
      "loss": 0.0347,
      "step": 88600
    },
    {
      "epoch": 6.099154232276697,
      "grad_norm": 0.16677041351795197,
      "learning_rate": 1.1893341585435042e-05,
      "loss": 0.032,
      "step": 88700
    },
    {
      "epoch": 6.106030392628756,
      "grad_norm": 0.1336669921875,
      "learning_rate": 1.1850361889043617e-05,
      "loss": 0.0339,
      "step": 88800
    },
    {
      "epoch": 6.1129065529808155,
      "grad_norm": 0.04805508628487587,
      "learning_rate": 1.1807382192652191e-05,
      "loss": 0.031,
      "step": 88900
    },
    {
      "epoch": 6.119782713332875,
      "grad_norm": 0.162921741604805,
      "learning_rate": 1.1764402496260767e-05,
      "loss": 0.0321,
      "step": 89000
    },
    {
      "epoch": 6.126658873684934,
      "grad_norm": 0.12688200175762177,
      "learning_rate": 1.1721422799869342e-05,
      "loss": 0.033,
      "step": 89100
    },
    {
      "epoch": 6.133535034036994,
      "grad_norm": 0.16089266538619995,
      "learning_rate": 1.1678443103477918e-05,
      "loss": 0.0337,
      "step": 89200
    },
    {
      "epoch": 6.140411194389053,
      "grad_norm": 0.18094618618488312,
      "learning_rate": 1.1635463407086494e-05,
      "loss": 0.0314,
      "step": 89300
    },
    {
      "epoch": 6.147287354741112,
      "grad_norm": 0.20763598382472992,
      "learning_rate": 1.1592483710695068e-05,
      "loss": 0.0311,
      "step": 89400
    },
    {
      "epoch": 6.154163515093172,
      "grad_norm": 0.2302483320236206,
      "learning_rate": 1.1549504014303643e-05,
      "loss": 0.0325,
      "step": 89500
    },
    {
      "epoch": 6.161039675445231,
      "grad_norm": 0.3417641818523407,
      "learning_rate": 1.1506524317912219e-05,
      "loss": 0.0308,
      "step": 89600
    },
    {
      "epoch": 6.167915835797291,
      "grad_norm": 0.3204025626182556,
      "learning_rate": 1.1463544621520794e-05,
      "loss": 0.0319,
      "step": 89700
    },
    {
      "epoch": 6.1747919961493505,
      "grad_norm": 0.1616019755601883,
      "learning_rate": 1.142056492512937e-05,
      "loss": 0.0334,
      "step": 89800
    },
    {
      "epoch": 6.181668156501409,
      "grad_norm": 0.17289206385612488,
      "learning_rate": 1.1377585228737944e-05,
      "loss": 0.0337,
      "step": 89900
    },
    {
      "epoch": 6.188544316853469,
      "grad_norm": 0.18691904842853546,
      "learning_rate": 1.1334605532346521e-05,
      "loss": 0.0321,
      "step": 90000
    },
    {
      "epoch": 6.195420477205529,
      "grad_norm": 0.32534077763557434,
      "learning_rate": 1.1291625835955095e-05,
      "loss": 0.0323,
      "step": 90100
    },
    {
      "epoch": 6.202296637557588,
      "grad_norm": 0.1463542878627777,
      "learning_rate": 1.124864613956367e-05,
      "loss": 0.0321,
      "step": 90200
    },
    {
      "epoch": 6.209172797909647,
      "grad_norm": 0.18313603103160858,
      "learning_rate": 1.1205666443172246e-05,
      "loss": 0.0316,
      "step": 90300
    },
    {
      "epoch": 6.216048958261707,
      "grad_norm": 0.2251037359237671,
      "learning_rate": 1.1162686746780822e-05,
      "loss": 0.0319,
      "step": 90400
    },
    {
      "epoch": 6.222925118613766,
      "grad_norm": 0.27962592244148254,
      "learning_rate": 1.1119707050389398e-05,
      "loss": 0.0331,
      "step": 90500
    },
    {
      "epoch": 6.229801278965826,
      "grad_norm": 0.19257937371730804,
      "learning_rate": 1.1076727353997971e-05,
      "loss": 0.0299,
      "step": 90600
    },
    {
      "epoch": 6.2366774393178845,
      "grad_norm": 0.08644678443670273,
      "learning_rate": 1.1033747657606547e-05,
      "loss": 0.0297,
      "step": 90700
    },
    {
      "epoch": 6.243553599669944,
      "grad_norm": 0.237782284617424,
      "learning_rate": 1.0990767961215121e-05,
      "loss": 0.0313,
      "step": 90800
    },
    {
      "epoch": 6.250429760022004,
      "grad_norm": 0.27371299266815186,
      "learning_rate": 1.0947788264823698e-05,
      "loss": 0.0318,
      "step": 90900
    },
    {
      "epoch": 6.257305920374063,
      "grad_norm": 0.1845482736825943,
      "learning_rate": 1.0904808568432274e-05,
      "loss": 0.0344,
      "step": 91000
    },
    {
      "epoch": 6.264182080726123,
      "grad_norm": 0.22030837833881378,
      "learning_rate": 1.0862258669004763e-05,
      "loss": 0.0331,
      "step": 91100
    },
    {
      "epoch": 6.271058241078182,
      "grad_norm": 0.18034523725509644,
      "learning_rate": 1.0819278972613339e-05,
      "loss": 0.0319,
      "step": 91200
    },
    {
      "epoch": 6.277934401430241,
      "grad_norm": 0.18649862706661224,
      "learning_rate": 1.0776299276221912e-05,
      "loss": 0.0298,
      "step": 91300
    },
    {
      "epoch": 6.284810561782301,
      "grad_norm": 0.19167885184288025,
      "learning_rate": 1.073331957983049e-05,
      "loss": 0.0327,
      "step": 91400
    },
    {
      "epoch": 6.29168672213436,
      "grad_norm": 0.2514731287956238,
      "learning_rate": 1.0690339883439064e-05,
      "loss": 0.0317,
      "step": 91500
    },
    {
      "epoch": 6.2985628824864195,
      "grad_norm": 0.26021286845207214,
      "learning_rate": 1.064736018704764e-05,
      "loss": 0.0313,
      "step": 91600
    },
    {
      "epoch": 6.305439042838479,
      "grad_norm": 0.21721574664115906,
      "learning_rate": 1.0604380490656215e-05,
      "loss": 0.0323,
      "step": 91700
    },
    {
      "epoch": 6.312315203190538,
      "grad_norm": 0.13005593419075012,
      "learning_rate": 1.056140079426479e-05,
      "loss": 0.0361,
      "step": 91800
    },
    {
      "epoch": 6.319191363542598,
      "grad_norm": 0.11923662573099136,
      "learning_rate": 1.0518421097873366e-05,
      "loss": 0.0334,
      "step": 91900
    },
    {
      "epoch": 6.3260675238946575,
      "grad_norm": 0.17067204415798187,
      "learning_rate": 1.047544140148194e-05,
      "loss": 0.032,
      "step": 92000
    },
    {
      "epoch": 6.332943684246716,
      "grad_norm": 0.19187454879283905,
      "learning_rate": 1.0432461705090516e-05,
      "loss": 0.0313,
      "step": 92100
    },
    {
      "epoch": 6.339819844598776,
      "grad_norm": 0.24901188910007477,
      "learning_rate": 1.0389482008699091e-05,
      "loss": 0.0313,
      "step": 92200
    },
    {
      "epoch": 6.346696004950836,
      "grad_norm": 0.16788800060749054,
      "learning_rate": 1.0346502312307667e-05,
      "loss": 0.0321,
      "step": 92300
    },
    {
      "epoch": 6.353572165302895,
      "grad_norm": 0.3032115697860718,
      "learning_rate": 1.0303522615916242e-05,
      "loss": 0.0332,
      "step": 92400
    },
    {
      "epoch": 6.360448325654954,
      "grad_norm": 0.20208731293678284,
      "learning_rate": 1.0260542919524816e-05,
      "loss": 0.0349,
      "step": 92500
    },
    {
      "epoch": 6.367324486007013,
      "grad_norm": 0.16416309773921967,
      "learning_rate": 1.0217563223133392e-05,
      "loss": 0.0315,
      "step": 92600
    },
    {
      "epoch": 6.374200646359073,
      "grad_norm": 0.3787587881088257,
      "learning_rate": 1.0174583526741968e-05,
      "loss": 0.0325,
      "step": 92700
    },
    {
      "epoch": 6.381076806711133,
      "grad_norm": 0.21940229833126068,
      "learning_rate": 1.0131603830350543e-05,
      "loss": 0.0313,
      "step": 92800
    },
    {
      "epoch": 6.387952967063192,
      "grad_norm": 0.16271710395812988,
      "learning_rate": 1.0088624133959119e-05,
      "loss": 0.0313,
      "step": 92900
    },
    {
      "epoch": 6.394829127415251,
      "grad_norm": 0.21378186345100403,
      "learning_rate": 1.0046074234531608e-05,
      "loss": 0.0305,
      "step": 93000
    },
    {
      "epoch": 6.401705287767311,
      "grad_norm": 0.1249094009399414,
      "learning_rate": 1.0003094538140183e-05,
      "loss": 0.0323,
      "step": 93100
    },
    {
      "epoch": 6.40858144811937,
      "grad_norm": 0.17382323741912842,
      "learning_rate": 9.960114841748757e-06,
      "loss": 0.0313,
      "step": 93200
    },
    {
      "epoch": 6.41545760847143,
      "grad_norm": 0.14474333822727203,
      "learning_rate": 9.917135145357335e-06,
      "loss": 0.0321,
      "step": 93300
    },
    {
      "epoch": 6.4223337688234885,
      "grad_norm": 0.17463402450084686,
      "learning_rate": 9.874155448965909e-06,
      "loss": 0.031,
      "step": 93400
    },
    {
      "epoch": 6.429209929175548,
      "grad_norm": 0.24103385210037231,
      "learning_rate": 9.831175752574484e-06,
      "loss": 0.0304,
      "step": 93500
    },
    {
      "epoch": 6.436086089527608,
      "grad_norm": 0.2795628607273102,
      "learning_rate": 9.78819605618306e-06,
      "loss": 0.0328,
      "step": 93600
    },
    {
      "epoch": 6.442962249879667,
      "grad_norm": 0.18835918605327606,
      "learning_rate": 9.745216359791635e-06,
      "loss": 0.0293,
      "step": 93700
    },
    {
      "epoch": 6.4498384102317265,
      "grad_norm": 0.13818036019802094,
      "learning_rate": 9.702236663400211e-06,
      "loss": 0.0309,
      "step": 93800
    },
    {
      "epoch": 6.456714570583786,
      "grad_norm": 0.30028027296066284,
      "learning_rate": 9.659256967008785e-06,
      "loss": 0.0338,
      "step": 93900
    },
    {
      "epoch": 6.463590730935845,
      "grad_norm": 0.12212613224983215,
      "learning_rate": 9.61627727061736e-06,
      "loss": 0.028,
      "step": 94000
    },
    {
      "epoch": 6.470466891287905,
      "grad_norm": 0.26392269134521484,
      "learning_rate": 9.573297574225936e-06,
      "loss": 0.0336,
      "step": 94100
    },
    {
      "epoch": 6.477343051639965,
      "grad_norm": 0.14211411774158478,
      "learning_rate": 9.530317877834512e-06,
      "loss": 0.0302,
      "step": 94200
    },
    {
      "epoch": 6.4842192119920234,
      "grad_norm": 0.3688662648200989,
      "learning_rate": 9.487338181443087e-06,
      "loss": 0.0301,
      "step": 94300
    },
    {
      "epoch": 6.491095372344083,
      "grad_norm": 0.2554140090942383,
      "learning_rate": 9.444358485051661e-06,
      "loss": 0.0317,
      "step": 94400
    },
    {
      "epoch": 6.497971532696143,
      "grad_norm": 0.2929839789867401,
      "learning_rate": 9.401378788660237e-06,
      "loss": 0.0316,
      "step": 94500
    },
    {
      "epoch": 6.504847693048202,
      "grad_norm": 0.2118287980556488,
      "learning_rate": 9.358399092268812e-06,
      "loss": 0.0312,
      "step": 94600
    },
    {
      "epoch": 6.5117238534002615,
      "grad_norm": 0.16543494164943695,
      "learning_rate": 9.315419395877388e-06,
      "loss": 0.0303,
      "step": 94700
    },
    {
      "epoch": 6.51860001375232,
      "grad_norm": 0.19433489441871643,
      "learning_rate": 9.272439699485964e-06,
      "loss": 0.0332,
      "step": 94800
    },
    {
      "epoch": 6.52547617410438,
      "grad_norm": 0.13171038031578064,
      "learning_rate": 9.229460003094538e-06,
      "loss": 0.0297,
      "step": 94900
    },
    {
      "epoch": 6.53235233445644,
      "grad_norm": 0.20348693430423737,
      "learning_rate": 9.186480306703115e-06,
      "loss": 0.0311,
      "step": 95000
    },
    {
      "epoch": 6.539228494808499,
      "grad_norm": 0.07322593778371811,
      "learning_rate": 9.143500610311689e-06,
      "loss": 0.0307,
      "step": 95100
    },
    {
      "epoch": 6.546104655160558,
      "grad_norm": 0.5042943954467773,
      "learning_rate": 9.100520913920264e-06,
      "loss": 0.0336,
      "step": 95200
    },
    {
      "epoch": 6.552980815512618,
      "grad_norm": 0.2048545479774475,
      "learning_rate": 9.05754121752884e-06,
      "loss": 0.0307,
      "step": 95300
    },
    {
      "epoch": 6.559856975864677,
      "grad_norm": 0.11657595634460449,
      "learning_rate": 9.014561521137416e-06,
      "loss": 0.0303,
      "step": 95400
    },
    {
      "epoch": 6.566733136216737,
      "grad_norm": 0.08815329521894455,
      "learning_rate": 8.971581824745991e-06,
      "loss": 0.0304,
      "step": 95500
    },
    {
      "epoch": 6.573609296568796,
      "grad_norm": 0.1352669894695282,
      "learning_rate": 8.928602128354565e-06,
      "loss": 0.0303,
      "step": 95600
    },
    {
      "epoch": 6.580485456920855,
      "grad_norm": 0.1950332671403885,
      "learning_rate": 8.88562243196314e-06,
      "loss": 0.034,
      "step": 95700
    },
    {
      "epoch": 6.587361617272915,
      "grad_norm": 0.18973013758659363,
      "learning_rate": 8.842642735571716e-06,
      "loss": 0.0323,
      "step": 95800
    },
    {
      "epoch": 6.594237777624974,
      "grad_norm": 0.19959242641925812,
      "learning_rate": 8.799663039180292e-06,
      "loss": 0.0319,
      "step": 95900
    },
    {
      "epoch": 6.601113937977034,
      "grad_norm": 0.31822678446769714,
      "learning_rate": 8.756683342788867e-06,
      "loss": 0.0303,
      "step": 96000
    },
    {
      "epoch": 6.607990098329093,
      "grad_norm": 0.29330646991729736,
      "learning_rate": 8.713703646397441e-06,
      "loss": 0.0299,
      "step": 96100
    },
    {
      "epoch": 6.614866258681152,
      "grad_norm": 0.14722266793251038,
      "learning_rate": 8.670723950006017e-06,
      "loss": 0.031,
      "step": 96200
    },
    {
      "epoch": 6.621742419033212,
      "grad_norm": 0.10368449240922928,
      "learning_rate": 8.628603847542421e-06,
      "loss": 0.0316,
      "step": 96300
    },
    {
      "epoch": 6.628618579385272,
      "grad_norm": 0.3034310042858124,
      "learning_rate": 8.585624151150997e-06,
      "loss": 0.0315,
      "step": 96400
    },
    {
      "epoch": 6.6354947397373305,
      "grad_norm": 0.202740877866745,
      "learning_rate": 8.54264445475957e-06,
      "loss": 0.0289,
      "step": 96500
    },
    {
      "epoch": 6.64237090008939,
      "grad_norm": 0.1594460904598236,
      "learning_rate": 8.499664758368148e-06,
      "loss": 0.0311,
      "step": 96600
    },
    {
      "epoch": 6.64924706044145,
      "grad_norm": 0.18280304968357086,
      "learning_rate": 8.456685061976722e-06,
      "loss": 0.0306,
      "step": 96700
    },
    {
      "epoch": 6.656123220793509,
      "grad_norm": 0.14763443171977997,
      "learning_rate": 8.413705365585298e-06,
      "loss": 0.0331,
      "step": 96800
    },
    {
      "epoch": 6.662999381145569,
      "grad_norm": 0.26228246092796326,
      "learning_rate": 8.370725669193873e-06,
      "loss": 0.033,
      "step": 96900
    },
    {
      "epoch": 6.669875541497627,
      "grad_norm": 0.15136057138442993,
      "learning_rate": 8.327745972802449e-06,
      "loss": 0.0329,
      "step": 97000
    },
    {
      "epoch": 6.676751701849687,
      "grad_norm": 0.07659294456243515,
      "learning_rate": 8.284766276411024e-06,
      "loss": 0.0308,
      "step": 97100
    },
    {
      "epoch": 6.683627862201747,
      "grad_norm": 0.19481536746025085,
      "learning_rate": 8.241786580019598e-06,
      "loss": 0.031,
      "step": 97200
    },
    {
      "epoch": 6.690504022553806,
      "grad_norm": 0.126896932721138,
      "learning_rate": 8.198806883628174e-06,
      "loss": 0.032,
      "step": 97300
    },
    {
      "epoch": 6.6973801829058655,
      "grad_norm": 0.10872215777635574,
      "learning_rate": 8.15582718723675e-06,
      "loss": 0.0344,
      "step": 97400
    },
    {
      "epoch": 6.704256343257924,
      "grad_norm": 0.18798939883708954,
      "learning_rate": 8.112847490845325e-06,
      "loss": 0.0314,
      "step": 97500
    },
    {
      "epoch": 6.711132503609984,
      "grad_norm": 0.1517731100320816,
      "learning_rate": 8.0698677944539e-06,
      "loss": 0.031,
      "step": 97600
    },
    {
      "epoch": 6.718008663962044,
      "grad_norm": 0.19148610532283783,
      "learning_rate": 8.026888098062475e-06,
      "loss": 0.0329,
      "step": 97700
    },
    {
      "epoch": 6.724884824314103,
      "grad_norm": 0.18289102613925934,
      "learning_rate": 7.983908401671052e-06,
      "loss": 0.0335,
      "step": 97800
    },
    {
      "epoch": 6.731760984666162,
      "grad_norm": 0.2645573616027832,
      "learning_rate": 7.940928705279626e-06,
      "loss": 0.0315,
      "step": 97900
    },
    {
      "epoch": 6.738637145018222,
      "grad_norm": 0.20271222293376923,
      "learning_rate": 7.897949008888201e-06,
      "loss": 0.0298,
      "step": 98000
    },
    {
      "epoch": 6.745513305370281,
      "grad_norm": 0.2271750271320343,
      "learning_rate": 7.854969312496777e-06,
      "loss": 0.0317,
      "step": 98100
    },
    {
      "epoch": 6.752389465722341,
      "grad_norm": 0.3105889856815338,
      "learning_rate": 7.811989616105351e-06,
      "loss": 0.0318,
      "step": 98200
    },
    {
      "epoch": 6.7592656260744,
      "grad_norm": 0.18753214180469513,
      "learning_rate": 7.769009919713928e-06,
      "loss": 0.0333,
      "step": 98300
    },
    {
      "epoch": 6.766141786426459,
      "grad_norm": 0.11696048080921173,
      "learning_rate": 7.726030223322502e-06,
      "loss": 0.0308,
      "step": 98400
    },
    {
      "epoch": 6.773017946778519,
      "grad_norm": 0.2996651530265808,
      "learning_rate": 7.683050526931078e-06,
      "loss": 0.0347,
      "step": 98500
    },
    {
      "epoch": 6.779894107130579,
      "grad_norm": 0.17232069373130798,
      "learning_rate": 7.640070830539653e-06,
      "loss": 0.0328,
      "step": 98600
    },
    {
      "epoch": 6.786770267482638,
      "grad_norm": 0.24742138385772705,
      "learning_rate": 7.597091134148229e-06,
      "loss": 0.0313,
      "step": 98700
    },
    {
      "epoch": 6.793646427834697,
      "grad_norm": 0.20134633779525757,
      "learning_rate": 7.5541114377568046e-06,
      "loss": 0.0324,
      "step": 98800
    },
    {
      "epoch": 6.800522588186756,
      "grad_norm": 0.1583126038312912,
      "learning_rate": 7.511131741365379e-06,
      "loss": 0.0311,
      "step": 98900
    },
    {
      "epoch": 6.807398748538816,
      "grad_norm": 0.13991528749465942,
      "learning_rate": 7.468581841937869e-06,
      "loss": 0.0295,
      "step": 99000
    },
    {
      "epoch": 6.814274908890876,
      "grad_norm": 0.17182672023773193,
      "learning_rate": 7.425602145546444e-06,
      "loss": 0.0334,
      "step": 99100
    },
    {
      "epoch": 6.8211510692429345,
      "grad_norm": 0.21152344346046448,
      "learning_rate": 7.382622449155019e-06,
      "loss": 0.0357,
      "step": 99200
    },
    {
      "epoch": 6.828027229594994,
      "grad_norm": 0.21142327785491943,
      "learning_rate": 7.339642752763595e-06,
      "loss": 0.0296,
      "step": 99300
    },
    {
      "epoch": 6.834903389947054,
      "grad_norm": 0.18944135308265686,
      "learning_rate": 7.29666305637217e-06,
      "loss": 0.0346,
      "step": 99400
    },
    {
      "epoch": 6.841779550299113,
      "grad_norm": 0.2639297842979431,
      "learning_rate": 7.2536833599807456e-06,
      "loss": 0.0321,
      "step": 99500
    },
    {
      "epoch": 6.8486557106511725,
      "grad_norm": 0.23153537511825562,
      "learning_rate": 7.21070366358932e-06,
      "loss": 0.0314,
      "step": 99600
    },
    {
      "epoch": 6.855531871003231,
      "grad_norm": 0.18641743063926697,
      "learning_rate": 7.16815376416181e-06,
      "loss": 0.0314,
      "step": 99700
    },
    {
      "epoch": 6.862408031355291,
      "grad_norm": 0.23133939504623413,
      "learning_rate": 7.125174067770387e-06,
      "loss": 0.032,
      "step": 99800
    },
    {
      "epoch": 6.869284191707351,
      "grad_norm": 0.22044309973716736,
      "learning_rate": 7.0821943713789614e-06,
      "loss": 0.0314,
      "step": 99900
    },
    {
      "epoch": 6.87616035205941,
      "grad_norm": 0.10098618268966675,
      "learning_rate": 7.039214674987536e-06,
      "loss": 0.0314,
      "step": 100000
    },
    {
      "epoch": 6.883036512411469,
      "grad_norm": 0.15650983154773712,
      "learning_rate": 6.996234978596111e-06,
      "loss": 0.0322,
      "step": 100100
    },
    {
      "epoch": 6.889912672763529,
      "grad_norm": 0.25678443908691406,
      "learning_rate": 6.9532552822046865e-06,
      "loss": 0.0308,
      "step": 100200
    },
    {
      "epoch": 6.896788833115588,
      "grad_norm": 0.10872591286897659,
      "learning_rate": 6.910275585813262e-06,
      "loss": 0.0337,
      "step": 100300
    },
    {
      "epoch": 6.903664993467648,
      "grad_norm": 0.2371656894683838,
      "learning_rate": 6.867295889421838e-06,
      "loss": 0.0309,
      "step": 100400
    },
    {
      "epoch": 6.9105411538197075,
      "grad_norm": 0.13755270838737488,
      "learning_rate": 6.8243161930304125e-06,
      "loss": 0.0325,
      "step": 100500
    },
    {
      "epoch": 6.917417314171766,
      "grad_norm": 0.22686530649662018,
      "learning_rate": 6.781336496638987e-06,
      "loss": 0.0289,
      "step": 100600
    },
    {
      "epoch": 6.924293474523826,
      "grad_norm": 0.23135361075401306,
      "learning_rate": 6.738356800247564e-06,
      "loss": 0.032,
      "step": 100700
    },
    {
      "epoch": 6.931169634875886,
      "grad_norm": 0.3012297451496124,
      "learning_rate": 6.6953771038561385e-06,
      "loss": 0.0316,
      "step": 100800
    },
    {
      "epoch": 6.938045795227945,
      "grad_norm": 0.2148767113685608,
      "learning_rate": 6.652397407464714e-06,
      "loss": 0.0318,
      "step": 100900
    },
    {
      "epoch": 6.944921955580004,
      "grad_norm": 0.15781822800636292,
      "learning_rate": 6.609417711073289e-06,
      "loss": 0.0326,
      "step": 101000
    },
    {
      "epoch": 6.951798115932063,
      "grad_norm": 0.13304345309734344,
      "learning_rate": 6.566867811645779e-06,
      "loss": 0.0303,
      "step": 101100
    },
    {
      "epoch": 6.958674276284123,
      "grad_norm": 0.10867806524038315,
      "learning_rate": 6.5238881152543535e-06,
      "loss": 0.0326,
      "step": 101200
    },
    {
      "epoch": 6.965550436636183,
      "grad_norm": 0.11329267174005508,
      "learning_rate": 6.48090841886293e-06,
      "loss": 0.0302,
      "step": 101300
    },
    {
      "epoch": 6.9724265969882415,
      "grad_norm": 0.35687047243118286,
      "learning_rate": 6.437928722471505e-06,
      "loss": 0.0327,
      "step": 101400
    },
    {
      "epoch": 6.979302757340301,
      "grad_norm": 0.12429936975240707,
      "learning_rate": 6.3949490260800795e-06,
      "loss": 0.0341,
      "step": 101500
    },
    {
      "epoch": 6.98617891769236,
      "grad_norm": 0.2028927206993103,
      "learning_rate": 6.351969329688655e-06,
      "loss": 0.0307,
      "step": 101600
    },
    {
      "epoch": 6.99305507804442,
      "grad_norm": 0.2612012028694153,
      "learning_rate": 6.3089896332972315e-06,
      "loss": 0.0334,
      "step": 101700
    },
    {
      "epoch": 6.99993123839648,
      "grad_norm": 0.2663586735725403,
      "learning_rate": 6.266009936905806e-06,
      "loss": 0.029,
      "step": 101800
    },
    {
      "epoch": 7.0,
      "eval_accuracy_macro_0.5": 0.9851149320602417,
      "eval_accuracy_micro_0.5": 0.9851148724555969,
      "eval_accuracy_weighted_0.5": 0.9829756021499634,
      "eval_f1_macro_0.5": 0.810366153717041,
      "eval_f1_macro_0.6": 0.7998283505439758,
      "eval_f1_macro_0.7": 0.7783054709434509,
      "eval_f1_macro_0.8": 0.6501764059066772,
      "eval_f1_micro_0.5": 0.8076275587081909,
      "eval_f1_micro_0.6": 0.7989464402198792,
      "eval_f1_micro_0.7": 0.780715823173523,
      "eval_f1_micro_0.8": 0.74415522813797,
      "eval_f1_micro_0.9": 0.6639163494110107,
      "eval_f1_weighted_0.5": 0.8046387434005737,
      "eval_f1_weighted_0.6": 0.7934414148330688,
      "eval_f1_weighted_0.7": 0.7714824676513672,
      "eval_f1_weighted_0.8": 0.6388780474662781,
      "eval_loss": 0.030673103407025337,
      "eval_runtime": 133.3773,
      "eval_samples_per_second": 217.706,
      "eval_steps_per_second": 27.216,
      "step": 101801
    }
  ],
  "logging_steps": 100,
  "max_steps": 116344,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.636820625263411e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
