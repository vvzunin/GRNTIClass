{
  "best_metric": 0.8045868277549744,
  "best_model_checkpoint": "aleksandr-test-labse-turbo/model bert lora level 1/checkpoint-101801",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 101801,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00687616035205941,
      "grad_norm": 0.3494836091995239,
      "learning_rate": 4.996131827324772e-05,
      "loss": 0.3468,
      "step": 100
    },
    {
      "epoch": 0.01375232070411882,
      "grad_norm": 0.2400950938463211,
      "learning_rate": 4.9918338576856295e-05,
      "loss": 0.1395,
      "step": 200
    },
    {
      "epoch": 0.02062848105617823,
      "grad_norm": 0.21777625381946564,
      "learning_rate": 4.9875358880464876e-05,
      "loss": 0.1305,
      "step": 300
    },
    {
      "epoch": 0.02750464140823764,
      "grad_norm": 0.24047908186912537,
      "learning_rate": 4.983237918407345e-05,
      "loss": 0.1245,
      "step": 400
    },
    {
      "epoch": 0.03438080176029705,
      "grad_norm": 0.21167919039726257,
      "learning_rate": 4.978939948768202e-05,
      "loss": 0.1148,
      "step": 500
    },
    {
      "epoch": 0.04125696211235646,
      "grad_norm": 0.22984285652637482,
      "learning_rate": 4.97464197912906e-05,
      "loss": 0.1075,
      "step": 600
    },
    {
      "epoch": 0.04813312246441587,
      "grad_norm": 0.2125236988067627,
      "learning_rate": 4.970344009489917e-05,
      "loss": 0.0994,
      "step": 700
    },
    {
      "epoch": 0.05500928281647528,
      "grad_norm": 0.22270217537879944,
      "learning_rate": 4.9660460398507745e-05,
      "loss": 0.0903,
      "step": 800
    },
    {
      "epoch": 0.06188544316853469,
      "grad_norm": 0.16013851761817932,
      "learning_rate": 4.961748070211632e-05,
      "loss": 0.0875,
      "step": 900
    },
    {
      "epoch": 0.0687616035205941,
      "grad_norm": 0.17997440695762634,
      "learning_rate": 4.95745010057249e-05,
      "loss": 0.0819,
      "step": 1000
    },
    {
      "epoch": 0.07563776387265352,
      "grad_norm": 0.20167270302772522,
      "learning_rate": 4.9531521309333474e-05,
      "loss": 0.0794,
      "step": 1100
    },
    {
      "epoch": 0.08251392422471292,
      "grad_norm": 0.20595140755176544,
      "learning_rate": 4.948854161294205e-05,
      "loss": 0.0746,
      "step": 1200
    },
    {
      "epoch": 0.08939008457677233,
      "grad_norm": 0.1756923645734787,
      "learning_rate": 4.944556191655063e-05,
      "loss": 0.0769,
      "step": 1300
    },
    {
      "epoch": 0.09626624492883173,
      "grad_norm": 0.1727135330438614,
      "learning_rate": 4.94025822201592e-05,
      "loss": 0.0735,
      "step": 1400
    },
    {
      "epoch": 0.10314240528089115,
      "grad_norm": 0.15490588545799255,
      "learning_rate": 4.9359602523767776e-05,
      "loss": 0.0681,
      "step": 1500
    },
    {
      "epoch": 0.11001856563295057,
      "grad_norm": 0.1849944293498993,
      "learning_rate": 4.931662282737635e-05,
      "loss": 0.0669,
      "step": 1600
    },
    {
      "epoch": 0.11689472598500997,
      "grad_norm": 0.13691774010658264,
      "learning_rate": 4.9273643130984924e-05,
      "loss": 0.0689,
      "step": 1700
    },
    {
      "epoch": 0.12377088633706938,
      "grad_norm": 0.1883181780576706,
      "learning_rate": 4.92306634345935e-05,
      "loss": 0.067,
      "step": 1800
    },
    {
      "epoch": 0.1306470466891288,
      "grad_norm": 0.23880599439144135,
      "learning_rate": 4.918768373820208e-05,
      "loss": 0.0635,
      "step": 1900
    },
    {
      "epoch": 0.1375232070411882,
      "grad_norm": 0.16639144718647003,
      "learning_rate": 4.914470404181065e-05,
      "loss": 0.0634,
      "step": 2000
    },
    {
      "epoch": 0.1443993673932476,
      "grad_norm": 0.2871297597885132,
      "learning_rate": 4.9101724345419226e-05,
      "loss": 0.0621,
      "step": 2100
    },
    {
      "epoch": 0.15127552774530703,
      "grad_norm": 0.15436823666095734,
      "learning_rate": 4.90587446490278e-05,
      "loss": 0.0597,
      "step": 2200
    },
    {
      "epoch": 0.15815168809736643,
      "grad_norm": 0.197611466050148,
      "learning_rate": 4.901576495263638e-05,
      "loss": 0.0632,
      "step": 2300
    },
    {
      "epoch": 0.16502784844942583,
      "grad_norm": 0.14367584884166718,
      "learning_rate": 4.8972785256244955e-05,
      "loss": 0.0622,
      "step": 2400
    },
    {
      "epoch": 0.17190400880148526,
      "grad_norm": 0.15426833927631378,
      "learning_rate": 4.892980555985353e-05,
      "loss": 0.0589,
      "step": 2500
    },
    {
      "epoch": 0.17878016915354467,
      "grad_norm": 0.2340749204158783,
      "learning_rate": 4.88868258634621e-05,
      "loss": 0.0628,
      "step": 2600
    },
    {
      "epoch": 0.18565632950560407,
      "grad_norm": 0.1938389539718628,
      "learning_rate": 4.8843846167070677e-05,
      "loss": 0.0603,
      "step": 2700
    },
    {
      "epoch": 0.19253248985766347,
      "grad_norm": 0.1395816057920456,
      "learning_rate": 4.880086647067925e-05,
      "loss": 0.059,
      "step": 2800
    },
    {
      "epoch": 0.1994086502097229,
      "grad_norm": 0.21101002395153046,
      "learning_rate": 4.875788677428783e-05,
      "loss": 0.0568,
      "step": 2900
    },
    {
      "epoch": 0.2062848105617823,
      "grad_norm": 0.15602076053619385,
      "learning_rate": 4.8714907077896405e-05,
      "loss": 0.0591,
      "step": 3000
    },
    {
      "epoch": 0.2131609709138417,
      "grad_norm": 0.21381264925003052,
      "learning_rate": 4.867192738150498e-05,
      "loss": 0.0592,
      "step": 3100
    },
    {
      "epoch": 0.22003713126590113,
      "grad_norm": 0.13132783770561218,
      "learning_rate": 4.862894768511356e-05,
      "loss": 0.0616,
      "step": 3200
    },
    {
      "epoch": 0.22691329161796053,
      "grad_norm": 0.13419105112552643,
      "learning_rate": 4.8585967988722134e-05,
      "loss": 0.0555,
      "step": 3300
    },
    {
      "epoch": 0.23378945197001993,
      "grad_norm": 0.22879694402217865,
      "learning_rate": 4.854298829233071e-05,
      "loss": 0.0581,
      "step": 3400
    },
    {
      "epoch": 0.24066561232207936,
      "grad_norm": 0.15899857878684998,
      "learning_rate": 4.850000859593928e-05,
      "loss": 0.0562,
      "step": 3500
    },
    {
      "epoch": 0.24754177267413877,
      "grad_norm": 0.15306124091148376,
      "learning_rate": 4.8457028899547855e-05,
      "loss": 0.0565,
      "step": 3600
    },
    {
      "epoch": 0.2544179330261982,
      "grad_norm": 0.21415087580680847,
      "learning_rate": 4.841404920315643e-05,
      "loss": 0.0555,
      "step": 3700
    },
    {
      "epoch": 0.2612940933782576,
      "grad_norm": 0.23041705787181854,
      "learning_rate": 4.8371069506765e-05,
      "loss": 0.0581,
      "step": 3800
    },
    {
      "epoch": 0.268170253730317,
      "grad_norm": 0.18269070982933044,
      "learning_rate": 4.8328089810373584e-05,
      "loss": 0.0582,
      "step": 3900
    },
    {
      "epoch": 0.2750464140823764,
      "grad_norm": 0.18419256806373596,
      "learning_rate": 4.828511011398216e-05,
      "loss": 0.0551,
      "step": 4000
    },
    {
      "epoch": 0.2819225744344358,
      "grad_norm": 0.1505516767501831,
      "learning_rate": 4.824213041759073e-05,
      "loss": 0.0552,
      "step": 4100
    },
    {
      "epoch": 0.2887987347864952,
      "grad_norm": 0.2063106894493103,
      "learning_rate": 4.819915072119931e-05,
      "loss": 0.0536,
      "step": 4200
    },
    {
      "epoch": 0.2956748951385546,
      "grad_norm": 0.1859690397977829,
      "learning_rate": 4.8156171024807886e-05,
      "loss": 0.055,
      "step": 4300
    },
    {
      "epoch": 0.30255105549061406,
      "grad_norm": 0.16548731923103333,
      "learning_rate": 4.811319132841646e-05,
      "loss": 0.0533,
      "step": 4400
    },
    {
      "epoch": 0.30942721584267346,
      "grad_norm": 0.1344287246465683,
      "learning_rate": 4.8070211632025034e-05,
      "loss": 0.0548,
      "step": 4500
    },
    {
      "epoch": 0.31630337619473287,
      "grad_norm": 0.1492222249507904,
      "learning_rate": 4.802723193563361e-05,
      "loss": 0.054,
      "step": 4600
    },
    {
      "epoch": 0.32317953654679227,
      "grad_norm": 0.20519272983074188,
      "learning_rate": 4.798425223924218e-05,
      "loss": 0.0525,
      "step": 4700
    },
    {
      "epoch": 0.33005569689885167,
      "grad_norm": 0.13788670301437378,
      "learning_rate": 4.7941272542850756e-05,
      "loss": 0.0549,
      "step": 4800
    },
    {
      "epoch": 0.33693185725091107,
      "grad_norm": 0.16325294971466064,
      "learning_rate": 4.7898292846459336e-05,
      "loss": 0.0544,
      "step": 4900
    },
    {
      "epoch": 0.34380801760297053,
      "grad_norm": 0.20673806965351105,
      "learning_rate": 4.785531315006791e-05,
      "loss": 0.0528,
      "step": 5000
    },
    {
      "epoch": 0.35068417795502993,
      "grad_norm": 0.16452321410179138,
      "learning_rate": 4.7812333453676484e-05,
      "loss": 0.0528,
      "step": 5100
    },
    {
      "epoch": 0.35756033830708933,
      "grad_norm": 0.12309420108795166,
      "learning_rate": 4.7769353757285065e-05,
      "loss": 0.0527,
      "step": 5200
    },
    {
      "epoch": 0.36443649865914873,
      "grad_norm": 0.2208714336156845,
      "learning_rate": 4.772637406089364e-05,
      "loss": 0.0529,
      "step": 5300
    },
    {
      "epoch": 0.37131265901120813,
      "grad_norm": 0.15084277093410492,
      "learning_rate": 4.768339436450221e-05,
      "loss": 0.0552,
      "step": 5400
    },
    {
      "epoch": 0.37818881936326754,
      "grad_norm": 0.27266597747802734,
      "learning_rate": 4.764041466811079e-05,
      "loss": 0.0511,
      "step": 5500
    },
    {
      "epoch": 0.38506497971532694,
      "grad_norm": 0.2783379852771759,
      "learning_rate": 4.759743497171936e-05,
      "loss": 0.0512,
      "step": 5600
    },
    {
      "epoch": 0.3919411400673864,
      "grad_norm": 0.16977554559707642,
      "learning_rate": 4.7554455275327935e-05,
      "loss": 0.0525,
      "step": 5700
    },
    {
      "epoch": 0.3988173004194458,
      "grad_norm": 0.21377629041671753,
      "learning_rate": 4.7511475578936515e-05,
      "loss": 0.055,
      "step": 5800
    },
    {
      "epoch": 0.4056934607715052,
      "grad_norm": 0.1196548268198967,
      "learning_rate": 4.7468925679509004e-05,
      "loss": 0.0543,
      "step": 5900
    },
    {
      "epoch": 0.4125696211235646,
      "grad_norm": 0.16500040888786316,
      "learning_rate": 4.742594598311758e-05,
      "loss": 0.0535,
      "step": 6000
    },
    {
      "epoch": 0.419445781475624,
      "grad_norm": 0.13692517578601837,
      "learning_rate": 4.738296628672615e-05,
      "loss": 0.0501,
      "step": 6100
    },
    {
      "epoch": 0.4263219418276834,
      "grad_norm": 0.10642541944980621,
      "learning_rate": 4.7339986590334726e-05,
      "loss": 0.051,
      "step": 6200
    },
    {
      "epoch": 0.4331981021797428,
      "grad_norm": 0.17544329166412354,
      "learning_rate": 4.72970068939433e-05,
      "loss": 0.0488,
      "step": 6300
    },
    {
      "epoch": 0.44007426253180226,
      "grad_norm": 0.1336066722869873,
      "learning_rate": 4.725402719755188e-05,
      "loss": 0.0517,
      "step": 6400
    },
    {
      "epoch": 0.44695042288386166,
      "grad_norm": 0.23041406273841858,
      "learning_rate": 4.7211047501160455e-05,
      "loss": 0.0518,
      "step": 6500
    },
    {
      "epoch": 0.45382658323592107,
      "grad_norm": 0.14973551034927368,
      "learning_rate": 4.716806780476903e-05,
      "loss": 0.0501,
      "step": 6600
    },
    {
      "epoch": 0.46070274358798047,
      "grad_norm": 0.09727271646261215,
      "learning_rate": 4.71250881083776e-05,
      "loss": 0.0512,
      "step": 6700
    },
    {
      "epoch": 0.46757890394003987,
      "grad_norm": 0.20699192583560944,
      "learning_rate": 4.708210841198618e-05,
      "loss": 0.0527,
      "step": 6800
    },
    {
      "epoch": 0.47445506429209927,
      "grad_norm": 0.20775751769542694,
      "learning_rate": 4.703912871559476e-05,
      "loss": 0.0496,
      "step": 6900
    },
    {
      "epoch": 0.48133122464415873,
      "grad_norm": 0.20093637704849243,
      "learning_rate": 4.699614901920333e-05,
      "loss": 0.0509,
      "step": 7000
    },
    {
      "epoch": 0.48820738499621813,
      "grad_norm": 0.23959000408649445,
      "learning_rate": 4.6953169322811905e-05,
      "loss": 0.0493,
      "step": 7100
    },
    {
      "epoch": 0.49508354534827753,
      "grad_norm": 0.17447403073310852,
      "learning_rate": 4.691018962642048e-05,
      "loss": 0.052,
      "step": 7200
    },
    {
      "epoch": 0.5019597057003369,
      "grad_norm": 0.14796437323093414,
      "learning_rate": 4.686720993002905e-05,
      "loss": 0.0483,
      "step": 7300
    },
    {
      "epoch": 0.5088358660523964,
      "grad_norm": 0.10260551422834396,
      "learning_rate": 4.682423023363763e-05,
      "loss": 0.0504,
      "step": 7400
    },
    {
      "epoch": 0.5157120264044558,
      "grad_norm": 0.26234161853790283,
      "learning_rate": 4.678125053724621e-05,
      "loss": 0.0469,
      "step": 7500
    },
    {
      "epoch": 0.5225881867565152,
      "grad_norm": 0.16844990849494934,
      "learning_rate": 4.673827084085478e-05,
      "loss": 0.0507,
      "step": 7600
    },
    {
      "epoch": 0.5294643471085746,
      "grad_norm": 0.2771579325199127,
      "learning_rate": 4.669529114446336e-05,
      "loss": 0.052,
      "step": 7700
    },
    {
      "epoch": 0.536340507460634,
      "grad_norm": 0.13514290750026703,
      "learning_rate": 4.6652311448071936e-05,
      "loss": 0.0511,
      "step": 7800
    },
    {
      "epoch": 0.5432166678126934,
      "grad_norm": 0.22120968997478485,
      "learning_rate": 4.660933175168051e-05,
      "loss": 0.0493,
      "step": 7900
    },
    {
      "epoch": 0.5500928281647528,
      "grad_norm": 0.0815834254026413,
      "learning_rate": 4.6566352055289084e-05,
      "loss": 0.0482,
      "step": 8000
    },
    {
      "epoch": 0.5569689885168122,
      "grad_norm": 0.1673063188791275,
      "learning_rate": 4.652337235889766e-05,
      "loss": 0.0475,
      "step": 8100
    },
    {
      "epoch": 0.5638451488688716,
      "grad_norm": 0.26232075691223145,
      "learning_rate": 4.648039266250623e-05,
      "loss": 0.0514,
      "step": 8200
    },
    {
      "epoch": 0.570721309220931,
      "grad_norm": 0.18334265053272247,
      "learning_rate": 4.6437412966114805e-05,
      "loss": 0.0502,
      "step": 8300
    },
    {
      "epoch": 0.5775974695729904,
      "grad_norm": 0.2980876564979553,
      "learning_rate": 4.6394433269723386e-05,
      "loss": 0.0501,
      "step": 8400
    },
    {
      "epoch": 0.5844736299250498,
      "grad_norm": 0.20662064850330353,
      "learning_rate": 4.635145357333196e-05,
      "loss": 0.0499,
      "step": 8500
    },
    {
      "epoch": 0.5913497902771092,
      "grad_norm": 0.1523662507534027,
      "learning_rate": 4.6308473876940534e-05,
      "loss": 0.0505,
      "step": 8600
    },
    {
      "epoch": 0.5982259506291687,
      "grad_norm": 0.15090306103229523,
      "learning_rate": 4.6265494180549114e-05,
      "loss": 0.0499,
      "step": 8700
    },
    {
      "epoch": 0.6051021109812281,
      "grad_norm": 0.2515985667705536,
      "learning_rate": 4.622251448415769e-05,
      "loss": 0.0486,
      "step": 8800
    },
    {
      "epoch": 0.6119782713332875,
      "grad_norm": 0.1907932460308075,
      "learning_rate": 4.617953478776626e-05,
      "loss": 0.0508,
      "step": 8900
    },
    {
      "epoch": 0.6188544316853469,
      "grad_norm": 0.24625195562839508,
      "learning_rate": 4.6136555091374836e-05,
      "loss": 0.0482,
      "step": 9000
    },
    {
      "epoch": 0.6257305920374063,
      "grad_norm": 0.242705300450325,
      "learning_rate": 4.609357539498341e-05,
      "loss": 0.0503,
      "step": 9100
    },
    {
      "epoch": 0.6326067523894657,
      "grad_norm": 0.2701078951358795,
      "learning_rate": 4.6050595698591984e-05,
      "loss": 0.0504,
      "step": 9200
    },
    {
      "epoch": 0.6394829127415251,
      "grad_norm": 0.14876095950603485,
      "learning_rate": 4.6007616002200565e-05,
      "loss": 0.0488,
      "step": 9300
    },
    {
      "epoch": 0.6463590730935845,
      "grad_norm": 0.18895256519317627,
      "learning_rate": 4.596463630580914e-05,
      "loss": 0.0454,
      "step": 9400
    },
    {
      "epoch": 0.6532352334456439,
      "grad_norm": 0.17919598519802094,
      "learning_rate": 4.592165660941771e-05,
      "loss": 0.0497,
      "step": 9500
    },
    {
      "epoch": 0.6601113937977033,
      "grad_norm": 0.1418171525001526,
      "learning_rate": 4.5878676913026286e-05,
      "loss": 0.0487,
      "step": 9600
    },
    {
      "epoch": 0.6669875541497627,
      "grad_norm": 0.1254504770040512,
      "learning_rate": 4.583569721663487e-05,
      "loss": 0.0471,
      "step": 9700
    },
    {
      "epoch": 0.6738637145018221,
      "grad_norm": 0.365803599357605,
      "learning_rate": 4.579271752024344e-05,
      "loss": 0.0467,
      "step": 9800
    },
    {
      "epoch": 0.6807398748538815,
      "grad_norm": 0.3339933454990387,
      "learning_rate": 4.5749737823852015e-05,
      "loss": 0.0478,
      "step": 9900
    },
    {
      "epoch": 0.6876160352059411,
      "grad_norm": 0.24409063160419464,
      "learning_rate": 4.570675812746059e-05,
      "loss": 0.0475,
      "step": 10000
    },
    {
      "epoch": 0.6944921955580005,
      "grad_norm": 0.21409401297569275,
      "learning_rate": 4.566377843106916e-05,
      "loss": 0.0486,
      "step": 10100
    },
    {
      "epoch": 0.7013683559100599,
      "grad_norm": 0.24511940777301788,
      "learning_rate": 4.562079873467774e-05,
      "loss": 0.047,
      "step": 10200
    },
    {
      "epoch": 0.7082445162621193,
      "grad_norm": 0.24838030338287354,
      "learning_rate": 4.557781903828632e-05,
      "loss": 0.0448,
      "step": 10300
    },
    {
      "epoch": 0.7151206766141787,
      "grad_norm": 0.14897286891937256,
      "learning_rate": 4.553483934189489e-05,
      "loss": 0.0469,
      "step": 10400
    },
    {
      "epoch": 0.7219968369662381,
      "grad_norm": 0.15483133494853973,
      "learning_rate": 4.5491859645503465e-05,
      "loss": 0.0483,
      "step": 10500
    },
    {
      "epoch": 0.7288729973182975,
      "grad_norm": 0.16320885717868805,
      "learning_rate": 4.5448879949112046e-05,
      "loss": 0.0481,
      "step": 10600
    },
    {
      "epoch": 0.7357491576703569,
      "grad_norm": 0.19499355554580688,
      "learning_rate": 4.540590025272062e-05,
      "loss": 0.0447,
      "step": 10700
    },
    {
      "epoch": 0.7426253180224163,
      "grad_norm": 0.17446723580360413,
      "learning_rate": 4.5362920556329194e-05,
      "loss": 0.0478,
      "step": 10800
    },
    {
      "epoch": 0.7495014783744757,
      "grad_norm": 0.21879707276821136,
      "learning_rate": 4.531994085993777e-05,
      "loss": 0.0478,
      "step": 10900
    },
    {
      "epoch": 0.7563776387265351,
      "grad_norm": 0.28613945841789246,
      "learning_rate": 4.527696116354634e-05,
      "loss": 0.0464,
      "step": 11000
    },
    {
      "epoch": 0.7632537990785945,
      "grad_norm": 0.17292699217796326,
      "learning_rate": 4.523441126411883e-05,
      "loss": 0.0452,
      "step": 11100
    },
    {
      "epoch": 0.7701299594306539,
      "grad_norm": 0.16578808426856995,
      "learning_rate": 4.519143156772741e-05,
      "loss": 0.0473,
      "step": 11200
    },
    {
      "epoch": 0.7770061197827133,
      "grad_norm": 0.15418212115764618,
      "learning_rate": 4.5148451871335985e-05,
      "loss": 0.0476,
      "step": 11300
    },
    {
      "epoch": 0.7838822801347728,
      "grad_norm": 0.20619817078113556,
      "learning_rate": 4.510547217494456e-05,
      "loss": 0.0477,
      "step": 11400
    },
    {
      "epoch": 0.7907584404868322,
      "grad_norm": 0.16919320821762085,
      "learning_rate": 4.506249247855313e-05,
      "loss": 0.045,
      "step": 11500
    },
    {
      "epoch": 0.7976346008388916,
      "grad_norm": 0.1883801966905594,
      "learning_rate": 4.501951278216171e-05,
      "loss": 0.048,
      "step": 11600
    },
    {
      "epoch": 0.804510761190951,
      "grad_norm": 0.17788812518119812,
      "learning_rate": 4.497653308577028e-05,
      "loss": 0.0468,
      "step": 11700
    },
    {
      "epoch": 0.8113869215430104,
      "grad_norm": 0.13492439687252045,
      "learning_rate": 4.4933553389378855e-05,
      "loss": 0.0436,
      "step": 11800
    },
    {
      "epoch": 0.8182630818950698,
      "grad_norm": 0.14187152683734894,
      "learning_rate": 4.4890573692987435e-05,
      "loss": 0.0461,
      "step": 11900
    },
    {
      "epoch": 0.8251392422471292,
      "grad_norm": 0.27444323897361755,
      "learning_rate": 4.484759399659601e-05,
      "loss": 0.0471,
      "step": 12000
    },
    {
      "epoch": 0.8320154025991886,
      "grad_norm": 0.1583532840013504,
      "learning_rate": 4.480461430020458e-05,
      "loss": 0.0461,
      "step": 12100
    },
    {
      "epoch": 0.838891562951248,
      "grad_norm": 0.12082485109567642,
      "learning_rate": 4.4761634603813164e-05,
      "loss": 0.0443,
      "step": 12200
    },
    {
      "epoch": 0.8457677233033074,
      "grad_norm": 0.15015029907226562,
      "learning_rate": 4.471865490742174e-05,
      "loss": 0.0426,
      "step": 12300
    },
    {
      "epoch": 0.8526438836553668,
      "grad_norm": 0.1783471554517746,
      "learning_rate": 4.467567521103031e-05,
      "loss": 0.044,
      "step": 12400
    },
    {
      "epoch": 0.8595200440074262,
      "grad_norm": 0.19373662769794464,
      "learning_rate": 4.463269551463889e-05,
      "loss": 0.0457,
      "step": 12500
    },
    {
      "epoch": 0.8663962043594856,
      "grad_norm": 0.2792156934738159,
      "learning_rate": 4.458971581824746e-05,
      "loss": 0.0456,
      "step": 12600
    },
    {
      "epoch": 0.8732723647115451,
      "grad_norm": 0.1354520618915558,
      "learning_rate": 4.4546736121856033e-05,
      "loss": 0.0458,
      "step": 12700
    },
    {
      "epoch": 0.8801485250636045,
      "grad_norm": 0.1695944219827652,
      "learning_rate": 4.450375642546461e-05,
      "loss": 0.0489,
      "step": 12800
    },
    {
      "epoch": 0.8870246854156639,
      "grad_norm": 0.27577170729637146,
      "learning_rate": 4.446077672907319e-05,
      "loss": 0.0482,
      "step": 12900
    },
    {
      "epoch": 0.8939008457677233,
      "grad_norm": 0.15434661507606506,
      "learning_rate": 4.441779703268176e-05,
      "loss": 0.0466,
      "step": 13000
    },
    {
      "epoch": 0.9007770061197827,
      "grad_norm": 0.32467931509017944,
      "learning_rate": 4.4374817336290336e-05,
      "loss": 0.0473,
      "step": 13100
    },
    {
      "epoch": 0.9076531664718421,
      "grad_norm": 0.17841821908950806,
      "learning_rate": 4.4331837639898917e-05,
      "loss": 0.0475,
      "step": 13200
    },
    {
      "epoch": 0.9145293268239015,
      "grad_norm": 0.27982327342033386,
      "learning_rate": 4.428885794350749e-05,
      "loss": 0.0474,
      "step": 13300
    },
    {
      "epoch": 0.9214054871759609,
      "grad_norm": 0.13148917257785797,
      "learning_rate": 4.4245878247116064e-05,
      "loss": 0.0412,
      "step": 13400
    },
    {
      "epoch": 0.9282816475280203,
      "grad_norm": 0.16057005524635315,
      "learning_rate": 4.4202898550724645e-05,
      "loss": 0.0443,
      "step": 13500
    },
    {
      "epoch": 0.9351578078800797,
      "grad_norm": 0.22458145022392273,
      "learning_rate": 4.415991885433321e-05,
      "loss": 0.0463,
      "step": 13600
    },
    {
      "epoch": 0.9420339682321391,
      "grad_norm": 0.15816844999790192,
      "learning_rate": 4.41173689549057e-05,
      "loss": 0.0473,
      "step": 13700
    },
    {
      "epoch": 0.9489101285841985,
      "grad_norm": 0.17077341675758362,
      "learning_rate": 4.407438925851428e-05,
      "loss": 0.0461,
      "step": 13800
    },
    {
      "epoch": 0.9557862889362579,
      "grad_norm": 0.1572801172733307,
      "learning_rate": 4.4031409562122856e-05,
      "loss": 0.0449,
      "step": 13900
    },
    {
      "epoch": 0.9626624492883175,
      "grad_norm": 0.1435624659061432,
      "learning_rate": 4.398842986573143e-05,
      "loss": 0.0454,
      "step": 14000
    },
    {
      "epoch": 0.9695386096403769,
      "grad_norm": 0.22659634053707123,
      "learning_rate": 4.394545016934001e-05,
      "loss": 0.0452,
      "step": 14100
    },
    {
      "epoch": 0.9764147699924363,
      "grad_norm": 0.12380655109882355,
      "learning_rate": 4.3902470472948584e-05,
      "loss": 0.0447,
      "step": 14200
    },
    {
      "epoch": 0.9832909303444957,
      "grad_norm": 0.1747438907623291,
      "learning_rate": 4.385949077655716e-05,
      "loss": 0.0429,
      "step": 14300
    },
    {
      "epoch": 0.9901670906965551,
      "grad_norm": 0.21468108892440796,
      "learning_rate": 4.381651108016573e-05,
      "loss": 0.0442,
      "step": 14400
    },
    {
      "epoch": 0.9970432510486145,
      "grad_norm": 0.18561553955078125,
      "learning_rate": 4.3773531383774306e-05,
      "loss": 0.0429,
      "step": 14500
    },
    {
      "epoch": 1.0,
      "eval_accuracy_macro_0.5": 0.9794346690177917,
      "eval_accuracy_micro_0.5": 0.9794346690177917,
      "eval_accuracy_weighted_0.5": 0.976768434047699,
      "eval_f1_macro_0.5": 0.7127324342727661,
      "eval_f1_macro_0.6": 0.684624195098877,
      "eval_f1_macro_0.7": 0.6407092809677124,
      "eval_f1_macro_0.8": 0.43794313073158264,
      "eval_f1_micro_0.5": 0.7181106209754944,
      "eval_f1_micro_0.6": 0.6954126358032227,
      "eval_f1_micro_0.7": 0.6568505167961121,
      "eval_f1_micro_0.8": 0.5874584913253784,
      "eval_f1_micro_0.9": 0.45752382278442383,
      "eval_f1_weighted_0.5": 0.7082252502441406,
      "eval_f1_weighted_0.6": 0.6793698668479919,
      "eval_f1_weighted_0.7": 0.6336773633956909,
      "eval_f1_weighted_0.8": 0.4193017780780792,
      "eval_loss": 0.04235515370965004,
      "eval_runtime": 133.5329,
      "eval_samples_per_second": 217.452,
      "eval_steps_per_second": 27.184,
      "step": 14543
    },
    {
      "epoch": 1.0039194114006738,
      "grad_norm": 0.13995543122291565,
      "learning_rate": 4.373055168738288e-05,
      "loss": 0.0432,
      "step": 14600
    },
    {
      "epoch": 1.0107955717527333,
      "grad_norm": 0.15008927881717682,
      "learning_rate": 4.368757199099146e-05,
      "loss": 0.0427,
      "step": 14700
    },
    {
      "epoch": 1.0176717321047928,
      "grad_norm": 0.15533962845802307,
      "learning_rate": 4.3644592294600035e-05,
      "loss": 0.0432,
      "step": 14800
    },
    {
      "epoch": 1.024547892456852,
      "grad_norm": 0.1692904382944107,
      "learning_rate": 4.360161259820861e-05,
      "loss": 0.0433,
      "step": 14900
    },
    {
      "epoch": 1.0314240528089116,
      "grad_norm": 0.36446279287338257,
      "learning_rate": 4.355863290181718e-05,
      "loss": 0.044,
      "step": 15000
    },
    {
      "epoch": 1.0383002131609709,
      "grad_norm": 0.1736949384212494,
      "learning_rate": 4.351608300238967e-05,
      "loss": 0.0454,
      "step": 15100
    },
    {
      "epoch": 1.0451763735130304,
      "grad_norm": 0.132110133767128,
      "learning_rate": 4.3473103305998245e-05,
      "loss": 0.0405,
      "step": 15200
    },
    {
      "epoch": 1.0520525338650897,
      "grad_norm": 0.19778136909008026,
      "learning_rate": 4.3430123609606826e-05,
      "loss": 0.0432,
      "step": 15300
    },
    {
      "epoch": 1.0589286942171492,
      "grad_norm": 0.16933046281337738,
      "learning_rate": 4.33871439132154e-05,
      "loss": 0.0454,
      "step": 15400
    },
    {
      "epoch": 1.0658048545692085,
      "grad_norm": 0.2236081212759018,
      "learning_rate": 4.3344164216823974e-05,
      "loss": 0.0445,
      "step": 15500
    },
    {
      "epoch": 1.072681014921268,
      "grad_norm": 0.11907467991113663,
      "learning_rate": 4.330118452043255e-05,
      "loss": 0.0415,
      "step": 15600
    },
    {
      "epoch": 1.0795571752733273,
      "grad_norm": 0.2061263471841812,
      "learning_rate": 4.325820482404113e-05,
      "loss": 0.0427,
      "step": 15700
    },
    {
      "epoch": 1.0864333356253868,
      "grad_norm": 0.24898286163806915,
      "learning_rate": 4.32152251276497e-05,
      "loss": 0.0429,
      "step": 15800
    },
    {
      "epoch": 1.0933094959774463,
      "grad_norm": 0.11379172652959824,
      "learning_rate": 4.3172245431258276e-05,
      "loss": 0.0438,
      "step": 15900
    },
    {
      "epoch": 1.1001856563295056,
      "grad_norm": 0.11078380793333054,
      "learning_rate": 4.312926573486685e-05,
      "loss": 0.0413,
      "step": 16000
    },
    {
      "epoch": 1.1070618166815651,
      "grad_norm": 0.12742599844932556,
      "learning_rate": 4.3086286038475424e-05,
      "loss": 0.0413,
      "step": 16100
    },
    {
      "epoch": 1.1139379770336244,
      "grad_norm": 0.1699492186307907,
      "learning_rate": 4.3043306342084e-05,
      "loss": 0.0396,
      "step": 16200
    },
    {
      "epoch": 1.120814137385684,
      "grad_norm": 0.1998293399810791,
      "learning_rate": 4.300032664569258e-05,
      "loss": 0.0415,
      "step": 16300
    },
    {
      "epoch": 1.1276902977377432,
      "grad_norm": 0.15296398103237152,
      "learning_rate": 4.295734694930115e-05,
      "loss": 0.0421,
      "step": 16400
    },
    {
      "epoch": 1.1345664580898027,
      "grad_norm": 0.2380618005990982,
      "learning_rate": 4.2914367252909727e-05,
      "loss": 0.0442,
      "step": 16500
    },
    {
      "epoch": 1.141442618441862,
      "grad_norm": 0.1742071658372879,
      "learning_rate": 4.287138755651831e-05,
      "loss": 0.0439,
      "step": 16600
    },
    {
      "epoch": 1.1483187787939215,
      "grad_norm": 0.18615767359733582,
      "learning_rate": 4.282840786012688e-05,
      "loss": 0.0445,
      "step": 16700
    },
    {
      "epoch": 1.1551949391459808,
      "grad_norm": 0.1664491444826126,
      "learning_rate": 4.2785428163735455e-05,
      "loss": 0.0442,
      "step": 16800
    },
    {
      "epoch": 1.1620710994980403,
      "grad_norm": 0.24052515625953674,
      "learning_rate": 4.274244846734403e-05,
      "loss": 0.0437,
      "step": 16900
    },
    {
      "epoch": 1.1689472598500996,
      "grad_norm": 0.18192660808563232,
      "learning_rate": 4.26994687709526e-05,
      "loss": 0.0421,
      "step": 17000
    },
    {
      "epoch": 1.1758234202021591,
      "grad_norm": 0.15545953810214996,
      "learning_rate": 4.265648907456118e-05,
      "loss": 0.0418,
      "step": 17100
    },
    {
      "epoch": 1.1826995805542184,
      "grad_norm": 0.18574191629886627,
      "learning_rate": 4.261350937816975e-05,
      "loss": 0.0418,
      "step": 17200
    },
    {
      "epoch": 1.189575740906278,
      "grad_norm": 0.1593371480703354,
      "learning_rate": 4.257052968177833e-05,
      "loss": 0.0454,
      "step": 17300
    },
    {
      "epoch": 1.1964519012583374,
      "grad_norm": 0.15871886909008026,
      "learning_rate": 4.2527549985386905e-05,
      "loss": 0.0445,
      "step": 17400
    },
    {
      "epoch": 1.2033280616103967,
      "grad_norm": 0.18160532414913177,
      "learning_rate": 4.248457028899548e-05,
      "loss": 0.0447,
      "step": 17500
    },
    {
      "epoch": 1.2102042219624563,
      "grad_norm": 0.1213468387722969,
      "learning_rate": 4.244159059260406e-05,
      "loss": 0.0436,
      "step": 17600
    },
    {
      "epoch": 1.2170803823145155,
      "grad_norm": 0.1495291143655777,
      "learning_rate": 4.2398610896212634e-05,
      "loss": 0.0457,
      "step": 17700
    },
    {
      "epoch": 1.223956542666575,
      "grad_norm": 0.15270377695560455,
      "learning_rate": 4.235563119982121e-05,
      "loss": 0.0428,
      "step": 17800
    },
    {
      "epoch": 1.2308327030186343,
      "grad_norm": 0.1760796308517456,
      "learning_rate": 4.231265150342978e-05,
      "loss": 0.042,
      "step": 17900
    },
    {
      "epoch": 1.2377088633706939,
      "grad_norm": 0.1234435960650444,
      "learning_rate": 4.2269671807038356e-05,
      "loss": 0.0419,
      "step": 18000
    },
    {
      "epoch": 1.2445850237227531,
      "grad_norm": 0.09379880130290985,
      "learning_rate": 4.222669211064693e-05,
      "loss": 0.0416,
      "step": 18100
    },
    {
      "epoch": 1.2514611840748127,
      "grad_norm": 0.21663334965705872,
      "learning_rate": 4.2183712414255503e-05,
      "loss": 0.0428,
      "step": 18200
    },
    {
      "epoch": 1.258337344426872,
      "grad_norm": 0.1677258312702179,
      "learning_rate": 4.2140732717864084e-05,
      "loss": 0.0421,
      "step": 18300
    },
    {
      "epoch": 1.2652135047789315,
      "grad_norm": 0.16964347660541534,
      "learning_rate": 4.209775302147266e-05,
      "loss": 0.0418,
      "step": 18400
    },
    {
      "epoch": 1.272089665130991,
      "grad_norm": 0.2395198941230774,
      "learning_rate": 4.205477332508123e-05,
      "loss": 0.0441,
      "step": 18500
    },
    {
      "epoch": 1.2789658254830503,
      "grad_norm": 0.15091197192668915,
      "learning_rate": 4.201179362868981e-05,
      "loss": 0.0405,
      "step": 18600
    },
    {
      "epoch": 1.2858419858351096,
      "grad_norm": 0.13398796319961548,
      "learning_rate": 4.1968813932298387e-05,
      "loss": 0.0395,
      "step": 18700
    },
    {
      "epoch": 1.292718146187169,
      "grad_norm": 0.17923475801944733,
      "learning_rate": 4.192583423590696e-05,
      "loss": 0.044,
      "step": 18800
    },
    {
      "epoch": 1.2995943065392286,
      "grad_norm": 0.2274736911058426,
      "learning_rate": 4.1882854539515534e-05,
      "loss": 0.0407,
      "step": 18900
    },
    {
      "epoch": 1.3064704668912879,
      "grad_norm": 0.13962283730506897,
      "learning_rate": 4.183987484312411e-05,
      "loss": 0.0422,
      "step": 19000
    },
    {
      "epoch": 1.3133466272433474,
      "grad_norm": 0.08800111711025238,
      "learning_rate": 4.179689514673268e-05,
      "loss": 0.0414,
      "step": 19100
    },
    {
      "epoch": 1.3202227875954067,
      "grad_norm": 0.21156930923461914,
      "learning_rate": 4.175434524730518e-05,
      "loss": 0.0453,
      "step": 19200
    },
    {
      "epoch": 1.3270989479474662,
      "grad_norm": 0.2867698669433594,
      "learning_rate": 4.171136555091375e-05,
      "loss": 0.0433,
      "step": 19300
    },
    {
      "epoch": 1.3339751082995255,
      "grad_norm": 0.18408292531967163,
      "learning_rate": 4.1668385854522326e-05,
      "loss": 0.0415,
      "step": 19400
    },
    {
      "epoch": 1.340851268651585,
      "grad_norm": 0.19204270839691162,
      "learning_rate": 4.16254061581309e-05,
      "loss": 0.0436,
      "step": 19500
    },
    {
      "epoch": 1.3477274290036443,
      "grad_norm": 0.16011664271354675,
      "learning_rate": 4.1582426461739474e-05,
      "loss": 0.0398,
      "step": 19600
    },
    {
      "epoch": 1.3546035893557038,
      "grad_norm": 0.27836573123931885,
      "learning_rate": 4.153944676534805e-05,
      "loss": 0.0426,
      "step": 19700
    },
    {
      "epoch": 1.361479749707763,
      "grad_norm": 0.20188409090042114,
      "learning_rate": 4.149646706895663e-05,
      "loss": 0.0411,
      "step": 19800
    },
    {
      "epoch": 1.3683559100598226,
      "grad_norm": 0.1636689007282257,
      "learning_rate": 4.14534873725652e-05,
      "loss": 0.0423,
      "step": 19900
    },
    {
      "epoch": 1.3752320704118821,
      "grad_norm": 0.1465161293745041,
      "learning_rate": 4.1410507676173776e-05,
      "loss": 0.0416,
      "step": 20000
    },
    {
      "epoch": 1.3821082307639414,
      "grad_norm": 0.22287176549434662,
      "learning_rate": 4.136752797978235e-05,
      "loss": 0.0412,
      "step": 20100
    },
    {
      "epoch": 1.3889843911160007,
      "grad_norm": 0.2067747861146927,
      "learning_rate": 4.132454828339093e-05,
      "loss": 0.0417,
      "step": 20200
    },
    {
      "epoch": 1.3958605514680602,
      "grad_norm": 0.17827825248241425,
      "learning_rate": 4.1281568586999505e-05,
      "loss": 0.0414,
      "step": 20300
    },
    {
      "epoch": 1.4027367118201197,
      "grad_norm": 0.11615662276744843,
      "learning_rate": 4.123858889060808e-05,
      "loss": 0.0419,
      "step": 20400
    },
    {
      "epoch": 1.409612872172179,
      "grad_norm": 0.1439063400030136,
      "learning_rate": 4.119560919421665e-05,
      "loss": 0.0419,
      "step": 20500
    },
    {
      "epoch": 1.4164890325242385,
      "grad_norm": 0.20535384118556976,
      "learning_rate": 4.1152629497825226e-05,
      "loss": 0.0401,
      "step": 20600
    },
    {
      "epoch": 1.4233651928762978,
      "grad_norm": 0.21121425926685333,
      "learning_rate": 4.11096498014338e-05,
      "loss": 0.0425,
      "step": 20700
    },
    {
      "epoch": 1.4302413532283573,
      "grad_norm": 0.10852662473917007,
      "learning_rate": 4.106667010504238e-05,
      "loss": 0.0406,
      "step": 20800
    },
    {
      "epoch": 1.4371175135804166,
      "grad_norm": 0.3245897591114044,
      "learning_rate": 4.1023690408650955e-05,
      "loss": 0.0429,
      "step": 20900
    },
    {
      "epoch": 1.4439936739324761,
      "grad_norm": 0.1767052412033081,
      "learning_rate": 4.098071071225953e-05,
      "loss": 0.0444,
      "step": 21000
    },
    {
      "epoch": 1.4508698342845356,
      "grad_norm": 0.20625102519989014,
      "learning_rate": 4.093773101586811e-05,
      "loss": 0.0431,
      "step": 21100
    },
    {
      "epoch": 1.457745994636595,
      "grad_norm": 0.23947200179100037,
      "learning_rate": 4.089475131947668e-05,
      "loss": 0.0428,
      "step": 21200
    },
    {
      "epoch": 1.4646221549886542,
      "grad_norm": 0.17137515544891357,
      "learning_rate": 4.085177162308526e-05,
      "loss": 0.0423,
      "step": 21300
    },
    {
      "epoch": 1.4714983153407137,
      "grad_norm": 0.260757178068161,
      "learning_rate": 4.080879192669383e-05,
      "loss": 0.0393,
      "step": 21400
    },
    {
      "epoch": 1.4783744756927732,
      "grad_norm": 0.15565349161624908,
      "learning_rate": 4.076624202726632e-05,
      "loss": 0.0435,
      "step": 21500
    },
    {
      "epoch": 1.4852506360448325,
      "grad_norm": 0.18165037035942078,
      "learning_rate": 4.072369212783881e-05,
      "loss": 0.0413,
      "step": 21600
    },
    {
      "epoch": 1.492126796396892,
      "grad_norm": 0.16426895558834076,
      "learning_rate": 4.068071243144739e-05,
      "loss": 0.0434,
      "step": 21700
    },
    {
      "epoch": 1.4990029567489513,
      "grad_norm": 0.14237192273139954,
      "learning_rate": 4.0637732735055964e-05,
      "loss": 0.0406,
      "step": 21800
    },
    {
      "epoch": 1.5058791171010109,
      "grad_norm": 0.12311092764139175,
      "learning_rate": 4.059518283562845e-05,
      "loss": 0.0411,
      "step": 21900
    },
    {
      "epoch": 1.5127552774530701,
      "grad_norm": 0.2118053436279297,
      "learning_rate": 4.055220313923703e-05,
      "loss": 0.0407,
      "step": 22000
    },
    {
      "epoch": 1.5196314378051297,
      "grad_norm": 0.20054097473621368,
      "learning_rate": 4.05092234428456e-05,
      "loss": 0.04,
      "step": 22100
    },
    {
      "epoch": 1.5265075981571892,
      "grad_norm": 0.16573530435562134,
      "learning_rate": 4.0466243746454175e-05,
      "loss": 0.0406,
      "step": 22200
    },
    {
      "epoch": 1.5333837585092485,
      "grad_norm": 0.21465525031089783,
      "learning_rate": 4.0423264050062755e-05,
      "loss": 0.0425,
      "step": 22300
    },
    {
      "epoch": 1.5402599188613078,
      "grad_norm": 0.39551490545272827,
      "learning_rate": 4.038028435367133e-05,
      "loss": 0.044,
      "step": 22400
    },
    {
      "epoch": 1.5471360792133673,
      "grad_norm": 0.11718718707561493,
      "learning_rate": 4.03373046572799e-05,
      "loss": 0.0384,
      "step": 22500
    },
    {
      "epoch": 1.5540122395654268,
      "grad_norm": 0.23424851894378662,
      "learning_rate": 4.029432496088848e-05,
      "loss": 0.0409,
      "step": 22600
    },
    {
      "epoch": 1.560888399917486,
      "grad_norm": 0.286459743976593,
      "learning_rate": 4.025134526449705e-05,
      "loss": 0.0409,
      "step": 22700
    },
    {
      "epoch": 1.5677645602695454,
      "grad_norm": 0.1849789023399353,
      "learning_rate": 4.0208365568105625e-05,
      "loss": 0.0427,
      "step": 22800
    },
    {
      "epoch": 1.5746407206216049,
      "grad_norm": 0.2265091836452484,
      "learning_rate": 4.0165385871714206e-05,
      "loss": 0.0409,
      "step": 22900
    },
    {
      "epoch": 1.5815168809736644,
      "grad_norm": 0.1544346958398819,
      "learning_rate": 4.012240617532278e-05,
      "loss": 0.0403,
      "step": 23000
    },
    {
      "epoch": 1.5883930413257237,
      "grad_norm": 0.15201158821582794,
      "learning_rate": 4.0079426478931353e-05,
      "loss": 0.0396,
      "step": 23100
    },
    {
      "epoch": 1.595269201677783,
      "grad_norm": 0.13596928119659424,
      "learning_rate": 4.0036446782539934e-05,
      "loss": 0.0373,
      "step": 23200
    },
    {
      "epoch": 1.6021453620298427,
      "grad_norm": 0.17150892317295074,
      "learning_rate": 3.999346708614851e-05,
      "loss": 0.0401,
      "step": 23300
    },
    {
      "epoch": 1.609021522381902,
      "grad_norm": 0.1646670550107956,
      "learning_rate": 3.995048738975708e-05,
      "loss": 0.0387,
      "step": 23400
    },
    {
      "epoch": 1.6158976827339613,
      "grad_norm": 0.3572830259799957,
      "learning_rate": 3.9907507693365656e-05,
      "loss": 0.0422,
      "step": 23500
    },
    {
      "epoch": 1.6227738430860208,
      "grad_norm": 0.15825167298316956,
      "learning_rate": 3.986452799697423e-05,
      "loss": 0.0404,
      "step": 23600
    },
    {
      "epoch": 1.6296500034380803,
      "grad_norm": 0.16831021010875702,
      "learning_rate": 3.9821548300582804e-05,
      "loss": 0.0397,
      "step": 23700
    },
    {
      "epoch": 1.6365261637901396,
      "grad_norm": 0.23507864773273468,
      "learning_rate": 3.977856860419138e-05,
      "loss": 0.0398,
      "step": 23800
    },
    {
      "epoch": 1.643402324142199,
      "grad_norm": 0.2554427683353424,
      "learning_rate": 3.973558890779996e-05,
      "loss": 0.043,
      "step": 23900
    },
    {
      "epoch": 1.6502784844942584,
      "grad_norm": 0.18814894556999207,
      "learning_rate": 3.969260921140853e-05,
      "loss": 0.0417,
      "step": 24000
    },
    {
      "epoch": 1.657154644846318,
      "grad_norm": 0.209445059299469,
      "learning_rate": 3.9649629515017106e-05,
      "loss": 0.0421,
      "step": 24100
    },
    {
      "epoch": 1.6640308051983772,
      "grad_norm": 0.10876074433326721,
      "learning_rate": 3.960664981862569e-05,
      "loss": 0.0399,
      "step": 24200
    },
    {
      "epoch": 1.6709069655504365,
      "grad_norm": 0.19145125150680542,
      "learning_rate": 3.956367012223426e-05,
      "loss": 0.0381,
      "step": 24300
    },
    {
      "epoch": 1.677783125902496,
      "grad_norm": 0.18999193608760834,
      "learning_rate": 3.952112022280674e-05,
      "loss": 0.0407,
      "step": 24400
    },
    {
      "epoch": 1.6846592862545555,
      "grad_norm": 0.18694119155406952,
      "learning_rate": 3.9478140526415324e-05,
      "loss": 0.0386,
      "step": 24500
    },
    {
      "epoch": 1.6915354466066148,
      "grad_norm": 0.19093012809753418,
      "learning_rate": 3.94351608300239e-05,
      "loss": 0.0396,
      "step": 24600
    },
    {
      "epoch": 1.6984116069586743,
      "grad_norm": 0.25303250551223755,
      "learning_rate": 3.939218113363247e-05,
      "loss": 0.0419,
      "step": 24700
    },
    {
      "epoch": 1.7052877673107338,
      "grad_norm": 0.18821847438812256,
      "learning_rate": 3.934920143724105e-05,
      "loss": 0.0415,
      "step": 24800
    },
    {
      "epoch": 1.7121639276627931,
      "grad_norm": 0.15510641038417816,
      "learning_rate": 3.9306221740849626e-05,
      "loss": 0.0406,
      "step": 24900
    },
    {
      "epoch": 1.7190400880148524,
      "grad_norm": 0.13660703599452972,
      "learning_rate": 3.92632420444582e-05,
      "loss": 0.04,
      "step": 25000
    },
    {
      "epoch": 1.725916248366912,
      "grad_norm": 0.2622469663619995,
      "learning_rate": 3.922026234806678e-05,
      "loss": 0.0417,
      "step": 25100
    },
    {
      "epoch": 1.7327924087189714,
      "grad_norm": 0.2685571014881134,
      "learning_rate": 3.917728265167535e-05,
      "loss": 0.0421,
      "step": 25200
    },
    {
      "epoch": 1.7396685690710307,
      "grad_norm": 0.18408434092998505,
      "learning_rate": 3.913430295528392e-05,
      "loss": 0.0387,
      "step": 25300
    },
    {
      "epoch": 1.74654472942309,
      "grad_norm": 0.13141433894634247,
      "learning_rate": 3.90913232588925e-05,
      "loss": 0.0388,
      "step": 25400
    },
    {
      "epoch": 1.7534208897751495,
      "grad_norm": 0.1986013948917389,
      "learning_rate": 3.9048343562501076e-05,
      "loss": 0.0388,
      "step": 25500
    },
    {
      "epoch": 1.760297050127209,
      "grad_norm": 0.1935201734304428,
      "learning_rate": 3.900536386610965e-05,
      "loss": 0.0399,
      "step": 25600
    },
    {
      "epoch": 1.7671732104792683,
      "grad_norm": 0.3090725839138031,
      "learning_rate": 3.8962384169718224e-05,
      "loss": 0.0422,
      "step": 25700
    },
    {
      "epoch": 1.7740493708313276,
      "grad_norm": 0.16107109189033508,
      "learning_rate": 3.8919404473326805e-05,
      "loss": 0.0433,
      "step": 25800
    },
    {
      "epoch": 1.7809255311833871,
      "grad_norm": 0.1630348116159439,
      "learning_rate": 3.887642477693538e-05,
      "loss": 0.0415,
      "step": 25900
    },
    {
      "epoch": 1.7878016915354467,
      "grad_norm": 0.1475321501493454,
      "learning_rate": 3.883344508054395e-05,
      "loss": 0.0399,
      "step": 26000
    },
    {
      "epoch": 1.794677851887506,
      "grad_norm": 0.2255730926990509,
      "learning_rate": 3.879046538415253e-05,
      "loss": 0.04,
      "step": 26100
    },
    {
      "epoch": 1.8015540122395655,
      "grad_norm": 0.16276800632476807,
      "learning_rate": 3.87474856877611e-05,
      "loss": 0.0387,
      "step": 26200
    },
    {
      "epoch": 1.808430172591625,
      "grad_norm": 0.1572532206773758,
      "learning_rate": 3.8704505991369674e-05,
      "loss": 0.0394,
      "step": 26300
    },
    {
      "epoch": 1.8153063329436843,
      "grad_norm": 0.18668098747730255,
      "learning_rate": 3.8661526294978255e-05,
      "loss": 0.0407,
      "step": 26400
    },
    {
      "epoch": 1.8221824932957436,
      "grad_norm": 0.15194931626319885,
      "learning_rate": 3.861854659858683e-05,
      "loss": 0.0435,
      "step": 26500
    },
    {
      "epoch": 1.829058653647803,
      "grad_norm": 0.13216516375541687,
      "learning_rate": 3.85755669021954e-05,
      "loss": 0.0421,
      "step": 26600
    },
    {
      "epoch": 1.8359348139998626,
      "grad_norm": 0.18485027551651,
      "learning_rate": 3.8532587205803984e-05,
      "loss": 0.0415,
      "step": 26700
    },
    {
      "epoch": 1.8428109743519219,
      "grad_norm": 0.1751081496477127,
      "learning_rate": 3.848960750941256e-05,
      "loss": 0.0395,
      "step": 26800
    },
    {
      "epoch": 1.8496871347039812,
      "grad_norm": 0.24164384603500366,
      "learning_rate": 3.844662781302113e-05,
      "loss": 0.0404,
      "step": 26900
    },
    {
      "epoch": 1.8565632950560407,
      "grad_norm": 0.15894187986850739,
      "learning_rate": 3.8403648116629705e-05,
      "loss": 0.0396,
      "step": 27000
    },
    {
      "epoch": 1.8634394554081002,
      "grad_norm": 0.15125466883182526,
      "learning_rate": 3.8360668420238286e-05,
      "loss": 0.0405,
      "step": 27100
    },
    {
      "epoch": 1.8703156157601595,
      "grad_norm": 0.18983116745948792,
      "learning_rate": 3.831768872384685e-05,
      "loss": 0.0414,
      "step": 27200
    },
    {
      "epoch": 1.877191776112219,
      "grad_norm": 0.16110111773014069,
      "learning_rate": 3.827470902745543e-05,
      "loss": 0.0406,
      "step": 27300
    },
    {
      "epoch": 1.8840679364642785,
      "grad_norm": 0.19111782312393188,
      "learning_rate": 3.823172933106401e-05,
      "loss": 0.0392,
      "step": 27400
    },
    {
      "epoch": 1.8909440968163378,
      "grad_norm": 0.14296546578407288,
      "learning_rate": 3.818874963467258e-05,
      "loss": 0.0396,
      "step": 27500
    },
    {
      "epoch": 1.897820257168397,
      "grad_norm": 0.22052013874053955,
      "learning_rate": 3.8145769938281156e-05,
      "loss": 0.0403,
      "step": 27600
    },
    {
      "epoch": 1.9046964175204566,
      "grad_norm": 0.20620693266391754,
      "learning_rate": 3.8102790241889736e-05,
      "loss": 0.0416,
      "step": 27700
    },
    {
      "epoch": 1.911572577872516,
      "grad_norm": 0.25787144899368286,
      "learning_rate": 3.805981054549831e-05,
      "loss": 0.0405,
      "step": 27800
    },
    {
      "epoch": 1.9184487382245754,
      "grad_norm": 0.19042663276195526,
      "learning_rate": 3.8016830849106884e-05,
      "loss": 0.0431,
      "step": 27900
    },
    {
      "epoch": 1.9253248985766347,
      "grad_norm": 0.20225022733211517,
      "learning_rate": 3.7973851152715465e-05,
      "loss": 0.0386,
      "step": 28000
    },
    {
      "epoch": 1.9322010589286942,
      "grad_norm": 0.23228923976421356,
      "learning_rate": 3.793087145632403e-05,
      "loss": 0.039,
      "step": 28100
    },
    {
      "epoch": 1.9390772192807537,
      "grad_norm": 0.19112655520439148,
      "learning_rate": 3.7887891759932606e-05,
      "loss": 0.0439,
      "step": 28200
    },
    {
      "epoch": 1.945953379632813,
      "grad_norm": 0.22752425074577332,
      "learning_rate": 3.784491206354118e-05,
      "loss": 0.0373,
      "step": 28300
    },
    {
      "epoch": 1.9528295399848723,
      "grad_norm": 0.1575002819299698,
      "learning_rate": 3.780193236714976e-05,
      "loss": 0.0389,
      "step": 28400
    },
    {
      "epoch": 1.9597057003369318,
      "grad_norm": 0.2313840240240097,
      "learning_rate": 3.7758952670758334e-05,
      "loss": 0.0386,
      "step": 28500
    },
    {
      "epoch": 1.9665818606889913,
      "grad_norm": 0.19227740168571472,
      "learning_rate": 3.771597297436691e-05,
      "loss": 0.0396,
      "step": 28600
    },
    {
      "epoch": 1.9734580210410506,
      "grad_norm": 0.12655098736286163,
      "learning_rate": 3.767299327797549e-05,
      "loss": 0.0389,
      "step": 28700
    },
    {
      "epoch": 1.9803341813931101,
      "grad_norm": 0.19023862481117249,
      "learning_rate": 3.763001358158406e-05,
      "loss": 0.0418,
      "step": 28800
    },
    {
      "epoch": 1.9872103417451696,
      "grad_norm": 0.23257341980934143,
      "learning_rate": 3.758703388519264e-05,
      "loss": 0.0405,
      "step": 28900
    },
    {
      "epoch": 1.994086502097229,
      "grad_norm": 0.11359452456235886,
      "learning_rate": 3.754405418880122e-05,
      "loss": 0.0409,
      "step": 29000
    },
    {
      "epoch": 2.0,
      "eval_accuracy_macro_0.5": 0.9819390177726746,
      "eval_accuracy_micro_0.5": 0.9819390177726746,
      "eval_accuracy_weighted_0.5": 0.9794479012489319,
      "eval_f1_macro_0.5": 0.7558115720748901,
      "eval_f1_macro_0.6": 0.7341622710227966,
      "eval_f1_macro_0.7": 0.6967151761054993,
      "eval_f1_macro_0.8": 0.5211657285690308,
      "eval_f1_micro_0.5": 0.7577655911445618,
      "eval_f1_micro_0.6": 0.740336537361145,
      "eval_f1_micro_0.7": 0.7087509036064148,
      "eval_f1_micro_0.8": 0.6547778248786926,
      "eval_f1_micro_0.9": 0.5471720099449158,
      "eval_f1_weighted_0.5": 0.7507672905921936,
      "eval_f1_weighted_0.6": 0.7289060950279236,
      "eval_f1_weighted_0.7": 0.6913760900497437,
      "eval_f1_weighted_0.8": 0.5117002725601196,
      "eval_loss": 0.03701925650238991,
      "eval_runtime": 133.5949,
      "eval_samples_per_second": 217.351,
      "eval_steps_per_second": 27.172,
      "step": 29086
    },
    {
      "epoch": 2.000962662449288,
      "grad_norm": 0.13367247581481934,
      "learning_rate": 3.7501074492409785e-05,
      "loss": 0.0396,
      "step": 29100
    },
    {
      "epoch": 2.0078388228013475,
      "grad_norm": 0.13856805860996246,
      "learning_rate": 3.745809479601836e-05,
      "loss": 0.0381,
      "step": 29200
    },
    {
      "epoch": 2.0147149831534072,
      "grad_norm": 0.21900448203086853,
      "learning_rate": 3.741511509962694e-05,
      "loss": 0.0408,
      "step": 29300
    },
    {
      "epoch": 2.0215911435054665,
      "grad_norm": 0.12734302878379822,
      "learning_rate": 3.737213540323551e-05,
      "loss": 0.0419,
      "step": 29400
    },
    {
      "epoch": 2.028467303857526,
      "grad_norm": 0.26547718048095703,
      "learning_rate": 3.732915570684409e-05,
      "loss": 0.0399,
      "step": 29500
    },
    {
      "epoch": 2.0353434642095856,
      "grad_norm": 0.16204489767551422,
      "learning_rate": 3.728617601045266e-05,
      "loss": 0.0346,
      "step": 29600
    },
    {
      "epoch": 2.042219624561645,
      "grad_norm": 0.14105655252933502,
      "learning_rate": 3.724319631406124e-05,
      "loss": 0.0394,
      "step": 29700
    },
    {
      "epoch": 2.049095784913704,
      "grad_norm": 0.2906256318092346,
      "learning_rate": 3.7200216617669816e-05,
      "loss": 0.0377,
      "step": 29800
    },
    {
      "epoch": 2.0559719452657634,
      "grad_norm": 0.09365873038768768,
      "learning_rate": 3.715723692127839e-05,
      "loss": 0.0406,
      "step": 29900
    },
    {
      "epoch": 2.062848105617823,
      "grad_norm": 0.1562964767217636,
      "learning_rate": 3.711425722488697e-05,
      "loss": 0.0363,
      "step": 30000
    },
    {
      "epoch": 2.0697242659698825,
      "grad_norm": 0.2125658243894577,
      "learning_rate": 3.707127752849554e-05,
      "loss": 0.0382,
      "step": 30100
    },
    {
      "epoch": 2.0766004263219418,
      "grad_norm": 0.08078601211309433,
      "learning_rate": 3.702829783210411e-05,
      "loss": 0.0388,
      "step": 30200
    },
    {
      "epoch": 2.083476586674001,
      "grad_norm": 0.24354279041290283,
      "learning_rate": 3.698531813571269e-05,
      "loss": 0.037,
      "step": 30300
    },
    {
      "epoch": 2.0903527470260608,
      "grad_norm": 0.1901589035987854,
      "learning_rate": 3.6942338439321266e-05,
      "loss": 0.0384,
      "step": 30400
    },
    {
      "epoch": 2.09722890737812,
      "grad_norm": 0.22660395503044128,
      "learning_rate": 3.689935874292984e-05,
      "loss": 0.0404,
      "step": 30500
    },
    {
      "epoch": 2.1041050677301794,
      "grad_norm": 0.27143263816833496,
      "learning_rate": 3.685637904653842e-05,
      "loss": 0.0392,
      "step": 30600
    },
    {
      "epoch": 2.110981228082239,
      "grad_norm": 0.1529139280319214,
      "learning_rate": 3.6813399350146994e-05,
      "loss": 0.0422,
      "step": 30700
    },
    {
      "epoch": 2.1178573884342984,
      "grad_norm": 0.1358320415019989,
      "learning_rate": 3.677041965375557e-05,
      "loss": 0.0398,
      "step": 30800
    },
    {
      "epoch": 2.1247335487863577,
      "grad_norm": 0.17210330069065094,
      "learning_rate": 3.672743995736414e-05,
      "loss": 0.038,
      "step": 30900
    },
    {
      "epoch": 2.131609709138417,
      "grad_norm": 0.18828085064888,
      "learning_rate": 3.668446026097272e-05,
      "loss": 0.0389,
      "step": 31000
    },
    {
      "epoch": 2.1384858694904767,
      "grad_norm": 0.149435892701149,
      "learning_rate": 3.664148056458129e-05,
      "loss": 0.0405,
      "step": 31100
    },
    {
      "epoch": 2.145362029842536,
      "grad_norm": 0.15618905425071716,
      "learning_rate": 3.6598500868189864e-05,
      "loss": 0.037,
      "step": 31200
    },
    {
      "epoch": 2.1522381901945953,
      "grad_norm": 0.18531434237957,
      "learning_rate": 3.6555521171798445e-05,
      "loss": 0.0373,
      "step": 31300
    },
    {
      "epoch": 2.1591143505466546,
      "grad_norm": 0.26272058486938477,
      "learning_rate": 3.651254147540702e-05,
      "loss": 0.0377,
      "step": 31400
    },
    {
      "epoch": 2.1659905108987143,
      "grad_norm": 0.20782242715358734,
      "learning_rate": 3.646956177901559e-05,
      "loss": 0.0372,
      "step": 31500
    },
    {
      "epoch": 2.1728666712507736,
      "grad_norm": 0.14669068157672882,
      "learning_rate": 3.642658208262417e-05,
      "loss": 0.0397,
      "step": 31600
    },
    {
      "epoch": 2.179742831602833,
      "grad_norm": 0.10764780640602112,
      "learning_rate": 3.638360238623275e-05,
      "loss": 0.0381,
      "step": 31700
    },
    {
      "epoch": 2.1866189919548926,
      "grad_norm": 0.2098299264907837,
      "learning_rate": 3.634062268984132e-05,
      "loss": 0.0339,
      "step": 31800
    },
    {
      "epoch": 2.193495152306952,
      "grad_norm": 0.15840113162994385,
      "learning_rate": 3.62976429934499e-05,
      "loss": 0.0376,
      "step": 31900
    },
    {
      "epoch": 2.200371312659011,
      "grad_norm": 0.08804409205913544,
      "learning_rate": 3.6254663297058475e-05,
      "loss": 0.0375,
      "step": 32000
    },
    {
      "epoch": 2.2072474730110705,
      "grad_norm": 0.15509048104286194,
      "learning_rate": 3.621168360066704e-05,
      "loss": 0.0373,
      "step": 32100
    },
    {
      "epoch": 2.2141236333631302,
      "grad_norm": 0.2614527940750122,
      "learning_rate": 3.6168703904275616e-05,
      "loss": 0.0417,
      "step": 32200
    },
    {
      "epoch": 2.2209997937151895,
      "grad_norm": 0.18313787877559662,
      "learning_rate": 3.61257242078842e-05,
      "loss": 0.0374,
      "step": 32300
    },
    {
      "epoch": 2.227875954067249,
      "grad_norm": 0.15968921780586243,
      "learning_rate": 3.608274451149277e-05,
      "loss": 0.0359,
      "step": 32400
    },
    {
      "epoch": 2.234752114419308,
      "grad_norm": 0.2580258548259735,
      "learning_rate": 3.6039764815101345e-05,
      "loss": 0.0378,
      "step": 32500
    },
    {
      "epoch": 2.241628274771368,
      "grad_norm": 0.26996007561683655,
      "learning_rate": 3.5996785118709926e-05,
      "loss": 0.0353,
      "step": 32600
    },
    {
      "epoch": 2.248504435123427,
      "grad_norm": 0.24468904733657837,
      "learning_rate": 3.59538054223185e-05,
      "loss": 0.0392,
      "step": 32700
    },
    {
      "epoch": 2.2553805954754864,
      "grad_norm": 0.1977817416191101,
      "learning_rate": 3.5910825725927074e-05,
      "loss": 0.0382,
      "step": 32800
    },
    {
      "epoch": 2.2622567558275457,
      "grad_norm": 0.16981028020381927,
      "learning_rate": 3.5867846029535654e-05,
      "loss": 0.0359,
      "step": 32900
    },
    {
      "epoch": 2.2691329161796054,
      "grad_norm": 0.23832093179225922,
      "learning_rate": 3.5825296130108136e-05,
      "loss": 0.0394,
      "step": 33000
    },
    {
      "epoch": 2.2760090765316647,
      "grad_norm": 0.2095680683851242,
      "learning_rate": 3.578231643371671e-05,
      "loss": 0.038,
      "step": 33100
    },
    {
      "epoch": 2.282885236883724,
      "grad_norm": 0.16210146248340607,
      "learning_rate": 3.573933673732529e-05,
      "loss": 0.041,
      "step": 33200
    },
    {
      "epoch": 2.2897613972357833,
      "grad_norm": 0.18483567237854004,
      "learning_rate": 3.5696357040933865e-05,
      "loss": 0.0399,
      "step": 33300
    },
    {
      "epoch": 2.296637557587843,
      "grad_norm": 0.22736261785030365,
      "learning_rate": 3.565337734454244e-05,
      "loss": 0.0411,
      "step": 33400
    },
    {
      "epoch": 2.3035137179399023,
      "grad_norm": 0.18659518659114838,
      "learning_rate": 3.561039764815102e-05,
      "loss": 0.0383,
      "step": 33500
    },
    {
      "epoch": 2.3103898782919616,
      "grad_norm": 0.24172981083393097,
      "learning_rate": 3.5567417951759593e-05,
      "loss": 0.0402,
      "step": 33600
    },
    {
      "epoch": 2.3172660386440214,
      "grad_norm": 0.2147575169801712,
      "learning_rate": 3.5524868052332076e-05,
      "loss": 0.0404,
      "step": 33700
    },
    {
      "epoch": 2.3241421989960807,
      "grad_norm": 0.19107939302921295,
      "learning_rate": 3.5481888355940656e-05,
      "loss": 0.034,
      "step": 33800
    },
    {
      "epoch": 2.33101835934814,
      "grad_norm": 0.1923719048500061,
      "learning_rate": 3.543890865954923e-05,
      "loss": 0.0382,
      "step": 33900
    },
    {
      "epoch": 2.3378945197001992,
      "grad_norm": 0.1699693351984024,
      "learning_rate": 3.5395928963157804e-05,
      "loss": 0.0387,
      "step": 34000
    },
    {
      "epoch": 2.344770680052259,
      "grad_norm": 0.26110661029815674,
      "learning_rate": 3.535337906373029e-05,
      "loss": 0.0406,
      "step": 34100
    },
    {
      "epoch": 2.3516468404043183,
      "grad_norm": 0.1638038009405136,
      "learning_rate": 3.531039936733887e-05,
      "loss": 0.0408,
      "step": 34200
    },
    {
      "epoch": 2.3585230007563776,
      "grad_norm": 0.1642715334892273,
      "learning_rate": 3.526741967094744e-05,
      "loss": 0.036,
      "step": 34300
    },
    {
      "epoch": 2.365399161108437,
      "grad_norm": 0.23310603201389313,
      "learning_rate": 3.522443997455602e-05,
      "loss": 0.035,
      "step": 34400
    },
    {
      "epoch": 2.3722753214604966,
      "grad_norm": 0.18543286621570587,
      "learning_rate": 3.5181460278164596e-05,
      "loss": 0.0397,
      "step": 34500
    },
    {
      "epoch": 2.379151481812556,
      "grad_norm": 0.12274504452943802,
      "learning_rate": 3.513848058177317e-05,
      "loss": 0.0372,
      "step": 34600
    },
    {
      "epoch": 2.386027642164615,
      "grad_norm": 0.17857620120048523,
      "learning_rate": 3.509550088538175e-05,
      "loss": 0.0392,
      "step": 34700
    },
    {
      "epoch": 2.392903802516675,
      "grad_norm": 0.05019589141011238,
      "learning_rate": 3.5052521188990324e-05,
      "loss": 0.0397,
      "step": 34800
    },
    {
      "epoch": 2.399779962868734,
      "grad_norm": 0.15066391229629517,
      "learning_rate": 3.50095414925989e-05,
      "loss": 0.0358,
      "step": 34900
    },
    {
      "epoch": 2.4066561232207935,
      "grad_norm": 0.15309128165245056,
      "learning_rate": 3.496656179620747e-05,
      "loss": 0.0409,
      "step": 35000
    },
    {
      "epoch": 2.4135322835728528,
      "grad_norm": 0.13848069310188293,
      "learning_rate": 3.4923582099816046e-05,
      "loss": 0.037,
      "step": 35100
    },
    {
      "epoch": 2.4204084439249125,
      "grad_norm": 0.2115834802389145,
      "learning_rate": 3.488060240342462e-05,
      "loss": 0.0371,
      "step": 35200
    },
    {
      "epoch": 2.427284604276972,
      "grad_norm": 0.14352549612522125,
      "learning_rate": 3.48376227070332e-05,
      "loss": 0.0395,
      "step": 35300
    },
    {
      "epoch": 2.434160764629031,
      "grad_norm": 0.17555873095989227,
      "learning_rate": 3.4794643010641775e-05,
      "loss": 0.0363,
      "step": 35400
    },
    {
      "epoch": 2.4410369249810904,
      "grad_norm": 0.21757450699806213,
      "learning_rate": 3.475166331425035e-05,
      "loss": 0.0413,
      "step": 35500
    },
    {
      "epoch": 2.44791308533315,
      "grad_norm": 0.207267165184021,
      "learning_rate": 3.470868361785892e-05,
      "loss": 0.0405,
      "step": 35600
    },
    {
      "epoch": 2.4547892456852094,
      "grad_norm": 0.2719336450099945,
      "learning_rate": 3.46657039214675e-05,
      "loss": 0.0369,
      "step": 35700
    },
    {
      "epoch": 2.4616654060372687,
      "grad_norm": 0.2414855808019638,
      "learning_rate": 3.462272422507608e-05,
      "loss": 0.0391,
      "step": 35800
    },
    {
      "epoch": 2.4685415663893284,
      "grad_norm": 0.14064519107341766,
      "learning_rate": 3.457974452868465e-05,
      "loss": 0.0378,
      "step": 35900
    },
    {
      "epoch": 2.4754177267413877,
      "grad_norm": 0.26730090379714966,
      "learning_rate": 3.4536764832293225e-05,
      "loss": 0.0359,
      "step": 36000
    },
    {
      "epoch": 2.482293887093447,
      "grad_norm": 0.10148501396179199,
      "learning_rate": 3.44937851359018e-05,
      "loss": 0.0383,
      "step": 36100
    },
    {
      "epoch": 2.4891700474455063,
      "grad_norm": 0.14661915600299835,
      "learning_rate": 3.445080543951037e-05,
      "loss": 0.0403,
      "step": 36200
    },
    {
      "epoch": 2.496046207797566,
      "grad_norm": 0.14788874983787537,
      "learning_rate": 3.440825554008287e-05,
      "loss": 0.0388,
      "step": 36300
    },
    {
      "epoch": 2.5029223681496253,
      "grad_norm": 0.09920548647642136,
      "learning_rate": 3.436527584369144e-05,
      "loss": 0.0386,
      "step": 36400
    },
    {
      "epoch": 2.5097985285016846,
      "grad_norm": 0.23198701441287994,
      "learning_rate": 3.4322296147300016e-05,
      "loss": 0.0381,
      "step": 36500
    },
    {
      "epoch": 2.516674688853744,
      "grad_norm": 0.23048517107963562,
      "learning_rate": 3.42793164509086e-05,
      "loss": 0.0366,
      "step": 36600
    },
    {
      "epoch": 2.5235508492058036,
      "grad_norm": 0.18930891156196594,
      "learning_rate": 3.423633675451717e-05,
      "loss": 0.0384,
      "step": 36700
    },
    {
      "epoch": 2.530427009557863,
      "grad_norm": 0.16515952348709106,
      "learning_rate": 3.419335705812574e-05,
      "loss": 0.0376,
      "step": 36800
    },
    {
      "epoch": 2.537303169909922,
      "grad_norm": 0.07311467826366425,
      "learning_rate": 3.415037736173432e-05,
      "loss": 0.0373,
      "step": 36900
    },
    {
      "epoch": 2.544179330261982,
      "grad_norm": 0.14698435366153717,
      "learning_rate": 3.410739766534289e-05,
      "loss": 0.0365,
      "step": 37000
    },
    {
      "epoch": 2.5510554906140412,
      "grad_norm": 0.1859947293996811,
      "learning_rate": 3.4064417968951466e-05,
      "loss": 0.0381,
      "step": 37100
    },
    {
      "epoch": 2.5579316509661005,
      "grad_norm": 0.18247927725315094,
      "learning_rate": 3.402143827256005e-05,
      "loss": 0.0376,
      "step": 37200
    },
    {
      "epoch": 2.56480781131816,
      "grad_norm": 0.15809448063373566,
      "learning_rate": 3.397845857616862e-05,
      "loss": 0.0373,
      "step": 37300
    },
    {
      "epoch": 2.571683971670219,
      "grad_norm": 0.17922459542751312,
      "learning_rate": 3.3935478879777195e-05,
      "loss": 0.0365,
      "step": 37400
    },
    {
      "epoch": 2.578560132022279,
      "grad_norm": 0.16265325248241425,
      "learning_rate": 3.389249918338577e-05,
      "loss": 0.0402,
      "step": 37500
    },
    {
      "epoch": 2.585436292374338,
      "grad_norm": 0.23302635550498962,
      "learning_rate": 3.384951948699435e-05,
      "loss": 0.0368,
      "step": 37600
    },
    {
      "epoch": 2.5923124527263974,
      "grad_norm": 0.17308251559734344,
      "learning_rate": 3.3806539790602923e-05,
      "loss": 0.0387,
      "step": 37700
    },
    {
      "epoch": 2.599188613078457,
      "grad_norm": 0.14877250790596008,
      "learning_rate": 3.376356009421149e-05,
      "loss": 0.0382,
      "step": 37800
    },
    {
      "epoch": 2.6060647734305165,
      "grad_norm": 0.16892166435718536,
      "learning_rate": 3.3721010194783986e-05,
      "loss": 0.0356,
      "step": 37900
    },
    {
      "epoch": 2.6129409337825757,
      "grad_norm": 0.24185864627361298,
      "learning_rate": 3.367803049839256e-05,
      "loss": 0.0404,
      "step": 38000
    },
    {
      "epoch": 2.6198170941346355,
      "grad_norm": 0.14377298951148987,
      "learning_rate": 3.363505080200114e-05,
      "loss": 0.0381,
      "step": 38100
    },
    {
      "epoch": 2.6266932544866948,
      "grad_norm": 0.178401380777359,
      "learning_rate": 3.3592071105609715e-05,
      "loss": 0.0362,
      "step": 38200
    },
    {
      "epoch": 2.633569414838754,
      "grad_norm": 0.20331326127052307,
      "learning_rate": 3.354909140921829e-05,
      "loss": 0.0389,
      "step": 38300
    },
    {
      "epoch": 2.6404455751908134,
      "grad_norm": 0.04326581954956055,
      "learning_rate": 3.350611171282686e-05,
      "loss": 0.034,
      "step": 38400
    },
    {
      "epoch": 2.6473217355428726,
      "grad_norm": 0.1552913635969162,
      "learning_rate": 3.346313201643544e-05,
      "loss": 0.0392,
      "step": 38500
    },
    {
      "epoch": 2.6541978958949324,
      "grad_norm": 0.23774844408035278,
      "learning_rate": 3.342015232004401e-05,
      "loss": 0.0338,
      "step": 38600
    },
    {
      "epoch": 2.6610740562469917,
      "grad_norm": 0.24146082997322083,
      "learning_rate": 3.3377172623652585e-05,
      "loss": 0.0385,
      "step": 38700
    },
    {
      "epoch": 2.667950216599051,
      "grad_norm": 0.23321060836315155,
      "learning_rate": 3.3334192927261165e-05,
      "loss": 0.0401,
      "step": 38800
    },
    {
      "epoch": 2.6748263769511107,
      "grad_norm": 0.16201218962669373,
      "learning_rate": 3.329121323086974e-05,
      "loss": 0.0345,
      "step": 38900
    },
    {
      "epoch": 2.68170253730317,
      "grad_norm": 0.24993738532066345,
      "learning_rate": 3.324823353447831e-05,
      "loss": 0.0377,
      "step": 39000
    },
    {
      "epoch": 2.6885786976552293,
      "grad_norm": 0.1871921718120575,
      "learning_rate": 3.3205253838086894e-05,
      "loss": 0.0359,
      "step": 39100
    },
    {
      "epoch": 2.6954548580072886,
      "grad_norm": 0.23846305906772614,
      "learning_rate": 3.316227414169547e-05,
      "loss": 0.0377,
      "step": 39200
    },
    {
      "epoch": 2.7023310183593483,
      "grad_norm": 0.27033543586730957,
      "learning_rate": 3.311929444530404e-05,
      "loss": 0.038,
      "step": 39300
    },
    {
      "epoch": 2.7092071787114076,
      "grad_norm": 0.22130893170833588,
      "learning_rate": 3.3076314748912615e-05,
      "loss": 0.0384,
      "step": 39400
    },
    {
      "epoch": 2.716083339063467,
      "grad_norm": 0.17078272998332977,
      "learning_rate": 3.303333505252119e-05,
      "loss": 0.0378,
      "step": 39500
    },
    {
      "epoch": 2.722959499415526,
      "grad_norm": 0.1867801398038864,
      "learning_rate": 3.299035535612976e-05,
      "loss": 0.0383,
      "step": 39600
    },
    {
      "epoch": 2.729835659767586,
      "grad_norm": 0.1992446482181549,
      "learning_rate": 3.294737565973834e-05,
      "loss": 0.0361,
      "step": 39700
    },
    {
      "epoch": 2.736711820119645,
      "grad_norm": 0.13997767865657806,
      "learning_rate": 3.290439596334692e-05,
      "loss": 0.0383,
      "step": 39800
    },
    {
      "epoch": 2.7435879804717045,
      "grad_norm": 0.14934520423412323,
      "learning_rate": 3.286141626695549e-05,
      "loss": 0.036,
      "step": 39900
    },
    {
      "epoch": 2.7504641408237642,
      "grad_norm": 0.209257110953331,
      "learning_rate": 3.2818436570564066e-05,
      "loss": 0.0365,
      "step": 40000
    },
    {
      "epoch": 2.7573403011758235,
      "grad_norm": 0.1441500186920166,
      "learning_rate": 3.2775456874172646e-05,
      "loss": 0.0373,
      "step": 40100
    },
    {
      "epoch": 2.764216461527883,
      "grad_norm": 0.17181673645973206,
      "learning_rate": 3.273247717778122e-05,
      "loss": 0.0338,
      "step": 40200
    },
    {
      "epoch": 2.771092621879942,
      "grad_norm": 0.19314229488372803,
      "learning_rate": 3.2689497481389794e-05,
      "loss": 0.0395,
      "step": 40300
    },
    {
      "epoch": 2.7779687822320014,
      "grad_norm": 0.16253747045993805,
      "learning_rate": 3.264651778499837e-05,
      "loss": 0.0386,
      "step": 40400
    },
    {
      "epoch": 2.784844942584061,
      "grad_norm": 0.25656023621559143,
      "learning_rate": 3.260353808860694e-05,
      "loss": 0.0381,
      "step": 40500
    },
    {
      "epoch": 2.7917211029361204,
      "grad_norm": 0.21345998346805573,
      "learning_rate": 3.256098818917943e-05,
      "loss": 0.0401,
      "step": 40600
    },
    {
      "epoch": 2.7985972632881797,
      "grad_norm": 0.13556182384490967,
      "learning_rate": 3.251800849278801e-05,
      "loss": 0.0362,
      "step": 40700
    },
    {
      "epoch": 2.8054734236402394,
      "grad_norm": 0.11481267213821411,
      "learning_rate": 3.2475028796396586e-05,
      "loss": 0.0363,
      "step": 40800
    },
    {
      "epoch": 2.8123495839922987,
      "grad_norm": 0.1479717344045639,
      "learning_rate": 3.243204910000516e-05,
      "loss": 0.0372,
      "step": 40900
    },
    {
      "epoch": 2.819225744344358,
      "grad_norm": 0.08161962777376175,
      "learning_rate": 3.2389069403613734e-05,
      "loss": 0.0359,
      "step": 41000
    },
    {
      "epoch": 2.8261019046964178,
      "grad_norm": 0.23168520629405975,
      "learning_rate": 3.234608970722231e-05,
      "loss": 0.0363,
      "step": 41100
    },
    {
      "epoch": 2.832978065048477,
      "grad_norm": 0.17861776053905487,
      "learning_rate": 3.230311001083088e-05,
      "loss": 0.0379,
      "step": 41200
    },
    {
      "epoch": 2.8398542254005363,
      "grad_norm": 0.2114315778017044,
      "learning_rate": 3.226013031443946e-05,
      "loss": 0.0362,
      "step": 41300
    },
    {
      "epoch": 2.8467303857525956,
      "grad_norm": 0.07998563349246979,
      "learning_rate": 3.2217150618048036e-05,
      "loss": 0.0365,
      "step": 41400
    },
    {
      "epoch": 2.853606546104655,
      "grad_norm": 0.17806121706962585,
      "learning_rate": 3.217417092165661e-05,
      "loss": 0.0348,
      "step": 41500
    },
    {
      "epoch": 2.8604827064567147,
      "grad_norm": 0.12732097506523132,
      "learning_rate": 3.2131191225265184e-05,
      "loss": 0.0376,
      "step": 41600
    },
    {
      "epoch": 2.867358866808774,
      "grad_norm": 0.17116717994213104,
      "learning_rate": 3.2088211528873764e-05,
      "loss": 0.0355,
      "step": 41700
    },
    {
      "epoch": 2.8742350271608332,
      "grad_norm": 0.2555536925792694,
      "learning_rate": 3.204523183248234e-05,
      "loss": 0.036,
      "step": 41800
    },
    {
      "epoch": 2.881111187512893,
      "grad_norm": 0.1312401294708252,
      "learning_rate": 3.200225213609091e-05,
      "loss": 0.038,
      "step": 41900
    },
    {
      "epoch": 2.8879873478649523,
      "grad_norm": 0.23670977354049683,
      "learning_rate": 3.1959272439699486e-05,
      "loss": 0.0373,
      "step": 42000
    },
    {
      "epoch": 2.8948635082170115,
      "grad_norm": 0.14067688584327698,
      "learning_rate": 3.191629274330806e-05,
      "loss": 0.0384,
      "step": 42100
    },
    {
      "epoch": 2.9017396685690713,
      "grad_norm": 0.16304904222488403,
      "learning_rate": 3.1873313046916634e-05,
      "loss": 0.0354,
      "step": 42200
    },
    {
      "epoch": 2.9086158289211306,
      "grad_norm": 0.19330479204654694,
      "learning_rate": 3.1830333350525215e-05,
      "loss": 0.0345,
      "step": 42300
    },
    {
      "epoch": 2.91549198927319,
      "grad_norm": 0.1337396651506424,
      "learning_rate": 3.178735365413379e-05,
      "loss": 0.0346,
      "step": 42400
    },
    {
      "epoch": 2.922368149625249,
      "grad_norm": 0.07845620065927505,
      "learning_rate": 3.174437395774236e-05,
      "loss": 0.0365,
      "step": 42500
    },
    {
      "epoch": 2.9292443099773084,
      "grad_norm": 0.10903960466384888,
      "learning_rate": 3.170139426135094e-05,
      "loss": 0.0374,
      "step": 42600
    },
    {
      "epoch": 2.936120470329368,
      "grad_norm": 0.11552683264017105,
      "learning_rate": 3.165841456495952e-05,
      "loss": 0.0369,
      "step": 42700
    },
    {
      "epoch": 2.9429966306814275,
      "grad_norm": 0.29174456000328064,
      "learning_rate": 3.161543486856809e-05,
      "loss": 0.0351,
      "step": 42800
    },
    {
      "epoch": 2.9498727910334868,
      "grad_norm": 0.10112129151821136,
      "learning_rate": 3.1572455172176665e-05,
      "loss": 0.0371,
      "step": 42900
    },
    {
      "epoch": 2.9567489513855465,
      "grad_norm": 0.17112278938293457,
      "learning_rate": 3.152947547578524e-05,
      "loss": 0.0381,
      "step": 43000
    },
    {
      "epoch": 2.963625111737606,
      "grad_norm": 0.15243369340896606,
      "learning_rate": 3.148649577939381e-05,
      "loss": 0.0348,
      "step": 43100
    },
    {
      "epoch": 2.970501272089665,
      "grad_norm": 0.13451287150382996,
      "learning_rate": 3.144351608300239e-05,
      "loss": 0.0369,
      "step": 43200
    },
    {
      "epoch": 2.977377432441725,
      "grad_norm": 0.2866349220275879,
      "learning_rate": 3.140053638661097e-05,
      "loss": 0.0349,
      "step": 43300
    },
    {
      "epoch": 2.984253592793784,
      "grad_norm": 0.128305584192276,
      "learning_rate": 3.135755669021954e-05,
      "loss": 0.0356,
      "step": 43400
    },
    {
      "epoch": 2.9911297531458434,
      "grad_norm": 0.12142308056354523,
      "learning_rate": 3.1314576993828115e-05,
      "loss": 0.0356,
      "step": 43500
    },
    {
      "epoch": 2.9980059134979027,
      "grad_norm": 0.1833568960428238,
      "learning_rate": 3.1271597297436696e-05,
      "loss": 0.0363,
      "step": 43600
    },
    {
      "epoch": 3.0,
      "eval_accuracy_macro_0.5": 0.9831885099411011,
      "eval_accuracy_micro_0.5": 0.9831884503364563,
      "eval_accuracy_weighted_0.5": 0.9808424711227417,
      "eval_f1_macro_0.5": 0.7763031721115112,
      "eval_f1_macro_0.6": 0.7577846050262451,
      "eval_f1_macro_0.7": 0.7261654138565063,
      "eval_f1_macro_0.8": 0.5639108419418335,
      "eval_f1_micro_0.5": 0.7755119800567627,
      "eval_f1_micro_0.6": 0.7597060799598694,
      "eval_f1_micro_0.7": 0.7318995594978333,
      "eval_f1_micro_0.8": 0.6826069951057434,
      "eval_f1_micro_0.9": 0.5833755135536194,
      "eval_f1_weighted_0.5": 0.7691315412521362,
      "eval_f1_weighted_0.6": 0.7495914101600647,
      "eval_f1_weighted_0.7": 0.7162628173828125,
      "eval_f1_weighted_0.8": 0.5487428903579712,
      "eval_loss": 0.03445659950375557,
      "eval_runtime": 133.5509,
      "eval_samples_per_second": 217.423,
      "eval_steps_per_second": 27.181,
      "step": 43629
    },
    {
      "epoch": 3.004882073849962,
      "grad_norm": 0.2134506106376648,
      "learning_rate": 3.122861760104527e-05,
      "loss": 0.035,
      "step": 43700
    },
    {
      "epoch": 3.0117582342020217,
      "grad_norm": 0.20734190940856934,
      "learning_rate": 3.1185637904653844e-05,
      "loss": 0.0363,
      "step": 43800
    },
    {
      "epoch": 3.018634394554081,
      "grad_norm": 0.1814837008714676,
      "learning_rate": 3.114265820826242e-05,
      "loss": 0.033,
      "step": 43900
    },
    {
      "epoch": 3.0255105549061403,
      "grad_norm": 0.296842485666275,
      "learning_rate": 3.109967851187099e-05,
      "loss": 0.0391,
      "step": 44000
    },
    {
      "epoch": 3.0323867152582,
      "grad_norm": 0.102895587682724,
      "learning_rate": 3.105712861244348e-05,
      "loss": 0.0348,
      "step": 44100
    },
    {
      "epoch": 3.0392628756102593,
      "grad_norm": 0.1862899512052536,
      "learning_rate": 3.101414891605206e-05,
      "loss": 0.0351,
      "step": 44200
    },
    {
      "epoch": 3.0461390359623186,
      "grad_norm": 0.05755171924829483,
      "learning_rate": 3.0971169219660635e-05,
      "loss": 0.036,
      "step": 44300
    },
    {
      "epoch": 3.053015196314378,
      "grad_norm": 0.11086376756429672,
      "learning_rate": 3.092818952326921e-05,
      "loss": 0.0353,
      "step": 44400
    },
    {
      "epoch": 3.0598913566664376,
      "grad_norm": 0.17741890251636505,
      "learning_rate": 3.088520982687779e-05,
      "loss": 0.0352,
      "step": 44500
    },
    {
      "epoch": 3.066767517018497,
      "grad_norm": 0.19773811101913452,
      "learning_rate": 3.0842230130486364e-05,
      "loss": 0.0347,
      "step": 44600
    },
    {
      "epoch": 3.073643677370556,
      "grad_norm": 0.2457268238067627,
      "learning_rate": 3.079925043409493e-05,
      "loss": 0.0377,
      "step": 44700
    },
    {
      "epoch": 3.0805198377226155,
      "grad_norm": 0.11451302468776703,
      "learning_rate": 3.075627073770351e-05,
      "loss": 0.0357,
      "step": 44800
    },
    {
      "epoch": 3.0873959980746752,
      "grad_norm": 0.1819365918636322,
      "learning_rate": 3.0713291041312085e-05,
      "loss": 0.0364,
      "step": 44900
    },
    {
      "epoch": 3.0942721584267345,
      "grad_norm": 0.1538633406162262,
      "learning_rate": 3.067031134492066e-05,
      "loss": 0.0381,
      "step": 45000
    },
    {
      "epoch": 3.101148318778794,
      "grad_norm": 0.18955238163471222,
      "learning_rate": 3.062733164852923e-05,
      "loss": 0.0329,
      "step": 45100
    },
    {
      "epoch": 3.1080244791308536,
      "grad_norm": 0.17810192704200745,
      "learning_rate": 3.0584351952137814e-05,
      "loss": 0.0357,
      "step": 45200
    },
    {
      "epoch": 3.114900639482913,
      "grad_norm": 0.33077678084373474,
      "learning_rate": 3.054137225574639e-05,
      "loss": 0.036,
      "step": 45300
    },
    {
      "epoch": 3.121776799834972,
      "grad_norm": 0.18024908006191254,
      "learning_rate": 3.0498392559354962e-05,
      "loss": 0.0366,
      "step": 45400
    },
    {
      "epoch": 3.1286529601870314,
      "grad_norm": 0.1854056417942047,
      "learning_rate": 3.045541286296354e-05,
      "loss": 0.0359,
      "step": 45500
    },
    {
      "epoch": 3.135529120539091,
      "grad_norm": 0.2225530743598938,
      "learning_rate": 3.0412433166572113e-05,
      "loss": 0.0369,
      "step": 45600
    },
    {
      "epoch": 3.1424052808911505,
      "grad_norm": 0.11217363178730011,
      "learning_rate": 3.0369453470180687e-05,
      "loss": 0.0352,
      "step": 45700
    },
    {
      "epoch": 3.1492814412432097,
      "grad_norm": 0.17343197762966156,
      "learning_rate": 3.0326473773789264e-05,
      "loss": 0.0349,
      "step": 45800
    },
    {
      "epoch": 3.156157601595269,
      "grad_norm": 0.1345687061548233,
      "learning_rate": 3.0283494077397838e-05,
      "loss": 0.0352,
      "step": 45900
    },
    {
      "epoch": 3.1630337619473288,
      "grad_norm": 0.23004621267318726,
      "learning_rate": 3.0240514381006412e-05,
      "loss": 0.0369,
      "step": 46000
    },
    {
      "epoch": 3.169909922299388,
      "grad_norm": 0.21977141499519348,
      "learning_rate": 3.0197534684614993e-05,
      "loss": 0.0363,
      "step": 46100
    },
    {
      "epoch": 3.1767860826514474,
      "grad_norm": 0.1965373158454895,
      "learning_rate": 3.0154554988223567e-05,
      "loss": 0.0346,
      "step": 46200
    },
    {
      "epoch": 3.1836622430035066,
      "grad_norm": 0.16250765323638916,
      "learning_rate": 3.011157529183214e-05,
      "loss": 0.0341,
      "step": 46300
    },
    {
      "epoch": 3.1905384033555664,
      "grad_norm": 0.1777803897857666,
      "learning_rate": 3.0068595595440714e-05,
      "loss": 0.0338,
      "step": 46400
    },
    {
      "epoch": 3.1974145637076257,
      "grad_norm": 0.22795407474040985,
      "learning_rate": 3.0025615899049292e-05,
      "loss": 0.0372,
      "step": 46500
    },
    {
      "epoch": 3.204290724059685,
      "grad_norm": 0.11559133231639862,
      "learning_rate": 2.9982636202657866e-05,
      "loss": 0.0367,
      "step": 46600
    },
    {
      "epoch": 3.2111668844117442,
      "grad_norm": 0.14777342975139618,
      "learning_rate": 2.993965650626644e-05,
      "loss": 0.0349,
      "step": 46700
    },
    {
      "epoch": 3.218043044763804,
      "grad_norm": 0.21801085770130157,
      "learning_rate": 2.9896676809875017e-05,
      "loss": 0.0355,
      "step": 46800
    },
    {
      "epoch": 3.2249192051158633,
      "grad_norm": 0.23324696719646454,
      "learning_rate": 2.985369711348359e-05,
      "loss": 0.0377,
      "step": 46900
    },
    {
      "epoch": 3.2317953654679226,
      "grad_norm": 0.20767143368721008,
      "learning_rate": 2.9810717417092165e-05,
      "loss": 0.0375,
      "step": 47000
    },
    {
      "epoch": 3.2386715258199823,
      "grad_norm": 0.15755483508110046,
      "learning_rate": 2.9767737720700745e-05,
      "loss": 0.0351,
      "step": 47100
    },
    {
      "epoch": 3.2455476861720416,
      "grad_norm": 0.18351033329963684,
      "learning_rate": 2.972475802430932e-05,
      "loss": 0.0364,
      "step": 47200
    },
    {
      "epoch": 3.252423846524101,
      "grad_norm": 0.2789646089076996,
      "learning_rate": 2.9681778327917893e-05,
      "loss": 0.0363,
      "step": 47300
    },
    {
      "epoch": 3.25930000687616,
      "grad_norm": 0.2044118493795395,
      "learning_rate": 2.963879863152647e-05,
      "loss": 0.0343,
      "step": 47400
    },
    {
      "epoch": 3.26617616722822,
      "grad_norm": 0.24502809345722198,
      "learning_rate": 2.9595818935135044e-05,
      "loss": 0.0336,
      "step": 47500
    },
    {
      "epoch": 3.273052327580279,
      "grad_norm": 0.18090280890464783,
      "learning_rate": 2.9552839238743618e-05,
      "loss": 0.0363,
      "step": 47600
    },
    {
      "epoch": 3.2799284879323385,
      "grad_norm": 0.1837949901819229,
      "learning_rate": 2.9509859542352192e-05,
      "loss": 0.0334,
      "step": 47700
    },
    {
      "epoch": 3.286804648284398,
      "grad_norm": 0.16976365447044373,
      "learning_rate": 2.946687984596077e-05,
      "loss": 0.0345,
      "step": 47800
    },
    {
      "epoch": 3.2936808086364575,
      "grad_norm": 0.3161658048629761,
      "learning_rate": 2.942432994653326e-05,
      "loss": 0.0353,
      "step": 47900
    },
    {
      "epoch": 3.300556968988517,
      "grad_norm": 0.17382211983203888,
      "learning_rate": 2.9381350250141836e-05,
      "loss": 0.0371,
      "step": 48000
    },
    {
      "epoch": 3.307433129340576,
      "grad_norm": 0.14837679266929626,
      "learning_rate": 2.933837055375041e-05,
      "loss": 0.0387,
      "step": 48100
    },
    {
      "epoch": 3.314309289692636,
      "grad_norm": 0.11524328589439392,
      "learning_rate": 2.9295390857358984e-05,
      "loss": 0.0337,
      "step": 48200
    },
    {
      "epoch": 3.321185450044695,
      "grad_norm": 0.20336505770683289,
      "learning_rate": 2.9252411160967558e-05,
      "loss": 0.0348,
      "step": 48300
    },
    {
      "epoch": 3.3280616103967544,
      "grad_norm": 0.14726589620113373,
      "learning_rate": 2.9209431464576138e-05,
      "loss": 0.0332,
      "step": 48400
    },
    {
      "epoch": 3.3349377707488137,
      "grad_norm": 0.1451738029718399,
      "learning_rate": 2.916645176818471e-05,
      "loss": 0.0374,
      "step": 48500
    },
    {
      "epoch": 3.3418139311008734,
      "grad_norm": 0.1897554248571396,
      "learning_rate": 2.9123472071793283e-05,
      "loss": 0.0356,
      "step": 48600
    },
    {
      "epoch": 3.3486900914529327,
      "grad_norm": 0.1631104052066803,
      "learning_rate": 2.9080492375401863e-05,
      "loss": 0.0368,
      "step": 48700
    },
    {
      "epoch": 3.355566251804992,
      "grad_norm": 0.10977617651224136,
      "learning_rate": 2.9037512679010437e-05,
      "loss": 0.0358,
      "step": 48800
    },
    {
      "epoch": 3.3624424121570513,
      "grad_norm": 0.11387956887483597,
      "learning_rate": 2.899453298261901e-05,
      "loss": 0.0334,
      "step": 48900
    },
    {
      "epoch": 3.369318572509111,
      "grad_norm": 0.23049324750900269,
      "learning_rate": 2.895155328622759e-05,
      "loss": 0.0367,
      "step": 49000
    },
    {
      "epoch": 3.3761947328611703,
      "grad_norm": 0.13139574229717255,
      "learning_rate": 2.8908573589836162e-05,
      "loss": 0.0365,
      "step": 49100
    },
    {
      "epoch": 3.3830708932132296,
      "grad_norm": 0.05209381505846977,
      "learning_rate": 2.8865593893444736e-05,
      "loss": 0.0329,
      "step": 49200
    },
    {
      "epoch": 3.3899470535652894,
      "grad_norm": 0.13994798064231873,
      "learning_rate": 2.8822614197053317e-05,
      "loss": 0.0347,
      "step": 49300
    },
    {
      "epoch": 3.3968232139173486,
      "grad_norm": 0.11619751900434494,
      "learning_rate": 2.877963450066189e-05,
      "loss": 0.0351,
      "step": 49400
    },
    {
      "epoch": 3.403699374269408,
      "grad_norm": 0.1803285926580429,
      "learning_rate": 2.873665480427046e-05,
      "loss": 0.0357,
      "step": 49500
    },
    {
      "epoch": 3.4105755346214672,
      "grad_norm": 0.22959953546524048,
      "learning_rate": 2.8693675107879035e-05,
      "loss": 0.0365,
      "step": 49600
    },
    {
      "epoch": 3.417451694973527,
      "grad_norm": 0.16988900303840637,
      "learning_rate": 2.8650695411487616e-05,
      "loss": 0.0344,
      "step": 49700
    },
    {
      "epoch": 3.4243278553255863,
      "grad_norm": 0.16891953349113464,
      "learning_rate": 2.860771571509619e-05,
      "loss": 0.0363,
      "step": 49800
    },
    {
      "epoch": 3.4312040156776455,
      "grad_norm": 0.3391919732093811,
      "learning_rate": 2.8564736018704764e-05,
      "loss": 0.0341,
      "step": 49900
    },
    {
      "epoch": 3.438080176029705,
      "grad_norm": 0.24050331115722656,
      "learning_rate": 2.852175632231334e-05,
      "loss": 0.0347,
      "step": 50000
    },
    {
      "epoch": 3.4449563363817646,
      "grad_norm": 0.13359344005584717,
      "learning_rate": 2.8478776625921915e-05,
      "loss": 0.0343,
      "step": 50100
    },
    {
      "epoch": 3.451832496733824,
      "grad_norm": 0.2784908413887024,
      "learning_rate": 2.843579692953049e-05,
      "loss": 0.0374,
      "step": 50200
    },
    {
      "epoch": 3.458708657085883,
      "grad_norm": 0.255441278219223,
      "learning_rate": 2.839281723313907e-05,
      "loss": 0.0358,
      "step": 50300
    },
    {
      "epoch": 3.465584817437943,
      "grad_norm": 0.15022718906402588,
      "learning_rate": 2.8349837536747644e-05,
      "loss": 0.0368,
      "step": 50400
    },
    {
      "epoch": 3.472460977790002,
      "grad_norm": 0.17096982896327972,
      "learning_rate": 2.8306857840356214e-05,
      "loss": 0.0351,
      "step": 50500
    },
    {
      "epoch": 3.4793371381420615,
      "grad_norm": 0.20883849263191223,
      "learning_rate": 2.8263878143964795e-05,
      "loss": 0.0351,
      "step": 50600
    },
    {
      "epoch": 3.4862132984941208,
      "grad_norm": 0.18199759721755981,
      "learning_rate": 2.822089844757337e-05,
      "loss": 0.0396,
      "step": 50700
    },
    {
      "epoch": 3.49308945884618,
      "grad_norm": 0.17646095156669617,
      "learning_rate": 2.8177918751181943e-05,
      "loss": 0.0338,
      "step": 50800
    },
    {
      "epoch": 3.49996561919824,
      "grad_norm": 0.1748303472995758,
      "learning_rate": 2.8134939054790517e-05,
      "loss": 0.0368,
      "step": 50900
    },
    {
      "epoch": 3.506841779550299,
      "grad_norm": 0.21823343634605408,
      "learning_rate": 2.8091959358399094e-05,
      "loss": 0.0347,
      "step": 51000
    },
    {
      "epoch": 3.5137179399023584,
      "grad_norm": 0.11984248459339142,
      "learning_rate": 2.8048979662007668e-05,
      "loss": 0.0349,
      "step": 51100
    },
    {
      "epoch": 3.520594100254418,
      "grad_norm": 0.215992271900177,
      "learning_rate": 2.800599996561624e-05,
      "loss": 0.0341,
      "step": 51200
    },
    {
      "epoch": 3.5274702606064774,
      "grad_norm": 0.1603226363658905,
      "learning_rate": 2.7963020269224822e-05,
      "loss": 0.0385,
      "step": 51300
    },
    {
      "epoch": 3.5343464209585367,
      "grad_norm": 0.23391126096248627,
      "learning_rate": 2.7920040572833396e-05,
      "loss": 0.0342,
      "step": 51400
    },
    {
      "epoch": 3.5412225813105964,
      "grad_norm": 0.19839709997177124,
      "learning_rate": 2.7877060876441967e-05,
      "loss": 0.0344,
      "step": 51500
    },
    {
      "epoch": 3.5480987416626557,
      "grad_norm": 0.15294590592384338,
      "learning_rate": 2.7834081180050547e-05,
      "loss": 0.0373,
      "step": 51600
    },
    {
      "epoch": 3.554974902014715,
      "grad_norm": 0.1411149799823761,
      "learning_rate": 2.779110148365912e-05,
      "loss": 0.0388,
      "step": 51700
    },
    {
      "epoch": 3.5618510623667743,
      "grad_norm": 0.14452901482582092,
      "learning_rate": 2.7748121787267695e-05,
      "loss": 0.034,
      "step": 51800
    },
    {
      "epoch": 3.5687272227188336,
      "grad_norm": 0.18478703498840332,
      "learning_rate": 2.7705142090876273e-05,
      "loss": 0.0368,
      "step": 51900
    },
    {
      "epoch": 3.5756033830708933,
      "grad_norm": 0.180294468998909,
      "learning_rate": 2.7662162394484847e-05,
      "loss": 0.0352,
      "step": 52000
    },
    {
      "epoch": 3.5824795434229526,
      "grad_norm": 0.2585941553115845,
      "learning_rate": 2.761918269809342e-05,
      "loss": 0.0371,
      "step": 52100
    },
    {
      "epoch": 3.589355703775012,
      "grad_norm": 0.2664262354373932,
      "learning_rate": 2.7576632798665913e-05,
      "loss": 0.0388,
      "step": 52200
    },
    {
      "epoch": 3.5962318641270716,
      "grad_norm": 0.088248610496521,
      "learning_rate": 2.7533653102274487e-05,
      "loss": 0.0343,
      "step": 52300
    },
    {
      "epoch": 3.603108024479131,
      "grad_norm": 0.1422095149755478,
      "learning_rate": 2.749067340588306e-05,
      "loss": 0.0353,
      "step": 52400
    },
    {
      "epoch": 3.60998418483119,
      "grad_norm": 0.139974907040596,
      "learning_rate": 2.744769370949164e-05,
      "loss": 0.0369,
      "step": 52500
    },
    {
      "epoch": 3.61686034518325,
      "grad_norm": 0.1677938550710678,
      "learning_rate": 2.7404714013100212e-05,
      "loss": 0.0374,
      "step": 52600
    },
    {
      "epoch": 3.6237365055353092,
      "grad_norm": 0.25605762004852295,
      "learning_rate": 2.7361734316708786e-05,
      "loss": 0.0335,
      "step": 52700
    },
    {
      "epoch": 3.6306126658873685,
      "grad_norm": 0.14194324612617493,
      "learning_rate": 2.7318754620317367e-05,
      "loss": 0.0349,
      "step": 52800
    },
    {
      "epoch": 3.637488826239428,
      "grad_norm": 0.13548965752124786,
      "learning_rate": 2.727577492392594e-05,
      "loss": 0.0335,
      "step": 52900
    },
    {
      "epoch": 3.644364986591487,
      "grad_norm": 0.15812800824642181,
      "learning_rate": 2.7232795227534514e-05,
      "loss": 0.0364,
      "step": 53000
    },
    {
      "epoch": 3.651241146943547,
      "grad_norm": 0.12906254827976227,
      "learning_rate": 2.7189815531143088e-05,
      "loss": 0.0348,
      "step": 53100
    },
    {
      "epoch": 3.658117307295606,
      "grad_norm": 0.23171430826187134,
      "learning_rate": 2.7146835834751666e-05,
      "loss": 0.0331,
      "step": 53200
    },
    {
      "epoch": 3.6649934676476654,
      "grad_norm": 0.15435990691184998,
      "learning_rate": 2.710385613836024e-05,
      "loss": 0.0363,
      "step": 53300
    },
    {
      "epoch": 3.671869627999725,
      "grad_norm": 0.1341685950756073,
      "learning_rate": 2.7060876441968813e-05,
      "loss": 0.035,
      "step": 53400
    },
    {
      "epoch": 3.6787457883517845,
      "grad_norm": 0.24037986993789673,
      "learning_rate": 2.7017896745577394e-05,
      "loss": 0.036,
      "step": 53500
    },
    {
      "epoch": 3.6856219487038437,
      "grad_norm": 0.18499217927455902,
      "learning_rate": 2.6974917049185965e-05,
      "loss": 0.035,
      "step": 53600
    },
    {
      "epoch": 3.692498109055903,
      "grad_norm": 0.2675955891609192,
      "learning_rate": 2.693193735279454e-05,
      "loss": 0.0348,
      "step": 53700
    },
    {
      "epoch": 3.6993742694079623,
      "grad_norm": 0.20632390677928925,
      "learning_rate": 2.688895765640312e-05,
      "loss": 0.0361,
      "step": 53800
    },
    {
      "epoch": 3.706250429760022,
      "grad_norm": 0.19970987737178802,
      "learning_rate": 2.6845977960011693e-05,
      "loss": 0.0355,
      "step": 53900
    },
    {
      "epoch": 3.7131265901120813,
      "grad_norm": 0.15861769020557404,
      "learning_rate": 2.6802998263620267e-05,
      "loss": 0.0364,
      "step": 54000
    },
    {
      "epoch": 3.7200027504641406,
      "grad_norm": 0.15536567568778992,
      "learning_rate": 2.6760018567228844e-05,
      "loss": 0.0347,
      "step": 54100
    },
    {
      "epoch": 3.7268789108162004,
      "grad_norm": 0.16025663912296295,
      "learning_rate": 2.6717038870837418e-05,
      "loss": 0.0331,
      "step": 54200
    },
    {
      "epoch": 3.7337550711682597,
      "grad_norm": 0.11350789666175842,
      "learning_rate": 2.6674059174445992e-05,
      "loss": 0.0357,
      "step": 54300
    },
    {
      "epoch": 3.740631231520319,
      "grad_norm": 0.2517392337322235,
      "learning_rate": 2.6631079478054566e-05,
      "loss": 0.0342,
      "step": 54400
    },
    {
      "epoch": 3.7475073918723787,
      "grad_norm": 0.08815344423055649,
      "learning_rate": 2.6588099781663143e-05,
      "loss": 0.0363,
      "step": 54500
    },
    {
      "epoch": 3.754383552224438,
      "grad_norm": 0.10793463885784149,
      "learning_rate": 2.6545120085271717e-05,
      "loss": 0.035,
      "step": 54600
    },
    {
      "epoch": 3.7612597125764973,
      "grad_norm": 0.2670855224132538,
      "learning_rate": 2.650214038888029e-05,
      "loss": 0.0352,
      "step": 54700
    },
    {
      "epoch": 3.7681358729285566,
      "grad_norm": 0.09153133630752563,
      "learning_rate": 2.6459160692488872e-05,
      "loss": 0.0347,
      "step": 54800
    },
    {
      "epoch": 3.775012033280616,
      "grad_norm": 0.17433875799179077,
      "learning_rate": 2.6416180996097446e-05,
      "loss": 0.0324,
      "step": 54900
    },
    {
      "epoch": 3.7818881936326756,
      "grad_norm": 0.18446792662143707,
      "learning_rate": 2.637320129970602e-05,
      "loss": 0.0359,
      "step": 55000
    },
    {
      "epoch": 3.788764353984735,
      "grad_norm": 0.04157065972685814,
      "learning_rate": 2.6330221603314597e-05,
      "loss": 0.034,
      "step": 55100
    },
    {
      "epoch": 3.795640514336794,
      "grad_norm": 0.09830840677022934,
      "learning_rate": 2.628724190692317e-05,
      "loss": 0.0353,
      "step": 55200
    },
    {
      "epoch": 3.802516674688854,
      "grad_norm": 0.1499682068824768,
      "learning_rate": 2.6244262210531745e-05,
      "loss": 0.034,
      "step": 55300
    },
    {
      "epoch": 3.809392835040913,
      "grad_norm": 0.2132674902677536,
      "learning_rate": 2.6201282514140325e-05,
      "loss": 0.0371,
      "step": 55400
    },
    {
      "epoch": 3.8162689953929725,
      "grad_norm": 0.21068443357944489,
      "learning_rate": 2.6158302817748896e-05,
      "loss": 0.0361,
      "step": 55500
    },
    {
      "epoch": 3.823145155745032,
      "grad_norm": 0.20186187326908112,
      "learning_rate": 2.611532312135747e-05,
      "loss": 0.0367,
      "step": 55600
    },
    {
      "epoch": 3.8300213160970915,
      "grad_norm": 0.16098666191101074,
      "learning_rate": 2.6072343424966044e-05,
      "loss": 0.0343,
      "step": 55700
    },
    {
      "epoch": 3.836897476449151,
      "grad_norm": 0.17592322826385498,
      "learning_rate": 2.6029363728574625e-05,
      "loss": 0.032,
      "step": 55800
    },
    {
      "epoch": 3.84377363680121,
      "grad_norm": 0.14515142142772675,
      "learning_rate": 2.59863840321832e-05,
      "loss": 0.0327,
      "step": 55900
    },
    {
      "epoch": 3.8506497971532694,
      "grad_norm": 0.11591381579637527,
      "learning_rate": 2.5943404335791772e-05,
      "loss": 0.0344,
      "step": 56000
    },
    {
      "epoch": 3.857525957505329,
      "grad_norm": 0.24588608741760254,
      "learning_rate": 2.590042463940035e-05,
      "loss": 0.0353,
      "step": 56100
    },
    {
      "epoch": 3.8644021178573884,
      "grad_norm": 0.18000471591949463,
      "learning_rate": 2.5857444943008924e-05,
      "loss": 0.0367,
      "step": 56200
    },
    {
      "epoch": 3.8712782782094477,
      "grad_norm": 0.11948543787002563,
      "learning_rate": 2.5814465246617497e-05,
      "loss": 0.0356,
      "step": 56300
    },
    {
      "epoch": 3.8781544385615074,
      "grad_norm": 0.149010568857193,
      "learning_rate": 2.5771485550226078e-05,
      "loss": 0.034,
      "step": 56400
    },
    {
      "epoch": 3.8850305989135667,
      "grad_norm": 0.26101839542388916,
      "learning_rate": 2.572850585383465e-05,
      "loss": 0.0327,
      "step": 56500
    },
    {
      "epoch": 3.891906759265626,
      "grad_norm": 0.20629245042800903,
      "learning_rate": 2.5685526157443223e-05,
      "loss": 0.035,
      "step": 56600
    },
    {
      "epoch": 3.8987829196176857,
      "grad_norm": 0.11930975317955017,
      "learning_rate": 2.5642546461051803e-05,
      "loss": 0.0352,
      "step": 56700
    },
    {
      "epoch": 3.905659079969745,
      "grad_norm": 0.15061315894126892,
      "learning_rate": 2.5599566764660377e-05,
      "loss": 0.0375,
      "step": 56800
    },
    {
      "epoch": 3.9125352403218043,
      "grad_norm": 0.2577289342880249,
      "learning_rate": 2.555658706826895e-05,
      "loss": 0.0385,
      "step": 56900
    },
    {
      "epoch": 3.9194114006738636,
      "grad_norm": 0.1428958624601364,
      "learning_rate": 2.5513607371877525e-05,
      "loss": 0.0314,
      "step": 57000
    },
    {
      "epoch": 3.926287561025923,
      "grad_norm": 0.18970373272895813,
      "learning_rate": 2.5470627675486102e-05,
      "loss": 0.0349,
      "step": 57100
    },
    {
      "epoch": 3.9331637213779826,
      "grad_norm": 0.22370193898677826,
      "learning_rate": 2.5427647979094676e-05,
      "loss": 0.0349,
      "step": 57200
    },
    {
      "epoch": 3.940039881730042,
      "grad_norm": 0.3441774249076843,
      "learning_rate": 2.538466828270325e-05,
      "loss": 0.0342,
      "step": 57300
    },
    {
      "epoch": 3.9469160420821012,
      "grad_norm": 0.1412924975156784,
      "learning_rate": 2.534168858631183e-05,
      "loss": 0.0335,
      "step": 57400
    },
    {
      "epoch": 3.953792202434161,
      "grad_norm": 0.19929809868335724,
      "learning_rate": 2.52987088899204e-05,
      "loss": 0.0335,
      "step": 57500
    },
    {
      "epoch": 3.9606683627862203,
      "grad_norm": 0.20979627966880798,
      "learning_rate": 2.5255729193528975e-05,
      "loss": 0.033,
      "step": 57600
    },
    {
      "epoch": 3.9675445231382795,
      "grad_norm": 0.2500518262386322,
      "learning_rate": 2.5212749497137556e-05,
      "loss": 0.0344,
      "step": 57700
    },
    {
      "epoch": 3.974420683490339,
      "grad_norm": 0.286241352558136,
      "learning_rate": 2.516976980074613e-05,
      "loss": 0.0353,
      "step": 57800
    },
    {
      "epoch": 3.9812968438423986,
      "grad_norm": 0.21895383298397064,
      "learning_rate": 2.5126790104354704e-05,
      "loss": 0.0321,
      "step": 57900
    },
    {
      "epoch": 3.988173004194458,
      "grad_norm": 0.1841808259487152,
      "learning_rate": 2.508381040796328e-05,
      "loss": 0.0325,
      "step": 58000
    },
    {
      "epoch": 3.995049164546517,
      "grad_norm": 0.2521754205226898,
      "learning_rate": 2.5040830711571855e-05,
      "loss": 0.0361,
      "step": 58100
    },
    {
      "epoch": 4.0,
      "eval_accuracy_macro_0.5": 0.9839030504226685,
      "eval_accuracy_micro_0.5": 0.9839031100273132,
      "eval_accuracy_weighted_0.5": 0.9816370010375977,
      "eval_f1_macro_0.5": 0.7927306294441223,
      "eval_f1_macro_0.6": 0.780267596244812,
      "eval_f1_macro_0.7": 0.7551068067550659,
      "eval_f1_macro_0.8": 0.6139432787895203,
      "eval_f1_micro_0.5": 0.7907087206840515,
      "eval_f1_micro_0.6": 0.7805781960487366,
      "eval_f1_micro_0.7": 0.7592756152153015,
      "eval_f1_micro_0.8": 0.7189017534255981,
      "eval_f1_micro_0.9": 0.6315200328826904,
      "eval_f1_weighted_0.5": 0.7866448163986206,
      "eval_f1_weighted_0.6": 0.7733427286148071,
      "eval_f1_weighted_0.7": 0.7475390434265137,
      "eval_f1_weighted_0.8": 0.6014272570610046,
      "eval_loss": 0.0331142395734787,
      "eval_runtime": 133.4816,
      "eval_samples_per_second": 217.536,
      "eval_steps_per_second": 27.195,
      "step": 58172
    },
    {
      "epoch": 4.001925324898576,
      "grad_norm": 0.16634972393512726,
      "learning_rate": 2.499785101518043e-05,
      "loss": 0.0364,
      "step": 58200
    },
    {
      "epoch": 4.008801485250636,
      "grad_norm": 0.1779119372367859,
      "learning_rate": 2.4954871318789006e-05,
      "loss": 0.0342,
      "step": 58300
    },
    {
      "epoch": 4.015677645602695,
      "grad_norm": 0.16908295452594757,
      "learning_rate": 2.4911891622397583e-05,
      "loss": 0.0346,
      "step": 58400
    },
    {
      "epoch": 4.022553805954755,
      "grad_norm": 0.24002386629581451,
      "learning_rate": 2.4868911926006154e-05,
      "loss": 0.038,
      "step": 58500
    },
    {
      "epoch": 4.0294299663068145,
      "grad_norm": 0.1665738821029663,
      "learning_rate": 2.4826362026578646e-05,
      "loss": 0.0304,
      "step": 58600
    },
    {
      "epoch": 4.036306126658873,
      "grad_norm": 0.22020317614078522,
      "learning_rate": 2.478338233018722e-05,
      "loss": 0.0341,
      "step": 58700
    },
    {
      "epoch": 4.043182287010933,
      "grad_norm": 0.180162712931633,
      "learning_rate": 2.4740402633795794e-05,
      "loss": 0.0346,
      "step": 58800
    },
    {
      "epoch": 4.050058447362993,
      "grad_norm": 0.12116554379463196,
      "learning_rate": 2.469742293740437e-05,
      "loss": 0.0333,
      "step": 58900
    },
    {
      "epoch": 4.056934607715052,
      "grad_norm": 0.14088009297847748,
      "learning_rate": 2.465444324101295e-05,
      "loss": 0.0344,
      "step": 59000
    },
    {
      "epoch": 4.063810768067111,
      "grad_norm": 0.1925506591796875,
      "learning_rate": 2.4611463544621523e-05,
      "loss": 0.0345,
      "step": 59100
    },
    {
      "epoch": 4.070686928419171,
      "grad_norm": 0.20548906922340393,
      "learning_rate": 2.4568483848230097e-05,
      "loss": 0.0341,
      "step": 59200
    },
    {
      "epoch": 4.07756308877123,
      "grad_norm": 0.3353140950202942,
      "learning_rate": 2.452550415183867e-05,
      "loss": 0.0344,
      "step": 59300
    },
    {
      "epoch": 4.08443924912329,
      "grad_norm": 0.15389592945575714,
      "learning_rate": 2.4482524455447248e-05,
      "loss": 0.034,
      "step": 59400
    },
    {
      "epoch": 4.0913154094753486,
      "grad_norm": 0.16656740009784698,
      "learning_rate": 2.4439544759055825e-05,
      "loss": 0.0325,
      "step": 59500
    },
    {
      "epoch": 4.098191569827408,
      "grad_norm": 0.04877224937081337,
      "learning_rate": 2.43965650626644e-05,
      "loss": 0.0366,
      "step": 59600
    },
    {
      "epoch": 4.105067730179468,
      "grad_norm": 0.15091627836227417,
      "learning_rate": 2.4353585366272973e-05,
      "loss": 0.033,
      "step": 59700
    },
    {
      "epoch": 4.111943890531527,
      "grad_norm": 0.1737847477197647,
      "learning_rate": 2.431060566988155e-05,
      "loss": 0.0344,
      "step": 59800
    },
    {
      "epoch": 4.118820050883587,
      "grad_norm": 0.11119135469198227,
      "learning_rate": 2.4267625973490124e-05,
      "loss": 0.0354,
      "step": 59900
    },
    {
      "epoch": 4.125696211235646,
      "grad_norm": 0.13122695684432983,
      "learning_rate": 2.42246462770987e-05,
      "loss": 0.0341,
      "step": 60000
    },
    {
      "epoch": 4.132572371587705,
      "grad_norm": 0.19072985649108887,
      "learning_rate": 2.4181666580707275e-05,
      "loss": 0.0332,
      "step": 60100
    },
    {
      "epoch": 4.139448531939765,
      "grad_norm": 0.18625837564468384,
      "learning_rate": 2.413868688431585e-05,
      "loss": 0.0308,
      "step": 60200
    },
    {
      "epoch": 4.146324692291825,
      "grad_norm": 0.15569497644901276,
      "learning_rate": 2.4095707187924427e-05,
      "loss": 0.0328,
      "step": 60300
    },
    {
      "epoch": 4.1532008526438835,
      "grad_norm": 0.24422670900821686,
      "learning_rate": 2.4052727491533e-05,
      "loss": 0.035,
      "step": 60400
    },
    {
      "epoch": 4.160077012995943,
      "grad_norm": 0.14220109581947327,
      "learning_rate": 2.4009747795141578e-05,
      "loss": 0.0343,
      "step": 60500
    },
    {
      "epoch": 4.166953173348002,
      "grad_norm": 0.15838149189949036,
      "learning_rate": 2.3966768098750152e-05,
      "loss": 0.0342,
      "step": 60600
    },
    {
      "epoch": 4.173829333700062,
      "grad_norm": 0.17484158277511597,
      "learning_rate": 2.3923788402358726e-05,
      "loss": 0.0306,
      "step": 60700
    },
    {
      "epoch": 4.1807054940521216,
      "grad_norm": 0.2378147393465042,
      "learning_rate": 2.3880808705967303e-05,
      "loss": 0.0341,
      "step": 60800
    },
    {
      "epoch": 4.18758165440418,
      "grad_norm": 0.1355435997247696,
      "learning_rate": 2.3837829009575877e-05,
      "loss": 0.035,
      "step": 60900
    },
    {
      "epoch": 4.19445781475624,
      "grad_norm": 0.1766427606344223,
      "learning_rate": 2.3794849313184454e-05,
      "loss": 0.0337,
      "step": 61000
    },
    {
      "epoch": 4.2013339751083,
      "grad_norm": 0.17310017347335815,
      "learning_rate": 2.3751869616793028e-05,
      "loss": 0.0341,
      "step": 61100
    },
    {
      "epoch": 4.208210135460359,
      "grad_norm": 0.23087751865386963,
      "learning_rate": 2.3708889920401602e-05,
      "loss": 0.0333,
      "step": 61200
    },
    {
      "epoch": 4.2150862958124184,
      "grad_norm": 0.22529691457748413,
      "learning_rate": 2.366591022401018e-05,
      "loss": 0.0324,
      "step": 61300
    },
    {
      "epoch": 4.221962456164478,
      "grad_norm": 0.16079062223434448,
      "learning_rate": 2.3622930527618753e-05,
      "loss": 0.033,
      "step": 61400
    },
    {
      "epoch": 4.228838616516537,
      "grad_norm": 0.19467121362686157,
      "learning_rate": 2.357995083122733e-05,
      "loss": 0.0322,
      "step": 61500
    },
    {
      "epoch": 4.235714776868597,
      "grad_norm": 0.18265828490257263,
      "learning_rate": 2.353740093179982e-05,
      "loss": 0.0363,
      "step": 61600
    },
    {
      "epoch": 4.242590937220656,
      "grad_norm": 0.16657397150993347,
      "learning_rate": 2.3494421235408397e-05,
      "loss": 0.0359,
      "step": 61700
    },
    {
      "epoch": 4.249467097572715,
      "grad_norm": 0.3071703016757965,
      "learning_rate": 2.3451441539016967e-05,
      "loss": 0.0328,
      "step": 61800
    },
    {
      "epoch": 4.256343257924775,
      "grad_norm": 0.22465430200099945,
      "learning_rate": 2.3408461842625545e-05,
      "loss": 0.0326,
      "step": 61900
    },
    {
      "epoch": 4.263219418276834,
      "grad_norm": 0.2727764844894409,
      "learning_rate": 2.336548214623412e-05,
      "loss": 0.0366,
      "step": 62000
    },
    {
      "epoch": 4.270095578628894,
      "grad_norm": 0.30492982268333435,
      "learning_rate": 2.3322502449842696e-05,
      "loss": 0.0346,
      "step": 62100
    },
    {
      "epoch": 4.276971738980953,
      "grad_norm": 0.13709859549999237,
      "learning_rate": 2.3279522753451273e-05,
      "loss": 0.0321,
      "step": 62200
    },
    {
      "epoch": 4.283847899333012,
      "grad_norm": 0.15165312588214874,
      "learning_rate": 2.3236543057059844e-05,
      "loss": 0.0356,
      "step": 62300
    },
    {
      "epoch": 4.290724059685072,
      "grad_norm": 0.259950190782547,
      "learning_rate": 2.319356336066842e-05,
      "loss": 0.0338,
      "step": 62400
    },
    {
      "epoch": 4.297600220037131,
      "grad_norm": 0.2972570061683655,
      "learning_rate": 2.3150583664277e-05,
      "loss": 0.0326,
      "step": 62500
    },
    {
      "epoch": 4.304476380389191,
      "grad_norm": 0.3157096207141876,
      "learning_rate": 2.3107603967885572e-05,
      "loss": 0.0356,
      "step": 62600
    },
    {
      "epoch": 4.31135254074125,
      "grad_norm": 0.2628950774669647,
      "learning_rate": 2.306462427149415e-05,
      "loss": 0.0335,
      "step": 62700
    },
    {
      "epoch": 4.318228701093309,
      "grad_norm": 0.24981237947940826,
      "learning_rate": 2.302164457510272e-05,
      "loss": 0.0331,
      "step": 62800
    },
    {
      "epoch": 4.325104861445369,
      "grad_norm": 0.15988337993621826,
      "learning_rate": 2.2978664878711297e-05,
      "loss": 0.0332,
      "step": 62900
    },
    {
      "epoch": 4.331981021797429,
      "grad_norm": 0.25509384274482727,
      "learning_rate": 2.2935685182319875e-05,
      "loss": 0.0352,
      "step": 63000
    },
    {
      "epoch": 4.3388571821494875,
      "grad_norm": 0.13038043677806854,
      "learning_rate": 2.289270548592845e-05,
      "loss": 0.0328,
      "step": 63100
    },
    {
      "epoch": 4.345733342501547,
      "grad_norm": 0.20825925469398499,
      "learning_rate": 2.2849725789537026e-05,
      "loss": 0.0345,
      "step": 63200
    },
    {
      "epoch": 4.352609502853607,
      "grad_norm": 0.12585848569869995,
      "learning_rate": 2.2806746093145596e-05,
      "loss": 0.0312,
      "step": 63300
    },
    {
      "epoch": 4.359485663205666,
      "grad_norm": 0.22420699894428253,
      "learning_rate": 2.2763766396754174e-05,
      "loss": 0.0345,
      "step": 63400
    },
    {
      "epoch": 4.3663618235577255,
      "grad_norm": 0.2166382521390915,
      "learning_rate": 2.272078670036275e-05,
      "loss": 0.0339,
      "step": 63500
    },
    {
      "epoch": 4.373237983909785,
      "grad_norm": 0.18832392990589142,
      "learning_rate": 2.2677807003971325e-05,
      "loss": 0.0362,
      "step": 63600
    },
    {
      "epoch": 4.380114144261844,
      "grad_norm": 0.1473868489265442,
      "learning_rate": 2.2635257104543814e-05,
      "loss": 0.0373,
      "step": 63700
    },
    {
      "epoch": 4.386990304613904,
      "grad_norm": 0.32521235942840576,
      "learning_rate": 2.259227740815239e-05,
      "loss": 0.0341,
      "step": 63800
    },
    {
      "epoch": 4.393866464965963,
      "grad_norm": 0.1764564961194992,
      "learning_rate": 2.2549297711760965e-05,
      "loss": 0.0336,
      "step": 63900
    },
    {
      "epoch": 4.400742625318022,
      "grad_norm": 0.2513299882411957,
      "learning_rate": 2.250631801536954e-05,
      "loss": 0.032,
      "step": 64000
    },
    {
      "epoch": 4.407618785670082,
      "grad_norm": 0.19319283962249756,
      "learning_rate": 2.2463338318978116e-05,
      "loss": 0.0324,
      "step": 64100
    },
    {
      "epoch": 4.414494946022141,
      "grad_norm": 0.1150578111410141,
      "learning_rate": 2.242035862258669e-05,
      "loss": 0.0335,
      "step": 64200
    },
    {
      "epoch": 4.421371106374201,
      "grad_norm": 0.17555467784404755,
      "learning_rate": 2.2377378926195268e-05,
      "loss": 0.0353,
      "step": 64300
    },
    {
      "epoch": 4.4282472667262605,
      "grad_norm": 0.2664862871170044,
      "learning_rate": 2.233439922980384e-05,
      "loss": 0.0342,
      "step": 64400
    },
    {
      "epoch": 4.435123427078319,
      "grad_norm": 0.18321943283081055,
      "learning_rate": 2.2291419533412415e-05,
      "loss": 0.0333,
      "step": 64500
    },
    {
      "epoch": 4.441999587430379,
      "grad_norm": 0.17240889370441437,
      "learning_rate": 2.2248439837020993e-05,
      "loss": 0.0326,
      "step": 64600
    },
    {
      "epoch": 4.448875747782438,
      "grad_norm": 0.24010415375232697,
      "learning_rate": 2.2205460140629567e-05,
      "loss": 0.0328,
      "step": 64700
    },
    {
      "epoch": 4.455751908134498,
      "grad_norm": 0.25030821561813354,
      "learning_rate": 2.2162480444238144e-05,
      "loss": 0.0335,
      "step": 64800
    },
    {
      "epoch": 4.462628068486557,
      "grad_norm": 0.08662763237953186,
      "learning_rate": 2.2119500747846718e-05,
      "loss": 0.0338,
      "step": 64900
    },
    {
      "epoch": 4.469504228838616,
      "grad_norm": 0.15883445739746094,
      "learning_rate": 2.2076521051455292e-05,
      "loss": 0.0324,
      "step": 65000
    },
    {
      "epoch": 4.476380389190676,
      "grad_norm": 0.21665635704994202,
      "learning_rate": 2.203354135506387e-05,
      "loss": 0.0347,
      "step": 65100
    },
    {
      "epoch": 4.483256549542736,
      "grad_norm": 0.18756438791751862,
      "learning_rate": 2.1990561658672446e-05,
      "loss": 0.0351,
      "step": 65200
    },
    {
      "epoch": 4.4901327098947945,
      "grad_norm": 0.20959816873073578,
      "learning_rate": 2.194758196228102e-05,
      "loss": 0.0341,
      "step": 65300
    },
    {
      "epoch": 4.497008870246854,
      "grad_norm": 0.1733372062444687,
      "learning_rate": 2.1904602265889594e-05,
      "loss": 0.0324,
      "step": 65400
    },
    {
      "epoch": 4.503885030598914,
      "grad_norm": 0.18947091698646545,
      "learning_rate": 2.1861622569498168e-05,
      "loss": 0.0323,
      "step": 65500
    },
    {
      "epoch": 4.510761190950973,
      "grad_norm": 0.20746055245399475,
      "learning_rate": 2.1818642873106745e-05,
      "loss": 0.033,
      "step": 65600
    },
    {
      "epoch": 4.517637351303033,
      "grad_norm": 0.15529808402061462,
      "learning_rate": 2.1775663176715323e-05,
      "loss": 0.0329,
      "step": 65700
    },
    {
      "epoch": 4.524513511655091,
      "grad_norm": 0.1795995682477951,
      "learning_rate": 2.1732683480323897e-05,
      "loss": 0.0322,
      "step": 65800
    },
    {
      "epoch": 4.531389672007151,
      "grad_norm": 0.096605584025383,
      "learning_rate": 2.168970378393247e-05,
      "loss": 0.0311,
      "step": 65900
    },
    {
      "epoch": 4.538265832359211,
      "grad_norm": 0.06841831654310226,
      "learning_rate": 2.1646724087541044e-05,
      "loss": 0.0298,
      "step": 66000
    },
    {
      "epoch": 4.54514199271127,
      "grad_norm": 0.23933468759059906,
      "learning_rate": 2.1603744391149622e-05,
      "loss": 0.0345,
      "step": 66100
    },
    {
      "epoch": 4.5520181530633295,
      "grad_norm": 0.20389559864997864,
      "learning_rate": 2.15607646947582e-05,
      "loss": 0.0366,
      "step": 66200
    },
    {
      "epoch": 4.558894313415389,
      "grad_norm": 0.1460561901330948,
      "learning_rate": 2.1517784998366773e-05,
      "loss": 0.0336,
      "step": 66300
    },
    {
      "epoch": 4.565770473767448,
      "grad_norm": 0.2283129096031189,
      "learning_rate": 2.1474805301975347e-05,
      "loss": 0.0333,
      "step": 66400
    },
    {
      "epoch": 4.572646634119508,
      "grad_norm": 0.2160114347934723,
      "learning_rate": 2.1431825605583924e-05,
      "loss": 0.034,
      "step": 66500
    },
    {
      "epoch": 4.579522794471567,
      "grad_norm": 0.1254139244556427,
      "learning_rate": 2.1388845909192498e-05,
      "loss": 0.0302,
      "step": 66600
    },
    {
      "epoch": 4.586398954823626,
      "grad_norm": 0.27571022510528564,
      "learning_rate": 2.1346296009764987e-05,
      "loss": 0.0323,
      "step": 66700
    },
    {
      "epoch": 4.593275115175686,
      "grad_norm": 0.17989777028560638,
      "learning_rate": 2.1303316313373564e-05,
      "loss": 0.0349,
      "step": 66800
    },
    {
      "epoch": 4.600151275527745,
      "grad_norm": 0.24338969588279724,
      "learning_rate": 2.126033661698214e-05,
      "loss": 0.032,
      "step": 66900
    },
    {
      "epoch": 4.607027435879805,
      "grad_norm": 0.33032333850860596,
      "learning_rate": 2.1217356920590716e-05,
      "loss": 0.0334,
      "step": 67000
    },
    {
      "epoch": 4.613903596231864,
      "grad_norm": 0.14527779817581177,
      "learning_rate": 2.117437722419929e-05,
      "loss": 0.0349,
      "step": 67100
    },
    {
      "epoch": 4.620779756583923,
      "grad_norm": 0.2987152636051178,
      "learning_rate": 2.1131397527807863e-05,
      "loss": 0.0327,
      "step": 67200
    },
    {
      "epoch": 4.627655916935983,
      "grad_norm": 0.20809818804264069,
      "learning_rate": 2.108841783141644e-05,
      "loss": 0.0338,
      "step": 67300
    },
    {
      "epoch": 4.634532077288043,
      "grad_norm": 0.2110910415649414,
      "learning_rate": 2.1045438135025015e-05,
      "loss": 0.0347,
      "step": 67400
    },
    {
      "epoch": 4.641408237640102,
      "grad_norm": 0.15356822311878204,
      "learning_rate": 2.1002458438633592e-05,
      "loss": 0.0323,
      "step": 67500
    },
    {
      "epoch": 4.648284397992161,
      "grad_norm": 0.19312776625156403,
      "learning_rate": 2.0959478742242166e-05,
      "loss": 0.0328,
      "step": 67600
    },
    {
      "epoch": 4.655160558344221,
      "grad_norm": 0.182016059756279,
      "learning_rate": 2.091649904585074e-05,
      "loss": 0.0329,
      "step": 67700
    },
    {
      "epoch": 4.66203671869628,
      "grad_norm": 0.10674513876438141,
      "learning_rate": 2.0873519349459317e-05,
      "loss": 0.0328,
      "step": 67800
    },
    {
      "epoch": 4.66891287904834,
      "grad_norm": 0.26164349913597107,
      "learning_rate": 2.083053965306789e-05,
      "loss": 0.0338,
      "step": 67900
    },
    {
      "epoch": 4.6757890394003985,
      "grad_norm": 0.15075509250164032,
      "learning_rate": 2.0787559956676468e-05,
      "loss": 0.0339,
      "step": 68000
    },
    {
      "epoch": 4.682665199752458,
      "grad_norm": 0.18562887609004974,
      "learning_rate": 2.0744580260285042e-05,
      "loss": 0.0342,
      "step": 68100
    },
    {
      "epoch": 4.689541360104518,
      "grad_norm": 0.1674683392047882,
      "learning_rate": 2.0701600563893616e-05,
      "loss": 0.0318,
      "step": 68200
    },
    {
      "epoch": 4.696417520456577,
      "grad_norm": 0.16726677119731903,
      "learning_rate": 2.0658620867502193e-05,
      "loss": 0.0319,
      "step": 68300
    },
    {
      "epoch": 4.7032936808086365,
      "grad_norm": 0.13703104853630066,
      "learning_rate": 2.061564117111077e-05,
      "loss": 0.0351,
      "step": 68400
    },
    {
      "epoch": 4.710169841160695,
      "grad_norm": 0.2282876819372177,
      "learning_rate": 2.0572661474719345e-05,
      "loss": 0.0346,
      "step": 68500
    },
    {
      "epoch": 4.717046001512755,
      "grad_norm": 0.14625364542007446,
      "learning_rate": 2.052968177832792e-05,
      "loss": 0.0327,
      "step": 68600
    },
    {
      "epoch": 4.723922161864815,
      "grad_norm": 0.17534755170345306,
      "learning_rate": 2.0486702081936492e-05,
      "loss": 0.0331,
      "step": 68700
    },
    {
      "epoch": 4.730798322216874,
      "grad_norm": 0.11700695008039474,
      "learning_rate": 2.044372238554507e-05,
      "loss": 0.0306,
      "step": 68800
    },
    {
      "epoch": 4.737674482568933,
      "grad_norm": 0.24187199771404266,
      "learning_rate": 2.0400742689153647e-05,
      "loss": 0.0317,
      "step": 68900
    },
    {
      "epoch": 4.744550642920993,
      "grad_norm": 0.14506179094314575,
      "learning_rate": 2.035776299276222e-05,
      "loss": 0.0322,
      "step": 69000
    },
    {
      "epoch": 4.751426803273052,
      "grad_norm": 0.16655083000659943,
      "learning_rate": 2.0314783296370795e-05,
      "loss": 0.0341,
      "step": 69100
    },
    {
      "epoch": 4.758302963625112,
      "grad_norm": 0.09174799919128418,
      "learning_rate": 2.0271803599979372e-05,
      "loss": 0.0338,
      "step": 69200
    },
    {
      "epoch": 4.7651791239771715,
      "grad_norm": 0.2631629407405853,
      "learning_rate": 2.0229253700551858e-05,
      "loss": 0.0331,
      "step": 69300
    },
    {
      "epoch": 4.77205528432923,
      "grad_norm": 0.14904376864433289,
      "learning_rate": 2.0186274004160435e-05,
      "loss": 0.0324,
      "step": 69400
    },
    {
      "epoch": 4.77893144468129,
      "grad_norm": 0.12289803475141525,
      "learning_rate": 2.0143294307769012e-05,
      "loss": 0.0339,
      "step": 69500
    },
    {
      "epoch": 4.78580760503335,
      "grad_norm": 0.07240503281354904,
      "learning_rate": 2.0100314611377586e-05,
      "loss": 0.0318,
      "step": 69600
    },
    {
      "epoch": 4.792683765385409,
      "grad_norm": 0.24696965515613556,
      "learning_rate": 2.005733491498616e-05,
      "loss": 0.0356,
      "step": 69700
    },
    {
      "epoch": 4.799559925737468,
      "grad_norm": 0.28306111693382263,
      "learning_rate": 2.0014355218594738e-05,
      "loss": 0.0308,
      "step": 69800
    },
    {
      "epoch": 4.806436086089528,
      "grad_norm": 0.19225898385047913,
      "learning_rate": 1.997137552220331e-05,
      "loss": 0.0353,
      "step": 69900
    },
    {
      "epoch": 4.813312246441587,
      "grad_norm": 0.1466844230890274,
      "learning_rate": 1.992839582581189e-05,
      "loss": 0.0347,
      "step": 70000
    },
    {
      "epoch": 4.820188406793647,
      "grad_norm": 0.19586028158664703,
      "learning_rate": 1.9885416129420463e-05,
      "loss": 0.0328,
      "step": 70100
    },
    {
      "epoch": 4.8270645671457055,
      "grad_norm": 0.26472407579421997,
      "learning_rate": 1.9842436433029037e-05,
      "loss": 0.0351,
      "step": 70200
    },
    {
      "epoch": 4.833940727497765,
      "grad_norm": 0.10166449844837189,
      "learning_rate": 1.9799456736637614e-05,
      "loss": 0.0342,
      "step": 70300
    },
    {
      "epoch": 4.840816887849825,
      "grad_norm": 0.18833179771900177,
      "learning_rate": 1.9756477040246188e-05,
      "loss": 0.0317,
      "step": 70400
    },
    {
      "epoch": 4.847693048201884,
      "grad_norm": 0.31485891342163086,
      "learning_rate": 1.9713497343854765e-05,
      "loss": 0.0373,
      "step": 70500
    },
    {
      "epoch": 4.854569208553944,
      "grad_norm": 0.15536817908287048,
      "learning_rate": 1.967051764746334e-05,
      "loss": 0.0378,
      "step": 70600
    },
    {
      "epoch": 4.861445368906002,
      "grad_norm": 0.1345825344324112,
      "learning_rate": 1.9627537951071913e-05,
      "loss": 0.0334,
      "step": 70700
    },
    {
      "epoch": 4.868321529258062,
      "grad_norm": 0.161643847823143,
      "learning_rate": 1.958455825468049e-05,
      "loss": 0.0303,
      "step": 70800
    },
    {
      "epoch": 4.875197689610122,
      "grad_norm": 0.21037882566452026,
      "learning_rate": 1.9541578558289064e-05,
      "loss": 0.0335,
      "step": 70900
    },
    {
      "epoch": 4.882073849962181,
      "grad_norm": 0.18031510710716248,
      "learning_rate": 1.949859886189764e-05,
      "loss": 0.0373,
      "step": 71000
    },
    {
      "epoch": 4.8889500103142405,
      "grad_norm": 0.14869803190231323,
      "learning_rate": 1.9455619165506215e-05,
      "loss": 0.0317,
      "step": 71100
    },
    {
      "epoch": 4.8958261706663,
      "grad_norm": 0.18262071907520294,
      "learning_rate": 1.9413069266078708e-05,
      "loss": 0.0352,
      "step": 71200
    },
    {
      "epoch": 4.902702331018359,
      "grad_norm": 0.2040647268295288,
      "learning_rate": 1.9370089569687282e-05,
      "loss": 0.0363,
      "step": 71300
    },
    {
      "epoch": 4.909578491370419,
      "grad_norm": 0.1204870268702507,
      "learning_rate": 1.9327109873295856e-05,
      "loss": 0.0325,
      "step": 71400
    },
    {
      "epoch": 4.9164546517224785,
      "grad_norm": 0.12457379698753357,
      "learning_rate": 1.928413017690443e-05,
      "loss": 0.0336,
      "step": 71500
    },
    {
      "epoch": 4.923330812074537,
      "grad_norm": 0.16600170731544495,
      "learning_rate": 1.9241150480513007e-05,
      "loss": 0.0364,
      "step": 71600
    },
    {
      "epoch": 4.930206972426597,
      "grad_norm": 0.16359427571296692,
      "learning_rate": 1.9198170784121584e-05,
      "loss": 0.0372,
      "step": 71700
    },
    {
      "epoch": 4.937083132778657,
      "grad_norm": 0.2004282921552658,
      "learning_rate": 1.9155191087730158e-05,
      "loss": 0.0342,
      "step": 71800
    },
    {
      "epoch": 4.943959293130716,
      "grad_norm": 0.2566646933555603,
      "learning_rate": 1.9112211391338732e-05,
      "loss": 0.034,
      "step": 71900
    },
    {
      "epoch": 4.950835453482775,
      "grad_norm": 0.1521938443183899,
      "learning_rate": 1.9069231694947306e-05,
      "loss": 0.0319,
      "step": 72000
    },
    {
      "epoch": 4.957711613834834,
      "grad_norm": 0.2246682494878769,
      "learning_rate": 1.9026251998555883e-05,
      "loss": 0.0317,
      "step": 72100
    },
    {
      "epoch": 4.964587774186894,
      "grad_norm": 0.26702502369880676,
      "learning_rate": 1.898327230216446e-05,
      "loss": 0.0339,
      "step": 72200
    },
    {
      "epoch": 4.971463934538954,
      "grad_norm": 0.1262054145336151,
      "learning_rate": 1.8940292605773034e-05,
      "loss": 0.0312,
      "step": 72300
    },
    {
      "epoch": 4.978340094891013,
      "grad_norm": 0.36919355392456055,
      "learning_rate": 1.8897312909381608e-05,
      "loss": 0.0327,
      "step": 72400
    },
    {
      "epoch": 4.985216255243072,
      "grad_norm": 0.2907280921936035,
      "learning_rate": 1.8854333212990186e-05,
      "loss": 0.0356,
      "step": 72500
    },
    {
      "epoch": 4.992092415595132,
      "grad_norm": 0.13561569154262543,
      "learning_rate": 1.881135351659876e-05,
      "loss": 0.0326,
      "step": 72600
    },
    {
      "epoch": 4.998968575947191,
      "grad_norm": 0.30514904856681824,
      "learning_rate": 1.8768373820207337e-05,
      "loss": 0.0344,
      "step": 72700
    },
    {
      "epoch": 5.0,
      "eval_accuracy_macro_0.5": 0.9844756126403809,
      "eval_accuracy_micro_0.5": 0.9844756126403809,
      "eval_accuracy_weighted_0.5": 0.9822466373443604,
      "eval_f1_macro_0.5": 0.8005357384681702,
      "eval_f1_macro_0.6": 0.7886233329772949,
      "eval_f1_macro_0.7": 0.7649803161621094,
      "eval_f1_macro_0.8": 0.629375159740448,
      "eval_f1_micro_0.5": 0.7986993789672852,
      "eval_f1_micro_0.6": 0.7886808514595032,
      "eval_f1_micro_0.7": 0.768515944480896,
      "eval_f1_micro_0.8": 0.7301727533340454,
      "eval_f1_micro_0.9": 0.6455451846122742,
      "eval_f1_weighted_0.5": 0.7951176166534424,
      "eval_f1_weighted_0.6": 0.7823148965835571,
      "eval_f1_weighted_0.7": 0.7580999732017517,
      "eval_f1_weighted_0.8": 0.6174876093864441,
      "eval_loss": 0.032012078911066055,
      "eval_runtime": 133.5961,
      "eval_samples_per_second": 217.349,
      "eval_steps_per_second": 27.171,
      "step": 72715
    },
    {
      "epoch": 5.005844736299251,
      "grad_norm": 0.15866819024085999,
      "learning_rate": 1.872539412381591e-05,
      "loss": 0.0322,
      "step": 72800
    },
    {
      "epoch": 5.0127208966513095,
      "grad_norm": 0.2523478865623474,
      "learning_rate": 1.8682414427424485e-05,
      "loss": 0.0308,
      "step": 72900
    },
    {
      "epoch": 5.019597057003369,
      "grad_norm": 0.15472674369812012,
      "learning_rate": 1.8639434731033062e-05,
      "loss": 0.0321,
      "step": 73000
    },
    {
      "epoch": 5.026473217355429,
      "grad_norm": 0.17655308544635773,
      "learning_rate": 1.8596455034641636e-05,
      "loss": 0.0328,
      "step": 73100
    },
    {
      "epoch": 5.033349377707488,
      "grad_norm": 0.24769513309001923,
      "learning_rate": 1.8553475338250213e-05,
      "loss": 0.0328,
      "step": 73200
    },
    {
      "epoch": 5.0402255380595475,
      "grad_norm": 0.24143965542316437,
      "learning_rate": 1.8510495641858787e-05,
      "loss": 0.0293,
      "step": 73300
    },
    {
      "epoch": 5.047101698411607,
      "grad_norm": 0.18478365242481232,
      "learning_rate": 1.846751594546736e-05,
      "loss": 0.0316,
      "step": 73400
    },
    {
      "epoch": 5.053977858763666,
      "grad_norm": 0.18905948102474213,
      "learning_rate": 1.8424536249075938e-05,
      "loss": 0.0321,
      "step": 73500
    },
    {
      "epoch": 5.060854019115726,
      "grad_norm": 0.2148280292749405,
      "learning_rate": 1.8381556552684512e-05,
      "loss": 0.0342,
      "step": 73600
    },
    {
      "epoch": 5.067730179467786,
      "grad_norm": 0.21308909356594086,
      "learning_rate": 1.833857685629309e-05,
      "loss": 0.0339,
      "step": 73700
    },
    {
      "epoch": 5.074606339819844,
      "grad_norm": 0.13000135123729706,
      "learning_rate": 1.8295597159901663e-05,
      "loss": 0.032,
      "step": 73800
    },
    {
      "epoch": 5.081482500171904,
      "grad_norm": 0.26349079608917236,
      "learning_rate": 1.8252617463510237e-05,
      "loss": 0.0333,
      "step": 73900
    },
    {
      "epoch": 5.088358660523963,
      "grad_norm": 0.1592567265033722,
      "learning_rate": 1.8209637767118815e-05,
      "loss": 0.0325,
      "step": 74000
    },
    {
      "epoch": 5.095234820876023,
      "grad_norm": 0.2310464233160019,
      "learning_rate": 1.816665807072739e-05,
      "loss": 0.0322,
      "step": 74100
    },
    {
      "epoch": 5.1021109812280825,
      "grad_norm": 0.2519240975379944,
      "learning_rate": 1.8123678374335966e-05,
      "loss": 0.033,
      "step": 74200
    },
    {
      "epoch": 5.108987141580141,
      "grad_norm": 0.25338202714920044,
      "learning_rate": 1.808069867794454e-05,
      "loss": 0.0332,
      "step": 74300
    },
    {
      "epoch": 5.115863301932201,
      "grad_norm": 0.1760442852973938,
      "learning_rate": 1.8037718981553114e-05,
      "loss": 0.0322,
      "step": 74400
    },
    {
      "epoch": 5.122739462284261,
      "grad_norm": 0.18646244704723358,
      "learning_rate": 1.7995169082125603e-05,
      "loss": 0.0323,
      "step": 74500
    },
    {
      "epoch": 5.12961562263632,
      "grad_norm": 0.11079051345586777,
      "learning_rate": 1.795218938573418e-05,
      "loss": 0.0328,
      "step": 74600
    },
    {
      "epoch": 5.136491782988379,
      "grad_norm": 0.21712273359298706,
      "learning_rate": 1.7909209689342754e-05,
      "loss": 0.0308,
      "step": 74700
    },
    {
      "epoch": 5.143367943340439,
      "grad_norm": 0.30778196454048157,
      "learning_rate": 1.786622999295133e-05,
      "loss": 0.0348,
      "step": 74800
    },
    {
      "epoch": 5.150244103692498,
      "grad_norm": 0.07921776920557022,
      "learning_rate": 1.782325029655991e-05,
      "loss": 0.0307,
      "step": 74900
    },
    {
      "epoch": 5.157120264044558,
      "grad_norm": 0.1959865242242813,
      "learning_rate": 1.778027060016848e-05,
      "loss": 0.0311,
      "step": 75000
    },
    {
      "epoch": 5.1639964243966165,
      "grad_norm": 0.21061971783638,
      "learning_rate": 1.7737290903777056e-05,
      "loss": 0.0326,
      "step": 75100
    },
    {
      "epoch": 5.170872584748676,
      "grad_norm": 0.11600439995527267,
      "learning_rate": 1.7694311207385634e-05,
      "loss": 0.0321,
      "step": 75200
    },
    {
      "epoch": 5.177748745100736,
      "grad_norm": 0.1631862074136734,
      "learning_rate": 1.7651331510994208e-05,
      "loss": 0.0314,
      "step": 75300
    },
    {
      "epoch": 5.184624905452795,
      "grad_norm": 0.14888553321361542,
      "learning_rate": 1.7608351814602785e-05,
      "loss": 0.0338,
      "step": 75400
    },
    {
      "epoch": 5.191501065804855,
      "grad_norm": 0.20253810286521912,
      "learning_rate": 1.7565372118211355e-05,
      "loss": 0.0355,
      "step": 75500
    },
    {
      "epoch": 5.198377226156914,
      "grad_norm": 0.26910915970802307,
      "learning_rate": 1.7522392421819933e-05,
      "loss": 0.0297,
      "step": 75600
    },
    {
      "epoch": 5.205253386508973,
      "grad_norm": 0.29314544796943665,
      "learning_rate": 1.747941272542851e-05,
      "loss": 0.0338,
      "step": 75700
    },
    {
      "epoch": 5.212129546861033,
      "grad_norm": 0.11290719360113144,
      "learning_rate": 1.7436433029037084e-05,
      "loss": 0.0329,
      "step": 75800
    },
    {
      "epoch": 5.219005707213093,
      "grad_norm": 0.11548873782157898,
      "learning_rate": 1.739345333264566e-05,
      "loss": 0.0321,
      "step": 75900
    },
    {
      "epoch": 5.2258818675651515,
      "grad_norm": 0.20508576929569244,
      "learning_rate": 1.735047363625423e-05,
      "loss": 0.0333,
      "step": 76000
    },
    {
      "epoch": 5.232758027917211,
      "grad_norm": 0.13135553896427155,
      "learning_rate": 1.730749393986281e-05,
      "loss": 0.0316,
      "step": 76100
    },
    {
      "epoch": 5.23963418826927,
      "grad_norm": 0.1383853554725647,
      "learning_rate": 1.7264514243471386e-05,
      "loss": 0.0327,
      "step": 76200
    },
    {
      "epoch": 5.24651034862133,
      "grad_norm": 0.2097683846950531,
      "learning_rate": 1.722153454707996e-05,
      "loss": 0.0324,
      "step": 76300
    },
    {
      "epoch": 5.2533865089733895,
      "grad_norm": 0.09868083149194717,
      "learning_rate": 1.7178554850688534e-05,
      "loss": 0.0329,
      "step": 76400
    },
    {
      "epoch": 5.260262669325448,
      "grad_norm": 0.0645025372505188,
      "learning_rate": 1.713557515429711e-05,
      "loss": 0.0329,
      "step": 76500
    },
    {
      "epoch": 5.267138829677508,
      "grad_norm": 0.17222833633422852,
      "learning_rate": 1.7092595457905685e-05,
      "loss": 0.0329,
      "step": 76600
    },
    {
      "epoch": 5.274014990029568,
      "grad_norm": 0.1486726850271225,
      "learning_rate": 1.7049615761514263e-05,
      "loss": 0.0314,
      "step": 76700
    },
    {
      "epoch": 5.280891150381627,
      "grad_norm": 0.2592962086200714,
      "learning_rate": 1.7006636065122837e-05,
      "loss": 0.0322,
      "step": 76800
    },
    {
      "epoch": 5.287767310733686,
      "grad_norm": 0.20092763006687164,
      "learning_rate": 1.6964086165695326e-05,
      "loss": 0.0346,
      "step": 76900
    },
    {
      "epoch": 5.294643471085745,
      "grad_norm": 0.1647704690694809,
      "learning_rate": 1.6921106469303903e-05,
      "loss": 0.0324,
      "step": 77000
    },
    {
      "epoch": 5.301519631437805,
      "grad_norm": 0.27830228209495544,
      "learning_rate": 1.6878126772912477e-05,
      "loss": 0.0333,
      "step": 77100
    },
    {
      "epoch": 5.308395791789865,
      "grad_norm": 0.14868012070655823,
      "learning_rate": 1.683514707652105e-05,
      "loss": 0.0314,
      "step": 77200
    },
    {
      "epoch": 5.315271952141924,
      "grad_norm": 0.1144220381975174,
      "learning_rate": 1.6792167380129628e-05,
      "loss": 0.034,
      "step": 77300
    },
    {
      "epoch": 5.322148112493983,
      "grad_norm": 0.1871190369129181,
      "learning_rate": 1.6749187683738202e-05,
      "loss": 0.0319,
      "step": 77400
    },
    {
      "epoch": 5.329024272846043,
      "grad_norm": 0.1567627489566803,
      "learning_rate": 1.670620798734678e-05,
      "loss": 0.0299,
      "step": 77500
    },
    {
      "epoch": 5.335900433198102,
      "grad_norm": 0.2695292532444,
      "learning_rate": 1.6663228290955353e-05,
      "loss": 0.0369,
      "step": 77600
    },
    {
      "epoch": 5.342776593550162,
      "grad_norm": 0.152372345328331,
      "learning_rate": 1.6620248594563927e-05,
      "loss": 0.0335,
      "step": 77700
    },
    {
      "epoch": 5.349652753902221,
      "grad_norm": 0.1564255654811859,
      "learning_rate": 1.6577268898172504e-05,
      "loss": 0.0324,
      "step": 77800
    },
    {
      "epoch": 5.35652891425428,
      "grad_norm": 0.19096046686172485,
      "learning_rate": 1.653428920178108e-05,
      "loss": 0.0321,
      "step": 77900
    },
    {
      "epoch": 5.36340507460634,
      "grad_norm": 0.32127290964126587,
      "learning_rate": 1.6491309505389656e-05,
      "loss": 0.0349,
      "step": 78000
    },
    {
      "epoch": 5.370281234958399,
      "grad_norm": 0.13557693362236023,
      "learning_rate": 1.6448759605962145e-05,
      "loss": 0.034,
      "step": 78100
    },
    {
      "epoch": 5.3771573953104586,
      "grad_norm": 0.21776323020458221,
      "learning_rate": 1.6405779909570722e-05,
      "loss": 0.0312,
      "step": 78200
    },
    {
      "epoch": 5.384033555662518,
      "grad_norm": 0.23975250124931335,
      "learning_rate": 1.6362800213179292e-05,
      "loss": 0.0341,
      "step": 78300
    },
    {
      "epoch": 5.390909716014577,
      "grad_norm": 0.2053869068622589,
      "learning_rate": 1.631982051678787e-05,
      "loss": 0.0341,
      "step": 78400
    },
    {
      "epoch": 5.397785876366637,
      "grad_norm": 0.08436129242181778,
      "learning_rate": 1.6276840820396447e-05,
      "loss": 0.0325,
      "step": 78500
    },
    {
      "epoch": 5.404662036718697,
      "grad_norm": 0.31712621450424194,
      "learning_rate": 1.623386112400502e-05,
      "loss": 0.0341,
      "step": 78600
    },
    {
      "epoch": 5.4115381970707555,
      "grad_norm": 0.2724548578262329,
      "learning_rate": 1.6190881427613598e-05,
      "loss": 0.0314,
      "step": 78700
    },
    {
      "epoch": 5.418414357422815,
      "grad_norm": 0.2069968730211258,
      "learning_rate": 1.614790173122217e-05,
      "loss": 0.0316,
      "step": 78800
    },
    {
      "epoch": 5.425290517774875,
      "grad_norm": 0.2205028533935547,
      "learning_rate": 1.6104922034830746e-05,
      "loss": 0.0313,
      "step": 78900
    },
    {
      "epoch": 5.432166678126934,
      "grad_norm": 0.12685884535312653,
      "learning_rate": 1.6061942338439323e-05,
      "loss": 0.0335,
      "step": 79000
    },
    {
      "epoch": 5.4390428384789935,
      "grad_norm": 0.17874756455421448,
      "learning_rate": 1.6018962642047897e-05,
      "loss": 0.031,
      "step": 79100
    },
    {
      "epoch": 5.445918998831052,
      "grad_norm": 0.13791213929653168,
      "learning_rate": 1.5975982945656475e-05,
      "loss": 0.0317,
      "step": 79200
    },
    {
      "epoch": 5.452795159183112,
      "grad_norm": 0.28535038232803345,
      "learning_rate": 1.5933003249265045e-05,
      "loss": 0.0307,
      "step": 79300
    },
    {
      "epoch": 5.459671319535172,
      "grad_norm": 0.10667114704847336,
      "learning_rate": 1.5890023552873622e-05,
      "loss": 0.0298,
      "step": 79400
    },
    {
      "epoch": 5.466547479887231,
      "grad_norm": 0.10935854911804199,
      "learning_rate": 1.58470438564822e-05,
      "loss": 0.0328,
      "step": 79500
    },
    {
      "epoch": 5.47342364023929,
      "grad_norm": 0.1290147304534912,
      "learning_rate": 1.5804064160090774e-05,
      "loss": 0.0341,
      "step": 79600
    },
    {
      "epoch": 5.48029980059135,
      "grad_norm": 0.17699751257896423,
      "learning_rate": 1.576108446369935e-05,
      "loss": 0.0316,
      "step": 79700
    },
    {
      "epoch": 5.487175960943409,
      "grad_norm": 0.17328186333179474,
      "learning_rate": 1.5718104767307925e-05,
      "loss": 0.0332,
      "step": 79800
    },
    {
      "epoch": 5.494052121295469,
      "grad_norm": 0.1855487823486328,
      "learning_rate": 1.56751250709165e-05,
      "loss": 0.0318,
      "step": 79900
    },
    {
      "epoch": 5.5009282816475285,
      "grad_norm": 0.19482900202274323,
      "learning_rate": 1.5632145374525076e-05,
      "loss": 0.0316,
      "step": 80000
    },
    {
      "epoch": 5.507804441999587,
      "grad_norm": 0.1676287055015564,
      "learning_rate": 1.558916567813365e-05,
      "loss": 0.031,
      "step": 80100
    },
    {
      "epoch": 5.514680602351647,
      "grad_norm": 0.14386191964149475,
      "learning_rate": 1.5546185981742227e-05,
      "loss": 0.032,
      "step": 80200
    },
    {
      "epoch": 5.521556762703706,
      "grad_norm": 0.2222312092781067,
      "learning_rate": 1.55032062853508e-05,
      "loss": 0.0298,
      "step": 80300
    },
    {
      "epoch": 5.528432923055766,
      "grad_norm": 0.13175290822982788,
      "learning_rate": 1.5460226588959375e-05,
      "loss": 0.0338,
      "step": 80400
    },
    {
      "epoch": 5.535309083407825,
      "grad_norm": 0.17417800426483154,
      "learning_rate": 1.5417246892567952e-05,
      "loss": 0.0342,
      "step": 80500
    },
    {
      "epoch": 5.542185243759884,
      "grad_norm": 0.19373689591884613,
      "learning_rate": 1.537426719617653e-05,
      "loss": 0.0326,
      "step": 80600
    },
    {
      "epoch": 5.549061404111944,
      "grad_norm": 0.18791289627552032,
      "learning_rate": 1.5331287499785104e-05,
      "loss": 0.0312,
      "step": 80700
    },
    {
      "epoch": 5.555937564464004,
      "grad_norm": 0.11156214773654938,
      "learning_rate": 1.5288307803393677e-05,
      "loss": 0.0345,
      "step": 80800
    },
    {
      "epoch": 5.5628137248160625,
      "grad_norm": 0.14980295300483704,
      "learning_rate": 1.5245328107002251e-05,
      "loss": 0.0301,
      "step": 80900
    },
    {
      "epoch": 5.569689885168122,
      "grad_norm": 0.24489367008209229,
      "learning_rate": 1.5202348410610829e-05,
      "loss": 0.0332,
      "step": 81000
    },
    {
      "epoch": 5.576566045520181,
      "grad_norm": 0.15770450234413147,
      "learning_rate": 1.5159368714219404e-05,
      "loss": 0.033,
      "step": 81100
    },
    {
      "epoch": 5.583442205872241,
      "grad_norm": 0.1616005003452301,
      "learning_rate": 1.5116389017827978e-05,
      "loss": 0.033,
      "step": 81200
    },
    {
      "epoch": 5.590318366224301,
      "grad_norm": 0.15057595074176788,
      "learning_rate": 1.5073409321436554e-05,
      "loss": 0.0331,
      "step": 81300
    },
    {
      "epoch": 5.597194526576359,
      "grad_norm": 0.18421560525894165,
      "learning_rate": 1.5030429625045128e-05,
      "loss": 0.0331,
      "step": 81400
    },
    {
      "epoch": 5.604070686928419,
      "grad_norm": 0.22067084908485413,
      "learning_rate": 1.4987449928653705e-05,
      "loss": 0.031,
      "step": 81500
    },
    {
      "epoch": 5.610946847280479,
      "grad_norm": 0.11553296446800232,
      "learning_rate": 1.494447023226228e-05,
      "loss": 0.0341,
      "step": 81600
    },
    {
      "epoch": 5.617823007632538,
      "grad_norm": 0.1497456580400467,
      "learning_rate": 1.4901490535870855e-05,
      "loss": 0.0325,
      "step": 81700
    },
    {
      "epoch": 5.6246991679845975,
      "grad_norm": 0.1626954823732376,
      "learning_rate": 1.485851083947943e-05,
      "loss": 0.0334,
      "step": 81800
    },
    {
      "epoch": 5.631575328336657,
      "grad_norm": 0.30474501848220825,
      "learning_rate": 1.4815531143088007e-05,
      "loss": 0.0356,
      "step": 81900
    },
    {
      "epoch": 5.638451488688716,
      "grad_norm": 0.15999194979667664,
      "learning_rate": 1.4772551446696581e-05,
      "loss": 0.0343,
      "step": 82000
    },
    {
      "epoch": 5.645327649040776,
      "grad_norm": 0.151027649641037,
      "learning_rate": 1.4729571750305157e-05,
      "loss": 0.031,
      "step": 82100
    },
    {
      "epoch": 5.6522038093928355,
      "grad_norm": 0.2988131642341614,
      "learning_rate": 1.4686592053913731e-05,
      "loss": 0.0338,
      "step": 82200
    },
    {
      "epoch": 5.659079969744894,
      "grad_norm": 0.13033683598041534,
      "learning_rate": 1.464404215448622e-05,
      "loss": 0.0307,
      "step": 82300
    },
    {
      "epoch": 5.665956130096954,
      "grad_norm": 0.15692979097366333,
      "learning_rate": 1.4601062458094797e-05,
      "loss": 0.0312,
      "step": 82400
    },
    {
      "epoch": 5.672832290449013,
      "grad_norm": 0.16479791700839996,
      "learning_rate": 1.4558082761703373e-05,
      "loss": 0.0329,
      "step": 82500
    },
    {
      "epoch": 5.679708450801073,
      "grad_norm": 0.21956989169120789,
      "learning_rate": 1.4515103065311947e-05,
      "loss": 0.0342,
      "step": 82600
    },
    {
      "epoch": 5.686584611153132,
      "grad_norm": 0.2850506901741028,
      "learning_rate": 1.4472123368920524e-05,
      "loss": 0.0313,
      "step": 82700
    },
    {
      "epoch": 5.693460771505191,
      "grad_norm": 0.17053097486495972,
      "learning_rate": 1.4429143672529096e-05,
      "loss": 0.0341,
      "step": 82800
    },
    {
      "epoch": 5.700336931857251,
      "grad_norm": 0.06571391969919205,
      "learning_rate": 1.4386163976137674e-05,
      "loss": 0.0305,
      "step": 82900
    },
    {
      "epoch": 5.70721309220931,
      "grad_norm": 0.12587404251098633,
      "learning_rate": 1.4343184279746249e-05,
      "loss": 0.0327,
      "step": 83000
    },
    {
      "epoch": 5.71408925256137,
      "grad_norm": 0.12045647203922272,
      "learning_rate": 1.4300204583354823e-05,
      "loss": 0.0316,
      "step": 83100
    },
    {
      "epoch": 5.720965412913429,
      "grad_norm": 0.24085403978824615,
      "learning_rate": 1.42572248869634e-05,
      "loss": 0.0346,
      "step": 83200
    },
    {
      "epoch": 5.727841573265488,
      "grad_norm": 0.18692494928836823,
      "learning_rate": 1.4214245190571973e-05,
      "loss": 0.0352,
      "step": 83300
    },
    {
      "epoch": 5.734717733617548,
      "grad_norm": 0.22327201068401337,
      "learning_rate": 1.417126549418055e-05,
      "loss": 0.0319,
      "step": 83400
    },
    {
      "epoch": 5.741593893969608,
      "grad_norm": 0.17808113992214203,
      "learning_rate": 1.4128285797789125e-05,
      "loss": 0.0358,
      "step": 83500
    },
    {
      "epoch": 5.7484700543216665,
      "grad_norm": 0.2684541940689087,
      "learning_rate": 1.40853061013977e-05,
      "loss": 0.0326,
      "step": 83600
    },
    {
      "epoch": 5.755346214673726,
      "grad_norm": 0.2688677906990051,
      "learning_rate": 1.4042326405006275e-05,
      "loss": 0.0338,
      "step": 83700
    },
    {
      "epoch": 5.762222375025786,
      "grad_norm": 0.1936996579170227,
      "learning_rate": 1.3999346708614852e-05,
      "loss": 0.0321,
      "step": 83800
    },
    {
      "epoch": 5.769098535377845,
      "grad_norm": 0.18636354804039001,
      "learning_rate": 1.3956367012223426e-05,
      "loss": 0.0329,
      "step": 83900
    },
    {
      "epoch": 5.7759746957299045,
      "grad_norm": 0.13003361225128174,
      "learning_rate": 1.3913387315832002e-05,
      "loss": 0.0332,
      "step": 84000
    },
    {
      "epoch": 5.782850856081964,
      "grad_norm": 0.17188604176044464,
      "learning_rate": 1.3870407619440576e-05,
      "loss": 0.0335,
      "step": 84100
    },
    {
      "epoch": 5.789727016434023,
      "grad_norm": 0.24610170722007751,
      "learning_rate": 1.3827427923049151e-05,
      "loss": 0.0328,
      "step": 84200
    },
    {
      "epoch": 5.796603176786083,
      "grad_norm": 0.15322032570838928,
      "learning_rate": 1.3784448226657729e-05,
      "loss": 0.0352,
      "step": 84300
    },
    {
      "epoch": 5.803479337138142,
      "grad_norm": 0.16646870970726013,
      "learning_rate": 1.3741468530266303e-05,
      "loss": 0.0335,
      "step": 84400
    },
    {
      "epoch": 5.810355497490201,
      "grad_norm": 0.23850752413272858,
      "learning_rate": 1.3698488833874878e-05,
      "loss": 0.0328,
      "step": 84500
    },
    {
      "epoch": 5.817231657842261,
      "grad_norm": 0.1283629834651947,
      "learning_rate": 1.3655509137483455e-05,
      "loss": 0.0322,
      "step": 84600
    },
    {
      "epoch": 5.82410781819432,
      "grad_norm": 0.27573853731155396,
      "learning_rate": 1.3612529441092028e-05,
      "loss": 0.0311,
      "step": 84700
    },
    {
      "epoch": 5.83098397854638,
      "grad_norm": 0.1272459477186203,
      "learning_rate": 1.3569549744700605e-05,
      "loss": 0.0315,
      "step": 84800
    },
    {
      "epoch": 5.8378601388984395,
      "grad_norm": 0.13160304725170135,
      "learning_rate": 1.3526999845273094e-05,
      "loss": 0.0344,
      "step": 84900
    },
    {
      "epoch": 5.844736299250498,
      "grad_norm": 0.2087145745754242,
      "learning_rate": 1.3484020148881668e-05,
      "loss": 0.0334,
      "step": 85000
    },
    {
      "epoch": 5.851612459602558,
      "grad_norm": 0.17881444096565247,
      "learning_rate": 1.3441040452490245e-05,
      "loss": 0.0301,
      "step": 85100
    },
    {
      "epoch": 5.858488619954617,
      "grad_norm": 0.29645076394081116,
      "learning_rate": 1.339806075609882e-05,
      "loss": 0.0316,
      "step": 85200
    },
    {
      "epoch": 5.865364780306677,
      "grad_norm": 0.12800325453281403,
      "learning_rate": 1.3355081059707395e-05,
      "loss": 0.0318,
      "step": 85300
    },
    {
      "epoch": 5.872240940658736,
      "grad_norm": 0.2192990481853485,
      "learning_rate": 1.331210136331597e-05,
      "loss": 0.0327,
      "step": 85400
    },
    {
      "epoch": 5.879117101010795,
      "grad_norm": 0.1788347214460373,
      "learning_rate": 1.3269121666924544e-05,
      "loss": 0.0331,
      "step": 85500
    },
    {
      "epoch": 5.885993261362855,
      "grad_norm": 0.1319074183702469,
      "learning_rate": 1.3226141970533122e-05,
      "loss": 0.0322,
      "step": 85600
    },
    {
      "epoch": 5.892869421714915,
      "grad_norm": 0.18994376063346863,
      "learning_rate": 1.3183162274141697e-05,
      "loss": 0.0349,
      "step": 85700
    },
    {
      "epoch": 5.8997455820669735,
      "grad_norm": 0.31154781579971313,
      "learning_rate": 1.3140182577750271e-05,
      "loss": 0.0334,
      "step": 85800
    },
    {
      "epoch": 5.906621742419033,
      "grad_norm": 0.13022848963737488,
      "learning_rate": 1.3097202881358847e-05,
      "loss": 0.0311,
      "step": 85900
    },
    {
      "epoch": 5.913497902771093,
      "grad_norm": 0.15911538898944855,
      "learning_rate": 1.305422318496742e-05,
      "loss": 0.0305,
      "step": 86000
    },
    {
      "epoch": 5.920374063123152,
      "grad_norm": 0.20566558837890625,
      "learning_rate": 1.3011243488575998e-05,
      "loss": 0.0327,
      "step": 86100
    },
    {
      "epoch": 5.927250223475212,
      "grad_norm": 0.15441195666790009,
      "learning_rate": 1.2968263792184574e-05,
      "loss": 0.0312,
      "step": 86200
    },
    {
      "epoch": 5.934126383827271,
      "grad_norm": 0.14388076961040497,
      "learning_rate": 1.2925284095793147e-05,
      "loss": 0.0328,
      "step": 86300
    },
    {
      "epoch": 5.94100254417933,
      "grad_norm": 0.14295630156993866,
      "learning_rate": 1.2882304399401723e-05,
      "loss": 0.0327,
      "step": 86400
    },
    {
      "epoch": 5.94787870453139,
      "grad_norm": 0.12845724821090698,
      "learning_rate": 1.28393247030103e-05,
      "loss": 0.0331,
      "step": 86500
    },
    {
      "epoch": 5.954754864883449,
      "grad_norm": 0.10835886001586914,
      "learning_rate": 1.2796345006618873e-05,
      "loss": 0.0304,
      "step": 86600
    },
    {
      "epoch": 5.9616310252355085,
      "grad_norm": 0.16720619797706604,
      "learning_rate": 1.275336531022745e-05,
      "loss": 0.0311,
      "step": 86700
    },
    {
      "epoch": 5.968507185587568,
      "grad_norm": 0.26027029752731323,
      "learning_rate": 1.2710385613836024e-05,
      "loss": 0.0338,
      "step": 86800
    },
    {
      "epoch": 5.975383345939627,
      "grad_norm": 0.24923424422740936,
      "learning_rate": 1.26674059174446e-05,
      "loss": 0.0353,
      "step": 86900
    },
    {
      "epoch": 5.982259506291687,
      "grad_norm": 0.25503215193748474,
      "learning_rate": 1.2624426221053177e-05,
      "loss": 0.0293,
      "step": 87000
    },
    {
      "epoch": 5.989135666643746,
      "grad_norm": 0.2826632261276245,
      "learning_rate": 1.2581446524661749e-05,
      "loss": 0.0354,
      "step": 87100
    },
    {
      "epoch": 5.996011826995805,
      "grad_norm": 0.1612866222858429,
      "learning_rate": 1.2538466828270326e-05,
      "loss": 0.0334,
      "step": 87200
    },
    {
      "epoch": 6.0,
      "eval_accuracy_macro_0.5": 0.9849438071250916,
      "eval_accuracy_micro_0.5": 0.9849438071250916,
      "eval_accuracy_weighted_0.5": 0.9827542901039124,
      "eval_f1_macro_0.5": 0.8077710270881653,
      "eval_f1_macro_0.6": 0.795868456363678,
      "eval_f1_macro_0.7": 0.7725446820259094,
      "eval_f1_macro_0.8": 0.6403828263282776,
      "eval_f1_micro_0.5": 0.8046634793281555,
      "eval_f1_micro_0.6": 0.7945994734764099,
      "eval_f1_micro_0.7": 0.774850606918335,
      "eval_f1_micro_0.8": 0.736173152923584,
      "eval_f1_micro_0.9": 0.6540033221244812,
      "eval_f1_weighted_0.5": 0.8017138838768005,
      "eval_f1_weighted_0.6": 0.789038360118866,
      "eval_f1_weighted_0.7": 0.7654786705970764,
      "eval_f1_weighted_0.8": 0.6281622648239136,
      "eval_loss": 0.030961263924837112,
      "eval_runtime": 133.4082,
      "eval_samples_per_second": 217.655,
      "eval_steps_per_second": 27.21,
      "step": 87258
    },
    {
      "epoch": 6.002887987347865,
      "grad_norm": 0.2694825530052185,
      "learning_rate": 1.2495487131878902e-05,
      "loss": 0.0321,
      "step": 87300
    },
    {
      "epoch": 6.009764147699924,
      "grad_norm": 0.13867151737213135,
      "learning_rate": 1.2452507435487476e-05,
      "loss": 0.0311,
      "step": 87400
    },
    {
      "epoch": 6.016640308051984,
      "grad_norm": 0.09044768661260605,
      "learning_rate": 1.2409527739096051e-05,
      "loss": 0.0298,
      "step": 87500
    },
    {
      "epoch": 6.023516468404043,
      "grad_norm": 0.43743717670440674,
      "learning_rate": 1.2366548042704627e-05,
      "loss": 0.0312,
      "step": 87600
    },
    {
      "epoch": 6.030392628756102,
      "grad_norm": 0.20038411021232605,
      "learning_rate": 1.2323568346313203e-05,
      "loss": 0.0339,
      "step": 87700
    },
    {
      "epoch": 6.037268789108162,
      "grad_norm": 0.21806804835796356,
      "learning_rate": 1.2280588649921778e-05,
      "loss": 0.0299,
      "step": 87800
    },
    {
      "epoch": 6.044144949460222,
      "grad_norm": 0.11158847063779831,
      "learning_rate": 1.2237608953530352e-05,
      "loss": 0.0333,
      "step": 87900
    },
    {
      "epoch": 6.051021109812281,
      "grad_norm": 0.1845880150794983,
      "learning_rate": 1.219462925713893e-05,
      "loss": 0.0318,
      "step": 88000
    },
    {
      "epoch": 6.05789727016434,
      "grad_norm": 0.1584121435880661,
      "learning_rate": 1.2151649560747503e-05,
      "loss": 0.0292,
      "step": 88100
    },
    {
      "epoch": 6.0647734305164,
      "grad_norm": 0.23016072809696198,
      "learning_rate": 1.2108669864356079e-05,
      "loss": 0.0319,
      "step": 88200
    },
    {
      "epoch": 6.071649590868459,
      "grad_norm": 0.10420095920562744,
      "learning_rate": 1.2065690167964654e-05,
      "loss": 0.0301,
      "step": 88300
    },
    {
      "epoch": 6.078525751220519,
      "grad_norm": 0.1838977038860321,
      "learning_rate": 1.202271047157323e-05,
      "loss": 0.0314,
      "step": 88400
    },
    {
      "epoch": 6.0854019115725775,
      "grad_norm": 0.19499832391738892,
      "learning_rate": 1.1979730775181806e-05,
      "loss": 0.0343,
      "step": 88500
    },
    {
      "epoch": 6.092278071924637,
      "grad_norm": 0.2936946153640747,
      "learning_rate": 1.193675107879038e-05,
      "loss": 0.0347,
      "step": 88600
    },
    {
      "epoch": 6.099154232276697,
      "grad_norm": 0.16772013902664185,
      "learning_rate": 1.1893771382398955e-05,
      "loss": 0.032,
      "step": 88700
    },
    {
      "epoch": 6.106030392628756,
      "grad_norm": 0.13246989250183105,
      "learning_rate": 1.1850791686007529e-05,
      "loss": 0.034,
      "step": 88800
    },
    {
      "epoch": 6.1129065529808155,
      "grad_norm": 0.048021309077739716,
      "learning_rate": 1.1807811989616106e-05,
      "loss": 0.0309,
      "step": 88900
    },
    {
      "epoch": 6.119782713332875,
      "grad_norm": 0.16253557801246643,
      "learning_rate": 1.1764832293224682e-05,
      "loss": 0.0321,
      "step": 89000
    },
    {
      "epoch": 6.126658873684934,
      "grad_norm": 0.12688134610652924,
      "learning_rate": 1.1721852596833256e-05,
      "loss": 0.033,
      "step": 89100
    },
    {
      "epoch": 6.133535034036994,
      "grad_norm": 0.16053879261016846,
      "learning_rate": 1.1678872900441832e-05,
      "loss": 0.0337,
      "step": 89200
    },
    {
      "epoch": 6.140411194389053,
      "grad_norm": 0.18206530809402466,
      "learning_rate": 1.1635893204050407e-05,
      "loss": 0.0314,
      "step": 89300
    },
    {
      "epoch": 6.147287354741112,
      "grad_norm": 0.20788608491420746,
      "learning_rate": 1.1592913507658983e-05,
      "loss": 0.0312,
      "step": 89400
    },
    {
      "epoch": 6.154163515093172,
      "grad_norm": 0.22918935120105743,
      "learning_rate": 1.1549933811267558e-05,
      "loss": 0.0325,
      "step": 89500
    },
    {
      "epoch": 6.161039675445231,
      "grad_norm": 0.341900110244751,
      "learning_rate": 1.1506954114876132e-05,
      "loss": 0.0308,
      "step": 89600
    },
    {
      "epoch": 6.167915835797291,
      "grad_norm": 0.3214976489543915,
      "learning_rate": 1.146397441848471e-05,
      "loss": 0.0319,
      "step": 89700
    },
    {
      "epoch": 6.1747919961493505,
      "grad_norm": 0.15966224670410156,
      "learning_rate": 1.1420994722093283e-05,
      "loss": 0.0334,
      "step": 89800
    },
    {
      "epoch": 6.181668156501409,
      "grad_norm": 0.1717524230480194,
      "learning_rate": 1.1378015025701859e-05,
      "loss": 0.0337,
      "step": 89900
    },
    {
      "epoch": 6.188544316853469,
      "grad_norm": 0.18642491102218628,
      "learning_rate": 1.1335035329310435e-05,
      "loss": 0.0321,
      "step": 90000
    },
    {
      "epoch": 6.195420477205529,
      "grad_norm": 0.32453668117523193,
      "learning_rate": 1.129205563291901e-05,
      "loss": 0.0323,
      "step": 90100
    },
    {
      "epoch": 6.202296637557588,
      "grad_norm": 0.1482531577348709,
      "learning_rate": 1.1249075936527586e-05,
      "loss": 0.0321,
      "step": 90200
    },
    {
      "epoch": 6.209172797909647,
      "grad_norm": 0.18162700533866882,
      "learning_rate": 1.120609624013616e-05,
      "loss": 0.0316,
      "step": 90300
    },
    {
      "epoch": 6.216048958261707,
      "grad_norm": 0.22635699808597565,
      "learning_rate": 1.1163116543744735e-05,
      "loss": 0.0319,
      "step": 90400
    },
    {
      "epoch": 6.222925118613766,
      "grad_norm": 0.27863362431526184,
      "learning_rate": 1.1120136847353311e-05,
      "loss": 0.0331,
      "step": 90500
    },
    {
      "epoch": 6.229801278965826,
      "grad_norm": 0.19448818266391754,
      "learning_rate": 1.1077157150961887e-05,
      "loss": 0.0299,
      "step": 90600
    },
    {
      "epoch": 6.2366774393178845,
      "grad_norm": 0.08693291991949081,
      "learning_rate": 1.1034607251534376e-05,
      "loss": 0.0297,
      "step": 90700
    },
    {
      "epoch": 6.243553599669944,
      "grad_norm": 0.23643161356449127,
      "learning_rate": 1.0991627555142951e-05,
      "loss": 0.0313,
      "step": 90800
    },
    {
      "epoch": 6.250429760022004,
      "grad_norm": 0.27196434140205383,
      "learning_rate": 1.094907765571544e-05,
      "loss": 0.0318,
      "step": 90900
    },
    {
      "epoch": 6.257305920374063,
      "grad_norm": 0.18505284190177917,
      "learning_rate": 1.0906097959324016e-05,
      "loss": 0.0344,
      "step": 91000
    },
    {
      "epoch": 6.264182080726123,
      "grad_norm": 0.22312957048416138,
      "learning_rate": 1.0863118262932592e-05,
      "loss": 0.0331,
      "step": 91100
    },
    {
      "epoch": 6.271058241078182,
      "grad_norm": 0.18030446767807007,
      "learning_rate": 1.0820138566541165e-05,
      "loss": 0.0319,
      "step": 91200
    },
    {
      "epoch": 6.277934401430241,
      "grad_norm": 0.1852988600730896,
      "learning_rate": 1.0777158870149743e-05,
      "loss": 0.0298,
      "step": 91300
    },
    {
      "epoch": 6.284810561782301,
      "grad_norm": 0.1919926255941391,
      "learning_rate": 1.0734179173758317e-05,
      "loss": 0.0327,
      "step": 91400
    },
    {
      "epoch": 6.29168672213436,
      "grad_norm": 0.2514614760875702,
      "learning_rate": 1.0691199477366892e-05,
      "loss": 0.0317,
      "step": 91500
    },
    {
      "epoch": 6.2985628824864195,
      "grad_norm": 0.26042255759239197,
      "learning_rate": 1.0648219780975468e-05,
      "loss": 0.0313,
      "step": 91600
    },
    {
      "epoch": 6.305439042838479,
      "grad_norm": 0.21770906448364258,
      "learning_rate": 1.0605240084584043e-05,
      "loss": 0.0322,
      "step": 91700
    },
    {
      "epoch": 6.312315203190538,
      "grad_norm": 0.12714478373527527,
      "learning_rate": 1.0562260388192619e-05,
      "loss": 0.036,
      "step": 91800
    },
    {
      "epoch": 6.319191363542598,
      "grad_norm": 0.1175251454114914,
      "learning_rate": 1.0519280691801193e-05,
      "loss": 0.0334,
      "step": 91900
    },
    {
      "epoch": 6.3260675238946575,
      "grad_norm": 0.1706778109073639,
      "learning_rate": 1.0476300995409769e-05,
      "loss": 0.0319,
      "step": 92000
    },
    {
      "epoch": 6.332943684246716,
      "grad_norm": 0.19355906546115875,
      "learning_rate": 1.0433321299018344e-05,
      "loss": 0.0313,
      "step": 92100
    },
    {
      "epoch": 6.339819844598776,
      "grad_norm": 0.24879135191440582,
      "learning_rate": 1.039034160262692e-05,
      "loss": 0.0313,
      "step": 92200
    },
    {
      "epoch": 6.346696004950836,
      "grad_norm": 0.168400838971138,
      "learning_rate": 1.0347361906235495e-05,
      "loss": 0.0321,
      "step": 92300
    },
    {
      "epoch": 6.353572165302895,
      "grad_norm": 0.2950645685195923,
      "learning_rate": 1.030438220984407e-05,
      "loss": 0.0332,
      "step": 92400
    },
    {
      "epoch": 6.360448325654954,
      "grad_norm": 0.20187368988990784,
      "learning_rate": 1.0261402513452645e-05,
      "loss": 0.0349,
      "step": 92500
    },
    {
      "epoch": 6.367324486007013,
      "grad_norm": 0.16365382075309753,
      "learning_rate": 1.021842281706122e-05,
      "loss": 0.0315,
      "step": 92600
    },
    {
      "epoch": 6.374200646359073,
      "grad_norm": 0.37837713956832886,
      "learning_rate": 1.0175443120669796e-05,
      "loss": 0.0325,
      "step": 92700
    },
    {
      "epoch": 6.381076806711133,
      "grad_norm": 0.21877220273017883,
      "learning_rate": 1.0132463424278372e-05,
      "loss": 0.0313,
      "step": 92800
    },
    {
      "epoch": 6.387952967063192,
      "grad_norm": 0.16203206777572632,
      "learning_rate": 1.0089483727886946e-05,
      "loss": 0.0313,
      "step": 92900
    },
    {
      "epoch": 6.394829127415251,
      "grad_norm": 0.21407464146614075,
      "learning_rate": 1.0046504031495523e-05,
      "loss": 0.0305,
      "step": 93000
    },
    {
      "epoch": 6.401705287767311,
      "grad_norm": 0.12500642240047455,
      "learning_rate": 1.0003524335104097e-05,
      "loss": 0.0323,
      "step": 93100
    },
    {
      "epoch": 6.40858144811937,
      "grad_norm": 0.17318980395793915,
      "learning_rate": 9.960544638712672e-06,
      "loss": 0.0312,
      "step": 93200
    },
    {
      "epoch": 6.41545760847143,
      "grad_norm": 0.14339065551757812,
      "learning_rate": 9.917564942321248e-06,
      "loss": 0.032,
      "step": 93300
    },
    {
      "epoch": 6.4223337688234885,
      "grad_norm": 0.1747785359621048,
      "learning_rate": 9.874585245929824e-06,
      "loss": 0.0309,
      "step": 93400
    },
    {
      "epoch": 6.429209929175548,
      "grad_norm": 0.24018341302871704,
      "learning_rate": 9.8316055495384e-06,
      "loss": 0.0303,
      "step": 93500
    },
    {
      "epoch": 6.436086089527608,
      "grad_norm": 0.2815745770931244,
      "learning_rate": 9.788625853146973e-06,
      "loss": 0.0328,
      "step": 93600
    },
    {
      "epoch": 6.442962249879667,
      "grad_norm": 0.18776878714561462,
      "learning_rate": 9.745646156755549e-06,
      "loss": 0.0293,
      "step": 93700
    },
    {
      "epoch": 6.4498384102317265,
      "grad_norm": 0.13701342046260834,
      "learning_rate": 9.702666460364124e-06,
      "loss": 0.0309,
      "step": 93800
    },
    {
      "epoch": 6.456714570583786,
      "grad_norm": 0.30073997378349304,
      "learning_rate": 9.6596867639727e-06,
      "loss": 0.0338,
      "step": 93900
    },
    {
      "epoch": 6.463590730935845,
      "grad_norm": 0.12231975048780441,
      "learning_rate": 9.616707067581276e-06,
      "loss": 0.0281,
      "step": 94000
    },
    {
      "epoch": 6.470466891287905,
      "grad_norm": 0.261921226978302,
      "learning_rate": 9.57372737118985e-06,
      "loss": 0.0335,
      "step": 94100
    },
    {
      "epoch": 6.477343051639965,
      "grad_norm": 0.14184808731079102,
      "learning_rate": 9.530747674798425e-06,
      "loss": 0.0302,
      "step": 94200
    },
    {
      "epoch": 6.4842192119920234,
      "grad_norm": 0.3704206347465515,
      "learning_rate": 9.487767978407e-06,
      "loss": 0.0301,
      "step": 94300
    },
    {
      "epoch": 6.491095372344083,
      "grad_norm": 0.260042667388916,
      "learning_rate": 9.444788282015576e-06,
      "loss": 0.0317,
      "step": 94400
    },
    {
      "epoch": 6.497971532696143,
      "grad_norm": 0.29246678948402405,
      "learning_rate": 9.401808585624152e-06,
      "loss": 0.0316,
      "step": 94500
    },
    {
      "epoch": 6.504847693048202,
      "grad_norm": 0.2115141749382019,
      "learning_rate": 9.358828889232726e-06,
      "loss": 0.0312,
      "step": 94600
    },
    {
      "epoch": 6.5117238534002615,
      "grad_norm": 0.16702900826931,
      "learning_rate": 9.315849192841303e-06,
      "loss": 0.0303,
      "step": 94700
    },
    {
      "epoch": 6.51860001375232,
      "grad_norm": 0.19114933907985687,
      "learning_rate": 9.272869496449877e-06,
      "loss": 0.0331,
      "step": 94800
    },
    {
      "epoch": 6.52547617410438,
      "grad_norm": 0.13153035938739777,
      "learning_rate": 9.229889800058453e-06,
      "loss": 0.0297,
      "step": 94900
    },
    {
      "epoch": 6.53235233445644,
      "grad_norm": 0.2031831443309784,
      "learning_rate": 9.186910103667028e-06,
      "loss": 0.031,
      "step": 95000
    },
    {
      "epoch": 6.539228494808499,
      "grad_norm": 0.07279882580041885,
      "learning_rate": 9.143930407275604e-06,
      "loss": 0.0306,
      "step": 95100
    },
    {
      "epoch": 6.546104655160558,
      "grad_norm": 0.5052416920661926,
      "learning_rate": 9.10095071088418e-06,
      "loss": 0.0335,
      "step": 95200
    },
    {
      "epoch": 6.552980815512618,
      "grad_norm": 0.20316769182682037,
      "learning_rate": 9.057971014492753e-06,
      "loss": 0.0307,
      "step": 95300
    },
    {
      "epoch": 6.559856975864677,
      "grad_norm": 0.11578374356031418,
      "learning_rate": 9.014991318101329e-06,
      "loss": 0.0303,
      "step": 95400
    },
    {
      "epoch": 6.566733136216737,
      "grad_norm": 0.08710400015115738,
      "learning_rate": 8.972011621709905e-06,
      "loss": 0.0304,
      "step": 95500
    },
    {
      "epoch": 6.573609296568796,
      "grad_norm": 0.13456110656261444,
      "learning_rate": 8.92903192531848e-06,
      "loss": 0.0303,
      "step": 95600
    },
    {
      "epoch": 6.580485456920855,
      "grad_norm": 0.1949843317270279,
      "learning_rate": 8.886052228927056e-06,
      "loss": 0.034,
      "step": 95700
    },
    {
      "epoch": 6.587361617272915,
      "grad_norm": 0.18997398018836975,
      "learning_rate": 8.84307253253563e-06,
      "loss": 0.0323,
      "step": 95800
    },
    {
      "epoch": 6.594237777624974,
      "grad_norm": 0.2002885490655899,
      "learning_rate": 8.800092836144205e-06,
      "loss": 0.0319,
      "step": 95900
    },
    {
      "epoch": 6.601113937977034,
      "grad_norm": 0.31647828221321106,
      "learning_rate": 8.757113139752781e-06,
      "loss": 0.0304,
      "step": 96000
    },
    {
      "epoch": 6.607990098329093,
      "grad_norm": 0.29145288467407227,
      "learning_rate": 8.714133443361357e-06,
      "loss": 0.0299,
      "step": 96100
    },
    {
      "epoch": 6.614866258681152,
      "grad_norm": 0.1487341821193695,
      "learning_rate": 8.671153746969932e-06,
      "loss": 0.031,
      "step": 96200
    },
    {
      "epoch": 6.621742419033212,
      "grad_norm": 0.10435155779123306,
      "learning_rate": 8.628174050578506e-06,
      "loss": 0.0315,
      "step": 96300
    },
    {
      "epoch": 6.628618579385272,
      "grad_norm": 0.3017873764038086,
      "learning_rate": 8.585194354187083e-06,
      "loss": 0.0315,
      "step": 96400
    },
    {
      "epoch": 6.6354947397373305,
      "grad_norm": 0.20268985629081726,
      "learning_rate": 8.542214657795657e-06,
      "loss": 0.0289,
      "step": 96500
    },
    {
      "epoch": 6.64237090008939,
      "grad_norm": 0.1594974398612976,
      "learning_rate": 8.499234961404233e-06,
      "loss": 0.0312,
      "step": 96600
    },
    {
      "epoch": 6.64924706044145,
      "grad_norm": 0.18321938812732697,
      "learning_rate": 8.456255265012808e-06,
      "loss": 0.0306,
      "step": 96700
    },
    {
      "epoch": 6.656123220793509,
      "grad_norm": 0.14779509603977203,
      "learning_rate": 8.413275568621384e-06,
      "loss": 0.033,
      "step": 96800
    },
    {
      "epoch": 6.662999381145569,
      "grad_norm": 0.2634109556674957,
      "learning_rate": 8.37029587222996e-06,
      "loss": 0.033,
      "step": 96900
    },
    {
      "epoch": 6.669875541497627,
      "grad_norm": 0.15357469022274017,
      "learning_rate": 8.327316175838534e-06,
      "loss": 0.0329,
      "step": 97000
    },
    {
      "epoch": 6.676751701849687,
      "grad_norm": 0.07758616656064987,
      "learning_rate": 8.28433647944711e-06,
      "loss": 0.0308,
      "step": 97100
    },
    {
      "epoch": 6.683627862201747,
      "grad_norm": 0.19367656111717224,
      "learning_rate": 8.241356783055685e-06,
      "loss": 0.031,
      "step": 97200
    },
    {
      "epoch": 6.690504022553806,
      "grad_norm": 0.12709712982177734,
      "learning_rate": 8.198806883628174e-06,
      "loss": 0.032,
      "step": 97300
    },
    {
      "epoch": 6.6973801829058655,
      "grad_norm": 0.10820931941270828,
      "learning_rate": 8.15582718723675e-06,
      "loss": 0.0344,
      "step": 97400
    },
    {
      "epoch": 6.704256343257924,
      "grad_norm": 0.18739312887191772,
      "learning_rate": 8.112847490845325e-06,
      "loss": 0.0313,
      "step": 97500
    },
    {
      "epoch": 6.711132503609984,
      "grad_norm": 0.15314823389053345,
      "learning_rate": 8.0698677944539e-06,
      "loss": 0.031,
      "step": 97600
    },
    {
      "epoch": 6.718008663962044,
      "grad_norm": 0.1922966092824936,
      "learning_rate": 8.026888098062475e-06,
      "loss": 0.0329,
      "step": 97700
    },
    {
      "epoch": 6.724884824314103,
      "grad_norm": 0.18226778507232666,
      "learning_rate": 7.984338198634965e-06,
      "loss": 0.0335,
      "step": 97800
    },
    {
      "epoch": 6.731760984666162,
      "grad_norm": 0.2647506594657898,
      "learning_rate": 7.941788299207454e-06,
      "loss": 0.0315,
      "step": 97900
    },
    {
      "epoch": 6.738637145018222,
      "grad_norm": 0.2043202817440033,
      "learning_rate": 7.89880860281603e-06,
      "loss": 0.0298,
      "step": 98000
    },
    {
      "epoch": 6.745513305370281,
      "grad_norm": 0.22837978601455688,
      "learning_rate": 7.855828906424606e-06,
      "loss": 0.0317,
      "step": 98100
    },
    {
      "epoch": 6.752389465722341,
      "grad_norm": 0.30991342663764954,
      "learning_rate": 7.812849210033181e-06,
      "loss": 0.0318,
      "step": 98200
    },
    {
      "epoch": 6.7592656260744,
      "grad_norm": 0.1912916749715805,
      "learning_rate": 7.769869513641755e-06,
      "loss": 0.0332,
      "step": 98300
    },
    {
      "epoch": 6.766141786426459,
      "grad_norm": 0.11713049560785294,
      "learning_rate": 7.72688981725033e-06,
      "loss": 0.0308,
      "step": 98400
    },
    {
      "epoch": 6.773017946778519,
      "grad_norm": 0.304177850484848,
      "learning_rate": 7.683910120858906e-06,
      "loss": 0.0346,
      "step": 98500
    },
    {
      "epoch": 6.779894107130579,
      "grad_norm": 0.17116747796535492,
      "learning_rate": 7.640930424467482e-06,
      "loss": 0.0328,
      "step": 98600
    },
    {
      "epoch": 6.786770267482638,
      "grad_norm": 0.24331338703632355,
      "learning_rate": 7.5979507280760575e-06,
      "loss": 0.0313,
      "step": 98700
    },
    {
      "epoch": 6.793646427834697,
      "grad_norm": 0.20224761962890625,
      "learning_rate": 7.554971031684632e-06,
      "loss": 0.0324,
      "step": 98800
    },
    {
      "epoch": 6.800522588186756,
      "grad_norm": 0.15894460678100586,
      "learning_rate": 7.511991335293207e-06,
      "loss": 0.0311,
      "step": 98900
    },
    {
      "epoch": 6.807398748538816,
      "grad_norm": 0.14062483608722687,
      "learning_rate": 7.4690116389017835e-06,
      "loss": 0.0296,
      "step": 99000
    },
    {
      "epoch": 6.814274908890876,
      "grad_norm": 0.17143282294273376,
      "learning_rate": 7.426031942510358e-06,
      "loss": 0.0334,
      "step": 99100
    },
    {
      "epoch": 6.8211510692429345,
      "grad_norm": 0.21178245544433594,
      "learning_rate": 7.383052246118934e-06,
      "loss": 0.0357,
      "step": 99200
    },
    {
      "epoch": 6.828027229594994,
      "grad_norm": 0.2121976912021637,
      "learning_rate": 7.340072549727509e-06,
      "loss": 0.0295,
      "step": 99300
    },
    {
      "epoch": 6.834903389947054,
      "grad_norm": 0.1875234842300415,
      "learning_rate": 7.297092853336085e-06,
      "loss": 0.0346,
      "step": 99400
    },
    {
      "epoch": 6.841779550299113,
      "grad_norm": 0.2646057605743408,
      "learning_rate": 7.25411315694466e-06,
      "loss": 0.0321,
      "step": 99500
    },
    {
      "epoch": 6.8486557106511725,
      "grad_norm": 0.23039473593235016,
      "learning_rate": 7.211133460553235e-06,
      "loss": 0.0313,
      "step": 99600
    },
    {
      "epoch": 6.855531871003231,
      "grad_norm": 0.18565179407596588,
      "learning_rate": 7.16815376416181e-06,
      "loss": 0.0313,
      "step": 99700
    },
    {
      "epoch": 6.862408031355291,
      "grad_norm": 0.23161202669143677,
      "learning_rate": 7.125174067770387e-06,
      "loss": 0.032,
      "step": 99800
    },
    {
      "epoch": 6.869284191707351,
      "grad_norm": 0.205058291554451,
      "learning_rate": 7.0821943713789614e-06,
      "loss": 0.0313,
      "step": 99900
    },
    {
      "epoch": 6.87616035205941,
      "grad_norm": 0.10077299177646637,
      "learning_rate": 7.039214674987536e-06,
      "loss": 0.0314,
      "step": 100000
    },
    {
      "epoch": 6.883036512411469,
      "grad_norm": 0.15465496480464935,
      "learning_rate": 6.996234978596111e-06,
      "loss": 0.0321,
      "step": 100100
    },
    {
      "epoch": 6.889912672763529,
      "grad_norm": 0.25433194637298584,
      "learning_rate": 6.9532552822046865e-06,
      "loss": 0.0308,
      "step": 100200
    },
    {
      "epoch": 6.896788833115588,
      "grad_norm": 0.10822468250989914,
      "learning_rate": 6.910275585813262e-06,
      "loss": 0.0337,
      "step": 100300
    },
    {
      "epoch": 6.903664993467648,
      "grad_norm": 0.2366822361946106,
      "learning_rate": 6.867295889421838e-06,
      "loss": 0.0309,
      "step": 100400
    },
    {
      "epoch": 6.9105411538197075,
      "grad_norm": 0.13883700966835022,
      "learning_rate": 6.8243161930304125e-06,
      "loss": 0.0325,
      "step": 100500
    },
    {
      "epoch": 6.917417314171766,
      "grad_norm": 0.23646441102027893,
      "learning_rate": 6.781336496638987e-06,
      "loss": 0.0288,
      "step": 100600
    },
    {
      "epoch": 6.924293474523826,
      "grad_norm": 0.23339217901229858,
      "learning_rate": 6.738356800247564e-06,
      "loss": 0.032,
      "step": 100700
    },
    {
      "epoch": 6.931169634875886,
      "grad_norm": 0.30301305651664734,
      "learning_rate": 6.6953771038561385e-06,
      "loss": 0.0316,
      "step": 100800
    },
    {
      "epoch": 6.938045795227945,
      "grad_norm": 0.21653543412685394,
      "learning_rate": 6.652397407464714e-06,
      "loss": 0.0318,
      "step": 100900
    },
    {
      "epoch": 6.944921955580004,
      "grad_norm": 0.1571028232574463,
      "learning_rate": 6.609417711073289e-06,
      "loss": 0.0326,
      "step": 101000
    },
    {
      "epoch": 6.951798115932063,
      "grad_norm": 0.13074533641338348,
      "learning_rate": 6.566438014681865e-06,
      "loss": 0.0303,
      "step": 101100
    },
    {
      "epoch": 6.958674276284123,
      "grad_norm": 0.10903273522853851,
      "learning_rate": 6.52345831829044e-06,
      "loss": 0.0326,
      "step": 101200
    },
    {
      "epoch": 6.965550436636183,
      "grad_norm": 0.11291171610355377,
      "learning_rate": 6.480478621899015e-06,
      "loss": 0.0302,
      "step": 101300
    },
    {
      "epoch": 6.9724265969882415,
      "grad_norm": 0.3540322482585907,
      "learning_rate": 6.4374989255075904e-06,
      "loss": 0.0326,
      "step": 101400
    },
    {
      "epoch": 6.979302757340301,
      "grad_norm": 0.12453985959291458,
      "learning_rate": 6.394519229116167e-06,
      "loss": 0.0341,
      "step": 101500
    },
    {
      "epoch": 6.98617891769236,
      "grad_norm": 0.20432323217391968,
      "learning_rate": 6.351539532724742e-06,
      "loss": 0.0307,
      "step": 101600
    },
    {
      "epoch": 6.99305507804442,
      "grad_norm": 0.26210659742355347,
      "learning_rate": 6.308559836333316e-06,
      "loss": 0.0334,
      "step": 101700
    },
    {
      "epoch": 6.99993123839648,
      "grad_norm": 0.2667025029659271,
      "learning_rate": 6.265580139941891e-06,
      "loss": 0.0289,
      "step": 101800
    },
    {
      "epoch": 7.0,
      "eval_accuracy_macro_0.5": 0.9851051568984985,
      "eval_accuracy_micro_0.5": 0.9851052165031433,
      "eval_accuracy_weighted_0.5": 0.9829662442207336,
      "eval_f1_macro_0.5": 0.8102790713310242,
      "eval_f1_macro_0.6": 0.7999968528747559,
      "eval_f1_macro_0.7": 0.778724193572998,
      "eval_f1_macro_0.8": 0.6508909463882446,
      "eval_f1_micro_0.5": 0.8075693249702454,
      "eval_f1_micro_0.6": 0.7990748882293701,
      "eval_f1_micro_0.7": 0.7809742093086243,
      "eval_f1_micro_0.8": 0.7443860769271851,
      "eval_f1_micro_0.9": 0.6644580364227295,
      "eval_f1_weighted_0.5": 0.8045868277549744,
      "eval_f1_weighted_0.6": 0.7935420274734497,
      "eval_f1_weighted_0.7": 0.7717772126197815,
      "eval_f1_weighted_0.8": 0.6394160389900208,
      "eval_loss": 0.03067469410598278,
      "eval_runtime": 133.4651,
      "eval_samples_per_second": 217.562,
      "eval_steps_per_second": 27.198,
      "step": 101801
    }
  ],
  "logging_steps": 100,
  "max_steps": 116344,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.636820625263411e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
