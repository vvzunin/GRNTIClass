{
  "best_metric": 0.7118565440177917,
  "best_model_checkpoint": "aleksandr-test-user-base/model bert lora level 1/checkpoint-101801",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 101801,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00687616035205941,
      "grad_norm": 0.2997826039791107,
      "learning_rate": 4.996131827324772e-05,
      "loss": 0.5384,
      "step": 100
    },
    {
      "epoch": 0.01375232070411882,
      "grad_norm": 0.21458019316196442,
      "learning_rate": 4.9918338576856295e-05,
      "loss": 0.3112,
      "step": 200
    },
    {
      "epoch": 0.02062848105617823,
      "grad_norm": 0.15404854714870453,
      "learning_rate": 4.9875358880464876e-05,
      "loss": 0.2006,
      "step": 300
    },
    {
      "epoch": 0.02750464140823764,
      "grad_norm": 0.12076938152313232,
      "learning_rate": 4.983237918407345e-05,
      "loss": 0.162,
      "step": 400
    },
    {
      "epoch": 0.03438080176029705,
      "grad_norm": 0.10199097543954849,
      "learning_rate": 4.978939948768202e-05,
      "loss": 0.1436,
      "step": 500
    },
    {
      "epoch": 0.04125696211235646,
      "grad_norm": 0.12249921262264252,
      "learning_rate": 4.97464197912906e-05,
      "loss": 0.1401,
      "step": 600
    },
    {
      "epoch": 0.04813312246441587,
      "grad_norm": 0.1016814261674881,
      "learning_rate": 4.970344009489917e-05,
      "loss": 0.1371,
      "step": 700
    },
    {
      "epoch": 0.05500928281647528,
      "grad_norm": 0.10480780154466629,
      "learning_rate": 4.9660460398507745e-05,
      "loss": 0.1334,
      "step": 800
    },
    {
      "epoch": 0.06188544316853469,
      "grad_norm": 0.08576846867799759,
      "learning_rate": 4.961748070211632e-05,
      "loss": 0.1333,
      "step": 900
    },
    {
      "epoch": 0.0687616035205941,
      "grad_norm": 0.11806758493185043,
      "learning_rate": 4.95745010057249e-05,
      "loss": 0.1325,
      "step": 1000
    },
    {
      "epoch": 0.07563776387265352,
      "grad_norm": 0.10391774773597717,
      "learning_rate": 4.9531521309333474e-05,
      "loss": 0.1344,
      "step": 1100
    },
    {
      "epoch": 0.08251392422471292,
      "grad_norm": 0.10070917010307312,
      "learning_rate": 4.948854161294205e-05,
      "loss": 0.1325,
      "step": 1200
    },
    {
      "epoch": 0.08939008457677233,
      "grad_norm": 0.1160920113325119,
      "learning_rate": 4.944556191655063e-05,
      "loss": 0.1342,
      "step": 1300
    },
    {
      "epoch": 0.09626624492883173,
      "grad_norm": 0.09114602208137512,
      "learning_rate": 4.94025822201592e-05,
      "loss": 0.1354,
      "step": 1400
    },
    {
      "epoch": 0.10314240528089115,
      "grad_norm": 0.08890243619680405,
      "learning_rate": 4.9359602523767776e-05,
      "loss": 0.1334,
      "step": 1500
    },
    {
      "epoch": 0.11001856563295057,
      "grad_norm": 0.1021142452955246,
      "learning_rate": 4.931662282737635e-05,
      "loss": 0.1305,
      "step": 1600
    },
    {
      "epoch": 0.11689472598500997,
      "grad_norm": 0.08131574839353561,
      "learning_rate": 4.9273643130984924e-05,
      "loss": 0.1336,
      "step": 1700
    },
    {
      "epoch": 0.12377088633706938,
      "grad_norm": 0.10344178974628448,
      "learning_rate": 4.92306634345935e-05,
      "loss": 0.1338,
      "step": 1800
    },
    {
      "epoch": 0.1306470466891288,
      "grad_norm": 0.11446978896856308,
      "learning_rate": 4.918768373820208e-05,
      "loss": 0.1314,
      "step": 1900
    },
    {
      "epoch": 0.1375232070411882,
      "grad_norm": 0.07354670763015747,
      "learning_rate": 4.914470404181065e-05,
      "loss": 0.1303,
      "step": 2000
    },
    {
      "epoch": 0.1443993673932476,
      "grad_norm": 0.09738998860120773,
      "learning_rate": 4.9101724345419226e-05,
      "loss": 0.1312,
      "step": 2100
    },
    {
      "epoch": 0.15127552774530703,
      "grad_norm": 0.07699208706617355,
      "learning_rate": 4.90587446490278e-05,
      "loss": 0.1304,
      "step": 2200
    },
    {
      "epoch": 0.15815168809736643,
      "grad_norm": 0.1024329662322998,
      "learning_rate": 4.901576495263638e-05,
      "loss": 0.1319,
      "step": 2300
    },
    {
      "epoch": 0.16502784844942583,
      "grad_norm": 0.08973785489797592,
      "learning_rate": 4.8972785256244955e-05,
      "loss": 0.1308,
      "step": 2400
    },
    {
      "epoch": 0.17190400880148526,
      "grad_norm": 0.08133155107498169,
      "learning_rate": 4.892980555985353e-05,
      "loss": 0.1272,
      "step": 2500
    },
    {
      "epoch": 0.17878016915354467,
      "grad_norm": 0.12324642390012741,
      "learning_rate": 4.88868258634621e-05,
      "loss": 0.1316,
      "step": 2600
    },
    {
      "epoch": 0.18565632950560407,
      "grad_norm": 0.10440349578857422,
      "learning_rate": 4.8843846167070677e-05,
      "loss": 0.1291,
      "step": 2700
    },
    {
      "epoch": 0.19253248985766347,
      "grad_norm": 0.10321274399757385,
      "learning_rate": 4.880086647067925e-05,
      "loss": 0.1303,
      "step": 2800
    },
    {
      "epoch": 0.1994086502097229,
      "grad_norm": 0.12795084714889526,
      "learning_rate": 4.875788677428783e-05,
      "loss": 0.1297,
      "step": 2900
    },
    {
      "epoch": 0.2062848105617823,
      "grad_norm": 0.09647592902183533,
      "learning_rate": 4.871533687486032e-05,
      "loss": 0.1281,
      "step": 3000
    },
    {
      "epoch": 0.2131609709138417,
      "grad_norm": 0.13613474369049072,
      "learning_rate": 4.8672357178468894e-05,
      "loss": 0.1276,
      "step": 3100
    },
    {
      "epoch": 0.22003713126590113,
      "grad_norm": 0.1300554871559143,
      "learning_rate": 4.862937748207747e-05,
      "loss": 0.1281,
      "step": 3200
    },
    {
      "epoch": 0.22691329161796053,
      "grad_norm": 0.10659209638834,
      "learning_rate": 4.858639778568604e-05,
      "loss": 0.1261,
      "step": 3300
    },
    {
      "epoch": 0.23378945197001993,
      "grad_norm": 0.10762561857700348,
      "learning_rate": 4.8543418089294616e-05,
      "loss": 0.1279,
      "step": 3400
    },
    {
      "epoch": 0.24066561232207936,
      "grad_norm": 0.0853533148765564,
      "learning_rate": 4.8500438392903197e-05,
      "loss": 0.1242,
      "step": 3500
    },
    {
      "epoch": 0.24754177267413877,
      "grad_norm": 0.24375949800014496,
      "learning_rate": 4.845745869651177e-05,
      "loss": 0.1233,
      "step": 3600
    },
    {
      "epoch": 0.2544179330261982,
      "grad_norm": 0.11399756371974945,
      "learning_rate": 4.8414479000120344e-05,
      "loss": 0.1213,
      "step": 3700
    },
    {
      "epoch": 0.2612940933782576,
      "grad_norm": 0.11883140355348587,
      "learning_rate": 4.8371499303728925e-05,
      "loss": 0.1215,
      "step": 3800
    },
    {
      "epoch": 0.268170253730317,
      "grad_norm": 0.1463688164949417,
      "learning_rate": 4.83285196073375e-05,
      "loss": 0.1231,
      "step": 3900
    },
    {
      "epoch": 0.2750464140823764,
      "grad_norm": 0.09246113896369934,
      "learning_rate": 4.828553991094607e-05,
      "loss": 0.1202,
      "step": 4000
    },
    {
      "epoch": 0.2819225744344358,
      "grad_norm": 0.0958087369799614,
      "learning_rate": 4.824256021455465e-05,
      "loss": 0.1203,
      "step": 4100
    },
    {
      "epoch": 0.2887987347864952,
      "grad_norm": 0.17706726491451263,
      "learning_rate": 4.819958051816322e-05,
      "loss": 0.1183,
      "step": 4200
    },
    {
      "epoch": 0.2956748951385546,
      "grad_norm": 0.15634094178676605,
      "learning_rate": 4.8156600821771795e-05,
      "loss": 0.1159,
      "step": 4300
    },
    {
      "epoch": 0.30255105549061406,
      "grad_norm": 0.14165998995304108,
      "learning_rate": 4.811362112538037e-05,
      "loss": 0.1166,
      "step": 4400
    },
    {
      "epoch": 0.30942721584267346,
      "grad_norm": 0.13535352051258087,
      "learning_rate": 4.807064142898895e-05,
      "loss": 0.1155,
      "step": 4500
    },
    {
      "epoch": 0.31630337619473287,
      "grad_norm": 0.11801252514123917,
      "learning_rate": 4.802766173259752e-05,
      "loss": 0.1148,
      "step": 4600
    },
    {
      "epoch": 0.32317953654679227,
      "grad_norm": 0.12324301898479462,
      "learning_rate": 4.79846820362061e-05,
      "loss": 0.1136,
      "step": 4700
    },
    {
      "epoch": 0.33005569689885167,
      "grad_norm": 0.097643181681633,
      "learning_rate": 4.794170233981468e-05,
      "loss": 0.1131,
      "step": 4800
    },
    {
      "epoch": 0.33693185725091107,
      "grad_norm": 0.13105766475200653,
      "learning_rate": 4.789872264342325e-05,
      "loss": 0.1113,
      "step": 4900
    },
    {
      "epoch": 0.34380801760297053,
      "grad_norm": 0.16803021728992462,
      "learning_rate": 4.7856172743995734e-05,
      "loss": 0.1118,
      "step": 5000
    },
    {
      "epoch": 0.35068417795502993,
      "grad_norm": 0.14695677161216736,
      "learning_rate": 4.7813193047604315e-05,
      "loss": 0.1101,
      "step": 5100
    },
    {
      "epoch": 0.35756033830708933,
      "grad_norm": 0.140085831284523,
      "learning_rate": 4.777021335121289e-05,
      "loss": 0.111,
      "step": 5200
    },
    {
      "epoch": 0.36443649865914873,
      "grad_norm": 0.10465002804994583,
      "learning_rate": 4.772723365482146e-05,
      "loss": 0.1102,
      "step": 5300
    },
    {
      "epoch": 0.37131265901120813,
      "grad_norm": 0.1764952838420868,
      "learning_rate": 4.768425395843004e-05,
      "loss": 0.1105,
      "step": 5400
    },
    {
      "epoch": 0.37818881936326754,
      "grad_norm": 0.21449372172355652,
      "learning_rate": 4.764127426203862e-05,
      "loss": 0.1068,
      "step": 5500
    },
    {
      "epoch": 0.38506497971532694,
      "grad_norm": 0.13906441628932953,
      "learning_rate": 4.759829456564719e-05,
      "loss": 0.1059,
      "step": 5600
    },
    {
      "epoch": 0.3919411400673864,
      "grad_norm": 0.17571081221103668,
      "learning_rate": 4.7555314869255765e-05,
      "loss": 0.1059,
      "step": 5700
    },
    {
      "epoch": 0.3988173004194458,
      "grad_norm": 0.1393422782421112,
      "learning_rate": 4.751233517286434e-05,
      "loss": 0.1074,
      "step": 5800
    },
    {
      "epoch": 0.4056934607715052,
      "grad_norm": 0.1707332879304886,
      "learning_rate": 4.746935547647291e-05,
      "loss": 0.107,
      "step": 5900
    },
    {
      "epoch": 0.4125696211235646,
      "grad_norm": 0.13714270293712616,
      "learning_rate": 4.742637578008149e-05,
      "loss": 0.1045,
      "step": 6000
    },
    {
      "epoch": 0.419445781475624,
      "grad_norm": 0.10416944324970245,
      "learning_rate": 4.738382588065398e-05,
      "loss": 0.1025,
      "step": 6100
    },
    {
      "epoch": 0.4263219418276834,
      "grad_norm": 0.14284661412239075,
      "learning_rate": 4.7340846184262556e-05,
      "loss": 0.0996,
      "step": 6200
    },
    {
      "epoch": 0.4331981021797428,
      "grad_norm": 0.15305180847644806,
      "learning_rate": 4.729786648787114e-05,
      "loss": 0.1002,
      "step": 6300
    },
    {
      "epoch": 0.44007426253180226,
      "grad_norm": 0.16472774744033813,
      "learning_rate": 4.725488679147971e-05,
      "loss": 0.0988,
      "step": 6400
    },
    {
      "epoch": 0.44695042288386166,
      "grad_norm": 0.28733450174331665,
      "learning_rate": 4.721190709508828e-05,
      "loss": 0.1003,
      "step": 6500
    },
    {
      "epoch": 0.45382658323592107,
      "grad_norm": 0.1484164148569107,
      "learning_rate": 4.716892739869686e-05,
      "loss": 0.1,
      "step": 6600
    },
    {
      "epoch": 0.46070274358798047,
      "grad_norm": 0.1221017986536026,
      "learning_rate": 4.712594770230543e-05,
      "loss": 0.0992,
      "step": 6700
    },
    {
      "epoch": 0.46757890394003987,
      "grad_norm": 0.1492253839969635,
      "learning_rate": 4.7082968005914007e-05,
      "loss": 0.1026,
      "step": 6800
    },
    {
      "epoch": 0.47445506429209927,
      "grad_norm": 0.12931987643241882,
      "learning_rate": 4.703998830952258e-05,
      "loss": 0.0979,
      "step": 6900
    },
    {
      "epoch": 0.48133122464415873,
      "grad_norm": 0.13471929728984833,
      "learning_rate": 4.699700861313116e-05,
      "loss": 0.0975,
      "step": 7000
    },
    {
      "epoch": 0.48820738499621813,
      "grad_norm": 0.20965610444545746,
      "learning_rate": 4.6954028916739735e-05,
      "loss": 0.0979,
      "step": 7100
    },
    {
      "epoch": 0.49508354534827753,
      "grad_norm": 0.18931537866592407,
      "learning_rate": 4.691104922034831e-05,
      "loss": 0.0969,
      "step": 7200
    },
    {
      "epoch": 0.5019597057003369,
      "grad_norm": 0.1526222974061966,
      "learning_rate": 4.686806952395689e-05,
      "loss": 0.095,
      "step": 7300
    },
    {
      "epoch": 0.5088358660523964,
      "grad_norm": 0.19604451954364777,
      "learning_rate": 4.6825089827565464e-05,
      "loss": 0.0953,
      "step": 7400
    },
    {
      "epoch": 0.5157120264044558,
      "grad_norm": 0.19090388715267181,
      "learning_rate": 4.678211013117403e-05,
      "loss": 0.0946,
      "step": 7500
    },
    {
      "epoch": 0.5225881867565152,
      "grad_norm": 0.23292556405067444,
      "learning_rate": 4.673913043478261e-05,
      "loss": 0.0972,
      "step": 7600
    },
    {
      "epoch": 0.5294643471085746,
      "grad_norm": 0.16372673213481903,
      "learning_rate": 4.6696150738391185e-05,
      "loss": 0.093,
      "step": 7700
    },
    {
      "epoch": 0.536340507460634,
      "grad_norm": 0.20450519025325775,
      "learning_rate": 4.665317104199976e-05,
      "loss": 0.0992,
      "step": 7800
    },
    {
      "epoch": 0.5432166678126934,
      "grad_norm": 0.1633414328098297,
      "learning_rate": 4.661019134560834e-05,
      "loss": 0.0933,
      "step": 7900
    },
    {
      "epoch": 0.5500928281647528,
      "grad_norm": 0.15958021581172943,
      "learning_rate": 4.6567211649216914e-05,
      "loss": 0.0935,
      "step": 8000
    },
    {
      "epoch": 0.5569689885168122,
      "grad_norm": 0.09867032617330551,
      "learning_rate": 4.652423195282549e-05,
      "loss": 0.0907,
      "step": 8100
    },
    {
      "epoch": 0.5638451488688716,
      "grad_norm": 0.20047171413898468,
      "learning_rate": 4.648125225643406e-05,
      "loss": 0.0923,
      "step": 8200
    },
    {
      "epoch": 0.570721309220931,
      "grad_norm": 0.15371744334697723,
      "learning_rate": 4.643827256004264e-05,
      "loss": 0.0902,
      "step": 8300
    },
    {
      "epoch": 0.5775974695729904,
      "grad_norm": 0.33365970849990845,
      "learning_rate": 4.6395292863651216e-05,
      "loss": 0.0916,
      "step": 8400
    },
    {
      "epoch": 0.5844736299250498,
      "grad_norm": 0.20536164939403534,
      "learning_rate": 4.635231316725978e-05,
      "loss": 0.0918,
      "step": 8500
    },
    {
      "epoch": 0.5913497902771092,
      "grad_norm": 0.16517622768878937,
      "learning_rate": 4.6309333470868364e-05,
      "loss": 0.0907,
      "step": 8600
    },
    {
      "epoch": 0.5982259506291687,
      "grad_norm": 0.16698306798934937,
      "learning_rate": 4.626635377447694e-05,
      "loss": 0.0897,
      "step": 8700
    },
    {
      "epoch": 0.6051021109812281,
      "grad_norm": 0.2174324095249176,
      "learning_rate": 4.622337407808551e-05,
      "loss": 0.0895,
      "step": 8800
    },
    {
      "epoch": 0.6119782713332875,
      "grad_norm": 0.39089152216911316,
      "learning_rate": 4.618039438169409e-05,
      "loss": 0.0904,
      "step": 8900
    },
    {
      "epoch": 0.6188544316853469,
      "grad_norm": 0.21284592151641846,
      "learning_rate": 4.6137414685302666e-05,
      "loss": 0.0892,
      "step": 9000
    },
    {
      "epoch": 0.6257305920374063,
      "grad_norm": 0.283803254365921,
      "learning_rate": 4.609443498891124e-05,
      "loss": 0.0886,
      "step": 9100
    },
    {
      "epoch": 0.6326067523894657,
      "grad_norm": 0.36548087000846863,
      "learning_rate": 4.605145529251982e-05,
      "loss": 0.0922,
      "step": 9200
    },
    {
      "epoch": 0.6394829127415251,
      "grad_norm": 0.26133817434310913,
      "learning_rate": 4.6008475596128395e-05,
      "loss": 0.0889,
      "step": 9300
    },
    {
      "epoch": 0.6463590730935845,
      "grad_norm": 0.1921788454055786,
      "learning_rate": 4.596549589973697e-05,
      "loss": 0.085,
      "step": 9400
    },
    {
      "epoch": 0.6532352334456439,
      "grad_norm": 0.15109072625637054,
      "learning_rate": 4.5922516203345536e-05,
      "loss": 0.0882,
      "step": 9500
    },
    {
      "epoch": 0.6601113937977033,
      "grad_norm": 0.2814554274082184,
      "learning_rate": 4.587953650695412e-05,
      "loss": 0.0865,
      "step": 9600
    },
    {
      "epoch": 0.6669875541497627,
      "grad_norm": 0.1455131471157074,
      "learning_rate": 4.583655681056269e-05,
      "loss": 0.0867,
      "step": 9700
    },
    {
      "epoch": 0.6738637145018221,
      "grad_norm": 0.352204829454422,
      "learning_rate": 4.5793577114171265e-05,
      "loss": 0.0845,
      "step": 9800
    },
    {
      "epoch": 0.6807398748538815,
      "grad_norm": 0.32636818289756775,
      "learning_rate": 4.5750597417779845e-05,
      "loss": 0.0832,
      "step": 9900
    },
    {
      "epoch": 0.6876160352059411,
      "grad_norm": 0.2455734759569168,
      "learning_rate": 4.570761772138842e-05,
      "loss": 0.085,
      "step": 10000
    },
    {
      "epoch": 0.6944921955580005,
      "grad_norm": 0.16262048482894897,
      "learning_rate": 4.566463802499699e-05,
      "loss": 0.0869,
      "step": 10100
    },
    {
      "epoch": 0.7013683559100599,
      "grad_norm": 0.21784892678260803,
      "learning_rate": 4.5621658328605574e-05,
      "loss": 0.0858,
      "step": 10200
    },
    {
      "epoch": 0.7082445162621193,
      "grad_norm": 0.211098775267601,
      "learning_rate": 4.557867863221415e-05,
      "loss": 0.0829,
      "step": 10300
    },
    {
      "epoch": 0.7151206766141787,
      "grad_norm": 0.2394261509180069,
      "learning_rate": 4.553569893582272e-05,
      "loss": 0.0838,
      "step": 10400
    },
    {
      "epoch": 0.7219968369662381,
      "grad_norm": 0.1414715200662613,
      "learning_rate": 4.5492719239431295e-05,
      "loss": 0.083,
      "step": 10500
    },
    {
      "epoch": 0.7288729973182975,
      "grad_norm": 0.3307701647281647,
      "learning_rate": 4.544973954303987e-05,
      "loss": 0.0852,
      "step": 10600
    },
    {
      "epoch": 0.7357491576703569,
      "grad_norm": 0.2696862518787384,
      "learning_rate": 4.540675984664844e-05,
      "loss": 0.0794,
      "step": 10700
    },
    {
      "epoch": 0.7426253180224163,
      "grad_norm": 0.25416213274002075,
      "learning_rate": 4.536420994722094e-05,
      "loss": 0.0826,
      "step": 10800
    },
    {
      "epoch": 0.7495014783744757,
      "grad_norm": 0.33287596702575684,
      "learning_rate": 4.532123025082951e-05,
      "loss": 0.0842,
      "step": 10900
    },
    {
      "epoch": 0.7563776387265351,
      "grad_norm": 0.2544245719909668,
      "learning_rate": 4.527825055443809e-05,
      "loss": 0.0815,
      "step": 11000
    },
    {
      "epoch": 0.7632537990785945,
      "grad_norm": 0.15972641110420227,
      "learning_rate": 4.523527085804666e-05,
      "loss": 0.0813,
      "step": 11100
    },
    {
      "epoch": 0.7701299594306539,
      "grad_norm": 0.28968802094459534,
      "learning_rate": 4.5192291161655235e-05,
      "loss": 0.0806,
      "step": 11200
    },
    {
      "epoch": 0.7770061197827133,
      "grad_norm": 0.25137752294540405,
      "learning_rate": 4.514931146526381e-05,
      "loss": 0.0804,
      "step": 11300
    },
    {
      "epoch": 0.7838822801347728,
      "grad_norm": 0.25998014211654663,
      "learning_rate": 4.510633176887238e-05,
      "loss": 0.0824,
      "step": 11400
    },
    {
      "epoch": 0.7907584404868322,
      "grad_norm": 0.15390481054782867,
      "learning_rate": 4.506335207248096e-05,
      "loss": 0.0808,
      "step": 11500
    },
    {
      "epoch": 0.7976346008388916,
      "grad_norm": 0.3035992383956909,
      "learning_rate": 4.502037237608954e-05,
      "loss": 0.0813,
      "step": 11600
    },
    {
      "epoch": 0.804510761190951,
      "grad_norm": 0.2381909042596817,
      "learning_rate": 4.497739267969811e-05,
      "loss": 0.0798,
      "step": 11700
    },
    {
      "epoch": 0.8113869215430104,
      "grad_norm": 0.19182348251342773,
      "learning_rate": 4.493441298330669e-05,
      "loss": 0.0801,
      "step": 11800
    },
    {
      "epoch": 0.8182630818950698,
      "grad_norm": 0.4209042489528656,
      "learning_rate": 4.4891433286915266e-05,
      "loss": 0.0792,
      "step": 11900
    },
    {
      "epoch": 0.8251392422471292,
      "grad_norm": 0.2318972647190094,
      "learning_rate": 4.484845359052384e-05,
      "loss": 0.0819,
      "step": 12000
    },
    {
      "epoch": 0.8320154025991886,
      "grad_norm": 0.22141744196414948,
      "learning_rate": 4.4805473894132414e-05,
      "loss": 0.0801,
      "step": 12100
    },
    {
      "epoch": 0.838891562951248,
      "grad_norm": 0.6072866320610046,
      "learning_rate": 4.476249419774099e-05,
      "loss": 0.0778,
      "step": 12200
    },
    {
      "epoch": 0.8457677233033074,
      "grad_norm": 0.16170765459537506,
      "learning_rate": 4.471951450134956e-05,
      "loss": 0.0759,
      "step": 12300
    },
    {
      "epoch": 0.8526438836553668,
      "grad_norm": 0.27822238206863403,
      "learning_rate": 4.467653480495814e-05,
      "loss": 0.0769,
      "step": 12400
    },
    {
      "epoch": 0.8595200440074262,
      "grad_norm": 0.17139796912670135,
      "learning_rate": 4.4633555108566716e-05,
      "loss": 0.0773,
      "step": 12500
    },
    {
      "epoch": 0.8663962043594856,
      "grad_norm": 0.3242327868938446,
      "learning_rate": 4.459057541217529e-05,
      "loss": 0.0785,
      "step": 12600
    },
    {
      "epoch": 0.8732723647115451,
      "grad_norm": 0.21692684292793274,
      "learning_rate": 4.454759571578387e-05,
      "loss": 0.0788,
      "step": 12700
    },
    {
      "epoch": 0.8801485250636045,
      "grad_norm": 0.3352234959602356,
      "learning_rate": 4.4504616019392444e-05,
      "loss": 0.0788,
      "step": 12800
    },
    {
      "epoch": 0.8870246854156639,
      "grad_norm": 0.2884388566017151,
      "learning_rate": 4.446163632300102e-05,
      "loss": 0.0799,
      "step": 12900
    },
    {
      "epoch": 0.8939008457677233,
      "grad_norm": 0.2713114321231842,
      "learning_rate": 4.441865662660959e-05,
      "loss": 0.0769,
      "step": 13000
    },
    {
      "epoch": 0.9007770061197827,
      "grad_norm": 0.2805975079536438,
      "learning_rate": 4.4375676930218166e-05,
      "loss": 0.0771,
      "step": 13100
    },
    {
      "epoch": 0.9076531664718421,
      "grad_norm": 0.1707334816455841,
      "learning_rate": 4.433269723382674e-05,
      "loss": 0.0772,
      "step": 13200
    },
    {
      "epoch": 0.9145293268239015,
      "grad_norm": 0.2917965352535248,
      "learning_rate": 4.4289717537435314e-05,
      "loss": 0.0767,
      "step": 13300
    },
    {
      "epoch": 0.9214054871759609,
      "grad_norm": 0.22661684453487396,
      "learning_rate": 4.4246737841043895e-05,
      "loss": 0.074,
      "step": 13400
    },
    {
      "epoch": 0.9282816475280203,
      "grad_norm": 0.2407449185848236,
      "learning_rate": 4.420375814465247e-05,
      "loss": 0.076,
      "step": 13500
    },
    {
      "epoch": 0.9351578078800797,
      "grad_norm": 0.18638481199741364,
      "learning_rate": 4.416077844826104e-05,
      "loss": 0.0752,
      "step": 13600
    },
    {
      "epoch": 0.9420339682321391,
      "grad_norm": 0.15642240643501282,
      "learning_rate": 4.411779875186962e-05,
      "loss": 0.0755,
      "step": 13700
    },
    {
      "epoch": 0.9489101285841985,
      "grad_norm": 0.32682913541793823,
      "learning_rate": 4.40748190554782e-05,
      "loss": 0.0745,
      "step": 13800
    },
    {
      "epoch": 0.9557862889362579,
      "grad_norm": 0.2927244305610657,
      "learning_rate": 4.403183935908677e-05,
      "loss": 0.0746,
      "step": 13900
    },
    {
      "epoch": 0.9626624492883175,
      "grad_norm": 0.36352765560150146,
      "learning_rate": 4.3988859662695345e-05,
      "loss": 0.0763,
      "step": 14000
    },
    {
      "epoch": 0.9695386096403769,
      "grad_norm": 0.2725991904735565,
      "learning_rate": 4.394587996630392e-05,
      "loss": 0.0766,
      "step": 14100
    },
    {
      "epoch": 0.9764147699924363,
      "grad_norm": 0.3966827690601349,
      "learning_rate": 4.390290026991249e-05,
      "loss": 0.0747,
      "step": 14200
    },
    {
      "epoch": 0.9832909303444957,
      "grad_norm": 0.30134275555610657,
      "learning_rate": 4.385992057352107e-05,
      "loss": 0.0729,
      "step": 14300
    },
    {
      "epoch": 0.9901670906965551,
      "grad_norm": 0.3184598982334137,
      "learning_rate": 4.381694087712965e-05,
      "loss": 0.0716,
      "step": 14400
    },
    {
      "epoch": 0.9970432510486145,
      "grad_norm": 0.20146863162517548,
      "learning_rate": 4.377396118073822e-05,
      "loss": 0.0747,
      "step": 14500
    },
    {
      "epoch": 1.0,
      "eval_accuracy_macro_0.5": 0.967118501663208,
      "eval_accuracy_micro_0.5": 0.9671184420585632,
      "eval_accuracy_weighted_0.5": 0.9632192850112915,
      "eval_f1_macro_0.5": 0.3363932967185974,
      "eval_f1_macro_0.6": 0.2075342983007431,
      "eval_f1_macro_0.7": 0.10522819310426712,
      "eval_f1_macro_0.8": 0.0,
      "eval_f1_micro_0.5": 0.41184285283088684,
      "eval_f1_micro_0.6": 0.279207706451416,
      "eval_f1_micro_0.7": 0.14301224052906036,
      "eval_f1_micro_0.8": 0.05714136362075806,
      "eval_f1_micro_0.9": 0.0,
      "eval_f1_weighted_0.5": 0.3401452600955963,
      "eval_f1_weighted_0.6": 0.21967944502830505,
      "eval_f1_weighted_0.7": 0.10478268563747406,
      "eval_f1_weighted_0.8": 0.0,
      "eval_loss": 0.07216792553663254,
      "eval_runtime": 291.0086,
      "eval_samples_per_second": 99.781,
      "eval_steps_per_second": 12.474,
      "step": 14543
    },
    {
      "epoch": 1.0039194114006738,
      "grad_norm": 0.31590718030929565,
      "learning_rate": 4.3730981484346795e-05,
      "loss": 0.0726,
      "step": 14600
    },
    {
      "epoch": 1.0107955717527333,
      "grad_norm": 0.19869238138198853,
      "learning_rate": 4.3688001787955376e-05,
      "loss": 0.0726,
      "step": 14700
    },
    {
      "epoch": 1.0176717321047928,
      "grad_norm": 0.18372592329978943,
      "learning_rate": 4.364545188852786e-05,
      "loss": 0.0729,
      "step": 14800
    },
    {
      "epoch": 1.024547892456852,
      "grad_norm": 2.1701979637145996,
      "learning_rate": 4.360247219213643e-05,
      "loss": 0.0717,
      "step": 14900
    },
    {
      "epoch": 1.0314240528089116,
      "grad_norm": 0.17548060417175293,
      "learning_rate": 4.355949249574501e-05,
      "loss": 0.0747,
      "step": 15000
    },
    {
      "epoch": 1.0383002131609709,
      "grad_norm": 0.4524548649787903,
      "learning_rate": 4.35169425963175e-05,
      "loss": 0.0738,
      "step": 15100
    },
    {
      "epoch": 1.0451763735130304,
      "grad_norm": 0.23333673179149628,
      "learning_rate": 4.347396289992608e-05,
      "loss": 0.0712,
      "step": 15200
    },
    {
      "epoch": 1.0520525338650897,
      "grad_norm": 0.311694860458374,
      "learning_rate": 4.3430983203534656e-05,
      "loss": 0.071,
      "step": 15300
    },
    {
      "epoch": 1.0589286942171492,
      "grad_norm": 0.23067790269851685,
      "learning_rate": 4.3388003507143224e-05,
      "loss": 0.0743,
      "step": 15400
    },
    {
      "epoch": 1.0658048545692085,
      "grad_norm": 0.2756853401660919,
      "learning_rate": 4.33450238107518e-05,
      "loss": 0.0728,
      "step": 15500
    },
    {
      "epoch": 1.072681014921268,
      "grad_norm": 0.4602694511413574,
      "learning_rate": 4.330204411436038e-05,
      "loss": 0.0681,
      "step": 15600
    },
    {
      "epoch": 1.0795571752733273,
      "grad_norm": 0.3867562711238861,
      "learning_rate": 4.325906441796895e-05,
      "loss": 0.0733,
      "step": 15700
    },
    {
      "epoch": 1.0864333356253868,
      "grad_norm": 0.21738481521606445,
      "learning_rate": 4.3216084721577526e-05,
      "loss": 0.0722,
      "step": 15800
    },
    {
      "epoch": 1.0933094959774463,
      "grad_norm": 0.24408327043056488,
      "learning_rate": 4.317310502518611e-05,
      "loss": 0.0726,
      "step": 15900
    },
    {
      "epoch": 1.1001856563295056,
      "grad_norm": 0.3430807590484619,
      "learning_rate": 4.313012532879468e-05,
      "loss": 0.072,
      "step": 16000
    },
    {
      "epoch": 1.1070618166815651,
      "grad_norm": 0.2718815505504608,
      "learning_rate": 4.3087145632403254e-05,
      "loss": 0.0685,
      "step": 16100
    },
    {
      "epoch": 1.1139379770336244,
      "grad_norm": 0.2289183884859085,
      "learning_rate": 4.3044165936011835e-05,
      "loss": 0.0696,
      "step": 16200
    },
    {
      "epoch": 1.120814137385684,
      "grad_norm": 0.22514452040195465,
      "learning_rate": 4.300118623962041e-05,
      "loss": 0.0693,
      "step": 16300
    },
    {
      "epoch": 1.1276902977377432,
      "grad_norm": 0.2468690276145935,
      "learning_rate": 4.2958206543228976e-05,
      "loss": 0.0713,
      "step": 16400
    },
    {
      "epoch": 1.1345664580898027,
      "grad_norm": 0.24190033972263336,
      "learning_rate": 4.291522684683756e-05,
      "loss": 0.0701,
      "step": 16500
    },
    {
      "epoch": 1.141442618441862,
      "grad_norm": 0.28342047333717346,
      "learning_rate": 4.287224715044613e-05,
      "loss": 0.0702,
      "step": 16600
    },
    {
      "epoch": 1.1483187787939215,
      "grad_norm": 0.24659477174282074,
      "learning_rate": 4.2829267454054705e-05,
      "loss": 0.0692,
      "step": 16700
    },
    {
      "epoch": 1.1551949391459808,
      "grad_norm": 0.24938136339187622,
      "learning_rate": 4.278628775766328e-05,
      "loss": 0.0703,
      "step": 16800
    },
    {
      "epoch": 1.1620710994980403,
      "grad_norm": 0.4976220726966858,
      "learning_rate": 4.274330806127186e-05,
      "loss": 0.0707,
      "step": 16900
    },
    {
      "epoch": 1.1689472598500996,
      "grad_norm": 0.30299970507621765,
      "learning_rate": 4.270032836488043e-05,
      "loss": 0.0713,
      "step": 17000
    },
    {
      "epoch": 1.1758234202021591,
      "grad_norm": 0.3997788727283478,
      "learning_rate": 4.265734866848901e-05,
      "loss": 0.0711,
      "step": 17100
    },
    {
      "epoch": 1.1826995805542184,
      "grad_norm": 0.37619534134864807,
      "learning_rate": 4.261436897209759e-05,
      "loss": 0.07,
      "step": 17200
    },
    {
      "epoch": 1.189575740906278,
      "grad_norm": 0.4088234007358551,
      "learning_rate": 4.2571389275706155e-05,
      "loss": 0.0709,
      "step": 17300
    },
    {
      "epoch": 1.1964519012583374,
      "grad_norm": 0.2846820652484894,
      "learning_rate": 4.252840957931473e-05,
      "loss": 0.068,
      "step": 17400
    },
    {
      "epoch": 1.2033280616103967,
      "grad_norm": 0.22630348801612854,
      "learning_rate": 4.248542988292331e-05,
      "loss": 0.0701,
      "step": 17500
    },
    {
      "epoch": 1.2102042219624563,
      "grad_norm": 0.3893091678619385,
      "learning_rate": 4.2442450186531883e-05,
      "loss": 0.0695,
      "step": 17600
    },
    {
      "epoch": 1.2170803823145155,
      "grad_norm": 0.30879634618759155,
      "learning_rate": 4.239947049014046e-05,
      "loss": 0.0721,
      "step": 17700
    },
    {
      "epoch": 1.223956542666575,
      "grad_norm": 0.2657661736011505,
      "learning_rate": 4.235649079374904e-05,
      "loss": 0.0682,
      "step": 17800
    },
    {
      "epoch": 1.2308327030186343,
      "grad_norm": 0.28407686948776245,
      "learning_rate": 4.231351109735761e-05,
      "loss": 0.0675,
      "step": 17900
    },
    {
      "epoch": 1.2377088633706939,
      "grad_norm": 0.30028489232063293,
      "learning_rate": 4.2270531400966186e-05,
      "loss": 0.0692,
      "step": 18000
    },
    {
      "epoch": 1.2445850237227531,
      "grad_norm": 0.23945163190364838,
      "learning_rate": 4.222755170457476e-05,
      "loss": 0.0685,
      "step": 18100
    },
    {
      "epoch": 1.2514611840748127,
      "grad_norm": 0.30779725313186646,
      "learning_rate": 4.218457200818334e-05,
      "loss": 0.0689,
      "step": 18200
    },
    {
      "epoch": 1.258337344426872,
      "grad_norm": 0.20421338081359863,
      "learning_rate": 4.214159231179191e-05,
      "loss": 0.0669,
      "step": 18300
    },
    {
      "epoch": 1.2652135047789315,
      "grad_norm": 0.19943936169147491,
      "learning_rate": 4.209861261540048e-05,
      "loss": 0.0661,
      "step": 18400
    },
    {
      "epoch": 1.272089665130991,
      "grad_norm": 0.2881696820259094,
      "learning_rate": 4.205563291900906e-05,
      "loss": 0.0684,
      "step": 18500
    },
    {
      "epoch": 1.2789658254830503,
      "grad_norm": 0.4399412274360657,
      "learning_rate": 4.2012653222617636e-05,
      "loss": 0.0667,
      "step": 18600
    },
    {
      "epoch": 1.2858419858351096,
      "grad_norm": 0.19585523009300232,
      "learning_rate": 4.196967352622621e-05,
      "loss": 0.0655,
      "step": 18700
    },
    {
      "epoch": 1.292718146187169,
      "grad_norm": 0.2389429807662964,
      "learning_rate": 4.192669382983479e-05,
      "loss": 0.0694,
      "step": 18800
    },
    {
      "epoch": 1.2995943065392286,
      "grad_norm": 0.2911076247692108,
      "learning_rate": 4.1883714133443365e-05,
      "loss": 0.066,
      "step": 18900
    },
    {
      "epoch": 1.3064704668912879,
      "grad_norm": 0.29227662086486816,
      "learning_rate": 4.184073443705194e-05,
      "loss": 0.0668,
      "step": 19000
    },
    {
      "epoch": 1.3133466272433474,
      "grad_norm": 0.23533491790294647,
      "learning_rate": 4.179775474066052e-05,
      "loss": 0.0655,
      "step": 19100
    },
    {
      "epoch": 1.3202227875954067,
      "grad_norm": 0.4659481346607208,
      "learning_rate": 4.175477504426909e-05,
      "loss": 0.0713,
      "step": 19200
    },
    {
      "epoch": 1.3270989479474662,
      "grad_norm": 0.3335985243320465,
      "learning_rate": 4.171179534787766e-05,
      "loss": 0.0679,
      "step": 19300
    },
    {
      "epoch": 1.3339751082995255,
      "grad_norm": 0.1980050504207611,
      "learning_rate": 4.166881565148624e-05,
      "loss": 0.0641,
      "step": 19400
    },
    {
      "epoch": 1.340851268651585,
      "grad_norm": 0.4900844097137451,
      "learning_rate": 4.1625835955094815e-05,
      "loss": 0.0671,
      "step": 19500
    },
    {
      "epoch": 1.3477274290036443,
      "grad_norm": 0.4099608361721039,
      "learning_rate": 4.158285625870339e-05,
      "loss": 0.0669,
      "step": 19600
    },
    {
      "epoch": 1.3546035893557038,
      "grad_norm": 0.29569077491760254,
      "learning_rate": 4.153987656231196e-05,
      "loss": 0.0662,
      "step": 19700
    },
    {
      "epoch": 1.361479749707763,
      "grad_norm": 0.5161888003349304,
      "learning_rate": 4.1496896865920543e-05,
      "loss": 0.0659,
      "step": 19800
    },
    {
      "epoch": 1.3683559100598226,
      "grad_norm": 0.1573789417743683,
      "learning_rate": 4.145391716952912e-05,
      "loss": 0.0643,
      "step": 19900
    },
    {
      "epoch": 1.3752320704118821,
      "grad_norm": 0.27253973484039307,
      "learning_rate": 4.1411367270101606e-05,
      "loss": 0.0645,
      "step": 20000
    },
    {
      "epoch": 1.3821082307639414,
      "grad_norm": 0.2772437334060669,
      "learning_rate": 4.136838757371018e-05,
      "loss": 0.0656,
      "step": 20100
    },
    {
      "epoch": 1.3889843911160007,
      "grad_norm": 0.25404706597328186,
      "learning_rate": 4.1325407877318754e-05,
      "loss": 0.0658,
      "step": 20200
    },
    {
      "epoch": 1.3958605514680602,
      "grad_norm": 0.2221718430519104,
      "learning_rate": 4.128242818092733e-05,
      "loss": 0.0659,
      "step": 20300
    },
    {
      "epoch": 1.4027367118201197,
      "grad_norm": 0.29563605785369873,
      "learning_rate": 4.123944848453591e-05,
      "loss": 0.0671,
      "step": 20400
    },
    {
      "epoch": 1.409612872172179,
      "grad_norm": 0.2907097637653351,
      "learning_rate": 4.119646878814448e-05,
      "loss": 0.0664,
      "step": 20500
    },
    {
      "epoch": 1.4164890325242385,
      "grad_norm": 0.3745127022266388,
      "learning_rate": 4.115348909175306e-05,
      "loss": 0.0631,
      "step": 20600
    },
    {
      "epoch": 1.4233651928762978,
      "grad_norm": 0.35639458894729614,
      "learning_rate": 4.111050939536164e-05,
      "loss": 0.0686,
      "step": 20700
    },
    {
      "epoch": 1.4302413532283573,
      "grad_norm": 0.25147226452827454,
      "learning_rate": 4.106752969897021e-05,
      "loss": 0.0641,
      "step": 20800
    },
    {
      "epoch": 1.4371175135804166,
      "grad_norm": 0.22569040954113007,
      "learning_rate": 4.1024550002578785e-05,
      "loss": 0.0664,
      "step": 20900
    },
    {
      "epoch": 1.4439936739324761,
      "grad_norm": 0.37598180770874023,
      "learning_rate": 4.098157030618736e-05,
      "loss": 0.0687,
      "step": 21000
    },
    {
      "epoch": 1.4508698342845356,
      "grad_norm": 0.2945687472820282,
      "learning_rate": 4.093859060979593e-05,
      "loss": 0.0681,
      "step": 21100
    },
    {
      "epoch": 1.457745994636595,
      "grad_norm": 0.1816684901714325,
      "learning_rate": 4.089561091340451e-05,
      "loss": 0.0653,
      "step": 21200
    },
    {
      "epoch": 1.4646221549886542,
      "grad_norm": 0.3597780764102936,
      "learning_rate": 4.085263121701309e-05,
      "loss": 0.0654,
      "step": 21300
    },
    {
      "epoch": 1.4714983153407137,
      "grad_norm": 0.30590054392814636,
      "learning_rate": 4.080965152062166e-05,
      "loss": 0.0617,
      "step": 21400
    },
    {
      "epoch": 1.4783744756927732,
      "grad_norm": 0.30267006158828735,
      "learning_rate": 4.0766671824230235e-05,
      "loss": 0.0668,
      "step": 21500
    },
    {
      "epoch": 1.4852506360448325,
      "grad_norm": 0.3549284040927887,
      "learning_rate": 4.072369212783881e-05,
      "loss": 0.065,
      "step": 21600
    },
    {
      "epoch": 1.492126796396892,
      "grad_norm": 0.3153601288795471,
      "learning_rate": 4.068071243144739e-05,
      "loss": 0.0661,
      "step": 21700
    },
    {
      "epoch": 1.4990029567489513,
      "grad_norm": 0.2597208619117737,
      "learning_rate": 4.0637732735055964e-05,
      "loss": 0.0632,
      "step": 21800
    },
    {
      "epoch": 1.5058791171010109,
      "grad_norm": 0.1608840674161911,
      "learning_rate": 4.059475303866454e-05,
      "loss": 0.063,
      "step": 21900
    },
    {
      "epoch": 1.5127552774530701,
      "grad_norm": 0.3212774097919464,
      "learning_rate": 4.055177334227311e-05,
      "loss": 0.0649,
      "step": 22000
    },
    {
      "epoch": 1.5196314378051297,
      "grad_norm": 0.31102055311203003,
      "learning_rate": 4.0508793645881686e-05,
      "loss": 0.0628,
      "step": 22100
    },
    {
      "epoch": 1.5265075981571892,
      "grad_norm": 0.1763499230146408,
      "learning_rate": 4.046581394949026e-05,
      "loss": 0.061,
      "step": 22200
    },
    {
      "epoch": 1.5333837585092485,
      "grad_norm": 0.256102591753006,
      "learning_rate": 4.042283425309884e-05,
      "loss": 0.0636,
      "step": 22300
    },
    {
      "epoch": 1.5402599188613078,
      "grad_norm": 0.6212247610092163,
      "learning_rate": 4.0379854556707414e-05,
      "loss": 0.067,
      "step": 22400
    },
    {
      "epoch": 1.5471360792133673,
      "grad_norm": 0.20510630309581757,
      "learning_rate": 4.033687486031599e-05,
      "loss": 0.0632,
      "step": 22500
    },
    {
      "epoch": 1.5540122395654268,
      "grad_norm": 0.3111613988876343,
      "learning_rate": 4.029389516392457e-05,
      "loss": 0.0625,
      "step": 22600
    },
    {
      "epoch": 1.560888399917486,
      "grad_norm": 0.2308914065361023,
      "learning_rate": 4.025091546753314e-05,
      "loss": 0.0643,
      "step": 22700
    },
    {
      "epoch": 1.5677645602695454,
      "grad_norm": 0.32520243525505066,
      "learning_rate": 4.0207935771141717e-05,
      "loss": 0.065,
      "step": 22800
    },
    {
      "epoch": 1.5746407206216049,
      "grad_norm": 0.23494426906108856,
      "learning_rate": 4.016495607475029e-05,
      "loss": 0.0652,
      "step": 22900
    },
    {
      "epoch": 1.5815168809736644,
      "grad_norm": 0.22465920448303223,
      "learning_rate": 4.0121976378358864e-05,
      "loss": 0.0624,
      "step": 23000
    },
    {
      "epoch": 1.5883930413257237,
      "grad_norm": 0.45014986395835876,
      "learning_rate": 4.007899668196744e-05,
      "loss": 0.0632,
      "step": 23100
    },
    {
      "epoch": 1.595269201677783,
      "grad_norm": 0.3324112594127655,
      "learning_rate": 4.003601698557601e-05,
      "loss": 0.0632,
      "step": 23200
    },
    {
      "epoch": 1.6021453620298427,
      "grad_norm": 0.24731110036373138,
      "learning_rate": 3.999346708614851e-05,
      "loss": 0.0633,
      "step": 23300
    },
    {
      "epoch": 1.609021522381902,
      "grad_norm": 0.3249538540840149,
      "learning_rate": 3.995048738975708e-05,
      "loss": 0.0619,
      "step": 23400
    },
    {
      "epoch": 1.6158976827339613,
      "grad_norm": 0.3929673433303833,
      "learning_rate": 3.9907507693365656e-05,
      "loss": 0.0659,
      "step": 23500
    },
    {
      "epoch": 1.6227738430860208,
      "grad_norm": 0.3529106378555298,
      "learning_rate": 3.986452799697423e-05,
      "loss": 0.0648,
      "step": 23600
    },
    {
      "epoch": 1.6296500034380803,
      "grad_norm": 0.3540194034576416,
      "learning_rate": 3.9821548300582804e-05,
      "loss": 0.0634,
      "step": 23700
    },
    {
      "epoch": 1.6365261637901396,
      "grad_norm": 0.20395636558532715,
      "learning_rate": 3.977856860419138e-05,
      "loss": 0.0633,
      "step": 23800
    },
    {
      "epoch": 1.643402324142199,
      "grad_norm": 0.29817163944244385,
      "learning_rate": 3.973558890779996e-05,
      "loss": 0.0662,
      "step": 23900
    },
    {
      "epoch": 1.6502784844942584,
      "grad_norm": 0.37265992164611816,
      "learning_rate": 3.969260921140853e-05,
      "loss": 0.0643,
      "step": 24000
    },
    {
      "epoch": 1.657154644846318,
      "grad_norm": 0.3632989227771759,
      "learning_rate": 3.9649629515017106e-05,
      "loss": 0.0638,
      "step": 24100
    },
    {
      "epoch": 1.6640308051983772,
      "grad_norm": 0.24782152473926544,
      "learning_rate": 3.960664981862569e-05,
      "loss": 0.0619,
      "step": 24200
    },
    {
      "epoch": 1.6709069655504365,
      "grad_norm": 0.32892748713493347,
      "learning_rate": 3.956367012223426e-05,
      "loss": 0.0622,
      "step": 24300
    },
    {
      "epoch": 1.677783125902496,
      "grad_norm": 0.20331862568855286,
      "learning_rate": 3.9520690425842835e-05,
      "loss": 0.0608,
      "step": 24400
    },
    {
      "epoch": 1.6846592862545555,
      "grad_norm": 0.33554109930992126,
      "learning_rate": 3.947771072945141e-05,
      "loss": 0.061,
      "step": 24500
    },
    {
      "epoch": 1.6915354466066148,
      "grad_norm": 0.37583309412002563,
      "learning_rate": 3.943473103305998e-05,
      "loss": 0.0624,
      "step": 24600
    },
    {
      "epoch": 1.6984116069586743,
      "grad_norm": 0.40116026997566223,
      "learning_rate": 3.9391751336668556e-05,
      "loss": 0.063,
      "step": 24700
    },
    {
      "epoch": 1.7052877673107338,
      "grad_norm": 0.37329521775245667,
      "learning_rate": 3.934877164027713e-05,
      "loss": 0.0633,
      "step": 24800
    },
    {
      "epoch": 1.7121639276627931,
      "grad_norm": 0.3106386661529541,
      "learning_rate": 3.930579194388571e-05,
      "loss": 0.0612,
      "step": 24900
    },
    {
      "epoch": 1.7190400880148524,
      "grad_norm": 0.3175917863845825,
      "learning_rate": 3.9262812247494285e-05,
      "loss": 0.0627,
      "step": 25000
    },
    {
      "epoch": 1.725916248366912,
      "grad_norm": 0.6477707624435425,
      "learning_rate": 3.921983255110286e-05,
      "loss": 0.0632,
      "step": 25100
    },
    {
      "epoch": 1.7327924087189714,
      "grad_norm": 0.2287348061800003,
      "learning_rate": 3.917685285471144e-05,
      "loss": 0.0631,
      "step": 25200
    },
    {
      "epoch": 1.7396685690710307,
      "grad_norm": 0.24253973364830017,
      "learning_rate": 3.913387315832001e-05,
      "loss": 0.0599,
      "step": 25300
    },
    {
      "epoch": 1.74654472942309,
      "grad_norm": 0.21061216294765472,
      "learning_rate": 3.909089346192859e-05,
      "loss": 0.0598,
      "step": 25400
    },
    {
      "epoch": 1.7534208897751495,
      "grad_norm": 0.35644376277923584,
      "learning_rate": 3.904791376553716e-05,
      "loss": 0.0607,
      "step": 25500
    },
    {
      "epoch": 1.760297050127209,
      "grad_norm": 0.35302117466926575,
      "learning_rate": 3.9004934069145735e-05,
      "loss": 0.0612,
      "step": 25600
    },
    {
      "epoch": 1.7671732104792683,
      "grad_norm": 0.3544166386127472,
      "learning_rate": 3.896195437275431e-05,
      "loss": 0.0609,
      "step": 25700
    },
    {
      "epoch": 1.7740493708313276,
      "grad_norm": 0.20006318390369415,
      "learning_rate": 3.891897467636289e-05,
      "loss": 0.063,
      "step": 25800
    },
    {
      "epoch": 1.7809255311833871,
      "grad_norm": 0.2643216550350189,
      "learning_rate": 3.8875994979971464e-05,
      "loss": 0.0629,
      "step": 25900
    },
    {
      "epoch": 1.7878016915354467,
      "grad_norm": 0.40733447670936584,
      "learning_rate": 3.883301528358004e-05,
      "loss": 0.0609,
      "step": 26000
    },
    {
      "epoch": 1.794677851887506,
      "grad_norm": 0.22986508905887604,
      "learning_rate": 3.879003558718861e-05,
      "loss": 0.0619,
      "step": 26100
    },
    {
      "epoch": 1.8015540122395655,
      "grad_norm": 0.32375428080558777,
      "learning_rate": 3.874705589079719e-05,
      "loss": 0.0611,
      "step": 26200
    },
    {
      "epoch": 1.808430172591625,
      "grad_norm": 0.33177196979522705,
      "learning_rate": 3.8704076194405766e-05,
      "loss": 0.0606,
      "step": 26300
    },
    {
      "epoch": 1.8153063329436843,
      "grad_norm": 0.6934763193130493,
      "learning_rate": 3.866109649801434e-05,
      "loss": 0.0616,
      "step": 26400
    },
    {
      "epoch": 1.8221824932957436,
      "grad_norm": 0.2643113136291504,
      "learning_rate": 3.8618116801622914e-05,
      "loss": 0.0651,
      "step": 26500
    },
    {
      "epoch": 1.829058653647803,
      "grad_norm": 0.18280990421772003,
      "learning_rate": 3.857513710523149e-05,
      "loss": 0.0637,
      "step": 26600
    },
    {
      "epoch": 1.8359348139998626,
      "grad_norm": 0.31155791878700256,
      "learning_rate": 3.853215740884006e-05,
      "loss": 0.0619,
      "step": 26700
    },
    {
      "epoch": 1.8428109743519219,
      "grad_norm": 0.4225581884384155,
      "learning_rate": 3.848917771244864e-05,
      "loss": 0.0609,
      "step": 26800
    },
    {
      "epoch": 1.8496871347039812,
      "grad_norm": 0.20449277758598328,
      "learning_rate": 3.8446198016057216e-05,
      "loss": 0.0605,
      "step": 26900
    },
    {
      "epoch": 1.8565632950560407,
      "grad_norm": 0.28260311484336853,
      "learning_rate": 3.840321831966579e-05,
      "loss": 0.0613,
      "step": 27000
    },
    {
      "epoch": 1.8634394554081002,
      "grad_norm": 0.31872889399528503,
      "learning_rate": 3.836023862327437e-05,
      "loss": 0.0594,
      "step": 27100
    },
    {
      "epoch": 1.8703156157601595,
      "grad_norm": 0.4425065219402313,
      "learning_rate": 3.8317258926882945e-05,
      "loss": 0.0603,
      "step": 27200
    },
    {
      "epoch": 1.877191776112219,
      "grad_norm": 0.38628900051116943,
      "learning_rate": 3.827427923049152e-05,
      "loss": 0.0604,
      "step": 27300
    },
    {
      "epoch": 1.8840679364642785,
      "grad_norm": 0.37921851873397827,
      "learning_rate": 3.823172933106401e-05,
      "loss": 0.0619,
      "step": 27400
    },
    {
      "epoch": 1.8909440968163378,
      "grad_norm": 0.28073370456695557,
      "learning_rate": 3.818874963467258e-05,
      "loss": 0.0604,
      "step": 27500
    },
    {
      "epoch": 1.897820257168397,
      "grad_norm": 0.3828907310962677,
      "learning_rate": 3.814619973524507e-05,
      "loss": 0.0604,
      "step": 27600
    },
    {
      "epoch": 1.9046964175204566,
      "grad_norm": 0.18603043258190155,
      "learning_rate": 3.810322003885365e-05,
      "loss": 0.0594,
      "step": 27700
    },
    {
      "epoch": 1.911572577872516,
      "grad_norm": 0.2923184335231781,
      "learning_rate": 3.8060240342462225e-05,
      "loss": 0.0601,
      "step": 27800
    },
    {
      "epoch": 1.9184487382245754,
      "grad_norm": 0.2570328414440155,
      "learning_rate": 3.80172606460708e-05,
      "loss": 0.0619,
      "step": 27900
    },
    {
      "epoch": 1.9253248985766347,
      "grad_norm": 0.2504546046257019,
      "learning_rate": 3.797428094967937e-05,
      "loss": 0.0593,
      "step": 28000
    },
    {
      "epoch": 1.9322010589286942,
      "grad_norm": 0.2272268831729889,
      "learning_rate": 3.793130125328795e-05,
      "loss": 0.0581,
      "step": 28100
    },
    {
      "epoch": 1.9390772192807537,
      "grad_norm": 0.3200293779373169,
      "learning_rate": 3.788832155689652e-05,
      "loss": 0.0642,
      "step": 28200
    },
    {
      "epoch": 1.945953379632813,
      "grad_norm": 0.21948213875293732,
      "learning_rate": 3.78453418605051e-05,
      "loss": 0.0597,
      "step": 28300
    },
    {
      "epoch": 1.9528295399848723,
      "grad_norm": 0.403256893157959,
      "learning_rate": 3.7802362164113676e-05,
      "loss": 0.0608,
      "step": 28400
    },
    {
      "epoch": 1.9597057003369318,
      "grad_norm": 0.37420475482940674,
      "learning_rate": 3.775938246772225e-05,
      "loss": 0.0589,
      "step": 28500
    },
    {
      "epoch": 1.9665818606889913,
      "grad_norm": 0.35587140917778015,
      "learning_rate": 3.771640277133083e-05,
      "loss": 0.0611,
      "step": 28600
    },
    {
      "epoch": 1.9734580210410506,
      "grad_norm": 0.37529081106185913,
      "learning_rate": 3.7673423074939404e-05,
      "loss": 0.0572,
      "step": 28700
    },
    {
      "epoch": 1.9803341813931101,
      "grad_norm": 0.2044173926115036,
      "learning_rate": 3.763044337854798e-05,
      "loss": 0.0607,
      "step": 28800
    },
    {
      "epoch": 1.9872103417451696,
      "grad_norm": 0.23073045909404755,
      "learning_rate": 3.7587463682156545e-05,
      "loss": 0.0613,
      "step": 28900
    },
    {
      "epoch": 1.994086502097229,
      "grad_norm": 0.272026389837265,
      "learning_rate": 3.7544483985765126e-05,
      "loss": 0.0594,
      "step": 29000
    },
    {
      "epoch": 2.0,
      "eval_accuracy_macro_0.5": 0.9726179838180542,
      "eval_accuracy_micro_0.5": 0.9726179242134094,
      "eval_accuracy_weighted_0.5": 0.9691275358200073,
      "eval_f1_macro_0.5": 0.5348020792007446,
      "eval_f1_macro_0.6": 0.4644765853881836,
      "eval_f1_macro_0.7": 0.4011407196521759,
      "eval_f1_macro_0.8": 0.08675143867731094,
      "eval_f1_micro_0.5": 0.5763524770736694,
      "eval_f1_micro_0.6": 0.5190556645393372,
      "eval_f1_micro_0.7": 0.44822558760643005,
      "eval_f1_micro_0.8": 0.31502580642700195,
      "eval_f1_micro_0.9": 0.09655560553073883,
      "eval_f1_weighted_0.5": 0.5285619497299194,
      "eval_f1_weighted_0.6": 0.45116713643074036,
      "eval_f1_weighted_0.7": 0.3824048936367035,
      "eval_f1_weighted_0.8": 0.07264871895313263,
      "eval_loss": 0.057697881013154984,
      "eval_runtime": 290.7418,
      "eval_samples_per_second": 99.872,
      "eval_steps_per_second": 12.485,
      "step": 29086
    },
    {
      "epoch": 2.000962662449288,
      "grad_norm": 0.555939793586731,
      "learning_rate": 3.7501934086337615e-05,
      "loss": 0.0578,
      "step": 29100
    },
    {
      "epoch": 2.0078388228013475,
      "grad_norm": 0.2444874495267868,
      "learning_rate": 3.7458954389946196e-05,
      "loss": 0.0594,
      "step": 29200
    },
    {
      "epoch": 2.0147149831534072,
      "grad_norm": 0.22101067006587982,
      "learning_rate": 3.741597469355477e-05,
      "loss": 0.06,
      "step": 29300
    },
    {
      "epoch": 2.0215911435054665,
      "grad_norm": 0.25738367438316345,
      "learning_rate": 3.737299499716334e-05,
      "loss": 0.0613,
      "step": 29400
    },
    {
      "epoch": 2.028467303857526,
      "grad_norm": 0.4401857554912567,
      "learning_rate": 3.733001530077192e-05,
      "loss": 0.0601,
      "step": 29500
    },
    {
      "epoch": 2.0353434642095856,
      "grad_norm": 0.20908315479755402,
      "learning_rate": 3.728703560438049e-05,
      "loss": 0.056,
      "step": 29600
    },
    {
      "epoch": 2.042219624561645,
      "grad_norm": 0.26146355271339417,
      "learning_rate": 3.7244055907989065e-05,
      "loss": 0.0588,
      "step": 29700
    },
    {
      "epoch": 2.049095784913704,
      "grad_norm": 0.25421154499053955,
      "learning_rate": 3.720107621159764e-05,
      "loss": 0.0583,
      "step": 29800
    },
    {
      "epoch": 2.0559719452657634,
      "grad_norm": 0.228659987449646,
      "learning_rate": 3.715809651520622e-05,
      "loss": 0.0584,
      "step": 29900
    },
    {
      "epoch": 2.062848105617823,
      "grad_norm": 0.47180792689323425,
      "learning_rate": 3.7115116818814794e-05,
      "loss": 0.0562,
      "step": 30000
    },
    {
      "epoch": 2.0697242659698825,
      "grad_norm": 0.35261788964271545,
      "learning_rate": 3.707213712242337e-05,
      "loss": 0.0597,
      "step": 30100
    },
    {
      "epoch": 2.0766004263219418,
      "grad_norm": 0.607873260974884,
      "learning_rate": 3.702915742603195e-05,
      "loss": 0.0601,
      "step": 30200
    },
    {
      "epoch": 2.083476586674001,
      "grad_norm": 0.3318248689174652,
      "learning_rate": 3.698617772964052e-05,
      "loss": 0.0571,
      "step": 30300
    },
    {
      "epoch": 2.0903527470260608,
      "grad_norm": 0.49551206827163696,
      "learning_rate": 3.6943198033249096e-05,
      "loss": 0.0592,
      "step": 30400
    },
    {
      "epoch": 2.09722890737812,
      "grad_norm": 0.40438756346702576,
      "learning_rate": 3.690021833685767e-05,
      "loss": 0.0595,
      "step": 30500
    },
    {
      "epoch": 2.1041050677301794,
      "grad_norm": 0.6586868166923523,
      "learning_rate": 3.6857238640466244e-05,
      "loss": 0.0585,
      "step": 30600
    },
    {
      "epoch": 2.110981228082239,
      "grad_norm": 0.20502087473869324,
      "learning_rate": 3.681425894407482e-05,
      "loss": 0.0613,
      "step": 30700
    },
    {
      "epoch": 2.1178573884342984,
      "grad_norm": 0.39309200644493103,
      "learning_rate": 3.677127924768339e-05,
      "loss": 0.0612,
      "step": 30800
    },
    {
      "epoch": 2.1247335487863577,
      "grad_norm": 0.2846764922142029,
      "learning_rate": 3.672829955129197e-05,
      "loss": 0.0598,
      "step": 30900
    },
    {
      "epoch": 2.131609709138417,
      "grad_norm": 0.45885708928108215,
      "learning_rate": 3.6685319854900546e-05,
      "loss": 0.0594,
      "step": 31000
    },
    {
      "epoch": 2.1384858694904767,
      "grad_norm": 0.5516362190246582,
      "learning_rate": 3.664234015850912e-05,
      "loss": 0.0615,
      "step": 31100
    },
    {
      "epoch": 2.145362029842536,
      "grad_norm": 0.43504607677459717,
      "learning_rate": 3.65993604621177e-05,
      "loss": 0.0569,
      "step": 31200
    },
    {
      "epoch": 2.1522381901945953,
      "grad_norm": 0.5431807041168213,
      "learning_rate": 3.6556380765726275e-05,
      "loss": 0.0578,
      "step": 31300
    },
    {
      "epoch": 2.1591143505466546,
      "grad_norm": 0.28530675172805786,
      "learning_rate": 3.651340106933485e-05,
      "loss": 0.0577,
      "step": 31400
    },
    {
      "epoch": 2.1659905108987143,
      "grad_norm": 0.2492671012878418,
      "learning_rate": 3.647042137294342e-05,
      "loss": 0.0561,
      "step": 31500
    },
    {
      "epoch": 2.1728666712507736,
      "grad_norm": 0.3213369846343994,
      "learning_rate": 3.6427441676551997e-05,
      "loss": 0.0579,
      "step": 31600
    },
    {
      "epoch": 2.179742831602833,
      "grad_norm": 0.17299818992614746,
      "learning_rate": 3.638446198016057e-05,
      "loss": 0.058,
      "step": 31700
    },
    {
      "epoch": 2.1866189919548926,
      "grad_norm": 0.5265032649040222,
      "learning_rate": 3.634148228376915e-05,
      "loss": 0.0529,
      "step": 31800
    },
    {
      "epoch": 2.193495152306952,
      "grad_norm": 0.2918134331703186,
      "learning_rate": 3.6298502587377725e-05,
      "loss": 0.0563,
      "step": 31900
    },
    {
      "epoch": 2.200371312659011,
      "grad_norm": 0.20961813628673553,
      "learning_rate": 3.62555228909863e-05,
      "loss": 0.0556,
      "step": 32000
    },
    {
      "epoch": 2.2072474730110705,
      "grad_norm": 0.21788087487220764,
      "learning_rate": 3.621254319459488e-05,
      "loss": 0.056,
      "step": 32100
    },
    {
      "epoch": 2.2141236333631302,
      "grad_norm": 0.25599101185798645,
      "learning_rate": 3.6169563498203454e-05,
      "loss": 0.0604,
      "step": 32200
    },
    {
      "epoch": 2.2209997937151895,
      "grad_norm": 0.23379595577716827,
      "learning_rate": 3.612658380181203e-05,
      "loss": 0.0555,
      "step": 32300
    },
    {
      "epoch": 2.227875954067249,
      "grad_norm": 0.36744555830955505,
      "learning_rate": 3.60836041054206e-05,
      "loss": 0.055,
      "step": 32400
    },
    {
      "epoch": 2.234752114419308,
      "grad_norm": 0.4635046124458313,
      "learning_rate": 3.6040624409029175e-05,
      "loss": 0.0596,
      "step": 32500
    },
    {
      "epoch": 2.241628274771368,
      "grad_norm": 0.29799312353134155,
      "learning_rate": 3.599764471263775e-05,
      "loss": 0.0579,
      "step": 32600
    },
    {
      "epoch": 2.248504435123427,
      "grad_norm": 0.2918890416622162,
      "learning_rate": 3.595466501624632e-05,
      "loss": 0.057,
      "step": 32700
    },
    {
      "epoch": 2.2553805954754864,
      "grad_norm": 0.21291851997375488,
      "learning_rate": 3.5911685319854904e-05,
      "loss": 0.0569,
      "step": 32800
    },
    {
      "epoch": 2.2622567558275457,
      "grad_norm": 0.3339179754257202,
      "learning_rate": 3.586870562346348e-05,
      "loss": 0.0569,
      "step": 32900
    },
    {
      "epoch": 2.2691329161796054,
      "grad_norm": 0.36134567856788635,
      "learning_rate": 3.582572592707205e-05,
      "loss": 0.0576,
      "step": 33000
    },
    {
      "epoch": 2.2760090765316647,
      "grad_norm": 0.4559621810913086,
      "learning_rate": 3.578274623068063e-05,
      "loss": 0.0554,
      "step": 33100
    },
    {
      "epoch": 2.282885236883724,
      "grad_norm": 0.39836063981056213,
      "learning_rate": 3.5739766534289206e-05,
      "loss": 0.0588,
      "step": 33200
    },
    {
      "epoch": 2.2897613972357833,
      "grad_norm": 0.4515230655670166,
      "learning_rate": 3.569678683789778e-05,
      "loss": 0.0578,
      "step": 33300
    },
    {
      "epoch": 2.296637557587843,
      "grad_norm": 0.47423166036605835,
      "learning_rate": 3.565423693847027e-05,
      "loss": 0.06,
      "step": 33400
    },
    {
      "epoch": 2.3035137179399023,
      "grad_norm": 0.23321136832237244,
      "learning_rate": 3.561125724207884e-05,
      "loss": 0.059,
      "step": 33500
    },
    {
      "epoch": 2.3103898782919616,
      "grad_norm": 0.3427594304084778,
      "learning_rate": 3.556827754568742e-05,
      "loss": 0.0574,
      "step": 33600
    },
    {
      "epoch": 2.3172660386440214,
      "grad_norm": 0.3098748028278351,
      "learning_rate": 3.5525297849296e-05,
      "loss": 0.0559,
      "step": 33700
    },
    {
      "epoch": 2.3241421989960807,
      "grad_norm": 0.23115107417106628,
      "learning_rate": 3.548231815290457e-05,
      "loss": 0.0533,
      "step": 33800
    },
    {
      "epoch": 2.33101835934814,
      "grad_norm": 0.6182118654251099,
      "learning_rate": 3.5439338456513146e-05,
      "loss": 0.0563,
      "step": 33900
    },
    {
      "epoch": 2.3378945197001992,
      "grad_norm": 0.3042629361152649,
      "learning_rate": 3.539635876012172e-05,
      "loss": 0.0566,
      "step": 34000
    },
    {
      "epoch": 2.344770680052259,
      "grad_norm": 0.45751044154167175,
      "learning_rate": 3.535337906373029e-05,
      "loss": 0.0602,
      "step": 34100
    },
    {
      "epoch": 2.3516468404043183,
      "grad_norm": 0.4102898836135864,
      "learning_rate": 3.531082916430278e-05,
      "loss": 0.059,
      "step": 34200
    },
    {
      "epoch": 2.3585230007563776,
      "grad_norm": 0.32996252179145813,
      "learning_rate": 3.526784946791136e-05,
      "loss": 0.0567,
      "step": 34300
    },
    {
      "epoch": 2.365399161108437,
      "grad_norm": 0.48702019453048706,
      "learning_rate": 3.522486977151994e-05,
      "loss": 0.0534,
      "step": 34400
    },
    {
      "epoch": 2.3722753214604966,
      "grad_norm": 0.19351814687252045,
      "learning_rate": 3.518189007512851e-05,
      "loss": 0.0582,
      "step": 34500
    },
    {
      "epoch": 2.379151481812556,
      "grad_norm": 0.21642470359802246,
      "learning_rate": 3.513891037873709e-05,
      "loss": 0.0552,
      "step": 34600
    },
    {
      "epoch": 2.386027642164615,
      "grad_norm": 0.3484146296977997,
      "learning_rate": 3.5095930682345665e-05,
      "loss": 0.058,
      "step": 34700
    },
    {
      "epoch": 2.392903802516675,
      "grad_norm": 0.45817041397094727,
      "learning_rate": 3.505295098595423e-05,
      "loss": 0.0562,
      "step": 34800
    },
    {
      "epoch": 2.399779962868734,
      "grad_norm": 0.44899052381515503,
      "learning_rate": 3.5009971289562807e-05,
      "loss": 0.0555,
      "step": 34900
    },
    {
      "epoch": 2.4066561232207935,
      "grad_norm": 0.6250734925270081,
      "learning_rate": 3.496699159317139e-05,
      "loss": 0.0585,
      "step": 35000
    },
    {
      "epoch": 2.4135322835728528,
      "grad_norm": 0.330614298582077,
      "learning_rate": 3.492401189677996e-05,
      "loss": 0.054,
      "step": 35100
    },
    {
      "epoch": 2.4204084439249125,
      "grad_norm": 0.4274143576622009,
      "learning_rate": 3.4881032200388535e-05,
      "loss": 0.0545,
      "step": 35200
    },
    {
      "epoch": 2.427284604276972,
      "grad_norm": 0.39280375838279724,
      "learning_rate": 3.4838052503997116e-05,
      "loss": 0.0584,
      "step": 35300
    },
    {
      "epoch": 2.434160764629031,
      "grad_norm": 0.37992414832115173,
      "learning_rate": 3.479507280760569e-05,
      "loss": 0.0546,
      "step": 35400
    },
    {
      "epoch": 2.4410369249810904,
      "grad_norm": 0.53380286693573,
      "learning_rate": 3.4752093111214264e-05,
      "loss": 0.0592,
      "step": 35500
    },
    {
      "epoch": 2.44791308533315,
      "grad_norm": 0.45487767457962036,
      "learning_rate": 3.4709113414822844e-05,
      "loss": 0.0593,
      "step": 35600
    },
    {
      "epoch": 2.4547892456852094,
      "grad_norm": 0.38629913330078125,
      "learning_rate": 3.466613371843142e-05,
      "loss": 0.0563,
      "step": 35700
    },
    {
      "epoch": 2.4616654060372687,
      "grad_norm": 0.3671329617500305,
      "learning_rate": 3.4623154022039985e-05,
      "loss": 0.0577,
      "step": 35800
    },
    {
      "epoch": 2.4685415663893284,
      "grad_norm": 0.4861680567264557,
      "learning_rate": 3.4580174325648566e-05,
      "loss": 0.0546,
      "step": 35900
    },
    {
      "epoch": 2.4754177267413877,
      "grad_norm": 0.31135162711143494,
      "learning_rate": 3.453719462925714e-05,
      "loss": 0.0548,
      "step": 36000
    },
    {
      "epoch": 2.482293887093447,
      "grad_norm": 0.3708465099334717,
      "learning_rate": 3.4494214932865714e-05,
      "loss": 0.0559,
      "step": 36100
    },
    {
      "epoch": 2.4891700474455063,
      "grad_norm": 1.1631507873535156,
      "learning_rate": 3.445123523647429e-05,
      "loss": 0.0578,
      "step": 36200
    },
    {
      "epoch": 2.496046207797566,
      "grad_norm": 0.2820110321044922,
      "learning_rate": 3.440825554008287e-05,
      "loss": 0.0546,
      "step": 36300
    },
    {
      "epoch": 2.5029223681496253,
      "grad_norm": 0.24303166568279266,
      "learning_rate": 3.436527584369144e-05,
      "loss": 0.0568,
      "step": 36400
    },
    {
      "epoch": 2.5097985285016846,
      "grad_norm": 0.33737948536872864,
      "learning_rate": 3.4322296147300016e-05,
      "loss": 0.0568,
      "step": 36500
    },
    {
      "epoch": 2.516674688853744,
      "grad_norm": 0.5237900018692017,
      "learning_rate": 3.42793164509086e-05,
      "loss": 0.0563,
      "step": 36600
    },
    {
      "epoch": 2.5235508492058036,
      "grad_norm": 0.27618956565856934,
      "learning_rate": 3.423633675451717e-05,
      "loss": 0.0596,
      "step": 36700
    },
    {
      "epoch": 2.530427009557863,
      "grad_norm": 0.290836900472641,
      "learning_rate": 3.419335705812574e-05,
      "loss": 0.0568,
      "step": 36800
    },
    {
      "epoch": 2.537303169909922,
      "grad_norm": 0.26150578260421753,
      "learning_rate": 3.415037736173432e-05,
      "loss": 0.0583,
      "step": 36900
    },
    {
      "epoch": 2.544179330261982,
      "grad_norm": 0.27536657452583313,
      "learning_rate": 3.410739766534289e-05,
      "loss": 0.0541,
      "step": 37000
    },
    {
      "epoch": 2.5510554906140412,
      "grad_norm": 0.21795186400413513,
      "learning_rate": 3.4064417968951466e-05,
      "loss": 0.0555,
      "step": 37100
    },
    {
      "epoch": 2.5579316509661005,
      "grad_norm": 0.3542826771736145,
      "learning_rate": 3.402143827256005e-05,
      "loss": 0.0554,
      "step": 37200
    },
    {
      "epoch": 2.56480781131816,
      "grad_norm": 0.4369813799858093,
      "learning_rate": 3.397845857616862e-05,
      "loss": 0.0556,
      "step": 37300
    },
    {
      "epoch": 2.571683971670219,
      "grad_norm": 0.46523013710975647,
      "learning_rate": 3.3935478879777195e-05,
      "loss": 0.0561,
      "step": 37400
    },
    {
      "epoch": 2.578560132022279,
      "grad_norm": 0.5469226241111755,
      "learning_rate": 3.389249918338577e-05,
      "loss": 0.059,
      "step": 37500
    },
    {
      "epoch": 2.585436292374338,
      "grad_norm": 0.4256637394428253,
      "learning_rate": 3.384951948699435e-05,
      "loss": 0.0556,
      "step": 37600
    },
    {
      "epoch": 2.5923124527263974,
      "grad_norm": 0.4176403880119324,
      "learning_rate": 3.3806539790602923e-05,
      "loss": 0.0571,
      "step": 37700
    },
    {
      "epoch": 2.599188613078457,
      "grad_norm": 0.2702120244503021,
      "learning_rate": 3.376356009421149e-05,
      "loss": 0.0547,
      "step": 37800
    },
    {
      "epoch": 2.6060647734305165,
      "grad_norm": 0.2907278835773468,
      "learning_rate": 3.372058039782007e-05,
      "loss": 0.055,
      "step": 37900
    },
    {
      "epoch": 2.6129409337825757,
      "grad_norm": 0.3697715401649475,
      "learning_rate": 3.367803049839256e-05,
      "loss": 0.0556,
      "step": 38000
    },
    {
      "epoch": 2.6198170941346355,
      "grad_norm": 0.4930869936943054,
      "learning_rate": 3.363505080200114e-05,
      "loss": 0.0545,
      "step": 38100
    },
    {
      "epoch": 2.6266932544866948,
      "grad_norm": 0.27233242988586426,
      "learning_rate": 3.3592071105609715e-05,
      "loss": 0.0549,
      "step": 38200
    },
    {
      "epoch": 2.633569414838754,
      "grad_norm": 0.2715320289134979,
      "learning_rate": 3.354909140921829e-05,
      "loss": 0.0571,
      "step": 38300
    },
    {
      "epoch": 2.6404455751908134,
      "grad_norm": 0.23217132687568665,
      "learning_rate": 3.350611171282686e-05,
      "loss": 0.0512,
      "step": 38400
    },
    {
      "epoch": 2.6473217355428726,
      "grad_norm": 0.6440960764884949,
      "learning_rate": 3.346313201643544e-05,
      "loss": 0.0541,
      "step": 38500
    },
    {
      "epoch": 2.6541978958949324,
      "grad_norm": 0.373293936252594,
      "learning_rate": 3.342015232004401e-05,
      "loss": 0.0513,
      "step": 38600
    },
    {
      "epoch": 2.6610740562469917,
      "grad_norm": 0.5812636017799377,
      "learning_rate": 3.3377172623652585e-05,
      "loss": 0.0563,
      "step": 38700
    },
    {
      "epoch": 2.667950216599051,
      "grad_norm": 0.34340110421180725,
      "learning_rate": 3.3334192927261165e-05,
      "loss": 0.0576,
      "step": 38800
    },
    {
      "epoch": 2.6748263769511107,
      "grad_norm": 0.4762651324272156,
      "learning_rate": 3.329121323086974e-05,
      "loss": 0.0533,
      "step": 38900
    },
    {
      "epoch": 2.68170253730317,
      "grad_norm": 0.30388543009757996,
      "learning_rate": 3.324823353447831e-05,
      "loss": 0.0545,
      "step": 39000
    },
    {
      "epoch": 2.6885786976552293,
      "grad_norm": 0.316133975982666,
      "learning_rate": 3.3205253838086894e-05,
      "loss": 0.0533,
      "step": 39100
    },
    {
      "epoch": 2.6954548580072886,
      "grad_norm": 0.553942084312439,
      "learning_rate": 3.316227414169547e-05,
      "loss": 0.0538,
      "step": 39200
    },
    {
      "epoch": 2.7023310183593483,
      "grad_norm": 0.25157102942466736,
      "learning_rate": 3.311929444530404e-05,
      "loss": 0.0547,
      "step": 39300
    },
    {
      "epoch": 2.7092071787114076,
      "grad_norm": 0.5132796168327332,
      "learning_rate": 3.3076314748912615e-05,
      "loss": 0.0556,
      "step": 39400
    },
    {
      "epoch": 2.716083339063467,
      "grad_norm": 0.3462388813495636,
      "learning_rate": 3.303333505252119e-05,
      "loss": 0.0545,
      "step": 39500
    },
    {
      "epoch": 2.722959499415526,
      "grad_norm": 0.443263977766037,
      "learning_rate": 3.299035535612976e-05,
      "loss": 0.0557,
      "step": 39600
    },
    {
      "epoch": 2.729835659767586,
      "grad_norm": 0.6478957533836365,
      "learning_rate": 3.294737565973834e-05,
      "loss": 0.0554,
      "step": 39700
    },
    {
      "epoch": 2.736711820119645,
      "grad_norm": 0.49332982301712036,
      "learning_rate": 3.290439596334692e-05,
      "loss": 0.0554,
      "step": 39800
    },
    {
      "epoch": 2.7435879804717045,
      "grad_norm": 0.3399956524372101,
      "learning_rate": 3.286141626695549e-05,
      "loss": 0.0527,
      "step": 39900
    },
    {
      "epoch": 2.7504641408237642,
      "grad_norm": 0.3027910888195038,
      "learning_rate": 3.2818436570564066e-05,
      "loss": 0.0565,
      "step": 40000
    },
    {
      "epoch": 2.7573403011758235,
      "grad_norm": 0.26971426606178284,
      "learning_rate": 3.2775456874172646e-05,
      "loss": 0.0567,
      "step": 40100
    },
    {
      "epoch": 2.764216461527883,
      "grad_norm": 0.6852771043777466,
      "learning_rate": 3.273247717778122e-05,
      "loss": 0.0517,
      "step": 40200
    },
    {
      "epoch": 2.771092621879942,
      "grad_norm": 0.6445386409759521,
      "learning_rate": 3.2689497481389794e-05,
      "loss": 0.0582,
      "step": 40300
    },
    {
      "epoch": 2.7779687822320014,
      "grad_norm": 0.6643605828285217,
      "learning_rate": 3.264651778499837e-05,
      "loss": 0.056,
      "step": 40400
    },
    {
      "epoch": 2.784844942584061,
      "grad_norm": 0.3093867003917694,
      "learning_rate": 3.260353808860694e-05,
      "loss": 0.0563,
      "step": 40500
    },
    {
      "epoch": 2.7917211029361204,
      "grad_norm": 0.19117121398448944,
      "learning_rate": 3.2560558392215516e-05,
      "loss": 0.0563,
      "step": 40600
    },
    {
      "epoch": 2.7985972632881797,
      "grad_norm": 0.3670908510684967,
      "learning_rate": 3.25175786958241e-05,
      "loss": 0.0531,
      "step": 40700
    },
    {
      "epoch": 2.8054734236402394,
      "grad_norm": 0.6280624270439148,
      "learning_rate": 3.247459899943267e-05,
      "loss": 0.0542,
      "step": 40800
    },
    {
      "epoch": 2.8123495839922987,
      "grad_norm": 0.15470802783966064,
      "learning_rate": 3.2431619303041244e-05,
      "loss": 0.0544,
      "step": 40900
    },
    {
      "epoch": 2.819225744344358,
      "grad_norm": 0.2379990816116333,
      "learning_rate": 3.2389069403613734e-05,
      "loss": 0.0542,
      "step": 41000
    },
    {
      "epoch": 2.8261019046964178,
      "grad_norm": 0.2654736340045929,
      "learning_rate": 3.234608970722231e-05,
      "loss": 0.0539,
      "step": 41100
    },
    {
      "epoch": 2.832978065048477,
      "grad_norm": 1.4886003732681274,
      "learning_rate": 3.230311001083088e-05,
      "loss": 0.0567,
      "step": 41200
    },
    {
      "epoch": 2.8398542254005363,
      "grad_norm": 0.3861308693885803,
      "learning_rate": 3.226013031443946e-05,
      "loss": 0.0531,
      "step": 41300
    },
    {
      "epoch": 2.8467303857525956,
      "grad_norm": 0.49089476466178894,
      "learning_rate": 3.2217150618048036e-05,
      "loss": 0.0529,
      "step": 41400
    },
    {
      "epoch": 2.853606546104655,
      "grad_norm": 0.3637150824069977,
      "learning_rate": 3.217417092165661e-05,
      "loss": 0.0517,
      "step": 41500
    },
    {
      "epoch": 2.8604827064567147,
      "grad_norm": 0.2234794795513153,
      "learning_rate": 3.2131191225265184e-05,
      "loss": 0.0548,
      "step": 41600
    },
    {
      "epoch": 2.867358866808774,
      "grad_norm": 0.5304256677627563,
      "learning_rate": 3.2088211528873764e-05,
      "loss": 0.0519,
      "step": 41700
    },
    {
      "epoch": 2.8742350271608332,
      "grad_norm": 0.25185659527778625,
      "learning_rate": 3.204523183248234e-05,
      "loss": 0.0516,
      "step": 41800
    },
    {
      "epoch": 2.881111187512893,
      "grad_norm": 0.5153031945228577,
      "learning_rate": 3.200225213609091e-05,
      "loss": 0.0562,
      "step": 41900
    },
    {
      "epoch": 2.8879873478649523,
      "grad_norm": 0.43327605724334717,
      "learning_rate": 3.1959272439699486e-05,
      "loss": 0.0556,
      "step": 42000
    },
    {
      "epoch": 2.8948635082170115,
      "grad_norm": 0.45909827947616577,
      "learning_rate": 3.191629274330806e-05,
      "loss": 0.0546,
      "step": 42100
    },
    {
      "epoch": 2.9017396685690713,
      "grad_norm": 0.35977238416671753,
      "learning_rate": 3.1873313046916634e-05,
      "loss": 0.0539,
      "step": 42200
    },
    {
      "epoch": 2.9086158289211306,
      "grad_norm": 0.32706964015960693,
      "learning_rate": 3.1830333350525215e-05,
      "loss": 0.0505,
      "step": 42300
    },
    {
      "epoch": 2.91549198927319,
      "grad_norm": 0.37459129095077515,
      "learning_rate": 3.178735365413379e-05,
      "loss": 0.0518,
      "step": 42400
    },
    {
      "epoch": 2.922368149625249,
      "grad_norm": 0.2940053343772888,
      "learning_rate": 3.174437395774236e-05,
      "loss": 0.0537,
      "step": 42500
    },
    {
      "epoch": 2.9292443099773084,
      "grad_norm": 0.2034706026315689,
      "learning_rate": 3.170139426135094e-05,
      "loss": 0.0537,
      "step": 42600
    },
    {
      "epoch": 2.936120470329368,
      "grad_norm": 0.5698168277740479,
      "learning_rate": 3.165841456495952e-05,
      "loss": 0.0537,
      "step": 42700
    },
    {
      "epoch": 2.9429966306814275,
      "grad_norm": 0.17541290819644928,
      "learning_rate": 3.161543486856809e-05,
      "loss": 0.0523,
      "step": 42800
    },
    {
      "epoch": 2.9498727910334868,
      "grad_norm": 0.6961156129837036,
      "learning_rate": 3.1572455172176665e-05,
      "loss": 0.0548,
      "step": 42900
    },
    {
      "epoch": 2.9567489513855465,
      "grad_norm": 0.27944913506507874,
      "learning_rate": 3.152947547578524e-05,
      "loss": 0.0574,
      "step": 43000
    },
    {
      "epoch": 2.963625111737606,
      "grad_norm": 0.33645099401474,
      "learning_rate": 3.148649577939381e-05,
      "loss": 0.0522,
      "step": 43100
    },
    {
      "epoch": 2.970501272089665,
      "grad_norm": 0.14954042434692383,
      "learning_rate": 3.144351608300239e-05,
      "loss": 0.0537,
      "step": 43200
    },
    {
      "epoch": 2.977377432441725,
      "grad_norm": 0.4368475377559662,
      "learning_rate": 3.140053638661097e-05,
      "loss": 0.0522,
      "step": 43300
    },
    {
      "epoch": 2.984253592793784,
      "grad_norm": 0.21278993785381317,
      "learning_rate": 3.135755669021954e-05,
      "loss": 0.0517,
      "step": 43400
    },
    {
      "epoch": 2.9911297531458434,
      "grad_norm": 0.39388564229011536,
      "learning_rate": 3.1314576993828115e-05,
      "loss": 0.0527,
      "step": 43500
    },
    {
      "epoch": 2.9980059134979027,
      "grad_norm": 0.3804696202278137,
      "learning_rate": 3.1271597297436696e-05,
      "loss": 0.0543,
      "step": 43600
    },
    {
      "epoch": 3.0,
      "eval_accuracy_macro_0.5": 0.9749823212623596,
      "eval_accuracy_micro_0.5": 0.9749823212623596,
      "eval_accuracy_weighted_0.5": 0.9716547131538391,
      "eval_f1_macro_0.5": 0.6222599148750305,
      "eval_f1_macro_0.6": 0.5639148354530334,
      "eval_f1_macro_0.7": 0.4815506041049957,
      "eval_f1_macro_0.8": 0.2502806782722473,
      "eval_f1_micro_0.5": 0.6369174122810364,
      "eval_f1_micro_0.6": 0.5937099456787109,
      "eval_f1_micro_0.7": 0.5279672145843506,
      "eval_f1_micro_0.8": 0.4413582682609558,
      "eval_f1_micro_0.9": 0.27875110507011414,
      "eval_f1_weighted_0.5": 0.6103987693786621,
      "eval_f1_weighted_0.6": 0.5490998029708862,
      "eval_f1_weighted_0.7": 0.46322569251060486,
      "eval_f1_weighted_0.8": 0.22278709709644318,
      "eval_loss": 0.05239352211356163,
      "eval_runtime": 290.8635,
      "eval_samples_per_second": 99.83,
      "eval_steps_per_second": 12.48,
      "step": 43629
    },
    {
      "epoch": 3.004882073849962,
      "grad_norm": 0.257719486951828,
      "learning_rate": 3.122904739800918e-05,
      "loss": 0.0545,
      "step": 43700
    },
    {
      "epoch": 3.0117582342020217,
      "grad_norm": 0.4458342492580414,
      "learning_rate": 3.118606770161775e-05,
      "loss": 0.0541,
      "step": 43800
    },
    {
      "epoch": 3.018634394554081,
      "grad_norm": 0.3399268388748169,
      "learning_rate": 3.114308800522633e-05,
      "loss": 0.0504,
      "step": 43900
    },
    {
      "epoch": 3.0255105549061403,
      "grad_norm": 0.27679792046546936,
      "learning_rate": 3.110010830883491e-05,
      "loss": 0.054,
      "step": 44000
    },
    {
      "epoch": 3.0323867152582,
      "grad_norm": 0.2137993425130844,
      "learning_rate": 3.105712861244348e-05,
      "loss": 0.0513,
      "step": 44100
    },
    {
      "epoch": 3.0392628756102593,
      "grad_norm": 0.2648603320121765,
      "learning_rate": 3.101414891605206e-05,
      "loss": 0.0521,
      "step": 44200
    },
    {
      "epoch": 3.0461390359623186,
      "grad_norm": 0.3284968137741089,
      "learning_rate": 3.0971169219660635e-05,
      "loss": 0.054,
      "step": 44300
    },
    {
      "epoch": 3.053015196314378,
      "grad_norm": 0.5185254812240601,
      "learning_rate": 3.092818952326921e-05,
      "loss": 0.0528,
      "step": 44400
    },
    {
      "epoch": 3.0598913566664376,
      "grad_norm": 0.34563055634498596,
      "learning_rate": 3.088520982687779e-05,
      "loss": 0.0524,
      "step": 44500
    },
    {
      "epoch": 3.066767517018497,
      "grad_norm": 0.32221946120262146,
      "learning_rate": 3.0842230130486364e-05,
      "loss": 0.0522,
      "step": 44600
    },
    {
      "epoch": 3.073643677370556,
      "grad_norm": 0.3508049547672272,
      "learning_rate": 3.079925043409493e-05,
      "loss": 0.0544,
      "step": 44700
    },
    {
      "epoch": 3.0805198377226155,
      "grad_norm": 0.4943521022796631,
      "learning_rate": 3.075627073770351e-05,
      "loss": 0.0539,
      "step": 44800
    },
    {
      "epoch": 3.0873959980746752,
      "grad_norm": 0.20209161937236786,
      "learning_rate": 3.0713291041312085e-05,
      "loss": 0.0546,
      "step": 44900
    },
    {
      "epoch": 3.0942721584267345,
      "grad_norm": 0.37468427419662476,
      "learning_rate": 3.067031134492066e-05,
      "loss": 0.0562,
      "step": 45000
    },
    {
      "epoch": 3.101148318778794,
      "grad_norm": 0.4921012818813324,
      "learning_rate": 3.062733164852923e-05,
      "loss": 0.0516,
      "step": 45100
    },
    {
      "epoch": 3.1080244791308536,
      "grad_norm": 0.38985535502433777,
      "learning_rate": 3.0584351952137814e-05,
      "loss": 0.0524,
      "step": 45200
    },
    {
      "epoch": 3.114900639482913,
      "grad_norm": 0.2986833155155182,
      "learning_rate": 3.054137225574639e-05,
      "loss": 0.0528,
      "step": 45300
    },
    {
      "epoch": 3.121776799834972,
      "grad_norm": 0.3127956688404083,
      "learning_rate": 3.0498392559354962e-05,
      "loss": 0.0526,
      "step": 45400
    },
    {
      "epoch": 3.1286529601870314,
      "grad_norm": 0.27097928524017334,
      "learning_rate": 3.045541286296354e-05,
      "loss": 0.0541,
      "step": 45500
    },
    {
      "epoch": 3.135529120539091,
      "grad_norm": 0.31548887491226196,
      "learning_rate": 3.0412433166572113e-05,
      "loss": 0.0519,
      "step": 45600
    },
    {
      "epoch": 3.1424052808911505,
      "grad_norm": 0.38674989342689514,
      "learning_rate": 3.0369453470180687e-05,
      "loss": 0.0521,
      "step": 45700
    },
    {
      "epoch": 3.1492814412432097,
      "grad_norm": 0.4195467531681061,
      "learning_rate": 3.0326473773789264e-05,
      "loss": 0.0538,
      "step": 45800
    },
    {
      "epoch": 3.156157601595269,
      "grad_norm": 0.5345178842544556,
      "learning_rate": 3.0283494077397838e-05,
      "loss": 0.0513,
      "step": 45900
    },
    {
      "epoch": 3.1630337619473288,
      "grad_norm": 0.38973918557167053,
      "learning_rate": 3.0240514381006412e-05,
      "loss": 0.0545,
      "step": 46000
    },
    {
      "epoch": 3.169909922299388,
      "grad_norm": 0.33932673931121826,
      "learning_rate": 3.0197534684614993e-05,
      "loss": 0.0535,
      "step": 46100
    },
    {
      "epoch": 3.1767860826514474,
      "grad_norm": 0.3978631794452667,
      "learning_rate": 3.0154554988223567e-05,
      "loss": 0.0488,
      "step": 46200
    },
    {
      "epoch": 3.1836622430035066,
      "grad_norm": 0.3213846981525421,
      "learning_rate": 3.011157529183214e-05,
      "loss": 0.0525,
      "step": 46300
    },
    {
      "epoch": 3.1905384033555664,
      "grad_norm": 0.36149680614471436,
      "learning_rate": 3.0068595595440714e-05,
      "loss": 0.0506,
      "step": 46400
    },
    {
      "epoch": 3.1974145637076257,
      "grad_norm": 0.39953890442848206,
      "learning_rate": 3.0025615899049292e-05,
      "loss": 0.053,
      "step": 46500
    },
    {
      "epoch": 3.204290724059685,
      "grad_norm": 0.22908933460712433,
      "learning_rate": 2.9982636202657866e-05,
      "loss": 0.0517,
      "step": 46600
    },
    {
      "epoch": 3.2111668844117442,
      "grad_norm": 0.3713325262069702,
      "learning_rate": 2.993965650626644e-05,
      "loss": 0.0532,
      "step": 46700
    },
    {
      "epoch": 3.218043044763804,
      "grad_norm": 0.29389840364456177,
      "learning_rate": 2.9896676809875017e-05,
      "loss": 0.0532,
      "step": 46800
    },
    {
      "epoch": 3.2249192051158633,
      "grad_norm": 0.45856425166130066,
      "learning_rate": 2.985369711348359e-05,
      "loss": 0.0511,
      "step": 46900
    },
    {
      "epoch": 3.2317953654679226,
      "grad_norm": 0.800268828868866,
      "learning_rate": 2.9810717417092165e-05,
      "loss": 0.053,
      "step": 47000
    },
    {
      "epoch": 3.2386715258199823,
      "grad_norm": 0.2707008421421051,
      "learning_rate": 2.9767737720700745e-05,
      "loss": 0.0516,
      "step": 47100
    },
    {
      "epoch": 3.2455476861720416,
      "grad_norm": 0.5213265419006348,
      "learning_rate": 2.972475802430932e-05,
      "loss": 0.0511,
      "step": 47200
    },
    {
      "epoch": 3.252423846524101,
      "grad_norm": 0.4424110949039459,
      "learning_rate": 2.9681778327917893e-05,
      "loss": 0.0539,
      "step": 47300
    },
    {
      "epoch": 3.25930000687616,
      "grad_norm": 0.5703087449073792,
      "learning_rate": 2.963879863152647e-05,
      "loss": 0.0505,
      "step": 47400
    },
    {
      "epoch": 3.26617616722822,
      "grad_norm": 0.47800925374031067,
      "learning_rate": 2.9595818935135044e-05,
      "loss": 0.0494,
      "step": 47500
    },
    {
      "epoch": 3.273052327580279,
      "grad_norm": 0.6335893273353577,
      "learning_rate": 2.9552839238743618e-05,
      "loss": 0.0524,
      "step": 47600
    },
    {
      "epoch": 3.2799284879323385,
      "grad_norm": 0.4678957760334015,
      "learning_rate": 2.9509859542352192e-05,
      "loss": 0.0498,
      "step": 47700
    },
    {
      "epoch": 3.286804648284398,
      "grad_norm": 0.4551332890987396,
      "learning_rate": 2.946687984596077e-05,
      "loss": 0.0526,
      "step": 47800
    },
    {
      "epoch": 3.2936808086364575,
      "grad_norm": 0.4970153272151947,
      "learning_rate": 2.9423900149569343e-05,
      "loss": 0.0511,
      "step": 47900
    },
    {
      "epoch": 3.300556968988517,
      "grad_norm": 0.31020647287368774,
      "learning_rate": 2.9380920453177917e-05,
      "loss": 0.0568,
      "step": 48000
    },
    {
      "epoch": 3.307433129340576,
      "grad_norm": 0.6223040223121643,
      "learning_rate": 2.9337940756786498e-05,
      "loss": 0.0544,
      "step": 48100
    },
    {
      "epoch": 3.314309289692636,
      "grad_norm": 0.3279930055141449,
      "learning_rate": 2.9294961060395072e-05,
      "loss": 0.0502,
      "step": 48200
    },
    {
      "epoch": 3.321185450044695,
      "grad_norm": 0.30995479226112366,
      "learning_rate": 2.9251981364003646e-05,
      "loss": 0.0511,
      "step": 48300
    },
    {
      "epoch": 3.3280616103967544,
      "grad_norm": 0.4355621933937073,
      "learning_rate": 2.9209001667612223e-05,
      "loss": 0.0497,
      "step": 48400
    },
    {
      "epoch": 3.3349377707488137,
      "grad_norm": 0.2686949670314789,
      "learning_rate": 2.9166021971220797e-05,
      "loss": 0.0515,
      "step": 48500
    },
    {
      "epoch": 3.3418139311008734,
      "grad_norm": 0.3371274769306183,
      "learning_rate": 2.912304227482937e-05,
      "loss": 0.0539,
      "step": 48600
    },
    {
      "epoch": 3.3486900914529327,
      "grad_norm": 0.294778436422348,
      "learning_rate": 2.9080062578437948e-05,
      "loss": 0.052,
      "step": 48700
    },
    {
      "epoch": 3.355566251804992,
      "grad_norm": 0.29766616225242615,
      "learning_rate": 2.9037082882046522e-05,
      "loss": 0.0503,
      "step": 48800
    },
    {
      "epoch": 3.3624424121570513,
      "grad_norm": 0.5079801678657532,
      "learning_rate": 2.8994103185655096e-05,
      "loss": 0.0505,
      "step": 48900
    },
    {
      "epoch": 3.369318572509111,
      "grad_norm": 0.20689916610717773,
      "learning_rate": 2.895112348926367e-05,
      "loss": 0.0548,
      "step": 49000
    },
    {
      "epoch": 3.3761947328611703,
      "grad_norm": 0.3376536965370178,
      "learning_rate": 2.8908573589836162e-05,
      "loss": 0.0516,
      "step": 49100
    },
    {
      "epoch": 3.3830708932132296,
      "grad_norm": 0.37990641593933105,
      "learning_rate": 2.8865593893444736e-05,
      "loss": 0.047,
      "step": 49200
    },
    {
      "epoch": 3.3899470535652894,
      "grad_norm": 0.4137129485607147,
      "learning_rate": 2.8822614197053317e-05,
      "loss": 0.0509,
      "step": 49300
    },
    {
      "epoch": 3.3968232139173486,
      "grad_norm": 0.2366722822189331,
      "learning_rate": 2.877963450066189e-05,
      "loss": 0.0538,
      "step": 49400
    },
    {
      "epoch": 3.403699374269408,
      "grad_norm": 0.6310495138168335,
      "learning_rate": 2.873665480427046e-05,
      "loss": 0.0508,
      "step": 49500
    },
    {
      "epoch": 3.4105755346214672,
      "grad_norm": 0.7401272058486938,
      "learning_rate": 2.8693675107879035e-05,
      "loss": 0.0532,
      "step": 49600
    },
    {
      "epoch": 3.417451694973527,
      "grad_norm": 0.48847496509552,
      "learning_rate": 2.8650695411487616e-05,
      "loss": 0.0531,
      "step": 49700
    },
    {
      "epoch": 3.4243278553255863,
      "grad_norm": 0.3821718692779541,
      "learning_rate": 2.860771571509619e-05,
      "loss": 0.0523,
      "step": 49800
    },
    {
      "epoch": 3.4312040156776455,
      "grad_norm": 0.5478968620300293,
      "learning_rate": 2.8564736018704764e-05,
      "loss": 0.0528,
      "step": 49900
    },
    {
      "epoch": 3.438080176029705,
      "grad_norm": 0.2783187925815582,
      "learning_rate": 2.852175632231334e-05,
      "loss": 0.0529,
      "step": 50000
    },
    {
      "epoch": 3.4449563363817646,
      "grad_norm": 0.5416108965873718,
      "learning_rate": 2.8478776625921915e-05,
      "loss": 0.0504,
      "step": 50100
    },
    {
      "epoch": 3.451832496733824,
      "grad_norm": 0.5300498604774475,
      "learning_rate": 2.843579692953049e-05,
      "loss": 0.054,
      "step": 50200
    },
    {
      "epoch": 3.458708657085883,
      "grad_norm": 0.3500445485115051,
      "learning_rate": 2.839281723313907e-05,
      "loss": 0.0538,
      "step": 50300
    },
    {
      "epoch": 3.465584817437943,
      "grad_norm": 0.2168014943599701,
      "learning_rate": 2.8349837536747644e-05,
      "loss": 0.0536,
      "step": 50400
    },
    {
      "epoch": 3.472460977790002,
      "grad_norm": 0.47956952452659607,
      "learning_rate": 2.8306857840356214e-05,
      "loss": 0.0515,
      "step": 50500
    },
    {
      "epoch": 3.4793371381420615,
      "grad_norm": 0.3753385543823242,
      "learning_rate": 2.8263878143964795e-05,
      "loss": 0.0492,
      "step": 50600
    },
    {
      "epoch": 3.4862132984941208,
      "grad_norm": 0.49927714467048645,
      "learning_rate": 2.822132824453728e-05,
      "loss": 0.0546,
      "step": 50700
    },
    {
      "epoch": 3.49308945884618,
      "grad_norm": 0.4725818336009979,
      "learning_rate": 2.8178348548145854e-05,
      "loss": 0.051,
      "step": 50800
    },
    {
      "epoch": 3.49996561919824,
      "grad_norm": 0.356568843126297,
      "learning_rate": 2.8135368851754435e-05,
      "loss": 0.0516,
      "step": 50900
    },
    {
      "epoch": 3.506841779550299,
      "grad_norm": 0.3793630599975586,
      "learning_rate": 2.809238915536301e-05,
      "loss": 0.0495,
      "step": 51000
    },
    {
      "epoch": 3.5137179399023584,
      "grad_norm": 0.5130413174629211,
      "learning_rate": 2.8049409458971583e-05,
      "loss": 0.0514,
      "step": 51100
    },
    {
      "epoch": 3.520594100254418,
      "grad_norm": 0.5646392703056335,
      "learning_rate": 2.800642976258016e-05,
      "loss": 0.0506,
      "step": 51200
    },
    {
      "epoch": 3.5274702606064774,
      "grad_norm": 0.36716973781585693,
      "learning_rate": 2.7963450066188734e-05,
      "loss": 0.0529,
      "step": 51300
    },
    {
      "epoch": 3.5343464209585367,
      "grad_norm": 0.3046954274177551,
      "learning_rate": 2.7920470369797308e-05,
      "loss": 0.0494,
      "step": 51400
    },
    {
      "epoch": 3.5412225813105964,
      "grad_norm": 0.37363192439079285,
      "learning_rate": 2.787749067340589e-05,
      "loss": 0.0508,
      "step": 51500
    },
    {
      "epoch": 3.5480987416626557,
      "grad_norm": 0.4179843068122864,
      "learning_rate": 2.783451097701446e-05,
      "loss": 0.0529,
      "step": 51600
    },
    {
      "epoch": 3.554974902014715,
      "grad_norm": 0.43178364634513855,
      "learning_rate": 2.7791531280623033e-05,
      "loss": 0.0534,
      "step": 51700
    },
    {
      "epoch": 3.5618510623667743,
      "grad_norm": 0.21797339618206024,
      "learning_rate": 2.7748551584231607e-05,
      "loss": 0.0503,
      "step": 51800
    },
    {
      "epoch": 3.5687272227188336,
      "grad_norm": 0.2686239182949066,
      "learning_rate": 2.7705571887840188e-05,
      "loss": 0.052,
      "step": 51900
    },
    {
      "epoch": 3.5756033830708933,
      "grad_norm": 0.35057055950164795,
      "learning_rate": 2.766259219144876e-05,
      "loss": 0.0499,
      "step": 52000
    },
    {
      "epoch": 3.5824795434229526,
      "grad_norm": 0.2514003813266754,
      "learning_rate": 2.7619612495057336e-05,
      "loss": 0.0506,
      "step": 52100
    },
    {
      "epoch": 3.589355703775012,
      "grad_norm": 0.5430564284324646,
      "learning_rate": 2.7576632798665913e-05,
      "loss": 0.0505,
      "step": 52200
    },
    {
      "epoch": 3.5962318641270716,
      "grad_norm": 0.30849653482437134,
      "learning_rate": 2.7533653102274487e-05,
      "loss": 0.0508,
      "step": 52300
    },
    {
      "epoch": 3.603108024479131,
      "grad_norm": 0.5187185406684875,
      "learning_rate": 2.749067340588306e-05,
      "loss": 0.0517,
      "step": 52400
    },
    {
      "epoch": 3.60998418483119,
      "grad_norm": 0.45373407006263733,
      "learning_rate": 2.744769370949164e-05,
      "loss": 0.0539,
      "step": 52500
    },
    {
      "epoch": 3.61686034518325,
      "grad_norm": 0.6860144734382629,
      "learning_rate": 2.7404714013100212e-05,
      "loss": 0.0509,
      "step": 52600
    },
    {
      "epoch": 3.6237365055353092,
      "grad_norm": 0.5724996328353882,
      "learning_rate": 2.7361734316708786e-05,
      "loss": 0.0475,
      "step": 52700
    },
    {
      "epoch": 3.6306126658873685,
      "grad_norm": 0.48375120759010315,
      "learning_rate": 2.7318754620317367e-05,
      "loss": 0.0526,
      "step": 52800
    },
    {
      "epoch": 3.637488826239428,
      "grad_norm": 0.27993133664131165,
      "learning_rate": 2.727577492392594e-05,
      "loss": 0.0507,
      "step": 52900
    },
    {
      "epoch": 3.644364986591487,
      "grad_norm": 0.6061789393424988,
      "learning_rate": 2.7232795227534514e-05,
      "loss": 0.0517,
      "step": 53000
    },
    {
      "epoch": 3.651241146943547,
      "grad_norm": 0.2215803861618042,
      "learning_rate": 2.7189815531143088e-05,
      "loss": 0.0512,
      "step": 53100
    },
    {
      "epoch": 3.658117307295606,
      "grad_norm": 0.4027780294418335,
      "learning_rate": 2.7146835834751666e-05,
      "loss": 0.0492,
      "step": 53200
    },
    {
      "epoch": 3.6649934676476654,
      "grad_norm": 0.26145535707473755,
      "learning_rate": 2.710385613836024e-05,
      "loss": 0.0504,
      "step": 53300
    },
    {
      "epoch": 3.671869627999725,
      "grad_norm": 0.18459700047969818,
      "learning_rate": 2.7060876441968813e-05,
      "loss": 0.0507,
      "step": 53400
    },
    {
      "epoch": 3.6787457883517845,
      "grad_norm": 0.3396250903606415,
      "learning_rate": 2.7017896745577394e-05,
      "loss": 0.0524,
      "step": 53500
    },
    {
      "epoch": 3.6856219487038437,
      "grad_norm": 0.40485164523124695,
      "learning_rate": 2.6974917049185965e-05,
      "loss": 0.0489,
      "step": 53600
    },
    {
      "epoch": 3.692498109055903,
      "grad_norm": 0.7877950072288513,
      "learning_rate": 2.693193735279454e-05,
      "loss": 0.0507,
      "step": 53700
    },
    {
      "epoch": 3.6993742694079623,
      "grad_norm": 0.25773659348487854,
      "learning_rate": 2.688938745336703e-05,
      "loss": 0.0516,
      "step": 53800
    },
    {
      "epoch": 3.706250429760022,
      "grad_norm": 0.6013898253440857,
      "learning_rate": 2.6846407756975605e-05,
      "loss": 0.0518,
      "step": 53900
    },
    {
      "epoch": 3.7131265901120813,
      "grad_norm": 0.44801437854766846,
      "learning_rate": 2.680342806058418e-05,
      "loss": 0.0506,
      "step": 54000
    },
    {
      "epoch": 3.7200027504641406,
      "grad_norm": 0.3406153619289398,
      "learning_rate": 2.676044836419276e-05,
      "loss": 0.0505,
      "step": 54100
    },
    {
      "epoch": 3.7268789108162004,
      "grad_norm": 0.41668665409088135,
      "learning_rate": 2.6717468667801333e-05,
      "loss": 0.0477,
      "step": 54200
    },
    {
      "epoch": 3.7337550711682597,
      "grad_norm": 0.33348941802978516,
      "learning_rate": 2.6674488971409904e-05,
      "loss": 0.051,
      "step": 54300
    },
    {
      "epoch": 3.740631231520319,
      "grad_norm": 0.5030969381332397,
      "learning_rate": 2.6631509275018485e-05,
      "loss": 0.0486,
      "step": 54400
    },
    {
      "epoch": 3.7475073918723787,
      "grad_norm": 0.5392497181892395,
      "learning_rate": 2.658852957862706e-05,
      "loss": 0.0518,
      "step": 54500
    },
    {
      "epoch": 3.754383552224438,
      "grad_norm": 0.2197997272014618,
      "learning_rate": 2.6545549882235632e-05,
      "loss": 0.0484,
      "step": 54600
    },
    {
      "epoch": 3.7612597125764973,
      "grad_norm": 0.2925490736961365,
      "learning_rate": 2.650257018584421e-05,
      "loss": 0.0499,
      "step": 54700
    },
    {
      "epoch": 3.7681358729285566,
      "grad_norm": 0.4199662506580353,
      "learning_rate": 2.6459590489452784e-05,
      "loss": 0.0508,
      "step": 54800
    },
    {
      "epoch": 3.775012033280616,
      "grad_norm": 0.6665706634521484,
      "learning_rate": 2.6416610793061358e-05,
      "loss": 0.049,
      "step": 54900
    },
    {
      "epoch": 3.7818881936326756,
      "grad_norm": 0.3379688858985901,
      "learning_rate": 2.637363109666993e-05,
      "loss": 0.0507,
      "step": 55000
    },
    {
      "epoch": 3.788764353984735,
      "grad_norm": 0.29589301347732544,
      "learning_rate": 2.6330651400278512e-05,
      "loss": 0.0496,
      "step": 55100
    },
    {
      "epoch": 3.795640514336794,
      "grad_norm": 0.40113675594329834,
      "learning_rate": 2.6287671703887086e-05,
      "loss": 0.0535,
      "step": 55200
    },
    {
      "epoch": 3.802516674688854,
      "grad_norm": 0.35261479020118713,
      "learning_rate": 2.6244692007495657e-05,
      "loss": 0.0514,
      "step": 55300
    },
    {
      "epoch": 3.809392835040913,
      "grad_norm": 0.24825499951839447,
      "learning_rate": 2.6201712311104237e-05,
      "loss": 0.0511,
      "step": 55400
    },
    {
      "epoch": 3.8162689953929725,
      "grad_norm": 0.3163580298423767,
      "learning_rate": 2.615873261471281e-05,
      "loss": 0.0528,
      "step": 55500
    },
    {
      "epoch": 3.823145155745032,
      "grad_norm": 0.45862242579460144,
      "learning_rate": 2.6115752918321385e-05,
      "loss": 0.0519,
      "step": 55600
    },
    {
      "epoch": 3.8300213160970915,
      "grad_norm": 0.6121447086334229,
      "learning_rate": 2.6072773221929962e-05,
      "loss": 0.049,
      "step": 55700
    },
    {
      "epoch": 3.836897476449151,
      "grad_norm": 0.2583243250846863,
      "learning_rate": 2.6029793525538536e-05,
      "loss": 0.0459,
      "step": 55800
    },
    {
      "epoch": 3.84377363680121,
      "grad_norm": 0.5440360903739929,
      "learning_rate": 2.598681382914711e-05,
      "loss": 0.0471,
      "step": 55900
    },
    {
      "epoch": 3.8506497971532694,
      "grad_norm": 0.2476596236228943,
      "learning_rate": 2.594383413275569e-05,
      "loss": 0.0484,
      "step": 56000
    },
    {
      "epoch": 3.857525957505329,
      "grad_norm": 0.48723477125167847,
      "learning_rate": 2.5900854436364265e-05,
      "loss": 0.0489,
      "step": 56100
    },
    {
      "epoch": 3.8644021178573884,
      "grad_norm": 0.6678623557090759,
      "learning_rate": 2.585787473997284e-05,
      "loss": 0.0528,
      "step": 56200
    },
    {
      "epoch": 3.8712782782094477,
      "grad_norm": 0.27537286281585693,
      "learning_rate": 2.581489504358141e-05,
      "loss": 0.0504,
      "step": 56300
    },
    {
      "epoch": 3.8781544385615074,
      "grad_norm": 0.1267092376947403,
      "learning_rate": 2.577191534718999e-05,
      "loss": 0.048,
      "step": 56400
    },
    {
      "epoch": 3.8850305989135667,
      "grad_norm": 0.41341859102249146,
      "learning_rate": 2.5728935650798564e-05,
      "loss": 0.0486,
      "step": 56500
    },
    {
      "epoch": 3.891906759265626,
      "grad_norm": 0.3903611898422241,
      "learning_rate": 2.5685955954407138e-05,
      "loss": 0.0514,
      "step": 56600
    },
    {
      "epoch": 3.8987829196176857,
      "grad_norm": 0.3232334852218628,
      "learning_rate": 2.5642976258015715e-05,
      "loss": 0.0509,
      "step": 56700
    },
    {
      "epoch": 3.905659079969745,
      "grad_norm": 0.5075070261955261,
      "learning_rate": 2.559999656162429e-05,
      "loss": 0.0518,
      "step": 56800
    },
    {
      "epoch": 3.9125352403218043,
      "grad_norm": 0.2881719470024109,
      "learning_rate": 2.5557016865232863e-05,
      "loss": 0.0522,
      "step": 56900
    },
    {
      "epoch": 3.9194114006738636,
      "grad_norm": 0.26156124472618103,
      "learning_rate": 2.5514037168841444e-05,
      "loss": 0.0478,
      "step": 57000
    },
    {
      "epoch": 3.926287561025923,
      "grad_norm": 0.41415250301361084,
      "learning_rate": 2.5471057472450017e-05,
      "loss": 0.0497,
      "step": 57100
    },
    {
      "epoch": 3.9331637213779826,
      "grad_norm": 0.26444029808044434,
      "learning_rate": 2.542807777605859e-05,
      "loss": 0.0515,
      "step": 57200
    },
    {
      "epoch": 3.940039881730042,
      "grad_norm": 0.48617759346961975,
      "learning_rate": 2.538509807966717e-05,
      "loss": 0.0479,
      "step": 57300
    },
    {
      "epoch": 3.9469160420821012,
      "grad_norm": 0.3795866072177887,
      "learning_rate": 2.5342118383275743e-05,
      "loss": 0.0492,
      "step": 57400
    },
    {
      "epoch": 3.953792202434161,
      "grad_norm": 0.3073643445968628,
      "learning_rate": 2.5299138686884316e-05,
      "loss": 0.0491,
      "step": 57500
    },
    {
      "epoch": 3.9606683627862203,
      "grad_norm": 0.7538392543792725,
      "learning_rate": 2.525615899049289e-05,
      "loss": 0.0485,
      "step": 57600
    },
    {
      "epoch": 3.9675445231382795,
      "grad_norm": 0.5596213936805725,
      "learning_rate": 2.5213179294101468e-05,
      "loss": 0.0481,
      "step": 57700
    },
    {
      "epoch": 3.974420683490339,
      "grad_norm": 0.4195827543735504,
      "learning_rate": 2.517019959771004e-05,
      "loss": 0.0481,
      "step": 57800
    },
    {
      "epoch": 3.9812968438423986,
      "grad_norm": 0.26134374737739563,
      "learning_rate": 2.5127649698282534e-05,
      "loss": 0.0488,
      "step": 57900
    },
    {
      "epoch": 3.988173004194458,
      "grad_norm": 0.2407074272632599,
      "learning_rate": 2.5084670001891108e-05,
      "loss": 0.0483,
      "step": 58000
    },
    {
      "epoch": 3.995049164546517,
      "grad_norm": 0.41687142848968506,
      "learning_rate": 2.5041690305499682e-05,
      "loss": 0.05,
      "step": 58100
    },
    {
      "epoch": 4.0,
      "eval_accuracy_macro_0.5": 0.976850688457489,
      "eval_accuracy_micro_0.5": 0.9768506288528442,
      "eval_accuracy_weighted_0.5": 0.9737291932106018,
      "eval_f1_macro_0.5": 0.6681388020515442,
      "eval_f1_macro_0.6": 0.6273444294929504,
      "eval_f1_macro_0.7": 0.5627767443656921,
      "eval_f1_macro_0.8": 0.32137611508369446,
      "eval_f1_micro_0.5": 0.6754089593887329,
      "eval_f1_micro_0.6": 0.6448585987091064,
      "eval_f1_micro_0.7": 0.5939618349075317,
      "eval_f1_micro_0.8": 0.5150826573371887,
      "eval_f1_micro_0.9": 0.34925663471221924,
      "eval_f1_weighted_0.5": 0.658571183681488,
      "eval_f1_weighted_0.6": 0.6161644458770752,
      "eval_f1_weighted_0.7": 0.5490241646766663,
      "eval_f1_weighted_0.8": 0.2909170985221863,
      "eval_loss": 0.048998720943927765,
      "eval_runtime": 290.86,
      "eval_samples_per_second": 99.832,
      "eval_steps_per_second": 12.48,
      "step": 58172
    },
    {
      "epoch": 4.001925324898576,
      "grad_norm": 0.2792009115219116,
      "learning_rate": 2.499871060910826e-05,
      "loss": 0.0517,
      "step": 58200
    },
    {
      "epoch": 4.008801485250636,
      "grad_norm": 0.4053557813167572,
      "learning_rate": 2.4955730912716836e-05,
      "loss": 0.0495,
      "step": 58300
    },
    {
      "epoch": 4.015677645602695,
      "grad_norm": 0.3140171766281128,
      "learning_rate": 2.4912751216325407e-05,
      "loss": 0.0511,
      "step": 58400
    },
    {
      "epoch": 4.022553805954755,
      "grad_norm": 0.4070453643798828,
      "learning_rate": 2.4869771519933984e-05,
      "loss": 0.0544,
      "step": 58500
    },
    {
      "epoch": 4.0294299663068145,
      "grad_norm": 0.43282610177993774,
      "learning_rate": 2.4827221620506473e-05,
      "loss": 0.0453,
      "step": 58600
    },
    {
      "epoch": 4.036306126658873,
      "grad_norm": 0.2178328037261963,
      "learning_rate": 2.4784241924115047e-05,
      "loss": 0.0489,
      "step": 58700
    },
    {
      "epoch": 4.043182287010933,
      "grad_norm": 0.3490249216556549,
      "learning_rate": 2.4741262227723625e-05,
      "loss": 0.0502,
      "step": 58800
    },
    {
      "epoch": 4.050058447362993,
      "grad_norm": 0.4577271342277527,
      "learning_rate": 2.4698282531332202e-05,
      "loss": 0.0496,
      "step": 58900
    },
    {
      "epoch": 4.056934607715052,
      "grad_norm": 0.26630401611328125,
      "learning_rate": 2.4655302834940776e-05,
      "loss": 0.0491,
      "step": 59000
    },
    {
      "epoch": 4.063810768067111,
      "grad_norm": 0.4801911413669586,
      "learning_rate": 2.461232313854935e-05,
      "loss": 0.0487,
      "step": 59100
    },
    {
      "epoch": 4.070686928419171,
      "grad_norm": 0.965915322303772,
      "learning_rate": 2.4569343442157927e-05,
      "loss": 0.0488,
      "step": 59200
    },
    {
      "epoch": 4.07756308877123,
      "grad_norm": 0.24897706508636475,
      "learning_rate": 2.45263637457665e-05,
      "loss": 0.0491,
      "step": 59300
    },
    {
      "epoch": 4.08443924912329,
      "grad_norm": 0.8862230181694031,
      "learning_rate": 2.4483384049375078e-05,
      "loss": 0.0496,
      "step": 59400
    },
    {
      "epoch": 4.0913154094753486,
      "grad_norm": 0.2653886079788208,
      "learning_rate": 2.4440404352983652e-05,
      "loss": 0.0457,
      "step": 59500
    },
    {
      "epoch": 4.098191569827408,
      "grad_norm": 0.44072210788726807,
      "learning_rate": 2.4397424656592226e-05,
      "loss": 0.0538,
      "step": 59600
    },
    {
      "epoch": 4.105067730179468,
      "grad_norm": 0.29751884937286377,
      "learning_rate": 2.4354444960200803e-05,
      "loss": 0.0488,
      "step": 59700
    },
    {
      "epoch": 4.111943890531527,
      "grad_norm": 0.42583340406417847,
      "learning_rate": 2.4311465263809377e-05,
      "loss": 0.0495,
      "step": 59800
    },
    {
      "epoch": 4.118820050883587,
      "grad_norm": 0.435089647769928,
      "learning_rate": 2.4268485567417955e-05,
      "loss": 0.0514,
      "step": 59900
    },
    {
      "epoch": 4.125696211235646,
      "grad_norm": 0.3501838445663452,
      "learning_rate": 2.422550587102653e-05,
      "loss": 0.0469,
      "step": 60000
    },
    {
      "epoch": 4.132572371587705,
      "grad_norm": 0.7207052111625671,
      "learning_rate": 2.4182526174635102e-05,
      "loss": 0.0483,
      "step": 60100
    },
    {
      "epoch": 4.139448531939765,
      "grad_norm": 0.5047426223754883,
      "learning_rate": 2.413954647824368e-05,
      "loss": 0.0459,
      "step": 60200
    },
    {
      "epoch": 4.146324692291825,
      "grad_norm": 0.46453791856765747,
      "learning_rate": 2.4096566781852254e-05,
      "loss": 0.0495,
      "step": 60300
    },
    {
      "epoch": 4.1532008526438835,
      "grad_norm": 0.3407210111618042,
      "learning_rate": 2.405358708546083e-05,
      "loss": 0.049,
      "step": 60400
    },
    {
      "epoch": 4.160077012995943,
      "grad_norm": 0.2330649197101593,
      "learning_rate": 2.4010607389069405e-05,
      "loss": 0.0503,
      "step": 60500
    },
    {
      "epoch": 4.166953173348002,
      "grad_norm": 0.48645320534706116,
      "learning_rate": 2.396762769267798e-05,
      "loss": 0.0476,
      "step": 60600
    },
    {
      "epoch": 4.173829333700062,
      "grad_norm": 0.3161611557006836,
      "learning_rate": 2.3924647996286556e-05,
      "loss": 0.0452,
      "step": 60700
    },
    {
      "epoch": 4.1807054940521216,
      "grad_norm": 0.5778663754463196,
      "learning_rate": 2.388166829989513e-05,
      "loss": 0.0478,
      "step": 60800
    },
    {
      "epoch": 4.18758165440418,
      "grad_norm": 0.4079836308956146,
      "learning_rate": 2.3838688603503707e-05,
      "loss": 0.0506,
      "step": 60900
    },
    {
      "epoch": 4.19445781475624,
      "grad_norm": 0.42738398909568787,
      "learning_rate": 2.379570890711228e-05,
      "loss": 0.0481,
      "step": 61000
    },
    {
      "epoch": 4.2013339751083,
      "grad_norm": 0.2642631530761719,
      "learning_rate": 2.3752729210720855e-05,
      "loss": 0.0483,
      "step": 61100
    },
    {
      "epoch": 4.208210135460359,
      "grad_norm": 0.3936351239681244,
      "learning_rate": 2.3709749514329432e-05,
      "loss": 0.0483,
      "step": 61200
    },
    {
      "epoch": 4.2150862958124184,
      "grad_norm": 0.42846134305000305,
      "learning_rate": 2.3666769817938006e-05,
      "loss": 0.049,
      "step": 61300
    },
    {
      "epoch": 4.221962456164478,
      "grad_norm": 0.531674861907959,
      "learning_rate": 2.3623790121546584e-05,
      "loss": 0.0475,
      "step": 61400
    },
    {
      "epoch": 4.228838616516537,
      "grad_norm": 0.3522930145263672,
      "learning_rate": 2.3580810425155157e-05,
      "loss": 0.0469,
      "step": 61500
    },
    {
      "epoch": 4.235714776868597,
      "grad_norm": 0.3210441768169403,
      "learning_rate": 2.353783072876373e-05,
      "loss": 0.051,
      "step": 61600
    },
    {
      "epoch": 4.242590937220656,
      "grad_norm": 0.3826054036617279,
      "learning_rate": 2.349485103237231e-05,
      "loss": 0.05,
      "step": 61700
    },
    {
      "epoch": 4.249467097572715,
      "grad_norm": 0.723660945892334,
      "learning_rate": 2.3451871335980886e-05,
      "loss": 0.0463,
      "step": 61800
    },
    {
      "epoch": 4.256343257924775,
      "grad_norm": 0.5826228260993958,
      "learning_rate": 2.340889163958946e-05,
      "loss": 0.0472,
      "step": 61900
    },
    {
      "epoch": 4.263219418276834,
      "grad_norm": 0.3134252727031708,
      "learning_rate": 2.3365911943198034e-05,
      "loss": 0.0529,
      "step": 62000
    },
    {
      "epoch": 4.270095578628894,
      "grad_norm": 0.4670538008213043,
      "learning_rate": 2.3322932246806608e-05,
      "loss": 0.0491,
      "step": 62100
    },
    {
      "epoch": 4.276971738980953,
      "grad_norm": 0.42619484663009644,
      "learning_rate": 2.3279952550415185e-05,
      "loss": 0.0453,
      "step": 62200
    },
    {
      "epoch": 4.283847899333012,
      "grad_norm": 0.6236038208007812,
      "learning_rate": 2.3236972854023762e-05,
      "loss": 0.0487,
      "step": 62300
    },
    {
      "epoch": 4.290724059685072,
      "grad_norm": 0.5664134621620178,
      "learning_rate": 2.3193993157632336e-05,
      "loss": 0.0501,
      "step": 62400
    },
    {
      "epoch": 4.297600220037131,
      "grad_norm": 0.22975242137908936,
      "learning_rate": 2.315101346124091e-05,
      "loss": 0.0445,
      "step": 62500
    },
    {
      "epoch": 4.304476380389191,
      "grad_norm": 0.22544743120670319,
      "learning_rate": 2.3108033764849484e-05,
      "loss": 0.0496,
      "step": 62600
    },
    {
      "epoch": 4.31135254074125,
      "grad_norm": 0.4555671215057373,
      "learning_rate": 2.306505406845806e-05,
      "loss": 0.0501,
      "step": 62700
    },
    {
      "epoch": 4.318228701093309,
      "grad_norm": 0.4145359396934509,
      "learning_rate": 2.302207437206664e-05,
      "loss": 0.0483,
      "step": 62800
    },
    {
      "epoch": 4.325104861445369,
      "grad_norm": 0.331880658864975,
      "learning_rate": 2.2979094675675213e-05,
      "loss": 0.0473,
      "step": 62900
    },
    {
      "epoch": 4.331981021797429,
      "grad_norm": 0.39955708384513855,
      "learning_rate": 2.2936114979283786e-05,
      "loss": 0.0512,
      "step": 63000
    },
    {
      "epoch": 4.3388571821494875,
      "grad_norm": 0.2371813952922821,
      "learning_rate": 2.2893135282892364e-05,
      "loss": 0.0485,
      "step": 63100
    },
    {
      "epoch": 4.345733342501547,
      "grad_norm": 0.6312642693519592,
      "learning_rate": 2.2850155586500938e-05,
      "loss": 0.0492,
      "step": 63200
    },
    {
      "epoch": 4.352609502853607,
      "grad_norm": 0.4916054308414459,
      "learning_rate": 2.2807175890109515e-05,
      "loss": 0.0464,
      "step": 63300
    },
    {
      "epoch": 4.359485663205666,
      "grad_norm": 0.38746121525764465,
      "learning_rate": 2.276419619371809e-05,
      "loss": 0.0485,
      "step": 63400
    },
    {
      "epoch": 4.3663618235577255,
      "grad_norm": 0.313750684261322,
      "learning_rate": 2.2721216497326663e-05,
      "loss": 0.0508,
      "step": 63500
    },
    {
      "epoch": 4.373237983909785,
      "grad_norm": 0.8641745448112488,
      "learning_rate": 2.267823680093524e-05,
      "loss": 0.0515,
      "step": 63600
    },
    {
      "epoch": 4.380114144261844,
      "grad_norm": 0.6356676816940308,
      "learning_rate": 2.2635257104543814e-05,
      "loss": 0.053,
      "step": 63700
    },
    {
      "epoch": 4.386990304613904,
      "grad_norm": 0.37885811924934387,
      "learning_rate": 2.259227740815239e-05,
      "loss": 0.049,
      "step": 63800
    },
    {
      "epoch": 4.393866464965963,
      "grad_norm": 0.18935440480709076,
      "learning_rate": 2.2549297711760965e-05,
      "loss": 0.0492,
      "step": 63900
    },
    {
      "epoch": 4.400742625318022,
      "grad_norm": 0.26961347460746765,
      "learning_rate": 2.2506747812333454e-05,
      "loss": 0.0449,
      "step": 64000
    },
    {
      "epoch": 4.407618785670082,
      "grad_norm": 0.38494405150413513,
      "learning_rate": 2.246376811594203e-05,
      "loss": 0.0473,
      "step": 64100
    },
    {
      "epoch": 4.414494946022141,
      "grad_norm": 0.7545351386070251,
      "learning_rate": 2.2420788419550605e-05,
      "loss": 0.0485,
      "step": 64200
    },
    {
      "epoch": 4.421371106374201,
      "grad_norm": 0.44222530722618103,
      "learning_rate": 2.237780872315918e-05,
      "loss": 0.0505,
      "step": 64300
    },
    {
      "epoch": 4.4282472667262605,
      "grad_norm": 0.29066038131713867,
      "learning_rate": 2.2334829026767757e-05,
      "loss": 0.0456,
      "step": 64400
    },
    {
      "epoch": 4.435123427078319,
      "grad_norm": 0.43367287516593933,
      "learning_rate": 2.2291849330376334e-05,
      "loss": 0.0479,
      "step": 64500
    },
    {
      "epoch": 4.441999587430379,
      "grad_norm": 0.7428499460220337,
      "learning_rate": 2.2248869633984908e-05,
      "loss": 0.0476,
      "step": 64600
    },
    {
      "epoch": 4.448875747782438,
      "grad_norm": 0.6487501859664917,
      "learning_rate": 2.2205889937593482e-05,
      "loss": 0.0491,
      "step": 64700
    },
    {
      "epoch": 4.455751908134498,
      "grad_norm": 0.37733444571495056,
      "learning_rate": 2.216334003816597e-05,
      "loss": 0.0479,
      "step": 64800
    },
    {
      "epoch": 4.462628068486557,
      "grad_norm": 0.6580917239189148,
      "learning_rate": 2.2120360341774545e-05,
      "loss": 0.0476,
      "step": 64900
    },
    {
      "epoch": 4.469504228838616,
      "grad_norm": 0.29055115580558777,
      "learning_rate": 2.2077380645383122e-05,
      "loss": 0.0459,
      "step": 65000
    },
    {
      "epoch": 4.476380389190676,
      "grad_norm": 0.2591771185398102,
      "learning_rate": 2.20344009489917e-05,
      "loss": 0.0474,
      "step": 65100
    },
    {
      "epoch": 4.483256549542736,
      "grad_norm": 0.3588302731513977,
      "learning_rate": 2.1991421252600273e-05,
      "loss": 0.0498,
      "step": 65200
    },
    {
      "epoch": 4.4901327098947945,
      "grad_norm": 0.3223682641983032,
      "learning_rate": 2.1948441556208847e-05,
      "loss": 0.0485,
      "step": 65300
    },
    {
      "epoch": 4.497008870246854,
      "grad_norm": 0.488573282957077,
      "learning_rate": 2.190546185981742e-05,
      "loss": 0.0475,
      "step": 65400
    },
    {
      "epoch": 4.503885030598914,
      "grad_norm": 0.31883659958839417,
      "learning_rate": 2.1862482163426e-05,
      "loss": 0.049,
      "step": 65500
    },
    {
      "epoch": 4.510761190950973,
      "grad_norm": 0.2904549241065979,
      "learning_rate": 2.1819502467034576e-05,
      "loss": 0.0463,
      "step": 65600
    },
    {
      "epoch": 4.517637351303033,
      "grad_norm": 0.5759836435317993,
      "learning_rate": 2.177652277064315e-05,
      "loss": 0.0483,
      "step": 65700
    },
    {
      "epoch": 4.524513511655091,
      "grad_norm": 0.5149160623550415,
      "learning_rate": 2.1733543074251724e-05,
      "loss": 0.0483,
      "step": 65800
    },
    {
      "epoch": 4.531389672007151,
      "grad_norm": 0.5540605783462524,
      "learning_rate": 2.1690563377860297e-05,
      "loss": 0.0451,
      "step": 65900
    },
    {
      "epoch": 4.538265832359211,
      "grad_norm": 0.22863127291202545,
      "learning_rate": 2.1647583681468875e-05,
      "loss": 0.0465,
      "step": 66000
    },
    {
      "epoch": 4.54514199271127,
      "grad_norm": 0.41858622431755066,
      "learning_rate": 2.1604603985077452e-05,
      "loss": 0.0485,
      "step": 66100
    },
    {
      "epoch": 4.5520181530633295,
      "grad_norm": 0.3131212294101715,
      "learning_rate": 2.1561624288686026e-05,
      "loss": 0.0509,
      "step": 66200
    },
    {
      "epoch": 4.558894313415389,
      "grad_norm": 0.5979027152061462,
      "learning_rate": 2.15186445922946e-05,
      "loss": 0.05,
      "step": 66300
    },
    {
      "epoch": 4.565770473767448,
      "grad_norm": 0.7239702939987183,
      "learning_rate": 2.1475664895903177e-05,
      "loss": 0.0466,
      "step": 66400
    },
    {
      "epoch": 4.572646634119508,
      "grad_norm": 0.4278363883495331,
      "learning_rate": 2.143268519951175e-05,
      "loss": 0.0466,
      "step": 66500
    },
    {
      "epoch": 4.579522794471567,
      "grad_norm": 0.44007179141044617,
      "learning_rate": 2.138970550312033e-05,
      "loss": 0.0453,
      "step": 66600
    },
    {
      "epoch": 4.586398954823626,
      "grad_norm": 0.6705199480056763,
      "learning_rate": 2.1346725806728902e-05,
      "loss": 0.0494,
      "step": 66700
    },
    {
      "epoch": 4.593275115175686,
      "grad_norm": 0.44408831000328064,
      "learning_rate": 2.1303746110337476e-05,
      "loss": 0.0493,
      "step": 66800
    },
    {
      "epoch": 4.600151275527745,
      "grad_norm": 0.8891909122467041,
      "learning_rate": 2.1260766413946053e-05,
      "loss": 0.0478,
      "step": 66900
    },
    {
      "epoch": 4.607027435879805,
      "grad_norm": 0.4978923201560974,
      "learning_rate": 2.1217786717554627e-05,
      "loss": 0.0457,
      "step": 67000
    },
    {
      "epoch": 4.613903596231864,
      "grad_norm": 0.37366265058517456,
      "learning_rate": 2.1174807021163205e-05,
      "loss": 0.0484,
      "step": 67100
    },
    {
      "epoch": 4.620779756583923,
      "grad_norm": 0.4211031496524811,
      "learning_rate": 2.113182732477178e-05,
      "loss": 0.0473,
      "step": 67200
    },
    {
      "epoch": 4.627655916935983,
      "grad_norm": 0.3006146550178528,
      "learning_rate": 2.1088847628380353e-05,
      "loss": 0.0476,
      "step": 67300
    },
    {
      "epoch": 4.634532077288043,
      "grad_norm": 0.36436453461647034,
      "learning_rate": 2.104586793198893e-05,
      "loss": 0.0503,
      "step": 67400
    },
    {
      "epoch": 4.641408237640102,
      "grad_norm": 0.5855631828308105,
      "learning_rate": 2.1002888235597504e-05,
      "loss": 0.0457,
      "step": 67500
    },
    {
      "epoch": 4.648284397992161,
      "grad_norm": 0.3081413507461548,
      "learning_rate": 2.095990853920608e-05,
      "loss": 0.0474,
      "step": 67600
    },
    {
      "epoch": 4.655160558344221,
      "grad_norm": 0.23531708121299744,
      "learning_rate": 2.0916928842814655e-05,
      "loss": 0.0445,
      "step": 67700
    },
    {
      "epoch": 4.66203671869628,
      "grad_norm": 0.44628456234931946,
      "learning_rate": 2.087394914642323e-05,
      "loss": 0.0479,
      "step": 67800
    },
    {
      "epoch": 4.66891287904834,
      "grad_norm": 0.2732550799846649,
      "learning_rate": 2.0830969450031806e-05,
      "loss": 0.049,
      "step": 67900
    },
    {
      "epoch": 4.6757890394003985,
      "grad_norm": 0.40846648812294006,
      "learning_rate": 2.078798975364038e-05,
      "loss": 0.0479,
      "step": 68000
    },
    {
      "epoch": 4.682665199752458,
      "grad_norm": 0.8536500334739685,
      "learning_rate": 2.0745010057248957e-05,
      "loss": 0.0497,
      "step": 68100
    },
    {
      "epoch": 4.689541360104518,
      "grad_norm": 0.2823239266872406,
      "learning_rate": 2.070203036085753e-05,
      "loss": 0.0446,
      "step": 68200
    },
    {
      "epoch": 4.696417520456577,
      "grad_norm": 0.5073708295822144,
      "learning_rate": 2.0659050664466105e-05,
      "loss": 0.0481,
      "step": 68300
    },
    {
      "epoch": 4.7032936808086365,
      "grad_norm": 0.3120706379413605,
      "learning_rate": 2.0616070968074682e-05,
      "loss": 0.0472,
      "step": 68400
    },
    {
      "epoch": 4.710169841160695,
      "grad_norm": 0.41440749168395996,
      "learning_rate": 2.057309127168326e-05,
      "loss": 0.0482,
      "step": 68500
    },
    {
      "epoch": 4.717046001512755,
      "grad_norm": 0.4087902009487152,
      "learning_rate": 2.0530111575291834e-05,
      "loss": 0.0454,
      "step": 68600
    },
    {
      "epoch": 4.723922161864815,
      "grad_norm": 0.4253636300563812,
      "learning_rate": 2.0487131878900408e-05,
      "loss": 0.0481,
      "step": 68700
    },
    {
      "epoch": 4.730798322216874,
      "grad_norm": 0.6197254061698914,
      "learning_rate": 2.044415218250898e-05,
      "loss": 0.045,
      "step": 68800
    },
    {
      "epoch": 4.737674482568933,
      "grad_norm": 0.7560763359069824,
      "learning_rate": 2.0401602283081474e-05,
      "loss": 0.0458,
      "step": 68900
    },
    {
      "epoch": 4.744550642920993,
      "grad_norm": 0.23524074256420135,
      "learning_rate": 2.0358622586690048e-05,
      "loss": 0.0468,
      "step": 69000
    },
    {
      "epoch": 4.751426803273052,
      "grad_norm": 0.31097495555877686,
      "learning_rate": 2.0315642890298625e-05,
      "loss": 0.0462,
      "step": 69100
    },
    {
      "epoch": 4.758302963625112,
      "grad_norm": 0.2871588170528412,
      "learning_rate": 2.02726631939072e-05,
      "loss": 0.0472,
      "step": 69200
    },
    {
      "epoch": 4.7651791239771715,
      "grad_norm": 0.549233078956604,
      "learning_rate": 2.0229683497515776e-05,
      "loss": 0.0459,
      "step": 69300
    },
    {
      "epoch": 4.77205528432923,
      "grad_norm": 0.5832924246788025,
      "learning_rate": 2.018670380112435e-05,
      "loss": 0.0483,
      "step": 69400
    },
    {
      "epoch": 4.77893144468129,
      "grad_norm": 0.6066103577613831,
      "learning_rate": 2.0143724104732924e-05,
      "loss": 0.0511,
      "step": 69500
    },
    {
      "epoch": 4.78580760503335,
      "grad_norm": 0.3295849561691284,
      "learning_rate": 2.01007444083415e-05,
      "loss": 0.0478,
      "step": 69600
    },
    {
      "epoch": 4.792683765385409,
      "grad_norm": 0.3363598883152008,
      "learning_rate": 2.0057764711950075e-05,
      "loss": 0.0495,
      "step": 69700
    },
    {
      "epoch": 4.799559925737468,
      "grad_norm": 0.361955463886261,
      "learning_rate": 2.0014785015558653e-05,
      "loss": 0.0464,
      "step": 69800
    },
    {
      "epoch": 4.806436086089528,
      "grad_norm": 0.40497609972953796,
      "learning_rate": 1.9971805319167227e-05,
      "loss": 0.0481,
      "step": 69900
    },
    {
      "epoch": 4.813312246441587,
      "grad_norm": 0.4033549726009369,
      "learning_rate": 1.99288256227758e-05,
      "loss": 0.0486,
      "step": 70000
    },
    {
      "epoch": 4.820188406793647,
      "grad_norm": 0.5249682068824768,
      "learning_rate": 1.9885845926384378e-05,
      "loss": 0.0467,
      "step": 70100
    },
    {
      "epoch": 4.8270645671457055,
      "grad_norm": 0.5330911874771118,
      "learning_rate": 1.9842866229992952e-05,
      "loss": 0.0477,
      "step": 70200
    },
    {
      "epoch": 4.833940727497765,
      "grad_norm": 0.6127355694770813,
      "learning_rate": 1.979988653360153e-05,
      "loss": 0.0474,
      "step": 70300
    },
    {
      "epoch": 4.840816887849825,
      "grad_norm": 0.39064690470695496,
      "learning_rate": 1.9756906837210103e-05,
      "loss": 0.0462,
      "step": 70400
    },
    {
      "epoch": 4.847693048201884,
      "grad_norm": 0.5830504894256592,
      "learning_rate": 1.9713927140818677e-05,
      "loss": 0.0516,
      "step": 70500
    },
    {
      "epoch": 4.854569208553944,
      "grad_norm": 0.5206628441810608,
      "learning_rate": 1.9670947444427254e-05,
      "loss": 0.0517,
      "step": 70600
    },
    {
      "epoch": 4.861445368906002,
      "grad_norm": 0.30086109042167664,
      "learning_rate": 1.9627967748035828e-05,
      "loss": 0.0485,
      "step": 70700
    },
    {
      "epoch": 4.868321529258062,
      "grad_norm": 0.20120775699615479,
      "learning_rate": 1.9584988051644405e-05,
      "loss": 0.0447,
      "step": 70800
    },
    {
      "epoch": 4.875197689610122,
      "grad_norm": 0.38699963688850403,
      "learning_rate": 1.954200835525298e-05,
      "loss": 0.0481,
      "step": 70900
    },
    {
      "epoch": 4.882073849962181,
      "grad_norm": 0.241904154419899,
      "learning_rate": 1.9499028658861553e-05,
      "loss": 0.0515,
      "step": 71000
    },
    {
      "epoch": 4.8889500103142405,
      "grad_norm": 0.5399015545845032,
      "learning_rate": 1.945604896247013e-05,
      "loss": 0.0453,
      "step": 71100
    },
    {
      "epoch": 4.8958261706663,
      "grad_norm": 0.36358362436294556,
      "learning_rate": 1.9413069266078708e-05,
      "loss": 0.0499,
      "step": 71200
    },
    {
      "epoch": 4.902702331018359,
      "grad_norm": 0.5058878660202026,
      "learning_rate": 1.9370519366651193e-05,
      "loss": 0.0505,
      "step": 71300
    },
    {
      "epoch": 4.909578491370419,
      "grad_norm": 0.1694827377796173,
      "learning_rate": 1.932753967025977e-05,
      "loss": 0.0472,
      "step": 71400
    },
    {
      "epoch": 4.9164546517224785,
      "grad_norm": 0.5654694437980652,
      "learning_rate": 1.9284559973868345e-05,
      "loss": 0.0471,
      "step": 71500
    },
    {
      "epoch": 4.923330812074537,
      "grad_norm": 0.6563584208488464,
      "learning_rate": 1.924158027747692e-05,
      "loss": 0.0514,
      "step": 71600
    },
    {
      "epoch": 4.930206972426597,
      "grad_norm": 0.49913686513900757,
      "learning_rate": 1.919903037804941e-05,
      "loss": 0.0493,
      "step": 71700
    },
    {
      "epoch": 4.937083132778657,
      "grad_norm": 0.5904584527015686,
      "learning_rate": 1.9156050681657985e-05,
      "loss": 0.0467,
      "step": 71800
    },
    {
      "epoch": 4.943959293130716,
      "grad_norm": 0.5815942883491516,
      "learning_rate": 1.9113070985266562e-05,
      "loss": 0.0492,
      "step": 71900
    },
    {
      "epoch": 4.950835453482775,
      "grad_norm": 0.3470120131969452,
      "learning_rate": 1.9070091288875136e-05,
      "loss": 0.0478,
      "step": 72000
    },
    {
      "epoch": 4.957711613834834,
      "grad_norm": 0.4406501352787018,
      "learning_rate": 1.9027111592483713e-05,
      "loss": 0.0447,
      "step": 72100
    },
    {
      "epoch": 4.964587774186894,
      "grad_norm": 0.3423032760620117,
      "learning_rate": 1.8984131896092287e-05,
      "loss": 0.0443,
      "step": 72200
    },
    {
      "epoch": 4.971463934538954,
      "grad_norm": 0.43624046444892883,
      "learning_rate": 1.894115219970086e-05,
      "loss": 0.0467,
      "step": 72300
    },
    {
      "epoch": 4.978340094891013,
      "grad_norm": 0.40020591020584106,
      "learning_rate": 1.889817250330944e-05,
      "loss": 0.0456,
      "step": 72400
    },
    {
      "epoch": 4.985216255243072,
      "grad_norm": 0.3638494312763214,
      "learning_rate": 1.8855192806918012e-05,
      "loss": 0.0485,
      "step": 72500
    },
    {
      "epoch": 4.992092415595132,
      "grad_norm": 0.5586451292037964,
      "learning_rate": 1.881221311052659e-05,
      "loss": 0.0466,
      "step": 72600
    },
    {
      "epoch": 4.998968575947191,
      "grad_norm": 0.7656553387641907,
      "learning_rate": 1.8769233414135164e-05,
      "loss": 0.0484,
      "step": 72700
    },
    {
      "epoch": 5.0,
      "eval_accuracy_macro_0.5": 0.9780388474464417,
      "eval_accuracy_micro_0.5": 0.9780387878417969,
      "eval_accuracy_weighted_0.5": 0.9751322865486145,
      "eval_f1_macro_0.5": 0.6976240873336792,
      "eval_f1_macro_0.6": 0.6686318516731262,
      "eval_f1_macro_0.7": 0.6188344359397888,
      "eval_f1_macro_0.8": 0.3878145217895508,
      "eval_f1_micro_0.5": 0.7010460495948792,
      "eval_f1_micro_0.6": 0.6785563230514526,
      "eval_f1_micro_0.7": 0.6382173299789429,
      "eval_f1_micro_0.8": 0.5662890672683716,
      "eval_f1_micro_0.9": 0.4207902252674103,
      "eval_f1_weighted_0.5": 0.6890856027603149,
      "eval_f1_weighted_0.6": 0.6577298641204834,
      "eval_f1_weighted_0.7": 0.6052680015563965,
      "eval_f1_weighted_0.8": 0.3602874279022217,
      "eval_loss": 0.047140344977378845,
      "eval_runtime": 291.1081,
      "eval_samples_per_second": 99.746,
      "eval_steps_per_second": 12.47,
      "step": 72715
    },
    {
      "epoch": 5.005844736299251,
      "grad_norm": 0.4051695764064789,
      "learning_rate": 1.8726253717743738e-05,
      "loss": 0.0482,
      "step": 72800
    },
    {
      "epoch": 5.0127208966513095,
      "grad_norm": 0.4249260425567627,
      "learning_rate": 1.8683274021352315e-05,
      "loss": 0.0448,
      "step": 72900
    },
    {
      "epoch": 5.019597057003369,
      "grad_norm": 0.6155789494514465,
      "learning_rate": 1.864029432496089e-05,
      "loss": 0.0455,
      "step": 73000
    },
    {
      "epoch": 5.026473217355429,
      "grad_norm": 0.3023894429206848,
      "learning_rate": 1.8597314628569466e-05,
      "loss": 0.0471,
      "step": 73100
    },
    {
      "epoch": 5.033349377707488,
      "grad_norm": 0.3132617175579071,
      "learning_rate": 1.855433493217804e-05,
      "loss": 0.0464,
      "step": 73200
    },
    {
      "epoch": 5.0402255380595475,
      "grad_norm": 0.5922292470932007,
      "learning_rate": 1.8511355235786614e-05,
      "loss": 0.0439,
      "step": 73300
    },
    {
      "epoch": 5.047101698411607,
      "grad_norm": 0.33495059609413147,
      "learning_rate": 1.846837553939519e-05,
      "loss": 0.0465,
      "step": 73400
    },
    {
      "epoch": 5.053977858763666,
      "grad_norm": 0.52323979139328,
      "learning_rate": 1.8425395843003765e-05,
      "loss": 0.0464,
      "step": 73500
    },
    {
      "epoch": 5.060854019115726,
      "grad_norm": 0.38458484411239624,
      "learning_rate": 1.8382416146612342e-05,
      "loss": 0.0478,
      "step": 73600
    },
    {
      "epoch": 5.067730179467786,
      "grad_norm": 0.49908044934272766,
      "learning_rate": 1.8339436450220916e-05,
      "loss": 0.0477,
      "step": 73700
    },
    {
      "epoch": 5.074606339819844,
      "grad_norm": 0.3799764811992645,
      "learning_rate": 1.829645675382949e-05,
      "loss": 0.0484,
      "step": 73800
    },
    {
      "epoch": 5.081482500171904,
      "grad_norm": 0.4145110547542572,
      "learning_rate": 1.8253477057438068e-05,
      "loss": 0.0457,
      "step": 73900
    },
    {
      "epoch": 5.088358660523963,
      "grad_norm": 0.27877703309059143,
      "learning_rate": 1.821049736104664e-05,
      "loss": 0.0467,
      "step": 74000
    },
    {
      "epoch": 5.095234820876023,
      "grad_norm": 0.2785344123840332,
      "learning_rate": 1.816751766465522e-05,
      "loss": 0.0463,
      "step": 74100
    },
    {
      "epoch": 5.1021109812280825,
      "grad_norm": 0.5463196039199829,
      "learning_rate": 1.8124537968263793e-05,
      "loss": 0.0448,
      "step": 74200
    },
    {
      "epoch": 5.108987141580141,
      "grad_norm": 0.36322692036628723,
      "learning_rate": 1.8081558271872367e-05,
      "loss": 0.0477,
      "step": 74300
    },
    {
      "epoch": 5.115863301932201,
      "grad_norm": 0.31395602226257324,
      "learning_rate": 1.8038578575480944e-05,
      "loss": 0.048,
      "step": 74400
    },
    {
      "epoch": 5.122739462284261,
      "grad_norm": 0.4518638253211975,
      "learning_rate": 1.799559887908952e-05,
      "loss": 0.047,
      "step": 74500
    },
    {
      "epoch": 5.12961562263632,
      "grad_norm": 0.23717400431632996,
      "learning_rate": 1.7952619182698095e-05,
      "loss": 0.0457,
      "step": 74600
    },
    {
      "epoch": 5.136491782988379,
      "grad_norm": 0.3721643090248108,
      "learning_rate": 1.790963948630667e-05,
      "loss": 0.0451,
      "step": 74700
    },
    {
      "epoch": 5.143367943340439,
      "grad_norm": 0.7090948224067688,
      "learning_rate": 1.7866659789915243e-05,
      "loss": 0.0483,
      "step": 74800
    },
    {
      "epoch": 5.150244103692498,
      "grad_norm": 0.6094925403594971,
      "learning_rate": 1.782368009352382e-05,
      "loss": 0.0455,
      "step": 74900
    },
    {
      "epoch": 5.157120264044558,
      "grad_norm": 0.48953813314437866,
      "learning_rate": 1.7780700397132398e-05,
      "loss": 0.0451,
      "step": 75000
    },
    {
      "epoch": 5.1639964243966165,
      "grad_norm": 0.2510460913181305,
      "learning_rate": 1.773772070074097e-05,
      "loss": 0.0476,
      "step": 75100
    },
    {
      "epoch": 5.170872584748676,
      "grad_norm": 0.37338510155677795,
      "learning_rate": 1.7694741004349545e-05,
      "loss": 0.0465,
      "step": 75200
    },
    {
      "epoch": 5.177748745100736,
      "grad_norm": 0.3676324486732483,
      "learning_rate": 1.765176130795812e-05,
      "loss": 0.0445,
      "step": 75300
    },
    {
      "epoch": 5.184624905452795,
      "grad_norm": 0.47682228684425354,
      "learning_rate": 1.7608781611566697e-05,
      "loss": 0.05,
      "step": 75400
    },
    {
      "epoch": 5.191501065804855,
      "grad_norm": 0.6996554136276245,
      "learning_rate": 1.7565801915175274e-05,
      "loss": 0.0478,
      "step": 75500
    },
    {
      "epoch": 5.198377226156914,
      "grad_norm": 0.49049124121665955,
      "learning_rate": 1.7523252015747763e-05,
      "loss": 0.0422,
      "step": 75600
    },
    {
      "epoch": 5.205253386508973,
      "grad_norm": 0.3680521249771118,
      "learning_rate": 1.7480272319356337e-05,
      "loss": 0.0482,
      "step": 75700
    },
    {
      "epoch": 5.212129546861033,
      "grad_norm": 0.3111984431743622,
      "learning_rate": 1.7437292622964914e-05,
      "loss": 0.0466,
      "step": 75800
    },
    {
      "epoch": 5.219005707213093,
      "grad_norm": 0.37717702984809875,
      "learning_rate": 1.7394312926573488e-05,
      "loss": 0.0486,
      "step": 75900
    },
    {
      "epoch": 5.2258818675651515,
      "grad_norm": 0.4881318509578705,
      "learning_rate": 1.7351333230182062e-05,
      "loss": 0.0464,
      "step": 76000
    },
    {
      "epoch": 5.232758027917211,
      "grad_norm": 0.5474075675010681,
      "learning_rate": 1.730835353379064e-05,
      "loss": 0.0456,
      "step": 76100
    },
    {
      "epoch": 5.23963418826927,
      "grad_norm": 0.31759780645370483,
      "learning_rate": 1.7265373837399213e-05,
      "loss": 0.0468,
      "step": 76200
    },
    {
      "epoch": 5.24651034862133,
      "grad_norm": 0.26661792397499084,
      "learning_rate": 1.722239414100779e-05,
      "loss": 0.047,
      "step": 76300
    },
    {
      "epoch": 5.2533865089733895,
      "grad_norm": 0.4124866724014282,
      "learning_rate": 1.7179414444616364e-05,
      "loss": 0.0444,
      "step": 76400
    },
    {
      "epoch": 5.260262669325448,
      "grad_norm": 0.21711741387844086,
      "learning_rate": 1.7136434748224938e-05,
      "loss": 0.0455,
      "step": 76500
    },
    {
      "epoch": 5.267138829677508,
      "grad_norm": 0.4546815752983093,
      "learning_rate": 1.7093455051833516e-05,
      "loss": 0.0462,
      "step": 76600
    },
    {
      "epoch": 5.274014990029568,
      "grad_norm": 0.4443683624267578,
      "learning_rate": 1.705047535544209e-05,
      "loss": 0.0443,
      "step": 76700
    },
    {
      "epoch": 5.280891150381627,
      "grad_norm": 0.29404377937316895,
      "learning_rate": 1.7007495659050667e-05,
      "loss": 0.0445,
      "step": 76800
    },
    {
      "epoch": 5.287767310733686,
      "grad_norm": 0.7302094101905823,
      "learning_rate": 1.696451596265924e-05,
      "loss": 0.0469,
      "step": 76900
    },
    {
      "epoch": 5.294643471085745,
      "grad_norm": 0.23957055807113647,
      "learning_rate": 1.6921536266267815e-05,
      "loss": 0.0454,
      "step": 77000
    },
    {
      "epoch": 5.301519631437805,
      "grad_norm": 0.4173758327960968,
      "learning_rate": 1.6878556569876392e-05,
      "loss": 0.0454,
      "step": 77100
    },
    {
      "epoch": 5.308395791789865,
      "grad_norm": 0.3976815938949585,
      "learning_rate": 1.683557687348497e-05,
      "loss": 0.0465,
      "step": 77200
    },
    {
      "epoch": 5.315271952141924,
      "grad_norm": 0.30776333808898926,
      "learning_rate": 1.679259717709354e-05,
      "loss": 0.0494,
      "step": 77300
    },
    {
      "epoch": 5.322148112493983,
      "grad_norm": 0.3058994710445404,
      "learning_rate": 1.6749617480702117e-05,
      "loss": 0.0467,
      "step": 77400
    },
    {
      "epoch": 5.329024272846043,
      "grad_norm": 0.8816385269165039,
      "learning_rate": 1.670663778431069e-05,
      "loss": 0.0428,
      "step": 77500
    },
    {
      "epoch": 5.335900433198102,
      "grad_norm": 0.2968127727508545,
      "learning_rate": 1.6663658087919268e-05,
      "loss": 0.0504,
      "step": 77600
    },
    {
      "epoch": 5.342776593550162,
      "grad_norm": 0.48843666911125183,
      "learning_rate": 1.6620678391527846e-05,
      "loss": 0.0473,
      "step": 77700
    },
    {
      "epoch": 5.349652753902221,
      "grad_norm": 0.33026358485221863,
      "learning_rate": 1.6577698695136416e-05,
      "loss": 0.0457,
      "step": 77800
    },
    {
      "epoch": 5.35652891425428,
      "grad_norm": 0.3917922377586365,
      "learning_rate": 1.6534718998744993e-05,
      "loss": 0.0455,
      "step": 77900
    },
    {
      "epoch": 5.36340507460634,
      "grad_norm": 0.5131493806838989,
      "learning_rate": 1.6491739302353567e-05,
      "loss": 0.0479,
      "step": 78000
    },
    {
      "epoch": 5.370281234958399,
      "grad_norm": 0.6150908470153809,
      "learning_rate": 1.6448759605962145e-05,
      "loss": 0.0459,
      "step": 78100
    },
    {
      "epoch": 5.3771573953104586,
      "grad_norm": 0.33321601152420044,
      "learning_rate": 1.6405779909570722e-05,
      "loss": 0.0453,
      "step": 78200
    },
    {
      "epoch": 5.384033555662518,
      "grad_norm": 0.43460509181022644,
      "learning_rate": 1.6362800213179292e-05,
      "loss": 0.046,
      "step": 78300
    },
    {
      "epoch": 5.390909716014577,
      "grad_norm": 0.27401021122932434,
      "learning_rate": 1.631982051678787e-05,
      "loss": 0.0478,
      "step": 78400
    },
    {
      "epoch": 5.397785876366637,
      "grad_norm": 0.49357789754867554,
      "learning_rate": 1.6276840820396447e-05,
      "loss": 0.0457,
      "step": 78500
    },
    {
      "epoch": 5.404662036718697,
      "grad_norm": 0.23649217188358307,
      "learning_rate": 1.623386112400502e-05,
      "loss": 0.0474,
      "step": 78600
    },
    {
      "epoch": 5.4115381970707555,
      "grad_norm": 0.46896010637283325,
      "learning_rate": 1.6190881427613598e-05,
      "loss": 0.0454,
      "step": 78700
    },
    {
      "epoch": 5.418414357422815,
      "grad_norm": 0.264435350894928,
      "learning_rate": 1.614790173122217e-05,
      "loss": 0.0445,
      "step": 78800
    },
    {
      "epoch": 5.425290517774875,
      "grad_norm": 0.3124641180038452,
      "learning_rate": 1.6104922034830746e-05,
      "loss": 0.0457,
      "step": 78900
    },
    {
      "epoch": 5.432166678126934,
      "grad_norm": 0.39323949813842773,
      "learning_rate": 1.6061942338439323e-05,
      "loss": 0.0471,
      "step": 79000
    },
    {
      "epoch": 5.4390428384789935,
      "grad_norm": 0.3723582625389099,
      "learning_rate": 1.6018962642047897e-05,
      "loss": 0.0445,
      "step": 79100
    },
    {
      "epoch": 5.445918998831052,
      "grad_norm": 0.5765817761421204,
      "learning_rate": 1.5975982945656475e-05,
      "loss": 0.0459,
      "step": 79200
    },
    {
      "epoch": 5.452795159183112,
      "grad_norm": 0.6191818118095398,
      "learning_rate": 1.5933003249265045e-05,
      "loss": 0.0442,
      "step": 79300
    },
    {
      "epoch": 5.459671319535172,
      "grad_norm": 0.34482404589653015,
      "learning_rate": 1.5890023552873622e-05,
      "loss": 0.045,
      "step": 79400
    },
    {
      "epoch": 5.466547479887231,
      "grad_norm": 0.4541807472705841,
      "learning_rate": 1.58470438564822e-05,
      "loss": 0.047,
      "step": 79500
    },
    {
      "epoch": 5.47342364023929,
      "grad_norm": 0.4727941155433655,
      "learning_rate": 1.5804064160090774e-05,
      "loss": 0.048,
      "step": 79600
    },
    {
      "epoch": 5.48029980059135,
      "grad_norm": 0.4030800461769104,
      "learning_rate": 1.576108446369935e-05,
      "loss": 0.0442,
      "step": 79700
    },
    {
      "epoch": 5.487175960943409,
      "grad_norm": 0.3248293697834015,
      "learning_rate": 1.5718104767307925e-05,
      "loss": 0.046,
      "step": 79800
    },
    {
      "epoch": 5.494052121295469,
      "grad_norm": 0.5851033926010132,
      "learning_rate": 1.56751250709165e-05,
      "loss": 0.0453,
      "step": 79900
    },
    {
      "epoch": 5.5009282816475285,
      "grad_norm": 0.32280153036117554,
      "learning_rate": 1.5632145374525076e-05,
      "loss": 0.0451,
      "step": 80000
    },
    {
      "epoch": 5.507804441999587,
      "grad_norm": 0.42591169476509094,
      "learning_rate": 1.558916567813365e-05,
      "loss": 0.0443,
      "step": 80100
    },
    {
      "epoch": 5.514680602351647,
      "grad_norm": 0.34419673681259155,
      "learning_rate": 1.554661577870614e-05,
      "loss": 0.0469,
      "step": 80200
    },
    {
      "epoch": 5.521556762703706,
      "grad_norm": 0.4432138204574585,
      "learning_rate": 1.5503636082314716e-05,
      "loss": 0.0447,
      "step": 80300
    },
    {
      "epoch": 5.528432923055766,
      "grad_norm": 0.2451886534690857,
      "learning_rate": 1.546065638592329e-05,
      "loss": 0.0464,
      "step": 80400
    },
    {
      "epoch": 5.535309083407825,
      "grad_norm": 0.5467496514320374,
      "learning_rate": 1.5417676689531864e-05,
      "loss": 0.0472,
      "step": 80500
    },
    {
      "epoch": 5.542185243759884,
      "grad_norm": 0.42814749479293823,
      "learning_rate": 1.537469699314044e-05,
      "loss": 0.0453,
      "step": 80600
    },
    {
      "epoch": 5.549061404111944,
      "grad_norm": 0.550701916217804,
      "learning_rate": 1.5331717296749015e-05,
      "loss": 0.0452,
      "step": 80700
    },
    {
      "epoch": 5.555937564464004,
      "grad_norm": 0.9818922877311707,
      "learning_rate": 1.5288737600357593e-05,
      "loss": 0.0472,
      "step": 80800
    },
    {
      "epoch": 5.5628137248160625,
      "grad_norm": 0.7884935736656189,
      "learning_rate": 1.5245757903966168e-05,
      "loss": 0.0433,
      "step": 80900
    },
    {
      "epoch": 5.569689885168122,
      "grad_norm": 0.47347161173820496,
      "learning_rate": 1.5202778207574742e-05,
      "loss": 0.0468,
      "step": 81000
    },
    {
      "epoch": 5.576566045520181,
      "grad_norm": 0.4167385995388031,
      "learning_rate": 1.5159798511183318e-05,
      "loss": 0.047,
      "step": 81100
    },
    {
      "epoch": 5.583442205872241,
      "grad_norm": 0.4703584313392639,
      "learning_rate": 1.5116818814791895e-05,
      "loss": 0.0465,
      "step": 81200
    },
    {
      "epoch": 5.590318366224301,
      "grad_norm": 0.5560426115989685,
      "learning_rate": 1.5073839118400467e-05,
      "loss": 0.0477,
      "step": 81300
    },
    {
      "epoch": 5.597194526576359,
      "grad_norm": 0.29241231083869934,
      "learning_rate": 1.5030859422009045e-05,
      "loss": 0.0428,
      "step": 81400
    },
    {
      "epoch": 5.604070686928419,
      "grad_norm": 0.36847901344299316,
      "learning_rate": 1.4987879725617618e-05,
      "loss": 0.0444,
      "step": 81500
    },
    {
      "epoch": 5.610946847280479,
      "grad_norm": 0.3787606656551361,
      "learning_rate": 1.4944900029226194e-05,
      "loss": 0.0465,
      "step": 81600
    },
    {
      "epoch": 5.617823007632538,
      "grad_norm": 0.564600944519043,
      "learning_rate": 1.4901920332834771e-05,
      "loss": 0.046,
      "step": 81700
    },
    {
      "epoch": 5.6246991679845975,
      "grad_norm": 0.3862006962299347,
      "learning_rate": 1.4858940636443344e-05,
      "loss": 0.0444,
      "step": 81800
    },
    {
      "epoch": 5.631575328336657,
      "grad_norm": 0.485556960105896,
      "learning_rate": 1.4815960940051921e-05,
      "loss": 0.0468,
      "step": 81900
    },
    {
      "epoch": 5.638451488688716,
      "grad_norm": 0.25484800338745117,
      "learning_rate": 1.4772981243660495e-05,
      "loss": 0.048,
      "step": 82000
    },
    {
      "epoch": 5.645327649040776,
      "grad_norm": 0.4032110869884491,
      "learning_rate": 1.473000154726907e-05,
      "loss": 0.0451,
      "step": 82100
    },
    {
      "epoch": 5.6522038093928355,
      "grad_norm": 0.5697227120399475,
      "learning_rate": 1.4687021850877648e-05,
      "loss": 0.0462,
      "step": 82200
    },
    {
      "epoch": 5.659079969744894,
      "grad_norm": 0.27101823687553406,
      "learning_rate": 1.464404215448622e-05,
      "loss": 0.0443,
      "step": 82300
    },
    {
      "epoch": 5.665956130096954,
      "grad_norm": 0.3034610152244568,
      "learning_rate": 1.4601062458094797e-05,
      "loss": 0.045,
      "step": 82400
    },
    {
      "epoch": 5.672832290449013,
      "grad_norm": 0.3714049756526947,
      "learning_rate": 1.4558082761703373e-05,
      "loss": 0.0461,
      "step": 82500
    },
    {
      "epoch": 5.679708450801073,
      "grad_norm": 0.2932775914669037,
      "learning_rate": 1.4515103065311947e-05,
      "loss": 0.0495,
      "step": 82600
    },
    {
      "epoch": 5.686584611153132,
      "grad_norm": 0.7060993313789368,
      "learning_rate": 1.4472123368920524e-05,
      "loss": 0.0463,
      "step": 82700
    },
    {
      "epoch": 5.693460771505191,
      "grad_norm": 0.39876696467399597,
      "learning_rate": 1.4429143672529096e-05,
      "loss": 0.0463,
      "step": 82800
    },
    {
      "epoch": 5.700336931857251,
      "grad_norm": 0.2275385707616806,
      "learning_rate": 1.4386163976137674e-05,
      "loss": 0.0447,
      "step": 82900
    },
    {
      "epoch": 5.70721309220931,
      "grad_norm": 0.3804321885108948,
      "learning_rate": 1.4343184279746249e-05,
      "loss": 0.0469,
      "step": 83000
    },
    {
      "epoch": 5.71408925256137,
      "grad_norm": 0.4209919571876526,
      "learning_rate": 1.4300204583354823e-05,
      "loss": 0.0459,
      "step": 83100
    },
    {
      "epoch": 5.720965412913429,
      "grad_norm": 0.44924837350845337,
      "learning_rate": 1.42572248869634e-05,
      "loss": 0.0469,
      "step": 83200
    },
    {
      "epoch": 5.727841573265488,
      "grad_norm": 0.8799893260002136,
      "learning_rate": 1.4214245190571973e-05,
      "loss": 0.0468,
      "step": 83300
    },
    {
      "epoch": 5.734717733617548,
      "grad_norm": 0.40523380041122437,
      "learning_rate": 1.4171695291144463e-05,
      "loss": 0.0458,
      "step": 83400
    },
    {
      "epoch": 5.741593893969608,
      "grad_norm": 0.45939376950263977,
      "learning_rate": 1.4128715594753039e-05,
      "loss": 0.0485,
      "step": 83500
    },
    {
      "epoch": 5.7484700543216665,
      "grad_norm": 0.36318907141685486,
      "learning_rate": 1.4085735898361616e-05,
      "loss": 0.0461,
      "step": 83600
    },
    {
      "epoch": 5.755346214673726,
      "grad_norm": 0.44847890734672546,
      "learning_rate": 1.4042756201970188e-05,
      "loss": 0.0479,
      "step": 83700
    },
    {
      "epoch": 5.762222375025786,
      "grad_norm": 0.4801444113254547,
      "learning_rate": 1.3999776505578766e-05,
      "loss": 0.0455,
      "step": 83800
    },
    {
      "epoch": 5.769098535377845,
      "grad_norm": 0.34700849652290344,
      "learning_rate": 1.3956796809187341e-05,
      "loss": 0.046,
      "step": 83900
    },
    {
      "epoch": 5.7759746957299045,
      "grad_norm": 0.4171048104763031,
      "learning_rate": 1.3913817112795915e-05,
      "loss": 0.0462,
      "step": 84000
    },
    {
      "epoch": 5.782850856081964,
      "grad_norm": 0.3727758824825287,
      "learning_rate": 1.3870837416404493e-05,
      "loss": 0.0451,
      "step": 84100
    },
    {
      "epoch": 5.789727016434023,
      "grad_norm": 0.5647556781768799,
      "learning_rate": 1.3827857720013065e-05,
      "loss": 0.0452,
      "step": 84200
    },
    {
      "epoch": 5.796603176786083,
      "grad_norm": 0.39688175916671753,
      "learning_rate": 1.3784878023621642e-05,
      "loss": 0.0479,
      "step": 84300
    },
    {
      "epoch": 5.803479337138142,
      "grad_norm": 0.3503692150115967,
      "learning_rate": 1.3741898327230218e-05,
      "loss": 0.0466,
      "step": 84400
    },
    {
      "epoch": 5.810355497490201,
      "grad_norm": 0.5054221153259277,
      "learning_rate": 1.3698918630838792e-05,
      "loss": 0.0463,
      "step": 84500
    },
    {
      "epoch": 5.817231657842261,
      "grad_norm": 0.229537695646286,
      "learning_rate": 1.3655938934447369e-05,
      "loss": 0.0452,
      "step": 84600
    },
    {
      "epoch": 5.82410781819432,
      "grad_norm": 0.5622865557670593,
      "learning_rate": 1.3612959238055941e-05,
      "loss": 0.0454,
      "step": 84700
    },
    {
      "epoch": 5.83098397854638,
      "grad_norm": 0.3428959548473358,
      "learning_rate": 1.3569979541664518e-05,
      "loss": 0.0445,
      "step": 84800
    },
    {
      "epoch": 5.8378601388984395,
      "grad_norm": 0.46874624490737915,
      "learning_rate": 1.3526999845273094e-05,
      "loss": 0.0477,
      "step": 84900
    },
    {
      "epoch": 5.844736299250498,
      "grad_norm": 0.368764728307724,
      "learning_rate": 1.3484020148881668e-05,
      "loss": 0.0452,
      "step": 85000
    },
    {
      "epoch": 5.851612459602558,
      "grad_norm": 0.45391714572906494,
      "learning_rate": 1.3441040452490245e-05,
      "loss": 0.0444,
      "step": 85100
    },
    {
      "epoch": 5.858488619954617,
      "grad_norm": 0.4395121932029724,
      "learning_rate": 1.339806075609882e-05,
      "loss": 0.0433,
      "step": 85200
    },
    {
      "epoch": 5.865364780306677,
      "grad_norm": 0.556547224521637,
      "learning_rate": 1.3355081059707395e-05,
      "loss": 0.042,
      "step": 85300
    },
    {
      "epoch": 5.872240940658736,
      "grad_norm": 0.5217618942260742,
      "learning_rate": 1.3312531160279884e-05,
      "loss": 0.0453,
      "step": 85400
    },
    {
      "epoch": 5.879117101010795,
      "grad_norm": 0.1932644546031952,
      "learning_rate": 1.3269551463888461e-05,
      "loss": 0.0452,
      "step": 85500
    },
    {
      "epoch": 5.885993261362855,
      "grad_norm": 1.0815331935882568,
      "learning_rate": 1.3226571767497033e-05,
      "loss": 0.0462,
      "step": 85600
    },
    {
      "epoch": 5.892869421714915,
      "grad_norm": 0.42217370867729187,
      "learning_rate": 1.318359207110561e-05,
      "loss": 0.0491,
      "step": 85700
    },
    {
      "epoch": 5.8997455820669735,
      "grad_norm": 0.4573659300804138,
      "learning_rate": 1.3140612374714186e-05,
      "loss": 0.0447,
      "step": 85800
    },
    {
      "epoch": 5.906621742419033,
      "grad_norm": 0.41306793689727783,
      "learning_rate": 1.309763267832276e-05,
      "loss": 0.0459,
      "step": 85900
    },
    {
      "epoch": 5.913497902771093,
      "grad_norm": 0.2920190989971161,
      "learning_rate": 1.3054652981931337e-05,
      "loss": 0.0442,
      "step": 86000
    },
    {
      "epoch": 5.920374063123152,
      "grad_norm": 0.6976213455200195,
      "learning_rate": 1.301167328553991e-05,
      "loss": 0.0463,
      "step": 86100
    },
    {
      "epoch": 5.927250223475212,
      "grad_norm": 0.4135454297065735,
      "learning_rate": 1.2968693589148487e-05,
      "loss": 0.0464,
      "step": 86200
    },
    {
      "epoch": 5.934126383827271,
      "grad_norm": 0.36051955819129944,
      "learning_rate": 1.2925713892757063e-05,
      "loss": 0.0453,
      "step": 86300
    },
    {
      "epoch": 5.94100254417933,
      "grad_norm": 0.3139846920967102,
      "learning_rate": 1.2882734196365636e-05,
      "loss": 0.0463,
      "step": 86400
    },
    {
      "epoch": 5.94787870453139,
      "grad_norm": 0.459790974855423,
      "learning_rate": 1.2839754499974214e-05,
      "loss": 0.0453,
      "step": 86500
    },
    {
      "epoch": 5.954754864883449,
      "grad_norm": 0.4762972295284271,
      "learning_rate": 1.279677480358279e-05,
      "loss": 0.0447,
      "step": 86600
    },
    {
      "epoch": 5.9616310252355085,
      "grad_norm": 0.4636675715446472,
      "learning_rate": 1.2753795107191363e-05,
      "loss": 0.0458,
      "step": 86700
    },
    {
      "epoch": 5.968507185587568,
      "grad_norm": 0.3683740794658661,
      "learning_rate": 1.2710815410799939e-05,
      "loss": 0.0468,
      "step": 86800
    },
    {
      "epoch": 5.975383345939627,
      "grad_norm": 0.6464266180992126,
      "learning_rate": 1.2667835714408513e-05,
      "loss": 0.0478,
      "step": 86900
    },
    {
      "epoch": 5.982259506291687,
      "grad_norm": 0.2714278995990753,
      "learning_rate": 1.262485601801709e-05,
      "loss": 0.0421,
      "step": 87000
    },
    {
      "epoch": 5.989135666643746,
      "grad_norm": 0.42525872588157654,
      "learning_rate": 1.2581876321625666e-05,
      "loss": 0.0477,
      "step": 87100
    },
    {
      "epoch": 5.996011826995805,
      "grad_norm": 0.7574045658111572,
      "learning_rate": 1.253889662523424e-05,
      "loss": 0.0446,
      "step": 87200
    },
    {
      "epoch": 6.0,
      "eval_accuracy_macro_0.5": 0.9789804220199585,
      "eval_accuracy_micro_0.5": 0.9789804816246033,
      "eval_accuracy_weighted_0.5": 0.9761569499969482,
      "eval_f1_macro_0.5": 0.7092665433883667,
      "eval_f1_macro_0.6": 0.6810763478279114,
      "eval_f1_macro_0.7": 0.6313230395317078,
      "eval_f1_macro_0.8": 0.39831000566482544,
      "eval_f1_micro_0.5": 0.7125215530395508,
      "eval_f1_micro_0.6": 0.6904836297035217,
      "eval_f1_micro_0.7": 0.6508541703224182,
      "eval_f1_micro_0.8": 0.5837320685386658,
      "eval_f1_micro_0.9": 0.4339461922645569,
      "eval_f1_weighted_0.5": 0.7011061310768127,
      "eval_f1_weighted_0.6": 0.6713835000991821,
      "eval_f1_weighted_0.7": 0.6201763153076172,
      "eval_f1_weighted_0.8": 0.3728196322917938,
      "eval_loss": 0.044724851846694946,
      "eval_runtime": 291.046,
      "eval_samples_per_second": 99.768,
      "eval_steps_per_second": 12.472,
      "step": 87258
    },
    {
      "epoch": 6.002887987347865,
      "grad_norm": 0.38857966661453247,
      "learning_rate": 1.2495916928842815e-05,
      "loss": 0.0454,
      "step": 87300
    },
    {
      "epoch": 6.009764147699924,
      "grad_norm": 0.42995452880859375,
      "learning_rate": 1.245293723245139e-05,
      "loss": 0.0455,
      "step": 87400
    },
    {
      "epoch": 6.016640308051984,
      "grad_norm": 0.24564585089683533,
      "learning_rate": 1.2409957536059966e-05,
      "loss": 0.0438,
      "step": 87500
    },
    {
      "epoch": 6.023516468404043,
      "grad_norm": 0.5440049767494202,
      "learning_rate": 1.236697783966854e-05,
      "loss": 0.0447,
      "step": 87600
    },
    {
      "epoch": 6.030392628756102,
      "grad_norm": 0.4458625018596649,
      "learning_rate": 1.2323998143277118e-05,
      "loss": 0.0469,
      "step": 87700
    },
    {
      "epoch": 6.037268789108162,
      "grad_norm": 0.3403985798358917,
      "learning_rate": 1.2281018446885692e-05,
      "loss": 0.0435,
      "step": 87800
    },
    {
      "epoch": 6.044144949460222,
      "grad_norm": 0.33272331953048706,
      "learning_rate": 1.2238038750494267e-05,
      "loss": 0.047,
      "step": 87900
    },
    {
      "epoch": 6.051021109812281,
      "grad_norm": 0.3416047692298889,
      "learning_rate": 1.2195488851066756e-05,
      "loss": 0.0439,
      "step": 88000
    },
    {
      "epoch": 6.05789727016434,
      "grad_norm": 0.45218101143836975,
      "learning_rate": 1.2152509154675332e-05,
      "loss": 0.044,
      "step": 88100
    },
    {
      "epoch": 6.0647734305164,
      "grad_norm": 0.5680421590805054,
      "learning_rate": 1.2109529458283907e-05,
      "loss": 0.0436,
      "step": 88200
    },
    {
      "epoch": 6.071649590868459,
      "grad_norm": 0.3587448298931122,
      "learning_rate": 1.2066549761892483e-05,
      "loss": 0.0437,
      "step": 88300
    },
    {
      "epoch": 6.078525751220519,
      "grad_norm": 0.49048224091529846,
      "learning_rate": 1.2023570065501059e-05,
      "loss": 0.0454,
      "step": 88400
    },
    {
      "epoch": 6.0854019115725775,
      "grad_norm": 0.4067549407482147,
      "learning_rate": 1.1980590369109633e-05,
      "loss": 0.0469,
      "step": 88500
    },
    {
      "epoch": 6.092278071924637,
      "grad_norm": 0.6765941977500916,
      "learning_rate": 1.1937610672718208e-05,
      "loss": 0.047,
      "step": 88600
    },
    {
      "epoch": 6.099154232276697,
      "grad_norm": 0.38176456093788147,
      "learning_rate": 1.1894630976326784e-05,
      "loss": 0.0444,
      "step": 88700
    },
    {
      "epoch": 6.106030392628756,
      "grad_norm": 0.5644318461418152,
      "learning_rate": 1.185165127993536e-05,
      "loss": 0.0452,
      "step": 88800
    },
    {
      "epoch": 6.1129065529808155,
      "grad_norm": 0.30511724948883057,
      "learning_rate": 1.1809101380507848e-05,
      "loss": 0.0436,
      "step": 88900
    },
    {
      "epoch": 6.119782713332875,
      "grad_norm": 0.26575857400894165,
      "learning_rate": 1.1766121684116424e-05,
      "loss": 0.0441,
      "step": 89000
    },
    {
      "epoch": 6.126658873684934,
      "grad_norm": 0.3188166618347168,
      "learning_rate": 1.1723141987725e-05,
      "loss": 0.0463,
      "step": 89100
    },
    {
      "epoch": 6.133535034036994,
      "grad_norm": 0.6048237085342407,
      "learning_rate": 1.1680162291333574e-05,
      "loss": 0.0478,
      "step": 89200
    },
    {
      "epoch": 6.140411194389053,
      "grad_norm": 1.5846365690231323,
      "learning_rate": 1.163718259494215e-05,
      "loss": 0.0434,
      "step": 89300
    },
    {
      "epoch": 6.147287354741112,
      "grad_norm": 0.2732214331626892,
      "learning_rate": 1.1594202898550725e-05,
      "loss": 0.0449,
      "step": 89400
    },
    {
      "epoch": 6.154163515093172,
      "grad_norm": 0.29127973318099976,
      "learning_rate": 1.15512232021593e-05,
      "loss": 0.0447,
      "step": 89500
    },
    {
      "epoch": 6.161039675445231,
      "grad_norm": 0.35236722230911255,
      "learning_rate": 1.1508243505767876e-05,
      "loss": 0.044,
      "step": 89600
    },
    {
      "epoch": 6.167915835797291,
      "grad_norm": 0.4103042781352997,
      "learning_rate": 1.1465263809376452e-05,
      "loss": 0.0452,
      "step": 89700
    },
    {
      "epoch": 6.1747919961493505,
      "grad_norm": 0.3188674747943878,
      "learning_rate": 1.1422284112985027e-05,
      "loss": 0.0447,
      "step": 89800
    },
    {
      "epoch": 6.181668156501409,
      "grad_norm": 0.4430748224258423,
      "learning_rate": 1.1379304416593601e-05,
      "loss": 0.047,
      "step": 89900
    },
    {
      "epoch": 6.188544316853469,
      "grad_norm": 0.530227780342102,
      "learning_rate": 1.1336324720202177e-05,
      "loss": 0.0461,
      "step": 90000
    },
    {
      "epoch": 6.195420477205529,
      "grad_norm": 0.6718504428863525,
      "learning_rate": 1.1293345023810752e-05,
      "loss": 0.0454,
      "step": 90100
    },
    {
      "epoch": 6.202296637557588,
      "grad_norm": 0.4603680372238159,
      "learning_rate": 1.1250365327419328e-05,
      "loss": 0.0437,
      "step": 90200
    },
    {
      "epoch": 6.209172797909647,
      "grad_norm": 0.32584938406944275,
      "learning_rate": 1.1207385631027904e-05,
      "loss": 0.0445,
      "step": 90300
    },
    {
      "epoch": 6.216048958261707,
      "grad_norm": 0.3055243194103241,
      "learning_rate": 1.1164405934636477e-05,
      "loss": 0.0443,
      "step": 90400
    },
    {
      "epoch": 6.222925118613766,
      "grad_norm": 0.34559619426727295,
      "learning_rate": 1.1121426238245053e-05,
      "loss": 0.045,
      "step": 90500
    },
    {
      "epoch": 6.229801278965826,
      "grad_norm": 0.45193469524383545,
      "learning_rate": 1.1078446541853629e-05,
      "loss": 0.0428,
      "step": 90600
    },
    {
      "epoch": 6.2366774393178845,
      "grad_norm": 0.25805193185806274,
      "learning_rate": 1.1035466845462204e-05,
      "loss": 0.044,
      "step": 90700
    },
    {
      "epoch": 6.243553599669944,
      "grad_norm": 0.411454439163208,
      "learning_rate": 1.099248714907078e-05,
      "loss": 0.0443,
      "step": 90800
    },
    {
      "epoch": 6.250429760022004,
      "grad_norm": 0.5128999948501587,
      "learning_rate": 1.0949507452679354e-05,
      "loss": 0.0434,
      "step": 90900
    },
    {
      "epoch": 6.257305920374063,
      "grad_norm": 0.2554810047149658,
      "learning_rate": 1.0906527756287931e-05,
      "loss": 0.0459,
      "step": 91000
    },
    {
      "epoch": 6.264182080726123,
      "grad_norm": 0.3638697862625122,
      "learning_rate": 1.0863548059896505e-05,
      "loss": 0.0471,
      "step": 91100
    },
    {
      "epoch": 6.271058241078182,
      "grad_norm": 0.2337154597043991,
      "learning_rate": 1.082056836350508e-05,
      "loss": 0.0451,
      "step": 91200
    },
    {
      "epoch": 6.277934401430241,
      "grad_norm": 0.26793795824050903,
      "learning_rate": 1.0777588667113656e-05,
      "loss": 0.0426,
      "step": 91300
    },
    {
      "epoch": 6.284810561782301,
      "grad_norm": 0.5344179272651672,
      "learning_rate": 1.0734608970722232e-05,
      "loss": 0.0451,
      "step": 91400
    },
    {
      "epoch": 6.29168672213436,
      "grad_norm": 0.4260718822479248,
      "learning_rate": 1.0691629274330807e-05,
      "loss": 0.045,
      "step": 91500
    },
    {
      "epoch": 6.2985628824864195,
      "grad_norm": 0.4367917776107788,
      "learning_rate": 1.0648649577939381e-05,
      "loss": 0.0433,
      "step": 91600
    },
    {
      "epoch": 6.305439042838479,
      "grad_norm": 0.3063448965549469,
      "learning_rate": 1.0605669881547957e-05,
      "loss": 0.0441,
      "step": 91700
    },
    {
      "epoch": 6.312315203190538,
      "grad_norm": 0.5805526971817017,
      "learning_rate": 1.0562690185156533e-05,
      "loss": 0.048,
      "step": 91800
    },
    {
      "epoch": 6.319191363542598,
      "grad_norm": 0.4508161246776581,
      "learning_rate": 1.0519710488765108e-05,
      "loss": 0.0457,
      "step": 91900
    },
    {
      "epoch": 6.3260675238946575,
      "grad_norm": 0.42508357763290405,
      "learning_rate": 1.0476730792373684e-05,
      "loss": 0.0424,
      "step": 92000
    },
    {
      "epoch": 6.332943684246716,
      "grad_norm": 0.3535304069519043,
      "learning_rate": 1.0433751095982258e-05,
      "loss": 0.0429,
      "step": 92100
    },
    {
      "epoch": 6.339819844598776,
      "grad_norm": 0.8272221684455872,
      "learning_rate": 1.0390771399590833e-05,
      "loss": 0.0442,
      "step": 92200
    },
    {
      "epoch": 6.346696004950836,
      "grad_norm": 0.4154532253742218,
      "learning_rate": 1.0347791703199409e-05,
      "loss": 0.0457,
      "step": 92300
    },
    {
      "epoch": 6.353572165302895,
      "grad_norm": 0.5135306119918823,
      "learning_rate": 1.0304812006807984e-05,
      "loss": 0.0457,
      "step": 92400
    },
    {
      "epoch": 6.360448325654954,
      "grad_norm": 0.5762563347816467,
      "learning_rate": 1.026183231041656e-05,
      "loss": 0.049,
      "step": 92500
    },
    {
      "epoch": 6.367324486007013,
      "grad_norm": 0.5852146744728088,
      "learning_rate": 1.0218852614025134e-05,
      "loss": 0.0426,
      "step": 92600
    },
    {
      "epoch": 6.374200646359073,
      "grad_norm": 0.7664394378662109,
      "learning_rate": 1.0175872917633711e-05,
      "loss": 0.0465,
      "step": 92700
    },
    {
      "epoch": 6.381076806711133,
      "grad_norm": 0.9972914457321167,
      "learning_rate": 1.0132893221242285e-05,
      "loss": 0.0467,
      "step": 92800
    },
    {
      "epoch": 6.387952967063192,
      "grad_norm": 0.3303619623184204,
      "learning_rate": 1.008991352485086e-05,
      "loss": 0.0444,
      "step": 92900
    },
    {
      "epoch": 6.394829127415251,
      "grad_norm": 0.321668803691864,
      "learning_rate": 1.0046933828459436e-05,
      "loss": 0.0438,
      "step": 93000
    },
    {
      "epoch": 6.401705287767311,
      "grad_norm": 0.48114416003227234,
      "learning_rate": 1.0003954132068012e-05,
      "loss": 0.0429,
      "step": 93100
    },
    {
      "epoch": 6.40858144811937,
      "grad_norm": 0.3171711564064026,
      "learning_rate": 9.961404232640501e-06,
      "loss": 0.0443,
      "step": 93200
    },
    {
      "epoch": 6.41545760847143,
      "grad_norm": 0.7514258027076721,
      "learning_rate": 9.918424536249077e-06,
      "loss": 0.0459,
      "step": 93300
    },
    {
      "epoch": 6.4223337688234885,
      "grad_norm": 0.2731405198574066,
      "learning_rate": 9.875444839857652e-06,
      "loss": 0.0421,
      "step": 93400
    },
    {
      "epoch": 6.429209929175548,
      "grad_norm": 0.6005260944366455,
      "learning_rate": 9.832465143466226e-06,
      "loss": 0.0435,
      "step": 93500
    },
    {
      "epoch": 6.436086089527608,
      "grad_norm": 0.30248624086380005,
      "learning_rate": 9.789485447074802e-06,
      "loss": 0.0456,
      "step": 93600
    },
    {
      "epoch": 6.442962249879667,
      "grad_norm": 0.2851547300815582,
      "learning_rate": 9.746505750683377e-06,
      "loss": 0.0414,
      "step": 93700
    },
    {
      "epoch": 6.4498384102317265,
      "grad_norm": 0.8913211822509766,
      "learning_rate": 9.703526054291953e-06,
      "loss": 0.0438,
      "step": 93800
    },
    {
      "epoch": 6.456714570583786,
      "grad_norm": 0.38681766390800476,
      "learning_rate": 9.660546357900529e-06,
      "loss": 0.0462,
      "step": 93900
    },
    {
      "epoch": 6.463590730935845,
      "grad_norm": 0.37655109167099,
      "learning_rate": 9.617566661509103e-06,
      "loss": 0.0416,
      "step": 94000
    },
    {
      "epoch": 6.470466891287905,
      "grad_norm": 0.48169177770614624,
      "learning_rate": 9.57458696511768e-06,
      "loss": 0.047,
      "step": 94100
    },
    {
      "epoch": 6.477343051639965,
      "grad_norm": 0.4721084535121918,
      "learning_rate": 9.531607268726254e-06,
      "loss": 0.0433,
      "step": 94200
    },
    {
      "epoch": 6.4842192119920234,
      "grad_norm": 0.43478548526763916,
      "learning_rate": 9.48862757233483e-06,
      "loss": 0.0429,
      "step": 94300
    },
    {
      "epoch": 6.491095372344083,
      "grad_norm": 0.5647823810577393,
      "learning_rate": 9.445647875943405e-06,
      "loss": 0.0453,
      "step": 94400
    },
    {
      "epoch": 6.497971532696143,
      "grad_norm": 0.5486835837364197,
      "learning_rate": 9.402668179551979e-06,
      "loss": 0.0433,
      "step": 94500
    },
    {
      "epoch": 6.504847693048202,
      "grad_norm": 0.41428306698799133,
      "learning_rate": 9.359688483160556e-06,
      "loss": 0.0431,
      "step": 94600
    },
    {
      "epoch": 6.5117238534002615,
      "grad_norm": 0.42088639736175537,
      "learning_rate": 9.31670878676913e-06,
      "loss": 0.0429,
      "step": 94700
    },
    {
      "epoch": 6.51860001375232,
      "grad_norm": 0.4359976351261139,
      "learning_rate": 9.273729090377706e-06,
      "loss": 0.0448,
      "step": 94800
    },
    {
      "epoch": 6.52547617410438,
      "grad_norm": 0.374724417924881,
      "learning_rate": 9.230749393986281e-06,
      "loss": 0.0428,
      "step": 94900
    },
    {
      "epoch": 6.53235233445644,
      "grad_norm": 0.6555399298667908,
      "learning_rate": 9.187769697594857e-06,
      "loss": 0.044,
      "step": 95000
    },
    {
      "epoch": 6.539228494808499,
      "grad_norm": 0.4057709276676178,
      "learning_rate": 9.144790001203432e-06,
      "loss": 0.0442,
      "step": 95100
    },
    {
      "epoch": 6.546104655160558,
      "grad_norm": 0.469952255487442,
      "learning_rate": 9.101810304812006e-06,
      "loss": 0.0471,
      "step": 95200
    },
    {
      "epoch": 6.552980815512618,
      "grad_norm": 0.4076293110847473,
      "learning_rate": 9.058830608420582e-06,
      "loss": 0.0449,
      "step": 95300
    },
    {
      "epoch": 6.559856975864677,
      "grad_norm": 0.33173200488090515,
      "learning_rate": 9.015850912029158e-06,
      "loss": 0.0412,
      "step": 95400
    },
    {
      "epoch": 6.566733136216737,
      "grad_norm": 0.2549648880958557,
      "learning_rate": 8.972871215637733e-06,
      "loss": 0.0415,
      "step": 95500
    },
    {
      "epoch": 6.573609296568796,
      "grad_norm": 0.33038008213043213,
      "learning_rate": 8.929891519246309e-06,
      "loss": 0.0435,
      "step": 95600
    },
    {
      "epoch": 6.580485456920855,
      "grad_norm": 0.43109315633773804,
      "learning_rate": 8.886911822854883e-06,
      "loss": 0.0486,
      "step": 95700
    },
    {
      "epoch": 6.587361617272915,
      "grad_norm": 0.5426523089408875,
      "learning_rate": 8.84393212646346e-06,
      "loss": 0.0462,
      "step": 95800
    },
    {
      "epoch": 6.594237777624974,
      "grad_norm": 0.8276709914207458,
      "learning_rate": 8.801382227035947e-06,
      "loss": 0.0442,
      "step": 95900
    },
    {
      "epoch": 6.601113937977034,
      "grad_norm": 0.4868335425853729,
      "learning_rate": 8.758832327608438e-06,
      "loss": 0.0438,
      "step": 96000
    },
    {
      "epoch": 6.607990098329093,
      "grad_norm": 0.46592769026756287,
      "learning_rate": 8.715852631217014e-06,
      "loss": 0.0441,
      "step": 96100
    },
    {
      "epoch": 6.614866258681152,
      "grad_norm": 0.5220495462417603,
      "learning_rate": 8.67287293482559e-06,
      "loss": 0.0461,
      "step": 96200
    },
    {
      "epoch": 6.621742419033212,
      "grad_norm": 0.3902672529220581,
      "learning_rate": 8.629893238434163e-06,
      "loss": 0.0452,
      "step": 96300
    },
    {
      "epoch": 6.628618579385272,
      "grad_norm": 0.48432430624961853,
      "learning_rate": 8.586913542042739e-06,
      "loss": 0.0437,
      "step": 96400
    },
    {
      "epoch": 6.6354947397373305,
      "grad_norm": 0.2440929114818573,
      "learning_rate": 8.543933845651314e-06,
      "loss": 0.0417,
      "step": 96500
    },
    {
      "epoch": 6.64237090008939,
      "grad_norm": 0.40943023562431335,
      "learning_rate": 8.50095414925989e-06,
      "loss": 0.0441,
      "step": 96600
    },
    {
      "epoch": 6.64924706044145,
      "grad_norm": 0.4072720408439636,
      "learning_rate": 8.457974452868466e-06,
      "loss": 0.0436,
      "step": 96700
    },
    {
      "epoch": 6.656123220793509,
      "grad_norm": 0.5080424547195435,
      "learning_rate": 8.41499475647704e-06,
      "loss": 0.0459,
      "step": 96800
    },
    {
      "epoch": 6.662999381145569,
      "grad_norm": 0.30665016174316406,
      "learning_rate": 8.372015060085615e-06,
      "loss": 0.0463,
      "step": 96900
    },
    {
      "epoch": 6.669875541497627,
      "grad_norm": 0.41773930191993713,
      "learning_rate": 8.329035363694192e-06,
      "loss": 0.047,
      "step": 97000
    },
    {
      "epoch": 6.676751701849687,
      "grad_norm": 0.5791293382644653,
      "learning_rate": 8.286055667302766e-06,
      "loss": 0.0458,
      "step": 97100
    },
    {
      "epoch": 6.683627862201747,
      "grad_norm": 0.4019111692905426,
      "learning_rate": 8.243075970911342e-06,
      "loss": 0.0439,
      "step": 97200
    },
    {
      "epoch": 6.690504022553806,
      "grad_norm": 0.4583531618118286,
      "learning_rate": 8.200096274519916e-06,
      "loss": 0.0443,
      "step": 97300
    },
    {
      "epoch": 6.6973801829058655,
      "grad_norm": 0.4921664595603943,
      "learning_rate": 8.157116578128493e-06,
      "loss": 0.0446,
      "step": 97400
    },
    {
      "epoch": 6.704256343257924,
      "grad_norm": 0.21035388112068176,
      "learning_rate": 8.114136881737069e-06,
      "loss": 0.043,
      "step": 97500
    },
    {
      "epoch": 6.711132503609984,
      "grad_norm": 0.38558343052864075,
      "learning_rate": 8.071157185345643e-06,
      "loss": 0.0448,
      "step": 97600
    },
    {
      "epoch": 6.718008663962044,
      "grad_norm": 0.5778940320014954,
      "learning_rate": 8.028177488954218e-06,
      "loss": 0.0437,
      "step": 97700
    },
    {
      "epoch": 6.724884824314103,
      "grad_norm": 0.6808095574378967,
      "learning_rate": 7.985197792562794e-06,
      "loss": 0.0477,
      "step": 97800
    },
    {
      "epoch": 6.731760984666162,
      "grad_norm": 0.4133114516735077,
      "learning_rate": 7.94221809617137e-06,
      "loss": 0.0447,
      "step": 97900
    },
    {
      "epoch": 6.738637145018222,
      "grad_norm": 0.5389540195465088,
      "learning_rate": 7.899238399779945e-06,
      "loss": 0.0419,
      "step": 98000
    },
    {
      "epoch": 6.745513305370281,
      "grad_norm": 0.3537207245826721,
      "learning_rate": 7.856258703388519e-06,
      "loss": 0.0435,
      "step": 98100
    },
    {
      "epoch": 6.752389465722341,
      "grad_norm": 0.4881126880645752,
      "learning_rate": 7.813279006997095e-06,
      "loss": 0.0448,
      "step": 98200
    },
    {
      "epoch": 6.7592656260744,
      "grad_norm": 0.33254602551460266,
      "learning_rate": 7.77029931060567e-06,
      "loss": 0.0447,
      "step": 98300
    },
    {
      "epoch": 6.766141786426459,
      "grad_norm": 0.512460470199585,
      "learning_rate": 7.727319614214246e-06,
      "loss": 0.0451,
      "step": 98400
    },
    {
      "epoch": 6.773017946778519,
      "grad_norm": 0.3837965726852417,
      "learning_rate": 7.684339917822821e-06,
      "loss": 0.0481,
      "step": 98500
    },
    {
      "epoch": 6.779894107130579,
      "grad_norm": 0.4279669225215912,
      "learning_rate": 7.641360221431395e-06,
      "loss": 0.0456,
      "step": 98600
    },
    {
      "epoch": 6.786770267482638,
      "grad_norm": 0.2726851999759674,
      "learning_rate": 7.598380525039972e-06,
      "loss": 0.0447,
      "step": 98700
    },
    {
      "epoch": 6.793646427834697,
      "grad_norm": 0.3513340651988983,
      "learning_rate": 7.555400828648547e-06,
      "loss": 0.0447,
      "step": 98800
    },
    {
      "epoch": 6.800522588186756,
      "grad_norm": 0.4352700114250183,
      "learning_rate": 7.512421132257122e-06,
      "loss": 0.0453,
      "step": 98900
    },
    {
      "epoch": 6.807398748538816,
      "grad_norm": 0.5227136611938477,
      "learning_rate": 7.469441435865697e-06,
      "loss": 0.0417,
      "step": 99000
    },
    {
      "epoch": 6.814274908890876,
      "grad_norm": 0.30226096510887146,
      "learning_rate": 7.426461739474273e-06,
      "loss": 0.0431,
      "step": 99100
    },
    {
      "epoch": 6.8211510692429345,
      "grad_norm": 0.286270409822464,
      "learning_rate": 7.383482043082848e-06,
      "loss": 0.0462,
      "step": 99200
    },
    {
      "epoch": 6.828027229594994,
      "grad_norm": 0.30602654814720154,
      "learning_rate": 7.340932143655338e-06,
      "loss": 0.0427,
      "step": 99300
    },
    {
      "epoch": 6.834903389947054,
      "grad_norm": 0.463439404964447,
      "learning_rate": 7.297952447263913e-06,
      "loss": 0.0472,
      "step": 99400
    },
    {
      "epoch": 6.841779550299113,
      "grad_norm": 0.18099486827850342,
      "learning_rate": 7.254972750872488e-06,
      "loss": 0.0451,
      "step": 99500
    },
    {
      "epoch": 6.8486557106511725,
      "grad_norm": 0.5644833445549011,
      "learning_rate": 7.211993054481063e-06,
      "loss": 0.0434,
      "step": 99600
    },
    {
      "epoch": 6.855531871003231,
      "grad_norm": 0.45026618242263794,
      "learning_rate": 7.16901335808964e-06,
      "loss": 0.0426,
      "step": 99700
    },
    {
      "epoch": 6.862408031355291,
      "grad_norm": 0.3148750364780426,
      "learning_rate": 7.126033661698214e-06,
      "loss": 0.0434,
      "step": 99800
    },
    {
      "epoch": 6.869284191707351,
      "grad_norm": 0.2950364947319031,
      "learning_rate": 7.083053965306789e-06,
      "loss": 0.0431,
      "step": 99900
    },
    {
      "epoch": 6.87616035205941,
      "grad_norm": 1.2898123264312744,
      "learning_rate": 7.040074268915364e-06,
      "loss": 0.0431,
      "step": 100000
    },
    {
      "epoch": 6.883036512411469,
      "grad_norm": 0.4527111351490021,
      "learning_rate": 6.99709457252394e-06,
      "loss": 0.0469,
      "step": 100100
    },
    {
      "epoch": 6.889912672763529,
      "grad_norm": 0.8431515097618103,
      "learning_rate": 6.954114876132516e-06,
      "loss": 0.044,
      "step": 100200
    },
    {
      "epoch": 6.896788833115588,
      "grad_norm": 0.3813766539096832,
      "learning_rate": 6.911135179741091e-06,
      "loss": 0.0453,
      "step": 100300
    },
    {
      "epoch": 6.903664993467648,
      "grad_norm": 0.49122536182403564,
      "learning_rate": 6.8681554833496655e-06,
      "loss": 0.0454,
      "step": 100400
    },
    {
      "epoch": 6.9105411538197075,
      "grad_norm": 0.5981202721595764,
      "learning_rate": 6.825175786958242e-06,
      "loss": 0.0446,
      "step": 100500
    },
    {
      "epoch": 6.917417314171766,
      "grad_norm": 0.7902095317840576,
      "learning_rate": 6.782196090566817e-06,
      "loss": 0.0412,
      "step": 100600
    },
    {
      "epoch": 6.924293474523826,
      "grad_norm": 0.397964745759964,
      "learning_rate": 6.739216394175392e-06,
      "loss": 0.0439,
      "step": 100700
    },
    {
      "epoch": 6.931169634875886,
      "grad_norm": 0.3304089903831482,
      "learning_rate": 6.696236697783967e-06,
      "loss": 0.0453,
      "step": 100800
    },
    {
      "epoch": 6.938045795227945,
      "grad_norm": 0.5476592779159546,
      "learning_rate": 6.653257001392542e-06,
      "loss": 0.0456,
      "step": 100900
    },
    {
      "epoch": 6.944921955580004,
      "grad_norm": 0.521518886089325,
      "learning_rate": 6.610277305001118e-06,
      "loss": 0.0455,
      "step": 101000
    },
    {
      "epoch": 6.951798115932063,
      "grad_norm": 0.6679394245147705,
      "learning_rate": 6.567297608609693e-06,
      "loss": 0.0408,
      "step": 101100
    },
    {
      "epoch": 6.958674276284123,
      "grad_norm": 0.550542414188385,
      "learning_rate": 6.524317912218268e-06,
      "loss": 0.0443,
      "step": 101200
    },
    {
      "epoch": 6.965550436636183,
      "grad_norm": 0.35550084710121155,
      "learning_rate": 6.481338215826843e-06,
      "loss": 0.0445,
      "step": 101300
    },
    {
      "epoch": 6.9724265969882415,
      "grad_norm": 0.4106431305408478,
      "learning_rate": 6.43835851943542e-06,
      "loss": 0.0424,
      "step": 101400
    },
    {
      "epoch": 6.979302757340301,
      "grad_norm": 0.6368169188499451,
      "learning_rate": 6.395378823043995e-06,
      "loss": 0.0461,
      "step": 101500
    },
    {
      "epoch": 6.98617891769236,
      "grad_norm": 0.5073424577713013,
      "learning_rate": 6.352399126652569e-06,
      "loss": 0.0418,
      "step": 101600
    },
    {
      "epoch": 6.99305507804442,
      "grad_norm": 0.3531944751739502,
      "learning_rate": 6.309419430261144e-06,
      "loss": 0.0439,
      "step": 101700
    },
    {
      "epoch": 6.99993123839648,
      "grad_norm": 0.4385521709918976,
      "learning_rate": 6.266439733869721e-06,
      "loss": 0.0413,
      "step": 101800
    },
    {
      "epoch": 7.0,
      "eval_accuracy_macro_0.5": 0.9794561862945557,
      "eval_accuracy_micro_0.5": 0.9794561862945557,
      "eval_accuracy_weighted_0.5": 0.9766751527786255,
      "eval_f1_macro_0.5": 0.7198929190635681,
      "eval_f1_macro_0.6": 0.6936954259872437,
      "eval_f1_macro_0.7": 0.6463688015937805,
      "eval_f1_macro_0.8": 0.42725881934165955,
      "eval_f1_micro_0.5": 0.7214626669883728,
      "eval_f1_micro_0.6": 0.7006236910820007,
      "eval_f1_micro_0.7": 0.6624476909637451,
      "eval_f1_micro_0.8": 0.5974574685096741,
      "eval_f1_micro_0.9": 0.4640794098377228,
      "eval_f1_weighted_0.5": 0.7118565440177917,
      "eval_f1_weighted_0.6": 0.6838812232017517,
      "eval_f1_weighted_0.7": 0.63463294506073,
      "eval_f1_weighted_0.8": 0.40046632289886475,
      "eval_loss": 0.043907955288887024,
      "eval_runtime": 290.8793,
      "eval_samples_per_second": 99.825,
      "eval_steps_per_second": 12.479,
      "step": 101801
    }
  ],
  "logging_steps": 100,
  "max_steps": 116344,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0519851348551386e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
