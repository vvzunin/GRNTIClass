{
  "best_metric": 0.8397758603096008,
  "best_model_checkpoint": "results_7_no_lora/model bert lora level 1/checkpoint-228152",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 228152,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0035064343069532594,
      "grad_norm": 0.32441312074661255,
      "learning_rate": 4.998027544248758e-05,
      "loss": 0.462,
      "step": 100
    },
    {
      "epoch": 0.007012868613906519,
      "grad_norm": 0.2712792754173279,
      "learning_rate": 4.995835926747377e-05,
      "loss": 0.1463,
      "step": 200
    },
    {
      "epoch": 0.010519302920859779,
      "grad_norm": 0.28784698247909546,
      "learning_rate": 4.9936443092459964e-05,
      "loss": 0.1417,
      "step": 300
    },
    {
      "epoch": 0.014025737227813037,
      "grad_norm": 0.37224361300468445,
      "learning_rate": 4.9914526917446155e-05,
      "loss": 0.1352,
      "step": 400
    },
    {
      "epoch": 0.017532171534766296,
      "grad_norm": 0.20671747624874115,
      "learning_rate": 4.989261074243235e-05,
      "loss": 0.1312,
      "step": 500
    },
    {
      "epoch": 0.021038605841719557,
      "grad_norm": 0.4041837155818939,
      "learning_rate": 4.987069456741854e-05,
      "loss": 0.1175,
      "step": 600
    },
    {
      "epoch": 0.024545040148672814,
      "grad_norm": 0.1850184053182602,
      "learning_rate": 4.984877839240473e-05,
      "loss": 0.1074,
      "step": 700
    },
    {
      "epoch": 0.028051474455626075,
      "grad_norm": 0.2960622310638428,
      "learning_rate": 4.982686221739092e-05,
      "loss": 0.1024,
      "step": 800
    },
    {
      "epoch": 0.031557908762579336,
      "grad_norm": 0.3168170154094696,
      "learning_rate": 4.980494604237712e-05,
      "loss": 0.0957,
      "step": 900
    },
    {
      "epoch": 0.03506434306953259,
      "grad_norm": 0.23193050920963287,
      "learning_rate": 4.978302986736331e-05,
      "loss": 0.097,
      "step": 1000
    },
    {
      "epoch": 0.03857077737648585,
      "grad_norm": 0.37570682168006897,
      "learning_rate": 4.97611136923495e-05,
      "loss": 0.0891,
      "step": 1100
    },
    {
      "epoch": 0.042077211683439114,
      "grad_norm": 0.19566501677036285,
      "learning_rate": 4.97391975173357e-05,
      "loss": 0.0806,
      "step": 1200
    },
    {
      "epoch": 0.04558364599039237,
      "grad_norm": 0.20439743995666504,
      "learning_rate": 4.9717281342321895e-05,
      "loss": 0.0824,
      "step": 1300
    },
    {
      "epoch": 0.04909008029734563,
      "grad_norm": 0.2825549840927124,
      "learning_rate": 4.9695365167308085e-05,
      "loss": 0.0815,
      "step": 1400
    },
    {
      "epoch": 0.052596514604298886,
      "grad_norm": 0.2951584756374359,
      "learning_rate": 4.9673448992294275e-05,
      "loss": 0.0751,
      "step": 1500
    },
    {
      "epoch": 0.05610294891125215,
      "grad_norm": 0.25784480571746826,
      "learning_rate": 4.9651532817280466e-05,
      "loss": 0.0746,
      "step": 1600
    },
    {
      "epoch": 0.05960938321820541,
      "grad_norm": 0.2253948301076889,
      "learning_rate": 4.962961664226666e-05,
      "loss": 0.0743,
      "step": 1700
    },
    {
      "epoch": 0.06311581752515867,
      "grad_norm": 0.27561211585998535,
      "learning_rate": 4.960770046725285e-05,
      "loss": 0.0732,
      "step": 1800
    },
    {
      "epoch": 0.06662225183211193,
      "grad_norm": 0.24354901909828186,
      "learning_rate": 4.9585784292239044e-05,
      "loss": 0.0664,
      "step": 1900
    },
    {
      "epoch": 0.07012868613906519,
      "grad_norm": 0.28491082787513733,
      "learning_rate": 4.9563868117225234e-05,
      "loss": 0.0695,
      "step": 2000
    },
    {
      "epoch": 0.07363512044601844,
      "grad_norm": 0.24288097023963928,
      "learning_rate": 4.954195194221143e-05,
      "loss": 0.07,
      "step": 2100
    },
    {
      "epoch": 0.0771415547529717,
      "grad_norm": 0.3183673918247223,
      "learning_rate": 4.952003576719763e-05,
      "loss": 0.0727,
      "step": 2200
    },
    {
      "epoch": 0.08064798905992496,
      "grad_norm": 0.3569782078266144,
      "learning_rate": 4.949811959218382e-05,
      "loss": 0.0692,
      "step": 2300
    },
    {
      "epoch": 0.08415442336687823,
      "grad_norm": 0.1691238135099411,
      "learning_rate": 4.947620341717001e-05,
      "loss": 0.0662,
      "step": 2400
    },
    {
      "epoch": 0.08766085767383149,
      "grad_norm": 0.19537842273712158,
      "learning_rate": 4.9454287242156206e-05,
      "loss": 0.066,
      "step": 2500
    },
    {
      "epoch": 0.09116729198078474,
      "grad_norm": 0.272036612033844,
      "learning_rate": 4.9432371067142396e-05,
      "loss": 0.0686,
      "step": 2600
    },
    {
      "epoch": 0.094673726287738,
      "grad_norm": 0.2850540578365326,
      "learning_rate": 4.9410454892128586e-05,
      "loss": 0.0651,
      "step": 2700
    },
    {
      "epoch": 0.09818016059469126,
      "grad_norm": 0.11696089059114456,
      "learning_rate": 4.938853871711478e-05,
      "loss": 0.0639,
      "step": 2800
    },
    {
      "epoch": 0.10168659490164451,
      "grad_norm": 0.2200356125831604,
      "learning_rate": 4.9366622542100974e-05,
      "loss": 0.0658,
      "step": 2900
    },
    {
      "epoch": 0.10519302920859777,
      "grad_norm": 0.21344093978405,
      "learning_rate": 4.934470636708717e-05,
      "loss": 0.0595,
      "step": 3000
    },
    {
      "epoch": 0.10869946351555104,
      "grad_norm": 0.28685158491134644,
      "learning_rate": 4.93230093538235e-05,
      "loss": 0.0651,
      "step": 3100
    },
    {
      "epoch": 0.1122058978225043,
      "grad_norm": 0.6547405123710632,
      "learning_rate": 4.9301093178809694e-05,
      "loss": 0.0696,
      "step": 3200
    },
    {
      "epoch": 0.11571233212945756,
      "grad_norm": 0.2590680718421936,
      "learning_rate": 4.9279177003795884e-05,
      "loss": 0.067,
      "step": 3300
    },
    {
      "epoch": 0.11921876643641081,
      "grad_norm": 0.1655191332101822,
      "learning_rate": 4.9257260828782075e-05,
      "loss": 0.0599,
      "step": 3400
    },
    {
      "epoch": 0.12272520074336407,
      "grad_norm": 0.18330085277557373,
      "learning_rate": 4.9235344653768265e-05,
      "loss": 0.06,
      "step": 3500
    },
    {
      "epoch": 0.12623163505031734,
      "grad_norm": 0.27806058526039124,
      "learning_rate": 4.921342847875446e-05,
      "loss": 0.0625,
      "step": 3600
    },
    {
      "epoch": 0.12973806935727059,
      "grad_norm": 0.16588841378688812,
      "learning_rate": 4.919151230374065e-05,
      "loss": 0.0626,
      "step": 3700
    },
    {
      "epoch": 0.13324450366422386,
      "grad_norm": 0.22425268590450287,
      "learning_rate": 4.916959612872685e-05,
      "loss": 0.0579,
      "step": 3800
    },
    {
      "epoch": 0.1367509379711771,
      "grad_norm": 0.2038101702928543,
      "learning_rate": 4.914767995371304e-05,
      "loss": 0.0617,
      "step": 3900
    },
    {
      "epoch": 0.14025737227813037,
      "grad_norm": 0.2994924783706665,
      "learning_rate": 4.912576377869924e-05,
      "loss": 0.0559,
      "step": 4000
    },
    {
      "epoch": 0.14376380658508364,
      "grad_norm": 0.3225223124027252,
      "learning_rate": 4.910384760368543e-05,
      "loss": 0.0654,
      "step": 4100
    },
    {
      "epoch": 0.14727024089203689,
      "grad_norm": 0.22780948877334595,
      "learning_rate": 4.908193142867162e-05,
      "loss": 0.0575,
      "step": 4200
    },
    {
      "epoch": 0.15077667519899016,
      "grad_norm": 0.20801670849323273,
      "learning_rate": 4.906001525365781e-05,
      "loss": 0.0601,
      "step": 4300
    },
    {
      "epoch": 0.1542831095059434,
      "grad_norm": 0.13326556980609894,
      "learning_rate": 4.9038099078644005e-05,
      "loss": 0.0566,
      "step": 4400
    },
    {
      "epoch": 0.15778954381289667,
      "grad_norm": 0.49143996834754944,
      "learning_rate": 4.9016182903630195e-05,
      "loss": 0.0588,
      "step": 4500
    },
    {
      "epoch": 0.16129597811984991,
      "grad_norm": 0.23949365317821503,
      "learning_rate": 4.899426672861639e-05,
      "loss": 0.0557,
      "step": 4600
    },
    {
      "epoch": 0.16480241242680319,
      "grad_norm": 0.15507754683494568,
      "learning_rate": 4.897235055360258e-05,
      "loss": 0.0619,
      "step": 4700
    },
    {
      "epoch": 0.16830884673375646,
      "grad_norm": 0.38422924280166626,
      "learning_rate": 4.895043437858878e-05,
      "loss": 0.0557,
      "step": 4800
    },
    {
      "epoch": 0.1718152810407097,
      "grad_norm": 0.19725483655929565,
      "learning_rate": 4.892851820357497e-05,
      "loss": 0.056,
      "step": 4900
    },
    {
      "epoch": 0.17532171534766297,
      "grad_norm": 0.2061646282672882,
      "learning_rate": 4.890660202856116e-05,
      "loss": 0.0553,
      "step": 5000
    },
    {
      "epoch": 0.17882814965461621,
      "grad_norm": 0.29451146721839905,
      "learning_rate": 4.888468585354735e-05,
      "loss": 0.0568,
      "step": 5100
    },
    {
      "epoch": 0.18233458396156949,
      "grad_norm": 0.21562862396240234,
      "learning_rate": 4.886276967853355e-05,
      "loss": 0.0581,
      "step": 5200
    },
    {
      "epoch": 0.18584101826852273,
      "grad_norm": 0.2606694996356964,
      "learning_rate": 4.884085350351974e-05,
      "loss": 0.0565,
      "step": 5300
    },
    {
      "epoch": 0.189347452575476,
      "grad_norm": 0.30036500096321106,
      "learning_rate": 4.881893732850593e-05,
      "loss": 0.0534,
      "step": 5400
    },
    {
      "epoch": 0.19285388688242927,
      "grad_norm": 0.21891570091247559,
      "learning_rate": 4.8797021153492126e-05,
      "loss": 0.0571,
      "step": 5500
    },
    {
      "epoch": 0.19636032118938251,
      "grad_norm": 0.22949086129665375,
      "learning_rate": 4.877510497847832e-05,
      "loss": 0.0538,
      "step": 5600
    },
    {
      "epoch": 0.19986675549633579,
      "grad_norm": 0.1722595989704132,
      "learning_rate": 4.875318880346451e-05,
      "loss": 0.0558,
      "step": 5700
    },
    {
      "epoch": 0.20337318980328903,
      "grad_norm": 0.319430947303772,
      "learning_rate": 4.8731272628450704e-05,
      "loss": 0.061,
      "step": 5800
    },
    {
      "epoch": 0.2068796241102423,
      "grad_norm": 0.455900102853775,
      "learning_rate": 4.87093564534369e-05,
      "loss": 0.0591,
      "step": 5900
    },
    {
      "epoch": 0.21038605841719554,
      "grad_norm": 0.35639992356300354,
      "learning_rate": 4.868744027842309e-05,
      "loss": 0.0593,
      "step": 6000
    },
    {
      "epoch": 0.2138924927241488,
      "grad_norm": 0.23827925324440002,
      "learning_rate": 4.866552410340928e-05,
      "loss": 0.0527,
      "step": 6100
    },
    {
      "epoch": 0.21739892703110208,
      "grad_norm": 0.2825051546096802,
      "learning_rate": 4.864360792839547e-05,
      "loss": 0.0543,
      "step": 6200
    },
    {
      "epoch": 0.22090536133805533,
      "grad_norm": 0.27087631821632385,
      "learning_rate": 4.862169175338167e-05,
      "loss": 0.0489,
      "step": 6300
    },
    {
      "epoch": 0.2244117956450086,
      "grad_norm": 0.3366587460041046,
      "learning_rate": 4.859977557836786e-05,
      "loss": 0.0574,
      "step": 6400
    },
    {
      "epoch": 0.22791822995196184,
      "grad_norm": 0.27796581387519836,
      "learning_rate": 4.8577859403354056e-05,
      "loss": 0.0512,
      "step": 6500
    },
    {
      "epoch": 0.2314246642589151,
      "grad_norm": 0.33430081605911255,
      "learning_rate": 4.8555943228340246e-05,
      "loss": 0.0544,
      "step": 6600
    },
    {
      "epoch": 0.23493109856586836,
      "grad_norm": 0.3179198205471039,
      "learning_rate": 4.8534027053326444e-05,
      "loss": 0.0549,
      "step": 6700
    },
    {
      "epoch": 0.23843753287282163,
      "grad_norm": 0.438139945268631,
      "learning_rate": 4.8512110878312634e-05,
      "loss": 0.0532,
      "step": 6800
    },
    {
      "epoch": 0.2419439671797749,
      "grad_norm": 0.34939801692962646,
      "learning_rate": 4.8490194703298824e-05,
      "loss": 0.0548,
      "step": 6900
    },
    {
      "epoch": 0.24545040148672814,
      "grad_norm": 0.08497673273086548,
      "learning_rate": 4.8468278528285015e-05,
      "loss": 0.0539,
      "step": 7000
    },
    {
      "epoch": 0.2489568357936814,
      "grad_norm": 0.2156902253627777,
      "learning_rate": 4.844636235327121e-05,
      "loss": 0.0548,
      "step": 7100
    },
    {
      "epoch": 0.2524632701006347,
      "grad_norm": 0.2876072824001312,
      "learning_rate": 4.84244461782574e-05,
      "loss": 0.0569,
      "step": 7200
    },
    {
      "epoch": 0.25596970440758793,
      "grad_norm": 0.4061852693557739,
      "learning_rate": 4.84025300032436e-05,
      "loss": 0.0582,
      "step": 7300
    },
    {
      "epoch": 0.25947613871454117,
      "grad_norm": 0.32323312759399414,
      "learning_rate": 4.838061382822979e-05,
      "loss": 0.0543,
      "step": 7400
    },
    {
      "epoch": 0.2629825730214944,
      "grad_norm": 0.19901663064956665,
      "learning_rate": 4.8358697653215986e-05,
      "loss": 0.0514,
      "step": 7500
    },
    {
      "epoch": 0.2664890073284477,
      "grad_norm": 0.2674929201602936,
      "learning_rate": 4.833678147820218e-05,
      "loss": 0.0567,
      "step": 7600
    },
    {
      "epoch": 0.26999544163540096,
      "grad_norm": 0.3613262176513672,
      "learning_rate": 4.831486530318837e-05,
      "loss": 0.0532,
      "step": 7700
    },
    {
      "epoch": 0.2735018759423542,
      "grad_norm": 0.3808184564113617,
      "learning_rate": 4.829294912817456e-05,
      "loss": 0.0551,
      "step": 7800
    },
    {
      "epoch": 0.2770083102493075,
      "grad_norm": 0.2745293080806732,
      "learning_rate": 4.8271032953160755e-05,
      "loss": 0.0542,
      "step": 7900
    },
    {
      "epoch": 0.28051474455626074,
      "grad_norm": 0.24378886818885803,
      "learning_rate": 4.8249116778146945e-05,
      "loss": 0.0535,
      "step": 8000
    },
    {
      "epoch": 0.284021178863214,
      "grad_norm": 0.3196394145488739,
      "learning_rate": 4.8227200603133135e-05,
      "loss": 0.0556,
      "step": 8100
    },
    {
      "epoch": 0.2875276131701673,
      "grad_norm": 0.34177377820014954,
      "learning_rate": 4.820528442811933e-05,
      "loss": 0.052,
      "step": 8200
    },
    {
      "epoch": 0.2910340474771205,
      "grad_norm": 0.15498308837413788,
      "learning_rate": 4.818336825310553e-05,
      "loss": 0.0562,
      "step": 8300
    },
    {
      "epoch": 0.29454048178407377,
      "grad_norm": 0.2182765007019043,
      "learning_rate": 4.816145207809172e-05,
      "loss": 0.0499,
      "step": 8400
    },
    {
      "epoch": 0.298046916091027,
      "grad_norm": 0.2998393774032593,
      "learning_rate": 4.813953590307791e-05,
      "loss": 0.0509,
      "step": 8500
    },
    {
      "epoch": 0.3015533503979803,
      "grad_norm": 0.32959139347076416,
      "learning_rate": 4.81176197280641e-05,
      "loss": 0.0525,
      "step": 8600
    },
    {
      "epoch": 0.30505978470493356,
      "grad_norm": 0.24226216971874237,
      "learning_rate": 4.80957035530503e-05,
      "loss": 0.0547,
      "step": 8700
    },
    {
      "epoch": 0.3085662190118868,
      "grad_norm": 0.39769139885902405,
      "learning_rate": 4.807378737803649e-05,
      "loss": 0.053,
      "step": 8800
    },
    {
      "epoch": 0.3120726533188401,
      "grad_norm": 0.29845213890075684,
      "learning_rate": 4.805187120302268e-05,
      "loss": 0.049,
      "step": 8900
    },
    {
      "epoch": 0.31557908762579334,
      "grad_norm": 0.2843327522277832,
      "learning_rate": 4.802995502800887e-05,
      "loss": 0.0528,
      "step": 9000
    },
    {
      "epoch": 0.3190855219327466,
      "grad_norm": 0.15963415801525116,
      "learning_rate": 4.8008038852995066e-05,
      "loss": 0.0522,
      "step": 9100
    },
    {
      "epoch": 0.32259195623969983,
      "grad_norm": 0.3459770679473877,
      "learning_rate": 4.798612267798126e-05,
      "loss": 0.0536,
      "step": 9200
    },
    {
      "epoch": 0.3260983905466531,
      "grad_norm": 0.4766325056552887,
      "learning_rate": 4.796420650296745e-05,
      "loss": 0.0555,
      "step": 9300
    },
    {
      "epoch": 0.32960482485360637,
      "grad_norm": 0.19210052490234375,
      "learning_rate": 4.794229032795364e-05,
      "loss": 0.0501,
      "step": 9400
    },
    {
      "epoch": 0.3331112591605596,
      "grad_norm": 0.38215553760528564,
      "learning_rate": 4.792037415293984e-05,
      "loss": 0.049,
      "step": 9500
    },
    {
      "epoch": 0.3366176934675129,
      "grad_norm": 0.16479407250881195,
      "learning_rate": 4.789845797792603e-05,
      "loss": 0.0507,
      "step": 9600
    },
    {
      "epoch": 0.34012412777446616,
      "grad_norm": 0.20568957924842834,
      "learning_rate": 4.787654180291222e-05,
      "loss": 0.0546,
      "step": 9700
    },
    {
      "epoch": 0.3436305620814194,
      "grad_norm": 0.4748423099517822,
      "learning_rate": 4.7854844789648554e-05,
      "loss": 0.0522,
      "step": 9800
    },
    {
      "epoch": 0.34713699638837264,
      "grad_norm": 0.2373679131269455,
      "learning_rate": 4.783292861463475e-05,
      "loss": 0.051,
      "step": 9900
    },
    {
      "epoch": 0.35064343069532594,
      "grad_norm": 0.18913045525550842,
      "learning_rate": 4.781101243962094e-05,
      "loss": 0.0517,
      "step": 10000
    },
    {
      "epoch": 0.3541498650022792,
      "grad_norm": 0.3339824080467224,
      "learning_rate": 4.778909626460713e-05,
      "loss": 0.0511,
      "step": 10100
    },
    {
      "epoch": 0.35765629930923243,
      "grad_norm": 0.3818281590938568,
      "learning_rate": 4.776718008959333e-05,
      "loss": 0.0509,
      "step": 10200
    },
    {
      "epoch": 0.3611627336161857,
      "grad_norm": 0.32083722949028015,
      "learning_rate": 4.774526391457952e-05,
      "loss": 0.0499,
      "step": 10300
    },
    {
      "epoch": 0.36466916792313897,
      "grad_norm": 0.41359785199165344,
      "learning_rate": 4.772334773956571e-05,
      "loss": 0.0475,
      "step": 10400
    },
    {
      "epoch": 0.3681756022300922,
      "grad_norm": 0.16462992131710052,
      "learning_rate": 4.77014315645519e-05,
      "loss": 0.0535,
      "step": 10500
    },
    {
      "epoch": 0.37168203653704546,
      "grad_norm": 0.44861239194869995,
      "learning_rate": 4.76795153895381e-05,
      "loss": 0.0501,
      "step": 10600
    },
    {
      "epoch": 0.37518847084399876,
      "grad_norm": 0.3259599506855011,
      "learning_rate": 4.765759921452429e-05,
      "loss": 0.0554,
      "step": 10700
    },
    {
      "epoch": 0.378694905150952,
      "grad_norm": 0.19668608903884888,
      "learning_rate": 4.7635683039510484e-05,
      "loss": 0.0538,
      "step": 10800
    },
    {
      "epoch": 0.38220133945790524,
      "grad_norm": 0.4894883334636688,
      "learning_rate": 4.7613766864496675e-05,
      "loss": 0.0537,
      "step": 10900
    },
    {
      "epoch": 0.38570777376485854,
      "grad_norm": 0.23316600918769836,
      "learning_rate": 4.759185068948287e-05,
      "loss": 0.0505,
      "step": 11000
    },
    {
      "epoch": 0.3892142080718118,
      "grad_norm": 0.3598748445510864,
      "learning_rate": 4.756993451446906e-05,
      "loss": 0.0478,
      "step": 11100
    },
    {
      "epoch": 0.39272064237876503,
      "grad_norm": 0.38619476556777954,
      "learning_rate": 4.754801833945525e-05,
      "loss": 0.0489,
      "step": 11200
    },
    {
      "epoch": 0.39622707668571827,
      "grad_norm": 0.23192109167575836,
      "learning_rate": 4.752610216444144e-05,
      "loss": 0.0505,
      "step": 11300
    },
    {
      "epoch": 0.39973351099267157,
      "grad_norm": 0.14062196016311646,
      "learning_rate": 4.750418598942764e-05,
      "loss": 0.0513,
      "step": 11400
    },
    {
      "epoch": 0.4032399452996248,
      "grad_norm": 0.4947158694267273,
      "learning_rate": 4.748226981441383e-05,
      "loss": 0.0511,
      "step": 11500
    },
    {
      "epoch": 0.40674637960657806,
      "grad_norm": 0.22687168419361115,
      "learning_rate": 4.746035363940002e-05,
      "loss": 0.0445,
      "step": 11600
    },
    {
      "epoch": 0.41025281391353136,
      "grad_norm": 0.3574812114238739,
      "learning_rate": 4.743843746438622e-05,
      "loss": 0.0478,
      "step": 11700
    },
    {
      "epoch": 0.4137592482204846,
      "grad_norm": 0.23473267257213593,
      "learning_rate": 4.7416521289372415e-05,
      "loss": 0.0495,
      "step": 11800
    },
    {
      "epoch": 0.41726568252743784,
      "grad_norm": 0.2235366404056549,
      "learning_rate": 4.7394605114358605e-05,
      "loss": 0.0491,
      "step": 11900
    },
    {
      "epoch": 0.4207721168343911,
      "grad_norm": 0.27394920587539673,
      "learning_rate": 4.7372688939344795e-05,
      "loss": 0.0494,
      "step": 12000
    },
    {
      "epoch": 0.4242785511413444,
      "grad_norm": 0.23980014026165009,
      "learning_rate": 4.735077276433099e-05,
      "loss": 0.0499,
      "step": 12100
    },
    {
      "epoch": 0.4277849854482976,
      "grad_norm": 0.35004428029060364,
      "learning_rate": 4.732885658931718e-05,
      "loss": 0.0489,
      "step": 12200
    },
    {
      "epoch": 0.43129141975525087,
      "grad_norm": 0.4840461313724518,
      "learning_rate": 4.730694041430337e-05,
      "loss": 0.0537,
      "step": 12300
    },
    {
      "epoch": 0.43479785406220417,
      "grad_norm": 0.19853268563747406,
      "learning_rate": 4.728502423928956e-05,
      "loss": 0.0455,
      "step": 12400
    },
    {
      "epoch": 0.4383042883691574,
      "grad_norm": 0.1577153205871582,
      "learning_rate": 4.726310806427576e-05,
      "loss": 0.0492,
      "step": 12500
    },
    {
      "epoch": 0.44181072267611066,
      "grad_norm": 0.29782891273498535,
      "learning_rate": 4.724119188926196e-05,
      "loss": 0.0498,
      "step": 12600
    },
    {
      "epoch": 0.4453171569830639,
      "grad_norm": 0.2839454710483551,
      "learning_rate": 4.7219494875998283e-05,
      "loss": 0.0511,
      "step": 12700
    },
    {
      "epoch": 0.4488235912900172,
      "grad_norm": 0.14268121123313904,
      "learning_rate": 4.719757870098448e-05,
      "loss": 0.0488,
      "step": 12800
    },
    {
      "epoch": 0.45233002559697044,
      "grad_norm": 0.20322197675704956,
      "learning_rate": 4.717566252597067e-05,
      "loss": 0.05,
      "step": 12900
    },
    {
      "epoch": 0.4558364599039237,
      "grad_norm": 0.13332846760749817,
      "learning_rate": 4.715374635095686e-05,
      "loss": 0.0523,
      "step": 13000
    },
    {
      "epoch": 0.459342894210877,
      "grad_norm": 0.4022255539894104,
      "learning_rate": 4.713183017594305e-05,
      "loss": 0.0476,
      "step": 13100
    },
    {
      "epoch": 0.4628493285178302,
      "grad_norm": 0.24202053248882294,
      "learning_rate": 4.710991400092925e-05,
      "loss": 0.0469,
      "step": 13200
    },
    {
      "epoch": 0.46635576282478347,
      "grad_norm": 0.297405868768692,
      "learning_rate": 4.708799782591544e-05,
      "loss": 0.0458,
      "step": 13300
    },
    {
      "epoch": 0.4698621971317367,
      "grad_norm": 0.33673980832099915,
      "learning_rate": 4.706630081265177e-05,
      "loss": 0.0495,
      "step": 13400
    },
    {
      "epoch": 0.47336863143869,
      "grad_norm": 0.3988090455532074,
      "learning_rate": 4.704438463763797e-05,
      "loss": 0.0439,
      "step": 13500
    },
    {
      "epoch": 0.47687506574564326,
      "grad_norm": 0.2785412073135376,
      "learning_rate": 4.702246846262416e-05,
      "loss": 0.0485,
      "step": 13600
    },
    {
      "epoch": 0.4803815000525965,
      "grad_norm": 0.18336598575115204,
      "learning_rate": 4.700055228761035e-05,
      "loss": 0.0468,
      "step": 13700
    },
    {
      "epoch": 0.4838879343595498,
      "grad_norm": 0.30162256956100464,
      "learning_rate": 4.697863611259654e-05,
      "loss": 0.0472,
      "step": 13800
    },
    {
      "epoch": 0.48739436866650304,
      "grad_norm": 0.15374840795993805,
      "learning_rate": 4.695671993758274e-05,
      "loss": 0.0494,
      "step": 13900
    },
    {
      "epoch": 0.4909008029734563,
      "grad_norm": 0.2970229685306549,
      "learning_rate": 4.693480376256893e-05,
      "loss": 0.0525,
      "step": 14000
    },
    {
      "epoch": 0.49440723728040953,
      "grad_norm": 0.16952453553676605,
      "learning_rate": 4.6912887587555124e-05,
      "loss": 0.0463,
      "step": 14100
    },
    {
      "epoch": 0.4979136715873628,
      "grad_norm": 0.14409269392490387,
      "learning_rate": 4.6890971412541315e-05,
      "loss": 0.047,
      "step": 14200
    },
    {
      "epoch": 0.5014201058943161,
      "grad_norm": 0.5307942628860474,
      "learning_rate": 4.686905523752751e-05,
      "loss": 0.046,
      "step": 14300
    },
    {
      "epoch": 0.5049265402012694,
      "grad_norm": 0.15499401092529297,
      "learning_rate": 4.68471390625137e-05,
      "loss": 0.0478,
      "step": 14400
    },
    {
      "epoch": 0.5084329745082226,
      "grad_norm": 0.21514490246772766,
      "learning_rate": 4.682522288749989e-05,
      "loss": 0.0459,
      "step": 14500
    },
    {
      "epoch": 0.5119394088151759,
      "grad_norm": 0.15056520700454712,
      "learning_rate": 4.680330671248608e-05,
      "loss": 0.0461,
      "step": 14600
    },
    {
      "epoch": 0.5154458431221292,
      "grad_norm": 0.3214270770549774,
      "learning_rate": 4.678139053747228e-05,
      "loss": 0.0471,
      "step": 14700
    },
    {
      "epoch": 0.5189522774290823,
      "grad_norm": 0.2680407166481018,
      "learning_rate": 4.675947436245847e-05,
      "loss": 0.0474,
      "step": 14800
    },
    {
      "epoch": 0.5224587117360356,
      "grad_norm": 0.3832797706127167,
      "learning_rate": 4.673755818744466e-05,
      "loss": 0.0507,
      "step": 14900
    },
    {
      "epoch": 0.5259651460429888,
      "grad_norm": 0.30283689498901367,
      "learning_rate": 4.671564201243086e-05,
      "loss": 0.0467,
      "step": 15000
    },
    {
      "epoch": 0.5294715803499421,
      "grad_norm": 0.1795080453157425,
      "learning_rate": 4.6693725837417055e-05,
      "loss": 0.0467,
      "step": 15100
    },
    {
      "epoch": 0.5329780146568954,
      "grad_norm": 0.5376541614532471,
      "learning_rate": 4.6671809662403245e-05,
      "loss": 0.0495,
      "step": 15200
    },
    {
      "epoch": 0.5364844489638486,
      "grad_norm": 0.43424323201179504,
      "learning_rate": 4.6649893487389435e-05,
      "loss": 0.0475,
      "step": 15300
    },
    {
      "epoch": 0.5399908832708019,
      "grad_norm": 0.16303545236587524,
      "learning_rate": 4.6627977312375626e-05,
      "loss": 0.0482,
      "step": 15400
    },
    {
      "epoch": 0.5434973175777552,
      "grad_norm": 0.39276859164237976,
      "learning_rate": 4.660606113736182e-05,
      "loss": 0.0472,
      "step": 15500
    },
    {
      "epoch": 0.5470037518847084,
      "grad_norm": 0.0779540091753006,
      "learning_rate": 4.658414496234801e-05,
      "loss": 0.0465,
      "step": 15600
    },
    {
      "epoch": 0.5505101861916617,
      "grad_norm": 0.4121045768260956,
      "learning_rate": 4.6562228787334203e-05,
      "loss": 0.0479,
      "step": 15700
    },
    {
      "epoch": 0.554016620498615,
      "grad_norm": 0.35763129591941833,
      "learning_rate": 4.6540312612320394e-05,
      "loss": 0.0476,
      "step": 15800
    },
    {
      "epoch": 0.5575230548055682,
      "grad_norm": 0.3506748676300049,
      "learning_rate": 4.651839643730659e-05,
      "loss": 0.0467,
      "step": 15900
    },
    {
      "epoch": 0.5610294891125215,
      "grad_norm": 0.2938830554485321,
      "learning_rate": 4.649648026229279e-05,
      "loss": 0.0452,
      "step": 16000
    },
    {
      "epoch": 0.5645359234194748,
      "grad_norm": 0.3679121136665344,
      "learning_rate": 4.647456408727898e-05,
      "loss": 0.0468,
      "step": 16100
    },
    {
      "epoch": 0.568042357726428,
      "grad_norm": 0.06688520312309265,
      "learning_rate": 4.645264791226517e-05,
      "loss": 0.0462,
      "step": 16200
    },
    {
      "epoch": 0.5715487920333813,
      "grad_norm": 0.5006266832351685,
      "learning_rate": 4.6430731737251366e-05,
      "loss": 0.0482,
      "step": 16300
    },
    {
      "epoch": 0.5750552263403346,
      "grad_norm": 0.45093125104904175,
      "learning_rate": 4.6408815562237556e-05,
      "loss": 0.0525,
      "step": 16400
    },
    {
      "epoch": 0.5785616606472878,
      "grad_norm": 0.37918615341186523,
      "learning_rate": 4.6386899387223746e-05,
      "loss": 0.0475,
      "step": 16500
    },
    {
      "epoch": 0.582068094954241,
      "grad_norm": 0.18155768513679504,
      "learning_rate": 4.636498321220994e-05,
      "loss": 0.0471,
      "step": 16600
    },
    {
      "epoch": 0.5855745292611942,
      "grad_norm": 0.47181037068367004,
      "learning_rate": 4.6343067037196134e-05,
      "loss": 0.0492,
      "step": 16700
    },
    {
      "epoch": 0.5890809635681475,
      "grad_norm": 0.29393476247787476,
      "learning_rate": 4.632115086218233e-05,
      "loss": 0.0462,
      "step": 16800
    },
    {
      "epoch": 0.5925873978751008,
      "grad_norm": 0.2004152536392212,
      "learning_rate": 4.629923468716852e-05,
      "loss": 0.0448,
      "step": 16900
    },
    {
      "epoch": 0.596093832182054,
      "grad_norm": 0.3393872082233429,
      "learning_rate": 4.627731851215471e-05,
      "loss": 0.0487,
      "step": 17000
    },
    {
      "epoch": 0.5996002664890073,
      "grad_norm": 0.30068129301071167,
      "learning_rate": 4.625540233714091e-05,
      "loss": 0.0487,
      "step": 17100
    },
    {
      "epoch": 0.6031067007959606,
      "grad_norm": 0.20431436598300934,
      "learning_rate": 4.62334861621271e-05,
      "loss": 0.0459,
      "step": 17200
    },
    {
      "epoch": 0.6066131351029138,
      "grad_norm": 0.2572769224643707,
      "learning_rate": 4.621156998711329e-05,
      "loss": 0.0437,
      "step": 17300
    },
    {
      "epoch": 0.6101195694098671,
      "grad_norm": 0.2711150050163269,
      "learning_rate": 4.618965381209948e-05,
      "loss": 0.0434,
      "step": 17400
    },
    {
      "epoch": 0.6136260037168204,
      "grad_norm": 0.1501685380935669,
      "learning_rate": 4.616773763708568e-05,
      "loss": 0.0482,
      "step": 17500
    },
    {
      "epoch": 0.6171324380237736,
      "grad_norm": 0.19003242254257202,
      "learning_rate": 4.614582146207187e-05,
      "loss": 0.0442,
      "step": 17600
    },
    {
      "epoch": 0.6206388723307269,
      "grad_norm": 0.3087851405143738,
      "learning_rate": 4.6123905287058064e-05,
      "loss": 0.0482,
      "step": 17700
    },
    {
      "epoch": 0.6241453066376802,
      "grad_norm": 0.2168198823928833,
      "learning_rate": 4.6101989112044254e-05,
      "loss": 0.0476,
      "step": 17800
    },
    {
      "epoch": 0.6276517409446334,
      "grad_norm": 0.36220329999923706,
      "learning_rate": 4.608007293703045e-05,
      "loss": 0.045,
      "step": 17900
    },
    {
      "epoch": 0.6311581752515867,
      "grad_norm": 0.29221010208129883,
      "learning_rate": 4.605815676201664e-05,
      "loss": 0.0499,
      "step": 18000
    },
    {
      "epoch": 0.6346646095585399,
      "grad_norm": 0.2462194561958313,
      "learning_rate": 4.603624058700283e-05,
      "loss": 0.0477,
      "step": 18100
    },
    {
      "epoch": 0.6381710438654932,
      "grad_norm": 0.6128373146057129,
      "learning_rate": 4.601432441198903e-05,
      "loss": 0.0468,
      "step": 18200
    },
    {
      "epoch": 0.6416774781724465,
      "grad_norm": 0.3058200180530548,
      "learning_rate": 4.599240823697522e-05,
      "loss": 0.0503,
      "step": 18300
    },
    {
      "epoch": 0.6451839124793997,
      "grad_norm": 0.5226797461509705,
      "learning_rate": 4.597049206196141e-05,
      "loss": 0.043,
      "step": 18400
    },
    {
      "epoch": 0.648690346786353,
      "grad_norm": 0.2848636209964752,
      "learning_rate": 4.594879504869774e-05,
      "loss": 0.0442,
      "step": 18500
    },
    {
      "epoch": 0.6521967810933063,
      "grad_norm": 0.2284582108259201,
      "learning_rate": 4.592687887368394e-05,
      "loss": 0.0472,
      "step": 18600
    },
    {
      "epoch": 0.6557032154002594,
      "grad_norm": 0.409615695476532,
      "learning_rate": 4.590496269867013e-05,
      "loss": 0.0496,
      "step": 18700
    },
    {
      "epoch": 0.6592096497072127,
      "grad_norm": 0.192133828997612,
      "learning_rate": 4.588304652365632e-05,
      "loss": 0.0456,
      "step": 18800
    },
    {
      "epoch": 0.662716084014166,
      "grad_norm": 0.28202182054519653,
      "learning_rate": 4.586113034864252e-05,
      "loss": 0.0489,
      "step": 18900
    },
    {
      "epoch": 0.6662225183211192,
      "grad_norm": 0.1595294177532196,
      "learning_rate": 4.583921417362871e-05,
      "loss": 0.0486,
      "step": 19000
    },
    {
      "epoch": 0.6697289526280725,
      "grad_norm": 0.3320414423942566,
      "learning_rate": 4.58172979986149e-05,
      "loss": 0.0496,
      "step": 19100
    },
    {
      "epoch": 0.6732353869350258,
      "grad_norm": 0.17543113231658936,
      "learning_rate": 4.579538182360109e-05,
      "loss": 0.0403,
      "step": 19200
    },
    {
      "epoch": 0.676741821241979,
      "grad_norm": 0.4821883738040924,
      "learning_rate": 4.5773465648587286e-05,
      "loss": 0.0462,
      "step": 19300
    },
    {
      "epoch": 0.6802482555489323,
      "grad_norm": 0.20340022444725037,
      "learning_rate": 4.575154947357348e-05,
      "loss": 0.0487,
      "step": 19400
    },
    {
      "epoch": 0.6837546898558855,
      "grad_norm": 0.2533998489379883,
      "learning_rate": 4.572963329855967e-05,
      "loss": 0.045,
      "step": 19500
    },
    {
      "epoch": 0.6872611241628388,
      "grad_norm": 0.2785402834415436,
      "learning_rate": 4.5707717123545863e-05,
      "loss": 0.0468,
      "step": 19600
    },
    {
      "epoch": 0.6907675584697921,
      "grad_norm": 0.2761211395263672,
      "learning_rate": 4.568580094853206e-05,
      "loss": 0.0445,
      "step": 19700
    },
    {
      "epoch": 0.6942739927767453,
      "grad_norm": 0.34692254662513733,
      "learning_rate": 4.566388477351825e-05,
      "loss": 0.0434,
      "step": 19800
    },
    {
      "epoch": 0.6977804270836986,
      "grad_norm": 0.28560566902160645,
      "learning_rate": 4.564196859850444e-05,
      "loss": 0.0436,
      "step": 19900
    },
    {
      "epoch": 0.7012868613906519,
      "grad_norm": 0.271079957485199,
      "learning_rate": 4.562005242349063e-05,
      "loss": 0.0452,
      "step": 20000
    },
    {
      "epoch": 0.7047932956976051,
      "grad_norm": 0.40914949774742126,
      "learning_rate": 4.559813624847683e-05,
      "loss": 0.044,
      "step": 20100
    },
    {
      "epoch": 0.7082997300045584,
      "grad_norm": 0.1969819813966751,
      "learning_rate": 4.557622007346302e-05,
      "loss": 0.0488,
      "step": 20200
    },
    {
      "epoch": 0.7118061643115117,
      "grad_norm": 0.15970896184444427,
      "learning_rate": 4.5554303898449216e-05,
      "loss": 0.0445,
      "step": 20300
    },
    {
      "epoch": 0.7153125986184649,
      "grad_norm": 0.3744063973426819,
      "learning_rate": 4.553260688518555e-05,
      "loss": 0.0446,
      "step": 20400
    },
    {
      "epoch": 0.7188190329254182,
      "grad_norm": 0.21145619451999664,
      "learning_rate": 4.551069071017174e-05,
      "loss": 0.044,
      "step": 20500
    },
    {
      "epoch": 0.7223254672323715,
      "grad_norm": 0.2928839325904846,
      "learning_rate": 4.548877453515793e-05,
      "loss": 0.0468,
      "step": 20600
    },
    {
      "epoch": 0.7258319015393246,
      "grad_norm": 0.37675046920776367,
      "learning_rate": 4.546685836014412e-05,
      "loss": 0.0444,
      "step": 20700
    },
    {
      "epoch": 0.7293383358462779,
      "grad_norm": 0.3054589629173279,
      "learning_rate": 4.544494218513032e-05,
      "loss": 0.0457,
      "step": 20800
    },
    {
      "epoch": 0.7328447701532311,
      "grad_norm": 0.19964256882667542,
      "learning_rate": 4.542302601011651e-05,
      "loss": 0.0475,
      "step": 20900
    },
    {
      "epoch": 0.7363512044601844,
      "grad_norm": 0.36353883147239685,
      "learning_rate": 4.54011098351027e-05,
      "loss": 0.044,
      "step": 21000
    },
    {
      "epoch": 0.7398576387671377,
      "grad_norm": 0.4302000105381012,
      "learning_rate": 4.5379193660088895e-05,
      "loss": 0.0455,
      "step": 21100
    },
    {
      "epoch": 0.7433640730740909,
      "grad_norm": 0.41845834255218506,
      "learning_rate": 4.535727748507509e-05,
      "loss": 0.0482,
      "step": 21200
    },
    {
      "epoch": 0.7468705073810442,
      "grad_norm": 0.35202139616012573,
      "learning_rate": 4.533536131006128e-05,
      "loss": 0.0453,
      "step": 21300
    },
    {
      "epoch": 0.7503769416879975,
      "grad_norm": 0.25057005882263184,
      "learning_rate": 4.531344513504747e-05,
      "loss": 0.0447,
      "step": 21400
    },
    {
      "epoch": 0.7538833759949507,
      "grad_norm": 0.40141749382019043,
      "learning_rate": 4.529152896003366e-05,
      "loss": 0.0477,
      "step": 21500
    },
    {
      "epoch": 0.757389810301904,
      "grad_norm": 0.27719050645828247,
      "learning_rate": 4.526961278501986e-05,
      "loss": 0.0465,
      "step": 21600
    },
    {
      "epoch": 0.7608962446088573,
      "grad_norm": 0.2482399344444275,
      "learning_rate": 4.524769661000605e-05,
      "loss": 0.0454,
      "step": 21700
    },
    {
      "epoch": 0.7644026789158105,
      "grad_norm": 0.19910928606987,
      "learning_rate": 4.522578043499224e-05,
      "loss": 0.0447,
      "step": 21800
    },
    {
      "epoch": 0.7679091132227638,
      "grad_norm": 0.3043578267097473,
      "learning_rate": 4.520386425997844e-05,
      "loss": 0.0488,
      "step": 21900
    },
    {
      "epoch": 0.7714155475297171,
      "grad_norm": 0.07025361061096191,
      "learning_rate": 4.5181948084964635e-05,
      "loss": 0.0412,
      "step": 22000
    },
    {
      "epoch": 0.7749219818366703,
      "grad_norm": 0.08776561170816422,
      "learning_rate": 4.5160031909950825e-05,
      "loss": 0.0491,
      "step": 22100
    },
    {
      "epoch": 0.7784284161436236,
      "grad_norm": 0.27065280079841614,
      "learning_rate": 4.5138115734937015e-05,
      "loss": 0.0426,
      "step": 22200
    },
    {
      "epoch": 0.7819348504505768,
      "grad_norm": 0.7124661803245544,
      "learning_rate": 4.5116199559923206e-05,
      "loss": 0.0446,
      "step": 22300
    },
    {
      "epoch": 0.7854412847575301,
      "grad_norm": 0.39174914360046387,
      "learning_rate": 4.50942833849094e-05,
      "loss": 0.0411,
      "step": 22400
    },
    {
      "epoch": 0.7889477190644834,
      "grad_norm": 0.11610269546508789,
      "learning_rate": 4.507236720989559e-05,
      "loss": 0.0434,
      "step": 22500
    },
    {
      "epoch": 0.7924541533714365,
      "grad_norm": 0.42721444368362427,
      "learning_rate": 4.5050451034881783e-05,
      "loss": 0.0477,
      "step": 22600
    },
    {
      "epoch": 0.7959605876783898,
      "grad_norm": 0.3556917607784271,
      "learning_rate": 4.5028534859867974e-05,
      "loss": 0.0454,
      "step": 22700
    },
    {
      "epoch": 0.7994670219853431,
      "grad_norm": 0.357706755399704,
      "learning_rate": 4.500661868485417e-05,
      "loss": 0.0411,
      "step": 22800
    },
    {
      "epoch": 0.8029734562922963,
      "grad_norm": 0.373790979385376,
      "learning_rate": 4.498470250984037e-05,
      "loss": 0.039,
      "step": 22900
    },
    {
      "epoch": 0.8064798905992496,
      "grad_norm": 0.28537657856941223,
      "learning_rate": 4.496278633482656e-05,
      "loss": 0.0461,
      "step": 23000
    },
    {
      "epoch": 0.8099863249062029,
      "grad_norm": 0.33264651894569397,
      "learning_rate": 4.494087015981275e-05,
      "loss": 0.0485,
      "step": 23100
    },
    {
      "epoch": 0.8134927592131561,
      "grad_norm": 0.1694522202014923,
      "learning_rate": 4.4918953984798946e-05,
      "loss": 0.0425,
      "step": 23200
    },
    {
      "epoch": 0.8169991935201094,
      "grad_norm": 0.09672229737043381,
      "learning_rate": 4.4897037809785136e-05,
      "loss": 0.0409,
      "step": 23300
    },
    {
      "epoch": 0.8205056278270627,
      "grad_norm": 0.19648385047912598,
      "learning_rate": 4.4875121634771326e-05,
      "loss": 0.0408,
      "step": 23400
    },
    {
      "epoch": 0.8240120621340159,
      "grad_norm": 0.9591491222381592,
      "learning_rate": 4.485320545975752e-05,
      "loss": 0.044,
      "step": 23500
    },
    {
      "epoch": 0.8275184964409692,
      "grad_norm": 0.27548593282699585,
      "learning_rate": 4.4831289284743714e-05,
      "loss": 0.0427,
      "step": 23600
    },
    {
      "epoch": 0.8310249307479224,
      "grad_norm": 0.19187448918819427,
      "learning_rate": 4.4809373109729904e-05,
      "loss": 0.0422,
      "step": 23700
    },
    {
      "epoch": 0.8345313650548757,
      "grad_norm": 0.1294841468334198,
      "learning_rate": 4.47874569347161e-05,
      "loss": 0.043,
      "step": 23800
    },
    {
      "epoch": 0.838037799361829,
      "grad_norm": 0.30293750762939453,
      "learning_rate": 4.4765759921452434e-05,
      "loss": 0.0462,
      "step": 23900
    },
    {
      "epoch": 0.8415442336687822,
      "grad_norm": 0.3629881739616394,
      "learning_rate": 4.4743843746438624e-05,
      "loss": 0.0475,
      "step": 24000
    },
    {
      "epoch": 0.8450506679757355,
      "grad_norm": 0.25196373462677,
      "learning_rate": 4.4721927571424815e-05,
      "loss": 0.0471,
      "step": 24100
    },
    {
      "epoch": 0.8485571022826888,
      "grad_norm": 0.407917857170105,
      "learning_rate": 4.4700011396411005e-05,
      "loss": 0.0463,
      "step": 24200
    },
    {
      "epoch": 0.852063536589642,
      "grad_norm": 0.18811145424842834,
      "learning_rate": 4.46780952213972e-05,
      "loss": 0.0432,
      "step": 24300
    },
    {
      "epoch": 0.8555699708965953,
      "grad_norm": 0.2352750301361084,
      "learning_rate": 4.465617904638339e-05,
      "loss": 0.0448,
      "step": 24400
    },
    {
      "epoch": 0.8590764052035486,
      "grad_norm": 0.31805548071861267,
      "learning_rate": 4.463426287136959e-05,
      "loss": 0.0435,
      "step": 24500
    },
    {
      "epoch": 0.8625828395105017,
      "grad_norm": 0.28037208318710327,
      "learning_rate": 4.461234669635578e-05,
      "loss": 0.0446,
      "step": 24600
    },
    {
      "epoch": 0.866089273817455,
      "grad_norm": 0.4643436372280121,
      "learning_rate": 4.459043052134198e-05,
      "loss": 0.044,
      "step": 24700
    },
    {
      "epoch": 0.8695957081244083,
      "grad_norm": 0.13548511266708374,
      "learning_rate": 4.456851434632817e-05,
      "loss": 0.0405,
      "step": 24800
    },
    {
      "epoch": 0.8731021424313615,
      "grad_norm": 0.36023426055908203,
      "learning_rate": 4.454659817131436e-05,
      "loss": 0.0465,
      "step": 24900
    },
    {
      "epoch": 0.8766085767383148,
      "grad_norm": 0.39011096954345703,
      "learning_rate": 4.452468199630055e-05,
      "loss": 0.0443,
      "step": 25000
    },
    {
      "epoch": 0.880115011045268,
      "grad_norm": 0.29042306542396545,
      "learning_rate": 4.4502765821286745e-05,
      "loss": 0.0458,
      "step": 25100
    },
    {
      "epoch": 0.8836214453522213,
      "grad_norm": 0.18782366812229156,
      "learning_rate": 4.4480849646272935e-05,
      "loss": 0.0453,
      "step": 25200
    },
    {
      "epoch": 0.8871278796591746,
      "grad_norm": 0.19415253400802612,
      "learning_rate": 4.4458933471259126e-05,
      "loss": 0.0453,
      "step": 25300
    },
    {
      "epoch": 0.8906343139661278,
      "grad_norm": 0.24387794733047485,
      "learning_rate": 4.443701729624532e-05,
      "loss": 0.0431,
      "step": 25400
    },
    {
      "epoch": 0.8941407482730811,
      "grad_norm": 0.5245552659034729,
      "learning_rate": 4.441510112123152e-05,
      "loss": 0.0461,
      "step": 25500
    },
    {
      "epoch": 0.8976471825800344,
      "grad_norm": 0.2400495707988739,
      "learning_rate": 4.439318494621771e-05,
      "loss": 0.042,
      "step": 25600
    },
    {
      "epoch": 0.9011536168869876,
      "grad_norm": 0.36114659905433655,
      "learning_rate": 4.43712687712039e-05,
      "loss": 0.0416,
      "step": 25700
    },
    {
      "epoch": 0.9046600511939409,
      "grad_norm": 0.24099326133728027,
      "learning_rate": 4.43493525961901e-05,
      "loss": 0.0433,
      "step": 25800
    },
    {
      "epoch": 0.9081664855008942,
      "grad_norm": 0.20409977436065674,
      "learning_rate": 4.432743642117629e-05,
      "loss": 0.0407,
      "step": 25900
    },
    {
      "epoch": 0.9116729198078474,
      "grad_norm": 0.22689977288246155,
      "learning_rate": 4.430552024616248e-05,
      "loss": 0.041,
      "step": 26000
    },
    {
      "epoch": 0.9151793541148007,
      "grad_norm": 0.21763716638088226,
      "learning_rate": 4.428360407114867e-05,
      "loss": 0.04,
      "step": 26100
    },
    {
      "epoch": 0.918685788421754,
      "grad_norm": 0.13452225923538208,
      "learning_rate": 4.4261687896134866e-05,
      "loss": 0.0456,
      "step": 26200
    },
    {
      "epoch": 0.9221922227287072,
      "grad_norm": 0.08941579610109329,
      "learning_rate": 4.423977172112106e-05,
      "loss": 0.0455,
      "step": 26300
    },
    {
      "epoch": 0.9256986570356605,
      "grad_norm": 0.4091777801513672,
      "learning_rate": 4.421785554610725e-05,
      "loss": 0.0452,
      "step": 26400
    },
    {
      "epoch": 0.9292050913426136,
      "grad_norm": 0.19390077888965607,
      "learning_rate": 4.4195939371093443e-05,
      "loss": 0.0453,
      "step": 26500
    },
    {
      "epoch": 0.9327115256495669,
      "grad_norm": 0.29767853021621704,
      "learning_rate": 4.417402319607964e-05,
      "loss": 0.0418,
      "step": 26600
    },
    {
      "epoch": 0.9362179599565202,
      "grad_norm": 0.25129473209381104,
      "learning_rate": 4.415210702106583e-05,
      "loss": 0.0435,
      "step": 26700
    },
    {
      "epoch": 0.9397243942634734,
      "grad_norm": 0.11691455543041229,
      "learning_rate": 4.413019084605202e-05,
      "loss": 0.0413,
      "step": 26800
    },
    {
      "epoch": 0.9432308285704267,
      "grad_norm": 0.1618880182504654,
      "learning_rate": 4.410827467103821e-05,
      "loss": 0.0432,
      "step": 26900
    },
    {
      "epoch": 0.94673726287738,
      "grad_norm": 0.4969581663608551,
      "learning_rate": 4.408635849602441e-05,
      "loss": 0.0424,
      "step": 27000
    },
    {
      "epoch": 0.9502436971843332,
      "grad_norm": 0.18279705941677094,
      "learning_rate": 4.40644423210106e-05,
      "loss": 0.042,
      "step": 27100
    },
    {
      "epoch": 0.9537501314912865,
      "grad_norm": 0.269401490688324,
      "learning_rate": 4.4042526145996796e-05,
      "loss": 0.0436,
      "step": 27200
    },
    {
      "epoch": 0.9572565657982398,
      "grad_norm": 0.2861597537994385,
      "learning_rate": 4.4020609970982986e-05,
      "loss": 0.049,
      "step": 27300
    },
    {
      "epoch": 0.960763000105193,
      "grad_norm": 0.14530052244663239,
      "learning_rate": 4.3998693795969183e-05,
      "loss": 0.0421,
      "step": 27400
    },
    {
      "epoch": 0.9642694344121463,
      "grad_norm": 0.42120078206062317,
      "learning_rate": 4.3976777620955374e-05,
      "loss": 0.0412,
      "step": 27500
    },
    {
      "epoch": 0.9677758687190996,
      "grad_norm": 0.3238057494163513,
      "learning_rate": 4.3954861445941564e-05,
      "loss": 0.0418,
      "step": 27600
    },
    {
      "epoch": 0.9712823030260528,
      "grad_norm": 0.5250027775764465,
      "learning_rate": 4.3932945270927754e-05,
      "loss": 0.0428,
      "step": 27700
    },
    {
      "epoch": 0.9747887373330061,
      "grad_norm": 0.2523405849933624,
      "learning_rate": 4.391102909591395e-05,
      "loss": 0.0447,
      "step": 27800
    },
    {
      "epoch": 0.9782951716399593,
      "grad_norm": 0.2587428689002991,
      "learning_rate": 4.388911292090014e-05,
      "loss": 0.0405,
      "step": 27900
    },
    {
      "epoch": 0.9818016059469126,
      "grad_norm": 0.2461136281490326,
      "learning_rate": 4.386719674588633e-05,
      "loss": 0.0432,
      "step": 28000
    },
    {
      "epoch": 0.9853080402538659,
      "grad_norm": 0.3662518262863159,
      "learning_rate": 4.384549973262267e-05,
      "loss": 0.0474,
      "step": 28100
    },
    {
      "epoch": 0.9888144745608191,
      "grad_norm": 0.2529832422733307,
      "learning_rate": 4.382358355760886e-05,
      "loss": 0.0423,
      "step": 28200
    },
    {
      "epoch": 0.9923209088677724,
      "grad_norm": 0.24888411164283752,
      "learning_rate": 4.380166738259505e-05,
      "loss": 0.0406,
      "step": 28300
    },
    {
      "epoch": 0.9958273431747257,
      "grad_norm": 0.20059949159622192,
      "learning_rate": 4.377975120758124e-05,
      "loss": 0.0397,
      "step": 28400
    },
    {
      "epoch": 0.9993337774816788,
      "grad_norm": 0.1988232433795929,
      "learning_rate": 4.375783503256744e-05,
      "loss": 0.0415,
      "step": 28500
    },
    {
      "epoch": 1.0,
      "eval_accuracy_macro_0.5": 0.98243248462677,
      "eval_accuracy_micro_0.5": 0.9824325442314148,
      "eval_accuracy_weighted_0.5": 0.9741202592849731,
      "eval_f1_macro_0.5": 0.7298014760017395,
      "eval_f1_macro_0.6": 0.7089569568634033,
      "eval_f1_macro_0.7": 0.672174870967865,
      "eval_f1_macro_0.8": 0.4797486960887909,
      "eval_f1_micro_0.5": 0.7689056992530823,
      "eval_f1_micro_0.6": 0.7531165480613708,
      "eval_f1_micro_0.7": 0.7230796813964844,
      "eval_f1_micro_0.8": 0.6694392561912537,
      "eval_f1_micro_0.9": 0.5514929294586182,
      "eval_f1_weighted_0.5": 0.7611269950866699,
      "eval_f1_weighted_0.6": 0.7407739162445068,
      "eval_f1_weighted_0.7": 0.7047971487045288,
      "eval_f1_weighted_0.8": 0.5129241943359375,
      "eval_loss": 0.040417734533548355,
      "eval_runtime": 268.4908,
      "eval_samples_per_second": 212.324,
      "eval_steps_per_second": 26.541,
      "step": 28519
    },
    {
      "epoch": 1.0028402117886321,
      "grad_norm": 0.3333788812160492,
      "learning_rate": 4.373591885755363e-05,
      "loss": 0.037,
      "step": 28600
    },
    {
      "epoch": 1.0063466460955854,
      "grad_norm": 0.1775413453578949,
      "learning_rate": 4.371400268253982e-05,
      "loss": 0.0408,
      "step": 28700
    },
    {
      "epoch": 1.0098530804025387,
      "grad_norm": 0.15729983150959015,
      "learning_rate": 4.369208650752602e-05,
      "loss": 0.042,
      "step": 28800
    },
    {
      "epoch": 1.0133595147094918,
      "grad_norm": 0.22014464437961578,
      "learning_rate": 4.3670170332512215e-05,
      "loss": 0.0382,
      "step": 28900
    },
    {
      "epoch": 1.0168659490164451,
      "grad_norm": 0.0865837037563324,
      "learning_rate": 4.3648254157498405e-05,
      "loss": 0.0416,
      "step": 29000
    },
    {
      "epoch": 1.0203723833233984,
      "grad_norm": 0.3775807321071625,
      "learning_rate": 4.3626337982484595e-05,
      "loss": 0.0401,
      "step": 29100
    },
    {
      "epoch": 1.0238788176303517,
      "grad_norm": 0.17415763437747955,
      "learning_rate": 4.3604421807470786e-05,
      "loss": 0.0385,
      "step": 29200
    },
    {
      "epoch": 1.027385251937305,
      "grad_norm": 0.16199034452438354,
      "learning_rate": 4.358250563245698e-05,
      "loss": 0.0393,
      "step": 29300
    },
    {
      "epoch": 1.0308916862442583,
      "grad_norm": 0.3332769572734833,
      "learning_rate": 4.356058945744317e-05,
      "loss": 0.042,
      "step": 29400
    },
    {
      "epoch": 1.0343981205512114,
      "grad_norm": 0.18047863245010376,
      "learning_rate": 4.353867328242936e-05,
      "loss": 0.0428,
      "step": 29500
    },
    {
      "epoch": 1.0379045548581647,
      "grad_norm": 0.2360139787197113,
      "learning_rate": 4.3516757107415554e-05,
      "loss": 0.0406,
      "step": 29600
    },
    {
      "epoch": 1.041410989165118,
      "grad_norm": 0.4960644245147705,
      "learning_rate": 4.349484093240175e-05,
      "loss": 0.0406,
      "step": 29700
    },
    {
      "epoch": 1.0449174234720713,
      "grad_norm": 0.0907410979270935,
      "learning_rate": 4.347292475738795e-05,
      "loss": 0.0421,
      "step": 29800
    },
    {
      "epoch": 1.0484238577790246,
      "grad_norm": 0.17117661237716675,
      "learning_rate": 4.345100858237414e-05,
      "loss": 0.0394,
      "step": 29900
    },
    {
      "epoch": 1.0519302920859777,
      "grad_norm": 0.13229526579380035,
      "learning_rate": 4.342909240736033e-05,
      "loss": 0.0384,
      "step": 30000
    },
    {
      "epoch": 1.055436726392931,
      "grad_norm": 0.1387709379196167,
      "learning_rate": 4.3407176232346526e-05,
      "loss": 0.0425,
      "step": 30100
    },
    {
      "epoch": 1.0589431606998843,
      "grad_norm": 0.35267242789268494,
      "learning_rate": 4.3385260057332716e-05,
      "loss": 0.0411,
      "step": 30200
    },
    {
      "epoch": 1.0624495950068376,
      "grad_norm": 0.1711360663175583,
      "learning_rate": 4.3363343882318906e-05,
      "loss": 0.0382,
      "step": 30300
    },
    {
      "epoch": 1.0659560293137909,
      "grad_norm": 0.36959367990493774,
      "learning_rate": 4.33414277073051e-05,
      "loss": 0.0428,
      "step": 30400
    },
    {
      "epoch": 1.0694624636207442,
      "grad_norm": 0.32175102829933167,
      "learning_rate": 4.331973069404143e-05,
      "loss": 0.0438,
      "step": 30500
    },
    {
      "epoch": 1.0729688979276972,
      "grad_norm": 0.5593952536582947,
      "learning_rate": 4.3297814519027627e-05,
      "loss": 0.0416,
      "step": 30600
    },
    {
      "epoch": 1.0764753322346505,
      "grad_norm": 0.35797709226608276,
      "learning_rate": 4.327589834401382e-05,
      "loss": 0.0452,
      "step": 30700
    },
    {
      "epoch": 1.0799817665416038,
      "grad_norm": 0.24840837717056274,
      "learning_rate": 4.3253982169000014e-05,
      "loss": 0.0427,
      "step": 30800
    },
    {
      "epoch": 1.0834882008485571,
      "grad_norm": 0.26343798637390137,
      "learning_rate": 4.3232065993986204e-05,
      "loss": 0.0403,
      "step": 30900
    },
    {
      "epoch": 1.0869946351555104,
      "grad_norm": 0.21335835754871368,
      "learning_rate": 4.3210149818972395e-05,
      "loss": 0.0409,
      "step": 31000
    },
    {
      "epoch": 1.0905010694624637,
      "grad_norm": 0.10146183520555496,
      "learning_rate": 4.3188233643958585e-05,
      "loss": 0.041,
      "step": 31100
    },
    {
      "epoch": 1.0940075037694168,
      "grad_norm": 0.19053561985492706,
      "learning_rate": 4.316631746894478e-05,
      "loss": 0.0385,
      "step": 31200
    },
    {
      "epoch": 1.09751393807637,
      "grad_norm": 0.1397555023431778,
      "learning_rate": 4.314440129393097e-05,
      "loss": 0.0454,
      "step": 31300
    },
    {
      "epoch": 1.1010203723833234,
      "grad_norm": 0.16738371551036835,
      "learning_rate": 4.312248511891717e-05,
      "loss": 0.0408,
      "step": 31400
    },
    {
      "epoch": 1.1045268066902767,
      "grad_norm": 0.13040868937969208,
      "learning_rate": 4.310056894390336e-05,
      "loss": 0.039,
      "step": 31500
    },
    {
      "epoch": 1.10803324099723,
      "grad_norm": 0.40229710936546326,
      "learning_rate": 4.307865276888956e-05,
      "loss": 0.0439,
      "step": 31600
    },
    {
      "epoch": 1.111539675304183,
      "grad_norm": 0.2663978040218353,
      "learning_rate": 4.305673659387575e-05,
      "loss": 0.04,
      "step": 31700
    },
    {
      "epoch": 1.1150461096111364,
      "grad_norm": 0.15302343666553497,
      "learning_rate": 4.303482041886194e-05,
      "loss": 0.041,
      "step": 31800
    },
    {
      "epoch": 1.1185525439180897,
      "grad_norm": 0.3165964186191559,
      "learning_rate": 4.3012904243848135e-05,
      "loss": 0.0387,
      "step": 31900
    },
    {
      "epoch": 1.122058978225043,
      "grad_norm": 0.1450503021478653,
      "learning_rate": 4.2990988068834325e-05,
      "loss": 0.0435,
      "step": 32000
    },
    {
      "epoch": 1.1255654125319963,
      "grad_norm": 0.13471131026744843,
      "learning_rate": 4.2969071893820515e-05,
      "loss": 0.0394,
      "step": 32100
    },
    {
      "epoch": 1.1290718468389496,
      "grad_norm": 0.5081171989440918,
      "learning_rate": 4.2947155718806706e-05,
      "loss": 0.0427,
      "step": 32200
    },
    {
      "epoch": 1.1325782811459026,
      "grad_norm": 0.16989347338676453,
      "learning_rate": 4.29252395437929e-05,
      "loss": 0.0427,
      "step": 32300
    },
    {
      "epoch": 1.136084715452856,
      "grad_norm": 0.16526013612747192,
      "learning_rate": 4.29033233687791e-05,
      "loss": 0.043,
      "step": 32400
    },
    {
      "epoch": 1.1395911497598092,
      "grad_norm": 0.08589589595794678,
      "learning_rate": 4.288140719376529e-05,
      "loss": 0.038,
      "step": 32500
    },
    {
      "epoch": 1.1430975840667625,
      "grad_norm": 0.2608920931816101,
      "learning_rate": 4.285971018050162e-05,
      "loss": 0.0457,
      "step": 32600
    },
    {
      "epoch": 1.1466040183737158,
      "grad_norm": 0.16019156575202942,
      "learning_rate": 4.283801316723795e-05,
      "loss": 0.0416,
      "step": 32700
    },
    {
      "epoch": 1.1501104526806691,
      "grad_norm": 0.16969221830368042,
      "learning_rate": 4.281609699222414e-05,
      "loss": 0.0419,
      "step": 32800
    },
    {
      "epoch": 1.1536168869876222,
      "grad_norm": 0.23832890391349792,
      "learning_rate": 4.2794180817210336e-05,
      "loss": 0.0453,
      "step": 32900
    },
    {
      "epoch": 1.1571233212945755,
      "grad_norm": 0.15680935978889465,
      "learning_rate": 4.277226464219653e-05,
      "loss": 0.0414,
      "step": 33000
    },
    {
      "epoch": 1.1606297556015288,
      "grad_norm": 0.11112035065889359,
      "learning_rate": 4.2750348467182724e-05,
      "loss": 0.0394,
      "step": 33100
    },
    {
      "epoch": 1.164136189908482,
      "grad_norm": 0.2514348030090332,
      "learning_rate": 4.2728432292168914e-05,
      "loss": 0.0355,
      "step": 33200
    },
    {
      "epoch": 1.1676426242154354,
      "grad_norm": 0.24891351163387299,
      "learning_rate": 4.270651611715511e-05,
      "loss": 0.0422,
      "step": 33300
    },
    {
      "epoch": 1.1711490585223885,
      "grad_norm": 0.2270219624042511,
      "learning_rate": 4.26845999421413e-05,
      "loss": 0.0423,
      "step": 33400
    },
    {
      "epoch": 1.1746554928293418,
      "grad_norm": 0.31264257431030273,
      "learning_rate": 4.266268376712749e-05,
      "loss": 0.0404,
      "step": 33500
    },
    {
      "epoch": 1.178161927136295,
      "grad_norm": 0.14956314861774445,
      "learning_rate": 4.264076759211368e-05,
      "loss": 0.0387,
      "step": 33600
    },
    {
      "epoch": 1.1816683614432484,
      "grad_norm": 0.2291247397661209,
      "learning_rate": 4.261885141709988e-05,
      "loss": 0.0395,
      "step": 33700
    },
    {
      "epoch": 1.1851747957502017,
      "grad_norm": 0.21130216121673584,
      "learning_rate": 4.259693524208607e-05,
      "loss": 0.043,
      "step": 33800
    },
    {
      "epoch": 1.188681230057155,
      "grad_norm": 0.20871351659297943,
      "learning_rate": 4.257501906707227e-05,
      "loss": 0.0407,
      "step": 33900
    },
    {
      "epoch": 1.192187664364108,
      "grad_norm": 0.35650160908699036,
      "learning_rate": 4.255310289205846e-05,
      "loss": 0.0374,
      "step": 34000
    },
    {
      "epoch": 1.1956940986710614,
      "grad_norm": 0.15410931408405304,
      "learning_rate": 4.2531186717044654e-05,
      "loss": 0.0381,
      "step": 34100
    },
    {
      "epoch": 1.1992005329780147,
      "grad_norm": 0.38279491662979126,
      "learning_rate": 4.2509270542030845e-05,
      "loss": 0.0365,
      "step": 34200
    },
    {
      "epoch": 1.202706967284968,
      "grad_norm": 0.23900826275348663,
      "learning_rate": 4.2487354367017035e-05,
      "loss": 0.0408,
      "step": 34300
    },
    {
      "epoch": 1.2062134015919213,
      "grad_norm": 0.16490979492664337,
      "learning_rate": 4.2465438192003225e-05,
      "loss": 0.0385,
      "step": 34400
    },
    {
      "epoch": 1.2097198358988743,
      "grad_norm": 0.3459490239620209,
      "learning_rate": 4.244352201698942e-05,
      "loss": 0.0393,
      "step": 34500
    },
    {
      "epoch": 1.2132262702058276,
      "grad_norm": 0.1656678169965744,
      "learning_rate": 4.242160584197561e-05,
      "loss": 0.0396,
      "step": 34600
    },
    {
      "epoch": 1.216732704512781,
      "grad_norm": 0.49044865369796753,
      "learning_rate": 4.23996896669618e-05,
      "loss": 0.0406,
      "step": 34700
    },
    {
      "epoch": 1.2202391388197342,
      "grad_norm": 0.3687041997909546,
      "learning_rate": 4.2377773491948e-05,
      "loss": 0.0412,
      "step": 34800
    },
    {
      "epoch": 1.2237455731266875,
      "grad_norm": 0.1675226390361786,
      "learning_rate": 4.23558573169342e-05,
      "loss": 0.0399,
      "step": 34900
    },
    {
      "epoch": 1.2272520074336408,
      "grad_norm": 0.1180252954363823,
      "learning_rate": 4.233394114192039e-05,
      "loss": 0.0425,
      "step": 35000
    },
    {
      "epoch": 1.230758441740594,
      "grad_norm": 0.43268945813179016,
      "learning_rate": 4.231202496690658e-05,
      "loss": 0.0408,
      "step": 35100
    },
    {
      "epoch": 1.2342648760475472,
      "grad_norm": 0.21111315488815308,
      "learning_rate": 4.229010879189277e-05,
      "loss": 0.0408,
      "step": 35200
    },
    {
      "epoch": 1.2377713103545005,
      "grad_norm": 0.1834595799446106,
      "learning_rate": 4.2268192616878965e-05,
      "loss": 0.041,
      "step": 35300
    },
    {
      "epoch": 1.2412777446614538,
      "grad_norm": 0.2035180628299713,
      "learning_rate": 4.2246276441865155e-05,
      "loss": 0.0391,
      "step": 35400
    },
    {
      "epoch": 1.244784178968407,
      "grad_norm": 0.41441047191619873,
      "learning_rate": 4.2224360266851346e-05,
      "loss": 0.0383,
      "step": 35500
    },
    {
      "epoch": 1.2482906132753602,
      "grad_norm": 0.10055941343307495,
      "learning_rate": 4.220244409183754e-05,
      "loss": 0.0421,
      "step": 35600
    },
    {
      "epoch": 1.2517970475823135,
      "grad_norm": 0.27598756551742554,
      "learning_rate": 4.2180747078573876e-05,
      "loss": 0.042,
      "step": 35700
    },
    {
      "epoch": 1.2553034818892668,
      "grad_norm": 0.11754061281681061,
      "learning_rate": 4.2158830903560066e-05,
      "loss": 0.0386,
      "step": 35800
    },
    {
      "epoch": 1.25880991619622,
      "grad_norm": 0.09725441783666611,
      "learning_rate": 4.2136914728546256e-05,
      "loss": 0.04,
      "step": 35900
    },
    {
      "epoch": 1.2623163505031734,
      "grad_norm": 0.22603397071361542,
      "learning_rate": 4.2114998553532453e-05,
      "loss": 0.0407,
      "step": 36000
    },
    {
      "epoch": 1.2658227848101267,
      "grad_norm": 0.3897196650505066,
      "learning_rate": 4.2093082378518644e-05,
      "loss": 0.0381,
      "step": 36100
    },
    {
      "epoch": 1.26932921911708,
      "grad_norm": 0.1944335550069809,
      "learning_rate": 4.2071166203504834e-05,
      "loss": 0.039,
      "step": 36200
    },
    {
      "epoch": 1.272835653424033,
      "grad_norm": 0.144961416721344,
      "learning_rate": 4.2049250028491024e-05,
      "loss": 0.0418,
      "step": 36300
    },
    {
      "epoch": 1.2763420877309863,
      "grad_norm": 0.44773799180984497,
      "learning_rate": 4.202733385347722e-05,
      "loss": 0.0426,
      "step": 36400
    },
    {
      "epoch": 1.2798485220379396,
      "grad_norm": 0.27763062715530396,
      "learning_rate": 4.200541767846342e-05,
      "loss": 0.0409,
      "step": 36500
    },
    {
      "epoch": 1.283354956344893,
      "grad_norm": 0.1356600821018219,
      "learning_rate": 4.198350150344961e-05,
      "loss": 0.0392,
      "step": 36600
    },
    {
      "epoch": 1.286861390651846,
      "grad_norm": 0.2901052236557007,
      "learning_rate": 4.19615853284358e-05,
      "loss": 0.0423,
      "step": 36700
    },
    {
      "epoch": 1.2903678249587993,
      "grad_norm": 0.2729577422142029,
      "learning_rate": 4.1939669153421996e-05,
      "loss": 0.0386,
      "step": 36800
    },
    {
      "epoch": 1.2938742592657526,
      "grad_norm": 0.36189913749694824,
      "learning_rate": 4.191775297840819e-05,
      "loss": 0.0455,
      "step": 36900
    },
    {
      "epoch": 1.297380693572706,
      "grad_norm": 0.2881810963153839,
      "learning_rate": 4.189583680339438e-05,
      "loss": 0.0376,
      "step": 37000
    },
    {
      "epoch": 1.3008871278796592,
      "grad_norm": 0.0874117761850357,
      "learning_rate": 4.187392062838057e-05,
      "loss": 0.0392,
      "step": 37100
    },
    {
      "epoch": 1.3043935621866125,
      "grad_norm": 0.3076469898223877,
      "learning_rate": 4.1852004453366764e-05,
      "loss": 0.0413,
      "step": 37200
    },
    {
      "epoch": 1.3078999964935658,
      "grad_norm": 0.12752662599086761,
      "learning_rate": 4.1830088278352955e-05,
      "loss": 0.0404,
      "step": 37300
    },
    {
      "epoch": 1.3114064308005189,
      "grad_norm": 0.2252945452928543,
      "learning_rate": 4.180817210333915e-05,
      "loss": 0.0408,
      "step": 37400
    },
    {
      "epoch": 1.3149128651074722,
      "grad_norm": 0.4433138072490692,
      "learning_rate": 4.178625592832534e-05,
      "loss": 0.0388,
      "step": 37500
    },
    {
      "epoch": 1.3184192994144255,
      "grad_norm": 0.3108261823654175,
      "learning_rate": 4.176433975331154e-05,
      "loss": 0.0416,
      "step": 37600
    },
    {
      "epoch": 1.3219257337213788,
      "grad_norm": 0.2654540240764618,
      "learning_rate": 4.174242357829773e-05,
      "loss": 0.0401,
      "step": 37700
    },
    {
      "epoch": 1.3254321680283319,
      "grad_norm": 0.2152414321899414,
      "learning_rate": 4.172050740328392e-05,
      "loss": 0.0408,
      "step": 37800
    },
    {
      "epoch": 1.3289386023352852,
      "grad_norm": 0.18015193939208984,
      "learning_rate": 4.169859122827011e-05,
      "loss": 0.04,
      "step": 37900
    },
    {
      "epoch": 1.3324450366422385,
      "grad_norm": 0.12733906507492065,
      "learning_rate": 4.167689421500644e-05,
      "loss": 0.0373,
      "step": 38000
    },
    {
      "epoch": 1.3359514709491918,
      "grad_norm": 0.21263153851032257,
      "learning_rate": 4.165497803999264e-05,
      "loss": 0.0425,
      "step": 38100
    },
    {
      "epoch": 1.339457905256145,
      "grad_norm": 0.22649875283241272,
      "learning_rate": 4.163306186497883e-05,
      "loss": 0.0419,
      "step": 38200
    },
    {
      "epoch": 1.3429643395630984,
      "grad_norm": 0.2041233777999878,
      "learning_rate": 4.161114568996503e-05,
      "loss": 0.0369,
      "step": 38300
    },
    {
      "epoch": 1.3464707738700517,
      "grad_norm": 0.055152859538793564,
      "learning_rate": 4.158922951495122e-05,
      "loss": 0.0418,
      "step": 38400
    },
    {
      "epoch": 1.3499772081770047,
      "grad_norm": 0.2005815953016281,
      "learning_rate": 4.156731333993741e-05,
      "loss": 0.0386,
      "step": 38500
    },
    {
      "epoch": 1.353483642483958,
      "grad_norm": 0.2698611915111542,
      "learning_rate": 4.15453971649236e-05,
      "loss": 0.0392,
      "step": 38600
    },
    {
      "epoch": 1.3569900767909113,
      "grad_norm": 0.27472710609436035,
      "learning_rate": 4.1523480989909796e-05,
      "loss": 0.0398,
      "step": 38700
    },
    {
      "epoch": 1.3604965110978646,
      "grad_norm": 0.3537918031215668,
      "learning_rate": 4.1501564814895986e-05,
      "loss": 0.0436,
      "step": 38800
    },
    {
      "epoch": 1.364002945404818,
      "grad_norm": 0.1014179065823555,
      "learning_rate": 4.1479648639882176e-05,
      "loss": 0.0374,
      "step": 38900
    },
    {
      "epoch": 1.367509379711771,
      "grad_norm": 0.1608412116765976,
      "learning_rate": 4.1457732464868373e-05,
      "loss": 0.0429,
      "step": 39000
    },
    {
      "epoch": 1.3710158140187243,
      "grad_norm": 0.12576493620872498,
      "learning_rate": 4.143581628985457e-05,
      "loss": 0.0372,
      "step": 39100
    },
    {
      "epoch": 1.3745222483256776,
      "grad_norm": 0.19177867472171783,
      "learning_rate": 4.141390011484076e-05,
      "loss": 0.039,
      "step": 39200
    },
    {
      "epoch": 1.378028682632631,
      "grad_norm": 0.09965499490499496,
      "learning_rate": 4.139198393982695e-05,
      "loss": 0.0418,
      "step": 39300
    },
    {
      "epoch": 1.3815351169395842,
      "grad_norm": 0.06927776336669922,
      "learning_rate": 4.137006776481315e-05,
      "loss": 0.0394,
      "step": 39400
    },
    {
      "epoch": 1.3850415512465375,
      "grad_norm": 0.11209824681282043,
      "learning_rate": 4.134815158979934e-05,
      "loss": 0.0385,
      "step": 39500
    },
    {
      "epoch": 1.3885479855534908,
      "grad_norm": 0.12340063601732254,
      "learning_rate": 4.132623541478553e-05,
      "loss": 0.041,
      "step": 39600
    },
    {
      "epoch": 1.3920544198604439,
      "grad_norm": 0.24239641427993774,
      "learning_rate": 4.130431923977172e-05,
      "loss": 0.0398,
      "step": 39700
    },
    {
      "epoch": 1.3955608541673972,
      "grad_norm": 0.21791142225265503,
      "learning_rate": 4.1282403064757916e-05,
      "loss": 0.0427,
      "step": 39800
    },
    {
      "epoch": 1.3990672884743505,
      "grad_norm": 0.42172518372535706,
      "learning_rate": 4.126048688974411e-05,
      "loss": 0.0377,
      "step": 39900
    },
    {
      "epoch": 1.4025737227813038,
      "grad_norm": 0.28366875648498535,
      "learning_rate": 4.1238570714730304e-05,
      "loss": 0.0404,
      "step": 40000
    },
    {
      "epoch": 1.4060801570882568,
      "grad_norm": 0.19254779815673828,
      "learning_rate": 4.1216654539716494e-05,
      "loss": 0.0402,
      "step": 40100
    },
    {
      "epoch": 1.4095865913952101,
      "grad_norm": 0.307789146900177,
      "learning_rate": 4.119473836470269e-05,
      "loss": 0.0418,
      "step": 40200
    },
    {
      "epoch": 1.4130930257021634,
      "grad_norm": 0.2543804347515106,
      "learning_rate": 4.117282218968888e-05,
      "loss": 0.0399,
      "step": 40300
    },
    {
      "epoch": 1.4165994600091167,
      "grad_norm": 0.3601939380168915,
      "learning_rate": 4.115090601467507e-05,
      "loss": 0.0389,
      "step": 40400
    },
    {
      "epoch": 1.42010589431607,
      "grad_norm": 0.3235394358634949,
      "learning_rate": 4.112898983966126e-05,
      "loss": 0.04,
      "step": 40500
    },
    {
      "epoch": 1.4236123286230233,
      "grad_norm": 0.2619979679584503,
      "learning_rate": 4.110707366464746e-05,
      "loss": 0.0393,
      "step": 40600
    },
    {
      "epoch": 1.4271187629299766,
      "grad_norm": 0.31199172139167786,
      "learning_rate": 4.108515748963365e-05,
      "loss": 0.0408,
      "step": 40700
    },
    {
      "epoch": 1.4306251972369297,
      "grad_norm": 0.1818564236164093,
      "learning_rate": 4.106324131461985e-05,
      "loss": 0.0402,
      "step": 40800
    },
    {
      "epoch": 1.434131631543883,
      "grad_norm": 0.22476084530353546,
      "learning_rate": 4.104132513960604e-05,
      "loss": 0.0417,
      "step": 40900
    },
    {
      "epoch": 1.4376380658508363,
      "grad_norm": 0.15400929749011993,
      "learning_rate": 4.1019408964592234e-05,
      "loss": 0.0372,
      "step": 41000
    },
    {
      "epoch": 1.4411445001577896,
      "grad_norm": 0.2069476842880249,
      "learning_rate": 4.0997492789578424e-05,
      "loss": 0.0333,
      "step": 41100
    },
    {
      "epoch": 1.4446509344647427,
      "grad_norm": 0.30699029564857483,
      "learning_rate": 4.0975576614564615e-05,
      "loss": 0.0375,
      "step": 41200
    },
    {
      "epoch": 1.448157368771696,
      "grad_norm": 0.2012876272201538,
      "learning_rate": 4.0953660439550805e-05,
      "loss": 0.0392,
      "step": 41300
    },
    {
      "epoch": 1.4516638030786493,
      "grad_norm": 0.39698097109794617,
      "learning_rate": 4.0931744264537e-05,
      "loss": 0.0393,
      "step": 41400
    },
    {
      "epoch": 1.4551702373856026,
      "grad_norm": 0.26028379797935486,
      "learning_rate": 4.090982808952319e-05,
      "loss": 0.0393,
      "step": 41500
    },
    {
      "epoch": 1.4586766716925559,
      "grad_norm": 0.2789490818977356,
      "learning_rate": 4.088791191450938e-05,
      "loss": 0.0391,
      "step": 41600
    },
    {
      "epoch": 1.4621831059995092,
      "grad_norm": 0.4242878556251526,
      "learning_rate": 4.086599573949558e-05,
      "loss": 0.0397,
      "step": 41700
    },
    {
      "epoch": 1.4656895403064625,
      "grad_norm": 0.1943901926279068,
      "learning_rate": 4.084407956448178e-05,
      "loss": 0.0368,
      "step": 41800
    },
    {
      "epoch": 1.4691959746134156,
      "grad_norm": 0.1873067021369934,
      "learning_rate": 4.082216338946797e-05,
      "loss": 0.0383,
      "step": 41900
    },
    {
      "epoch": 1.4727024089203689,
      "grad_norm": 0.2636645436286926,
      "learning_rate": 4.080024721445416e-05,
      "loss": 0.0404,
      "step": 42000
    },
    {
      "epoch": 1.4762088432273222,
      "grad_norm": 0.11715248972177505,
      "learning_rate": 4.077855020119049e-05,
      "loss": 0.0387,
      "step": 42100
    },
    {
      "epoch": 1.4797152775342755,
      "grad_norm": 0.20506802201271057,
      "learning_rate": 4.075663402617668e-05,
      "loss": 0.0405,
      "step": 42200
    },
    {
      "epoch": 1.4832217118412285,
      "grad_norm": 0.09596329927444458,
      "learning_rate": 4.073471785116287e-05,
      "loss": 0.0327,
      "step": 42300
    },
    {
      "epoch": 1.4867281461481818,
      "grad_norm": 0.4647037982940674,
      "learning_rate": 4.071280167614907e-05,
      "loss": 0.0427,
      "step": 42400
    },
    {
      "epoch": 1.4902345804551351,
      "grad_norm": 0.1023421436548233,
      "learning_rate": 4.069088550113526e-05,
      "loss": 0.0381,
      "step": 42500
    },
    {
      "epoch": 1.4937410147620884,
      "grad_norm": 0.1916355937719345,
      "learning_rate": 4.0668969326121456e-05,
      "loss": 0.0389,
      "step": 42600
    },
    {
      "epoch": 1.4972474490690417,
      "grad_norm": 0.15301842987537384,
      "learning_rate": 4.0647053151107646e-05,
      "loss": 0.0435,
      "step": 42700
    },
    {
      "epoch": 1.500753883375995,
      "grad_norm": 0.11581095308065414,
      "learning_rate": 4.0625136976093836e-05,
      "loss": 0.0372,
      "step": 42800
    },
    {
      "epoch": 1.5042603176829483,
      "grad_norm": 0.2646077573299408,
      "learning_rate": 4.0603220801080033e-05,
      "loss": 0.038,
      "step": 42900
    },
    {
      "epoch": 1.5077667519899016,
      "grad_norm": 0.2813217043876648,
      "learning_rate": 4.0581304626066224e-05,
      "loss": 0.036,
      "step": 43000
    },
    {
      "epoch": 1.5112731862968547,
      "grad_norm": 0.2158242017030716,
      "learning_rate": 4.0559388451052414e-05,
      "loss": 0.0393,
      "step": 43100
    },
    {
      "epoch": 1.514779620603808,
      "grad_norm": 0.08116740733385086,
      "learning_rate": 4.0537472276038604e-05,
      "loss": 0.0401,
      "step": 43200
    },
    {
      "epoch": 1.5182860549107613,
      "grad_norm": 0.1589123010635376,
      "learning_rate": 4.05155561010248e-05,
      "loss": 0.0403,
      "step": 43300
    },
    {
      "epoch": 1.5217924892177144,
      "grad_norm": 0.18139100074768066,
      "learning_rate": 4.0493639926011e-05,
      "loss": 0.0382,
      "step": 43400
    },
    {
      "epoch": 1.5252989235246677,
      "grad_norm": 0.3963811993598938,
      "learning_rate": 4.047172375099719e-05,
      "loss": 0.039,
      "step": 43500
    },
    {
      "epoch": 1.528805357831621,
      "grad_norm": 0.20196892321109772,
      "learning_rate": 4.044980757598338e-05,
      "loss": 0.0414,
      "step": 43600
    },
    {
      "epoch": 1.5323117921385743,
      "grad_norm": 0.4279964864253998,
      "learning_rate": 4.0427891400969576e-05,
      "loss": 0.0356,
      "step": 43700
    },
    {
      "epoch": 1.5358182264455276,
      "grad_norm": 0.1778930425643921,
      "learning_rate": 4.040597522595577e-05,
      "loss": 0.0358,
      "step": 43800
    },
    {
      "epoch": 1.5393246607524809,
      "grad_norm": 0.2764241099357605,
      "learning_rate": 4.038405905094196e-05,
      "loss": 0.039,
      "step": 43900
    },
    {
      "epoch": 1.5428310950594342,
      "grad_norm": 0.10255198925733566,
      "learning_rate": 4.036214287592815e-05,
      "loss": 0.037,
      "step": 44000
    },
    {
      "epoch": 1.5463375293663875,
      "grad_norm": 0.22016964852809906,
      "learning_rate": 4.0340226700914344e-05,
      "loss": 0.0385,
      "step": 44100
    },
    {
      "epoch": 1.5498439636733405,
      "grad_norm": 0.17948758602142334,
      "learning_rate": 4.0318310525900535e-05,
      "loss": 0.0384,
      "step": 44200
    },
    {
      "epoch": 1.5533503979802938,
      "grad_norm": 0.13579753041267395,
      "learning_rate": 4.029639435088673e-05,
      "loss": 0.0386,
      "step": 44300
    },
    {
      "epoch": 1.5568568322872471,
      "grad_norm": 0.15174484252929688,
      "learning_rate": 4.027447817587292e-05,
      "loss": 0.0416,
      "step": 44400
    },
    {
      "epoch": 1.5603632665942002,
      "grad_norm": 0.3635401129722595,
      "learning_rate": 4.0252781162609255e-05,
      "loss": 0.0389,
      "step": 44500
    },
    {
      "epoch": 1.5638697009011535,
      "grad_norm": 0.3729710578918457,
      "learning_rate": 4.0230864987595445e-05,
      "loss": 0.0378,
      "step": 44600
    },
    {
      "epoch": 1.5673761352081068,
      "grad_norm": 0.3099483549594879,
      "learning_rate": 4.0208948812581636e-05,
      "loss": 0.0414,
      "step": 44700
    },
    {
      "epoch": 1.5708825695150601,
      "grad_norm": 0.25436702370643616,
      "learning_rate": 4.018703263756783e-05,
      "loss": 0.0413,
      "step": 44800
    },
    {
      "epoch": 1.5743890038220134,
      "grad_norm": 0.21603281795978546,
      "learning_rate": 4.016511646255402e-05,
      "loss": 0.0368,
      "step": 44900
    },
    {
      "epoch": 1.5778954381289667,
      "grad_norm": 0.11980436742305756,
      "learning_rate": 4.014320028754022e-05,
      "loss": 0.0378,
      "step": 45000
    },
    {
      "epoch": 1.58140187243592,
      "grad_norm": 0.2863785922527313,
      "learning_rate": 4.012128411252641e-05,
      "loss": 0.0371,
      "step": 45100
    },
    {
      "epoch": 1.5849083067428733,
      "grad_norm": 0.20943258702754974,
      "learning_rate": 4.009936793751261e-05,
      "loss": 0.0393,
      "step": 45200
    },
    {
      "epoch": 1.5884147410498264,
      "grad_norm": 0.4638271629810333,
      "learning_rate": 4.00774517624988e-05,
      "loss": 0.04,
      "step": 45300
    },
    {
      "epoch": 1.5919211753567797,
      "grad_norm": 0.10419311374425888,
      "learning_rate": 4.005553558748499e-05,
      "loss": 0.0379,
      "step": 45400
    },
    {
      "epoch": 1.595427609663733,
      "grad_norm": 0.1524180918931961,
      "learning_rate": 4.003361941247118e-05,
      "loss": 0.0401,
      "step": 45500
    },
    {
      "epoch": 1.598934043970686,
      "grad_norm": 0.06454000622034073,
      "learning_rate": 4.0011703237457376e-05,
      "loss": 0.037,
      "step": 45600
    },
    {
      "epoch": 1.6024404782776394,
      "grad_norm": 0.12361646443605423,
      "learning_rate": 3.9989787062443566e-05,
      "loss": 0.0375,
      "step": 45700
    },
    {
      "epoch": 1.6059469125845927,
      "grad_norm": 0.3941190540790558,
      "learning_rate": 3.9967870887429756e-05,
      "loss": 0.0433,
      "step": 45800
    },
    {
      "epoch": 1.609453346891546,
      "grad_norm": 0.3359866738319397,
      "learning_rate": 3.9945954712415953e-05,
      "loss": 0.0392,
      "step": 45900
    },
    {
      "epoch": 1.6129597811984993,
      "grad_norm": 0.49811306595802307,
      "learning_rate": 3.992403853740215e-05,
      "loss": 0.0414,
      "step": 46000
    },
    {
      "epoch": 1.6164662155054526,
      "grad_norm": 0.4739331007003784,
      "learning_rate": 3.990212236238834e-05,
      "loss": 0.0387,
      "step": 46100
    },
    {
      "epoch": 1.6199726498124059,
      "grad_norm": 0.1466778665781021,
      "learning_rate": 3.988020618737453e-05,
      "loss": 0.0374,
      "step": 46200
    },
    {
      "epoch": 1.6234790841193592,
      "grad_norm": 0.21696506440639496,
      "learning_rate": 3.985829001236073e-05,
      "loss": 0.0405,
      "step": 46300
    },
    {
      "epoch": 1.6269855184263124,
      "grad_norm": 0.26196038722991943,
      "learning_rate": 3.983637383734692e-05,
      "loss": 0.0375,
      "step": 46400
    },
    {
      "epoch": 1.6304919527332655,
      "grad_norm": 0.23340052366256714,
      "learning_rate": 3.981445766233311e-05,
      "loss": 0.0404,
      "step": 46500
    },
    {
      "epoch": 1.6339983870402188,
      "grad_norm": 0.35684746503829956,
      "learning_rate": 3.97925414873193e-05,
      "loss": 0.0371,
      "step": 46600
    },
    {
      "epoch": 1.637504821347172,
      "grad_norm": 0.11741432547569275,
      "learning_rate": 3.9770625312305496e-05,
      "loss": 0.039,
      "step": 46700
    },
    {
      "epoch": 1.6410112556541252,
      "grad_norm": 0.07096976041793823,
      "learning_rate": 3.974870913729169e-05,
      "loss": 0.0369,
      "step": 46800
    },
    {
      "epoch": 1.6445176899610785,
      "grad_norm": 0.13358841836452484,
      "learning_rate": 3.9726792962277884e-05,
      "loss": 0.039,
      "step": 46900
    },
    {
      "epoch": 1.6480241242680318,
      "grad_norm": 0.6255601048469543,
      "learning_rate": 3.9704876787264074e-05,
      "loss": 0.0401,
      "step": 47000
    },
    {
      "epoch": 1.651530558574985,
      "grad_norm": 0.22283528745174408,
      "learning_rate": 3.968296061225027e-05,
      "loss": 0.0362,
      "step": 47100
    },
    {
      "epoch": 1.6550369928819384,
      "grad_norm": 0.18725891411304474,
      "learning_rate": 3.966104443723646e-05,
      "loss": 0.0368,
      "step": 47200
    },
    {
      "epoch": 1.6585434271888917,
      "grad_norm": 0.21563923358917236,
      "learning_rate": 3.963912826222265e-05,
      "loss": 0.0419,
      "step": 47300
    },
    {
      "epoch": 1.662049861495845,
      "grad_norm": 0.17545239627361298,
      "learning_rate": 3.961721208720884e-05,
      "loss": 0.0382,
      "step": 47400
    },
    {
      "epoch": 1.6655562958027983,
      "grad_norm": 0.23905934393405914,
      "learning_rate": 3.959529591219504e-05,
      "loss": 0.038,
      "step": 47500
    },
    {
      "epoch": 1.6690627301097514,
      "grad_norm": 0.3037598431110382,
      "learning_rate": 3.957337973718123e-05,
      "loss": 0.0381,
      "step": 47600
    },
    {
      "epoch": 1.6725691644167047,
      "grad_norm": 0.1861494481563568,
      "learning_rate": 3.955146356216743e-05,
      "loss": 0.0358,
      "step": 47700
    },
    {
      "epoch": 1.676075598723658,
      "grad_norm": 0.136694997549057,
      "learning_rate": 3.952954738715362e-05,
      "loss": 0.0321,
      "step": 47800
    },
    {
      "epoch": 1.679582033030611,
      "grad_norm": 0.2670077383518219,
      "learning_rate": 3.9507631212139814e-05,
      "loss": 0.0407,
      "step": 47900
    },
    {
      "epoch": 1.6830884673375643,
      "grad_norm": 0.17857393622398376,
      "learning_rate": 3.9485715037126004e-05,
      "loss": 0.0375,
      "step": 48000
    },
    {
      "epoch": 1.6865949016445176,
      "grad_norm": 0.1433887481689453,
      "learning_rate": 3.9463798862112195e-05,
      "loss": 0.0377,
      "step": 48100
    },
    {
      "epoch": 1.690101335951471,
      "grad_norm": 0.16639842092990875,
      "learning_rate": 3.9441882687098385e-05,
      "loss": 0.035,
      "step": 48200
    },
    {
      "epoch": 1.6936077702584242,
      "grad_norm": 0.14204353094100952,
      "learning_rate": 3.942018567383472e-05,
      "loss": 0.0392,
      "step": 48300
    },
    {
      "epoch": 1.6971142045653775,
      "grad_norm": 0.21603815257549286,
      "learning_rate": 3.939826949882091e-05,
      "loss": 0.0382,
      "step": 48400
    },
    {
      "epoch": 1.7006206388723308,
      "grad_norm": 0.22477379441261292,
      "learning_rate": 3.9376353323807105e-05,
      "loss": 0.0368,
      "step": 48500
    },
    {
      "epoch": 1.7041270731792841,
      "grad_norm": 0.18409094214439392,
      "learning_rate": 3.93544371487933e-05,
      "loss": 0.0359,
      "step": 48600
    },
    {
      "epoch": 1.7076335074862372,
      "grad_norm": 0.20716916024684906,
      "learning_rate": 3.933252097377949e-05,
      "loss": 0.0376,
      "step": 48700
    },
    {
      "epoch": 1.7111399417931905,
      "grad_norm": 0.23008768260478973,
      "learning_rate": 3.931060479876568e-05,
      "loss": 0.0374,
      "step": 48800
    },
    {
      "epoch": 1.7146463761001438,
      "grad_norm": 0.2596879005432129,
      "learning_rate": 3.9288688623751873e-05,
      "loss": 0.0378,
      "step": 48900
    },
    {
      "epoch": 1.7181528104070969,
      "grad_norm": 0.4040012061595917,
      "learning_rate": 3.926677244873807e-05,
      "loss": 0.0356,
      "step": 49000
    },
    {
      "epoch": 1.7216592447140502,
      "grad_norm": 0.2854762673377991,
      "learning_rate": 3.924485627372426e-05,
      "loss": 0.0389,
      "step": 49100
    },
    {
      "epoch": 1.7251656790210035,
      "grad_norm": 0.17033930122852325,
      "learning_rate": 3.922294009871045e-05,
      "loss": 0.045,
      "step": 49200
    },
    {
      "epoch": 1.7286721133279568,
      "grad_norm": 0.218221515417099,
      "learning_rate": 3.920102392369664e-05,
      "loss": 0.0399,
      "step": 49300
    },
    {
      "epoch": 1.73217854763491,
      "grad_norm": 0.5775059461593628,
      "learning_rate": 3.917910774868284e-05,
      "loss": 0.0397,
      "step": 49400
    },
    {
      "epoch": 1.7356849819418634,
      "grad_norm": 0.2195887267589569,
      "learning_rate": 3.9157191573669036e-05,
      "loss": 0.038,
      "step": 49500
    },
    {
      "epoch": 1.7391914162488167,
      "grad_norm": 0.33447661995887756,
      "learning_rate": 3.9135275398655226e-05,
      "loss": 0.0413,
      "step": 49600
    },
    {
      "epoch": 1.74269785055577,
      "grad_norm": 0.11597117781639099,
      "learning_rate": 3.9113359223641416e-05,
      "loss": 0.0362,
      "step": 49700
    },
    {
      "epoch": 1.746204284862723,
      "grad_norm": 0.3005761504173279,
      "learning_rate": 3.9091443048627613e-05,
      "loss": 0.0377,
      "step": 49800
    },
    {
      "epoch": 1.7497107191696764,
      "grad_norm": 0.2691986858844757,
      "learning_rate": 3.9069526873613804e-05,
      "loss": 0.036,
      "step": 49900
    },
    {
      "epoch": 1.7532171534766297,
      "grad_norm": 0.3218156397342682,
      "learning_rate": 3.9047610698599994e-05,
      "loss": 0.0361,
      "step": 50000
    },
    {
      "epoch": 1.7567235877835827,
      "grad_norm": 0.42631229758262634,
      "learning_rate": 3.9025694523586184e-05,
      "loss": 0.0387,
      "step": 50100
    },
    {
      "epoch": 1.760230022090536,
      "grad_norm": 0.17747417092323303,
      "learning_rate": 3.900377834857238e-05,
      "loss": 0.0358,
      "step": 50200
    },
    {
      "epoch": 1.7637364563974893,
      "grad_norm": 0.2926805019378662,
      "learning_rate": 3.898186217355858e-05,
      "loss": 0.0389,
      "step": 50300
    },
    {
      "epoch": 1.7672428907044426,
      "grad_norm": 0.22717706859111786,
      "learning_rate": 3.8960165160294905e-05,
      "loss": 0.0362,
      "step": 50400
    },
    {
      "epoch": 1.770749325011396,
      "grad_norm": 0.04967745020985603,
      "learning_rate": 3.89382489852811e-05,
      "loss": 0.0382,
      "step": 50500
    },
    {
      "epoch": 1.7742557593183492,
      "grad_norm": 0.5813011527061462,
      "learning_rate": 3.891633281026729e-05,
      "loss": 0.0374,
      "step": 50600
    },
    {
      "epoch": 1.7777621936253025,
      "grad_norm": 0.2097448855638504,
      "learning_rate": 3.889441663525348e-05,
      "loss": 0.0397,
      "step": 50700
    },
    {
      "epoch": 1.7812686279322558,
      "grad_norm": 0.12529915571212769,
      "learning_rate": 3.887250046023967e-05,
      "loss": 0.0359,
      "step": 50800
    },
    {
      "epoch": 1.784775062239209,
      "grad_norm": 0.18629927933216095,
      "learning_rate": 3.885058428522587e-05,
      "loss": 0.0362,
      "step": 50900
    },
    {
      "epoch": 1.7882814965461622,
      "grad_norm": 0.22372955083847046,
      "learning_rate": 3.882866811021206e-05,
      "loss": 0.0352,
      "step": 51000
    },
    {
      "epoch": 1.7917879308531155,
      "grad_norm": 0.17454063892364502,
      "learning_rate": 3.880675193519826e-05,
      "loss": 0.0342,
      "step": 51100
    },
    {
      "epoch": 1.7952943651600686,
      "grad_norm": 0.12677451968193054,
      "learning_rate": 3.878483576018445e-05,
      "loss": 0.0405,
      "step": 51200
    },
    {
      "epoch": 1.7988007994670219,
      "grad_norm": 0.1941850781440735,
      "learning_rate": 3.8762919585170645e-05,
      "loss": 0.0366,
      "step": 51300
    },
    {
      "epoch": 1.8023072337739752,
      "grad_norm": 0.14971019327640533,
      "learning_rate": 3.8741003410156835e-05,
      "loss": 0.0363,
      "step": 51400
    },
    {
      "epoch": 1.8058136680809285,
      "grad_norm": 0.11157539486885071,
      "learning_rate": 3.8719087235143025e-05,
      "loss": 0.0396,
      "step": 51500
    },
    {
      "epoch": 1.8093201023878818,
      "grad_norm": 0.15641069412231445,
      "learning_rate": 3.869739022187936e-05,
      "loss": 0.0362,
      "step": 51600
    },
    {
      "epoch": 1.812826536694835,
      "grad_norm": 0.21747015416622162,
      "learning_rate": 3.867547404686555e-05,
      "loss": 0.0387,
      "step": 51700
    },
    {
      "epoch": 1.8163329710017884,
      "grad_norm": 0.2045918107032776,
      "learning_rate": 3.8653557871851746e-05,
      "loss": 0.0402,
      "step": 51800
    },
    {
      "epoch": 1.8198394053087417,
      "grad_norm": 0.14570780098438263,
      "learning_rate": 3.8631641696837936e-05,
      "loss": 0.0351,
      "step": 51900
    },
    {
      "epoch": 1.823345839615695,
      "grad_norm": 0.12747260928153992,
      "learning_rate": 3.860972552182413e-05,
      "loss": 0.0366,
      "step": 52000
    },
    {
      "epoch": 1.826852273922648,
      "grad_norm": 0.1429225653409958,
      "learning_rate": 3.858780934681032e-05,
      "loss": 0.0344,
      "step": 52100
    },
    {
      "epoch": 1.8303587082296013,
      "grad_norm": 0.08649855107069016,
      "learning_rate": 3.8565893171796514e-05,
      "loss": 0.0357,
      "step": 52200
    },
    {
      "epoch": 1.8338651425365544,
      "grad_norm": 0.27605053782463074,
      "learning_rate": 3.8543976996782704e-05,
      "loss": 0.0331,
      "step": 52300
    },
    {
      "epoch": 1.8373715768435077,
      "grad_norm": 0.048184044659137726,
      "learning_rate": 3.85220608217689e-05,
      "loss": 0.041,
      "step": 52400
    },
    {
      "epoch": 1.840878011150461,
      "grad_norm": 0.18429145216941833,
      "learning_rate": 3.850014464675509e-05,
      "loss": 0.0364,
      "step": 52500
    },
    {
      "epoch": 1.8443844454574143,
      "grad_norm": 0.20554429292678833,
      "learning_rate": 3.847822847174128e-05,
      "loss": 0.036,
      "step": 52600
    },
    {
      "epoch": 1.8478908797643676,
      "grad_norm": 0.2571895718574524,
      "learning_rate": 3.845631229672748e-05,
      "loss": 0.0386,
      "step": 52700
    },
    {
      "epoch": 1.851397314071321,
      "grad_norm": 0.5336530804634094,
      "learning_rate": 3.8434396121713676e-05,
      "loss": 0.0353,
      "step": 52800
    },
    {
      "epoch": 1.8549037483782742,
      "grad_norm": 0.09238265454769135,
      "learning_rate": 3.8412479946699866e-05,
      "loss": 0.0346,
      "step": 52900
    },
    {
      "epoch": 1.8584101826852275,
      "grad_norm": 0.37354230880737305,
      "learning_rate": 3.8390563771686057e-05,
      "loss": 0.0414,
      "step": 53000
    },
    {
      "epoch": 1.8619166169921808,
      "grad_norm": 0.31090620160102844,
      "learning_rate": 3.8368647596672254e-05,
      "loss": 0.0405,
      "step": 53100
    },
    {
      "epoch": 1.8654230512991339,
      "grad_norm": 0.08856762945652008,
      "learning_rate": 3.8346731421658444e-05,
      "loss": 0.0349,
      "step": 53200
    },
    {
      "epoch": 1.8689294856060872,
      "grad_norm": 0.11164364218711853,
      "learning_rate": 3.8324815246644634e-05,
      "loss": 0.038,
      "step": 53300
    },
    {
      "epoch": 1.8724359199130405,
      "grad_norm": 0.11345340311527252,
      "learning_rate": 3.8302899071630825e-05,
      "loss": 0.0369,
      "step": 53400
    },
    {
      "epoch": 1.8759423542199936,
      "grad_norm": 0.18791139125823975,
      "learning_rate": 3.828098289661702e-05,
      "loss": 0.0374,
      "step": 53500
    },
    {
      "epoch": 1.8794487885269469,
      "grad_norm": 0.2336268126964569,
      "learning_rate": 3.825906672160321e-05,
      "loss": 0.0401,
      "step": 53600
    },
    {
      "epoch": 1.8829552228339002,
      "grad_norm": 0.14461147785186768,
      "learning_rate": 3.823715054658941e-05,
      "loss": 0.0391,
      "step": 53700
    },
    {
      "epoch": 1.8864616571408535,
      "grad_norm": 0.12625862658023834,
      "learning_rate": 3.82152343715756e-05,
      "loss": 0.0338,
      "step": 53800
    },
    {
      "epoch": 1.8899680914478068,
      "grad_norm": 0.1688736081123352,
      "learning_rate": 3.8193318196561797e-05,
      "loss": 0.0368,
      "step": 53900
    },
    {
      "epoch": 1.89347452575476,
      "grad_norm": 0.22644327580928802,
      "learning_rate": 3.817140202154799e-05,
      "loss": 0.0371,
      "step": 54000
    },
    {
      "epoch": 1.8969809600617134,
      "grad_norm": 0.23586104810237885,
      "learning_rate": 3.814948584653418e-05,
      "loss": 0.0392,
      "step": 54100
    },
    {
      "epoch": 1.9004873943686666,
      "grad_norm": 0.32201555371284485,
      "learning_rate": 3.812756967152037e-05,
      "loss": 0.0426,
      "step": 54200
    },
    {
      "epoch": 1.9039938286756197,
      "grad_norm": 0.18496310710906982,
      "learning_rate": 3.8105653496506565e-05,
      "loss": 0.0396,
      "step": 54300
    },
    {
      "epoch": 1.907500262982573,
      "grad_norm": 0.30758580565452576,
      "learning_rate": 3.8083737321492755e-05,
      "loss": 0.0381,
      "step": 54400
    },
    {
      "epoch": 1.9110066972895263,
      "grad_norm": 0.236225426197052,
      "learning_rate": 3.806182114647895e-05,
      "loss": 0.0346,
      "step": 54500
    },
    {
      "epoch": 1.9145131315964794,
      "grad_norm": 0.03968239575624466,
      "learning_rate": 3.803990497146514e-05,
      "loss": 0.0374,
      "step": 54600
    },
    {
      "epoch": 1.9180195659034327,
      "grad_norm": 0.1633661836385727,
      "learning_rate": 3.801798879645134e-05,
      "loss": 0.037,
      "step": 54700
    },
    {
      "epoch": 1.921526000210386,
      "grad_norm": 0.3891404867172241,
      "learning_rate": 3.799607262143753e-05,
      "loss": 0.0374,
      "step": 54800
    },
    {
      "epoch": 1.9250324345173393,
      "grad_norm": 0.18710549175739288,
      "learning_rate": 3.797415644642372e-05,
      "loss": 0.0375,
      "step": 54900
    },
    {
      "epoch": 1.9285388688242926,
      "grad_norm": 0.2705898582935333,
      "learning_rate": 3.795224027140991e-05,
      "loss": 0.0364,
      "step": 55000
    },
    {
      "epoch": 1.932045303131246,
      "grad_norm": 0.2760929465293884,
      "learning_rate": 3.793032409639611e-05,
      "loss": 0.0357,
      "step": 55100
    },
    {
      "epoch": 1.9355517374381992,
      "grad_norm": 0.16556014120578766,
      "learning_rate": 3.79084079213823e-05,
      "loss": 0.0397,
      "step": 55200
    },
    {
      "epoch": 1.9390581717451525,
      "grad_norm": 0.22058424353599548,
      "learning_rate": 3.788649174636849e-05,
      "loss": 0.0354,
      "step": 55300
    },
    {
      "epoch": 1.9425646060521056,
      "grad_norm": 0.244344562292099,
      "learning_rate": 3.7864575571354685e-05,
      "loss": 0.0362,
      "step": 55400
    },
    {
      "epoch": 1.9460710403590589,
      "grad_norm": 0.16250842809677124,
      "learning_rate": 3.784265939634088e-05,
      "loss": 0.0359,
      "step": 55500
    },
    {
      "epoch": 1.9495774746660122,
      "grad_norm": 0.27938348054885864,
      "learning_rate": 3.782074322132707e-05,
      "loss": 0.0354,
      "step": 55600
    },
    {
      "epoch": 1.9530839089729652,
      "grad_norm": 0.2161007672548294,
      "learning_rate": 3.77990462080634e-05,
      "loss": 0.0358,
      "step": 55700
    },
    {
      "epoch": 1.9565903432799185,
      "grad_norm": 0.23809851706027985,
      "learning_rate": 3.7777130033049596e-05,
      "loss": 0.0361,
      "step": 55800
    },
    {
      "epoch": 1.9600967775868718,
      "grad_norm": 0.08394961059093475,
      "learning_rate": 3.7755213858035786e-05,
      "loss": 0.0399,
      "step": 55900
    },
    {
      "epoch": 1.9636032118938251,
      "grad_norm": 0.32449114322662354,
      "learning_rate": 3.7733297683021976e-05,
      "loss": 0.0358,
      "step": 56000
    },
    {
      "epoch": 1.9671096462007784,
      "grad_norm": 0.3957715630531311,
      "learning_rate": 3.771138150800817e-05,
      "loss": 0.0382,
      "step": 56100
    },
    {
      "epoch": 1.9706160805077317,
      "grad_norm": 0.31677722930908203,
      "learning_rate": 3.7689465332994364e-05,
      "loss": 0.0389,
      "step": 56200
    },
    {
      "epoch": 1.974122514814685,
      "grad_norm": 0.2915114462375641,
      "learning_rate": 3.766754915798056e-05,
      "loss": 0.0398,
      "step": 56300
    },
    {
      "epoch": 1.9776289491216383,
      "grad_norm": 0.35495540499687195,
      "learning_rate": 3.764563298296675e-05,
      "loss": 0.038,
      "step": 56400
    },
    {
      "epoch": 1.9811353834285914,
      "grad_norm": 0.13995349407196045,
      "learning_rate": 3.762371680795294e-05,
      "loss": 0.0362,
      "step": 56500
    },
    {
      "epoch": 1.9846418177355447,
      "grad_norm": 0.2939911484718323,
      "learning_rate": 3.760180063293914e-05,
      "loss": 0.038,
      "step": 56600
    },
    {
      "epoch": 1.988148252042498,
      "grad_norm": 0.45955976843833923,
      "learning_rate": 3.757988445792533e-05,
      "loss": 0.037,
      "step": 56700
    },
    {
      "epoch": 1.991654686349451,
      "grad_norm": 1.492717981338501,
      "learning_rate": 3.755796828291152e-05,
      "loss": 0.0329,
      "step": 56800
    },
    {
      "epoch": 1.9951611206564044,
      "grad_norm": 1.5219122171401978,
      "learning_rate": 3.753605210789771e-05,
      "loss": 0.0331,
      "step": 56900
    },
    {
      "epoch": 1.9986675549633577,
      "grad_norm": 0.740587592124939,
      "learning_rate": 3.751413593288391e-05,
      "loss": 0.0363,
      "step": 57000
    },
    {
      "epoch": 2.0,
      "eval_accuracy_macro_0.5": 0.9845857620239258,
      "eval_accuracy_micro_0.5": 0.9845857620239258,
      "eval_accuracy_weighted_0.5": 0.9773827195167542,
      "eval_f1_macro_0.5": 0.7842197418212891,
      "eval_f1_macro_0.6": 0.7727603912353516,
      "eval_f1_macro_0.7": 0.7499687671661377,
      "eval_f1_macro_0.8": 0.6052010655403137,
      "eval_f1_micro_0.5": 0.8042792677879333,
      "eval_f1_micro_0.6": 0.7958139181137085,
      "eval_f1_micro_0.7": 0.776292085647583,
      "eval_f1_micro_0.8": 0.7365719079971313,
      "eval_f1_micro_0.9": 0.646185576915741,
      "eval_f1_weighted_0.5": 0.8017644286155701,
      "eval_f1_weighted_0.6": 0.7900568246841431,
      "eval_f1_weighted_0.7": 0.7664441466331482,
      "eval_f1_weighted_0.8": 0.6175020337104797,
      "eval_loss": 0.03561539947986603,
      "eval_runtime": 405.922,
      "eval_samples_per_second": 140.438,
      "eval_steps_per_second": 17.555,
      "step": 57038
    },
    {
      "epoch": 2.002173989270311,
      "grad_norm": 0.24733507633209229,
      "learning_rate": 3.7492219757870104e-05,
      "loss": 0.0348,
      "step": 57100
    },
    {
      "epoch": 2.0056804235772643,
      "grad_norm": 0.13270239531993866,
      "learning_rate": 3.7470303582856294e-05,
      "loss": 0.0369,
      "step": 57200
    },
    {
      "epoch": 2.0091868578842176,
      "grad_norm": 0.1393701136112213,
      "learning_rate": 3.7448387407842485e-05,
      "loss": 0.0341,
      "step": 57300
    },
    {
      "epoch": 2.012693292191171,
      "grad_norm": 0.1582179218530655,
      "learning_rate": 3.742647123282868e-05,
      "loss": 0.0362,
      "step": 57400
    },
    {
      "epoch": 2.016199726498124,
      "grad_norm": 0.09798233211040497,
      "learning_rate": 3.740455505781487e-05,
      "loss": 0.0405,
      "step": 57500
    },
    {
      "epoch": 2.0197061608050775,
      "grad_norm": 0.4724281132221222,
      "learning_rate": 3.738263888280106e-05,
      "loss": 0.0364,
      "step": 57600
    },
    {
      "epoch": 2.0232125951120308,
      "grad_norm": 0.28009045124053955,
      "learning_rate": 3.7360941869537395e-05,
      "loss": 0.0344,
      "step": 57700
    },
    {
      "epoch": 2.0267190294189836,
      "grad_norm": 0.1976279765367508,
      "learning_rate": 3.7339025694523585e-05,
      "loss": 0.0366,
      "step": 57800
    },
    {
      "epoch": 2.030225463725937,
      "grad_norm": 0.16778555512428284,
      "learning_rate": 3.731710951950978e-05,
      "loss": 0.0319,
      "step": 57900
    },
    {
      "epoch": 2.0337318980328902,
      "grad_norm": 0.12885867059230804,
      "learning_rate": 3.729519334449597e-05,
      "loss": 0.0348,
      "step": 58000
    },
    {
      "epoch": 2.0372383323398435,
      "grad_norm": 0.27980345487594604,
      "learning_rate": 3.727327716948217e-05,
      "loss": 0.0369,
      "step": 58100
    },
    {
      "epoch": 2.040744766646797,
      "grad_norm": 0.24894171953201294,
      "learning_rate": 3.725136099446836e-05,
      "loss": 0.038,
      "step": 58200
    },
    {
      "epoch": 2.04425120095375,
      "grad_norm": 0.225530207157135,
      "learning_rate": 3.722944481945455e-05,
      "loss": 0.0338,
      "step": 58300
    },
    {
      "epoch": 2.0477576352607034,
      "grad_norm": 0.06151081249117851,
      "learning_rate": 3.720752864444074e-05,
      "loss": 0.0349,
      "step": 58400
    },
    {
      "epoch": 2.0512640695676567,
      "grad_norm": 0.189907044172287,
      "learning_rate": 3.718561246942694e-05,
      "loss": 0.0372,
      "step": 58500
    },
    {
      "epoch": 2.05477050387461,
      "grad_norm": 0.15427878499031067,
      "learning_rate": 3.716369629441313e-05,
      "loss": 0.0343,
      "step": 58600
    },
    {
      "epoch": 2.0582769381815633,
      "grad_norm": 0.36331790685653687,
      "learning_rate": 3.714178011939932e-05,
      "loss": 0.0374,
      "step": 58700
    },
    {
      "epoch": 2.0617833724885166,
      "grad_norm": 0.20476824045181274,
      "learning_rate": 3.7119863944385516e-05,
      "loss": 0.0346,
      "step": 58800
    },
    {
      "epoch": 2.0652898067954695,
      "grad_norm": 0.28214070200920105,
      "learning_rate": 3.709794776937171e-05,
      "loss": 0.0362,
      "step": 58900
    },
    {
      "epoch": 2.0687962411024228,
      "grad_norm": 0.6407483816146851,
      "learning_rate": 3.70760315943579e-05,
      "loss": 0.0387,
      "step": 59000
    },
    {
      "epoch": 2.072302675409376,
      "grad_norm": 0.1386672407388687,
      "learning_rate": 3.7054115419344094e-05,
      "loss": 0.0344,
      "step": 59100
    },
    {
      "epoch": 2.0758091097163294,
      "grad_norm": 0.4352254867553711,
      "learning_rate": 3.7032199244330284e-05,
      "loss": 0.0345,
      "step": 59200
    },
    {
      "epoch": 2.0793155440232827,
      "grad_norm": 0.12502379715442657,
      "learning_rate": 3.701028306931648e-05,
      "loss": 0.0364,
      "step": 59300
    },
    {
      "epoch": 2.082821978330236,
      "grad_norm": 0.2636312246322632,
      "learning_rate": 3.698836689430267e-05,
      "loss": 0.0354,
      "step": 59400
    },
    {
      "epoch": 2.0863284126371893,
      "grad_norm": 0.07240575551986694,
      "learning_rate": 3.696645071928886e-05,
      "loss": 0.0362,
      "step": 59500
    },
    {
      "epoch": 2.0898348469441426,
      "grad_norm": 0.08180846273899078,
      "learning_rate": 3.694453454427506e-05,
      "loss": 0.035,
      "step": 59600
    },
    {
      "epoch": 2.093341281251096,
      "grad_norm": 0.2016737014055252,
      "learning_rate": 3.6922618369261256e-05,
      "loss": 0.0345,
      "step": 59700
    },
    {
      "epoch": 2.096847715558049,
      "grad_norm": 0.1388668417930603,
      "learning_rate": 3.690092135599758e-05,
      "loss": 0.0321,
      "step": 59800
    },
    {
      "epoch": 2.1003541498650025,
      "grad_norm": 0.1453997939825058,
      "learning_rate": 3.687900518098378e-05,
      "loss": 0.0359,
      "step": 59900
    },
    {
      "epoch": 2.1038605841719553,
      "grad_norm": 0.09577056765556335,
      "learning_rate": 3.685708900596997e-05,
      "loss": 0.0342,
      "step": 60000
    },
    {
      "epoch": 2.1073670184789086,
      "grad_norm": 0.11123012006282806,
      "learning_rate": 3.683517283095616e-05,
      "loss": 0.0355,
      "step": 60100
    },
    {
      "epoch": 2.110873452785862,
      "grad_norm": 0.13995961844921112,
      "learning_rate": 3.6813475817692486e-05,
      "loss": 0.0344,
      "step": 60200
    },
    {
      "epoch": 2.114379887092815,
      "grad_norm": 0.2962336242198944,
      "learning_rate": 3.679155964267868e-05,
      "loss": 0.0383,
      "step": 60300
    },
    {
      "epoch": 2.1178863213997685,
      "grad_norm": 0.21216584742069244,
      "learning_rate": 3.676964346766488e-05,
      "loss": 0.036,
      "step": 60400
    },
    {
      "epoch": 2.121392755706722,
      "grad_norm": 0.1708914041519165,
      "learning_rate": 3.674772729265107e-05,
      "loss": 0.0341,
      "step": 60500
    },
    {
      "epoch": 2.124899190013675,
      "grad_norm": 0.11401747912168503,
      "learning_rate": 3.672581111763727e-05,
      "loss": 0.0388,
      "step": 60600
    },
    {
      "epoch": 2.1284056243206284,
      "grad_norm": 0.16503289341926575,
      "learning_rate": 3.670389494262346e-05,
      "loss": 0.0381,
      "step": 60700
    },
    {
      "epoch": 2.1319120586275817,
      "grad_norm": 0.13546375930309296,
      "learning_rate": 3.668197876760965e-05,
      "loss": 0.0365,
      "step": 60800
    },
    {
      "epoch": 2.135418492934535,
      "grad_norm": 0.31048667430877686,
      "learning_rate": 3.666006259259584e-05,
      "loss": 0.0318,
      "step": 60900
    },
    {
      "epoch": 2.1389249272414883,
      "grad_norm": 0.26256659626960754,
      "learning_rate": 3.6638146417582035e-05,
      "loss": 0.0372,
      "step": 61000
    },
    {
      "epoch": 2.142431361548441,
      "grad_norm": 0.14889349043369293,
      "learning_rate": 3.6616230242568226e-05,
      "loss": 0.0332,
      "step": 61100
    },
    {
      "epoch": 2.1459377958553945,
      "grad_norm": 0.2144240289926529,
      "learning_rate": 3.6594314067554416e-05,
      "loss": 0.0376,
      "step": 61200
    },
    {
      "epoch": 2.1494442301623478,
      "grad_norm": 0.12449328601360321,
      "learning_rate": 3.657239789254061e-05,
      "loss": 0.0374,
      "step": 61300
    },
    {
      "epoch": 2.152950664469301,
      "grad_norm": 0.3542783856391907,
      "learning_rate": 3.655048171752681e-05,
      "loss": 0.0362,
      "step": 61400
    },
    {
      "epoch": 2.1564570987762544,
      "grad_norm": 0.05290590226650238,
      "learning_rate": 3.6528565542513e-05,
      "loss": 0.0332,
      "step": 61500
    },
    {
      "epoch": 2.1599635330832077,
      "grad_norm": 0.18027786910533905,
      "learning_rate": 3.650664936749919e-05,
      "loss": 0.0372,
      "step": 61600
    },
    {
      "epoch": 2.163469967390161,
      "grad_norm": 0.10137079656124115,
      "learning_rate": 3.648473319248538e-05,
      "loss": 0.0347,
      "step": 61700
    },
    {
      "epoch": 2.1669764016971143,
      "grad_norm": 0.04987782984972,
      "learning_rate": 3.646281701747158e-05,
      "loss": 0.0355,
      "step": 61800
    },
    {
      "epoch": 2.1704828360040676,
      "grad_norm": 0.1160702109336853,
      "learning_rate": 3.644090084245777e-05,
      "loss": 0.0384,
      "step": 61900
    },
    {
      "epoch": 2.173989270311021,
      "grad_norm": 0.12047877162694931,
      "learning_rate": 3.641898466744396e-05,
      "loss": 0.0372,
      "step": 62000
    },
    {
      "epoch": 2.177495704617974,
      "grad_norm": 0.1729368269443512,
      "learning_rate": 3.6397068492430156e-05,
      "loss": 0.0368,
      "step": 62100
    },
    {
      "epoch": 2.1810021389249274,
      "grad_norm": 0.09620567411184311,
      "learning_rate": 3.637515231741635e-05,
      "loss": 0.0338,
      "step": 62200
    },
    {
      "epoch": 2.1845085732318803,
      "grad_norm": 0.19800615310668945,
      "learning_rate": 3.6353236142402543e-05,
      "loss": 0.0403,
      "step": 62300
    },
    {
      "epoch": 2.1880150075388336,
      "grad_norm": 0.11395490914583206,
      "learning_rate": 3.6331319967388734e-05,
      "loss": 0.0381,
      "step": 62400
    },
    {
      "epoch": 2.191521441845787,
      "grad_norm": 0.13755623996257782,
      "learning_rate": 3.6309403792374924e-05,
      "loss": 0.0371,
      "step": 62500
    },
    {
      "epoch": 2.19502787615274,
      "grad_norm": 0.1382681429386139,
      "learning_rate": 3.628748761736112e-05,
      "loss": 0.0363,
      "step": 62600
    },
    {
      "epoch": 2.1985343104596935,
      "grad_norm": 0.16291330754756927,
      "learning_rate": 3.626557144234731e-05,
      "loss": 0.032,
      "step": 62700
    },
    {
      "epoch": 2.202040744766647,
      "grad_norm": 0.10231243073940277,
      "learning_rate": 3.62436552673335e-05,
      "loss": 0.0375,
      "step": 62800
    },
    {
      "epoch": 2.2055471790736,
      "grad_norm": 0.10834924876689911,
      "learning_rate": 3.622173909231969e-05,
      "loss": 0.0355,
      "step": 62900
    },
    {
      "epoch": 2.2090536133805534,
      "grad_norm": 0.17542769014835358,
      "learning_rate": 3.619982291730589e-05,
      "loss": 0.0346,
      "step": 63000
    },
    {
      "epoch": 2.2125600476875067,
      "grad_norm": 0.135459765791893,
      "learning_rate": 3.6177906742292086e-05,
      "loss": 0.0341,
      "step": 63100
    },
    {
      "epoch": 2.21606648199446,
      "grad_norm": 0.3625603914260864,
      "learning_rate": 3.615599056727828e-05,
      "loss": 0.0382,
      "step": 63200
    },
    {
      "epoch": 2.2195729163014133,
      "grad_norm": 0.3112475872039795,
      "learning_rate": 3.613407439226447e-05,
      "loss": 0.0319,
      "step": 63300
    },
    {
      "epoch": 2.223079350608366,
      "grad_norm": 0.14281964302062988,
      "learning_rate": 3.6112158217250664e-05,
      "loss": 0.0322,
      "step": 63400
    },
    {
      "epoch": 2.2265857849153194,
      "grad_norm": 0.18255726993083954,
      "learning_rate": 3.6090242042236854e-05,
      "loss": 0.0373,
      "step": 63500
    },
    {
      "epoch": 2.2300922192222727,
      "grad_norm": 0.2627290189266205,
      "learning_rate": 3.6068325867223045e-05,
      "loss": 0.0342,
      "step": 63600
    },
    {
      "epoch": 2.233598653529226,
      "grad_norm": 0.25193145871162415,
      "learning_rate": 3.6046409692209235e-05,
      "loss": 0.0365,
      "step": 63700
    },
    {
      "epoch": 2.2371050878361793,
      "grad_norm": 0.22778134047985077,
      "learning_rate": 3.602449351719543e-05,
      "loss": 0.0375,
      "step": 63800
    },
    {
      "epoch": 2.2406115221431326,
      "grad_norm": 0.15527796745300293,
      "learning_rate": 3.600257734218163e-05,
      "loss": 0.0393,
      "step": 63900
    },
    {
      "epoch": 2.244117956450086,
      "grad_norm": 0.19948861002922058,
      "learning_rate": 3.598066116716782e-05,
      "loss": 0.036,
      "step": 64000
    },
    {
      "epoch": 2.2476243907570392,
      "grad_norm": 0.6227138638496399,
      "learning_rate": 3.595874499215401e-05,
      "loss": 0.0365,
      "step": 64100
    },
    {
      "epoch": 2.2511308250639925,
      "grad_norm": 0.306354284286499,
      "learning_rate": 3.593682881714021e-05,
      "loss": 0.0374,
      "step": 64200
    },
    {
      "epoch": 2.254637259370946,
      "grad_norm": 0.20353971421718597,
      "learning_rate": 3.59149126421264e-05,
      "loss": 0.0363,
      "step": 64300
    },
    {
      "epoch": 2.258143693677899,
      "grad_norm": 0.16252654790878296,
      "learning_rate": 3.589299646711259e-05,
      "loss": 0.0375,
      "step": 64400
    },
    {
      "epoch": 2.2616501279848524,
      "grad_norm": 0.6171749234199524,
      "learning_rate": 3.587108029209878e-05,
      "loss": 0.0381,
      "step": 64500
    },
    {
      "epoch": 2.2651565622918053,
      "grad_norm": 0.1796480268239975,
      "learning_rate": 3.5849164117084975e-05,
      "loss": 0.0376,
      "step": 64600
    },
    {
      "epoch": 2.2686629965987586,
      "grad_norm": 0.2823234498500824,
      "learning_rate": 3.5827247942071165e-05,
      "loss": 0.0347,
      "step": 64700
    },
    {
      "epoch": 2.272169430905712,
      "grad_norm": 0.1369429975748062,
      "learning_rate": 3.580533176705736e-05,
      "loss": 0.0384,
      "step": 64800
    },
    {
      "epoch": 2.275675865212665,
      "grad_norm": 0.13649605214595795,
      "learning_rate": 3.578341559204355e-05,
      "loss": 0.0393,
      "step": 64900
    },
    {
      "epoch": 2.2791822995196185,
      "grad_norm": 0.35905638337135315,
      "learning_rate": 3.576149941702975e-05,
      "loss": 0.0376,
      "step": 65000
    },
    {
      "epoch": 2.282688733826572,
      "grad_norm": 0.30107635259628296,
      "learning_rate": 3.573958324201594e-05,
      "loss": 0.0325,
      "step": 65100
    },
    {
      "epoch": 2.286195168133525,
      "grad_norm": 0.4394703805446625,
      "learning_rate": 3.571766706700213e-05,
      "loss": 0.0342,
      "step": 65200
    },
    {
      "epoch": 2.2897016024404784,
      "grad_norm": 0.09504421055316925,
      "learning_rate": 3.569575089198832e-05,
      "loss": 0.0382,
      "step": 65300
    },
    {
      "epoch": 2.2932080367474317,
      "grad_norm": 0.16942286491394043,
      "learning_rate": 3.567383471697452e-05,
      "loss": 0.0324,
      "step": 65400
    },
    {
      "epoch": 2.296714471054385,
      "grad_norm": 0.16814984381198883,
      "learning_rate": 3.565191854196071e-05,
      "loss": 0.0329,
      "step": 65500
    },
    {
      "epoch": 2.3002209053613383,
      "grad_norm": 0.31108558177948,
      "learning_rate": 3.56300023669469e-05,
      "loss": 0.0387,
      "step": 65600
    },
    {
      "epoch": 2.303727339668291,
      "grad_norm": 0.22576527297496796,
      "learning_rate": 3.5608086191933096e-05,
      "loss": 0.0339,
      "step": 65700
    },
    {
      "epoch": 2.3072337739752444,
      "grad_norm": 0.19632978737354279,
      "learning_rate": 3.558617001691929e-05,
      "loss": 0.0343,
      "step": 65800
    },
    {
      "epoch": 2.3107402082821977,
      "grad_norm": 0.19009004533290863,
      "learning_rate": 3.556425384190548e-05,
      "loss": 0.0355,
      "step": 65900
    },
    {
      "epoch": 2.314246642589151,
      "grad_norm": 0.2022814154624939,
      "learning_rate": 3.5542337666891674e-05,
      "loss": 0.0388,
      "step": 66000
    },
    {
      "epoch": 2.3177530768961043,
      "grad_norm": 0.5517968535423279,
      "learning_rate": 3.5520640653628006e-05,
      "loss": 0.0389,
      "step": 66100
    },
    {
      "epoch": 2.3212595112030576,
      "grad_norm": 0.15164302289485931,
      "learning_rate": 3.54987244786142e-05,
      "loss": 0.037,
      "step": 66200
    },
    {
      "epoch": 2.324765945510011,
      "grad_norm": 0.17371079325675964,
      "learning_rate": 3.547680830360039e-05,
      "loss": 0.0361,
      "step": 66300
    },
    {
      "epoch": 2.328272379816964,
      "grad_norm": 0.17986348271369934,
      "learning_rate": 3.5454892128586584e-05,
      "loss": 0.0333,
      "step": 66400
    },
    {
      "epoch": 2.3317788141239175,
      "grad_norm": 0.38325417041778564,
      "learning_rate": 3.543297595357278e-05,
      "loss": 0.0357,
      "step": 66500
    },
    {
      "epoch": 2.335285248430871,
      "grad_norm": 0.13076211512088776,
      "learning_rate": 3.541105977855897e-05,
      "loss": 0.0345,
      "step": 66600
    },
    {
      "epoch": 2.338791682737824,
      "grad_norm": 0.4099077880382538,
      "learning_rate": 3.538914360354516e-05,
      "loss": 0.0373,
      "step": 66700
    },
    {
      "epoch": 2.342298117044777,
      "grad_norm": 0.2065953016281128,
      "learning_rate": 3.536722742853136e-05,
      "loss": 0.0348,
      "step": 66800
    },
    {
      "epoch": 2.3458045513517303,
      "grad_norm": 0.4495672881603241,
      "learning_rate": 3.534531125351755e-05,
      "loss": 0.0351,
      "step": 66900
    },
    {
      "epoch": 2.3493109856586836,
      "grad_norm": 0.1290910691022873,
      "learning_rate": 3.532339507850374e-05,
      "loss": 0.0343,
      "step": 67000
    },
    {
      "epoch": 2.352817419965637,
      "grad_norm": 0.11679957062005997,
      "learning_rate": 3.530147890348993e-05,
      "loss": 0.0342,
      "step": 67100
    },
    {
      "epoch": 2.35632385427259,
      "grad_norm": 0.4263697862625122,
      "learning_rate": 3.527956272847613e-05,
      "loss": 0.0302,
      "step": 67200
    },
    {
      "epoch": 2.3598302885795435,
      "grad_norm": 0.1485746204853058,
      "learning_rate": 3.525764655346232e-05,
      "loss": 0.0376,
      "step": 67300
    },
    {
      "epoch": 2.3633367228864968,
      "grad_norm": 0.17954698204994202,
      "learning_rate": 3.5235730378448514e-05,
      "loss": 0.0334,
      "step": 67400
    },
    {
      "epoch": 2.36684315719345,
      "grad_norm": 0.25348252058029175,
      "learning_rate": 3.5213814203434705e-05,
      "loss": 0.0365,
      "step": 67500
    },
    {
      "epoch": 2.3703495915004034,
      "grad_norm": 0.30485275387763977,
      "learning_rate": 3.51918980284209e-05,
      "loss": 0.0338,
      "step": 67600
    },
    {
      "epoch": 2.3738560258073567,
      "grad_norm": 0.1922496259212494,
      "learning_rate": 3.516998185340709e-05,
      "loss": 0.0367,
      "step": 67700
    },
    {
      "epoch": 2.37736246011431,
      "grad_norm": 0.4570574164390564,
      "learning_rate": 3.514806567839328e-05,
      "loss": 0.0331,
      "step": 67800
    },
    {
      "epoch": 2.380868894421263,
      "grad_norm": 0.10296396911144257,
      "learning_rate": 3.512614950337947e-05,
      "loss": 0.0361,
      "step": 67900
    },
    {
      "epoch": 2.384375328728216,
      "grad_norm": 0.2562604546546936,
      "learning_rate": 3.510423332836567e-05,
      "loss": 0.0326,
      "step": 68000
    },
    {
      "epoch": 2.3878817630351694,
      "grad_norm": 0.3840527832508087,
      "learning_rate": 3.508231715335186e-05,
      "loss": 0.0351,
      "step": 68100
    },
    {
      "epoch": 2.3913881973421227,
      "grad_norm": 0.22260278463363647,
      "learning_rate": 3.506040097833805e-05,
      "loss": 0.0351,
      "step": 68200
    },
    {
      "epoch": 2.394894631649076,
      "grad_norm": 0.33371880650520325,
      "learning_rate": 3.503848480332425e-05,
      "loss": 0.0356,
      "step": 68300
    },
    {
      "epoch": 2.3984010659560293,
      "grad_norm": 0.14487716555595398,
      "learning_rate": 3.5016568628310445e-05,
      "loss": 0.0389,
      "step": 68400
    },
    {
      "epoch": 2.4019075002629826,
      "grad_norm": 0.1233796700835228,
      "learning_rate": 3.4994652453296635e-05,
      "loss": 0.0382,
      "step": 68500
    },
    {
      "epoch": 2.405413934569936,
      "grad_norm": 0.26662006974220276,
      "learning_rate": 3.4972736278282825e-05,
      "loss": 0.0341,
      "step": 68600
    },
    {
      "epoch": 2.408920368876889,
      "grad_norm": 0.09135917574167252,
      "learning_rate": 3.4950820103269016e-05,
      "loss": 0.0341,
      "step": 68700
    },
    {
      "epoch": 2.4124268031838425,
      "grad_norm": 0.1156720221042633,
      "learning_rate": 3.492890392825521e-05,
      "loss": 0.0308,
      "step": 68800
    },
    {
      "epoch": 2.415933237490796,
      "grad_norm": 0.2769717872142792,
      "learning_rate": 3.49069877532414e-05,
      "loss": 0.0338,
      "step": 68900
    },
    {
      "epoch": 2.4194396717977487,
      "grad_norm": 0.44543275237083435,
      "learning_rate": 3.4885071578227593e-05,
      "loss": 0.0353,
      "step": 69000
    },
    {
      "epoch": 2.422946106104702,
      "grad_norm": 0.2826821804046631,
      "learning_rate": 3.486315540321379e-05,
      "loss": 0.0347,
      "step": 69100
    },
    {
      "epoch": 2.4264525404116553,
      "grad_norm": 0.19007901847362518,
      "learning_rate": 3.484123922819999e-05,
      "loss": 0.0339,
      "step": 69200
    },
    {
      "epoch": 2.4299589747186086,
      "grad_norm": 0.252238005399704,
      "learning_rate": 3.481932305318618e-05,
      "loss": 0.0332,
      "step": 69300
    },
    {
      "epoch": 2.433465409025562,
      "grad_norm": 0.2286304533481598,
      "learning_rate": 3.479740687817237e-05,
      "loss": 0.0355,
      "step": 69400
    },
    {
      "epoch": 2.436971843332515,
      "grad_norm": 0.15445612370967865,
      "learning_rate": 3.477549070315856e-05,
      "loss": 0.0349,
      "step": 69500
    },
    {
      "epoch": 2.4404782776394685,
      "grad_norm": 0.1357656866312027,
      "learning_rate": 3.4753574528144756e-05,
      "loss": 0.0328,
      "step": 69600
    },
    {
      "epoch": 2.4439847119464218,
      "grad_norm": 0.1889413446187973,
      "learning_rate": 3.4731658353130946e-05,
      "loss": 0.0362,
      "step": 69700
    },
    {
      "epoch": 2.447491146253375,
      "grad_norm": 0.07354612648487091,
      "learning_rate": 3.4709742178117136e-05,
      "loss": 0.0357,
      "step": 69800
    },
    {
      "epoch": 2.4509975805603283,
      "grad_norm": 0.1338380128145218,
      "learning_rate": 3.468782600310333e-05,
      "loss": 0.0377,
      "step": 69900
    },
    {
      "epoch": 2.4545040148672816,
      "grad_norm": 0.21900029480457306,
      "learning_rate": 3.4665909828089524e-05,
      "loss": 0.0363,
      "step": 70000
    },
    {
      "epoch": 2.4580104491742345,
      "grad_norm": 0.24414855241775513,
      "learning_rate": 3.464421281482586e-05,
      "loss": 0.0343,
      "step": 70100
    },
    {
      "epoch": 2.461516883481188,
      "grad_norm": 0.11164283007383347,
      "learning_rate": 3.462229663981205e-05,
      "loss": 0.0358,
      "step": 70200
    },
    {
      "epoch": 2.465023317788141,
      "grad_norm": 0.36226242780685425,
      "learning_rate": 3.460059962654838e-05,
      "loss": 0.0375,
      "step": 70300
    },
    {
      "epoch": 2.4685297520950944,
      "grad_norm": 0.12846775352954865,
      "learning_rate": 3.457868345153457e-05,
      "loss": 0.0329,
      "step": 70400
    },
    {
      "epoch": 2.4720361864020477,
      "grad_norm": 0.14116713404655457,
      "learning_rate": 3.455676727652076e-05,
      "loss": 0.0338,
      "step": 70500
    },
    {
      "epoch": 2.475542620709001,
      "grad_norm": 0.15729501843452454,
      "learning_rate": 3.453485110150696e-05,
      "loss": 0.0359,
      "step": 70600
    },
    {
      "epoch": 2.4790490550159543,
      "grad_norm": 0.11132921278476715,
      "learning_rate": 3.451293492649315e-05,
      "loss": 0.0316,
      "step": 70700
    },
    {
      "epoch": 2.4825554893229076,
      "grad_norm": 0.15667781233787537,
      "learning_rate": 3.4491018751479345e-05,
      "loss": 0.035,
      "step": 70800
    },
    {
      "epoch": 2.486061923629861,
      "grad_norm": 0.09802110493183136,
      "learning_rate": 3.4469102576465535e-05,
      "loss": 0.0311,
      "step": 70900
    },
    {
      "epoch": 2.489568357936814,
      "grad_norm": 0.1274682730436325,
      "learning_rate": 3.444718640145173e-05,
      "loss": 0.0355,
      "step": 71000
    },
    {
      "epoch": 2.4930747922437675,
      "grad_norm": 0.28833672404289246,
      "learning_rate": 3.442527022643792e-05,
      "loss": 0.0356,
      "step": 71100
    },
    {
      "epoch": 2.4965812265507203,
      "grad_norm": 0.32478609681129456,
      "learning_rate": 3.440335405142411e-05,
      "loss": 0.0362,
      "step": 71200
    },
    {
      "epoch": 2.500087660857674,
      "grad_norm": 0.14154525101184845,
      "learning_rate": 3.4381657038160446e-05,
      "loss": 0.0334,
      "step": 71300
    },
    {
      "epoch": 2.503594095164627,
      "grad_norm": 0.3541743755340576,
      "learning_rate": 3.4359740863146636e-05,
      "loss": 0.0361,
      "step": 71400
    },
    {
      "epoch": 2.5071005294715802,
      "grad_norm": 0.2076278179883957,
      "learning_rate": 3.433782468813283e-05,
      "loss": 0.0344,
      "step": 71500
    },
    {
      "epoch": 2.5106069637785335,
      "grad_norm": 0.13352005183696747,
      "learning_rate": 3.4315908513119024e-05,
      "loss": 0.0351,
      "step": 71600
    },
    {
      "epoch": 2.514113398085487,
      "grad_norm": 0.6325993537902832,
      "learning_rate": 3.429399233810522e-05,
      "loss": 0.0347,
      "step": 71700
    },
    {
      "epoch": 2.51761983239244,
      "grad_norm": 0.2933913469314575,
      "learning_rate": 3.427207616309141e-05,
      "loss": 0.0326,
      "step": 71800
    },
    {
      "epoch": 2.5211262666993934,
      "grad_norm": 0.3937462568283081,
      "learning_rate": 3.42501599880776e-05,
      "loss": 0.0363,
      "step": 71900
    },
    {
      "epoch": 2.5246327010063467,
      "grad_norm": 0.07333960384130478,
      "learning_rate": 3.422824381306379e-05,
      "loss": 0.0388,
      "step": 72000
    },
    {
      "epoch": 2.5281391353133,
      "grad_norm": 0.35619714856147766,
      "learning_rate": 3.420632763804999e-05,
      "loss": 0.0331,
      "step": 72100
    },
    {
      "epoch": 2.5316455696202533,
      "grad_norm": 0.2924458682537079,
      "learning_rate": 3.418441146303618e-05,
      "loss": 0.0345,
      "step": 72200
    },
    {
      "epoch": 2.535152003927206,
      "grad_norm": 0.15126629173755646,
      "learning_rate": 3.416249528802237e-05,
      "loss": 0.0344,
      "step": 72300
    },
    {
      "epoch": 2.53865843823416,
      "grad_norm": 0.10092959553003311,
      "learning_rate": 3.4140579113008567e-05,
      "loss": 0.0344,
      "step": 72400
    },
    {
      "epoch": 2.542164872541113,
      "grad_norm": 0.1376333087682724,
      "learning_rate": 3.4118662937994764e-05,
      "loss": 0.0354,
      "step": 72500
    },
    {
      "epoch": 2.545671306848066,
      "grad_norm": 0.14797796308994293,
      "learning_rate": 3.4096746762980954e-05,
      "loss": 0.0352,
      "step": 72600
    },
    {
      "epoch": 2.5491777411550194,
      "grad_norm": 0.13859394192695618,
      "learning_rate": 3.4074830587967144e-05,
      "loss": 0.0378,
      "step": 72700
    },
    {
      "epoch": 2.5526841754619727,
      "grad_norm": 0.05692543089389801,
      "learning_rate": 3.4052914412953335e-05,
      "loss": 0.03,
      "step": 72800
    },
    {
      "epoch": 2.556190609768926,
      "grad_norm": 0.248186856508255,
      "learning_rate": 3.403099823793953e-05,
      "loss": 0.0325,
      "step": 72900
    },
    {
      "epoch": 2.5596970440758793,
      "grad_norm": 0.15708814561367035,
      "learning_rate": 3.400908206292572e-05,
      "loss": 0.0364,
      "step": 73000
    },
    {
      "epoch": 2.5632034783828326,
      "grad_norm": 0.08501755446195602,
      "learning_rate": 3.398716588791191e-05,
      "loss": 0.031,
      "step": 73100
    },
    {
      "epoch": 2.566709912689786,
      "grad_norm": 0.3308970332145691,
      "learning_rate": 3.396524971289811e-05,
      "loss": 0.0358,
      "step": 73200
    },
    {
      "epoch": 2.570216346996739,
      "grad_norm": 0.3089696168899536,
      "learning_rate": 3.39433335378843e-05,
      "loss": 0.0331,
      "step": 73300
    },
    {
      "epoch": 2.573722781303692,
      "grad_norm": 0.2471039593219757,
      "learning_rate": 3.39214173628705e-05,
      "loss": 0.0352,
      "step": 73400
    },
    {
      "epoch": 2.5772292156106458,
      "grad_norm": 0.12736113369464874,
      "learning_rate": 3.389950118785669e-05,
      "loss": 0.0361,
      "step": 73500
    },
    {
      "epoch": 2.5807356499175986,
      "grad_norm": 0.2225126326084137,
      "learning_rate": 3.3877585012842884e-05,
      "loss": 0.0355,
      "step": 73600
    },
    {
      "epoch": 2.584242084224552,
      "grad_norm": 0.3412981629371643,
      "learning_rate": 3.3855668837829075e-05,
      "loss": 0.0361,
      "step": 73700
    },
    {
      "epoch": 2.5877485185315052,
      "grad_norm": 0.13458716869354248,
      "learning_rate": 3.38339718245654e-05,
      "loss": 0.0357,
      "step": 73800
    },
    {
      "epoch": 2.5912549528384585,
      "grad_norm": 0.07932968437671661,
      "learning_rate": 3.38120556495516e-05,
      "loss": 0.0316,
      "step": 73900
    },
    {
      "epoch": 2.594761387145412,
      "grad_norm": 0.3274964988231659,
      "learning_rate": 3.379013947453779e-05,
      "loss": 0.0367,
      "step": 74000
    },
    {
      "epoch": 2.598267821452365,
      "grad_norm": 0.19042690098285675,
      "learning_rate": 3.3768223299523985e-05,
      "loss": 0.0343,
      "step": 74100
    },
    {
      "epoch": 2.6017742557593184,
      "grad_norm": 0.23378778994083405,
      "learning_rate": 3.3746307124510176e-05,
      "loss": 0.0326,
      "step": 74200
    },
    {
      "epoch": 2.6052806900662717,
      "grad_norm": 0.2607412040233612,
      "learning_rate": 3.372439094949637e-05,
      "loss": 0.0372,
      "step": 74300
    },
    {
      "epoch": 2.608787124373225,
      "grad_norm": 0.09576252847909927,
      "learning_rate": 3.370247477448256e-05,
      "loss": 0.0328,
      "step": 74400
    },
    {
      "epoch": 2.612293558680178,
      "grad_norm": 0.10791046917438507,
      "learning_rate": 3.368055859946875e-05,
      "loss": 0.0316,
      "step": 74500
    },
    {
      "epoch": 2.6157999929871316,
      "grad_norm": 0.04318847507238388,
      "learning_rate": 3.3658642424454944e-05,
      "loss": 0.0351,
      "step": 74600
    },
    {
      "epoch": 2.6193064272940845,
      "grad_norm": 0.12380599230527878,
      "learning_rate": 3.363672624944114e-05,
      "loss": 0.0351,
      "step": 74700
    },
    {
      "epoch": 2.6228128616010378,
      "grad_norm": 0.3862852156162262,
      "learning_rate": 3.361481007442733e-05,
      "loss": 0.0357,
      "step": 74800
    },
    {
      "epoch": 2.626319295907991,
      "grad_norm": 0.3763459622859955,
      "learning_rate": 3.359289389941352e-05,
      "loss": 0.035,
      "step": 74900
    },
    {
      "epoch": 2.6298257302149444,
      "grad_norm": 0.2141638696193695,
      "learning_rate": 3.357097772439972e-05,
      "loss": 0.0343,
      "step": 75000
    },
    {
      "epoch": 2.6333321645218977,
      "grad_norm": 0.19512830674648285,
      "learning_rate": 3.3549061549385916e-05,
      "loss": 0.0316,
      "step": 75100
    },
    {
      "epoch": 2.636838598828851,
      "grad_norm": 0.07354997098445892,
      "learning_rate": 3.3527145374372106e-05,
      "loss": 0.0319,
      "step": 75200
    },
    {
      "epoch": 2.6403450331358043,
      "grad_norm": 0.156423419713974,
      "learning_rate": 3.3505229199358296e-05,
      "loss": 0.0342,
      "step": 75300
    },
    {
      "epoch": 2.6438514674427576,
      "grad_norm": 0.19152086973190308,
      "learning_rate": 3.3483313024344487e-05,
      "loss": 0.0353,
      "step": 75400
    },
    {
      "epoch": 2.647357901749711,
      "grad_norm": 0.09940582513809204,
      "learning_rate": 3.3461396849330684e-05,
      "loss": 0.0328,
      "step": 75500
    },
    {
      "epoch": 2.6508643360566637,
      "grad_norm": 0.14599357545375824,
      "learning_rate": 3.3439480674316874e-05,
      "loss": 0.0342,
      "step": 75600
    },
    {
      "epoch": 2.6543707703636175,
      "grad_norm": 0.2758769690990448,
      "learning_rate": 3.3417564499303064e-05,
      "loss": 0.0335,
      "step": 75700
    },
    {
      "epoch": 2.6578772046705703,
      "grad_norm": 0.1243019700050354,
      "learning_rate": 3.339564832428926e-05,
      "loss": 0.0342,
      "step": 75800
    },
    {
      "epoch": 2.6613836389775236,
      "grad_norm": 0.15547595918178558,
      "learning_rate": 3.337373214927546e-05,
      "loss": 0.0327,
      "step": 75900
    },
    {
      "epoch": 2.664890073284477,
      "grad_norm": 0.30590999126434326,
      "learning_rate": 3.335181597426165e-05,
      "loss": 0.0359,
      "step": 76000
    },
    {
      "epoch": 2.66839650759143,
      "grad_norm": 0.32244953513145447,
      "learning_rate": 3.332989979924784e-05,
      "loss": 0.0384,
      "step": 76100
    },
    {
      "epoch": 2.6719029418983835,
      "grad_norm": 0.24485193192958832,
      "learning_rate": 3.330798362423403e-05,
      "loss": 0.0357,
      "step": 76200
    },
    {
      "epoch": 2.675409376205337,
      "grad_norm": 0.12248620390892029,
      "learning_rate": 3.3286067449220227e-05,
      "loss": 0.0338,
      "step": 76300
    },
    {
      "epoch": 2.67891581051229,
      "grad_norm": 0.2974448800086975,
      "learning_rate": 3.326415127420642e-05,
      "loss": 0.0339,
      "step": 76400
    },
    {
      "epoch": 2.6824222448192434,
      "grad_norm": 0.27066779136657715,
      "learning_rate": 3.324245426094274e-05,
      "loss": 0.0316,
      "step": 76500
    },
    {
      "epoch": 2.6859286791261967,
      "grad_norm": 0.08766007423400879,
      "learning_rate": 3.322053808592894e-05,
      "loss": 0.0329,
      "step": 76600
    },
    {
      "epoch": 2.6894351134331496,
      "grad_norm": 0.3255217671394348,
      "learning_rate": 3.319862191091514e-05,
      "loss": 0.0356,
      "step": 76700
    },
    {
      "epoch": 2.6929415477401033,
      "grad_norm": 0.22368386387825012,
      "learning_rate": 3.317670573590133e-05,
      "loss": 0.0341,
      "step": 76800
    },
    {
      "epoch": 2.696447982047056,
      "grad_norm": 0.13548995554447174,
      "learning_rate": 3.315478956088752e-05,
      "loss": 0.0345,
      "step": 76900
    },
    {
      "epoch": 2.6999544163540095,
      "grad_norm": 0.044535424560308456,
      "learning_rate": 3.3132873385873715e-05,
      "loss": 0.0348,
      "step": 77000
    },
    {
      "epoch": 2.7034608506609628,
      "grad_norm": 0.10505694895982742,
      "learning_rate": 3.3110957210859905e-05,
      "loss": 0.0356,
      "step": 77100
    },
    {
      "epoch": 2.706967284967916,
      "grad_norm": 0.11441611498594284,
      "learning_rate": 3.3089041035846095e-05,
      "loss": 0.0353,
      "step": 77200
    },
    {
      "epoch": 2.7104737192748694,
      "grad_norm": 0.22433757781982422,
      "learning_rate": 3.3067124860832286e-05,
      "loss": 0.037,
      "step": 77300
    },
    {
      "epoch": 2.7139801535818227,
      "grad_norm": 0.11560343950986862,
      "learning_rate": 3.304520868581848e-05,
      "loss": 0.0396,
      "step": 77400
    },
    {
      "epoch": 2.717486587888776,
      "grad_norm": 0.2487047165632248,
      "learning_rate": 3.302329251080467e-05,
      "loss": 0.0355,
      "step": 77500
    },
    {
      "epoch": 2.7209930221957292,
      "grad_norm": 0.18602286279201508,
      "learning_rate": 3.300137633579087e-05,
      "loss": 0.0339,
      "step": 77600
    },
    {
      "epoch": 2.7244994565026825,
      "grad_norm": 0.4968445301055908,
      "learning_rate": 3.297946016077706e-05,
      "loss": 0.0339,
      "step": 77700
    },
    {
      "epoch": 2.728005890809636,
      "grad_norm": 0.17354236543178558,
      "learning_rate": 3.295754398576326e-05,
      "loss": 0.0382,
      "step": 77800
    },
    {
      "epoch": 2.731512325116589,
      "grad_norm": 0.13672222197055817,
      "learning_rate": 3.293562781074945e-05,
      "loss": 0.0326,
      "step": 77900
    },
    {
      "epoch": 2.735018759423542,
      "grad_norm": 0.08172265440225601,
      "learning_rate": 3.291371163573564e-05,
      "loss": 0.0362,
      "step": 78000
    },
    {
      "epoch": 2.7385251937304953,
      "grad_norm": 0.2181069254875183,
      "learning_rate": 3.289179546072183e-05,
      "loss": 0.0338,
      "step": 78100
    },
    {
      "epoch": 2.7420316280374486,
      "grad_norm": 0.17887724936008453,
      "learning_rate": 3.2869879285708026e-05,
      "loss": 0.0333,
      "step": 78200
    },
    {
      "epoch": 2.745538062344402,
      "grad_norm": 0.25326526165008545,
      "learning_rate": 3.2847963110694216e-05,
      "loss": 0.0368,
      "step": 78300
    },
    {
      "epoch": 2.749044496651355,
      "grad_norm": 0.2543122470378876,
      "learning_rate": 3.282604693568041e-05,
      "loss": 0.0347,
      "step": 78400
    },
    {
      "epoch": 2.7525509309583085,
      "grad_norm": 0.3275042474269867,
      "learning_rate": 3.2804130760666604e-05,
      "loss": 0.0344,
      "step": 78500
    },
    {
      "epoch": 2.756057365265262,
      "grad_norm": 0.12196338176727295,
      "learning_rate": 3.2782433747402936e-05,
      "loss": 0.0338,
      "step": 78600
    },
    {
      "epoch": 2.759563799572215,
      "grad_norm": 0.17772983014583588,
      "learning_rate": 3.276051757238913e-05,
      "loss": 0.0327,
      "step": 78700
    },
    {
      "epoch": 2.7630702338791684,
      "grad_norm": 0.40380731225013733,
      "learning_rate": 3.273860139737532e-05,
      "loss": 0.0366,
      "step": 78800
    },
    {
      "epoch": 2.7665766681861217,
      "grad_norm": 0.1740141063928604,
      "learning_rate": 3.2716685222361514e-05,
      "loss": 0.0331,
      "step": 78900
    },
    {
      "epoch": 2.770083102493075,
      "grad_norm": 0.17457273602485657,
      "learning_rate": 3.2694769047347704e-05,
      "loss": 0.0335,
      "step": 79000
    },
    {
      "epoch": 2.773589536800028,
      "grad_norm": 0.19134829938411713,
      "learning_rate": 3.2672852872333895e-05,
      "loss": 0.0333,
      "step": 79100
    },
    {
      "epoch": 2.7770959711069816,
      "grad_norm": 0.168613001704216,
      "learning_rate": 3.265093669732009e-05,
      "loss": 0.0341,
      "step": 79200
    },
    {
      "epoch": 2.7806024054139344,
      "grad_norm": 0.1605447381734848,
      "learning_rate": 3.262902052230629e-05,
      "loss": 0.0337,
      "step": 79300
    },
    {
      "epoch": 2.7841088397208877,
      "grad_norm": 0.18469774723052979,
      "learning_rate": 3.260710434729248e-05,
      "loss": 0.0313,
      "step": 79400
    },
    {
      "epoch": 2.787615274027841,
      "grad_norm": 0.3358190655708313,
      "learning_rate": 3.258518817227867e-05,
      "loss": 0.036,
      "step": 79500
    },
    {
      "epoch": 2.7911217083347943,
      "grad_norm": 0.14022386074066162,
      "learning_rate": 3.256327199726486e-05,
      "loss": 0.0331,
      "step": 79600
    },
    {
      "epoch": 2.7946281426417476,
      "grad_norm": 0.29382210969924927,
      "learning_rate": 3.254135582225106e-05,
      "loss": 0.0363,
      "step": 79700
    },
    {
      "epoch": 2.798134576948701,
      "grad_norm": 0.5711276531219482,
      "learning_rate": 3.251943964723725e-05,
      "loss": 0.0345,
      "step": 79800
    },
    {
      "epoch": 2.8016410112556542,
      "grad_norm": 0.1330385059118271,
      "learning_rate": 3.249752347222344e-05,
      "loss": 0.0366,
      "step": 79900
    },
    {
      "epoch": 2.8051474455626075,
      "grad_norm": 0.1771305650472641,
      "learning_rate": 3.2475607297209635e-05,
      "loss": 0.0375,
      "step": 80000
    },
    {
      "epoch": 2.808653879869561,
      "grad_norm": 0.2146216332912445,
      "learning_rate": 3.2453691122195825e-05,
      "loss": 0.036,
      "step": 80100
    },
    {
      "epoch": 2.8121603141765137,
      "grad_norm": 0.18242637813091278,
      "learning_rate": 3.243177494718202e-05,
      "loss": 0.035,
      "step": 80200
    },
    {
      "epoch": 2.8156667484834674,
      "grad_norm": 0.10568858683109283,
      "learning_rate": 3.240985877216821e-05,
      "loss": 0.0342,
      "step": 80300
    },
    {
      "epoch": 2.8191731827904203,
      "grad_norm": 0.09580858796834946,
      "learning_rate": 3.238794259715441e-05,
      "loss": 0.0376,
      "step": 80400
    },
    {
      "epoch": 2.8226796170973736,
      "grad_norm": 0.37680375576019287,
      "learning_rate": 3.23660264221406e-05,
      "loss": 0.0318,
      "step": 80500
    },
    {
      "epoch": 2.826186051404327,
      "grad_norm": 0.12978054583072662,
      "learning_rate": 3.234411024712679e-05,
      "loss": 0.0382,
      "step": 80600
    },
    {
      "epoch": 2.82969248571128,
      "grad_norm": 0.17096897959709167,
      "learning_rate": 3.232219407211298e-05,
      "loss": 0.0358,
      "step": 80700
    },
    {
      "epoch": 2.8331989200182335,
      "grad_norm": 0.2905489504337311,
      "learning_rate": 3.230027789709918e-05,
      "loss": 0.0347,
      "step": 80800
    },
    {
      "epoch": 2.836705354325187,
      "grad_norm": 0.23519226908683777,
      "learning_rate": 3.227836172208537e-05,
      "loss": 0.0337,
      "step": 80900
    },
    {
      "epoch": 2.84021178863214,
      "grad_norm": 0.19526170194149017,
      "learning_rate": 3.2256445547071565e-05,
      "loss": 0.0335,
      "step": 81000
    },
    {
      "epoch": 2.8437182229390934,
      "grad_norm": 0.15259172022342682,
      "learning_rate": 3.2234529372057755e-05,
      "loss": 0.0357,
      "step": 81100
    },
    {
      "epoch": 2.8472246572460467,
      "grad_norm": 0.19504335522651672,
      "learning_rate": 3.221261319704395e-05,
      "loss": 0.0358,
      "step": 81200
    },
    {
      "epoch": 2.8507310915529995,
      "grad_norm": 0.21025274693965912,
      "learning_rate": 3.219069702203014e-05,
      "loss": 0.0336,
      "step": 81300
    },
    {
      "epoch": 2.8542375258599533,
      "grad_norm": 0.20504257082939148,
      "learning_rate": 3.216878084701633e-05,
      "loss": 0.0371,
      "step": 81400
    },
    {
      "epoch": 2.857743960166906,
      "grad_norm": 0.19315822422504425,
      "learning_rate": 3.2146864672002524e-05,
      "loss": 0.0333,
      "step": 81500
    },
    {
      "epoch": 2.8612503944738594,
      "grad_norm": 0.4723544418811798,
      "learning_rate": 3.212494849698872e-05,
      "loss": 0.0364,
      "step": 81600
    },
    {
      "epoch": 2.8647568287808127,
      "grad_norm": 0.1975494623184204,
      "learning_rate": 3.210303232197491e-05,
      "loss": 0.034,
      "step": 81700
    },
    {
      "epoch": 2.868263263087766,
      "grad_norm": 0.08907291293144226,
      "learning_rate": 3.20811161469611e-05,
      "loss": 0.0376,
      "step": 81800
    },
    {
      "epoch": 2.8717696973947193,
      "grad_norm": 0.23037320375442505,
      "learning_rate": 3.20591999719473e-05,
      "loss": 0.0364,
      "step": 81900
    },
    {
      "epoch": 2.8752761317016726,
      "grad_norm": 0.24009397625923157,
      "learning_rate": 3.2037283796933495e-05,
      "loss": 0.0366,
      "step": 82000
    },
    {
      "epoch": 2.878782566008626,
      "grad_norm": 0.08474280685186386,
      "learning_rate": 3.2015367621919686e-05,
      "loss": 0.036,
      "step": 82100
    },
    {
      "epoch": 2.882289000315579,
      "grad_norm": 0.5474190711975098,
      "learning_rate": 3.1993451446905876e-05,
      "loss": 0.0315,
      "step": 82200
    },
    {
      "epoch": 2.8857954346225325,
      "grad_norm": 0.24682268500328064,
      "learning_rate": 3.1971535271892066e-05,
      "loss": 0.034,
      "step": 82300
    },
    {
      "epoch": 2.8893018689294854,
      "grad_norm": 0.1896219402551651,
      "learning_rate": 3.1949619096878264e-05,
      "loss": 0.0352,
      "step": 82400
    },
    {
      "epoch": 2.892808303236439,
      "grad_norm": 0.23044276237487793,
      "learning_rate": 3.1927702921864454e-05,
      "loss": 0.0403,
      "step": 82500
    },
    {
      "epoch": 2.896314737543392,
      "grad_norm": 0.5233973264694214,
      "learning_rate": 3.1905786746850644e-05,
      "loss": 0.0359,
      "step": 82600
    },
    {
      "epoch": 2.8998211718503453,
      "grad_norm": 0.16952158510684967,
      "learning_rate": 3.188387057183684e-05,
      "loss": 0.0338,
      "step": 82700
    },
    {
      "epoch": 2.9033276061572986,
      "grad_norm": 0.27174562215805054,
      "learning_rate": 3.186195439682303e-05,
      "loss": 0.0312,
      "step": 82800
    },
    {
      "epoch": 2.906834040464252,
      "grad_norm": 0.17752431333065033,
      "learning_rate": 3.184003822180923e-05,
      "loss": 0.0328,
      "step": 82900
    },
    {
      "epoch": 2.910340474771205,
      "grad_norm": 0.33720287680625916,
      "learning_rate": 3.181812204679542e-05,
      "loss": 0.0313,
      "step": 83000
    },
    {
      "epoch": 2.9138469090781585,
      "grad_norm": 0.19030703604221344,
      "learning_rate": 3.179620587178161e-05,
      "loss": 0.036,
      "step": 83100
    },
    {
      "epoch": 2.9173533433851118,
      "grad_norm": 0.3725690543651581,
      "learning_rate": 3.177450885851794e-05,
      "loss": 0.0354,
      "step": 83200
    },
    {
      "epoch": 2.920859777692065,
      "grad_norm": 0.26889413595199585,
      "learning_rate": 3.175259268350413e-05,
      "loss": 0.0354,
      "step": 83300
    },
    {
      "epoch": 2.9243662119990184,
      "grad_norm": 0.3316810131072998,
      "learning_rate": 3.173067650849032e-05,
      "loss": 0.034,
      "step": 83400
    },
    {
      "epoch": 2.927872646305971,
      "grad_norm": 0.16600753366947174,
      "learning_rate": 3.170876033347652e-05,
      "loss": 0.0344,
      "step": 83500
    },
    {
      "epoch": 2.931379080612925,
      "grad_norm": 0.24229414761066437,
      "learning_rate": 3.168684415846272e-05,
      "loss": 0.0345,
      "step": 83600
    },
    {
      "epoch": 2.934885514919878,
      "grad_norm": 0.08226129412651062,
      "learning_rate": 3.166492798344891e-05,
      "loss": 0.0324,
      "step": 83700
    },
    {
      "epoch": 2.938391949226831,
      "grad_norm": 0.26208361983299255,
      "learning_rate": 3.16430118084351e-05,
      "loss": 0.0337,
      "step": 83800
    },
    {
      "epoch": 2.9418983835337844,
      "grad_norm": 0.12356790900230408,
      "learning_rate": 3.1621095633421295e-05,
      "loss": 0.0332,
      "step": 83900
    },
    {
      "epoch": 2.9454048178407377,
      "grad_norm": 0.2913462221622467,
      "learning_rate": 3.1599179458407485e-05,
      "loss": 0.0338,
      "step": 84000
    },
    {
      "epoch": 2.948911252147691,
      "grad_norm": 0.3389580249786377,
      "learning_rate": 3.1577263283393675e-05,
      "loss": 0.0348,
      "step": 84100
    },
    {
      "epoch": 2.9524176864546443,
      "grad_norm": 0.12009400129318237,
      "learning_rate": 3.1555347108379866e-05,
      "loss": 0.0319,
      "step": 84200
    },
    {
      "epoch": 2.9559241207615976,
      "grad_norm": 0.23558951914310455,
      "learning_rate": 3.153343093336606e-05,
      "loss": 0.0333,
      "step": 84300
    },
    {
      "epoch": 2.959430555068551,
      "grad_norm": 0.1315363347530365,
      "learning_rate": 3.151151475835225e-05,
      "loss": 0.0339,
      "step": 84400
    },
    {
      "epoch": 2.962936989375504,
      "grad_norm": 0.30917760729789734,
      "learning_rate": 3.148959858333845e-05,
      "loss": 0.0327,
      "step": 84500
    },
    {
      "epoch": 2.966443423682457,
      "grad_norm": 0.16573652625083923,
      "learning_rate": 3.146768240832464e-05,
      "loss": 0.035,
      "step": 84600
    },
    {
      "epoch": 2.969949857989411,
      "grad_norm": 0.22161664068698883,
      "learning_rate": 3.144576623331084e-05,
      "loss": 0.0356,
      "step": 84700
    },
    {
      "epoch": 2.9734562922963637,
      "grad_norm": 0.27239230275154114,
      "learning_rate": 3.142385005829703e-05,
      "loss": 0.0338,
      "step": 84800
    },
    {
      "epoch": 2.976962726603317,
      "grad_norm": 0.10373394191265106,
      "learning_rate": 3.140193388328322e-05,
      "loss": 0.0326,
      "step": 84900
    },
    {
      "epoch": 2.9804691609102703,
      "grad_norm": 0.17888091504573822,
      "learning_rate": 3.138001770826941e-05,
      "loss": 0.0352,
      "step": 85000
    },
    {
      "epoch": 2.9839755952172236,
      "grad_norm": 0.18847039341926575,
      "learning_rate": 3.1358101533255606e-05,
      "loss": 0.0339,
      "step": 85100
    },
    {
      "epoch": 2.987482029524177,
      "grad_norm": 0.07144718617200851,
      "learning_rate": 3.1336185358241796e-05,
      "loss": 0.0321,
      "step": 85200
    },
    {
      "epoch": 2.99098846383113,
      "grad_norm": 0.4008832275867462,
      "learning_rate": 3.131426918322799e-05,
      "loss": 0.0304,
      "step": 85300
    },
    {
      "epoch": 2.9944948981380834,
      "grad_norm": 0.2570416331291199,
      "learning_rate": 3.1292572169964326e-05,
      "loss": 0.0345,
      "step": 85400
    },
    {
      "epoch": 2.9980013324450367,
      "grad_norm": 0.32493042945861816,
      "learning_rate": 3.1270655994950516e-05,
      "loss": 0.0371,
      "step": 85500
    },
    {
      "epoch": 3.0,
      "eval_accuracy_macro_0.5": 0.9858038425445557,
      "eval_accuracy_micro_0.5": 0.9858038425445557,
      "eval_accuracy_weighted_0.5": 0.9790595769882202,
      "eval_f1_macro_0.5": 0.8006687760353088,
      "eval_f1_macro_0.6": 0.7895150184631348,
      "eval_f1_macro_0.7": 0.7676201462745667,
      "eval_f1_macro_0.8": 0.6311495304107666,
      "eval_f1_micro_0.5": 0.8195343613624573,
      "eval_f1_micro_0.6": 0.8112749457359314,
      "eval_f1_micro_0.7": 0.7929038405418396,
      "eval_f1_micro_0.8": 0.755355715751648,
      "eval_f1_micro_0.9": 0.6712506413459778,
      "eval_f1_weighted_0.5": 0.81683349609375,
      "eval_f1_weighted_0.6": 0.8058115243911743,
      "eval_f1_weighted_0.7": 0.7840247750282288,
      "eval_f1_weighted_0.8": 0.6445769667625427,
      "eval_loss": 0.03247472271323204,
      "eval_runtime": 406.9532,
      "eval_samples_per_second": 140.082,
      "eval_steps_per_second": 17.511,
      "step": 85557
    },
    {
      "epoch": 3.00150776675199,
      "grad_norm": 0.25050634145736694,
      "learning_rate": 3.124873981993671e-05,
      "loss": 0.0395,
      "step": 85600
    },
    {
      "epoch": 3.0050142010589433,
      "grad_norm": 0.45621904730796814,
      "learning_rate": 3.12268236449229e-05,
      "loss": 0.0335,
      "step": 85700
    },
    {
      "epoch": 3.008520635365896,
      "grad_norm": 0.10481509566307068,
      "learning_rate": 3.1204907469909094e-05,
      "loss": 0.0338,
      "step": 85800
    },
    {
      "epoch": 3.0120270696728495,
      "grad_norm": 0.421927809715271,
      "learning_rate": 3.1182991294895284e-05,
      "loss": 0.0365,
      "step": 85900
    },
    {
      "epoch": 3.015533503979803,
      "grad_norm": 0.23699654638767242,
      "learning_rate": 3.1161075119881475e-05,
      "loss": 0.0375,
      "step": 86000
    },
    {
      "epoch": 3.019039938286756,
      "grad_norm": 0.24230585992336273,
      "learning_rate": 3.113915894486767e-05,
      "loss": 0.0347,
      "step": 86100
    },
    {
      "epoch": 3.0225463725937094,
      "grad_norm": 0.15496639907360077,
      "learning_rate": 3.111724276985387e-05,
      "loss": 0.0338,
      "step": 86200
    },
    {
      "epoch": 3.0260528069006627,
      "grad_norm": 0.17547070980072021,
      "learning_rate": 3.109532659484006e-05,
      "loss": 0.0303,
      "step": 86300
    },
    {
      "epoch": 3.029559241207616,
      "grad_norm": 0.27648085355758667,
      "learning_rate": 3.107341041982625e-05,
      "loss": 0.0317,
      "step": 86400
    },
    {
      "epoch": 3.0330656755145693,
      "grad_norm": 0.2981176972389221,
      "learning_rate": 3.105171340656258e-05,
      "loss": 0.0346,
      "step": 86500
    },
    {
      "epoch": 3.0365721098215226,
      "grad_norm": 0.18850520253181458,
      "learning_rate": 3.102979723154877e-05,
      "loss": 0.0341,
      "step": 86600
    },
    {
      "epoch": 3.040078544128476,
      "grad_norm": 0.10206630080938339,
      "learning_rate": 3.100788105653496e-05,
      "loss": 0.0373,
      "step": 86700
    },
    {
      "epoch": 3.043584978435429,
      "grad_norm": 0.31889617443084717,
      "learning_rate": 3.0985964881521153e-05,
      "loss": 0.0315,
      "step": 86800
    },
    {
      "epoch": 3.0470914127423825,
      "grad_norm": 0.31365904211997986,
      "learning_rate": 3.096404870650735e-05,
      "loss": 0.0324,
      "step": 86900
    },
    {
      "epoch": 3.0505978470493353,
      "grad_norm": 0.07594818621873856,
      "learning_rate": 3.094213253149355e-05,
      "loss": 0.0344,
      "step": 87000
    },
    {
      "epoch": 3.0541042813562886,
      "grad_norm": 0.17351943254470825,
      "learning_rate": 3.092021635647974e-05,
      "loss": 0.0335,
      "step": 87100
    },
    {
      "epoch": 3.057610715663242,
      "grad_norm": 0.14813773334026337,
      "learning_rate": 3.089830018146593e-05,
      "loss": 0.0386,
      "step": 87200
    },
    {
      "epoch": 3.0611171499701952,
      "grad_norm": 0.3952517509460449,
      "learning_rate": 3.0876384006452125e-05,
      "loss": 0.0325,
      "step": 87300
    },
    {
      "epoch": 3.0646235842771485,
      "grad_norm": 0.15495671331882477,
      "learning_rate": 3.0854467831438316e-05,
      "loss": 0.0304,
      "step": 87400
    },
    {
      "epoch": 3.068130018584102,
      "grad_norm": 0.29214587807655334,
      "learning_rate": 3.0832551656424506e-05,
      "loss": 0.0338,
      "step": 87500
    },
    {
      "epoch": 3.071636452891055,
      "grad_norm": 0.13251668214797974,
      "learning_rate": 3.08106354814107e-05,
      "loss": 0.0379,
      "step": 87600
    },
    {
      "epoch": 3.0751428871980084,
      "grad_norm": 0.4130832850933075,
      "learning_rate": 3.0788719306396893e-05,
      "loss": 0.0301,
      "step": 87700
    },
    {
      "epoch": 3.0786493215049617,
      "grad_norm": 0.09738844633102417,
      "learning_rate": 3.076680313138309e-05,
      "loss": 0.0339,
      "step": 87800
    },
    {
      "epoch": 3.082155755811915,
      "grad_norm": 0.2899855375289917,
      "learning_rate": 3.074488695636928e-05,
      "loss": 0.0311,
      "step": 87900
    },
    {
      "epoch": 3.0856621901188683,
      "grad_norm": 0.3510735034942627,
      "learning_rate": 3.072297078135548e-05,
      "loss": 0.0344,
      "step": 88000
    },
    {
      "epoch": 3.089168624425821,
      "grad_norm": 0.4479234516620636,
      "learning_rate": 3.070105460634167e-05,
      "loss": 0.0334,
      "step": 88100
    },
    {
      "epoch": 3.0926750587327745,
      "grad_norm": 0.11801399290561676,
      "learning_rate": 3.067913843132786e-05,
      "loss": 0.0335,
      "step": 88200
    },
    {
      "epoch": 3.096181493039728,
      "grad_norm": 0.5480536222457886,
      "learning_rate": 3.065722225631405e-05,
      "loss": 0.0326,
      "step": 88300
    },
    {
      "epoch": 3.099687927346681,
      "grad_norm": 0.49145013093948364,
      "learning_rate": 3.0635306081300246e-05,
      "loss": 0.0354,
      "step": 88400
    },
    {
      "epoch": 3.1031943616536344,
      "grad_norm": 0.1083151176571846,
      "learning_rate": 3.0613389906286436e-05,
      "loss": 0.0354,
      "step": 88500
    },
    {
      "epoch": 3.1067007959605877,
      "grad_norm": 0.23310333490371704,
      "learning_rate": 3.059147373127263e-05,
      "loss": 0.0328,
      "step": 88600
    },
    {
      "epoch": 3.110207230267541,
      "grad_norm": 0.180449441075325,
      "learning_rate": 3.0569557556258824e-05,
      "loss": 0.0317,
      "step": 88700
    },
    {
      "epoch": 3.1137136645744943,
      "grad_norm": 0.3066881000995636,
      "learning_rate": 3.054764138124502e-05,
      "loss": 0.0325,
      "step": 88800
    },
    {
      "epoch": 3.1172200988814476,
      "grad_norm": 0.1770646870136261,
      "learning_rate": 3.052572520623121e-05,
      "loss": 0.0319,
      "step": 88900
    },
    {
      "epoch": 3.120726533188401,
      "grad_norm": 0.3414555490016937,
      "learning_rate": 3.05038090312174e-05,
      "loss": 0.0328,
      "step": 89000
    },
    {
      "epoch": 3.124232967495354,
      "grad_norm": 0.34697121381759644,
      "learning_rate": 3.0481892856203592e-05,
      "loss": 0.0313,
      "step": 89100
    },
    {
      "epoch": 3.127739401802307,
      "grad_norm": 0.1710326373577118,
      "learning_rate": 3.045997668118979e-05,
      "loss": 0.0341,
      "step": 89200
    },
    {
      "epoch": 3.1312458361092603,
      "grad_norm": 0.25105538964271545,
      "learning_rate": 3.043806050617598e-05,
      "loss": 0.0351,
      "step": 89300
    },
    {
      "epoch": 3.1347522704162136,
      "grad_norm": 0.43472278118133545,
      "learning_rate": 3.0416144331162173e-05,
      "loss": 0.031,
      "step": 89400
    },
    {
      "epoch": 3.138258704723167,
      "grad_norm": 0.2392071634531021,
      "learning_rate": 3.0394228156148363e-05,
      "loss": 0.0297,
      "step": 89500
    },
    {
      "epoch": 3.1417651390301202,
      "grad_norm": 0.3288412094116211,
      "learning_rate": 3.037231198113456e-05,
      "loss": 0.0315,
      "step": 89600
    },
    {
      "epoch": 3.1452715733370735,
      "grad_norm": 0.27132847905158997,
      "learning_rate": 3.035039580612075e-05,
      "loss": 0.0323,
      "step": 89700
    },
    {
      "epoch": 3.148778007644027,
      "grad_norm": 0.22989484667778015,
      "learning_rate": 3.0328479631106944e-05,
      "loss": 0.0337,
      "step": 89800
    },
    {
      "epoch": 3.15228444195098,
      "grad_norm": 0.104482002556324,
      "learning_rate": 3.0306563456093135e-05,
      "loss": 0.0309,
      "step": 89900
    },
    {
      "epoch": 3.1557908762579334,
      "grad_norm": 0.27222785353660583,
      "learning_rate": 3.0284647281079332e-05,
      "loss": 0.0324,
      "step": 90000
    },
    {
      "epoch": 3.1592973105648867,
      "grad_norm": 0.15517452359199524,
      "learning_rate": 3.0262731106065522e-05,
      "loss": 0.0313,
      "step": 90100
    },
    {
      "epoch": 3.16280374487184,
      "grad_norm": 0.18172378838062286,
      "learning_rate": 3.0240814931051712e-05,
      "loss": 0.0313,
      "step": 90200
    },
    {
      "epoch": 3.166310179178793,
      "grad_norm": 0.5566015243530273,
      "learning_rate": 3.0218898756037906e-05,
      "loss": 0.0325,
      "step": 90300
    },
    {
      "epoch": 3.169816613485746,
      "grad_norm": 0.23111245036125183,
      "learning_rate": 3.0196982581024103e-05,
      "loss": 0.0311,
      "step": 90400
    },
    {
      "epoch": 3.1733230477926995,
      "grad_norm": 0.2689162492752075,
      "learning_rate": 3.0175066406010294e-05,
      "loss": 0.0333,
      "step": 90500
    },
    {
      "epoch": 3.1768294820996528,
      "grad_norm": 0.3245375454425812,
      "learning_rate": 3.0153150230996484e-05,
      "loss": 0.0365,
      "step": 90600
    },
    {
      "epoch": 3.180335916406606,
      "grad_norm": 0.41507744789123535,
      "learning_rate": 3.0131234055982678e-05,
      "loss": 0.0335,
      "step": 90700
    },
    {
      "epoch": 3.1838423507135594,
      "grad_norm": 0.3013475835323334,
      "learning_rate": 3.0109317880968875e-05,
      "loss": 0.0288,
      "step": 90800
    },
    {
      "epoch": 3.1873487850205127,
      "grad_norm": 0.07838205993175507,
      "learning_rate": 3.0087401705955065e-05,
      "loss": 0.0374,
      "step": 90900
    },
    {
      "epoch": 3.190855219327466,
      "grad_norm": 0.1737070232629776,
      "learning_rate": 3.0065485530941255e-05,
      "loss": 0.0367,
      "step": 91000
    },
    {
      "epoch": 3.1943616536344193,
      "grad_norm": 0.4640186131000519,
      "learning_rate": 3.004356935592745e-05,
      "loss": 0.0341,
      "step": 91100
    },
    {
      "epoch": 3.1978680879413726,
      "grad_norm": 0.23840083181858063,
      "learning_rate": 3.0021872342663782e-05,
      "loss": 0.0359,
      "step": 91200
    },
    {
      "epoch": 3.201374522248326,
      "grad_norm": 0.1744738072156906,
      "learning_rate": 2.9999956167649972e-05,
      "loss": 0.0332,
      "step": 91300
    },
    {
      "epoch": 3.2048809565552787,
      "grad_norm": 0.22636082768440247,
      "learning_rate": 2.9978039992636166e-05,
      "loss": 0.0329,
      "step": 91400
    },
    {
      "epoch": 3.208387390862232,
      "grad_norm": 0.12888330221176147,
      "learning_rate": 2.995612381762236e-05,
      "loss": 0.0294,
      "step": 91500
    },
    {
      "epoch": 3.2118938251691853,
      "grad_norm": 0.3988366723060608,
      "learning_rate": 2.9934207642608553e-05,
      "loss": 0.0345,
      "step": 91600
    },
    {
      "epoch": 3.2154002594761386,
      "grad_norm": 0.2836996018886566,
      "learning_rate": 2.9912291467594744e-05,
      "loss": 0.0329,
      "step": 91700
    },
    {
      "epoch": 3.218906693783092,
      "grad_norm": 0.13670973479747772,
      "learning_rate": 2.9890375292580934e-05,
      "loss": 0.0317,
      "step": 91800
    },
    {
      "epoch": 3.222413128090045,
      "grad_norm": 0.27353957295417786,
      "learning_rate": 2.986845911756713e-05,
      "loss": 0.0312,
      "step": 91900
    },
    {
      "epoch": 3.2259195623969985,
      "grad_norm": 0.2557668387889862,
      "learning_rate": 2.9846542942553325e-05,
      "loss": 0.0337,
      "step": 92000
    },
    {
      "epoch": 3.229425996703952,
      "grad_norm": 0.2960083484649658,
      "learning_rate": 2.9824626767539515e-05,
      "loss": 0.0345,
      "step": 92100
    },
    {
      "epoch": 3.232932431010905,
      "grad_norm": 0.23820804059505463,
      "learning_rate": 2.9802710592525706e-05,
      "loss": 0.0324,
      "step": 92200
    },
    {
      "epoch": 3.2364388653178584,
      "grad_norm": 0.20647908747196198,
      "learning_rate": 2.9780794417511903e-05,
      "loss": 0.033,
      "step": 92300
    },
    {
      "epoch": 3.2399452996248117,
      "grad_norm": 0.32042399048805237,
      "learning_rate": 2.9758878242498096e-05,
      "loss": 0.033,
      "step": 92400
    },
    {
      "epoch": 3.2434517339317646,
      "grad_norm": 0.15015578269958496,
      "learning_rate": 2.9736962067484287e-05,
      "loss": 0.034,
      "step": 92500
    },
    {
      "epoch": 3.246958168238718,
      "grad_norm": 0.21402467787265778,
      "learning_rate": 2.9715045892470477e-05,
      "loss": 0.0343,
      "step": 92600
    },
    {
      "epoch": 3.250464602545671,
      "grad_norm": 0.09158508479595184,
      "learning_rate": 2.9693129717456674e-05,
      "loss": 0.0311,
      "step": 92700
    },
    {
      "epoch": 3.2539710368526245,
      "grad_norm": 0.4057469069957733,
      "learning_rate": 2.9671213542442868e-05,
      "loss": 0.0332,
      "step": 92800
    },
    {
      "epoch": 3.2574774711595778,
      "grad_norm": 0.12214825302362442,
      "learning_rate": 2.9649297367429058e-05,
      "loss": 0.0374,
      "step": 92900
    },
    {
      "epoch": 3.260983905466531,
      "grad_norm": 0.1518101990222931,
      "learning_rate": 2.962738119241525e-05,
      "loss": 0.0329,
      "step": 93000
    },
    {
      "epoch": 3.2644903397734844,
      "grad_norm": 0.46151891350746155,
      "learning_rate": 2.9605465017401446e-05,
      "loss": 0.0317,
      "step": 93100
    },
    {
      "epoch": 3.2679967740804376,
      "grad_norm": 0.1123645156621933,
      "learning_rate": 2.9583548842387636e-05,
      "loss": 0.0349,
      "step": 93200
    },
    {
      "epoch": 3.271503208387391,
      "grad_norm": 0.18650349974632263,
      "learning_rate": 2.956163266737383e-05,
      "loss": 0.0307,
      "step": 93300
    },
    {
      "epoch": 3.2750096426943442,
      "grad_norm": 0.5459833145141602,
      "learning_rate": 2.953971649236002e-05,
      "loss": 0.0343,
      "step": 93400
    },
    {
      "epoch": 3.2785160770012975,
      "grad_norm": 0.35156288743019104,
      "learning_rate": 2.9517800317346217e-05,
      "loss": 0.0344,
      "step": 93500
    },
    {
      "epoch": 3.2820225113082504,
      "grad_norm": 0.21424375474452972,
      "learning_rate": 2.9495884142332407e-05,
      "loss": 0.034,
      "step": 93600
    },
    {
      "epoch": 3.285528945615204,
      "grad_norm": 0.11435683816671371,
      "learning_rate": 2.94739679673186e-05,
      "loss": 0.03,
      "step": 93700
    },
    {
      "epoch": 3.289035379922157,
      "grad_norm": 0.15632973611354828,
      "learning_rate": 2.9452051792304798e-05,
      "loss": 0.0321,
      "step": 93800
    },
    {
      "epoch": 3.2925418142291103,
      "grad_norm": 0.17705217003822327,
      "learning_rate": 2.9430354779041124e-05,
      "loss": 0.0333,
      "step": 93900
    },
    {
      "epoch": 3.2960482485360636,
      "grad_norm": 0.27494707703590393,
      "learning_rate": 2.9408438604027318e-05,
      "loss": 0.0356,
      "step": 94000
    },
    {
      "epoch": 3.299554682843017,
      "grad_norm": 0.0988861694931984,
      "learning_rate": 2.938652242901351e-05,
      "loss": 0.0318,
      "step": 94100
    },
    {
      "epoch": 3.30306111714997,
      "grad_norm": 0.22883641719818115,
      "learning_rate": 2.9364606253999705e-05,
      "loss": 0.0334,
      "step": 94200
    },
    {
      "epoch": 3.3065675514569235,
      "grad_norm": 0.20605237782001495,
      "learning_rate": 2.9342690078985896e-05,
      "loss": 0.0351,
      "step": 94300
    },
    {
      "epoch": 3.310073985763877,
      "grad_norm": 0.27409178018569946,
      "learning_rate": 2.9320773903972086e-05,
      "loss": 0.0317,
      "step": 94400
    },
    {
      "epoch": 3.31358042007083,
      "grad_norm": 0.16889923810958862,
      "learning_rate": 2.9298857728958283e-05,
      "loss": 0.0318,
      "step": 94500
    },
    {
      "epoch": 3.3170868543777834,
      "grad_norm": 0.14268839359283447,
      "learning_rate": 2.9276941553944477e-05,
      "loss": 0.0359,
      "step": 94600
    },
    {
      "epoch": 3.3205932886847362,
      "grad_norm": 0.2488161325454712,
      "learning_rate": 2.9255025378930667e-05,
      "loss": 0.0319,
      "step": 94700
    },
    {
      "epoch": 3.32409972299169,
      "grad_norm": 0.19580794870853424,
      "learning_rate": 2.9233109203916857e-05,
      "loss": 0.0335,
      "step": 94800
    },
    {
      "epoch": 3.327606157298643,
      "grad_norm": 0.1952904313802719,
      "learning_rate": 2.9211193028903054e-05,
      "loss": 0.0334,
      "step": 94900
    },
    {
      "epoch": 3.331112591605596,
      "grad_norm": 0.22252778708934784,
      "learning_rate": 2.9189276853889248e-05,
      "loss": 0.032,
      "step": 95000
    },
    {
      "epoch": 3.3346190259125494,
      "grad_norm": 0.2976914644241333,
      "learning_rate": 2.916736067887544e-05,
      "loss": 0.0333,
      "step": 95100
    },
    {
      "epoch": 3.3381254602195027,
      "grad_norm": 0.1848483681678772,
      "learning_rate": 2.914544450386163e-05,
      "loss": 0.0322,
      "step": 95200
    },
    {
      "epoch": 3.341631894526456,
      "grad_norm": 0.18410123884677887,
      "learning_rate": 2.9123528328847826e-05,
      "loss": 0.0351,
      "step": 95300
    },
    {
      "epoch": 3.3451383288334093,
      "grad_norm": 0.3421960473060608,
      "learning_rate": 2.910161215383402e-05,
      "loss": 0.0311,
      "step": 95400
    },
    {
      "epoch": 3.3486447631403626,
      "grad_norm": 0.2394559532403946,
      "learning_rate": 2.907969597882021e-05,
      "loss": 0.0355,
      "step": 95500
    },
    {
      "epoch": 3.352151197447316,
      "grad_norm": 0.24471305310726166,
      "learning_rate": 2.90577798038064e-05,
      "loss": 0.0292,
      "step": 95600
    },
    {
      "epoch": 3.3556576317542692,
      "grad_norm": 0.19397954642772675,
      "learning_rate": 2.9035863628792597e-05,
      "loss": 0.0305,
      "step": 95700
    },
    {
      "epoch": 3.3591640660612225,
      "grad_norm": 0.11662071198225021,
      "learning_rate": 2.9013947453778788e-05,
      "loss": 0.0339,
      "step": 95800
    },
    {
      "epoch": 3.362670500368176,
      "grad_norm": 0.15141063928604126,
      "learning_rate": 2.899203127876498e-05,
      "loss": 0.0306,
      "step": 95900
    },
    {
      "epoch": 3.3661769346751287,
      "grad_norm": 0.3986697793006897,
      "learning_rate": 2.8970115103751172e-05,
      "loss": 0.0334,
      "step": 96000
    },
    {
      "epoch": 3.369683368982082,
      "grad_norm": 0.49464061856269836,
      "learning_rate": 2.894819892873737e-05,
      "loss": 0.0321,
      "step": 96100
    },
    {
      "epoch": 3.3731898032890353,
      "grad_norm": 0.2887583076953888,
      "learning_rate": 2.89265019154737e-05,
      "loss": 0.0353,
      "step": 96200
    },
    {
      "epoch": 3.3766962375959886,
      "grad_norm": 0.2761484682559967,
      "learning_rate": 2.890458574045989e-05,
      "loss": 0.028,
      "step": 96300
    },
    {
      "epoch": 3.380202671902942,
      "grad_norm": 0.3642329275608063,
      "learning_rate": 2.8882669565446086e-05,
      "loss": 0.0345,
      "step": 96400
    },
    {
      "epoch": 3.383709106209895,
      "grad_norm": 0.1426270455121994,
      "learning_rate": 2.8860753390432276e-05,
      "loss": 0.0309,
      "step": 96500
    },
    {
      "epoch": 3.3872155405168485,
      "grad_norm": 0.18831191956996918,
      "learning_rate": 2.883883721541847e-05,
      "loss": 0.0301,
      "step": 96600
    },
    {
      "epoch": 3.3907219748238018,
      "grad_norm": 0.3705560266971588,
      "learning_rate": 2.881692104040466e-05,
      "loss": 0.0327,
      "step": 96700
    },
    {
      "epoch": 3.394228409130755,
      "grad_norm": 0.20062310993671417,
      "learning_rate": 2.8795004865390857e-05,
      "loss": 0.0308,
      "step": 96800
    },
    {
      "epoch": 3.3977348434377084,
      "grad_norm": 0.1741276979446411,
      "learning_rate": 2.8773088690377048e-05,
      "loss": 0.0292,
      "step": 96900
    },
    {
      "epoch": 3.4012412777446617,
      "grad_norm": 0.2724839746952057,
      "learning_rate": 2.8751172515363238e-05,
      "loss": 0.0319,
      "step": 97000
    },
    {
      "epoch": 3.4047477120516145,
      "grad_norm": 0.14521801471710205,
      "learning_rate": 2.872925634034943e-05,
      "loss": 0.0306,
      "step": 97100
    },
    {
      "epoch": 3.408254146358568,
      "grad_norm": 0.22654616832733154,
      "learning_rate": 2.870734016533563e-05,
      "loss": 0.0325,
      "step": 97200
    },
    {
      "epoch": 3.411760580665521,
      "grad_norm": 0.33229053020477295,
      "learning_rate": 2.868542399032182e-05,
      "loss": 0.0347,
      "step": 97300
    },
    {
      "epoch": 3.4152670149724744,
      "grad_norm": 0.13322797417640686,
      "learning_rate": 2.866372697705815e-05,
      "loss": 0.0321,
      "step": 97400
    },
    {
      "epoch": 3.4187734492794277,
      "grad_norm": 0.445006400346756,
      "learning_rate": 2.8641810802044346e-05,
      "loss": 0.0309,
      "step": 97500
    },
    {
      "epoch": 3.422279883586381,
      "grad_norm": 0.1846768707036972,
      "learning_rate": 2.8619894627030536e-05,
      "loss": 0.0342,
      "step": 97600
    },
    {
      "epoch": 3.4257863178933343,
      "grad_norm": 0.22102893888950348,
      "learning_rate": 2.8597978452016726e-05,
      "loss": 0.0329,
      "step": 97700
    },
    {
      "epoch": 3.4292927522002876,
      "grad_norm": 0.5582813620567322,
      "learning_rate": 2.857606227700292e-05,
      "loss": 0.0293,
      "step": 97800
    },
    {
      "epoch": 3.432799186507241,
      "grad_norm": 0.20335330069065094,
      "learning_rate": 2.8554146101989117e-05,
      "loss": 0.0335,
      "step": 97900
    },
    {
      "epoch": 3.436305620814194,
      "grad_norm": 0.46832597255706787,
      "learning_rate": 2.8532229926975307e-05,
      "loss": 0.0348,
      "step": 98000
    },
    {
      "epoch": 3.4398120551211475,
      "grad_norm": 0.10298344492912292,
      "learning_rate": 2.8510313751961498e-05,
      "loss": 0.0326,
      "step": 98100
    },
    {
      "epoch": 3.4433184894281004,
      "grad_norm": 0.5163992047309875,
      "learning_rate": 2.8488397576947688e-05,
      "loss": 0.0356,
      "step": 98200
    },
    {
      "epoch": 3.4468249237350537,
      "grad_norm": 0.22698117792606354,
      "learning_rate": 2.8466481401933885e-05,
      "loss": 0.0311,
      "step": 98300
    },
    {
      "epoch": 3.450331358042007,
      "grad_norm": 0.16289108991622925,
      "learning_rate": 2.844456522692008e-05,
      "loss": 0.0332,
      "step": 98400
    },
    {
      "epoch": 3.4538377923489603,
      "grad_norm": 0.2303464561700821,
      "learning_rate": 2.842264905190627e-05,
      "loss": 0.0312,
      "step": 98500
    },
    {
      "epoch": 3.4573442266559136,
      "grad_norm": 0.22257806360721588,
      "learning_rate": 2.840073287689246e-05,
      "loss": 0.0294,
      "step": 98600
    },
    {
      "epoch": 3.460850660962867,
      "grad_norm": 0.22109854221343994,
      "learning_rate": 2.8378816701878656e-05,
      "loss": 0.0367,
      "step": 98700
    },
    {
      "epoch": 3.46435709526982,
      "grad_norm": 0.38145747780799866,
      "learning_rate": 2.835690052686485e-05,
      "loss": 0.0359,
      "step": 98800
    },
    {
      "epoch": 3.4678635295767735,
      "grad_norm": 0.3160852789878845,
      "learning_rate": 2.833498435185104e-05,
      "loss": 0.031,
      "step": 98900
    },
    {
      "epoch": 3.4713699638837268,
      "grad_norm": 0.32506975531578064,
      "learning_rate": 2.831306817683723e-05,
      "loss": 0.0327,
      "step": 99000
    },
    {
      "epoch": 3.47487639819068,
      "grad_norm": 0.17954538762569427,
      "learning_rate": 2.8291152001823428e-05,
      "loss": 0.0347,
      "step": 99100
    },
    {
      "epoch": 3.4783828324976334,
      "grad_norm": 0.2931441366672516,
      "learning_rate": 2.826923582680962e-05,
      "loss": 0.0323,
      "step": 99200
    },
    {
      "epoch": 3.481889266804586,
      "grad_norm": 0.10648740828037262,
      "learning_rate": 2.8247319651795812e-05,
      "loss": 0.0324,
      "step": 99300
    },
    {
      "epoch": 3.4853957011115395,
      "grad_norm": 0.32656624913215637,
      "learning_rate": 2.8225403476782002e-05,
      "loss": 0.0316,
      "step": 99400
    },
    {
      "epoch": 3.488902135418493,
      "grad_norm": 0.2963659465312958,
      "learning_rate": 2.82034873017682e-05,
      "loss": 0.0321,
      "step": 99500
    },
    {
      "epoch": 3.492408569725446,
      "grad_norm": 0.4078536033630371,
      "learning_rate": 2.818157112675439e-05,
      "loss": 0.0319,
      "step": 99600
    },
    {
      "epoch": 3.4959150040323994,
      "grad_norm": 0.08934314548969269,
      "learning_rate": 2.8159654951740583e-05,
      "loss": 0.0306,
      "step": 99700
    },
    {
      "epoch": 3.4994214383393527,
      "grad_norm": 0.18776057660579681,
      "learning_rate": 2.8137738776726774e-05,
      "loss": 0.0313,
      "step": 99800
    },
    {
      "epoch": 3.502927872646306,
      "grad_norm": 0.21933996677398682,
      "learning_rate": 2.811582260171297e-05,
      "loss": 0.0331,
      "step": 99900
    },
    {
      "epoch": 3.5064343069532593,
      "grad_norm": 0.08981231600046158,
      "learning_rate": 2.80941255884493e-05,
      "loss": 0.0333,
      "step": 100000
    },
    {
      "epoch": 3.5099407412602126,
      "grad_norm": 0.5318507552146912,
      "learning_rate": 2.807220941343549e-05,
      "loss": 0.0296,
      "step": 100100
    },
    {
      "epoch": 3.513447175567166,
      "grad_norm": 0.13223734498023987,
      "learning_rate": 2.8050293238421688e-05,
      "loss": 0.0302,
      "step": 100200
    },
    {
      "epoch": 3.516953609874119,
      "grad_norm": 0.37426599860191345,
      "learning_rate": 2.8028377063407878e-05,
      "loss": 0.0335,
      "step": 100300
    },
    {
      "epoch": 3.520460044181072,
      "grad_norm": 0.10703137516975403,
      "learning_rate": 2.8006460888394072e-05,
      "loss": 0.0304,
      "step": 100400
    },
    {
      "epoch": 3.523966478488026,
      "grad_norm": 0.35308125615119934,
      "learning_rate": 2.7984544713380262e-05,
      "loss": 0.0328,
      "step": 100500
    },
    {
      "epoch": 3.5274729127949787,
      "grad_norm": 0.5566038489341736,
      "learning_rate": 2.796262853836646e-05,
      "loss": 0.0336,
      "step": 100600
    },
    {
      "epoch": 3.530979347101932,
      "grad_norm": 0.26722726225852966,
      "learning_rate": 2.794071236335265e-05,
      "loss": 0.0322,
      "step": 100700
    },
    {
      "epoch": 3.5344857814088853,
      "grad_norm": 0.20021259784698486,
      "learning_rate": 2.7918796188338843e-05,
      "loss": 0.0287,
      "step": 100800
    },
    {
      "epoch": 3.5379922157158386,
      "grad_norm": 0.1960689127445221,
      "learning_rate": 2.7896880013325034e-05,
      "loss": 0.0333,
      "step": 100900
    },
    {
      "epoch": 3.541498650022792,
      "grad_norm": 0.3235430121421814,
      "learning_rate": 2.787496383831123e-05,
      "loss": 0.0332,
      "step": 101000
    },
    {
      "epoch": 3.545005084329745,
      "grad_norm": 0.07820174843072891,
      "learning_rate": 2.785304766329742e-05,
      "loss": 0.031,
      "step": 101100
    },
    {
      "epoch": 3.5485115186366984,
      "grad_norm": 0.19141502678394318,
      "learning_rate": 2.783113148828361e-05,
      "loss": 0.0295,
      "step": 101200
    },
    {
      "epoch": 3.5520179529436517,
      "grad_norm": 0.2658088207244873,
      "learning_rate": 2.780921531326981e-05,
      "loss": 0.0316,
      "step": 101300
    },
    {
      "epoch": 3.555524387250605,
      "grad_norm": 0.601635217666626,
      "learning_rate": 2.7787299138256002e-05,
      "loss": 0.0329,
      "step": 101400
    },
    {
      "epoch": 3.559030821557558,
      "grad_norm": 0.4898882210254669,
      "learning_rate": 2.7765382963242192e-05,
      "loss": 0.0306,
      "step": 101500
    },
    {
      "epoch": 3.5625372558645116,
      "grad_norm": 0.20294152200222015,
      "learning_rate": 2.7743466788228383e-05,
      "loss": 0.0339,
      "step": 101600
    },
    {
      "epoch": 3.5660436901714645,
      "grad_norm": 0.22682157158851624,
      "learning_rate": 2.772155061321458e-05,
      "loss": 0.0359,
      "step": 101700
    },
    {
      "epoch": 3.569550124478418,
      "grad_norm": 0.10619648545980453,
      "learning_rate": 2.7699634438200774e-05,
      "loss": 0.0338,
      "step": 101800
    },
    {
      "epoch": 3.573056558785371,
      "grad_norm": 0.18344652652740479,
      "learning_rate": 2.7677718263186964e-05,
      "loss": 0.0342,
      "step": 101900
    },
    {
      "epoch": 3.5765629930923244,
      "grad_norm": 0.22514678537845612,
      "learning_rate": 2.7655802088173154e-05,
      "loss": 0.0324,
      "step": 102000
    },
    {
      "epoch": 3.5800694273992777,
      "grad_norm": 0.1731768399477005,
      "learning_rate": 2.763388591315935e-05,
      "loss": 0.0341,
      "step": 102100
    },
    {
      "epoch": 3.583575861706231,
      "grad_norm": 0.21226447820663452,
      "learning_rate": 2.761196973814554e-05,
      "loss": 0.0322,
      "step": 102200
    },
    {
      "epoch": 3.5870822960131843,
      "grad_norm": 0.34885329008102417,
      "learning_rate": 2.7590053563131735e-05,
      "loss": 0.0311,
      "step": 102300
    },
    {
      "epoch": 3.5905887303201376,
      "grad_norm": 0.13877394795417786,
      "learning_rate": 2.7568137388117926e-05,
      "loss": 0.0326,
      "step": 102400
    },
    {
      "epoch": 3.594095164627091,
      "grad_norm": 0.5618727803230286,
      "learning_rate": 2.7546221213104123e-05,
      "loss": 0.0312,
      "step": 102500
    },
    {
      "epoch": 3.5976015989340437,
      "grad_norm": 0.350354939699173,
      "learning_rate": 2.7524305038090313e-05,
      "loss": 0.0325,
      "step": 102600
    },
    {
      "epoch": 3.6011080332409975,
      "grad_norm": 0.2179739773273468,
      "learning_rate": 2.7502388863076507e-05,
      "loss": 0.0345,
      "step": 102700
    },
    {
      "epoch": 3.6046144675479503,
      "grad_norm": 0.199798583984375,
      "learning_rate": 2.7480472688062697e-05,
      "loss": 0.0328,
      "step": 102800
    },
    {
      "epoch": 3.6081209018549036,
      "grad_norm": 0.49412938952445984,
      "learning_rate": 2.7458556513048894e-05,
      "loss": 0.0338,
      "step": 102900
    },
    {
      "epoch": 3.611627336161857,
      "grad_norm": 0.2888215184211731,
      "learning_rate": 2.7436640338035085e-05,
      "loss": 0.0348,
      "step": 103000
    },
    {
      "epoch": 3.6151337704688102,
      "grad_norm": 0.17165645956993103,
      "learning_rate": 2.7414724163021278e-05,
      "loss": 0.034,
      "step": 103100
    },
    {
      "epoch": 3.6186402047757635,
      "grad_norm": 0.262175977230072,
      "learning_rate": 2.739280798800747e-05,
      "loss": 0.0328,
      "step": 103200
    },
    {
      "epoch": 3.622146639082717,
      "grad_norm": 0.2569224536418915,
      "learning_rate": 2.7370891812993666e-05,
      "loss": 0.0304,
      "step": 103300
    },
    {
      "epoch": 3.62565307338967,
      "grad_norm": 0.3132643401622772,
      "learning_rate": 2.7348975637979856e-05,
      "loss": 0.0351,
      "step": 103400
    },
    {
      "epoch": 3.6291595076966234,
      "grad_norm": 0.17420250177383423,
      "learning_rate": 2.732705946296605e-05,
      "loss": 0.0315,
      "step": 103500
    },
    {
      "epoch": 3.6326659420035767,
      "grad_norm": 0.13211531937122345,
      "learning_rate": 2.730514328795224e-05,
      "loss": 0.0342,
      "step": 103600
    },
    {
      "epoch": 3.6361723763105296,
      "grad_norm": 0.20164592564105988,
      "learning_rate": 2.7283227112938437e-05,
      "loss": 0.032,
      "step": 103700
    },
    {
      "epoch": 3.6396788106174833,
      "grad_norm": 0.27539098262786865,
      "learning_rate": 2.7261310937924627e-05,
      "loss": 0.0326,
      "step": 103800
    },
    {
      "epoch": 3.643185244924436,
      "grad_norm": 0.11314801126718521,
      "learning_rate": 2.7239394762910818e-05,
      "loss": 0.0304,
      "step": 103900
    },
    {
      "epoch": 3.6466916792313895,
      "grad_norm": 0.2853139042854309,
      "learning_rate": 2.721747858789701e-05,
      "loss": 0.0337,
      "step": 104000
    },
    {
      "epoch": 3.650198113538343,
      "grad_norm": 0.21736258268356323,
      "learning_rate": 2.719556241288321e-05,
      "loss": 0.0334,
      "step": 104100
    },
    {
      "epoch": 3.653704547845296,
      "grad_norm": 0.2675122916698456,
      "learning_rate": 2.71736462378694e-05,
      "loss": 0.0332,
      "step": 104200
    },
    {
      "epoch": 3.6572109821522494,
      "grad_norm": 0.26756948232650757,
      "learning_rate": 2.715173006285559e-05,
      "loss": 0.0279,
      "step": 104300
    },
    {
      "epoch": 3.6607174164592027,
      "grad_norm": 0.18270835280418396,
      "learning_rate": 2.7129813887841783e-05,
      "loss": 0.0364,
      "step": 104400
    },
    {
      "epoch": 3.664223850766156,
      "grad_norm": 0.323832631111145,
      "learning_rate": 2.710789771282798e-05,
      "loss": 0.0327,
      "step": 104500
    },
    {
      "epoch": 3.6677302850731093,
      "grad_norm": 0.48453181982040405,
      "learning_rate": 2.708598153781417e-05,
      "loss": 0.0332,
      "step": 104600
    },
    {
      "epoch": 3.6712367193800626,
      "grad_norm": 0.3285485804080963,
      "learning_rate": 2.706406536280036e-05,
      "loss": 0.0339,
      "step": 104700
    },
    {
      "epoch": 3.6747431536870154,
      "grad_norm": 0.24775609374046326,
      "learning_rate": 2.7042149187786554e-05,
      "loss": 0.0316,
      "step": 104800
    },
    {
      "epoch": 3.678249587993969,
      "grad_norm": 0.3460433781147003,
      "learning_rate": 2.7020452174522887e-05,
      "loss": 0.036,
      "step": 104900
    },
    {
      "epoch": 3.681756022300922,
      "grad_norm": 0.38573119044303894,
      "learning_rate": 2.6998535999509078e-05,
      "loss": 0.0329,
      "step": 105000
    },
    {
      "epoch": 3.6852624566078753,
      "grad_norm": 0.1585167497396469,
      "learning_rate": 2.6976619824495268e-05,
      "loss": 0.0334,
      "step": 105100
    },
    {
      "epoch": 3.6887688909148286,
      "grad_norm": 0.4658356308937073,
      "learning_rate": 2.6954703649481465e-05,
      "loss": 0.0342,
      "step": 105200
    },
    {
      "epoch": 3.692275325221782,
      "grad_norm": 0.1701394021511078,
      "learning_rate": 2.693278747446766e-05,
      "loss": 0.0325,
      "step": 105300
    },
    {
      "epoch": 3.695781759528735,
      "grad_norm": 0.08637412637472153,
      "learning_rate": 2.691087129945385e-05,
      "loss": 0.0305,
      "step": 105400
    },
    {
      "epoch": 3.6992881938356885,
      "grad_norm": 0.30893760919570923,
      "learning_rate": 2.688895512444004e-05,
      "loss": 0.0334,
      "step": 105500
    },
    {
      "epoch": 3.702794628142642,
      "grad_norm": 0.31602299213409424,
      "learning_rate": 2.6867038949426236e-05,
      "loss": 0.0342,
      "step": 105600
    },
    {
      "epoch": 3.706301062449595,
      "grad_norm": 0.21468143165111542,
      "learning_rate": 2.684512277441243e-05,
      "loss": 0.0323,
      "step": 105700
    },
    {
      "epoch": 3.7098074967565484,
      "grad_norm": 0.20052094757556915,
      "learning_rate": 2.682320659939862e-05,
      "loss": 0.0351,
      "step": 105800
    },
    {
      "epoch": 3.7133139310635013,
      "grad_norm": 0.13415102660655975,
      "learning_rate": 2.680129042438481e-05,
      "loss": 0.0308,
      "step": 105900
    },
    {
      "epoch": 3.716820365370455,
      "grad_norm": 0.3572651147842407,
      "learning_rate": 2.6779374249371008e-05,
      "loss": 0.0296,
      "step": 106000
    },
    {
      "epoch": 3.720326799677408,
      "grad_norm": 0.31747621297836304,
      "learning_rate": 2.67574580743572e-05,
      "loss": 0.0338,
      "step": 106100
    },
    {
      "epoch": 3.723833233984361,
      "grad_norm": 0.13473840057849884,
      "learning_rate": 2.6735541899343392e-05,
      "loss": 0.0296,
      "step": 106200
    },
    {
      "epoch": 3.7273396682913145,
      "grad_norm": 0.20959632098674774,
      "learning_rate": 2.6713625724329582e-05,
      "loss": 0.0319,
      "step": 106300
    },
    {
      "epoch": 3.7308461025982678,
      "grad_norm": 0.18554967641830444,
      "learning_rate": 2.669170954931578e-05,
      "loss": 0.0302,
      "step": 106400
    },
    {
      "epoch": 3.734352536905221,
      "grad_norm": 0.36264654994010925,
      "learning_rate": 2.666979337430197e-05,
      "loss": 0.0337,
      "step": 106500
    },
    {
      "epoch": 3.7378589712121744,
      "grad_norm": 0.16592274606227875,
      "learning_rate": 2.6647877199288163e-05,
      "loss": 0.0285,
      "step": 106600
    },
    {
      "epoch": 3.7413654055191277,
      "grad_norm": 0.4148097336292267,
      "learning_rate": 2.6625961024274354e-05,
      "loss": 0.0333,
      "step": 106700
    },
    {
      "epoch": 3.744871839826081,
      "grad_norm": 0.3349902331829071,
      "learning_rate": 2.660404484926055e-05,
      "loss": 0.0343,
      "step": 106800
    },
    {
      "epoch": 3.7483782741330343,
      "grad_norm": 0.25481218099594116,
      "learning_rate": 2.658212867424674e-05,
      "loss": 0.0336,
      "step": 106900
    },
    {
      "epoch": 3.751884708439987,
      "grad_norm": 0.11364663392305374,
      "learning_rate": 2.6560212499232935e-05,
      "loss": 0.0322,
      "step": 107000
    },
    {
      "epoch": 3.755391142746941,
      "grad_norm": 0.13009025156497955,
      "learning_rate": 2.6538296324219132e-05,
      "loss": 0.0306,
      "step": 107100
    },
    {
      "epoch": 3.7588975770538937,
      "grad_norm": 0.2655772864818573,
      "learning_rate": 2.6516380149205322e-05,
      "loss": 0.0324,
      "step": 107200
    },
    {
      "epoch": 3.762404011360847,
      "grad_norm": 0.1602349728345871,
      "learning_rate": 2.6494463974191513e-05,
      "loss": 0.0313,
      "step": 107300
    },
    {
      "epoch": 3.7659104456678003,
      "grad_norm": 0.13920395076274872,
      "learning_rate": 2.6472547799177706e-05,
      "loss": 0.0276,
      "step": 107400
    },
    {
      "epoch": 3.7694168799747536,
      "grad_norm": 0.2660932242870331,
      "learning_rate": 2.6450631624163903e-05,
      "loss": 0.0331,
      "step": 107500
    },
    {
      "epoch": 3.772923314281707,
      "grad_norm": 0.1589323729276657,
      "learning_rate": 2.6428715449150094e-05,
      "loss": 0.0318,
      "step": 107600
    },
    {
      "epoch": 3.77642974858866,
      "grad_norm": 0.2582850754261017,
      "learning_rate": 2.6406799274136284e-05,
      "loss": 0.0308,
      "step": 107700
    },
    {
      "epoch": 3.7799361828956135,
      "grad_norm": 0.24554885923862457,
      "learning_rate": 2.6384883099122474e-05,
      "loss": 0.0303,
      "step": 107800
    },
    {
      "epoch": 3.783442617202567,
      "grad_norm": 0.28990355134010315,
      "learning_rate": 2.636296692410867e-05,
      "loss": 0.0334,
      "step": 107900
    },
    {
      "epoch": 3.78694905150952,
      "grad_norm": 0.20737002789974213,
      "learning_rate": 2.6341050749094865e-05,
      "loss": 0.0311,
      "step": 108000
    },
    {
      "epoch": 3.790455485816473,
      "grad_norm": 0.3106505274772644,
      "learning_rate": 2.631935373583119e-05,
      "loss": 0.0323,
      "step": 108100
    },
    {
      "epoch": 3.7939619201234267,
      "grad_norm": 0.18288014829158783,
      "learning_rate": 2.629743756081739e-05,
      "loss": 0.0307,
      "step": 108200
    },
    {
      "epoch": 3.7974683544303796,
      "grad_norm": 0.4573383927345276,
      "learning_rate": 2.6275521385803582e-05,
      "loss": 0.0327,
      "step": 108300
    },
    {
      "epoch": 3.800974788737333,
      "grad_norm": 0.09830732643604279,
      "learning_rate": 2.6253605210789772e-05,
      "loss": 0.0313,
      "step": 108400
    },
    {
      "epoch": 3.804481223044286,
      "grad_norm": 0.27739405632019043,
      "learning_rate": 2.6231689035775963e-05,
      "loss": 0.0323,
      "step": 108500
    },
    {
      "epoch": 3.8079876573512395,
      "grad_norm": 0.16777510941028595,
      "learning_rate": 2.620977286076216e-05,
      "loss": 0.0293,
      "step": 108600
    },
    {
      "epoch": 3.8114940916581928,
      "grad_norm": 0.20107212662696838,
      "learning_rate": 2.6187856685748354e-05,
      "loss": 0.035,
      "step": 108700
    },
    {
      "epoch": 3.815000525965146,
      "grad_norm": 0.14592725038528442,
      "learning_rate": 2.6165940510734544e-05,
      "loss": 0.0308,
      "step": 108800
    },
    {
      "epoch": 3.8185069602720993,
      "grad_norm": 0.1864856481552124,
      "learning_rate": 2.6144024335720734e-05,
      "loss": 0.0322,
      "step": 108900
    },
    {
      "epoch": 3.8220133945790526,
      "grad_norm": 0.143667533993721,
      "learning_rate": 2.612210816070693e-05,
      "loss": 0.0327,
      "step": 109000
    },
    {
      "epoch": 3.825519828886006,
      "grad_norm": 0.20383697748184204,
      "learning_rate": 2.610019198569312e-05,
      "loss": 0.0301,
      "step": 109100
    },
    {
      "epoch": 3.8290262631929592,
      "grad_norm": 0.37047985196113586,
      "learning_rate": 2.6078275810679315e-05,
      "loss": 0.0341,
      "step": 109200
    },
    {
      "epoch": 3.8325326974999125,
      "grad_norm": 0.5727856159210205,
      "learning_rate": 2.6056359635665506e-05,
      "loss": 0.0308,
      "step": 109300
    },
    {
      "epoch": 3.8360391318068654,
      "grad_norm": 0.10539611428976059,
      "learning_rate": 2.6034443460651703e-05,
      "loss": 0.0328,
      "step": 109400
    },
    {
      "epoch": 3.8395455661138187,
      "grad_norm": 0.2521023452281952,
      "learning_rate": 2.6012527285637893e-05,
      "loss": 0.0322,
      "step": 109500
    },
    {
      "epoch": 3.843052000420772,
      "grad_norm": 0.1631256341934204,
      "learning_rate": 2.5990611110624087e-05,
      "loss": 0.0316,
      "step": 109600
    },
    {
      "epoch": 3.8465584347277253,
      "grad_norm": 0.13152003288269043,
      "learning_rate": 2.5968694935610277e-05,
      "loss": 0.0306,
      "step": 109700
    },
    {
      "epoch": 3.8500648690346786,
      "grad_norm": 0.14955061674118042,
      "learning_rate": 2.5946778760596474e-05,
      "loss": 0.0314,
      "step": 109800
    },
    {
      "epoch": 3.853571303341632,
      "grad_norm": 0.43057724833488464,
      "learning_rate": 2.5924862585582665e-05,
      "loss": 0.0342,
      "step": 109900
    },
    {
      "epoch": 3.857077737648585,
      "grad_norm": 0.24702110886573792,
      "learning_rate": 2.5902946410568858e-05,
      "loss": 0.0314,
      "step": 110000
    },
    {
      "epoch": 3.8605841719555385,
      "grad_norm": 0.2118593454360962,
      "learning_rate": 2.588103023555505e-05,
      "loss": 0.0342,
      "step": 110100
    },
    {
      "epoch": 3.864090606262492,
      "grad_norm": 0.19801466166973114,
      "learning_rate": 2.5859114060541246e-05,
      "loss": 0.0321,
      "step": 110200
    },
    {
      "epoch": 3.867597040569445,
      "grad_norm": 0.22219674289226532,
      "learning_rate": 2.5837197885527436e-05,
      "loss": 0.03,
      "step": 110300
    },
    {
      "epoch": 3.8711034748763984,
      "grad_norm": 0.12138339877128601,
      "learning_rate": 2.5815281710513626e-05,
      "loss": 0.0391,
      "step": 110400
    },
    {
      "epoch": 3.8746099091833512,
      "grad_norm": 0.10668101161718369,
      "learning_rate": 2.579336553549982e-05,
      "loss": 0.0328,
      "step": 110500
    },
    {
      "epoch": 3.878116343490305,
      "grad_norm": 0.14660274982452393,
      "learning_rate": 2.5771449360486017e-05,
      "loss": 0.031,
      "step": 110600
    },
    {
      "epoch": 3.881622777797258,
      "grad_norm": 0.2838265895843506,
      "learning_rate": 2.5749533185472207e-05,
      "loss": 0.0331,
      "step": 110700
    },
    {
      "epoch": 3.885129212104211,
      "grad_norm": 0.11245670914649963,
      "learning_rate": 2.5727617010458398e-05,
      "loss": 0.0296,
      "step": 110800
    },
    {
      "epoch": 3.8886356464111644,
      "grad_norm": 0.29534175992012024,
      "learning_rate": 2.570570083544459e-05,
      "loss": 0.0301,
      "step": 110900
    },
    {
      "epoch": 3.8921420807181177,
      "grad_norm": 0.16127486526966095,
      "learning_rate": 2.568378466043079e-05,
      "loss": 0.0341,
      "step": 111000
    },
    {
      "epoch": 3.895648515025071,
      "grad_norm": 0.2507430613040924,
      "learning_rate": 2.566186848541698e-05,
      "loss": 0.0287,
      "step": 111100
    },
    {
      "epoch": 3.8991549493320243,
      "grad_norm": 0.37422311305999756,
      "learning_rate": 2.563995231040317e-05,
      "loss": 0.0305,
      "step": 111200
    },
    {
      "epoch": 3.9026613836389776,
      "grad_norm": 0.18000417947769165,
      "learning_rate": 2.5618036135389363e-05,
      "loss": 0.0329,
      "step": 111300
    },
    {
      "epoch": 3.906167817945931,
      "grad_norm": 0.2550163269042969,
      "learning_rate": 2.559611996037556e-05,
      "loss": 0.0319,
      "step": 111400
    },
    {
      "epoch": 3.9096742522528842,
      "grad_norm": 0.33557093143463135,
      "learning_rate": 2.557420378536175e-05,
      "loss": 0.0319,
      "step": 111500
    },
    {
      "epoch": 3.913180686559837,
      "grad_norm": 0.18759794533252716,
      "learning_rate": 2.555228761034794e-05,
      "loss": 0.032,
      "step": 111600
    },
    {
      "epoch": 3.916687120866791,
      "grad_norm": 0.15310952067375183,
      "learning_rate": 2.5530371435334134e-05,
      "loss": 0.0313,
      "step": 111700
    },
    {
      "epoch": 3.9201935551737437,
      "grad_norm": 0.3568075895309448,
      "learning_rate": 2.5508455260320328e-05,
      "loss": 0.0346,
      "step": 111800
    },
    {
      "epoch": 3.923699989480697,
      "grad_norm": 0.1657552868127823,
      "learning_rate": 2.5486539085306522e-05,
      "loss": 0.0311,
      "step": 111900
    },
    {
      "epoch": 3.9272064237876503,
      "grad_norm": 0.14150071144104004,
      "learning_rate": 2.5464622910292712e-05,
      "loss": 0.0324,
      "step": 112000
    },
    {
      "epoch": 3.9307128580946036,
      "grad_norm": 0.12004805356264114,
      "learning_rate": 2.5442706735278902e-05,
      "loss": 0.031,
      "step": 112100
    },
    {
      "epoch": 3.934219292401557,
      "grad_norm": 0.23824110627174377,
      "learning_rate": 2.54207905602651e-05,
      "loss": 0.0305,
      "step": 112200
    },
    {
      "epoch": 3.93772572670851,
      "grad_norm": 0.28936317563056946,
      "learning_rate": 2.539909354700143e-05,
      "loss": 0.0346,
      "step": 112300
    },
    {
      "epoch": 3.9412321610154635,
      "grad_norm": 0.18294595181941986,
      "learning_rate": 2.537717737198762e-05,
      "loss": 0.0339,
      "step": 112400
    },
    {
      "epoch": 3.9447385953224168,
      "grad_norm": 0.2502111792564392,
      "learning_rate": 2.5355480358723956e-05,
      "loss": 0.0326,
      "step": 112500
    },
    {
      "epoch": 3.94824502962937,
      "grad_norm": 0.3753832280635834,
      "learning_rate": 2.5333564183710146e-05,
      "loss": 0.0312,
      "step": 112600
    },
    {
      "epoch": 3.951751463936323,
      "grad_norm": 0.11955931782722473,
      "learning_rate": 2.5311648008696336e-05,
      "loss": 0.0334,
      "step": 112700
    },
    {
      "epoch": 3.9552578982432767,
      "grad_norm": 0.10867355763912201,
      "learning_rate": 2.5289731833682533e-05,
      "loss": 0.0322,
      "step": 112800
    },
    {
      "epoch": 3.9587643325502295,
      "grad_norm": 0.15867893397808075,
      "learning_rate": 2.5267815658668727e-05,
      "loss": 0.032,
      "step": 112900
    },
    {
      "epoch": 3.962270766857183,
      "grad_norm": 0.2628273665904999,
      "learning_rate": 2.5245899483654917e-05,
      "loss": 0.0316,
      "step": 113000
    },
    {
      "epoch": 3.965777201164136,
      "grad_norm": 0.15874230861663818,
      "learning_rate": 2.5223983308641108e-05,
      "loss": 0.035,
      "step": 113100
    },
    {
      "epoch": 3.9692836354710894,
      "grad_norm": 0.24846704304218292,
      "learning_rate": 2.5202067133627305e-05,
      "loss": 0.0312,
      "step": 113200
    },
    {
      "epoch": 3.9727900697780427,
      "grad_norm": 0.368216872215271,
      "learning_rate": 2.5180150958613495e-05,
      "loss": 0.0309,
      "step": 113300
    },
    {
      "epoch": 3.976296504084996,
      "grad_norm": 0.2338119000196457,
      "learning_rate": 2.515823478359969e-05,
      "loss": 0.032,
      "step": 113400
    },
    {
      "epoch": 3.9798029383919493,
      "grad_norm": 0.2914629876613617,
      "learning_rate": 2.513631860858588e-05,
      "loss": 0.0348,
      "step": 113500
    },
    {
      "epoch": 3.9833093726989026,
      "grad_norm": 0.3763912618160248,
      "learning_rate": 2.5114402433572076e-05,
      "loss": 0.0289,
      "step": 113600
    },
    {
      "epoch": 3.986815807005856,
      "grad_norm": 0.279581755399704,
      "learning_rate": 2.5092486258558267e-05,
      "loss": 0.0303,
      "step": 113700
    },
    {
      "epoch": 3.9903222413128088,
      "grad_norm": 0.10927806794643402,
      "learning_rate": 2.507057008354446e-05,
      "loss": 0.0313,
      "step": 113800
    },
    {
      "epoch": 3.9938286756197625,
      "grad_norm": 0.16375714540481567,
      "learning_rate": 2.504865390853065e-05,
      "loss": 0.0295,
      "step": 113900
    },
    {
      "epoch": 3.9973351099267154,
      "grad_norm": 0.10372047871351242,
      "learning_rate": 2.5026737733516848e-05,
      "loss": 0.0328,
      "step": 114000
    },
    {
      "epoch": 4.0,
      "eval_accuracy_macro_0.5": 0.986425518989563,
      "eval_accuracy_micro_0.5": 0.9864254593849182,
      "eval_accuracy_weighted_0.5": 0.9799469709396362,
      "eval_f1_macro_0.5": 0.8119847774505615,
      "eval_f1_macro_0.6": 0.8031979203224182,
      "eval_f1_macro_0.7": 0.7833685874938965,
      "eval_f1_macro_0.8": 0.6648023724555969,
      "eval_f1_micro_0.5": 0.8280717134475708,
      "eval_f1_micro_0.6": 0.8210265636444092,
      "eval_f1_micro_0.7": 0.8050622344017029,
      "eval_f1_micro_0.8": 0.773297131061554,
      "eval_f1_micro_0.9": 0.70041424036026,
      "eval_f1_weighted_0.5": 0.8255792856216431,
      "eval_f1_weighted_0.6": 0.8160821795463562,
      "eval_f1_weighted_0.7": 0.7967371344566345,
      "eval_f1_weighted_0.8": 0.6760013699531555,
      "eval_loss": 0.030745908617973328,
      "eval_runtime": 409.8731,
      "eval_samples_per_second": 139.085,
      "eval_steps_per_second": 17.386,
      "step": 114076
    },
    {
      "epoch": 4.000841544233669,
      "grad_norm": 0.07026787847280502,
      "learning_rate": 2.5004821558503038e-05,
      "loss": 0.0278,
      "step": 114100
    },
    {
      "epoch": 4.004347978540622,
      "grad_norm": 0.1194765567779541,
      "learning_rate": 2.498290538348923e-05,
      "loss": 0.0311,
      "step": 114200
    },
    {
      "epoch": 4.007854412847576,
      "grad_norm": 0.17440760135650635,
      "learning_rate": 2.4960989208475425e-05,
      "loss": 0.0287,
      "step": 114300
    },
    {
      "epoch": 4.011360847154529,
      "grad_norm": 0.5272427797317505,
      "learning_rate": 2.493907303346162e-05,
      "loss": 0.0346,
      "step": 114400
    },
    {
      "epoch": 4.014867281461481,
      "grad_norm": 0.2557806074619293,
      "learning_rate": 2.491715685844781e-05,
      "loss": 0.0297,
      "step": 114500
    },
    {
      "epoch": 4.018373715768435,
      "grad_norm": 0.1345297396183014,
      "learning_rate": 2.4895240683434003e-05,
      "loss": 0.0266,
      "step": 114600
    },
    {
      "epoch": 4.021880150075388,
      "grad_norm": 0.2377537488937378,
      "learning_rate": 2.4873324508420197e-05,
      "loss": 0.0288,
      "step": 114700
    },
    {
      "epoch": 4.025386584382342,
      "grad_norm": 0.20291252434253693,
      "learning_rate": 2.485140833340639e-05,
      "loss": 0.0302,
      "step": 114800
    },
    {
      "epoch": 4.028893018689295,
      "grad_norm": 0.43322640657424927,
      "learning_rate": 2.482949215839258e-05,
      "loss": 0.0316,
      "step": 114900
    },
    {
      "epoch": 4.032399452996248,
      "grad_norm": 0.26522257924079895,
      "learning_rate": 2.4807575983378775e-05,
      "loss": 0.032,
      "step": 115000
    },
    {
      "epoch": 4.035905887303201,
      "grad_norm": 0.46942171454429626,
      "learning_rate": 2.4785659808364965e-05,
      "loss": 0.0313,
      "step": 115100
    },
    {
      "epoch": 4.039412321610155,
      "grad_norm": 0.18544386327266693,
      "learning_rate": 2.4763743633351162e-05,
      "loss": 0.032,
      "step": 115200
    },
    {
      "epoch": 4.042918755917108,
      "grad_norm": 0.2738552689552307,
      "learning_rate": 2.4741827458337352e-05,
      "loss": 0.0312,
      "step": 115300
    },
    {
      "epoch": 4.0464251902240616,
      "grad_norm": 0.19420526921749115,
      "learning_rate": 2.4719911283323546e-05,
      "loss": 0.0313,
      "step": 115400
    },
    {
      "epoch": 4.049931624531014,
      "grad_norm": 0.4396192729473114,
      "learning_rate": 2.4697995108309736e-05,
      "loss": 0.0286,
      "step": 115500
    },
    {
      "epoch": 4.053438058837967,
      "grad_norm": 0.27808302640914917,
      "learning_rate": 2.4676078933295933e-05,
      "loss": 0.0299,
      "step": 115600
    },
    {
      "epoch": 4.056944493144921,
      "grad_norm": 0.32027357816696167,
      "learning_rate": 2.4654162758282124e-05,
      "loss": 0.0294,
      "step": 115700
    },
    {
      "epoch": 4.060450927451874,
      "grad_norm": 0.19151999056339264,
      "learning_rate": 2.4632246583268318e-05,
      "loss": 0.0286,
      "step": 115800
    },
    {
      "epoch": 4.063957361758828,
      "grad_norm": 0.20461304485797882,
      "learning_rate": 2.4610330408254508e-05,
      "loss": 0.0307,
      "step": 115900
    },
    {
      "epoch": 4.0674637960657805,
      "grad_norm": 0.2659148573875427,
      "learning_rate": 2.45884142332407e-05,
      "loss": 0.0279,
      "step": 116000
    },
    {
      "epoch": 4.070970230372734,
      "grad_norm": 0.1530834138393402,
      "learning_rate": 2.4566498058226895e-05,
      "loss": 0.0298,
      "step": 116100
    },
    {
      "epoch": 4.074476664679687,
      "grad_norm": 0.25958243012428284,
      "learning_rate": 2.454458188321309e-05,
      "loss": 0.0319,
      "step": 116200
    },
    {
      "epoch": 4.077983098986641,
      "grad_norm": 0.30160287022590637,
      "learning_rate": 2.452266570819928e-05,
      "loss": 0.0292,
      "step": 116300
    },
    {
      "epoch": 4.081489533293594,
      "grad_norm": 0.1882150024175644,
      "learning_rate": 2.4500749533185473e-05,
      "loss": 0.0325,
      "step": 116400
    },
    {
      "epoch": 4.084995967600547,
      "grad_norm": 0.16665112972259521,
      "learning_rate": 2.4478833358171667e-05,
      "loss": 0.0302,
      "step": 116500
    },
    {
      "epoch": 4.0885024019075,
      "grad_norm": 0.11554251611232758,
      "learning_rate": 2.445691718315786e-05,
      "loss": 0.0306,
      "step": 116600
    },
    {
      "epoch": 4.092008836214453,
      "grad_norm": NaN,
      "learning_rate": 2.443522016989419e-05,
      "loss": 0.0295,
      "step": 116700
    },
    {
      "epoch": 4.095515270521407,
      "grad_norm": 0.18378792703151703,
      "learning_rate": 2.4413303994880384e-05,
      "loss": 0.0306,
      "step": 116800
    },
    {
      "epoch": 4.09902170482836,
      "grad_norm": 0.12962380051612854,
      "learning_rate": 2.4391387819866577e-05,
      "loss": 0.0345,
      "step": 116900
    },
    {
      "epoch": 4.1025281391353134,
      "grad_norm": 0.2232440859079361,
      "learning_rate": 2.4369471644852768e-05,
      "loss": 0.0337,
      "step": 117000
    },
    {
      "epoch": 4.106034573442266,
      "grad_norm": 0.1560574322938919,
      "learning_rate": 2.434755546983896e-05,
      "loss": 0.0311,
      "step": 117100
    },
    {
      "epoch": 4.10954100774922,
      "grad_norm": 0.1416817009449005,
      "learning_rate": 2.432563929482515e-05,
      "loss": 0.0326,
      "step": 117200
    },
    {
      "epoch": 4.113047442056173,
      "grad_norm": 0.27109599113464355,
      "learning_rate": 2.430372311981135e-05,
      "loss": 0.0306,
      "step": 117300
    },
    {
      "epoch": 4.116553876363127,
      "grad_norm": 0.18275827169418335,
      "learning_rate": 2.428180694479754e-05,
      "loss": 0.0339,
      "step": 117400
    },
    {
      "epoch": 4.1200603106700795,
      "grad_norm": 0.2752998471260071,
      "learning_rate": 2.4259890769783733e-05,
      "loss": 0.0303,
      "step": 117500
    },
    {
      "epoch": 4.123566744977033,
      "grad_norm": 0.2123960703611374,
      "learning_rate": 2.4237974594769923e-05,
      "loss": 0.0293,
      "step": 117600
    },
    {
      "epoch": 4.127073179283986,
      "grad_norm": 0.11975701153278351,
      "learning_rate": 2.421605841975612e-05,
      "loss": 0.03,
      "step": 117700
    },
    {
      "epoch": 4.130579613590939,
      "grad_norm": 0.09422564506530762,
      "learning_rate": 2.419414224474231e-05,
      "loss": 0.0297,
      "step": 117800
    },
    {
      "epoch": 4.134086047897893,
      "grad_norm": 0.23702222108840942,
      "learning_rate": 2.4172226069728504e-05,
      "loss": 0.0338,
      "step": 117900
    },
    {
      "epoch": 4.1375924822048455,
      "grad_norm": 0.4127348065376282,
      "learning_rate": 2.4150309894714695e-05,
      "loss": 0.0289,
      "step": 118000
    },
    {
      "epoch": 4.141098916511799,
      "grad_norm": 0.23419345915317535,
      "learning_rate": 2.4128393719700888e-05,
      "loss": 0.0312,
      "step": 118100
    },
    {
      "epoch": 4.144605350818752,
      "grad_norm": 0.42115694284439087,
      "learning_rate": 2.4106477544687082e-05,
      "loss": 0.0316,
      "step": 118200
    },
    {
      "epoch": 4.148111785125706,
      "grad_norm": 0.12830393016338348,
      "learning_rate": 2.4084561369673276e-05,
      "loss": 0.0325,
      "step": 118300
    },
    {
      "epoch": 4.151618219432659,
      "grad_norm": 0.13328933715820312,
      "learning_rate": 2.4062645194659466e-05,
      "loss": 0.0314,
      "step": 118400
    },
    {
      "epoch": 4.1551246537396125,
      "grad_norm": 0.2111900895833969,
      "learning_rate": 2.40409481813958e-05,
      "loss": 0.0338,
      "step": 118500
    },
    {
      "epoch": 4.158631088046565,
      "grad_norm": 0.12845613062381744,
      "learning_rate": 2.4019032006381993e-05,
      "loss": 0.0329,
      "step": 118600
    },
    {
      "epoch": 4.162137522353519,
      "grad_norm": 0.3105718195438385,
      "learning_rate": 2.3997115831368183e-05,
      "loss": 0.0332,
      "step": 118700
    },
    {
      "epoch": 4.165643956660472,
      "grad_norm": 0.4324275851249695,
      "learning_rate": 2.3975199656354377e-05,
      "loss": 0.0329,
      "step": 118800
    },
    {
      "epoch": 4.169150390967426,
      "grad_norm": 0.2668763995170593,
      "learning_rate": 2.395328348134057e-05,
      "loss": 0.0301,
      "step": 118900
    },
    {
      "epoch": 4.1726568252743785,
      "grad_norm": 0.17051507532596588,
      "learning_rate": 2.3931367306326764e-05,
      "loss": 0.0312,
      "step": 119000
    },
    {
      "epoch": 4.176163259581331,
      "grad_norm": 0.19953754544258118,
      "learning_rate": 2.3909451131312954e-05,
      "loss": 0.0303,
      "step": 119100
    },
    {
      "epoch": 4.179669693888285,
      "grad_norm": 0.0791829526424408,
      "learning_rate": 2.3887534956299148e-05,
      "loss": 0.0302,
      "step": 119200
    },
    {
      "epoch": 4.183176128195238,
      "grad_norm": 0.23676559329032898,
      "learning_rate": 2.386561878128534e-05,
      "loss": 0.0312,
      "step": 119300
    },
    {
      "epoch": 4.186682562502192,
      "grad_norm": 0.11850856989622116,
      "learning_rate": 2.3843702606271535e-05,
      "loss": 0.0314,
      "step": 119400
    },
    {
      "epoch": 4.190188996809145,
      "grad_norm": 0.21739764511585236,
      "learning_rate": 2.3821786431257726e-05,
      "loss": 0.0281,
      "step": 119500
    },
    {
      "epoch": 4.193695431116098,
      "grad_norm": 0.11302117258310318,
      "learning_rate": 2.379987025624392e-05,
      "loss": 0.0323,
      "step": 119600
    },
    {
      "epoch": 4.197201865423051,
      "grad_norm": 0.3733636736869812,
      "learning_rate": 2.377795408123011e-05,
      "loss": 0.0328,
      "step": 119700
    },
    {
      "epoch": 4.200708299730005,
      "grad_norm": 0.2550649046897888,
      "learning_rate": 2.3756037906216304e-05,
      "loss": 0.0365,
      "step": 119800
    },
    {
      "epoch": 4.204214734036958,
      "grad_norm": 0.23559032380580902,
      "learning_rate": 2.3734121731202497e-05,
      "loss": 0.0305,
      "step": 119900
    },
    {
      "epoch": 4.207721168343911,
      "grad_norm": 0.08259356021881104,
      "learning_rate": 2.371220555618869e-05,
      "loss": 0.0314,
      "step": 120000
    },
    {
      "epoch": 4.211227602650864,
      "grad_norm": 0.1829351782798767,
      "learning_rate": 2.369028938117488e-05,
      "loss": 0.0316,
      "step": 120100
    },
    {
      "epoch": 4.214734036957817,
      "grad_norm": 0.16109046339988708,
      "learning_rate": 2.3668373206161075e-05,
      "loss": 0.029,
      "step": 120200
    },
    {
      "epoch": 4.218240471264771,
      "grad_norm": 0.12349540740251541,
      "learning_rate": 2.364645703114727e-05,
      "loss": 0.0268,
      "step": 120300
    },
    {
      "epoch": 4.221746905571724,
      "grad_norm": 0.29126209020614624,
      "learning_rate": 2.3624540856133462e-05,
      "loss": 0.0308,
      "step": 120400
    },
    {
      "epoch": 4.225253339878678,
      "grad_norm": 0.24766628444194794,
      "learning_rate": 2.3602843842869792e-05,
      "loss": 0.0347,
      "step": 120500
    },
    {
      "epoch": 4.22875977418563,
      "grad_norm": 0.41859060525894165,
      "learning_rate": 2.3580927667855986e-05,
      "loss": 0.03,
      "step": 120600
    },
    {
      "epoch": 4.232266208492584,
      "grad_norm": 0.14202232658863068,
      "learning_rate": 2.355901149284218e-05,
      "loss": 0.0322,
      "step": 120700
    },
    {
      "epoch": 4.235772642799537,
      "grad_norm": 0.37130990624427795,
      "learning_rate": 2.353709531782837e-05,
      "loss": 0.0311,
      "step": 120800
    },
    {
      "epoch": 4.239279077106491,
      "grad_norm": 0.3697068989276886,
      "learning_rate": 2.3515179142814563e-05,
      "loss": 0.0328,
      "step": 120900
    },
    {
      "epoch": 4.242785511413444,
      "grad_norm": 0.19710510969161987,
      "learning_rate": 2.3493262967800757e-05,
      "loss": 0.0291,
      "step": 121000
    },
    {
      "epoch": 4.246291945720397,
      "grad_norm": 0.5082036852836609,
      "learning_rate": 2.347134679278695e-05,
      "loss": 0.0281,
      "step": 121100
    },
    {
      "epoch": 4.24979838002735,
      "grad_norm": 0.18349073827266693,
      "learning_rate": 2.3449430617773144e-05,
      "loss": 0.0336,
      "step": 121200
    },
    {
      "epoch": 4.253304814334303,
      "grad_norm": 0.4061364233493805,
      "learning_rate": 2.3427514442759335e-05,
      "loss": 0.0322,
      "step": 121300
    },
    {
      "epoch": 4.256811248641257,
      "grad_norm": 0.053283389657735825,
      "learning_rate": 2.340559826774553e-05,
      "loss": 0.0335,
      "step": 121400
    },
    {
      "epoch": 4.26031768294821,
      "grad_norm": 0.13835173845291138,
      "learning_rate": 2.3383682092731722e-05,
      "loss": 0.0295,
      "step": 121500
    },
    {
      "epoch": 4.263824117255163,
      "grad_norm": 0.20752008259296417,
      "learning_rate": 2.3361765917717916e-05,
      "loss": 0.0305,
      "step": 121600
    },
    {
      "epoch": 4.267330551562116,
      "grad_norm": 0.2760469913482666,
      "learning_rate": 2.3339849742704106e-05,
      "loss": 0.0318,
      "step": 121700
    },
    {
      "epoch": 4.27083698586907,
      "grad_norm": 0.10280068963766098,
      "learning_rate": 2.33179335676903e-05,
      "loss": 0.0334,
      "step": 121800
    },
    {
      "epoch": 4.274343420176023,
      "grad_norm": 0.9714009761810303,
      "learning_rate": 2.329601739267649e-05,
      "loss": 0.032,
      "step": 121900
    },
    {
      "epoch": 4.277849854482977,
      "grad_norm": 0.09039005637168884,
      "learning_rate": 2.3274101217662687e-05,
      "loss": 0.0273,
      "step": 122000
    },
    {
      "epoch": 4.2813562887899295,
      "grad_norm": 0.3034602701663971,
      "learning_rate": 2.3252185042648878e-05,
      "loss": 0.0294,
      "step": 122100
    },
    {
      "epoch": 4.284862723096882,
      "grad_norm": 0.24395576119422913,
      "learning_rate": 2.323026886763507e-05,
      "loss": 0.0324,
      "step": 122200
    },
    {
      "epoch": 4.288369157403836,
      "grad_norm": 0.22792834043502808,
      "learning_rate": 2.3208352692621262e-05,
      "loss": 0.0341,
      "step": 122300
    },
    {
      "epoch": 4.291875591710789,
      "grad_norm": 0.2793425917625427,
      "learning_rate": 2.318643651760746e-05,
      "loss": 0.03,
      "step": 122400
    },
    {
      "epoch": 4.295382026017743,
      "grad_norm": 0.5022481083869934,
      "learning_rate": 2.316452034259365e-05,
      "loss": 0.0297,
      "step": 122500
    },
    {
      "epoch": 4.2988884603246955,
      "grad_norm": 0.22049662470817566,
      "learning_rate": 2.3142604167579843e-05,
      "loss": 0.0312,
      "step": 122600
    },
    {
      "epoch": 4.302394894631649,
      "grad_norm": 0.44092267751693726,
      "learning_rate": 2.3120687992566033e-05,
      "loss": 0.0356,
      "step": 122700
    },
    {
      "epoch": 4.305901328938602,
      "grad_norm": 0.3688656985759735,
      "learning_rate": 2.3098771817552227e-05,
      "loss": 0.0306,
      "step": 122800
    },
    {
      "epoch": 4.309407763245556,
      "grad_norm": 0.43101251125335693,
      "learning_rate": 2.307685564253842e-05,
      "loss": 0.0326,
      "step": 122900
    },
    {
      "epoch": 4.312914197552509,
      "grad_norm": 0.13180087506771088,
      "learning_rate": 2.3054939467524614e-05,
      "loss": 0.0292,
      "step": 123000
    },
    {
      "epoch": 4.3164206318594625,
      "grad_norm": 0.36671438813209534,
      "learning_rate": 2.3033023292510805e-05,
      "loss": 0.0306,
      "step": 123100
    },
    {
      "epoch": 4.319927066166415,
      "grad_norm": 0.1364699751138687,
      "learning_rate": 2.3011107117497e-05,
      "loss": 0.0301,
      "step": 123200
    },
    {
      "epoch": 4.323433500473369,
      "grad_norm": 0.16055884957313538,
      "learning_rate": 2.2989190942483192e-05,
      "loss": 0.0351,
      "step": 123300
    },
    {
      "epoch": 4.326939934780322,
      "grad_norm": 0.33254873752593994,
      "learning_rate": 2.2967274767469386e-05,
      "loss": 0.0285,
      "step": 123400
    },
    {
      "epoch": 4.330446369087275,
      "grad_norm": 0.3283978998661041,
      "learning_rate": 2.2945358592455576e-05,
      "loss": 0.0325,
      "step": 123500
    },
    {
      "epoch": 4.3339528033942285,
      "grad_norm": 0.1582465022802353,
      "learning_rate": 2.292344241744177e-05,
      "loss": 0.0321,
      "step": 123600
    },
    {
      "epoch": 4.337459237701181,
      "grad_norm": 0.22570081055164337,
      "learning_rate": 2.2901526242427964e-05,
      "loss": 0.0281,
      "step": 123700
    },
    {
      "epoch": 4.340965672008135,
      "grad_norm": 0.08111397922039032,
      "learning_rate": 2.2879610067414157e-05,
      "loss": 0.0311,
      "step": 123800
    },
    {
      "epoch": 4.344472106315088,
      "grad_norm": 0.18046414852142334,
      "learning_rate": 2.2857693892400348e-05,
      "loss": 0.0295,
      "step": 123900
    },
    {
      "epoch": 4.347978540622042,
      "grad_norm": 0.04957742244005203,
      "learning_rate": 2.283577771738654e-05,
      "loss": 0.0321,
      "step": 124000
    },
    {
      "epoch": 4.3514849749289946,
      "grad_norm": 0.12764577567577362,
      "learning_rate": 2.281386154237273e-05,
      "loss": 0.0315,
      "step": 124100
    },
    {
      "epoch": 4.354991409235948,
      "grad_norm": 0.10123768448829651,
      "learning_rate": 2.279194536735893e-05,
      "loss": 0.0279,
      "step": 124200
    },
    {
      "epoch": 4.358497843542901,
      "grad_norm": 0.42845240235328674,
      "learning_rate": 2.277002919234512e-05,
      "loss": 0.0301,
      "step": 124300
    },
    {
      "epoch": 4.362004277849855,
      "grad_norm": 0.4771183729171753,
      "learning_rate": 2.2748113017331313e-05,
      "loss": 0.0309,
      "step": 124400
    },
    {
      "epoch": 4.365510712156808,
      "grad_norm": 0.2122523933649063,
      "learning_rate": 2.2726196842317503e-05,
      "loss": 0.0298,
      "step": 124500
    },
    {
      "epoch": 4.369017146463761,
      "grad_norm": 0.2226203978061676,
      "learning_rate": 2.2704280667303697e-05,
      "loss": 0.0298,
      "step": 124600
    },
    {
      "epoch": 4.372523580770714,
      "grad_norm": 0.2365504503250122,
      "learning_rate": 2.268236449228989e-05,
      "loss": 0.0325,
      "step": 124700
    },
    {
      "epoch": 4.376030015077667,
      "grad_norm": 0.4702778160572052,
      "learning_rate": 2.2660448317276084e-05,
      "loss": 0.0315,
      "step": 124800
    },
    {
      "epoch": 4.379536449384621,
      "grad_norm": 0.08289714902639389,
      "learning_rate": 2.2638532142262275e-05,
      "loss": 0.0319,
      "step": 124900
    },
    {
      "epoch": 4.383042883691574,
      "grad_norm": 0.06645230203866959,
      "learning_rate": 2.2616615967248468e-05,
      "loss": 0.0351,
      "step": 125000
    },
    {
      "epoch": 4.3865493179985275,
      "grad_norm": 0.13450156152248383,
      "learning_rate": 2.2594699792234662e-05,
      "loss": 0.0291,
      "step": 125100
    },
    {
      "epoch": 4.39005575230548,
      "grad_norm": 0.09764751046895981,
      "learning_rate": 2.2572783617220856e-05,
      "loss": 0.0307,
      "step": 125200
    },
    {
      "epoch": 4.393562186612434,
      "grad_norm": 0.38333389163017273,
      "learning_rate": 2.2550867442207046e-05,
      "loss": 0.0294,
      "step": 125300
    },
    {
      "epoch": 4.397068620919387,
      "grad_norm": 0.23410725593566895,
      "learning_rate": 2.252895126719324e-05,
      "loss": 0.0288,
      "step": 125400
    },
    {
      "epoch": 4.400575055226341,
      "grad_norm": 0.11002442985773087,
      "learning_rate": 2.2507035092179433e-05,
      "loss": 0.0291,
      "step": 125500
    },
    {
      "epoch": 4.404081489533294,
      "grad_norm": 0.09288562834262848,
      "learning_rate": 2.2485118917165627e-05,
      "loss": 0.0325,
      "step": 125600
    },
    {
      "epoch": 4.4075879238402464,
      "grad_norm": 0.15493254363536835,
      "learning_rate": 2.2463202742151817e-05,
      "loss": 0.032,
      "step": 125700
    },
    {
      "epoch": 4.4110943581472,
      "grad_norm": 0.10461882501840591,
      "learning_rate": 2.244128656713801e-05,
      "loss": 0.0352,
      "step": 125800
    },
    {
      "epoch": 4.414600792454153,
      "grad_norm": 0.19256998598575592,
      "learning_rate": 2.2419370392124205e-05,
      "loss": 0.0307,
      "step": 125900
    },
    {
      "epoch": 4.418107226761107,
      "grad_norm": 0.22614239156246185,
      "learning_rate": 2.2397673378860534e-05,
      "loss": 0.0313,
      "step": 126000
    },
    {
      "epoch": 4.42161366106806,
      "grad_norm": 0.31081637740135193,
      "learning_rate": 2.2375757203846728e-05,
      "loss": 0.032,
      "step": 126100
    },
    {
      "epoch": 4.425120095375013,
      "grad_norm": 0.15883582830429077,
      "learning_rate": 2.235384102883292e-05,
      "loss": 0.0322,
      "step": 126200
    },
    {
      "epoch": 4.428626529681966,
      "grad_norm": 0.08509016782045364,
      "learning_rate": 2.2331924853819115e-05,
      "loss": 0.0297,
      "step": 126300
    },
    {
      "epoch": 4.43213296398892,
      "grad_norm": 0.13414107263088226,
      "learning_rate": 2.2310008678805306e-05,
      "loss": 0.0293,
      "step": 126400
    },
    {
      "epoch": 4.435639398295873,
      "grad_norm": 0.12874779105186462,
      "learning_rate": 2.22880925037915e-05,
      "loss": 0.0306,
      "step": 126500
    },
    {
      "epoch": 4.439145832602827,
      "grad_norm": 0.12175938487052917,
      "learning_rate": 2.226617632877769e-05,
      "loss": 0.032,
      "step": 126600
    },
    {
      "epoch": 4.442652266909779,
      "grad_norm": 0.06051742658019066,
      "learning_rate": 2.2244260153763884e-05,
      "loss": 0.032,
      "step": 126700
    },
    {
      "epoch": 4.446158701216732,
      "grad_norm": 0.13736315071582794,
      "learning_rate": 2.2222343978750077e-05,
      "loss": 0.0317,
      "step": 126800
    },
    {
      "epoch": 4.449665135523686,
      "grad_norm": 0.2644592821598053,
      "learning_rate": 2.220042780373627e-05,
      "loss": 0.0302,
      "step": 126900
    },
    {
      "epoch": 4.453171569830639,
      "grad_norm": 0.16470856964588165,
      "learning_rate": 2.217851162872246e-05,
      "loss": 0.0311,
      "step": 127000
    },
    {
      "epoch": 4.456678004137593,
      "grad_norm": 0.2078389674425125,
      "learning_rate": 2.2156595453708655e-05,
      "loss": 0.0296,
      "step": 127100
    },
    {
      "epoch": 4.4601844384445455,
      "grad_norm": 0.3383668065071106,
      "learning_rate": 2.213467927869485e-05,
      "loss": 0.0299,
      "step": 127200
    },
    {
      "epoch": 4.463690872751499,
      "grad_norm": 0.12888352572917938,
      "learning_rate": 2.2112763103681042e-05,
      "loss": 0.0295,
      "step": 127300
    },
    {
      "epoch": 4.467197307058452,
      "grad_norm": 0.23129916191101074,
      "learning_rate": 2.2090846928667236e-05,
      "loss": 0.0303,
      "step": 127400
    },
    {
      "epoch": 4.470703741365406,
      "grad_norm": 0.20036286115646362,
      "learning_rate": 2.2068930753653426e-05,
      "loss": 0.0328,
      "step": 127500
    },
    {
      "epoch": 4.474210175672359,
      "grad_norm": 0.3147942125797272,
      "learning_rate": 2.204701457863962e-05,
      "loss": 0.0334,
      "step": 127600
    },
    {
      "epoch": 4.477716609979312,
      "grad_norm": 0.14242734014987946,
      "learning_rate": 2.2025098403625814e-05,
      "loss": 0.0309,
      "step": 127700
    },
    {
      "epoch": 4.481223044286265,
      "grad_norm": 0.25030121207237244,
      "learning_rate": 2.2003182228612008e-05,
      "loss": 0.0282,
      "step": 127800
    },
    {
      "epoch": 4.484729478593218,
      "grad_norm": 0.1519295573234558,
      "learning_rate": 2.1981266053598198e-05,
      "loss": 0.0295,
      "step": 127900
    },
    {
      "epoch": 4.488235912900172,
      "grad_norm": 0.21909430623054504,
      "learning_rate": 2.1959788202084666e-05,
      "loss": 0.0303,
      "step": 128000
    },
    {
      "epoch": 4.491742347207125,
      "grad_norm": 0.08375073224306107,
      "learning_rate": 2.193787202707086e-05,
      "loss": 0.0298,
      "step": 128100
    },
    {
      "epoch": 4.4952487815140785,
      "grad_norm": 0.08635013550519943,
      "learning_rate": 2.1915955852057054e-05,
      "loss": 0.031,
      "step": 128200
    },
    {
      "epoch": 4.498755215821031,
      "grad_norm": 0.05883750319480896,
      "learning_rate": 2.1894039677043248e-05,
      "loss": 0.0337,
      "step": 128300
    },
    {
      "epoch": 4.502261650127985,
      "grad_norm": 0.3022518754005432,
      "learning_rate": 2.187212350202944e-05,
      "loss": 0.0305,
      "step": 128400
    },
    {
      "epoch": 4.505768084434938,
      "grad_norm": 0.10427609831094742,
      "learning_rate": 2.185020732701563e-05,
      "loss": 0.0311,
      "step": 128500
    },
    {
      "epoch": 4.509274518741892,
      "grad_norm": 0.38181421160697937,
      "learning_rate": 2.1828291152001825e-05,
      "loss": 0.0308,
      "step": 128600
    },
    {
      "epoch": 4.5127809530488445,
      "grad_norm": 0.3263927102088928,
      "learning_rate": 2.1806374976988016e-05,
      "loss": 0.0344,
      "step": 128700
    },
    {
      "epoch": 4.516287387355798,
      "grad_norm": 0.21340681612491608,
      "learning_rate": 2.1784458801974213e-05,
      "loss": 0.0273,
      "step": 128800
    },
    {
      "epoch": 4.519793821662751,
      "grad_norm": 0.09391622245311737,
      "learning_rate": 2.1762542626960403e-05,
      "loss": 0.0292,
      "step": 128900
    },
    {
      "epoch": 4.523300255969705,
      "grad_norm": 0.2079140692949295,
      "learning_rate": 2.1740626451946597e-05,
      "loss": 0.0318,
      "step": 129000
    },
    {
      "epoch": 4.526806690276658,
      "grad_norm": 0.24902912974357605,
      "learning_rate": 2.1718710276932787e-05,
      "loss": 0.0334,
      "step": 129100
    },
    {
      "epoch": 4.530313124583611,
      "grad_norm": 0.06678622961044312,
      "learning_rate": 2.169679410191898e-05,
      "loss": 0.0315,
      "step": 129200
    },
    {
      "epoch": 4.533819558890564,
      "grad_norm": 0.14517998695373535,
      "learning_rate": 2.1674877926905175e-05,
      "loss": 0.0304,
      "step": 129300
    },
    {
      "epoch": 4.537325993197517,
      "grad_norm": 0.0518295094370842,
      "learning_rate": 2.1652961751891368e-05,
      "loss": 0.0297,
      "step": 129400
    },
    {
      "epoch": 4.540832427504471,
      "grad_norm": 0.15265755355358124,
      "learning_rate": 2.163104557687756e-05,
      "loss": 0.0303,
      "step": 129500
    },
    {
      "epoch": 4.544338861811424,
      "grad_norm": 0.2974836230278015,
      "learning_rate": 2.1609129401863752e-05,
      "loss": 0.0284,
      "step": 129600
    },
    {
      "epoch": 4.5478452961183775,
      "grad_norm": 0.3231702446937561,
      "learning_rate": 2.1587213226849946e-05,
      "loss": 0.0319,
      "step": 129700
    },
    {
      "epoch": 4.55135173042533,
      "grad_norm": 0.11690932512283325,
      "learning_rate": 2.156529705183614e-05,
      "loss": 0.033,
      "step": 129800
    },
    {
      "epoch": 4.554858164732284,
      "grad_norm": 0.3215639293193817,
      "learning_rate": 2.154338087682233e-05,
      "loss": 0.0299,
      "step": 129900
    },
    {
      "epoch": 4.558364599039237,
      "grad_norm": 0.17856906354427338,
      "learning_rate": 2.1521464701808524e-05,
      "loss": 0.0299,
      "step": 130000
    },
    {
      "epoch": 4.56187103334619,
      "grad_norm": 0.4486771821975708,
      "learning_rate": 2.1499548526794717e-05,
      "loss": 0.0319,
      "step": 130100
    },
    {
      "epoch": 4.565377467653144,
      "grad_norm": 0.26676344871520996,
      "learning_rate": 2.147763235178091e-05,
      "loss": 0.031,
      "step": 130200
    },
    {
      "epoch": 4.568883901960096,
      "grad_norm": 0.4591303765773773,
      "learning_rate": 2.14557161767671e-05,
      "loss": 0.0329,
      "step": 130300
    },
    {
      "epoch": 4.57239033626705,
      "grad_norm": 0.2131040394306183,
      "learning_rate": 2.1433800001753295e-05,
      "loss": 0.0278,
      "step": 130400
    },
    {
      "epoch": 4.575896770574003,
      "grad_norm": 0.12688368558883667,
      "learning_rate": 2.141188382673949e-05,
      "loss": 0.0318,
      "step": 130500
    },
    {
      "epoch": 4.579403204880957,
      "grad_norm": 0.17617368698120117,
      "learning_rate": 2.1389967651725683e-05,
      "loss": 0.0294,
      "step": 130600
    },
    {
      "epoch": 4.58290963918791,
      "grad_norm": 0.20191676914691925,
      "learning_rate": 2.1368051476711873e-05,
      "loss": 0.0313,
      "step": 130700
    },
    {
      "epoch": 4.586416073494863,
      "grad_norm": 0.21588727831840515,
      "learning_rate": 2.1346135301698067e-05,
      "loss": 0.0338,
      "step": 130800
    },
    {
      "epoch": 4.589922507801816,
      "grad_norm": 0.17919185757637024,
      "learning_rate": 2.1324219126684257e-05,
      "loss": 0.0303,
      "step": 130900
    },
    {
      "epoch": 4.59342894210877,
      "grad_norm": 0.18115173280239105,
      "learning_rate": 2.1302302951670454e-05,
      "loss": 0.0292,
      "step": 131000
    },
    {
      "epoch": 4.596935376415723,
      "grad_norm": 0.1598835587501526,
      "learning_rate": 2.1280386776656644e-05,
      "loss": 0.0307,
      "step": 131100
    },
    {
      "epoch": 4.6004418107226765,
      "grad_norm": 0.06544283777475357,
      "learning_rate": 2.1258470601642838e-05,
      "loss": 0.0335,
      "step": 131200
    },
    {
      "epoch": 4.603948245029629,
      "grad_norm": 0.3136429786682129,
      "learning_rate": 2.123655442662903e-05,
      "loss": 0.0305,
      "step": 131300
    },
    {
      "epoch": 4.607454679336582,
      "grad_norm": 0.18588890135288239,
      "learning_rate": 2.1214638251615222e-05,
      "loss": 0.0311,
      "step": 131400
    },
    {
      "epoch": 4.610961113643536,
      "grad_norm": 0.30893221497535706,
      "learning_rate": 2.1192722076601416e-05,
      "loss": 0.0324,
      "step": 131500
    },
    {
      "epoch": 4.614467547950489,
      "grad_norm": 0.10200662910938263,
      "learning_rate": 2.117080590158761e-05,
      "loss": 0.0308,
      "step": 131600
    },
    {
      "epoch": 4.617973982257443,
      "grad_norm": 0.09800831973552704,
      "learning_rate": 2.11488897265738e-05,
      "loss": 0.0311,
      "step": 131700
    },
    {
      "epoch": 4.6214804165643955,
      "grad_norm": 0.06995420902967453,
      "learning_rate": 2.1126973551559994e-05,
      "loss": 0.0312,
      "step": 131800
    },
    {
      "epoch": 4.624986850871349,
      "grad_norm": 0.342597633600235,
      "learning_rate": 2.1105057376546187e-05,
      "loss": 0.0307,
      "step": 131900
    },
    {
      "epoch": 4.628493285178302,
      "grad_norm": 0.3584299385547638,
      "learning_rate": 2.108314120153238e-05,
      "loss": 0.0282,
      "step": 132000
    },
    {
      "epoch": 4.631999719485256,
      "grad_norm": 0.13881871104240417,
      "learning_rate": 2.106122502651857e-05,
      "loss": 0.0335,
      "step": 132100
    },
    {
      "epoch": 4.635506153792209,
      "grad_norm": 0.1327388733625412,
      "learning_rate": 2.1039528013254904e-05,
      "loss": 0.0315,
      "step": 132200
    },
    {
      "epoch": 4.6390125880991615,
      "grad_norm": 0.21438506245613098,
      "learning_rate": 2.1017611838241098e-05,
      "loss": 0.0321,
      "step": 132300
    },
    {
      "epoch": 4.642519022406115,
      "grad_norm": 0.451246976852417,
      "learning_rate": 2.0995695663227288e-05,
      "loss": 0.0318,
      "step": 132400
    },
    {
      "epoch": 4.646025456713068,
      "grad_norm": 0.1659700572490692,
      "learning_rate": 2.0973779488213482e-05,
      "loss": 0.0331,
      "step": 132500
    },
    {
      "epoch": 4.649531891020022,
      "grad_norm": 0.16104771196842194,
      "learning_rate": 2.0951863313199672e-05,
      "loss": 0.0326,
      "step": 132600
    },
    {
      "epoch": 4.653038325326975,
      "grad_norm": 0.3953014016151428,
      "learning_rate": 2.092994713818587e-05,
      "loss": 0.029,
      "step": 132700
    },
    {
      "epoch": 4.656544759633928,
      "grad_norm": 0.2398236244916916,
      "learning_rate": 2.090803096317206e-05,
      "loss": 0.0293,
      "step": 132800
    },
    {
      "epoch": 4.660051193940881,
      "grad_norm": 0.1575833112001419,
      "learning_rate": 2.0886114788158253e-05,
      "loss": 0.0296,
      "step": 132900
    },
    {
      "epoch": 4.663557628247835,
      "grad_norm": 0.07372043281793594,
      "learning_rate": 2.0864198613144444e-05,
      "loss": 0.0278,
      "step": 133000
    },
    {
      "epoch": 4.667064062554788,
      "grad_norm": 0.1595698893070221,
      "learning_rate": 2.084228243813064e-05,
      "loss": 0.0292,
      "step": 133100
    },
    {
      "epoch": 4.670570496861742,
      "grad_norm": 0.11797190457582474,
      "learning_rate": 2.082036626311683e-05,
      "loss": 0.0277,
      "step": 133200
    },
    {
      "epoch": 4.6740769311686945,
      "grad_norm": 0.3533415198326111,
      "learning_rate": 2.0798450088103025e-05,
      "loss": 0.0316,
      "step": 133300
    },
    {
      "epoch": 4.677583365475648,
      "grad_norm": 0.2668265998363495,
      "learning_rate": 2.0776533913089215e-05,
      "loss": 0.0319,
      "step": 133400
    },
    {
      "epoch": 4.681089799782601,
      "grad_norm": 0.18739329278469086,
      "learning_rate": 2.075461773807541e-05,
      "loss": 0.0331,
      "step": 133500
    },
    {
      "epoch": 4.684596234089554,
      "grad_norm": 0.0778627023100853,
      "learning_rate": 2.0732701563061603e-05,
      "loss": 0.0361,
      "step": 133600
    },
    {
      "epoch": 4.688102668396508,
      "grad_norm": 0.14021894335746765,
      "learning_rate": 2.0711004549797932e-05,
      "loss": 0.0353,
      "step": 133700
    },
    {
      "epoch": 4.6916091027034605,
      "grad_norm": 0.12021934241056442,
      "learning_rate": 2.0689088374784126e-05,
      "loss": 0.0305,
      "step": 133800
    },
    {
      "epoch": 4.695115537010414,
      "grad_norm": 0.17411597073078156,
      "learning_rate": 2.066717219977032e-05,
      "loss": 0.03,
      "step": 133900
    },
    {
      "epoch": 4.698621971317367,
      "grad_norm": 0.20893101394176483,
      "learning_rate": 2.0645256024756513e-05,
      "loss": 0.0305,
      "step": 134000
    },
    {
      "epoch": 4.702128405624321,
      "grad_norm": 0.16485440731048584,
      "learning_rate": 2.0623339849742703e-05,
      "loss": 0.0318,
      "step": 134100
    },
    {
      "epoch": 4.705634839931274,
      "grad_norm": 0.1416577696800232,
      "learning_rate": 2.0601423674728897e-05,
      "loss": 0.0357,
      "step": 134200
    },
    {
      "epoch": 4.7091412742382275,
      "grad_norm": 0.2675362527370453,
      "learning_rate": 2.057950749971509e-05,
      "loss": 0.0297,
      "step": 134300
    },
    {
      "epoch": 4.71264770854518,
      "grad_norm": 1.1788228750228882,
      "learning_rate": 2.0557591324701285e-05,
      "loss": 0.033,
      "step": 134400
    },
    {
      "epoch": 4.716154142852133,
      "grad_norm": 0.3349379003047943,
      "learning_rate": 2.0535675149687475e-05,
      "loss": 0.0321,
      "step": 134500
    },
    {
      "epoch": 4.719660577159087,
      "grad_norm": 0.49094775319099426,
      "learning_rate": 2.051375897467367e-05,
      "loss": 0.0303,
      "step": 134600
    },
    {
      "epoch": 4.723167011466041,
      "grad_norm": 0.2993098199367523,
      "learning_rate": 2.0491842799659862e-05,
      "loss": 0.0314,
      "step": 134700
    },
    {
      "epoch": 4.7266734457729935,
      "grad_norm": 0.3459148705005646,
      "learning_rate": 2.0469926624646056e-05,
      "loss": 0.0302,
      "step": 134800
    },
    {
      "epoch": 4.730179880079946,
      "grad_norm": 0.3117026388645172,
      "learning_rate": 2.044801044963225e-05,
      "loss": 0.0298,
      "step": 134900
    },
    {
      "epoch": 4.7336863143869,
      "grad_norm": 0.3053096830844879,
      "learning_rate": 2.042609427461844e-05,
      "loss": 0.0291,
      "step": 135000
    },
    {
      "epoch": 4.737192748693853,
      "grad_norm": 0.23483474552631378,
      "learning_rate": 2.0404178099604634e-05,
      "loss": 0.0315,
      "step": 135100
    },
    {
      "epoch": 4.740699183000807,
      "grad_norm": 0.4305286705493927,
      "learning_rate": 2.0382261924590828e-05,
      "loss": 0.0317,
      "step": 135200
    },
    {
      "epoch": 4.74420561730776,
      "grad_norm": 0.18979544937610626,
      "learning_rate": 2.036034574957702e-05,
      "loss": 0.0312,
      "step": 135300
    },
    {
      "epoch": 4.747712051614713,
      "grad_norm": 0.24790920317173004,
      "learning_rate": 2.033842957456321e-05,
      "loss": 0.0296,
      "step": 135400
    },
    {
      "epoch": 4.751218485921666,
      "grad_norm": 0.17898307740688324,
      "learning_rate": 2.0316513399549405e-05,
      "loss": 0.0333,
      "step": 135500
    },
    {
      "epoch": 4.75472492022862,
      "grad_norm": 0.1494806408882141,
      "learning_rate": 2.0294597224535596e-05,
      "loss": 0.0299,
      "step": 135600
    },
    {
      "epoch": 4.758231354535573,
      "grad_norm": 0.16575030982494354,
      "learning_rate": 2.0272681049521793e-05,
      "loss": 0.0329,
      "step": 135700
    },
    {
      "epoch": 4.761737788842526,
      "grad_norm": 0.14535383880138397,
      "learning_rate": 2.0250764874507983e-05,
      "loss": 0.0272,
      "step": 135800
    },
    {
      "epoch": 4.765244223149479,
      "grad_norm": 0.3552318215370178,
      "learning_rate": 2.0228848699494177e-05,
      "loss": 0.0318,
      "step": 135900
    },
    {
      "epoch": 4.768750657456432,
      "grad_norm": 0.16716554760932922,
      "learning_rate": 2.0206932524480367e-05,
      "loss": 0.0313,
      "step": 136000
    },
    {
      "epoch": 4.772257091763386,
      "grad_norm": 0.3658517003059387,
      "learning_rate": 2.018501634946656e-05,
      "loss": 0.0297,
      "step": 136100
    },
    {
      "epoch": 4.775763526070339,
      "grad_norm": 0.06256461143493652,
      "learning_rate": 2.0163100174452754e-05,
      "loss": 0.0295,
      "step": 136200
    },
    {
      "epoch": 4.779269960377293,
      "grad_norm": 0.48918819427490234,
      "learning_rate": 2.0141183999438948e-05,
      "loss": 0.0341,
      "step": 136300
    },
    {
      "epoch": 4.782776394684245,
      "grad_norm": 0.16864947974681854,
      "learning_rate": 2.011926782442514e-05,
      "loss": 0.0342,
      "step": 136400
    },
    {
      "epoch": 4.786282828991199,
      "grad_norm": 0.37726277112960815,
      "learning_rate": 2.0097351649411332e-05,
      "loss": 0.0325,
      "step": 136500
    },
    {
      "epoch": 4.789789263298152,
      "grad_norm": 0.26300349831581116,
      "learning_rate": 2.0075435474397526e-05,
      "loss": 0.0279,
      "step": 136600
    },
    {
      "epoch": 4.793295697605105,
      "grad_norm": 0.2370535135269165,
      "learning_rate": 2.005351929938372e-05,
      "loss": 0.0319,
      "step": 136700
    },
    {
      "epoch": 4.796802131912059,
      "grad_norm": 0.10762117803096771,
      "learning_rate": 2.003160312436991e-05,
      "loss": 0.0297,
      "step": 136800
    },
    {
      "epoch": 4.800308566219012,
      "grad_norm": 0.18614374101161957,
      "learning_rate": 2.0009686949356104e-05,
      "loss": 0.0317,
      "step": 136900
    },
    {
      "epoch": 4.803815000525965,
      "grad_norm": 0.4008622467517853,
      "learning_rate": 1.9987770774342297e-05,
      "loss": 0.0316,
      "step": 137000
    },
    {
      "epoch": 4.807321434832918,
      "grad_norm": 0.1338808387517929,
      "learning_rate": 1.996585459932849e-05,
      "loss": 0.0304,
      "step": 137100
    },
    {
      "epoch": 4.810827869139872,
      "grad_norm": 0.24884597957134247,
      "learning_rate": 1.994393842431468e-05,
      "loss": 0.0333,
      "step": 137200
    },
    {
      "epoch": 4.814334303446825,
      "grad_norm": 0.10160768777132034,
      "learning_rate": 1.9922022249300875e-05,
      "loss": 0.0311,
      "step": 137300
    },
    {
      "epoch": 4.817840737753778,
      "grad_norm": 0.1732320785522461,
      "learning_rate": 1.9900106074287065e-05,
      "loss": 0.0316,
      "step": 137400
    },
    {
      "epoch": 4.821347172060731,
      "grad_norm": 0.27661386132240295,
      "learning_rate": 1.9878189899273263e-05,
      "loss": 0.0307,
      "step": 137500
    },
    {
      "epoch": 4.824853606367685,
      "grad_norm": 0.2024194747209549,
      "learning_rate": 1.9856273724259453e-05,
      "loss": 0.0247,
      "step": 137600
    },
    {
      "epoch": 4.828360040674638,
      "grad_norm": 0.3610246479511261,
      "learning_rate": 1.9834357549245647e-05,
      "loss": 0.0305,
      "step": 137700
    },
    {
      "epoch": 4.831866474981592,
      "grad_norm": 0.24595150351524353,
      "learning_rate": 1.9812441374231837e-05,
      "loss": 0.0293,
      "step": 137800
    },
    {
      "epoch": 4.8353729092885445,
      "grad_norm": 0.19554226100444794,
      "learning_rate": 1.979074436096817e-05,
      "loss": 0.0328,
      "step": 137900
    },
    {
      "epoch": 4.838879343595497,
      "grad_norm": 0.09792526066303253,
      "learning_rate": 1.9768828185954363e-05,
      "loss": 0.0271,
      "step": 138000
    },
    {
      "epoch": 4.842385777902451,
      "grad_norm": 0.1855165809392929,
      "learning_rate": 1.9746912010940554e-05,
      "loss": 0.0298,
      "step": 138100
    },
    {
      "epoch": 4.845892212209404,
      "grad_norm": 0.14558953046798706,
      "learning_rate": 1.9724995835926747e-05,
      "loss": 0.0295,
      "step": 138200
    },
    {
      "epoch": 4.849398646516358,
      "grad_norm": 0.25479787588119507,
      "learning_rate": 1.970307966091294e-05,
      "loss": 0.0325,
      "step": 138300
    },
    {
      "epoch": 4.8529050808233105,
      "grad_norm": 0.15029682219028473,
      "learning_rate": 1.9681163485899135e-05,
      "loss": 0.0328,
      "step": 138400
    },
    {
      "epoch": 4.856411515130264,
      "grad_norm": 0.3887512981891632,
      "learning_rate": 1.9659247310885325e-05,
      "loss": 0.0296,
      "step": 138500
    },
    {
      "epoch": 4.859917949437217,
      "grad_norm": 0.10373134166002274,
      "learning_rate": 1.963733113587152e-05,
      "loss": 0.03,
      "step": 138600
    },
    {
      "epoch": 4.863424383744171,
      "grad_norm": 0.17038221657276154,
      "learning_rate": 1.9615414960857713e-05,
      "loss": 0.0313,
      "step": 138700
    },
    {
      "epoch": 4.866930818051124,
      "grad_norm": 0.09932099282741547,
      "learning_rate": 1.9593498785843906e-05,
      "loss": 0.0294,
      "step": 138800
    },
    {
      "epoch": 4.8704372523580775,
      "grad_norm": 0.09728512912988663,
      "learning_rate": 1.9571582610830097e-05,
      "loss": 0.0317,
      "step": 138900
    },
    {
      "epoch": 4.87394368666503,
      "grad_norm": 0.08154898136854172,
      "learning_rate": 1.954966643581629e-05,
      "loss": 0.0293,
      "step": 139000
    },
    {
      "epoch": 4.877450120971984,
      "grad_norm": 0.3561309278011322,
      "learning_rate": 1.9527750260802484e-05,
      "loss": 0.0335,
      "step": 139100
    },
    {
      "epoch": 4.880956555278937,
      "grad_norm": 0.16563156247138977,
      "learning_rate": 1.9505834085788678e-05,
      "loss": 0.0338,
      "step": 139200
    },
    {
      "epoch": 4.88446298958589,
      "grad_norm": 0.07117807120084763,
      "learning_rate": 1.9483917910774868e-05,
      "loss": 0.0323,
      "step": 139300
    },
    {
      "epoch": 4.8879694238928435,
      "grad_norm": 0.1124606803059578,
      "learning_rate": 1.9462001735761062e-05,
      "loss": 0.0319,
      "step": 139400
    },
    {
      "epoch": 4.891475858199796,
      "grad_norm": 0.15231136977672577,
      "learning_rate": 1.9440085560747252e-05,
      "loss": 0.03,
      "step": 139500
    },
    {
      "epoch": 4.89498229250675,
      "grad_norm": 0.3166895806789398,
      "learning_rate": 1.941816938573345e-05,
      "loss": 0.0292,
      "step": 139600
    },
    {
      "epoch": 4.898488726813703,
      "grad_norm": 0.245976984500885,
      "learning_rate": 1.939625321071964e-05,
      "loss": 0.0283,
      "step": 139700
    },
    {
      "epoch": 4.901995161120657,
      "grad_norm": 0.11320509761571884,
      "learning_rate": 1.9374337035705833e-05,
      "loss": 0.0324,
      "step": 139800
    },
    {
      "epoch": 4.9055015954276096,
      "grad_norm": 0.12426868081092834,
      "learning_rate": 1.9352420860692024e-05,
      "loss": 0.0326,
      "step": 139900
    },
    {
      "epoch": 4.909008029734563,
      "grad_norm": 0.2466878890991211,
      "learning_rate": 1.9330504685678217e-05,
      "loss": 0.0298,
      "step": 140000
    },
    {
      "epoch": 4.912514464041516,
      "grad_norm": 0.027191584929823875,
      "learning_rate": 1.930858851066441e-05,
      "loss": 0.0304,
      "step": 140100
    },
    {
      "epoch": 4.916020898348469,
      "grad_norm": 0.16640862822532654,
      "learning_rate": 1.9286672335650605e-05,
      "loss": 0.03,
      "step": 140200
    },
    {
      "epoch": 4.919527332655423,
      "grad_norm": 0.3674657940864563,
      "learning_rate": 1.9264756160636795e-05,
      "loss": 0.0302,
      "step": 140300
    },
    {
      "epoch": 4.923033766962376,
      "grad_norm": 0.21971756219863892,
      "learning_rate": 1.924283998562299e-05,
      "loss": 0.03,
      "step": 140400
    },
    {
      "epoch": 4.926540201269329,
      "grad_norm": 0.27285486459732056,
      "learning_rate": 1.9220923810609183e-05,
      "loss": 0.0321,
      "step": 140500
    },
    {
      "epoch": 4.930046635576282,
      "grad_norm": 0.15710784494876862,
      "learning_rate": 1.9199007635595376e-05,
      "loss": 0.0304,
      "step": 140600
    },
    {
      "epoch": 4.933553069883236,
      "grad_norm": 0.16095542907714844,
      "learning_rate": 1.917709146058157e-05,
      "loss": 0.0292,
      "step": 140700
    },
    {
      "epoch": 4.937059504190189,
      "grad_norm": 0.09760283678770065,
      "learning_rate": 1.915517528556776e-05,
      "loss": 0.0275,
      "step": 140800
    },
    {
      "epoch": 4.9405659384971425,
      "grad_norm": 0.2961195707321167,
      "learning_rate": 1.9133259110553954e-05,
      "loss": 0.0336,
      "step": 140900
    },
    {
      "epoch": 4.944072372804095,
      "grad_norm": 0.1675862967967987,
      "learning_rate": 1.9111342935540148e-05,
      "loss": 0.0284,
      "step": 141000
    },
    {
      "epoch": 4.947578807111049,
      "grad_norm": 0.15701603889465332,
      "learning_rate": 1.9089645922276477e-05,
      "loss": 0.0329,
      "step": 141100
    },
    {
      "epoch": 4.951085241418002,
      "grad_norm": 0.2326420098543167,
      "learning_rate": 1.906772974726267e-05,
      "loss": 0.0272,
      "step": 141200
    },
    {
      "epoch": 4.954591675724956,
      "grad_norm": 0.1581166684627533,
      "learning_rate": 1.9045813572248865e-05,
      "loss": 0.0294,
      "step": 141300
    },
    {
      "epoch": 4.958098110031909,
      "grad_norm": 0.06256797909736633,
      "learning_rate": 1.9023897397235058e-05,
      "loss": 0.0315,
      "step": 141400
    },
    {
      "epoch": 4.9616045443388614,
      "grad_norm": 0.1579725295305252,
      "learning_rate": 1.900198122222125e-05,
      "loss": 0.0295,
      "step": 141500
    },
    {
      "epoch": 4.965110978645815,
      "grad_norm": 0.2490004152059555,
      "learning_rate": 1.8980065047207442e-05,
      "loss": 0.0283,
      "step": 141600
    },
    {
      "epoch": 4.968617412952768,
      "grad_norm": 0.22454141080379486,
      "learning_rate": 1.8958148872193636e-05,
      "loss": 0.029,
      "step": 141700
    },
    {
      "epoch": 4.972123847259722,
      "grad_norm": 0.13515590131282806,
      "learning_rate": 1.893623269717983e-05,
      "loss": 0.0283,
      "step": 141800
    },
    {
      "epoch": 4.975630281566675,
      "grad_norm": 0.18927828967571259,
      "learning_rate": 1.891431652216602e-05,
      "loss": 0.0306,
      "step": 141900
    },
    {
      "epoch": 4.979136715873628,
      "grad_norm": 0.08511382341384888,
      "learning_rate": 1.8892400347152214e-05,
      "loss": 0.0333,
      "step": 142000
    },
    {
      "epoch": 4.982643150180581,
      "grad_norm": 0.1507302224636078,
      "learning_rate": 1.8870484172138404e-05,
      "loss": 0.027,
      "step": 142100
    },
    {
      "epoch": 4.986149584487535,
      "grad_norm": 0.13012048602104187,
      "learning_rate": 1.88485679971246e-05,
      "loss": 0.0311,
      "step": 142200
    },
    {
      "epoch": 4.989656018794488,
      "grad_norm": 0.1871897131204605,
      "learning_rate": 1.882665182211079e-05,
      "loss": 0.0305,
      "step": 142300
    },
    {
      "epoch": 4.993162453101441,
      "grad_norm": 0.19191370904445648,
      "learning_rate": 1.8804735647096985e-05,
      "loss": 0.0325,
      "step": 142400
    },
    {
      "epoch": 4.996668887408394,
      "grad_norm": 0.1287311613559723,
      "learning_rate": 1.8782819472083176e-05,
      "loss": 0.0331,
      "step": 142500
    },
    {
      "epoch": 5.0,
      "eval_accuracy_macro_0.5": 0.9868727922439575,
      "eval_accuracy_micro_0.5": 0.9868727922439575,
      "eval_accuracy_weighted_0.5": 0.9804642200469971,
      "eval_f1_macro_0.5": 0.8180760741233826,
      "eval_f1_macro_0.6": 0.8075745105743408,
      "eval_f1_macro_0.7": 0.7875555753707886,
      "eval_f1_macro_0.8": 0.6684744358062744,
      "eval_f1_micro_0.5": 0.8333855271339417,
      "eval_f1_micro_0.6": 0.8255319595336914,
      "eval_f1_micro_0.7": 0.8099324703216553,
      "eval_f1_micro_0.8": 0.7769790887832642,
      "eval_f1_micro_0.9": 0.7019407153129578,
      "eval_f1_weighted_0.5": 0.8310070037841797,
      "eval_f1_weighted_0.6": 0.8209747672080994,
      "eval_f1_weighted_0.7": 0.802333652973175,
      "eval_f1_weighted_0.8": 0.6800092458724976,
      "eval_loss": 0.02949119731783867,
      "eval_runtime": 406.6569,
      "eval_samples_per_second": 140.185,
      "eval_steps_per_second": 17.523,
      "step": 142595
    },
    {
      "epoch": 5.000175321715347,
      "grad_norm": 0.068520188331604,
      "learning_rate": 1.8760903297069373e-05,
      "loss": 0.0316,
      "step": 142600
    },
    {
      "epoch": 5.003681756022301,
      "grad_norm": 0.32274454832077026,
      "learning_rate": 1.8738987122055563e-05,
      "loss": 0.0293,
      "step": 142700
    },
    {
      "epoch": 5.007188190329254,
      "grad_norm": 0.04776673763990402,
      "learning_rate": 1.8717070947041757e-05,
      "loss": 0.0346,
      "step": 142800
    },
    {
      "epoch": 5.010694624636208,
      "grad_norm": 0.3211923837661743,
      "learning_rate": 1.8695154772027947e-05,
      "loss": 0.0329,
      "step": 142900
    },
    {
      "epoch": 5.0142010589431605,
      "grad_norm": 0.02536168321967125,
      "learning_rate": 1.867323859701414e-05,
      "loss": 0.0299,
      "step": 143000
    },
    {
      "epoch": 5.017707493250114,
      "grad_norm": 0.16981031000614166,
      "learning_rate": 1.8651322422000334e-05,
      "loss": 0.0285,
      "step": 143100
    },
    {
      "epoch": 5.021213927557067,
      "grad_norm": 0.09740877151489258,
      "learning_rate": 1.8629406246986528e-05,
      "loss": 0.0298,
      "step": 143200
    },
    {
      "epoch": 5.024720361864021,
      "grad_norm": 0.11285632103681564,
      "learning_rate": 1.860749007197272e-05,
      "loss": 0.0301,
      "step": 143300
    },
    {
      "epoch": 5.028226796170974,
      "grad_norm": 0.13530875742435455,
      "learning_rate": 1.8585573896958912e-05,
      "loss": 0.0313,
      "step": 143400
    },
    {
      "epoch": 5.031733230477927,
      "grad_norm": 0.251292884349823,
      "learning_rate": 1.8563657721945106e-05,
      "loss": 0.0274,
      "step": 143500
    },
    {
      "epoch": 5.03523966478488,
      "grad_norm": 0.1347755640745163,
      "learning_rate": 1.85417415469313e-05,
      "loss": 0.0281,
      "step": 143600
    },
    {
      "epoch": 5.038746099091833,
      "grad_norm": 0.2324586659669876,
      "learning_rate": 1.851982537191749e-05,
      "loss": 0.0285,
      "step": 143700
    },
    {
      "epoch": 5.042252533398787,
      "grad_norm": 0.1738976389169693,
      "learning_rate": 1.8497909196903684e-05,
      "loss": 0.0322,
      "step": 143800
    },
    {
      "epoch": 5.04575896770574,
      "grad_norm": 0.020605552941560745,
      "learning_rate": 1.8475993021889877e-05,
      "loss": 0.0288,
      "step": 143900
    },
    {
      "epoch": 5.0492654020126935,
      "grad_norm": 0.09742464870214462,
      "learning_rate": 1.8454296008626207e-05,
      "loss": 0.028,
      "step": 144000
    },
    {
      "epoch": 5.052771836319646,
      "grad_norm": 0.3946114182472229,
      "learning_rate": 1.84323798336124e-05,
      "loss": 0.0289,
      "step": 144100
    },
    {
      "epoch": 5.0562782706266,
      "grad_norm": 0.44336915016174316,
      "learning_rate": 1.8410682820348733e-05,
      "loss": 0.0315,
      "step": 144200
    },
    {
      "epoch": 5.059784704933553,
      "grad_norm": 0.12963604927062988,
      "learning_rate": 1.8388766645334924e-05,
      "loss": 0.027,
      "step": 144300
    },
    {
      "epoch": 5.063291139240507,
      "grad_norm": 0.10950125008821487,
      "learning_rate": 1.8366850470321117e-05,
      "loss": 0.0274,
      "step": 144400
    },
    {
      "epoch": 5.0667975735474595,
      "grad_norm": 0.352213054895401,
      "learning_rate": 1.8344934295307308e-05,
      "loss": 0.0315,
      "step": 144500
    },
    {
      "epoch": 5.070304007854413,
      "grad_norm": 0.08886713534593582,
      "learning_rate": 1.83230181202935e-05,
      "loss": 0.0283,
      "step": 144600
    },
    {
      "epoch": 5.073810442161366,
      "grad_norm": 0.10453522950410843,
      "learning_rate": 1.8301101945279695e-05,
      "loss": 0.0272,
      "step": 144700
    },
    {
      "epoch": 5.077316876468319,
      "grad_norm": 0.2292955219745636,
      "learning_rate": 1.827918577026589e-05,
      "loss": 0.0281,
      "step": 144800
    },
    {
      "epoch": 5.080823310775273,
      "grad_norm": 0.11079847067594528,
      "learning_rate": 1.825726959525208e-05,
      "loss": 0.0289,
      "step": 144900
    },
    {
      "epoch": 5.084329745082226,
      "grad_norm": 0.09485083073377609,
      "learning_rate": 1.8235353420238273e-05,
      "loss": 0.0281,
      "step": 145000
    },
    {
      "epoch": 5.087836179389179,
      "grad_norm": 0.43623003363609314,
      "learning_rate": 1.8213437245224467e-05,
      "loss": 0.0268,
      "step": 145100
    },
    {
      "epoch": 5.091342613696132,
      "grad_norm": 0.14749586582183838,
      "learning_rate": 1.819152107021066e-05,
      "loss": 0.0295,
      "step": 145200
    },
    {
      "epoch": 5.094849048003086,
      "grad_norm": 0.09064089506864548,
      "learning_rate": 1.816960489519685e-05,
      "loss": 0.032,
      "step": 145300
    },
    {
      "epoch": 5.098355482310039,
      "grad_norm": 0.1293824464082718,
      "learning_rate": 1.8147688720183044e-05,
      "loss": 0.0274,
      "step": 145400
    },
    {
      "epoch": 5.1018619166169925,
      "grad_norm": 0.139053076505661,
      "learning_rate": 1.8125772545169238e-05,
      "loss": 0.0304,
      "step": 145500
    },
    {
      "epoch": 5.105368350923945,
      "grad_norm": 0.19335845112800598,
      "learning_rate": 1.8103856370155432e-05,
      "loss": 0.0322,
      "step": 145600
    },
    {
      "epoch": 5.108874785230899,
      "grad_norm": 0.22578009963035583,
      "learning_rate": 1.8081940195141622e-05,
      "loss": 0.0303,
      "step": 145700
    },
    {
      "epoch": 5.112381219537852,
      "grad_norm": 0.1578761339187622,
      "learning_rate": 1.8060024020127816e-05,
      "loss": 0.0262,
      "step": 145800
    },
    {
      "epoch": 5.115887653844805,
      "grad_norm": 0.090535469353199,
      "learning_rate": 1.803810784511401e-05,
      "loss": 0.0321,
      "step": 145900
    },
    {
      "epoch": 5.119394088151759,
      "grad_norm": 0.39363107085227966,
      "learning_rate": 1.8016191670100203e-05,
      "loss": 0.0293,
      "step": 146000
    },
    {
      "epoch": 5.122900522458711,
      "grad_norm": 0.06954639405012131,
      "learning_rate": 1.7994275495086394e-05,
      "loss": 0.0309,
      "step": 146100
    },
    {
      "epoch": 5.126406956765665,
      "grad_norm": 0.20156407356262207,
      "learning_rate": 1.7972359320072587e-05,
      "loss": 0.0294,
      "step": 146200
    },
    {
      "epoch": 5.129913391072618,
      "grad_norm": 0.10152740776538849,
      "learning_rate": 1.7950443145058778e-05,
      "loss": 0.0305,
      "step": 146300
    },
    {
      "epoch": 5.133419825379572,
      "grad_norm": 0.14519210159778595,
      "learning_rate": 1.7928526970044975e-05,
      "loss": 0.0323,
      "step": 146400
    },
    {
      "epoch": 5.136926259686525,
      "grad_norm": 0.24123330414295197,
      "learning_rate": 1.7906610795031165e-05,
      "loss": 0.0326,
      "step": 146500
    },
    {
      "epoch": 5.140432693993478,
      "grad_norm": 0.1956324279308319,
      "learning_rate": 1.788469462001736e-05,
      "loss": 0.0265,
      "step": 146600
    },
    {
      "epoch": 5.143939128300431,
      "grad_norm": 0.22603504359722137,
      "learning_rate": 1.786277844500355e-05,
      "loss": 0.033,
      "step": 146700
    },
    {
      "epoch": 5.147445562607385,
      "grad_norm": 0.3565104901790619,
      "learning_rate": 1.7840862269989743e-05,
      "loss": 0.03,
      "step": 146800
    },
    {
      "epoch": 5.150951996914338,
      "grad_norm": 0.12782546877861023,
      "learning_rate": 1.7818946094975936e-05,
      "loss": 0.0286,
      "step": 146900
    },
    {
      "epoch": 5.154458431221291,
      "grad_norm": 0.2376997023820877,
      "learning_rate": 1.779702991996213e-05,
      "loss": 0.0334,
      "step": 147000
    },
    {
      "epoch": 5.157964865528244,
      "grad_norm": 0.17535705864429474,
      "learning_rate": 1.777511374494832e-05,
      "loss": 0.029,
      "step": 147100
    },
    {
      "epoch": 5.161471299835197,
      "grad_norm": 0.15475954115390778,
      "learning_rate": 1.7753197569934514e-05,
      "loss": 0.0306,
      "step": 147200
    },
    {
      "epoch": 5.164977734142151,
      "grad_norm": 0.05107906460762024,
      "learning_rate": 1.7731281394920708e-05,
      "loss": 0.0323,
      "step": 147300
    },
    {
      "epoch": 5.168484168449104,
      "grad_norm": 0.25339430570602417,
      "learning_rate": 1.77093652199069e-05,
      "loss": 0.0294,
      "step": 147400
    },
    {
      "epoch": 5.171990602756058,
      "grad_norm": 0.1330913007259369,
      "learning_rate": 1.7687449044893092e-05,
      "loss": 0.0297,
      "step": 147500
    },
    {
      "epoch": 5.1754970370630105,
      "grad_norm": 0.20870928466320038,
      "learning_rate": 1.7665532869879286e-05,
      "loss": 0.0279,
      "step": 147600
    },
    {
      "epoch": 5.179003471369964,
      "grad_norm": 0.10151004046201706,
      "learning_rate": 1.764361669486548e-05,
      "loss": 0.0337,
      "step": 147700
    },
    {
      "epoch": 5.182509905676917,
      "grad_norm": 0.14016090333461761,
      "learning_rate": 1.7621700519851673e-05,
      "loss": 0.0314,
      "step": 147800
    },
    {
      "epoch": 5.186016339983871,
      "grad_norm": 0.24833053350448608,
      "learning_rate": 1.7599784344837867e-05,
      "loss": 0.0304,
      "step": 147900
    },
    {
      "epoch": 5.189522774290824,
      "grad_norm": 0.3647688031196594,
      "learning_rate": 1.7577868169824057e-05,
      "loss": 0.0302,
      "step": 148000
    },
    {
      "epoch": 5.1930292085977765,
      "grad_norm": 0.21625807881355286,
      "learning_rate": 1.755595199481025e-05,
      "loss": 0.0323,
      "step": 148100
    },
    {
      "epoch": 5.19653564290473,
      "grad_norm": 0.015755489468574524,
      "learning_rate": 1.7534035819796445e-05,
      "loss": 0.03,
      "step": 148200
    },
    {
      "epoch": 5.200042077211683,
      "grad_norm": 0.1905258595943451,
      "learning_rate": 1.7512119644782638e-05,
      "loss": 0.0294,
      "step": 148300
    },
    {
      "epoch": 5.203548511518637,
      "grad_norm": 0.2945127487182617,
      "learning_rate": 1.749020346976883e-05,
      "loss": 0.0299,
      "step": 148400
    },
    {
      "epoch": 5.20705494582559,
      "grad_norm": 0.1629628688097,
      "learning_rate": 1.746850645650516e-05,
      "loss": 0.0292,
      "step": 148500
    },
    {
      "epoch": 5.210561380132543,
      "grad_norm": 0.1667708456516266,
      "learning_rate": 1.7446590281491355e-05,
      "loss": 0.0289,
      "step": 148600
    },
    {
      "epoch": 5.214067814439496,
      "grad_norm": 0.1679026186466217,
      "learning_rate": 1.7424674106477545e-05,
      "loss": 0.0313,
      "step": 148700
    },
    {
      "epoch": 5.21757424874645,
      "grad_norm": 0.247162327170372,
      "learning_rate": 1.740275793146374e-05,
      "loss": 0.0299,
      "step": 148800
    },
    {
      "epoch": 5.221080683053403,
      "grad_norm": 0.06216389313340187,
      "learning_rate": 1.738084175644993e-05,
      "loss": 0.0277,
      "step": 148900
    },
    {
      "epoch": 5.224587117360357,
      "grad_norm": 0.1041799858212471,
      "learning_rate": 1.7358925581436127e-05,
      "loss": 0.0276,
      "step": 149000
    },
    {
      "epoch": 5.2280935516673095,
      "grad_norm": 0.20347121357917786,
      "learning_rate": 1.7337009406422317e-05,
      "loss": 0.0315,
      "step": 149100
    },
    {
      "epoch": 5.231599985974262,
      "grad_norm": 0.10080238431692123,
      "learning_rate": 1.731509323140851e-05,
      "loss": 0.0294,
      "step": 149200
    },
    {
      "epoch": 5.235106420281216,
      "grad_norm": 0.08677399158477783,
      "learning_rate": 1.72931770563947e-05,
      "loss": 0.0317,
      "step": 149300
    },
    {
      "epoch": 5.238612854588169,
      "grad_norm": 0.3319700360298157,
      "learning_rate": 1.7271260881380895e-05,
      "loss": 0.0313,
      "step": 149400
    },
    {
      "epoch": 5.242119288895123,
      "grad_norm": 0.0884668231010437,
      "learning_rate": 1.724934470636709e-05,
      "loss": 0.0309,
      "step": 149500
    },
    {
      "epoch": 5.2456257232020755,
      "grad_norm": 0.12513573467731476,
      "learning_rate": 1.7227428531353282e-05,
      "loss": 0.0292,
      "step": 149600
    },
    {
      "epoch": 5.249132157509029,
      "grad_norm": 0.23569467663764954,
      "learning_rate": 1.7205512356339472e-05,
      "loss": 0.0287,
      "step": 149700
    },
    {
      "epoch": 5.252638591815982,
      "grad_norm": 0.2931962311267853,
      "learning_rate": 1.7183596181325666e-05,
      "loss": 0.0342,
      "step": 149800
    },
    {
      "epoch": 5.256145026122936,
      "grad_norm": 0.39208492636680603,
      "learning_rate": 1.716168000631186e-05,
      "loss": 0.0302,
      "step": 149900
    },
    {
      "epoch": 5.259651460429889,
      "grad_norm": 0.10484955459833145,
      "learning_rate": 1.7139763831298054e-05,
      "loss": 0.0299,
      "step": 150000
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 0.16586895287036896,
      "learning_rate": 1.7117847656284244e-05,
      "loss": 0.0289,
      "step": 150100
    },
    {
      "epoch": 5.266664329043795,
      "grad_norm": 0.15440808236598969,
      "learning_rate": 1.7095931481270438e-05,
      "loss": 0.0312,
      "step": 150200
    },
    {
      "epoch": 5.270170763350748,
      "grad_norm": 0.12651659548282623,
      "learning_rate": 1.707401530625663e-05,
      "loss": 0.0329,
      "step": 150300
    },
    {
      "epoch": 5.273677197657702,
      "grad_norm": 0.12559589743614197,
      "learning_rate": 1.7052099131242825e-05,
      "loss": 0.0274,
      "step": 150400
    },
    {
      "epoch": 5.277183631964655,
      "grad_norm": 0.5089060664176941,
      "learning_rate": 1.7030182956229015e-05,
      "loss": 0.0312,
      "step": 150500
    },
    {
      "epoch": 5.2806900662716085,
      "grad_norm": 0.2434748411178589,
      "learning_rate": 1.700826678121521e-05,
      "loss": 0.03,
      "step": 150600
    },
    {
      "epoch": 5.284196500578561,
      "grad_norm": 0.2743833065032959,
      "learning_rate": 1.6986350606201403e-05,
      "loss": 0.0297,
      "step": 150700
    },
    {
      "epoch": 5.287702934885515,
      "grad_norm": 0.11157919466495514,
      "learning_rate": 1.6964434431187596e-05,
      "loss": 0.0295,
      "step": 150800
    },
    {
      "epoch": 5.291209369192468,
      "grad_norm": 0.38460931181907654,
      "learning_rate": 1.6942518256173787e-05,
      "loss": 0.0275,
      "step": 150900
    },
    {
      "epoch": 5.294715803499422,
      "grad_norm": 0.0922238752245903,
      "learning_rate": 1.692060208115998e-05,
      "loss": 0.0303,
      "step": 151000
    },
    {
      "epoch": 5.298222237806375,
      "grad_norm": 0.2089644968509674,
      "learning_rate": 1.6898905067896313e-05,
      "loss": 0.0299,
      "step": 151100
    },
    {
      "epoch": 5.301728672113328,
      "grad_norm": 0.06127537786960602,
      "learning_rate": 1.6876988892882504e-05,
      "loss": 0.0284,
      "step": 151200
    },
    {
      "epoch": 5.305235106420281,
      "grad_norm": 0.08324761688709259,
      "learning_rate": 1.6855072717868697e-05,
      "loss": 0.0281,
      "step": 151300
    },
    {
      "epoch": 5.308741540727235,
      "grad_norm": 0.1446707397699356,
      "learning_rate": 1.6833156542854888e-05,
      "loss": 0.029,
      "step": 151400
    },
    {
      "epoch": 5.312247975034188,
      "grad_norm": 0.2961597144603729,
      "learning_rate": 1.681124036784108e-05,
      "loss": 0.0312,
      "step": 151500
    },
    {
      "epoch": 5.315754409341141,
      "grad_norm": 0.10278023034334183,
      "learning_rate": 1.6789324192827275e-05,
      "loss": 0.0299,
      "step": 151600
    },
    {
      "epoch": 5.319260843648094,
      "grad_norm": 0.21382273733615875,
      "learning_rate": 1.676740801781347e-05,
      "loss": 0.0287,
      "step": 151700
    },
    {
      "epoch": 5.322767277955047,
      "grad_norm": 0.65970379114151,
      "learning_rate": 1.674549184279966e-05,
      "loss": 0.0284,
      "step": 151800
    },
    {
      "epoch": 5.326273712262001,
      "grad_norm": 0.15955999493598938,
      "learning_rate": 1.6723575667785853e-05,
      "loss": 0.028,
      "step": 151900
    },
    {
      "epoch": 5.329780146568954,
      "grad_norm": 0.08103475719690323,
      "learning_rate": 1.6701659492772047e-05,
      "loss": 0.0293,
      "step": 152000
    },
    {
      "epoch": 5.333286580875908,
      "grad_norm": 0.10176222026348114,
      "learning_rate": 1.667974331775824e-05,
      "loss": 0.0277,
      "step": 152100
    },
    {
      "epoch": 5.33679301518286,
      "grad_norm": 0.3807416260242462,
      "learning_rate": 1.665782714274443e-05,
      "loss": 0.0323,
      "step": 152200
    },
    {
      "epoch": 5.340299449489814,
      "grad_norm": 0.1204332783818245,
      "learning_rate": 1.6635910967730624e-05,
      "loss": 0.0317,
      "step": 152300
    },
    {
      "epoch": 5.343805883796767,
      "grad_norm": 0.017350096255540848,
      "learning_rate": 1.6613994792716818e-05,
      "loss": 0.0266,
      "step": 152400
    },
    {
      "epoch": 5.34731231810372,
      "grad_norm": 0.09526083618402481,
      "learning_rate": 1.659207861770301e-05,
      "loss": 0.0301,
      "step": 152500
    },
    {
      "epoch": 5.350818752410674,
      "grad_norm": 0.07044278830289841,
      "learning_rate": 1.6570162442689202e-05,
      "loss": 0.0276,
      "step": 152600
    },
    {
      "epoch": 5.3543251867176265,
      "grad_norm": 0.8214720487594604,
      "learning_rate": 1.6548246267675396e-05,
      "loss": 0.0312,
      "step": 152700
    },
    {
      "epoch": 5.35783162102458,
      "grad_norm": 0.2943095564842224,
      "learning_rate": 1.6526330092661586e-05,
      "loss": 0.0297,
      "step": 152800
    },
    {
      "epoch": 5.361338055331533,
      "grad_norm": 0.07756512612104416,
      "learning_rate": 1.6504413917647783e-05,
      "loss": 0.0306,
      "step": 152900
    },
    {
      "epoch": 5.364844489638487,
      "grad_norm": 0.1700768768787384,
      "learning_rate": 1.6482497742633973e-05,
      "loss": 0.0327,
      "step": 153000
    },
    {
      "epoch": 5.36835092394544,
      "grad_norm": 0.2766614258289337,
      "learning_rate": 1.6460581567620167e-05,
      "loss": 0.0283,
      "step": 153100
    },
    {
      "epoch": 5.371857358252393,
      "grad_norm": 0.13157743215560913,
      "learning_rate": 1.6438665392606358e-05,
      "loss": 0.0296,
      "step": 153200
    },
    {
      "epoch": 5.375363792559346,
      "grad_norm": 0.32826223969459534,
      "learning_rate": 1.6416749217592555e-05,
      "loss": 0.0292,
      "step": 153300
    },
    {
      "epoch": 5.3788702268663,
      "grad_norm": 0.09701655060052872,
      "learning_rate": 1.6394833042578745e-05,
      "loss": 0.0281,
      "step": 153400
    },
    {
      "epoch": 5.382376661173253,
      "grad_norm": 0.09188027679920197,
      "learning_rate": 1.637291686756494e-05,
      "loss": 0.028,
      "step": 153500
    },
    {
      "epoch": 5.385883095480207,
      "grad_norm": 0.1161971390247345,
      "learning_rate": 1.635100069255113e-05,
      "loss": 0.0294,
      "step": 153600
    },
    {
      "epoch": 5.3893895297871595,
      "grad_norm": 0.10138954967260361,
      "learning_rate": 1.6329084517537323e-05,
      "loss": 0.0338,
      "step": 153700
    },
    {
      "epoch": 5.392895964094112,
      "grad_norm": 0.04866769537329674,
      "learning_rate": 1.6307168342523516e-05,
      "loss": 0.0308,
      "step": 153800
    },
    {
      "epoch": 5.396402398401066,
      "grad_norm": 0.08228817582130432,
      "learning_rate": 1.628525216750971e-05,
      "loss": 0.0287,
      "step": 153900
    },
    {
      "epoch": 5.399908832708019,
      "grad_norm": 0.12490914762020111,
      "learning_rate": 1.62633359924959e-05,
      "loss": 0.0279,
      "step": 154000
    },
    {
      "epoch": 5.403415267014973,
      "grad_norm": 0.08313654363155365,
      "learning_rate": 1.6241419817482094e-05,
      "loss": 0.0319,
      "step": 154100
    },
    {
      "epoch": 5.4069217013219255,
      "grad_norm": 0.33855652809143066,
      "learning_rate": 1.6219503642468288e-05,
      "loss": 0.0325,
      "step": 154200
    },
    {
      "epoch": 5.410428135628879,
      "grad_norm": 0.13012273609638214,
      "learning_rate": 1.619758746745448e-05,
      "loss": 0.0327,
      "step": 154300
    },
    {
      "epoch": 5.413934569935832,
      "grad_norm": 0.13491573929786682,
      "learning_rate": 1.6175671292440675e-05,
      "loss": 0.028,
      "step": 154400
    },
    {
      "epoch": 5.417441004242786,
      "grad_norm": 0.1978740692138672,
      "learning_rate": 1.6153755117426866e-05,
      "loss": 0.0332,
      "step": 154500
    },
    {
      "epoch": 5.420947438549739,
      "grad_norm": 0.12426359951496124,
      "learning_rate": 1.613183894241306e-05,
      "loss": 0.0289,
      "step": 154600
    },
    {
      "epoch": 5.424453872856692,
      "grad_norm": 0.19474227726459503,
      "learning_rate": 1.611014192914939e-05,
      "loss": 0.0295,
      "step": 154700
    },
    {
      "epoch": 5.427960307163645,
      "grad_norm": 0.49986904859542847,
      "learning_rate": 1.6088225754135582e-05,
      "loss": 0.0318,
      "step": 154800
    },
    {
      "epoch": 5.431466741470598,
      "grad_norm": 0.19229863584041595,
      "learning_rate": 1.6066309579121776e-05,
      "loss": 0.0277,
      "step": 154900
    },
    {
      "epoch": 5.434973175777552,
      "grad_norm": 0.17182201147079468,
      "learning_rate": 1.604439340410797e-05,
      "loss": 0.0274,
      "step": 155000
    },
    {
      "epoch": 5.438479610084505,
      "grad_norm": 0.16112098097801208,
      "learning_rate": 1.6022477229094164e-05,
      "loss": 0.0288,
      "step": 155100
    },
    {
      "epoch": 5.4419860443914585,
      "grad_norm": 0.3830941319465637,
      "learning_rate": 1.6000561054080354e-05,
      "loss": 0.0284,
      "step": 155200
    },
    {
      "epoch": 5.445492478698411,
      "grad_norm": 0.18310676515102386,
      "learning_rate": 1.5978644879066548e-05,
      "loss": 0.0273,
      "step": 155300
    },
    {
      "epoch": 5.448998913005365,
      "grad_norm": 0.9292767643928528,
      "learning_rate": 1.595672870405274e-05,
      "loss": 0.0277,
      "step": 155400
    },
    {
      "epoch": 5.452505347312318,
      "grad_norm": 0.20219483971595764,
      "learning_rate": 1.5934812529038935e-05,
      "loss": 0.0277,
      "step": 155500
    },
    {
      "epoch": 5.456011781619272,
      "grad_norm": 0.13637712597846985,
      "learning_rate": 1.5912896354025125e-05,
      "loss": 0.0291,
      "step": 155600
    },
    {
      "epoch": 5.4595182159262245,
      "grad_norm": 0.08109508454799652,
      "learning_rate": 1.589098017901132e-05,
      "loss": 0.0298,
      "step": 155700
    },
    {
      "epoch": 5.463024650233178,
      "grad_norm": 0.16044846177101135,
      "learning_rate": 1.586906400399751e-05,
      "loss": 0.0309,
      "step": 155800
    },
    {
      "epoch": 5.466531084540131,
      "grad_norm": 0.3521268367767334,
      "learning_rate": 1.5847147828983707e-05,
      "loss": 0.0297,
      "step": 155900
    },
    {
      "epoch": 5.470037518847084,
      "grad_norm": 0.125376358628273,
      "learning_rate": 1.5825231653969897e-05,
      "loss": 0.0312,
      "step": 156000
    },
    {
      "epoch": 5.473543953154038,
      "grad_norm": 0.15590284764766693,
      "learning_rate": 1.580331547895609e-05,
      "loss": 0.0279,
      "step": 156100
    },
    {
      "epoch": 5.477050387460991,
      "grad_norm": 0.3072222173213959,
      "learning_rate": 1.578139930394228e-05,
      "loss": 0.0323,
      "step": 156200
    },
    {
      "epoch": 5.480556821767944,
      "grad_norm": 0.127813920378685,
      "learning_rate": 1.5759483128928475e-05,
      "loss": 0.0327,
      "step": 156300
    },
    {
      "epoch": 5.484063256074897,
      "grad_norm": 0.08277620375156403,
      "learning_rate": 1.5737566953914668e-05,
      "loss": 0.0326,
      "step": 156400
    },
    {
      "epoch": 5.487569690381851,
      "grad_norm": 0.2447226494550705,
      "learning_rate": 1.5715650778900862e-05,
      "loss": 0.0278,
      "step": 156500
    },
    {
      "epoch": 5.491076124688804,
      "grad_norm": 0.1342809647321701,
      "learning_rate": 1.5693734603887052e-05,
      "loss": 0.0322,
      "step": 156600
    },
    {
      "epoch": 5.4945825589957575,
      "grad_norm": 0.2336425930261612,
      "learning_rate": 1.5671818428873246e-05,
      "loss": 0.0314,
      "step": 156700
    },
    {
      "epoch": 5.49808899330271,
      "grad_norm": 0.08377636969089508,
      "learning_rate": 1.564990225385944e-05,
      "loss": 0.0273,
      "step": 156800
    },
    {
      "epoch": 5.501595427609663,
      "grad_norm": 0.07228629291057587,
      "learning_rate": 1.5627986078845633e-05,
      "loss": 0.0253,
      "step": 156900
    },
    {
      "epoch": 5.505101861916617,
      "grad_norm": 0.16809792816638947,
      "learning_rate": 1.5606069903831824e-05,
      "loss": 0.0312,
      "step": 157000
    },
    {
      "epoch": 5.508608296223571,
      "grad_norm": 0.15048156678676605,
      "learning_rate": 1.5584153728818017e-05,
      "loss": 0.0263,
      "step": 157100
    },
    {
      "epoch": 5.512114730530524,
      "grad_norm": 0.08345086872577667,
      "learning_rate": 1.556245671555435e-05,
      "loss": 0.028,
      "step": 157200
    },
    {
      "epoch": 5.515621164837476,
      "grad_norm": 0.09932687133550644,
      "learning_rate": 1.554054054054054e-05,
      "loss": 0.0345,
      "step": 157300
    },
    {
      "epoch": 5.51912759914443,
      "grad_norm": 0.2371983379125595,
      "learning_rate": 1.5518624365526734e-05,
      "loss": 0.0275,
      "step": 157400
    },
    {
      "epoch": 5.522634033451383,
      "grad_norm": 0.042784009128808975,
      "learning_rate": 1.5496708190512925e-05,
      "loss": 0.0278,
      "step": 157500
    },
    {
      "epoch": 5.526140467758337,
      "grad_norm": 0.17949602007865906,
      "learning_rate": 1.5474792015499122e-05,
      "loss": 0.0286,
      "step": 157600
    },
    {
      "epoch": 5.52964690206529,
      "grad_norm": 0.07621093839406967,
      "learning_rate": 1.5452875840485312e-05,
      "loss": 0.0302,
      "step": 157700
    },
    {
      "epoch": 5.533153336372243,
      "grad_norm": 0.3586777448654175,
      "learning_rate": 1.5430959665471506e-05,
      "loss": 0.0275,
      "step": 157800
    },
    {
      "epoch": 5.536659770679196,
      "grad_norm": 0.07700427621603012,
      "learning_rate": 1.5409043490457696e-05,
      "loss": 0.031,
      "step": 157900
    },
    {
      "epoch": 5.54016620498615,
      "grad_norm": 0.45365357398986816,
      "learning_rate": 1.5387127315443893e-05,
      "loss": 0.0277,
      "step": 158000
    },
    {
      "epoch": 5.543672639293103,
      "grad_norm": 0.18323315680027008,
      "learning_rate": 1.5365211140430084e-05,
      "loss": 0.0295,
      "step": 158100
    },
    {
      "epoch": 5.547179073600056,
      "grad_norm": 0.23062410950660706,
      "learning_rate": 1.5343294965416277e-05,
      "loss": 0.0279,
      "step": 158200
    },
    {
      "epoch": 5.550685507907009,
      "grad_norm": 0.11594603210687637,
      "learning_rate": 1.5321597952152607e-05,
      "loss": 0.0285,
      "step": 158300
    },
    {
      "epoch": 5.554191942213962,
      "grad_norm": 0.10251795500516891,
      "learning_rate": 1.52996817771388e-05,
      "loss": 0.0278,
      "step": 158400
    },
    {
      "epoch": 5.557698376520916,
      "grad_norm": 0.23046642541885376,
      "learning_rate": 1.5277765602124994e-05,
      "loss": 0.0297,
      "step": 158500
    },
    {
      "epoch": 5.561204810827869,
      "grad_norm": 0.11229537427425385,
      "learning_rate": 1.5255849427111184e-05,
      "loss": 0.0325,
      "step": 158600
    },
    {
      "epoch": 5.564711245134823,
      "grad_norm": 0.2440994381904602,
      "learning_rate": 1.523393325209738e-05,
      "loss": 0.0299,
      "step": 158700
    },
    {
      "epoch": 5.5682176794417755,
      "grad_norm": 0.2514132559299469,
      "learning_rate": 1.521201707708357e-05,
      "loss": 0.033,
      "step": 158800
    },
    {
      "epoch": 5.571724113748729,
      "grad_norm": 0.1209351122379303,
      "learning_rate": 1.5190100902069766e-05,
      "loss": 0.0332,
      "step": 158900
    },
    {
      "epoch": 5.575230548055682,
      "grad_norm": 0.09617796540260315,
      "learning_rate": 1.5168184727055956e-05,
      "loss": 0.0305,
      "step": 159000
    },
    {
      "epoch": 5.578736982362636,
      "grad_norm": 0.31476372480392456,
      "learning_rate": 1.514626855204215e-05,
      "loss": 0.0336,
      "step": 159100
    },
    {
      "epoch": 5.582243416669589,
      "grad_norm": 0.17648230493068695,
      "learning_rate": 1.5124352377028342e-05,
      "loss": 0.0314,
      "step": 159200
    },
    {
      "epoch": 5.585749850976542,
      "grad_norm": 0.38551807403564453,
      "learning_rate": 1.5102436202014535e-05,
      "loss": 0.0356,
      "step": 159300
    },
    {
      "epoch": 5.589256285283495,
      "grad_norm": 0.21614548563957214,
      "learning_rate": 1.5080520027000727e-05,
      "loss": 0.0327,
      "step": 159400
    },
    {
      "epoch": 5.592762719590448,
      "grad_norm": 0.087900310754776,
      "learning_rate": 1.5058603851986921e-05,
      "loss": 0.0313,
      "step": 159500
    },
    {
      "epoch": 5.596269153897402,
      "grad_norm": 0.13042812049388885,
      "learning_rate": 1.5036687676973113e-05,
      "loss": 0.0273,
      "step": 159600
    },
    {
      "epoch": 5.599775588204355,
      "grad_norm": 0.08625496923923492,
      "learning_rate": 1.5014771501959307e-05,
      "loss": 0.0284,
      "step": 159700
    },
    {
      "epoch": 5.6032820225113085,
      "grad_norm": 0.17705689370632172,
      "learning_rate": 1.4992855326945499e-05,
      "loss": 0.0317,
      "step": 159800
    },
    {
      "epoch": 5.606788456818261,
      "grad_norm": 0.11201481521129608,
      "learning_rate": 1.4970939151931693e-05,
      "loss": 0.0268,
      "step": 159900
    },
    {
      "epoch": 5.610294891125215,
      "grad_norm": 0.09070125222206116,
      "learning_rate": 1.4949022976917885e-05,
      "loss": 0.0311,
      "step": 160000
    },
    {
      "epoch": 5.613801325432168,
      "grad_norm": 0.08850332349538803,
      "learning_rate": 1.4927106801904078e-05,
      "loss": 0.0302,
      "step": 160100
    },
    {
      "epoch": 5.617307759739122,
      "grad_norm": 0.4463838040828705,
      "learning_rate": 1.490519062689027e-05,
      "loss": 0.0287,
      "step": 160200
    },
    {
      "epoch": 5.6208141940460745,
      "grad_norm": 0.33068782091140747,
      "learning_rate": 1.4883274451876464e-05,
      "loss": 0.029,
      "step": 160300
    },
    {
      "epoch": 5.624320628353027,
      "grad_norm": 0.21807271242141724,
      "learning_rate": 1.4861358276862656e-05,
      "loss": 0.0296,
      "step": 160400
    },
    {
      "epoch": 5.627827062659981,
      "grad_norm": 0.2865072786808014,
      "learning_rate": 1.483944210184885e-05,
      "loss": 0.03,
      "step": 160500
    },
    {
      "epoch": 5.631333496966934,
      "grad_norm": 0.06669717282056808,
      "learning_rate": 1.481752592683504e-05,
      "loss": 0.0274,
      "step": 160600
    },
    {
      "epoch": 5.634839931273888,
      "grad_norm": 0.36936020851135254,
      "learning_rate": 1.4795609751821235e-05,
      "loss": 0.0294,
      "step": 160700
    },
    {
      "epoch": 5.638346365580841,
      "grad_norm": 0.24887801706790924,
      "learning_rate": 1.4773693576807426e-05,
      "loss": 0.0311,
      "step": 160800
    },
    {
      "epoch": 5.641852799887794,
      "grad_norm": 0.11627271771430969,
      "learning_rate": 1.4751777401793621e-05,
      "loss": 0.0293,
      "step": 160900
    },
    {
      "epoch": 5.645359234194747,
      "grad_norm": 0.1380593180656433,
      "learning_rate": 1.4729861226779812e-05,
      "loss": 0.0287,
      "step": 161000
    },
    {
      "epoch": 5.648865668501701,
      "grad_norm": 0.1493043452501297,
      "learning_rate": 1.4707945051766007e-05,
      "loss": 0.0331,
      "step": 161100
    },
    {
      "epoch": 5.652372102808654,
      "grad_norm": 0.12189099192619324,
      "learning_rate": 1.4686028876752197e-05,
      "loss": 0.0305,
      "step": 161200
    },
    {
      "epoch": 5.6558785371156075,
      "grad_norm": 0.444886177778244,
      "learning_rate": 1.4664112701738391e-05,
      "loss": 0.0261,
      "step": 161300
    },
    {
      "epoch": 5.65938497142256,
      "grad_norm": 0.3549575209617615,
      "learning_rate": 1.4642196526724586e-05,
      "loss": 0.0285,
      "step": 161400
    },
    {
      "epoch": 5.662891405729514,
      "grad_norm": 0.4260542392730713,
      "learning_rate": 1.4620280351710777e-05,
      "loss": 0.0354,
      "step": 161500
    },
    {
      "epoch": 5.666397840036467,
      "grad_norm": 0.056117892265319824,
      "learning_rate": 1.4598364176696972e-05,
      "loss": 0.0287,
      "step": 161600
    },
    {
      "epoch": 5.66990427434342,
      "grad_norm": 0.07491835951805115,
      "learning_rate": 1.4576448001683162e-05,
      "loss": 0.0306,
      "step": 161700
    },
    {
      "epoch": 5.673410708650374,
      "grad_norm": 0.13241779804229736,
      "learning_rate": 1.4554531826669358e-05,
      "loss": 0.027,
      "step": 161800
    },
    {
      "epoch": 5.676917142957326,
      "grad_norm": 0.146479070186615,
      "learning_rate": 1.4532615651655548e-05,
      "loss": 0.027,
      "step": 161900
    },
    {
      "epoch": 5.68042357726428,
      "grad_norm": 0.13095028698444366,
      "learning_rate": 1.4510699476641742e-05,
      "loss": 0.032,
      "step": 162000
    },
    {
      "epoch": 5.683930011571233,
      "grad_norm": 0.14975860714912415,
      "learning_rate": 1.4488783301627934e-05,
      "loss": 0.0311,
      "step": 162100
    },
    {
      "epoch": 5.687436445878187,
      "grad_norm": 0.25901535153388977,
      "learning_rate": 1.4466867126614128e-05,
      "loss": 0.0291,
      "step": 162200
    },
    {
      "epoch": 5.69094288018514,
      "grad_norm": 0.09272652864456177,
      "learning_rate": 1.444495095160032e-05,
      "loss": 0.0291,
      "step": 162300
    },
    {
      "epoch": 5.694449314492093,
      "grad_norm": 0.3195298910140991,
      "learning_rate": 1.4423034776586513e-05,
      "loss": 0.0324,
      "step": 162400
    },
    {
      "epoch": 5.697955748799046,
      "grad_norm": 0.030032271519303322,
      "learning_rate": 1.4401118601572705e-05,
      "loss": 0.0311,
      "step": 162500
    },
    {
      "epoch": 5.701462183105999,
      "grad_norm": 0.15849840641021729,
      "learning_rate": 1.4379202426558899e-05,
      "loss": 0.0272,
      "step": 162600
    },
    {
      "epoch": 5.704968617412953,
      "grad_norm": 0.027825968340039253,
      "learning_rate": 1.4357286251545091e-05,
      "loss": 0.031,
      "step": 162700
    },
    {
      "epoch": 5.708475051719906,
      "grad_norm": 0.06719605624675751,
      "learning_rate": 1.4335370076531285e-05,
      "loss": 0.0265,
      "step": 162800
    },
    {
      "epoch": 5.711981486026859,
      "grad_norm": 0.09805995225906372,
      "learning_rate": 1.4313453901517477e-05,
      "loss": 0.0283,
      "step": 162900
    },
    {
      "epoch": 5.715487920333812,
      "grad_norm": 0.06138238683342934,
      "learning_rate": 1.429153772650367e-05,
      "loss": 0.0285,
      "step": 163000
    },
    {
      "epoch": 5.718994354640766,
      "grad_norm": 0.12480605393648148,
      "learning_rate": 1.4269621551489863e-05,
      "loss": 0.0308,
      "step": 163100
    },
    {
      "epoch": 5.722500788947719,
      "grad_norm": 0.07179882377386093,
      "learning_rate": 1.4247705376476056e-05,
      "loss": 0.0303,
      "step": 163200
    },
    {
      "epoch": 5.726007223254673,
      "grad_norm": 0.13622641563415527,
      "learning_rate": 1.4225789201462247e-05,
      "loss": 0.0283,
      "step": 163300
    },
    {
      "epoch": 5.7295136575616255,
      "grad_norm": 0.2052576243877411,
      "learning_rate": 1.4203873026448442e-05,
      "loss": 0.0302,
      "step": 163400
    },
    {
      "epoch": 5.733020091868579,
      "grad_norm": 0.32120612263679504,
      "learning_rate": 1.4181956851434632e-05,
      "loss": 0.0291,
      "step": 163500
    },
    {
      "epoch": 5.736526526175532,
      "grad_norm": 0.09030847251415253,
      "learning_rate": 1.4160040676420828e-05,
      "loss": 0.03,
      "step": 163600
    },
    {
      "epoch": 5.740032960482486,
      "grad_norm": 0.13655638694763184,
      "learning_rate": 1.4138124501407018e-05,
      "loss": 0.028,
      "step": 163700
    },
    {
      "epoch": 5.743539394789439,
      "grad_norm": 0.11667705327272415,
      "learning_rate": 1.4116208326393213e-05,
      "loss": 0.0297,
      "step": 163800
    },
    {
      "epoch": 5.7470458290963915,
      "grad_norm": 0.24930857121944427,
      "learning_rate": 1.4094292151379404e-05,
      "loss": 0.0308,
      "step": 163900
    },
    {
      "epoch": 5.750552263403345,
      "grad_norm": 0.14544863998889923,
      "learning_rate": 1.4072375976365597e-05,
      "loss": 0.0307,
      "step": 164000
    },
    {
      "epoch": 5.754058697710298,
      "grad_norm": 0.07209714502096176,
      "learning_rate": 1.405045980135179e-05,
      "loss": 0.0318,
      "step": 164100
    },
    {
      "epoch": 5.757565132017252,
      "grad_norm": 0.12202556431293488,
      "learning_rate": 1.4028543626337983e-05,
      "loss": 0.0322,
      "step": 164200
    },
    {
      "epoch": 5.761071566324205,
      "grad_norm": 0.305458664894104,
      "learning_rate": 1.4006846613074314e-05,
      "loss": 0.0288,
      "step": 164300
    },
    {
      "epoch": 5.764578000631158,
      "grad_norm": 0.07206813991069794,
      "learning_rate": 1.3984930438060506e-05,
      "loss": 0.0327,
      "step": 164400
    },
    {
      "epoch": 5.768084434938111,
      "grad_norm": 0.32414647936820984,
      "learning_rate": 1.39630142630467e-05,
      "loss": 0.029,
      "step": 164500
    },
    {
      "epoch": 5.771590869245065,
      "grad_norm": 0.16367113590240479,
      "learning_rate": 1.3941098088032892e-05,
      "loss": 0.0275,
      "step": 164600
    },
    {
      "epoch": 5.775097303552018,
      "grad_norm": 0.15935741364955902,
      "learning_rate": 1.3919181913019086e-05,
      "loss": 0.0295,
      "step": 164700
    },
    {
      "epoch": 5.778603737858971,
      "grad_norm": 0.1436920166015625,
      "learning_rate": 1.3897265738005278e-05,
      "loss": 0.0279,
      "step": 164800
    },
    {
      "epoch": 5.7821101721659245,
      "grad_norm": 0.3654489815235138,
      "learning_rate": 1.3875349562991472e-05,
      "loss": 0.0334,
      "step": 164900
    },
    {
      "epoch": 5.785616606472877,
      "grad_norm": 0.23405325412750244,
      "learning_rate": 1.3853433387977664e-05,
      "loss": 0.0299,
      "step": 165000
    },
    {
      "epoch": 5.789123040779831,
      "grad_norm": 0.19495192170143127,
      "learning_rate": 1.3831517212963857e-05,
      "loss": 0.0289,
      "step": 165100
    },
    {
      "epoch": 5.792629475086784,
      "grad_norm": 0.1267712563276291,
      "learning_rate": 1.380960103795005e-05,
      "loss": 0.0293,
      "step": 165200
    },
    {
      "epoch": 5.796135909393738,
      "grad_norm": 0.06346191465854645,
      "learning_rate": 1.3787684862936243e-05,
      "loss": 0.0305,
      "step": 165300
    },
    {
      "epoch": 5.7996423437006905,
      "grad_norm": 0.13720309734344482,
      "learning_rate": 1.3765768687922433e-05,
      "loss": 0.0303,
      "step": 165400
    },
    {
      "epoch": 5.803148778007644,
      "grad_norm": 0.08933597803115845,
      "learning_rate": 1.3743852512908629e-05,
      "loss": 0.0294,
      "step": 165500
    },
    {
      "epoch": 5.806655212314597,
      "grad_norm": 0.13944318890571594,
      "learning_rate": 1.3721936337894819e-05,
      "loss": 0.0289,
      "step": 165600
    },
    {
      "epoch": 5.810161646621551,
      "grad_norm": 0.24887779355049133,
      "learning_rate": 1.3700020162881014e-05,
      "loss": 0.0283,
      "step": 165700
    },
    {
      "epoch": 5.813668080928504,
      "grad_norm": 0.11533205211162567,
      "learning_rate": 1.3678103987867205e-05,
      "loss": 0.0299,
      "step": 165800
    },
    {
      "epoch": 5.8171745152354575,
      "grad_norm": 0.2254687249660492,
      "learning_rate": 1.36561878128534e-05,
      "loss": 0.0292,
      "step": 165900
    },
    {
      "epoch": 5.82068094954241,
      "grad_norm": 0.13844554126262665,
      "learning_rate": 1.363427163783959e-05,
      "loss": 0.0304,
      "step": 166000
    },
    {
      "epoch": 5.824187383849363,
      "grad_norm": 0.19827985763549805,
      "learning_rate": 1.3612355462825784e-05,
      "loss": 0.0287,
      "step": 166100
    },
    {
      "epoch": 5.827693818156317,
      "grad_norm": 0.277974009513855,
      "learning_rate": 1.3590439287811976e-05,
      "loss": 0.0257,
      "step": 166200
    },
    {
      "epoch": 5.83120025246327,
      "grad_norm": 0.11789008975028992,
      "learning_rate": 1.356852311279817e-05,
      "loss": 0.0298,
      "step": 166300
    },
    {
      "epoch": 5.8347066867702235,
      "grad_norm": 0.10136070102453232,
      "learning_rate": 1.3546606937784362e-05,
      "loss": 0.0306,
      "step": 166400
    },
    {
      "epoch": 5.838213121077176,
      "grad_norm": 0.19981767237186432,
      "learning_rate": 1.3524909924520693e-05,
      "loss": 0.0335,
      "step": 166500
    },
    {
      "epoch": 5.84171955538413,
      "grad_norm": 0.482928067445755,
      "learning_rate": 1.3502993749506887e-05,
      "loss": 0.0322,
      "step": 166600
    },
    {
      "epoch": 5.845225989691083,
      "grad_norm": 0.05881032347679138,
      "learning_rate": 1.3481077574493079e-05,
      "loss": 0.0287,
      "step": 166700
    },
    {
      "epoch": 5.848732423998037,
      "grad_norm": 0.06905258446931839,
      "learning_rate": 1.3459161399479273e-05,
      "loss": 0.0268,
      "step": 166800
    },
    {
      "epoch": 5.85223885830499,
      "grad_norm": 0.04060431942343712,
      "learning_rate": 1.3437245224465465e-05,
      "loss": 0.03,
      "step": 166900
    },
    {
      "epoch": 5.855745292611942,
      "grad_norm": 0.13708658516407013,
      "learning_rate": 1.3415329049451658e-05,
      "loss": 0.0286,
      "step": 167000
    },
    {
      "epoch": 5.859251726918896,
      "grad_norm": 0.4445395767688751,
      "learning_rate": 1.339341287443785e-05,
      "loss": 0.0326,
      "step": 167100
    },
    {
      "epoch": 5.86275816122585,
      "grad_norm": 0.10049978643655777,
      "learning_rate": 1.3371496699424044e-05,
      "loss": 0.0282,
      "step": 167200
    },
    {
      "epoch": 5.866264595532803,
      "grad_norm": 0.29572737216949463,
      "learning_rate": 1.335001884791051e-05,
      "loss": 0.0295,
      "step": 167300
    },
    {
      "epoch": 5.869771029839756,
      "grad_norm": 0.06984449923038483,
      "learning_rate": 1.3328102672896706e-05,
      "loss": 0.0288,
      "step": 167400
    },
    {
      "epoch": 5.873277464146709,
      "grad_norm": 0.0727330893278122,
      "learning_rate": 1.3306186497882897e-05,
      "loss": 0.0314,
      "step": 167500
    },
    {
      "epoch": 5.876783898453662,
      "grad_norm": 0.11006388068199158,
      "learning_rate": 1.3284270322869092e-05,
      "loss": 0.0298,
      "step": 167600
    },
    {
      "epoch": 5.880290332760616,
      "grad_norm": 0.06117648631334305,
      "learning_rate": 1.3262354147855282e-05,
      "loss": 0.0341,
      "step": 167700
    },
    {
      "epoch": 5.883796767067569,
      "grad_norm": 0.0793786346912384,
      "learning_rate": 1.3240437972841476e-05,
      "loss": 0.0297,
      "step": 167800
    },
    {
      "epoch": 5.887303201374523,
      "grad_norm": 0.4418065845966339,
      "learning_rate": 1.3218521797827668e-05,
      "loss": 0.0306,
      "step": 167900
    },
    {
      "epoch": 5.890809635681475,
      "grad_norm": 0.10126479715108871,
      "learning_rate": 1.3196605622813862e-05,
      "loss": 0.0266,
      "step": 168000
    },
    {
      "epoch": 5.894316069988429,
      "grad_norm": 0.26546013355255127,
      "learning_rate": 1.3174689447800054e-05,
      "loss": 0.0293,
      "step": 168100
    },
    {
      "epoch": 5.897822504295382,
      "grad_norm": 0.04635007679462433,
      "learning_rate": 1.3152773272786247e-05,
      "loss": 0.0293,
      "step": 168200
    },
    {
      "epoch": 5.901328938602335,
      "grad_norm": 0.24854335188865662,
      "learning_rate": 1.313085709777244e-05,
      "loss": 0.0286,
      "step": 168300
    },
    {
      "epoch": 5.904835372909289,
      "grad_norm": 0.191279336810112,
      "learning_rate": 1.3108940922758633e-05,
      "loss": 0.0292,
      "step": 168400
    },
    {
      "epoch": 5.9083418072162415,
      "grad_norm": 0.4302729368209839,
      "learning_rate": 1.3087024747744825e-05,
      "loss": 0.0287,
      "step": 168500
    },
    {
      "epoch": 5.911848241523195,
      "grad_norm": 0.1411896049976349,
      "learning_rate": 1.3065108572731019e-05,
      "loss": 0.0282,
      "step": 168600
    },
    {
      "epoch": 5.915354675830148,
      "grad_norm": 0.07218103855848312,
      "learning_rate": 1.3043192397717211e-05,
      "loss": 0.0304,
      "step": 168700
    },
    {
      "epoch": 5.918861110137102,
      "grad_norm": 0.1420239955186844,
      "learning_rate": 1.3021276222703405e-05,
      "loss": 0.0301,
      "step": 168800
    },
    {
      "epoch": 5.922367544444055,
      "grad_norm": 0.2978675365447998,
      "learning_rate": 1.2999360047689598e-05,
      "loss": 0.027,
      "step": 168900
    },
    {
      "epoch": 5.925873978751008,
      "grad_norm": 0.28670674562454224,
      "learning_rate": 1.297744387267579e-05,
      "loss": 0.0277,
      "step": 169000
    },
    {
      "epoch": 5.929380413057961,
      "grad_norm": 0.20761923491954803,
      "learning_rate": 1.2955527697661984e-05,
      "loss": 0.0308,
      "step": 169100
    },
    {
      "epoch": 5.932886847364915,
      "grad_norm": 0.25505414605140686,
      "learning_rate": 1.2933611522648176e-05,
      "loss": 0.0284,
      "step": 169200
    },
    {
      "epoch": 5.936393281671868,
      "grad_norm": 0.17732198536396027,
      "learning_rate": 1.291169534763437e-05,
      "loss": 0.0263,
      "step": 169300
    },
    {
      "epoch": 5.939899715978822,
      "grad_norm": 0.06232975423336029,
      "learning_rate": 1.2889779172620562e-05,
      "loss": 0.0266,
      "step": 169400
    },
    {
      "epoch": 5.9434061502857745,
      "grad_norm": 0.29749760031700134,
      "learning_rate": 1.2867862997606756e-05,
      "loss": 0.0307,
      "step": 169500
    },
    {
      "epoch": 5.946912584592727,
      "grad_norm": 0.08161797374486923,
      "learning_rate": 1.2845946822592948e-05,
      "loss": 0.0296,
      "step": 169600
    },
    {
      "epoch": 5.950419018899681,
      "grad_norm": 0.2026349902153015,
      "learning_rate": 1.2824030647579141e-05,
      "loss": 0.03,
      "step": 169700
    },
    {
      "epoch": 5.953925453206634,
      "grad_norm": 0.0907214879989624,
      "learning_rate": 1.2802114472565333e-05,
      "loss": 0.0298,
      "step": 169800
    },
    {
      "epoch": 5.957431887513588,
      "grad_norm": 0.033900562673807144,
      "learning_rate": 1.2780198297551527e-05,
      "loss": 0.0304,
      "step": 169900
    },
    {
      "epoch": 5.9609383218205405,
      "grad_norm": 0.29704979062080383,
      "learning_rate": 1.2758282122537717e-05,
      "loss": 0.027,
      "step": 170000
    },
    {
      "epoch": 5.964444756127494,
      "grad_norm": 0.048203229904174805,
      "learning_rate": 1.2736365947523913e-05,
      "loss": 0.0308,
      "step": 170100
    },
    {
      "epoch": 5.967951190434447,
      "grad_norm": 0.09145376086235046,
      "learning_rate": 1.2714449772510103e-05,
      "loss": 0.0295,
      "step": 170200
    },
    {
      "epoch": 5.971457624741401,
      "grad_norm": 0.09788506478071213,
      "learning_rate": 1.2692533597496298e-05,
      "loss": 0.028,
      "step": 170300
    },
    {
      "epoch": 5.974964059048354,
      "grad_norm": 0.06099351495504379,
      "learning_rate": 1.2670617422482489e-05,
      "loss": 0.0257,
      "step": 170400
    },
    {
      "epoch": 5.978470493355307,
      "grad_norm": 0.15818223357200623,
      "learning_rate": 1.2648701247468684e-05,
      "loss": 0.0285,
      "step": 170500
    },
    {
      "epoch": 5.98197692766226,
      "grad_norm": 0.2780562937259674,
      "learning_rate": 1.2626785072454875e-05,
      "loss": 0.0298,
      "step": 170600
    },
    {
      "epoch": 5.985483361969213,
      "grad_norm": 0.05644268915057182,
      "learning_rate": 1.2604868897441068e-05,
      "loss": 0.0243,
      "step": 170700
    },
    {
      "epoch": 5.988989796276167,
      "grad_norm": 0.10605122894048691,
      "learning_rate": 1.25831718841774e-05,
      "loss": 0.0291,
      "step": 170800
    },
    {
      "epoch": 5.99249623058312,
      "grad_norm": 0.23295514285564423,
      "learning_rate": 1.2561255709163591e-05,
      "loss": 0.0297,
      "step": 170900
    },
    {
      "epoch": 5.9960026648900735,
      "grad_norm": 0.09804816544055939,
      "learning_rate": 1.2539339534149785e-05,
      "loss": 0.029,
      "step": 171000
    },
    {
      "epoch": 5.999509099197026,
      "grad_norm": 0.30846279859542847,
      "learning_rate": 1.2517423359135977e-05,
      "loss": 0.0314,
      "step": 171100
    },
    {
      "epoch": 6.0,
      "eval_accuracy_macro_0.5": 0.9870914816856384,
      "eval_accuracy_micro_0.5": 0.9870914816856384,
      "eval_accuracy_weighted_0.5": 0.9808343648910522,
      "eval_f1_macro_0.5": 0.8253560066223145,
      "eval_f1_macro_0.6": 0.8188965916633606,
      "eval_f1_macro_0.7": 0.8019421696662903,
      "eval_f1_macro_0.8": 0.694938600063324,
      "eval_f1_micro_0.5": 0.837575376033783,
      "eval_f1_micro_0.6": 0.8322721123695374,
      "eval_f1_micro_0.7": 0.8177044987678528,
      "eval_f1_micro_0.8": 0.7874404788017273,
      "eval_f1_micro_0.9": 0.7172235250473022,
      "eval_f1_weighted_0.5": 0.8362290859222412,
      "eval_f1_weighted_0.6": 0.8289154767990112,
      "eval_f1_weighted_0.7": 0.8116413354873657,
      "eval_f1_weighted_0.8": 0.6976609230041504,
      "eval_loss": 0.029101813212037086,
      "eval_runtime": 406.8069,
      "eval_samples_per_second": 140.133,
      "eval_steps_per_second": 17.517,
      "step": 171114
    },
    {
      "epoch": 6.00301553350398,
      "grad_norm": 0.128794863820076,
      "learning_rate": 1.2495507184122169e-05,
      "loss": 0.0269,
      "step": 171200
    },
    {
      "epoch": 6.006521967810933,
      "grad_norm": 0.11448121070861816,
      "learning_rate": 1.2473591009108363e-05,
      "loss": 0.0302,
      "step": 171300
    },
    {
      "epoch": 6.010028402117887,
      "grad_norm": 0.1809672862291336,
      "learning_rate": 1.2451674834094555e-05,
      "loss": 0.0296,
      "step": 171400
    },
    {
      "epoch": 6.0135348364248395,
      "grad_norm": 0.1715921014547348,
      "learning_rate": 1.2429758659080749e-05,
      "loss": 0.0294,
      "step": 171500
    },
    {
      "epoch": 6.017041270731792,
      "grad_norm": 0.14248842000961304,
      "learning_rate": 1.240784248406694e-05,
      "loss": 0.0313,
      "step": 171600
    },
    {
      "epoch": 6.020547705038746,
      "grad_norm": 0.36184486746788025,
      "learning_rate": 1.2385926309053134e-05,
      "loss": 0.0292,
      "step": 171700
    },
    {
      "epoch": 6.024054139345699,
      "grad_norm": 0.11362739652395248,
      "learning_rate": 1.2364010134039326e-05,
      "loss": 0.027,
      "step": 171800
    },
    {
      "epoch": 6.027560573652653,
      "grad_norm": 0.2601054310798645,
      "learning_rate": 1.2342093959025518e-05,
      "loss": 0.0265,
      "step": 171900
    },
    {
      "epoch": 6.031067007959606,
      "grad_norm": 0.23016969859600067,
      "learning_rate": 1.2320177784011712e-05,
      "loss": 0.032,
      "step": 172000
    },
    {
      "epoch": 6.034573442266559,
      "grad_norm": 0.3062250018119812,
      "learning_rate": 1.2298261608997906e-05,
      "loss": 0.0284,
      "step": 172100
    },
    {
      "epoch": 6.038079876573512,
      "grad_norm": 0.12701836228370667,
      "learning_rate": 1.22763454339841e-05,
      "loss": 0.0281,
      "step": 172200
    },
    {
      "epoch": 6.041586310880466,
      "grad_norm": 0.18837252259254456,
      "learning_rate": 1.2254429258970291e-05,
      "loss": 0.0275,
      "step": 172300
    },
    {
      "epoch": 6.045092745187419,
      "grad_norm": 0.09879378229379654,
      "learning_rate": 1.2232513083956485e-05,
      "loss": 0.0299,
      "step": 172400
    },
    {
      "epoch": 6.0485991794943725,
      "grad_norm": 0.21025286614894867,
      "learning_rate": 1.2210596908942677e-05,
      "loss": 0.0313,
      "step": 172500
    },
    {
      "epoch": 6.052105613801325,
      "grad_norm": 0.13457058370113373,
      "learning_rate": 1.218868073392887e-05,
      "loss": 0.03,
      "step": 172600
    },
    {
      "epoch": 6.055612048108278,
      "grad_norm": 0.21642674505710602,
      "learning_rate": 1.2166764558915063e-05,
      "loss": 0.031,
      "step": 172700
    },
    {
      "epoch": 6.059118482415232,
      "grad_norm": 0.045709677040576935,
      "learning_rate": 1.2144848383901255e-05,
      "loss": 0.0288,
      "step": 172800
    },
    {
      "epoch": 6.062624916722185,
      "grad_norm": 0.2577734887599945,
      "learning_rate": 1.2122932208887449e-05,
      "loss": 0.0273,
      "step": 172900
    },
    {
      "epoch": 6.066131351029139,
      "grad_norm": 0.17467118799686432,
      "learning_rate": 1.210101603387364e-05,
      "loss": 0.0299,
      "step": 173000
    },
    {
      "epoch": 6.069637785336091,
      "grad_norm": 0.11526484787464142,
      "learning_rate": 1.2079099858859834e-05,
      "loss": 0.0272,
      "step": 173100
    },
    {
      "epoch": 6.073144219643045,
      "grad_norm": 0.2749192416667938,
      "learning_rate": 1.2057183683846026e-05,
      "loss": 0.0286,
      "step": 173200
    },
    {
      "epoch": 6.076650653949998,
      "grad_norm": 0.37405553460121155,
      "learning_rate": 1.203526750883222e-05,
      "loss": 0.0294,
      "step": 173300
    },
    {
      "epoch": 6.080157088256952,
      "grad_norm": 0.1727287322282791,
      "learning_rate": 1.2013351333818412e-05,
      "loss": 0.0289,
      "step": 173400
    },
    {
      "epoch": 6.083663522563905,
      "grad_norm": 0.2110367715358734,
      "learning_rate": 1.1991435158804606e-05,
      "loss": 0.0316,
      "step": 173500
    },
    {
      "epoch": 6.087169956870858,
      "grad_norm": 0.1784440279006958,
      "learning_rate": 1.1969518983790798e-05,
      "loss": 0.0302,
      "step": 173600
    },
    {
      "epoch": 6.090676391177811,
      "grad_norm": 0.26216545701026917,
      "learning_rate": 1.194760280877699e-05,
      "loss": 0.0298,
      "step": 173700
    },
    {
      "epoch": 6.094182825484765,
      "grad_norm": 0.14172615110874176,
      "learning_rate": 1.1925686633763184e-05,
      "loss": 0.0316,
      "step": 173800
    },
    {
      "epoch": 6.097689259791718,
      "grad_norm": 0.1694784313440323,
      "learning_rate": 1.1903770458749376e-05,
      "loss": 0.026,
      "step": 173900
    },
    {
      "epoch": 6.101195694098671,
      "grad_norm": 0.2982383966445923,
      "learning_rate": 1.188185428373557e-05,
      "loss": 0.028,
      "step": 174000
    },
    {
      "epoch": 6.104702128405624,
      "grad_norm": 0.08213788270950317,
      "learning_rate": 1.1859938108721761e-05,
      "loss": 0.0307,
      "step": 174100
    },
    {
      "epoch": 6.108208562712577,
      "grad_norm": 0.14974164962768555,
      "learning_rate": 1.1838021933707955e-05,
      "loss": 0.027,
      "step": 174200
    },
    {
      "epoch": 6.111714997019531,
      "grad_norm": 0.3682398498058319,
      "learning_rate": 1.1816105758694147e-05,
      "loss": 0.0301,
      "step": 174300
    },
    {
      "epoch": 6.115221431326484,
      "grad_norm": 0.2052428126335144,
      "learning_rate": 1.179418958368034e-05,
      "loss": 0.0293,
      "step": 174400
    },
    {
      "epoch": 6.118727865633438,
      "grad_norm": 0.183889701962471,
      "learning_rate": 1.1772273408666533e-05,
      "loss": 0.0307,
      "step": 174500
    },
    {
      "epoch": 6.1222342999403905,
      "grad_norm": 0.3127274513244629,
      "learning_rate": 1.1750357233652727e-05,
      "loss": 0.0291,
      "step": 174600
    },
    {
      "epoch": 6.125740734247344,
      "grad_norm": 0.1720450073480606,
      "learning_rate": 1.1728441058638919e-05,
      "loss": 0.0275,
      "step": 174700
    },
    {
      "epoch": 6.129247168554297,
      "grad_norm": 0.4885766804218292,
      "learning_rate": 1.170652488362511e-05,
      "loss": 0.0255,
      "step": 174800
    },
    {
      "epoch": 6.132753602861251,
      "grad_norm": 0.32382041215896606,
      "learning_rate": 1.1684827870361442e-05,
      "loss": 0.031,
      "step": 174900
    },
    {
      "epoch": 6.136260037168204,
      "grad_norm": 0.4956663250923157,
      "learning_rate": 1.1662911695347635e-05,
      "loss": 0.031,
      "step": 175000
    },
    {
      "epoch": 6.1397664714751565,
      "grad_norm": 0.2200935035943985,
      "learning_rate": 1.1640995520333827e-05,
      "loss": 0.0296,
      "step": 175100
    },
    {
      "epoch": 6.14327290578211,
      "grad_norm": 0.2593481242656708,
      "learning_rate": 1.1619079345320021e-05,
      "loss": 0.0298,
      "step": 175200
    },
    {
      "epoch": 6.146779340089063,
      "grad_norm": 0.29537031054496765,
      "learning_rate": 1.1597163170306213e-05,
      "loss": 0.0288,
      "step": 175300
    },
    {
      "epoch": 6.150285774396017,
      "grad_norm": 0.11876444518566132,
      "learning_rate": 1.1575246995292407e-05,
      "loss": 0.0276,
      "step": 175400
    },
    {
      "epoch": 6.15379220870297,
      "grad_norm": 0.1319258213043213,
      "learning_rate": 1.1553330820278599e-05,
      "loss": 0.0293,
      "step": 175500
    },
    {
      "epoch": 6.1572986430099235,
      "grad_norm": 0.18815414607524872,
      "learning_rate": 1.1531414645264791e-05,
      "loss": 0.0292,
      "step": 175600
    },
    {
      "epoch": 6.160805077316876,
      "grad_norm": 0.2676254212856293,
      "learning_rate": 1.1509498470250985e-05,
      "loss": 0.0321,
      "step": 175700
    },
    {
      "epoch": 6.16431151162383,
      "grad_norm": 0.4013996124267578,
      "learning_rate": 1.1487582295237177e-05,
      "loss": 0.029,
      "step": 175800
    },
    {
      "epoch": 6.167817945930783,
      "grad_norm": 0.14999902248382568,
      "learning_rate": 1.146566612022337e-05,
      "loss": 0.0293,
      "step": 175900
    },
    {
      "epoch": 6.171324380237737,
      "grad_norm": 0.12873290479183197,
      "learning_rate": 1.1443749945209562e-05,
      "loss": 0.0289,
      "step": 176000
    },
    {
      "epoch": 6.1748308145446895,
      "grad_norm": 0.204967200756073,
      "learning_rate": 1.1421833770195756e-05,
      "loss": 0.0301,
      "step": 176100
    },
    {
      "epoch": 6.178337248851642,
      "grad_norm": 0.1544911414384842,
      "learning_rate": 1.1399917595181948e-05,
      "loss": 0.0287,
      "step": 176200
    },
    {
      "epoch": 6.181843683158596,
      "grad_norm": 0.15894578397274017,
      "learning_rate": 1.1378001420168142e-05,
      "loss": 0.0267,
      "step": 176300
    },
    {
      "epoch": 6.185350117465549,
      "grad_norm": 0.16058611869812012,
      "learning_rate": 1.1356085245154334e-05,
      "loss": 0.028,
      "step": 176400
    },
    {
      "epoch": 6.188856551772503,
      "grad_norm": 0.07471933215856552,
      "learning_rate": 1.1334169070140528e-05,
      "loss": 0.0319,
      "step": 176500
    },
    {
      "epoch": 6.192362986079456,
      "grad_norm": 0.1851888746023178,
      "learning_rate": 1.131225289512672e-05,
      "loss": 0.0291,
      "step": 176600
    },
    {
      "epoch": 6.195869420386409,
      "grad_norm": 0.1807228922843933,
      "learning_rate": 1.1290336720112912e-05,
      "loss": 0.0289,
      "step": 176700
    },
    {
      "epoch": 6.199375854693362,
      "grad_norm": 0.46340811252593994,
      "learning_rate": 1.1268420545099105e-05,
      "loss": 0.029,
      "step": 176800
    },
    {
      "epoch": 6.202882289000316,
      "grad_norm": 0.3704393208026886,
      "learning_rate": 1.1246504370085297e-05,
      "loss": 0.0296,
      "step": 176900
    },
    {
      "epoch": 6.206388723307269,
      "grad_norm": 0.11835427582263947,
      "learning_rate": 1.1224588195071491e-05,
      "loss": 0.0293,
      "step": 177000
    },
    {
      "epoch": 6.2098951576142225,
      "grad_norm": 0.10820610076189041,
      "learning_rate": 1.1202672020057683e-05,
      "loss": 0.0289,
      "step": 177100
    },
    {
      "epoch": 6.213401591921175,
      "grad_norm": 0.329646497964859,
      "learning_rate": 1.1180975006794014e-05,
      "loss": 0.028,
      "step": 177200
    },
    {
      "epoch": 6.216908026228128,
      "grad_norm": 0.21618035435676575,
      "learning_rate": 1.1159058831780208e-05,
      "loss": 0.0273,
      "step": 177300
    },
    {
      "epoch": 6.220414460535082,
      "grad_norm": 0.3343527913093567,
      "learning_rate": 1.11371426567664e-05,
      "loss": 0.0278,
      "step": 177400
    },
    {
      "epoch": 6.223920894842035,
      "grad_norm": 0.170479416847229,
      "learning_rate": 1.1115226481752594e-05,
      "loss": 0.0273,
      "step": 177500
    },
    {
      "epoch": 6.2274273291489886,
      "grad_norm": 0.18171937763690948,
      "learning_rate": 1.1093310306738786e-05,
      "loss": 0.0273,
      "step": 177600
    },
    {
      "epoch": 6.230933763455941,
      "grad_norm": 0.06875540316104889,
      "learning_rate": 1.1071394131724978e-05,
      "loss": 0.026,
      "step": 177700
    },
    {
      "epoch": 6.234440197762895,
      "grad_norm": 0.16407832503318787,
      "learning_rate": 1.1049477956711171e-05,
      "loss": 0.0309,
      "step": 177800
    },
    {
      "epoch": 6.237946632069848,
      "grad_norm": 0.1986485868692398,
      "learning_rate": 1.1027561781697363e-05,
      "loss": 0.0281,
      "step": 177900
    },
    {
      "epoch": 6.241453066376802,
      "grad_norm": 0.08734200894832611,
      "learning_rate": 1.1005645606683557e-05,
      "loss": 0.0319,
      "step": 178000
    },
    {
      "epoch": 6.244959500683755,
      "grad_norm": 0.38028717041015625,
      "learning_rate": 1.0983729431669749e-05,
      "loss": 0.0316,
      "step": 178100
    },
    {
      "epoch": 6.248465934990708,
      "grad_norm": 0.11891687661409378,
      "learning_rate": 1.0961813256655943e-05,
      "loss": 0.0263,
      "step": 178200
    },
    {
      "epoch": 6.251972369297661,
      "grad_norm": 0.3574620485305786,
      "learning_rate": 1.0939897081642135e-05,
      "loss": 0.0281,
      "step": 178300
    },
    {
      "epoch": 6.255478803604614,
      "grad_norm": 0.216646209359169,
      "learning_rate": 1.0917980906628329e-05,
      "loss": 0.0261,
      "step": 178400
    },
    {
      "epoch": 6.258985237911568,
      "grad_norm": 0.32395562529563904,
      "learning_rate": 1.089628389336466e-05,
      "loss": 0.0263,
      "step": 178500
    },
    {
      "epoch": 6.262491672218521,
      "grad_norm": 0.2914092540740967,
      "learning_rate": 1.0874367718350852e-05,
      "loss": 0.0265,
      "step": 178600
    },
    {
      "epoch": 6.265998106525474,
      "grad_norm": 0.06052060052752495,
      "learning_rate": 1.0852451543337044e-05,
      "loss": 0.0285,
      "step": 178700
    },
    {
      "epoch": 6.269504540832427,
      "grad_norm": 0.11360013484954834,
      "learning_rate": 1.0830535368323237e-05,
      "loss": 0.0278,
      "step": 178800
    },
    {
      "epoch": 6.273010975139381,
      "grad_norm": 0.09944275766611099,
      "learning_rate": 1.080861919330943e-05,
      "loss": 0.029,
      "step": 178900
    },
    {
      "epoch": 6.276517409446334,
      "grad_norm": 0.2389327436685562,
      "learning_rate": 1.0786703018295623e-05,
      "loss": 0.0286,
      "step": 179000
    },
    {
      "epoch": 6.280023843753288,
      "grad_norm": 0.19910916686058044,
      "learning_rate": 1.0764786843281817e-05,
      "loss": 0.0287,
      "step": 179100
    },
    {
      "epoch": 6.2835302780602404,
      "grad_norm": 0.21561755239963531,
      "learning_rate": 1.074287066826801e-05,
      "loss": 0.0287,
      "step": 179200
    },
    {
      "epoch": 6.287036712367194,
      "grad_norm": 0.10400277376174927,
      "learning_rate": 1.0720954493254203e-05,
      "loss": 0.0292,
      "step": 179300
    },
    {
      "epoch": 6.290543146674147,
      "grad_norm": 0.22201161086559296,
      "learning_rate": 1.0699038318240395e-05,
      "loss": 0.0311,
      "step": 179400
    },
    {
      "epoch": 6.294049580981101,
      "grad_norm": 0.3380620777606964,
      "learning_rate": 1.0677122143226588e-05,
      "loss": 0.0306,
      "step": 179500
    },
    {
      "epoch": 6.297556015288054,
      "grad_norm": 0.5153025984764099,
      "learning_rate": 1.065520596821278e-05,
      "loss": 0.0302,
      "step": 179600
    },
    {
      "epoch": 6.3010624495950065,
      "grad_norm": 0.2515389025211334,
      "learning_rate": 1.0633289793198974e-05,
      "loss": 0.0315,
      "step": 179700
    },
    {
      "epoch": 6.30456888390196,
      "grad_norm": 0.16306373476982117,
      "learning_rate": 1.0611373618185166e-05,
      "loss": 0.0288,
      "step": 179800
    },
    {
      "epoch": 6.308075318208913,
      "grad_norm": 0.1675235629081726,
      "learning_rate": 1.058945744317136e-05,
      "loss": 0.0281,
      "step": 179900
    },
    {
      "epoch": 6.311581752515867,
      "grad_norm": 0.19140562415122986,
      "learning_rate": 1.0567541268157552e-05,
      "loss": 0.0244,
      "step": 180000
    },
    {
      "epoch": 6.31508818682282,
      "grad_norm": 0.22489459812641144,
      "learning_rate": 1.0545625093143745e-05,
      "loss": 0.0337,
      "step": 180100
    },
    {
      "epoch": 6.318594621129773,
      "grad_norm": 0.46800512075424194,
      "learning_rate": 1.0523708918129937e-05,
      "loss": 0.0273,
      "step": 180200
    },
    {
      "epoch": 6.322101055436726,
      "grad_norm": 0.22152824699878693,
      "learning_rate": 1.050179274311613e-05,
      "loss": 0.0286,
      "step": 180300
    },
    {
      "epoch": 6.32560748974368,
      "grad_norm": 0.09516900777816772,
      "learning_rate": 1.0479876568102323e-05,
      "loss": 0.0259,
      "step": 180400
    },
    {
      "epoch": 6.329113924050633,
      "grad_norm": 0.3088325560092926,
      "learning_rate": 1.0457960393088515e-05,
      "loss": 0.0278,
      "step": 180500
    },
    {
      "epoch": 6.332620358357586,
      "grad_norm": 0.16589581966400146,
      "learning_rate": 1.0436044218074709e-05,
      "loss": 0.0303,
      "step": 180600
    },
    {
      "epoch": 6.3361267926645395,
      "grad_norm": 0.10433382540941238,
      "learning_rate": 1.0414128043060901e-05,
      "loss": 0.0299,
      "step": 180700
    },
    {
      "epoch": 6.339633226971492,
      "grad_norm": 0.1609390825033188,
      "learning_rate": 1.0392211868047095e-05,
      "loss": 0.0296,
      "step": 180800
    },
    {
      "epoch": 6.343139661278446,
      "grad_norm": 0.3226489722728729,
      "learning_rate": 1.0370295693033287e-05,
      "loss": 0.0287,
      "step": 180900
    },
    {
      "epoch": 6.346646095585399,
      "grad_norm": 0.2607421875,
      "learning_rate": 1.034837951801948e-05,
      "loss": 0.026,
      "step": 181000
    },
    {
      "epoch": 6.350152529892353,
      "grad_norm": 0.05673781782388687,
      "learning_rate": 1.0326463343005672e-05,
      "loss": 0.0308,
      "step": 181100
    },
    {
      "epoch": 6.3536589641993055,
      "grad_norm": 0.33487802743911743,
      "learning_rate": 1.0304547167991866e-05,
      "loss": 0.0317,
      "step": 181200
    },
    {
      "epoch": 6.357165398506259,
      "grad_norm": 0.12433938682079315,
      "learning_rate": 1.0282630992978058e-05,
      "loss": 0.0301,
      "step": 181300
    },
    {
      "epoch": 6.360671832813212,
      "grad_norm": 0.29726091027259827,
      "learning_rate": 1.026071481796425e-05,
      "loss": 0.0308,
      "step": 181400
    },
    {
      "epoch": 6.364178267120166,
      "grad_norm": 0.2462201565504074,
      "learning_rate": 1.0238798642950444e-05,
      "loss": 0.0281,
      "step": 181500
    },
    {
      "epoch": 6.367684701427119,
      "grad_norm": 0.16926003992557526,
      "learning_rate": 1.0216882467936636e-05,
      "loss": 0.0272,
      "step": 181600
    },
    {
      "epoch": 6.3711911357340725,
      "grad_norm": 0.39694586396217346,
      "learning_rate": 1.019496629292283e-05,
      "loss": 0.0304,
      "step": 181700
    },
    {
      "epoch": 6.374697570041025,
      "grad_norm": 0.11589433997869492,
      "learning_rate": 1.0173050117909022e-05,
      "loss": 0.0275,
      "step": 181800
    },
    {
      "epoch": 6.378204004347978,
      "grad_norm": 0.0978676900267601,
      "learning_rate": 1.0151133942895215e-05,
      "loss": 0.0302,
      "step": 181900
    },
    {
      "epoch": 6.381710438654932,
      "grad_norm": 0.12890686094760895,
      "learning_rate": 1.0129217767881407e-05,
      "loss": 0.0325,
      "step": 182000
    },
    {
      "epoch": 6.385216872961885,
      "grad_norm": 0.23404638469219208,
      "learning_rate": 1.0107301592867601e-05,
      "loss": 0.0254,
      "step": 182100
    },
    {
      "epoch": 6.3887233072688385,
      "grad_norm": 0.2298852652311325,
      "learning_rate": 1.0085385417853793e-05,
      "loss": 0.0298,
      "step": 182200
    },
    {
      "epoch": 6.392229741575791,
      "grad_norm": 0.07107648253440857,
      "learning_rate": 1.0063469242839987e-05,
      "loss": 0.0292,
      "step": 182300
    },
    {
      "epoch": 6.395736175882745,
      "grad_norm": 0.15285636484622955,
      "learning_rate": 1.0041553067826179e-05,
      "loss": 0.031,
      "step": 182400
    },
    {
      "epoch": 6.399242610189698,
      "grad_norm": 0.3944602608680725,
      "learning_rate": 1.001963689281237e-05,
      "loss": 0.0277,
      "step": 182500
    },
    {
      "epoch": 6.402749044496652,
      "grad_norm": 0.1945972591638565,
      "learning_rate": 9.997720717798565e-06,
      "loss": 0.0285,
      "step": 182600
    },
    {
      "epoch": 6.406255478803605,
      "grad_norm": 0.32994356751441956,
      "learning_rate": 9.975804542784757e-06,
      "loss": 0.026,
      "step": 182700
    },
    {
      "epoch": 6.409761913110557,
      "grad_norm": 0.17115215957164764,
      "learning_rate": 9.95388836777095e-06,
      "loss": 0.0324,
      "step": 182800
    },
    {
      "epoch": 6.413268347417511,
      "grad_norm": 0.13781076669692993,
      "learning_rate": 9.931972192757142e-06,
      "loss": 0.0271,
      "step": 182900
    },
    {
      "epoch": 6.416774781724464,
      "grad_norm": 0.22083255648612976,
      "learning_rate": 9.910056017743336e-06,
      "loss": 0.0297,
      "step": 183000
    },
    {
      "epoch": 6.420281216031418,
      "grad_norm": 0.40679115056991577,
      "learning_rate": 9.888139842729528e-06,
      "loss": 0.0298,
      "step": 183100
    },
    {
      "epoch": 6.423787650338371,
      "grad_norm": 0.20418384671211243,
      "learning_rate": 9.866223667715722e-06,
      "loss": 0.03,
      "step": 183200
    },
    {
      "epoch": 6.427294084645324,
      "grad_norm": 0.18417853116989136,
      "learning_rate": 9.844307492701914e-06,
      "loss": 0.0287,
      "step": 183300
    },
    {
      "epoch": 6.430800518952277,
      "grad_norm": 0.20810459554195404,
      "learning_rate": 9.822391317688106e-06,
      "loss": 0.0283,
      "step": 183400
    },
    {
      "epoch": 6.434306953259231,
      "grad_norm": 0.19634869694709778,
      "learning_rate": 9.8004751426743e-06,
      "loss": 0.0305,
      "step": 183500
    },
    {
      "epoch": 6.437813387566184,
      "grad_norm": 0.28348031640052795,
      "learning_rate": 9.778558967660491e-06,
      "loss": 0.0284,
      "step": 183600
    },
    {
      "epoch": 6.441319821873138,
      "grad_norm": 0.23127628862857819,
      "learning_rate": 9.756642792646685e-06,
      "loss": 0.0294,
      "step": 183700
    },
    {
      "epoch": 6.44482625618009,
      "grad_norm": 0.4087866246700287,
      "learning_rate": 9.734726617632877e-06,
      "loss": 0.0286,
      "step": 183800
    },
    {
      "epoch": 6.448332690487044,
      "grad_norm": 0.3606420159339905,
      "learning_rate": 9.712810442619071e-06,
      "loss": 0.03,
      "step": 183900
    },
    {
      "epoch": 6.451839124793997,
      "grad_norm": 0.2524222433567047,
      "learning_rate": 9.690894267605263e-06,
      "loss": 0.0299,
      "step": 184000
    },
    {
      "epoch": 6.45534555910095,
      "grad_norm": 0.14073152840137482,
      "learning_rate": 9.668978092591457e-06,
      "loss": 0.0286,
      "step": 184100
    },
    {
      "epoch": 6.458851993407904,
      "grad_norm": 0.2995222806930542,
      "learning_rate": 9.647061917577649e-06,
      "loss": 0.0299,
      "step": 184200
    },
    {
      "epoch": 6.4623584277148565,
      "grad_norm": 0.08767469227313995,
      "learning_rate": 9.625145742563842e-06,
      "loss": 0.0292,
      "step": 184300
    },
    {
      "epoch": 6.46586486202181,
      "grad_norm": 0.2838055491447449,
      "learning_rate": 9.603229567550034e-06,
      "loss": 0.0286,
      "step": 184400
    },
    {
      "epoch": 6.469371296328763,
      "grad_norm": 0.1066296398639679,
      "learning_rate": 9.581313392536226e-06,
      "loss": 0.0295,
      "step": 184500
    },
    {
      "epoch": 6.472877730635717,
      "grad_norm": 0.1350388526916504,
      "learning_rate": 9.55939721752242e-06,
      "loss": 0.0313,
      "step": 184600
    },
    {
      "epoch": 6.47638416494267,
      "grad_norm": 0.1596706211566925,
      "learning_rate": 9.537700204258751e-06,
      "loss": 0.0296,
      "step": 184700
    },
    {
      "epoch": 6.479890599249623,
      "grad_norm": 0.5415809154510498,
      "learning_rate": 9.515784029244943e-06,
      "loss": 0.0301,
      "step": 184800
    },
    {
      "epoch": 6.483397033556576,
      "grad_norm": 0.12533824145793915,
      "learning_rate": 9.493867854231137e-06,
      "loss": 0.0287,
      "step": 184900
    },
    {
      "epoch": 6.486903467863529,
      "grad_norm": 0.18293848633766174,
      "learning_rate": 9.471951679217329e-06,
      "loss": 0.0299,
      "step": 185000
    },
    {
      "epoch": 6.490409902170483,
      "grad_norm": 0.15894460678100586,
      "learning_rate": 9.450035504203523e-06,
      "loss": 0.027,
      "step": 185100
    },
    {
      "epoch": 6.493916336477436,
      "grad_norm": 0.2424415796995163,
      "learning_rate": 9.428119329189716e-06,
      "loss": 0.0314,
      "step": 185200
    },
    {
      "epoch": 6.4974227707843895,
      "grad_norm": 0.29550066590309143,
      "learning_rate": 9.406422315926046e-06,
      "loss": 0.0308,
      "step": 185300
    },
    {
      "epoch": 6.500929205091342,
      "grad_norm": 0.14913128316402435,
      "learning_rate": 9.384506140912238e-06,
      "loss": 0.0329,
      "step": 185400
    },
    {
      "epoch": 6.504435639398296,
      "grad_norm": 0.09730344265699387,
      "learning_rate": 9.362589965898432e-06,
      "loss": 0.0299,
      "step": 185500
    },
    {
      "epoch": 6.507942073705249,
      "grad_norm": 0.09946567565202713,
      "learning_rate": 9.340673790884624e-06,
      "loss": 0.027,
      "step": 185600
    },
    {
      "epoch": 6.511448508012203,
      "grad_norm": 0.285144180059433,
      "learning_rate": 9.318757615870819e-06,
      "loss": 0.0279,
      "step": 185700
    },
    {
      "epoch": 6.5149549423191555,
      "grad_norm": 0.24297036230564117,
      "learning_rate": 9.296841440857011e-06,
      "loss": 0.0286,
      "step": 185800
    },
    {
      "epoch": 6.518461376626109,
      "grad_norm": 0.15401652455329895,
      "learning_rate": 9.274925265843205e-06,
      "loss": 0.0286,
      "step": 185900
    },
    {
      "epoch": 6.521967810933062,
      "grad_norm": 0.48153939843177795,
      "learning_rate": 9.253009090829397e-06,
      "loss": 0.029,
      "step": 186000
    },
    {
      "epoch": 6.525474245240016,
      "grad_norm": 0.14754313230514526,
      "learning_rate": 9.231092915815589e-06,
      "loss": 0.0305,
      "step": 186100
    },
    {
      "epoch": 6.528980679546969,
      "grad_norm": 0.16637226939201355,
      "learning_rate": 9.209176740801783e-06,
      "loss": 0.0281,
      "step": 186200
    },
    {
      "epoch": 6.532487113853922,
      "grad_norm": 0.15441414713859558,
      "learning_rate": 9.187260565787975e-06,
      "loss": 0.0268,
      "step": 186300
    },
    {
      "epoch": 6.535993548160875,
      "grad_norm": 0.2836185395717621,
      "learning_rate": 9.165344390774168e-06,
      "loss": 0.0285,
      "step": 186400
    },
    {
      "epoch": 6.539499982467828,
      "grad_norm": 0.2690630257129669,
      "learning_rate": 9.14342821576036e-06,
      "loss": 0.0272,
      "step": 186500
    },
    {
      "epoch": 6.543006416774782,
      "grad_norm": 0.1883821040391922,
      "learning_rate": 9.121512040746554e-06,
      "loss": 0.0287,
      "step": 186600
    },
    {
      "epoch": 6.546512851081735,
      "grad_norm": 0.10899659991264343,
      "learning_rate": 9.099595865732746e-06,
      "loss": 0.0262,
      "step": 186700
    },
    {
      "epoch": 6.5500192853886885,
      "grad_norm": 0.041474055498838425,
      "learning_rate": 9.07767969071894e-06,
      "loss": 0.0297,
      "step": 186800
    },
    {
      "epoch": 6.553525719695641,
      "grad_norm": 0.2093636840581894,
      "learning_rate": 9.055763515705132e-06,
      "loss": 0.0279,
      "step": 186900
    },
    {
      "epoch": 6.557032154002595,
      "grad_norm": 0.29926326870918274,
      "learning_rate": 9.033847340691325e-06,
      "loss": 0.0302,
      "step": 187000
    },
    {
      "epoch": 6.560538588309548,
      "grad_norm": 0.2833368182182312,
      "learning_rate": 9.011931165677517e-06,
      "loss": 0.0262,
      "step": 187100
    },
    {
      "epoch": 6.564045022616501,
      "grad_norm": 0.2766372561454773,
      "learning_rate": 8.99001499066371e-06,
      "loss": 0.03,
      "step": 187200
    },
    {
      "epoch": 6.5675514569234545,
      "grad_norm": 0.13556897640228271,
      "learning_rate": 8.968098815649903e-06,
      "loss": 0.0281,
      "step": 187300
    },
    {
      "epoch": 6.571057891230408,
      "grad_norm": 0.4320928454399109,
      "learning_rate": 8.946182640636095e-06,
      "loss": 0.0292,
      "step": 187400
    },
    {
      "epoch": 6.574564325537361,
      "grad_norm": 0.1379343867301941,
      "learning_rate": 8.924266465622289e-06,
      "loss": 0.0279,
      "step": 187500
    },
    {
      "epoch": 6.578070759844314,
      "grad_norm": 0.18663464486598969,
      "learning_rate": 8.902350290608481e-06,
      "loss": 0.0273,
      "step": 187600
    },
    {
      "epoch": 6.581577194151268,
      "grad_norm": 0.4037814140319824,
      "learning_rate": 8.880434115594675e-06,
      "loss": 0.0295,
      "step": 187700
    },
    {
      "epoch": 6.585083628458221,
      "grad_norm": 0.19486719369888306,
      "learning_rate": 8.858517940580867e-06,
      "loss": 0.0275,
      "step": 187800
    },
    {
      "epoch": 6.588590062765174,
      "grad_norm": 0.14924897253513336,
      "learning_rate": 8.83660176556706e-06,
      "loss": 0.0295,
      "step": 187900
    },
    {
      "epoch": 6.592096497072127,
      "grad_norm": 0.15981478989124298,
      "learning_rate": 8.814685590553252e-06,
      "loss": 0.0269,
      "step": 188000
    },
    {
      "epoch": 6.595602931379081,
      "grad_norm": 0.4766330420970917,
      "learning_rate": 8.792769415539444e-06,
      "loss": 0.0309,
      "step": 188100
    },
    {
      "epoch": 6.599109365686034,
      "grad_norm": 0.05778517946600914,
      "learning_rate": 8.770853240525638e-06,
      "loss": 0.0252,
      "step": 188200
    },
    {
      "epoch": 6.6026157999929875,
      "grad_norm": 0.14220814406871796,
      "learning_rate": 8.74893706551183e-06,
      "loss": 0.0278,
      "step": 188300
    },
    {
      "epoch": 6.60612223429994,
      "grad_norm": 0.49463728070259094,
      "learning_rate": 8.727020890498024e-06,
      "loss": 0.0278,
      "step": 188400
    },
    {
      "epoch": 6.609628668606893,
      "grad_norm": 0.10284364968538284,
      "learning_rate": 8.705104715484216e-06,
      "loss": 0.0287,
      "step": 188500
    },
    {
      "epoch": 6.613135102913847,
      "grad_norm": 0.18509946763515472,
      "learning_rate": 8.68318854047041e-06,
      "loss": 0.0287,
      "step": 188600
    },
    {
      "epoch": 6.6166415372208,
      "grad_norm": 0.10286218672990799,
      "learning_rate": 8.661272365456602e-06,
      "loss": 0.0302,
      "step": 188700
    },
    {
      "epoch": 6.620147971527754,
      "grad_norm": 0.11068445444107056,
      "learning_rate": 8.639356190442795e-06,
      "loss": 0.0306,
      "step": 188800
    },
    {
      "epoch": 6.623654405834706,
      "grad_norm": 0.1830475628376007,
      "learning_rate": 8.617440015428987e-06,
      "loss": 0.0309,
      "step": 188900
    },
    {
      "epoch": 6.62716084014166,
      "grad_norm": 0.0959060937166214,
      "learning_rate": 8.595523840415181e-06,
      "loss": 0.0308,
      "step": 189000
    },
    {
      "epoch": 6.630667274448613,
      "grad_norm": 0.3409790098667145,
      "learning_rate": 8.57382682715151e-06,
      "loss": 0.0285,
      "step": 189100
    },
    {
      "epoch": 6.634173708755567,
      "grad_norm": 0.788002073764801,
      "learning_rate": 8.551910652137704e-06,
      "loss": 0.0288,
      "step": 189200
    },
    {
      "epoch": 6.63768014306252,
      "grad_norm": 0.27069178223609924,
      "learning_rate": 8.529994477123896e-06,
      "loss": 0.0281,
      "step": 189300
    },
    {
      "epoch": 6.6411865773694725,
      "grad_norm": 0.2501152455806732,
      "learning_rate": 8.50807830211009e-06,
      "loss": 0.0292,
      "step": 189400
    },
    {
      "epoch": 6.644693011676426,
      "grad_norm": 0.29500612616539,
      "learning_rate": 8.486162127096282e-06,
      "loss": 0.0298,
      "step": 189500
    },
    {
      "epoch": 6.64819944598338,
      "grad_norm": 0.5143106579780579,
      "learning_rate": 8.464245952082476e-06,
      "loss": 0.0286,
      "step": 189600
    },
    {
      "epoch": 6.651705880290333,
      "grad_norm": 0.11068087071180344,
      "learning_rate": 8.442329777068668e-06,
      "loss": 0.0301,
      "step": 189700
    },
    {
      "epoch": 6.655212314597286,
      "grad_norm": 0.16092798113822937,
      "learning_rate": 8.420413602054861e-06,
      "loss": 0.0293,
      "step": 189800
    },
    {
      "epoch": 6.658718748904239,
      "grad_norm": 0.2543628513813019,
      "learning_rate": 8.398497427041053e-06,
      "loss": 0.0282,
      "step": 189900
    },
    {
      "epoch": 6.662225183211192,
      "grad_norm": 0.16270504891872406,
      "learning_rate": 8.376581252027247e-06,
      "loss": 0.031,
      "step": 190000
    },
    {
      "epoch": 6.665731617518146,
      "grad_norm": 0.21627265214920044,
      "learning_rate": 8.354665077013439e-06,
      "loss": 0.0276,
      "step": 190100
    },
    {
      "epoch": 6.669238051825099,
      "grad_norm": 0.2951508164405823,
      "learning_rate": 8.332748901999631e-06,
      "loss": 0.0303,
      "step": 190200
    },
    {
      "epoch": 6.672744486132053,
      "grad_norm": 0.21254929900169373,
      "learning_rate": 8.310832726985825e-06,
      "loss": 0.0306,
      "step": 190300
    },
    {
      "epoch": 6.6762509204390055,
      "grad_norm": 0.1033138558268547,
      "learning_rate": 8.288916551972017e-06,
      "loss": 0.0284,
      "step": 190400
    },
    {
      "epoch": 6.679757354745959,
      "grad_norm": 0.23258818686008453,
      "learning_rate": 8.26700037695821e-06,
      "loss": 0.0274,
      "step": 190500
    },
    {
      "epoch": 6.683263789052912,
      "grad_norm": 0.22503241896629333,
      "learning_rate": 8.245084201944403e-06,
      "loss": 0.0296,
      "step": 190600
    },
    {
      "epoch": 6.686770223359865,
      "grad_norm": 0.3126146197319031,
      "learning_rate": 8.223168026930596e-06,
      "loss": 0.0279,
      "step": 190700
    },
    {
      "epoch": 6.690276657666819,
      "grad_norm": 0.23388345539569855,
      "learning_rate": 8.201251851916788e-06,
      "loss": 0.0284,
      "step": 190800
    },
    {
      "epoch": 6.6937830919737715,
      "grad_norm": 0.14970888197422028,
      "learning_rate": 8.179335676902982e-06,
      "loss": 0.0289,
      "step": 190900
    },
    {
      "epoch": 6.697289526280725,
      "grad_norm": 0.6275883913040161,
      "learning_rate": 8.157419501889174e-06,
      "loss": 0.0268,
      "step": 191000
    },
    {
      "epoch": 6.700795960587678,
      "grad_norm": 0.1458289623260498,
      "learning_rate": 8.135503326875368e-06,
      "loss": 0.0317,
      "step": 191100
    },
    {
      "epoch": 6.704302394894632,
      "grad_norm": 0.19891075789928436,
      "learning_rate": 8.11358715186156e-06,
      "loss": 0.0278,
      "step": 191200
    },
    {
      "epoch": 6.707808829201585,
      "grad_norm": 0.18596011400222778,
      "learning_rate": 8.091670976847752e-06,
      "loss": 0.0305,
      "step": 191300
    },
    {
      "epoch": 6.7113152635085385,
      "grad_norm": 0.1898796409368515,
      "learning_rate": 8.069754801833946e-06,
      "loss": 0.0262,
      "step": 191400
    },
    {
      "epoch": 6.714821697815491,
      "grad_norm": 0.2762117087841034,
      "learning_rate": 8.047838626820138e-06,
      "loss": 0.0288,
      "step": 191500
    },
    {
      "epoch": 6.718328132122445,
      "grad_norm": 0.28332796692848206,
      "learning_rate": 8.025922451806331e-06,
      "loss": 0.0312,
      "step": 191600
    },
    {
      "epoch": 6.721834566429398,
      "grad_norm": 0.18745991587638855,
      "learning_rate": 8.004006276792525e-06,
      "loss": 0.0297,
      "step": 191700
    },
    {
      "epoch": 6.725341000736352,
      "grad_norm": 0.2566463351249695,
      "learning_rate": 7.982090101778717e-06,
      "loss": 0.0275,
      "step": 191800
    },
    {
      "epoch": 6.7288474350433045,
      "grad_norm": 0.21666644513607025,
      "learning_rate": 7.96017392676491e-06,
      "loss": 0.0268,
      "step": 191900
    },
    {
      "epoch": 6.732353869350257,
      "grad_norm": 0.2673751711845398,
      "learning_rate": 7.938257751751103e-06,
      "loss": 0.031,
      "step": 192000
    },
    {
      "epoch": 6.735860303657211,
      "grad_norm": 0.3800947070121765,
      "learning_rate": 7.916341576737296e-06,
      "loss": 0.0264,
      "step": 192100
    },
    {
      "epoch": 6.739366737964164,
      "grad_norm": 0.1894204020500183,
      "learning_rate": 7.894425401723488e-06,
      "loss": 0.0297,
      "step": 192200
    },
    {
      "epoch": 6.742873172271118,
      "grad_norm": 0.17116713523864746,
      "learning_rate": 7.872509226709682e-06,
      "loss": 0.025,
      "step": 192300
    },
    {
      "epoch": 6.746379606578071,
      "grad_norm": 0.20147395133972168,
      "learning_rate": 7.850593051695874e-06,
      "loss": 0.0279,
      "step": 192400
    },
    {
      "epoch": 6.749886040885024,
      "grad_norm": 0.3515545427799225,
      "learning_rate": 7.828676876682068e-06,
      "loss": 0.0273,
      "step": 192500
    },
    {
      "epoch": 6.753392475191977,
      "grad_norm": 0.29756850004196167,
      "learning_rate": 7.80676070166826e-06,
      "loss": 0.0291,
      "step": 192600
    },
    {
      "epoch": 6.756898909498931,
      "grad_norm": 0.26656079292297363,
      "learning_rate": 7.784844526654454e-06,
      "loss": 0.0306,
      "step": 192700
    },
    {
      "epoch": 6.760405343805884,
      "grad_norm": 0.19867049157619476,
      "learning_rate": 7.762928351640646e-06,
      "loss": 0.029,
      "step": 192800
    },
    {
      "epoch": 6.763911778112837,
      "grad_norm": 0.5497426986694336,
      "learning_rate": 7.741231338376977e-06,
      "loss": 0.0307,
      "step": 192900
    },
    {
      "epoch": 6.76741821241979,
      "grad_norm": 0.11664652824401855,
      "learning_rate": 7.719315163363169e-06,
      "loss": 0.0304,
      "step": 193000
    },
    {
      "epoch": 6.770924646726743,
      "grad_norm": 0.2975855767726898,
      "learning_rate": 7.697398988349362e-06,
      "loss": 0.0295,
      "step": 193100
    },
    {
      "epoch": 6.774431081033697,
      "grad_norm": 0.18616075813770294,
      "learning_rate": 7.675482813335554e-06,
      "loss": 0.0283,
      "step": 193200
    },
    {
      "epoch": 6.77793751534065,
      "grad_norm": 0.22952747344970703,
      "learning_rate": 7.653566638321748e-06,
      "loss": 0.0283,
      "step": 193300
    },
    {
      "epoch": 6.7814439496476036,
      "grad_norm": 0.6775988936424255,
      "learning_rate": 7.63165046330794e-06,
      "loss": 0.03,
      "step": 193400
    },
    {
      "epoch": 6.784950383954556,
      "grad_norm": 0.17340153455734253,
      "learning_rate": 7.609734288294133e-06,
      "loss": 0.0294,
      "step": 193500
    },
    {
      "epoch": 6.78845681826151,
      "grad_norm": 0.2124447077512741,
      "learning_rate": 7.587818113280326e-06,
      "loss": 0.0277,
      "step": 193600
    },
    {
      "epoch": 6.791963252568463,
      "grad_norm": 0.23677678406238556,
      "learning_rate": 7.565901938266519e-06,
      "loss": 0.0295,
      "step": 193700
    },
    {
      "epoch": 6.795469686875417,
      "grad_norm": 0.3717871308326721,
      "learning_rate": 7.543985763252712e-06,
      "loss": 0.0311,
      "step": 193800
    },
    {
      "epoch": 6.79897612118237,
      "grad_norm": 0.21550235152244568,
      "learning_rate": 7.5220695882389045e-06,
      "loss": 0.0291,
      "step": 193900
    },
    {
      "epoch": 6.802482555489323,
      "grad_norm": 0.14463891088962555,
      "learning_rate": 7.500153413225097e-06,
      "loss": 0.0312,
      "step": 194000
    },
    {
      "epoch": 6.805988989796276,
      "grad_norm": 0.08167813718318939,
      "learning_rate": 7.47823723821129e-06,
      "loss": 0.0284,
      "step": 194100
    },
    {
      "epoch": 6.809495424103229,
      "grad_norm": 0.10978884249925613,
      "learning_rate": 7.456321063197483e-06,
      "loss": 0.0287,
      "step": 194200
    },
    {
      "epoch": 6.813001858410183,
      "grad_norm": 0.10779336839914322,
      "learning_rate": 7.434404888183676e-06,
      "loss": 0.0266,
      "step": 194300
    },
    {
      "epoch": 6.816508292717136,
      "grad_norm": 0.3048625588417053,
      "learning_rate": 7.412488713169868e-06,
      "loss": 0.0285,
      "step": 194400
    },
    {
      "epoch": 6.820014727024089,
      "grad_norm": 0.1367320418357849,
      "learning_rate": 7.390572538156061e-06,
      "loss": 0.0273,
      "step": 194500
    },
    {
      "epoch": 6.823521161331042,
      "grad_norm": 0.3964700698852539,
      "learning_rate": 7.368656363142254e-06,
      "loss": 0.0285,
      "step": 194600
    },
    {
      "epoch": 6.827027595637996,
      "grad_norm": 0.09120349586009979,
      "learning_rate": 7.346740188128447e-06,
      "loss": 0.0276,
      "step": 194700
    },
    {
      "epoch": 6.830534029944949,
      "grad_norm": 0.28061264753341675,
      "learning_rate": 7.325043174864778e-06,
      "loss": 0.0279,
      "step": 194800
    },
    {
      "epoch": 6.834040464251903,
      "grad_norm": 0.10618411004543304,
      "learning_rate": 7.303126999850971e-06,
      "loss": 0.0277,
      "step": 194900
    },
    {
      "epoch": 6.8375468985588554,
      "grad_norm": 0.11974306404590607,
      "learning_rate": 7.2812108248371635e-06,
      "loss": 0.027,
      "step": 195000
    },
    {
      "epoch": 6.841053332865808,
      "grad_norm": 0.10532225668430328,
      "learning_rate": 7.259294649823356e-06,
      "loss": 0.024,
      "step": 195100
    },
    {
      "epoch": 6.844559767172762,
      "grad_norm": 0.3061350882053375,
      "learning_rate": 7.237378474809549e-06,
      "loss": 0.0305,
      "step": 195200
    },
    {
      "epoch": 6.848066201479715,
      "grad_norm": 0.45966821908950806,
      "learning_rate": 7.215462299795741e-06,
      "loss": 0.0251,
      "step": 195300
    },
    {
      "epoch": 6.851572635786669,
      "grad_norm": 0.14725185930728912,
      "learning_rate": 7.193546124781934e-06,
      "loss": 0.0317,
      "step": 195400
    },
    {
      "epoch": 6.8550790700936215,
      "grad_norm": 0.15082155168056488,
      "learning_rate": 7.171629949768127e-06,
      "loss": 0.026,
      "step": 195500
    },
    {
      "epoch": 6.858585504400575,
      "grad_norm": 0.12258677929639816,
      "learning_rate": 7.14971377475432e-06,
      "loss": 0.0283,
      "step": 195600
    },
    {
      "epoch": 6.862091938707528,
      "grad_norm": 0.44188183546066284,
      "learning_rate": 7.127797599740513e-06,
      "loss": 0.0313,
      "step": 195700
    },
    {
      "epoch": 6.865598373014482,
      "grad_norm": 0.18203942477703094,
      "learning_rate": 7.1058814247267055e-06,
      "loss": 0.0296,
      "step": 195800
    },
    {
      "epoch": 6.869104807321435,
      "grad_norm": 0.25082990527153015,
      "learning_rate": 7.083965249712898e-06,
      "loss": 0.028,
      "step": 195900
    },
    {
      "epoch": 6.872611241628388,
      "grad_norm": 0.10061338543891907,
      "learning_rate": 7.062049074699091e-06,
      "loss": 0.0297,
      "step": 196000
    },
    {
      "epoch": 6.876117675935341,
      "grad_norm": 0.29491880536079407,
      "learning_rate": 7.040132899685284e-06,
      "loss": 0.0302,
      "step": 196100
    },
    {
      "epoch": 6.879624110242295,
      "grad_norm": 0.2202741652727127,
      "learning_rate": 7.018216724671477e-06,
      "loss": 0.028,
      "step": 196200
    },
    {
      "epoch": 6.883130544549248,
      "grad_norm": 0.11985248327255249,
      "learning_rate": 6.99630054965767e-06,
      "loss": 0.028,
      "step": 196300
    },
    {
      "epoch": 6.886636978856201,
      "grad_norm": 0.13436101377010345,
      "learning_rate": 6.974384374643862e-06,
      "loss": 0.0256,
      "step": 196400
    },
    {
      "epoch": 6.8901434131631545,
      "grad_norm": 0.30375105142593384,
      "learning_rate": 6.952468199630055e-06,
      "loss": 0.0299,
      "step": 196500
    },
    {
      "epoch": 6.893649847470107,
      "grad_norm": 0.33364200592041016,
      "learning_rate": 6.930552024616248e-06,
      "loss": 0.0277,
      "step": 196600
    },
    {
      "epoch": 6.897156281777061,
      "grad_norm": 0.1959468126296997,
      "learning_rate": 6.9086358496024405e-06,
      "loss": 0.0296,
      "step": 196700
    },
    {
      "epoch": 6.900662716084014,
      "grad_norm": 0.26538321375846863,
      "learning_rate": 6.886719674588633e-06,
      "loss": 0.0278,
      "step": 196800
    },
    {
      "epoch": 6.904169150390968,
      "grad_norm": 0.24938325583934784,
      "learning_rate": 6.864803499574826e-06,
      "loss": 0.0292,
      "step": 196900
    },
    {
      "epoch": 6.9076755846979205,
      "grad_norm": 0.13779139518737793,
      "learning_rate": 6.842887324561019e-06,
      "loss": 0.0296,
      "step": 197000
    },
    {
      "epoch": 6.911182019004874,
      "grad_norm": 0.24321898818016052,
      "learning_rate": 6.820971149547212e-06,
      "loss": 0.0316,
      "step": 197100
    },
    {
      "epoch": 6.914688453311827,
      "grad_norm": 0.22487883269786835,
      "learning_rate": 6.799054974533405e-06,
      "loss": 0.0281,
      "step": 197200
    },
    {
      "epoch": 6.91819488761878,
      "grad_norm": 0.32957911491394043,
      "learning_rate": 6.777138799519598e-06,
      "loss": 0.0337,
      "step": 197300
    },
    {
      "epoch": 6.921701321925734,
      "grad_norm": 0.08940105885267258,
      "learning_rate": 6.75522262450579e-06,
      "loss": 0.0265,
      "step": 197400
    },
    {
      "epoch": 6.9252077562326875,
      "grad_norm": 0.19494397938251495,
      "learning_rate": 6.7333064494919825e-06,
      "loss": 0.0291,
      "step": 197500
    },
    {
      "epoch": 6.92871419053964,
      "grad_norm": 0.20754706859588623,
      "learning_rate": 6.711390274478175e-06,
      "loss": 0.0314,
      "step": 197600
    },
    {
      "epoch": 6.932220624846593,
      "grad_norm": 0.14201439917087555,
      "learning_rate": 6.689474099464368e-06,
      "loss": 0.0281,
      "step": 197700
    },
    {
      "epoch": 6.935727059153547,
      "grad_norm": 0.11072392016649246,
      "learning_rate": 6.667557924450561e-06,
      "loss": 0.027,
      "step": 197800
    },
    {
      "epoch": 6.9392334934605,
      "grad_norm": 0.20719404518604279,
      "learning_rate": 6.645641749436754e-06,
      "loss": 0.0284,
      "step": 197900
    },
    {
      "epoch": 6.9427399277674535,
      "grad_norm": 0.10682062059640884,
      "learning_rate": 6.623725574422947e-06,
      "loss": 0.0257,
      "step": 198000
    },
    {
      "epoch": 6.946246362074406,
      "grad_norm": 0.21906818449497223,
      "learning_rate": 6.60180939940914e-06,
      "loss": 0.0264,
      "step": 198100
    },
    {
      "epoch": 6.94975279638136,
      "grad_norm": 0.3078736364841461,
      "learning_rate": 6.5798932243953334e-06,
      "loss": 0.0261,
      "step": 198200
    },
    {
      "epoch": 6.953259230688313,
      "grad_norm": 0.2963207960128784,
      "learning_rate": 6.557977049381526e-06,
      "loss": 0.0302,
      "step": 198300
    },
    {
      "epoch": 6.956765664995267,
      "grad_norm": 0.2752041816711426,
      "learning_rate": 6.536060874367719e-06,
      "loss": 0.0307,
      "step": 198400
    },
    {
      "epoch": 6.96027209930222,
      "grad_norm": 0.16236501932144165,
      "learning_rate": 6.514144699353912e-06,
      "loss": 0.0269,
      "step": 198500
    },
    {
      "epoch": 6.963778533609172,
      "grad_norm": 0.1234871968626976,
      "learning_rate": 6.492228524340105e-06,
      "loss": 0.0322,
      "step": 198600
    },
    {
      "epoch": 6.967284967916126,
      "grad_norm": 0.14899389445781708,
      "learning_rate": 6.470312349326298e-06,
      "loss": 0.0279,
      "step": 198700
    },
    {
      "epoch": 6.970791402223079,
      "grad_norm": 0.10915832966566086,
      "learning_rate": 6.448396174312491e-06,
      "loss": 0.0273,
      "step": 198800
    },
    {
      "epoch": 6.974297836530033,
      "grad_norm": 0.39879629015922546,
      "learning_rate": 6.4264799992986835e-06,
      "loss": 0.0277,
      "step": 198900
    },
    {
      "epoch": 6.977804270836986,
      "grad_norm": 0.2749481797218323,
      "learning_rate": 6.404563824284876e-06,
      "loss": 0.0297,
      "step": 199000
    },
    {
      "epoch": 6.981310705143939,
      "grad_norm": 0.14519181847572327,
      "learning_rate": 6.382647649271068e-06,
      "loss": 0.0268,
      "step": 199100
    },
    {
      "epoch": 6.984817139450892,
      "grad_norm": 0.13760018348693848,
      "learning_rate": 6.360731474257261e-06,
      "loss": 0.029,
      "step": 199200
    },
    {
      "epoch": 6.988323573757846,
      "grad_norm": 0.16362550854682922,
      "learning_rate": 6.338815299243454e-06,
      "loss": 0.0272,
      "step": 199300
    },
    {
      "epoch": 6.991830008064799,
      "grad_norm": 0.1825629025697708,
      "learning_rate": 6.316899124229647e-06,
      "loss": 0.0312,
      "step": 199400
    },
    {
      "epoch": 6.995336442371752,
      "grad_norm": 0.31248265504837036,
      "learning_rate": 6.29498294921584e-06,
      "loss": 0.027,
      "step": 199500
    },
    {
      "epoch": 6.998842876678705,
      "grad_norm": 0.25688934326171875,
      "learning_rate": 6.273066774202033e-06,
      "loss": 0.0311,
      "step": 199600
    },
    {
      "epoch": 7.0,
      "eval_accuracy_macro_0.5": 0.9874199032783508,
      "eval_accuracy_micro_0.5": 0.987419843673706,
      "eval_accuracy_weighted_0.5": 0.9812861084938049,
      "eval_f1_macro_0.5": 0.827113687992096,
      "eval_f1_macro_0.6": 0.8195788860321045,
      "eval_f1_macro_0.7": 0.8010125756263733,
      "eval_f1_macro_0.8": 0.692413330078125,
      "eval_f1_micro_0.5": 0.8404468894004822,
      "eval_f1_micro_0.6": 0.8346546292304993,
      "eval_f1_micro_0.7": 0.8186517357826233,
      "eval_f1_micro_0.8": 0.7875017523765564,
      "eval_f1_micro_0.9": 0.7177667021751404,
      "eval_f1_weighted_0.5": 0.8383070230484009,
      "eval_f1_weighted_0.6": 0.8305681347846985,
      "eval_f1_weighted_0.7": 0.8117265105247498,
      "eval_f1_weighted_0.8": 0.6969303488731384,
      "eval_loss": 0.02820652723312378,
      "eval_runtime": 406.504,
      "eval_samples_per_second": 140.237,
      "eval_steps_per_second": 17.53,
      "step": 199633
    },
    {
      "epoch": 7.002349310985658,
      "grad_norm": 0.13341446220874786,
      "learning_rate": 6.2511505991882256e-06,
      "loss": 0.0294,
      "step": 199700
    },
    {
      "epoch": 7.005855745292612,
      "grad_norm": 0.1468234807252884,
      "learning_rate": 6.2292344241744184e-06,
      "loss": 0.0274,
      "step": 199800
    },
    {
      "epoch": 7.009362179599565,
      "grad_norm": 0.10470923781394958,
      "learning_rate": 6.207318249160611e-06,
      "loss": 0.028,
      "step": 199900
    },
    {
      "epoch": 7.012868613906519,
      "grad_norm": 0.14890436828136444,
      "learning_rate": 6.185402074146804e-06,
      "loss": 0.0289,
      "step": 200000
    },
    {
      "epoch": 7.0163750482134715,
      "grad_norm": 0.23134082555770874,
      "learning_rate": 6.163485899132997e-06,
      "loss": 0.0285,
      "step": 200100
    },
    {
      "epoch": 7.019881482520425,
      "grad_norm": 0.49688440561294556,
      "learning_rate": 6.141569724119189e-06,
      "loss": 0.0272,
      "step": 200200
    },
    {
      "epoch": 7.023387916827378,
      "grad_norm": 0.2884977459907532,
      "learning_rate": 6.119653549105382e-06,
      "loss": 0.0315,
      "step": 200300
    },
    {
      "epoch": 7.026894351134332,
      "grad_norm": 0.17477884888648987,
      "learning_rate": 6.097737374091575e-06,
      "loss": 0.0286,
      "step": 200400
    },
    {
      "epoch": 7.030400785441285,
      "grad_norm": 0.1927473247051239,
      "learning_rate": 6.075821199077768e-06,
      "loss": 0.0307,
      "step": 200500
    },
    {
      "epoch": 7.033907219748238,
      "grad_norm": 0.19022318720817566,
      "learning_rate": 6.0539050240639605e-06,
      "loss": 0.0265,
      "step": 200600
    },
    {
      "epoch": 7.037413654055191,
      "grad_norm": 0.4040856659412384,
      "learning_rate": 6.032208010800292e-06,
      "loss": 0.0276,
      "step": 200700
    },
    {
      "epoch": 7.040920088362144,
      "grad_norm": 0.16122989356517792,
      "learning_rate": 6.0102918357864845e-06,
      "loss": 0.0267,
      "step": 200800
    },
    {
      "epoch": 7.044426522669098,
      "grad_norm": 0.10525146126747131,
      "learning_rate": 5.988375660772677e-06,
      "loss": 0.0276,
      "step": 200900
    },
    {
      "epoch": 7.047932956976051,
      "grad_norm": 0.43552669882774353,
      "learning_rate": 5.96645948575887e-06,
      "loss": 0.0254,
      "step": 201000
    },
    {
      "epoch": 7.0514393912830045,
      "grad_norm": 0.2997797727584839,
      "learning_rate": 5.944543310745062e-06,
      "loss": 0.0296,
      "step": 201100
    },
    {
      "epoch": 7.054945825589957,
      "grad_norm": 0.25950151681900024,
      "learning_rate": 5.922627135731255e-06,
      "loss": 0.0318,
      "step": 201200
    },
    {
      "epoch": 7.058452259896911,
      "grad_norm": 0.12444047629833221,
      "learning_rate": 5.900710960717448e-06,
      "loss": 0.0307,
      "step": 201300
    },
    {
      "epoch": 7.061958694203864,
      "grad_norm": 0.11913608014583588,
      "learning_rate": 5.878794785703641e-06,
      "loss": 0.0277,
      "step": 201400
    },
    {
      "epoch": 7.065465128510818,
      "grad_norm": 0.4335438013076782,
      "learning_rate": 5.856878610689834e-06,
      "loss": 0.0276,
      "step": 201500
    },
    {
      "epoch": 7.0689715628177705,
      "grad_norm": 0.2232704907655716,
      "learning_rate": 5.8349624356760266e-06,
      "loss": 0.027,
      "step": 201600
    },
    {
      "epoch": 7.072477997124724,
      "grad_norm": 0.14461492002010345,
      "learning_rate": 5.8130462606622194e-06,
      "loss": 0.0283,
      "step": 201700
    },
    {
      "epoch": 7.075984431431677,
      "grad_norm": 0.11733852326869965,
      "learning_rate": 5.791130085648412e-06,
      "loss": 0.0293,
      "step": 201800
    },
    {
      "epoch": 7.07949086573863,
      "grad_norm": 0.1627795398235321,
      "learning_rate": 5.769213910634605e-06,
      "loss": 0.026,
      "step": 201900
    },
    {
      "epoch": 7.082997300045584,
      "grad_norm": 0.4652884602546692,
      "learning_rate": 5.747297735620798e-06,
      "loss": 0.0252,
      "step": 202000
    },
    {
      "epoch": 7.0865037343525366,
      "grad_norm": 0.18128250539302826,
      "learning_rate": 5.725381560606991e-06,
      "loss": 0.0295,
      "step": 202100
    },
    {
      "epoch": 7.09001016865949,
      "grad_norm": 0.4184546172618866,
      "learning_rate": 5.703465385593183e-06,
      "loss": 0.0292,
      "step": 202200
    },
    {
      "epoch": 7.093516602966443,
      "grad_norm": 0.22444933652877808,
      "learning_rate": 5.681549210579376e-06,
      "loss": 0.0302,
      "step": 202300
    },
    {
      "epoch": 7.097023037273397,
      "grad_norm": 0.23034138977527618,
      "learning_rate": 5.659633035565569e-06,
      "loss": 0.031,
      "step": 202400
    },
    {
      "epoch": 7.10052947158035,
      "grad_norm": 0.2529158294200897,
      "learning_rate": 5.6377168605517615e-06,
      "loss": 0.0305,
      "step": 202500
    },
    {
      "epoch": 7.1040359058873035,
      "grad_norm": 0.24737131595611572,
      "learning_rate": 5.615800685537954e-06,
      "loss": 0.0298,
      "step": 202600
    },
    {
      "epoch": 7.107542340194256,
      "grad_norm": 0.11036665737628937,
      "learning_rate": 5.593884510524147e-06,
      "loss": 0.0301,
      "step": 202700
    },
    {
      "epoch": 7.11104877450121,
      "grad_norm": 0.2436961978673935,
      "learning_rate": 5.57196833551034e-06,
      "loss": 0.0282,
      "step": 202800
    },
    {
      "epoch": 7.114555208808163,
      "grad_norm": 0.3981580436229706,
      "learning_rate": 5.550052160496534e-06,
      "loss": 0.0312,
      "step": 202900
    },
    {
      "epoch": 7.118061643115116,
      "grad_norm": 0.08595912158489227,
      "learning_rate": 5.528135985482726e-06,
      "loss": 0.0296,
      "step": 203000
    },
    {
      "epoch": 7.1215680774220695,
      "grad_norm": 0.3899953365325928,
      "learning_rate": 5.506219810468919e-06,
      "loss": 0.0252,
      "step": 203100
    },
    {
      "epoch": 7.125074511729022,
      "grad_norm": 0.25758790969848633,
      "learning_rate": 5.4843036354551115e-06,
      "loss": 0.0272,
      "step": 203200
    },
    {
      "epoch": 7.128580946035976,
      "grad_norm": 0.12208131700754166,
      "learning_rate": 5.462387460441304e-06,
      "loss": 0.0245,
      "step": 203300
    },
    {
      "epoch": 7.132087380342929,
      "grad_norm": 0.13131769001483917,
      "learning_rate": 5.440471285427497e-06,
      "loss": 0.028,
      "step": 203400
    },
    {
      "epoch": 7.135593814649883,
      "grad_norm": 0.16223828494548798,
      "learning_rate": 5.41855511041369e-06,
      "loss": 0.0278,
      "step": 203500
    },
    {
      "epoch": 7.139100248956836,
      "grad_norm": 0.1808629333972931,
      "learning_rate": 5.396638935399883e-06,
      "loss": 0.0279,
      "step": 203600
    },
    {
      "epoch": 7.142606683263789,
      "grad_norm": 0.11689147353172302,
      "learning_rate": 5.374722760386076e-06,
      "loss": 0.0305,
      "step": 203700
    },
    {
      "epoch": 7.146113117570742,
      "grad_norm": 0.16489556431770325,
      "learning_rate": 5.352806585372269e-06,
      "loss": 0.0283,
      "step": 203800
    },
    {
      "epoch": 7.149619551877696,
      "grad_norm": 0.05929391086101532,
      "learning_rate": 5.330890410358462e-06,
      "loss": 0.0271,
      "step": 203900
    },
    {
      "epoch": 7.153125986184649,
      "grad_norm": 0.08356200158596039,
      "learning_rate": 5.3089742353446545e-06,
      "loss": 0.0307,
      "step": 204000
    },
    {
      "epoch": 7.1566324204916025,
      "grad_norm": 0.17004317045211792,
      "learning_rate": 5.2870580603308465e-06,
      "loss": 0.0288,
      "step": 204100
    },
    {
      "epoch": 7.160138854798555,
      "grad_norm": 0.24448227882385254,
      "learning_rate": 5.265141885317039e-06,
      "loss": 0.0272,
      "step": 204200
    },
    {
      "epoch": 7.163645289105508,
      "grad_norm": 0.39095598459243774,
      "learning_rate": 5.243225710303232e-06,
      "loss": 0.0296,
      "step": 204300
    },
    {
      "epoch": 7.167151723412462,
      "grad_norm": 0.17365983128547668,
      "learning_rate": 5.221309535289425e-06,
      "loss": 0.0269,
      "step": 204400
    },
    {
      "epoch": 7.170658157719415,
      "grad_norm": 0.18416254222393036,
      "learning_rate": 5.199393360275618e-06,
      "loss": 0.0292,
      "step": 204500
    },
    {
      "epoch": 7.174164592026369,
      "grad_norm": 0.08136743307113647,
      "learning_rate": 5.177696347011949e-06,
      "loss": 0.0268,
      "step": 204600
    },
    {
      "epoch": 7.177671026333321,
      "grad_norm": 0.19475068151950836,
      "learning_rate": 5.155780171998142e-06,
      "loss": 0.0287,
      "step": 204700
    },
    {
      "epoch": 7.181177460640275,
      "grad_norm": 0.1938997507095337,
      "learning_rate": 5.133863996984335e-06,
      "loss": 0.028,
      "step": 204800
    },
    {
      "epoch": 7.184683894947228,
      "grad_norm": 0.5289090275764465,
      "learning_rate": 5.111947821970528e-06,
      "loss": 0.0267,
      "step": 204900
    },
    {
      "epoch": 7.188190329254182,
      "grad_norm": 0.08644946664571762,
      "learning_rate": 5.09003164695672e-06,
      "loss": 0.029,
      "step": 205000
    },
    {
      "epoch": 7.191696763561135,
      "grad_norm": 0.2512880265712738,
      "learning_rate": 5.0681154719429125e-06,
      "loss": 0.0284,
      "step": 205100
    },
    {
      "epoch": 7.1952031978680875,
      "grad_norm": 0.18728336691856384,
      "learning_rate": 5.046199296929105e-06,
      "loss": 0.029,
      "step": 205200
    },
    {
      "epoch": 7.198709632175041,
      "grad_norm": 0.4903180003166199,
      "learning_rate": 5.024283121915298e-06,
      "loss": 0.0296,
      "step": 205300
    },
    {
      "epoch": 7.202216066481994,
      "grad_norm": 0.2500227093696594,
      "learning_rate": 5.002366946901491e-06,
      "loss": 0.0276,
      "step": 205400
    },
    {
      "epoch": 7.205722500788948,
      "grad_norm": 0.10612671822309494,
      "learning_rate": 4.980450771887684e-06,
      "loss": 0.0318,
      "step": 205500
    },
    {
      "epoch": 7.209228935095901,
      "grad_norm": 0.22141854465007782,
      "learning_rate": 4.958534596873877e-06,
      "loss": 0.0291,
      "step": 205600
    },
    {
      "epoch": 7.212735369402854,
      "grad_norm": 0.12854190170764923,
      "learning_rate": 4.93661842186007e-06,
      "loss": 0.0302,
      "step": 205700
    },
    {
      "epoch": 7.216241803709807,
      "grad_norm": 0.2798698842525482,
      "learning_rate": 4.914702246846263e-06,
      "loss": 0.0269,
      "step": 205800
    },
    {
      "epoch": 7.219748238016761,
      "grad_norm": 0.1681804656982422,
      "learning_rate": 4.8927860718324555e-06,
      "loss": 0.0288,
      "step": 205900
    },
    {
      "epoch": 7.223254672323714,
      "grad_norm": 0.1435975283384323,
      "learning_rate": 4.870869896818648e-06,
      "loss": 0.0266,
      "step": 206000
    },
    {
      "epoch": 7.226761106630668,
      "grad_norm": 0.24929490685462952,
      "learning_rate": 4.848953721804841e-06,
      "loss": 0.0288,
      "step": 206100
    },
    {
      "epoch": 7.2302675409376205,
      "grad_norm": 0.16108648478984833,
      "learning_rate": 4.827037546791034e-06,
      "loss": 0.0237,
      "step": 206200
    },
    {
      "epoch": 7.233773975244574,
      "grad_norm": 0.20690271258354187,
      "learning_rate": 4.805121371777227e-06,
      "loss": 0.0261,
      "step": 206300
    },
    {
      "epoch": 7.237280409551527,
      "grad_norm": 0.8147121667861938,
      "learning_rate": 4.78320519676342e-06,
      "loss": 0.0277,
      "step": 206400
    },
    {
      "epoch": 7.24078684385848,
      "grad_norm": 0.21370549499988556,
      "learning_rate": 4.761289021749613e-06,
      "loss": 0.0276,
      "step": 206500
    },
    {
      "epoch": 7.244293278165434,
      "grad_norm": 0.38793709874153137,
      "learning_rate": 4.7393728467358055e-06,
      "loss": 0.0295,
      "step": 206600
    },
    {
      "epoch": 7.2477997124723865,
      "grad_norm": 0.2440984845161438,
      "learning_rate": 4.717456671721998e-06,
      "loss": 0.0303,
      "step": 206700
    },
    {
      "epoch": 7.25130614677934,
      "grad_norm": 0.28126028180122375,
      "learning_rate": 4.695540496708191e-06,
      "loss": 0.0277,
      "step": 206800
    },
    {
      "epoch": 7.254812581086293,
      "grad_norm": 0.12541402876377106,
      "learning_rate": 4.673624321694384e-06,
      "loss": 0.0277,
      "step": 206900
    },
    {
      "epoch": 7.258319015393247,
      "grad_norm": 0.17261996865272522,
      "learning_rate": 4.651708146680576e-06,
      "loss": 0.0297,
      "step": 207000
    },
    {
      "epoch": 7.2618254497002,
      "grad_norm": 0.2624281048774719,
      "learning_rate": 4.630011133416907e-06,
      "loss": 0.0282,
      "step": 207100
    },
    {
      "epoch": 7.2653318840071535,
      "grad_norm": 0.534837007522583,
      "learning_rate": 4.6080949584031e-06,
      "loss": 0.0282,
      "step": 207200
    },
    {
      "epoch": 7.268838318314106,
      "grad_norm": 0.2175888568162918,
      "learning_rate": 4.586178783389293e-06,
      "loss": 0.0267,
      "step": 207300
    },
    {
      "epoch": 7.27234475262106,
      "grad_norm": 0.247919961810112,
      "learning_rate": 4.564262608375486e-06,
      "loss": 0.0258,
      "step": 207400
    },
    {
      "epoch": 7.275851186928013,
      "grad_norm": 0.06179654598236084,
      "learning_rate": 4.542346433361679e-06,
      "loss": 0.0308,
      "step": 207500
    },
    {
      "epoch": 7.279357621234966,
      "grad_norm": 0.27590563893318176,
      "learning_rate": 4.52064942009801e-06,
      "loss": 0.0276,
      "step": 207600
    },
    {
      "epoch": 7.2828640555419195,
      "grad_norm": 0.09943944215774536,
      "learning_rate": 4.498733245084203e-06,
      "loss": 0.0295,
      "step": 207700
    },
    {
      "epoch": 7.286370489848872,
      "grad_norm": 0.10648509860038757,
      "learning_rate": 4.476817070070395e-06,
      "loss": 0.0269,
      "step": 207800
    },
    {
      "epoch": 7.289876924155826,
      "grad_norm": 0.14390145242214203,
      "learning_rate": 4.454900895056588e-06,
      "loss": 0.0274,
      "step": 207900
    },
    {
      "epoch": 7.293383358462779,
      "grad_norm": 0.19459189474582672,
      "learning_rate": 4.4329847200427805e-06,
      "loss": 0.0304,
      "step": 208000
    },
    {
      "epoch": 7.296889792769733,
      "grad_norm": 0.4088968336582184,
      "learning_rate": 4.411068545028973e-06,
      "loss": 0.031,
      "step": 208100
    },
    {
      "epoch": 7.300396227076686,
      "grad_norm": 0.1684895157814026,
      "learning_rate": 4.389152370015166e-06,
      "loss": 0.028,
      "step": 208200
    },
    {
      "epoch": 7.303902661383639,
      "grad_norm": 0.07852062582969666,
      "learning_rate": 4.367236195001359e-06,
      "loss": 0.032,
      "step": 208300
    },
    {
      "epoch": 7.307409095690592,
      "grad_norm": 0.09397368878126144,
      "learning_rate": 4.345320019987552e-06,
      "loss": 0.0291,
      "step": 208400
    },
    {
      "epoch": 7.310915529997546,
      "grad_norm": 0.2824840247631073,
      "learning_rate": 4.323403844973745e-06,
      "loss": 0.0256,
      "step": 208500
    },
    {
      "epoch": 7.314421964304499,
      "grad_norm": 0.24191874265670776,
      "learning_rate": 4.301487669959938e-06,
      "loss": 0.0278,
      "step": 208600
    },
    {
      "epoch": 7.317928398611452,
      "grad_norm": 0.050817374140024185,
      "learning_rate": 4.2795714949461305e-06,
      "loss": 0.0271,
      "step": 208700
    },
    {
      "epoch": 7.321434832918405,
      "grad_norm": 0.33439725637435913,
      "learning_rate": 4.257655319932323e-06,
      "loss": 0.0299,
      "step": 208800
    },
    {
      "epoch": 7.324941267225358,
      "grad_norm": 0.3150347173213959,
      "learning_rate": 4.235739144918515e-06,
      "loss": 0.0307,
      "step": 208900
    },
    {
      "epoch": 7.328447701532312,
      "grad_norm": 0.18764494359493256,
      "learning_rate": 4.213822969904708e-06,
      "loss": 0.027,
      "step": 209000
    },
    {
      "epoch": 7.331954135839265,
      "grad_norm": 0.29239800572395325,
      "learning_rate": 4.191906794890901e-06,
      "loss": 0.028,
      "step": 209100
    },
    {
      "epoch": 7.3354605701462186,
      "grad_norm": 0.18162380158901215,
      "learning_rate": 4.169990619877094e-06,
      "loss": 0.0303,
      "step": 209200
    },
    {
      "epoch": 7.338967004453171,
      "grad_norm": 0.14075873792171478,
      "learning_rate": 4.148074444863287e-06,
      "loss": 0.0301,
      "step": 209300
    },
    {
      "epoch": 7.342473438760125,
      "grad_norm": 0.30547434091567993,
      "learning_rate": 4.12615826984948e-06,
      "loss": 0.0294,
      "step": 209400
    },
    {
      "epoch": 7.345979873067078,
      "grad_norm": 0.28013408184051514,
      "learning_rate": 4.104242094835673e-06,
      "loss": 0.0325,
      "step": 209500
    },
    {
      "epoch": 7.349486307374032,
      "grad_norm": 0.26418620347976685,
      "learning_rate": 4.0823259198218654e-06,
      "loss": 0.0263,
      "step": 209600
    },
    {
      "epoch": 7.352992741680985,
      "grad_norm": 0.32444682717323303,
      "learning_rate": 4.060409744808058e-06,
      "loss": 0.0272,
      "step": 209700
    },
    {
      "epoch": 7.3564991759879375,
      "grad_norm": 0.1345350444316864,
      "learning_rate": 4.038493569794251e-06,
      "loss": 0.0282,
      "step": 209800
    },
    {
      "epoch": 7.360005610294891,
      "grad_norm": 0.09551767259836197,
      "learning_rate": 4.016577394780444e-06,
      "loss": 0.0282,
      "step": 209900
    },
    {
      "epoch": 7.363512044601844,
      "grad_norm": 0.2928592264652252,
      "learning_rate": 3.994661219766637e-06,
      "loss": 0.027,
      "step": 210000
    },
    {
      "epoch": 7.367018478908798,
      "grad_norm": 0.3760584592819214,
      "learning_rate": 3.97274504475283e-06,
      "loss": 0.0261,
      "step": 210100
    },
    {
      "epoch": 7.370524913215751,
      "grad_norm": 0.17772220075130463,
      "learning_rate": 3.950828869739023e-06,
      "loss": 0.0301,
      "step": 210200
    },
    {
      "epoch": 7.374031347522704,
      "grad_norm": 0.39983096718788147,
      "learning_rate": 3.9289126947252155e-06,
      "loss": 0.027,
      "step": 210300
    },
    {
      "epoch": 7.377537781829657,
      "grad_norm": 0.6284992098808289,
      "learning_rate": 3.906996519711408e-06,
      "loss": 0.0285,
      "step": 210400
    },
    {
      "epoch": 7.381044216136611,
      "grad_norm": 0.2750774323940277,
      "learning_rate": 3.885080344697601e-06,
      "loss": 0.0288,
      "step": 210500
    },
    {
      "epoch": 7.384550650443564,
      "grad_norm": 0.40821999311447144,
      "learning_rate": 3.863164169683794e-06,
      "loss": 0.0278,
      "step": 210600
    },
    {
      "epoch": 7.388057084750518,
      "grad_norm": 0.26478949189186096,
      "learning_rate": 3.841247994669987e-06,
      "loss": 0.0298,
      "step": 210700
    },
    {
      "epoch": 7.39156351905747,
      "grad_norm": 0.3522239029407501,
      "learning_rate": 3.819331819656179e-06,
      "loss": 0.0278,
      "step": 210800
    },
    {
      "epoch": 7.395069953364423,
      "grad_norm": 0.41900569200515747,
      "learning_rate": 3.7974156446423723e-06,
      "loss": 0.0271,
      "step": 210900
    },
    {
      "epoch": 7.398576387671377,
      "grad_norm": 0.3086790144443512,
      "learning_rate": 3.7754994696285647e-06,
      "loss": 0.0303,
      "step": 211000
    },
    {
      "epoch": 7.40208282197833,
      "grad_norm": 0.09383147209882736,
      "learning_rate": 3.7535832946147576e-06,
      "loss": 0.0295,
      "step": 211100
    },
    {
      "epoch": 7.405589256285284,
      "grad_norm": 0.2239243984222412,
      "learning_rate": 3.7316671196009504e-06,
      "loss": 0.031,
      "step": 211200
    },
    {
      "epoch": 7.4090956905922365,
      "grad_norm": 0.1542387455701828,
      "learning_rate": 3.7097509445871433e-06,
      "loss": 0.0291,
      "step": 211300
    },
    {
      "epoch": 7.41260212489919,
      "grad_norm": 0.16606378555297852,
      "learning_rate": 3.687834769573336e-06,
      "loss": 0.0273,
      "step": 211400
    },
    {
      "epoch": 7.416108559206143,
      "grad_norm": 0.19623126089572906,
      "learning_rate": 3.665918594559529e-06,
      "loss": 0.026,
      "step": 211500
    },
    {
      "epoch": 7.419614993513097,
      "grad_norm": 0.2562004327774048,
      "learning_rate": 3.6440024195457215e-06,
      "loss": 0.0322,
      "step": 211600
    },
    {
      "epoch": 7.42312142782005,
      "grad_norm": 0.09192058444023132,
      "learning_rate": 3.6220862445319143e-06,
      "loss": 0.0229,
      "step": 211700
    },
    {
      "epoch": 7.426627862127003,
      "grad_norm": 0.14174696803092957,
      "learning_rate": 3.600170069518107e-06,
      "loss": 0.0287,
      "step": 211800
    },
    {
      "epoch": 7.430134296433956,
      "grad_norm": 0.1354394257068634,
      "learning_rate": 3.5782538945043e-06,
      "loss": 0.0294,
      "step": 211900
    },
    {
      "epoch": 7.43364073074091,
      "grad_norm": 0.22967340052127838,
      "learning_rate": 3.556337719490493e-06,
      "loss": 0.0268,
      "step": 212000
    },
    {
      "epoch": 7.437147165047863,
      "grad_norm": 0.27609550952911377,
      "learning_rate": 3.5344215444766854e-06,
      "loss": 0.0278,
      "step": 212100
    },
    {
      "epoch": 7.440653599354816,
      "grad_norm": 0.1519378423690796,
      "learning_rate": 3.5125053694628782e-06,
      "loss": 0.0281,
      "step": 212200
    },
    {
      "epoch": 7.4441600336617695,
      "grad_norm": 0.18006335198879242,
      "learning_rate": 3.490589194449071e-06,
      "loss": 0.0277,
      "step": 212300
    },
    {
      "epoch": 7.447666467968722,
      "grad_norm": 0.1481940746307373,
      "learning_rate": 3.468673019435264e-06,
      "loss": 0.0254,
      "step": 212400
    },
    {
      "epoch": 7.451172902275676,
      "grad_norm": 0.1375240832567215,
      "learning_rate": 3.446756844421457e-06,
      "loss": 0.0289,
      "step": 212500
    },
    {
      "epoch": 7.454679336582629,
      "grad_norm": 0.3014267683029175,
      "learning_rate": 3.4248406694076493e-06,
      "loss": 0.0283,
      "step": 212600
    },
    {
      "epoch": 7.458185770889583,
      "grad_norm": 0.18679280579090118,
      "learning_rate": 3.402924494393843e-06,
      "loss": 0.027,
      "step": 212700
    },
    {
      "epoch": 7.4616922051965355,
      "grad_norm": 0.12073025107383728,
      "learning_rate": 3.381008319380036e-06,
      "loss": 0.0237,
      "step": 212800
    },
    {
      "epoch": 7.465198639503489,
      "grad_norm": 0.43340516090393066,
      "learning_rate": 3.3590921443662283e-06,
      "loss": 0.0309,
      "step": 212900
    },
    {
      "epoch": 7.468705073810442,
      "grad_norm": 0.21975292265415192,
      "learning_rate": 3.337175969352421e-06,
      "loss": 0.0287,
      "step": 213000
    },
    {
      "epoch": 7.472211508117395,
      "grad_norm": 0.19765961170196533,
      "learning_rate": 3.315259794338614e-06,
      "loss": 0.0278,
      "step": 213100
    },
    {
      "epoch": 7.475717942424349,
      "grad_norm": 0.13511475920677185,
      "learning_rate": 3.293343619324807e-06,
      "loss": 0.0293,
      "step": 213200
    },
    {
      "epoch": 7.479224376731302,
      "grad_norm": 0.14023162424564362,
      "learning_rate": 3.2714274443109997e-06,
      "loss": 0.0281,
      "step": 213300
    },
    {
      "epoch": 7.482730811038255,
      "grad_norm": 0.09952816367149353,
      "learning_rate": 3.2495112692971926e-06,
      "loss": 0.0275,
      "step": 213400
    },
    {
      "epoch": 7.486237245345208,
      "grad_norm": 0.2805204689502716,
      "learning_rate": 3.2278142560335233e-06,
      "loss": 0.0306,
      "step": 213500
    },
    {
      "epoch": 7.489743679652162,
      "grad_norm": 0.09304061532020569,
      "learning_rate": 3.2061172427698536e-06,
      "loss": 0.0295,
      "step": 213600
    },
    {
      "epoch": 7.493250113959115,
      "grad_norm": 0.3030923902988434,
      "learning_rate": 3.1842010677560473e-06,
      "loss": 0.0311,
      "step": 213700
    },
    {
      "epoch": 7.4967565482660685,
      "grad_norm": 0.29770562052726746,
      "learning_rate": 3.1622848927422398e-06,
      "loss": 0.0275,
      "step": 213800
    },
    {
      "epoch": 7.500262982573021,
      "grad_norm": 0.4120267629623413,
      "learning_rate": 3.1403687177284326e-06,
      "loss": 0.0265,
      "step": 213900
    },
    {
      "epoch": 7.503769416879975,
      "grad_norm": 0.2778635621070862,
      "learning_rate": 3.118452542714625e-06,
      "loss": 0.0271,
      "step": 214000
    },
    {
      "epoch": 7.507275851186928,
      "grad_norm": 0.41703927516937256,
      "learning_rate": 3.096536367700818e-06,
      "loss": 0.0251,
      "step": 214100
    },
    {
      "epoch": 7.510782285493882,
      "grad_norm": 0.09408027678728104,
      "learning_rate": 3.074620192687011e-06,
      "loss": 0.0283,
      "step": 214200
    },
    {
      "epoch": 7.514288719800835,
      "grad_norm": 0.3712975084781647,
      "learning_rate": 3.0527040176732037e-06,
      "loss": 0.026,
      "step": 214300
    },
    {
      "epoch": 7.517795154107787,
      "grad_norm": 0.11149366199970245,
      "learning_rate": 3.0307878426593965e-06,
      "loss": 0.0294,
      "step": 214400
    },
    {
      "epoch": 7.521301588414741,
      "grad_norm": 0.17182987928390503,
      "learning_rate": 3.0088716676455894e-06,
      "loss": 0.0284,
      "step": 214500
    },
    {
      "epoch": 7.524808022721694,
      "grad_norm": 0.11877734214067459,
      "learning_rate": 2.9869554926317822e-06,
      "loss": 0.0279,
      "step": 214600
    },
    {
      "epoch": 7.528314457028648,
      "grad_norm": 0.27634063363075256,
      "learning_rate": 2.965039317617975e-06,
      "loss": 0.032,
      "step": 214700
    },
    {
      "epoch": 7.531820891335601,
      "grad_norm": 0.11718390136957169,
      "learning_rate": 2.943123142604168e-06,
      "loss": 0.028,
      "step": 214800
    },
    {
      "epoch": 7.535327325642554,
      "grad_norm": 0.2510230541229248,
      "learning_rate": 2.9212069675903604e-06,
      "loss": 0.027,
      "step": 214900
    },
    {
      "epoch": 7.538833759949507,
      "grad_norm": 0.16354061663150787,
      "learning_rate": 2.8992907925765533e-06,
      "loss": 0.0283,
      "step": 215000
    },
    {
      "epoch": 7.542340194256461,
      "grad_norm": 0.08586044609546661,
      "learning_rate": 2.877374617562746e-06,
      "loss": 0.0327,
      "step": 215100
    },
    {
      "epoch": 7.545846628563414,
      "grad_norm": 0.1856996864080429,
      "learning_rate": 2.855458442548939e-06,
      "loss": 0.031,
      "step": 215200
    },
    {
      "epoch": 7.549353062870367,
      "grad_norm": 0.10579686611890793,
      "learning_rate": 2.833542267535132e-06,
      "loss": 0.0283,
      "step": 215300
    },
    {
      "epoch": 7.55285949717732,
      "grad_norm": 0.11614294350147247,
      "learning_rate": 2.8116260925213243e-06,
      "loss": 0.0292,
      "step": 215400
    },
    {
      "epoch": 7.556365931484273,
      "grad_norm": 0.22216592729091644,
      "learning_rate": 2.789709917507517e-06,
      "loss": 0.0293,
      "step": 215500
    },
    {
      "epoch": 7.559872365791227,
      "grad_norm": 0.20104587078094482,
      "learning_rate": 2.76779374249371e-06,
      "loss": 0.026,
      "step": 215600
    },
    {
      "epoch": 7.56337880009818,
      "grad_norm": 0.04940788820385933,
      "learning_rate": 2.7458775674799033e-06,
      "loss": 0.0284,
      "step": 215700
    },
    {
      "epoch": 7.566885234405134,
      "grad_norm": 0.21863077580928802,
      "learning_rate": 2.7239613924660958e-06,
      "loss": 0.0311,
      "step": 215800
    },
    {
      "epoch": 7.5703916687120865,
      "grad_norm": 0.16485978662967682,
      "learning_rate": 2.7020452174522886e-06,
      "loss": 0.0301,
      "step": 215900
    },
    {
      "epoch": 7.57389810301904,
      "grad_norm": 0.10349487513303757,
      "learning_rate": 2.6801290424384815e-06,
      "loss": 0.0287,
      "step": 216000
    },
    {
      "epoch": 7.577404537325993,
      "grad_norm": 0.4119793772697449,
      "learning_rate": 2.6582128674246744e-06,
      "loss": 0.0292,
      "step": 216100
    },
    {
      "epoch": 7.580910971632947,
      "grad_norm": 0.702822744846344,
      "learning_rate": 2.6362966924108672e-06,
      "loss": 0.0277,
      "step": 216200
    },
    {
      "epoch": 7.5844174059399,
      "grad_norm": 0.15481145679950714,
      "learning_rate": 2.6143805173970597e-06,
      "loss": 0.0294,
      "step": 216300
    },
    {
      "epoch": 7.587923840246853,
      "grad_norm": 0.270817369222641,
      "learning_rate": 2.5924643423832525e-06,
      "loss": 0.0278,
      "step": 216400
    },
    {
      "epoch": 7.591430274553806,
      "grad_norm": 0.3404463827610016,
      "learning_rate": 2.5705481673694454e-06,
      "loss": 0.0307,
      "step": 216500
    },
    {
      "epoch": 7.594936708860759,
      "grad_norm": 0.15460601449012756,
      "learning_rate": 2.5486319923556383e-06,
      "loss": 0.0261,
      "step": 216600
    },
    {
      "epoch": 7.598443143167713,
      "grad_norm": 0.24936319887638092,
      "learning_rate": 2.526715817341831e-06,
      "loss": 0.03,
      "step": 216700
    },
    {
      "epoch": 7.601949577474666,
      "grad_norm": 0.18052791059017181,
      "learning_rate": 2.504799642328024e-06,
      "loss": 0.0281,
      "step": 216800
    },
    {
      "epoch": 7.6054560117816195,
      "grad_norm": 0.21425949037075043,
      "learning_rate": 2.4828834673142164e-06,
      "loss": 0.0307,
      "step": 216900
    },
    {
      "epoch": 7.608962446088572,
      "grad_norm": 0.4368768036365509,
      "learning_rate": 2.4609672923004093e-06,
      "loss": 0.0271,
      "step": 217000
    },
    {
      "epoch": 7.612468880395526,
      "grad_norm": 0.09812237322330475,
      "learning_rate": 2.4390511172866026e-06,
      "loss": 0.0304,
      "step": 217100
    },
    {
      "epoch": 7.615975314702479,
      "grad_norm": 0.37392544746398926,
      "learning_rate": 2.4171349422727955e-06,
      "loss": 0.0276,
      "step": 217200
    },
    {
      "epoch": 7.619481749009433,
      "grad_norm": 0.2837739586830139,
      "learning_rate": 2.395218767258988e-06,
      "loss": 0.0237,
      "step": 217300
    },
    {
      "epoch": 7.6229881833163855,
      "grad_norm": 0.20176741480827332,
      "learning_rate": 2.3733025922451808e-06,
      "loss": 0.0281,
      "step": 217400
    },
    {
      "epoch": 7.626494617623338,
      "grad_norm": 0.2186509519815445,
      "learning_rate": 2.3513864172313736e-06,
      "loss": 0.0288,
      "step": 217500
    },
    {
      "epoch": 7.630001051930292,
      "grad_norm": 0.20240198075771332,
      "learning_rate": 2.3294702422175665e-06,
      "loss": 0.0351,
      "step": 217600
    },
    {
      "epoch": 7.633507486237246,
      "grad_norm": 0.08440953493118286,
      "learning_rate": 2.3075540672037594e-06,
      "loss": 0.0297,
      "step": 217700
    },
    {
      "epoch": 7.637013920544199,
      "grad_norm": 0.3867081105709076,
      "learning_rate": 2.285637892189952e-06,
      "loss": 0.0285,
      "step": 217800
    },
    {
      "epoch": 7.6405203548511516,
      "grad_norm": 0.15333756804466248,
      "learning_rate": 2.2637217171761447e-06,
      "loss": 0.0293,
      "step": 217900
    },
    {
      "epoch": 7.644026789158105,
      "grad_norm": 0.13368608057498932,
      "learning_rate": 2.2418055421623375e-06,
      "loss": 0.0316,
      "step": 218000
    },
    {
      "epoch": 7.647533223465058,
      "grad_norm": 0.14650313556194305,
      "learning_rate": 2.2201085288986687e-06,
      "loss": 0.0268,
      "step": 218100
    },
    {
      "epoch": 7.651039657772012,
      "grad_norm": 0.19249245524406433,
      "learning_rate": 2.198192353884861e-06,
      "loss": 0.0298,
      "step": 218200
    },
    {
      "epoch": 7.654546092078965,
      "grad_norm": 0.25028955936431885,
      "learning_rate": 2.176276178871054e-06,
      "loss": 0.0336,
      "step": 218300
    },
    {
      "epoch": 7.6580525263859185,
      "grad_norm": 0.07228169590234756,
      "learning_rate": 2.154360003857247e-06,
      "loss": 0.0249,
      "step": 218400
    },
    {
      "epoch": 7.661558960692871,
      "grad_norm": 0.11504723131656647,
      "learning_rate": 2.1324438288434397e-06,
      "loss": 0.026,
      "step": 218500
    },
    {
      "epoch": 7.665065394999825,
      "grad_norm": 0.12249771505594254,
      "learning_rate": 2.1105276538296326e-06,
      "loss": 0.0294,
      "step": 218600
    },
    {
      "epoch": 7.668571829306778,
      "grad_norm": 0.15484245121479034,
      "learning_rate": 2.0886114788158254e-06,
      "loss": 0.0272,
      "step": 218700
    },
    {
      "epoch": 7.672078263613731,
      "grad_norm": 0.6139376759529114,
      "learning_rate": 2.066695303802018e-06,
      "loss": 0.0252,
      "step": 218800
    },
    {
      "epoch": 7.6755846979206845,
      "grad_norm": 0.17970368266105652,
      "learning_rate": 2.0447791287882107e-06,
      "loss": 0.0302,
      "step": 218900
    },
    {
      "epoch": 7.679091132227637,
      "grad_norm": 0.18569035828113556,
      "learning_rate": 2.022862953774404e-06,
      "loss": 0.0286,
      "step": 219000
    },
    {
      "epoch": 7.682597566534591,
      "grad_norm": 0.2563164532184601,
      "learning_rate": 2.000946778760597e-06,
      "loss": 0.0312,
      "step": 219100
    },
    {
      "epoch": 7.686104000841544,
      "grad_norm": 0.20581330358982086,
      "learning_rate": 1.9790306037467893e-06,
      "loss": 0.0282,
      "step": 219200
    },
    {
      "epoch": 7.689610435148498,
      "grad_norm": 0.48600563406944275,
      "learning_rate": 1.957114428732982e-06,
      "loss": 0.0325,
      "step": 219300
    },
    {
      "epoch": 7.693116869455451,
      "grad_norm": 0.18086779117584229,
      "learning_rate": 1.935198253719175e-06,
      "loss": 0.0279,
      "step": 219400
    },
    {
      "epoch": 7.696623303762404,
      "grad_norm": 0.1838015764951706,
      "learning_rate": 1.913282078705368e-06,
      "loss": 0.0255,
      "step": 219500
    },
    {
      "epoch": 7.700129738069357,
      "grad_norm": 0.09950914233922958,
      "learning_rate": 1.8913659036915606e-06,
      "loss": 0.0256,
      "step": 219600
    },
    {
      "epoch": 7.70363617237631,
      "grad_norm": 0.31654879450798035,
      "learning_rate": 1.8694497286777534e-06,
      "loss": 0.0296,
      "step": 219700
    },
    {
      "epoch": 7.707142606683264,
      "grad_norm": 0.09094363451004028,
      "learning_rate": 1.847533553663946e-06,
      "loss": 0.027,
      "step": 219800
    },
    {
      "epoch": 7.7106490409902175,
      "grad_norm": 0.11957398802042007,
      "learning_rate": 1.825617378650139e-06,
      "loss": 0.0267,
      "step": 219900
    },
    {
      "epoch": 7.71415547529717,
      "grad_norm": 0.11550958454608917,
      "learning_rate": 1.8037012036363318e-06,
      "loss": 0.0277,
      "step": 220000
    },
    {
      "epoch": 7.717661909604123,
      "grad_norm": 0.16890260577201843,
      "learning_rate": 1.7817850286225245e-06,
      "loss": 0.0269,
      "step": 220100
    },
    {
      "epoch": 7.721168343911077,
      "grad_norm": 0.144451305270195,
      "learning_rate": 1.7598688536087173e-06,
      "loss": 0.0301,
      "step": 220200
    },
    {
      "epoch": 7.72467477821803,
      "grad_norm": 0.24828402698040009,
      "learning_rate": 1.7379526785949102e-06,
      "loss": 0.0282,
      "step": 220300
    },
    {
      "epoch": 7.728181212524984,
      "grad_norm": 0.21162256598472595,
      "learning_rate": 1.7160365035811033e-06,
      "loss": 0.0278,
      "step": 220400
    },
    {
      "epoch": 7.731687646831936,
      "grad_norm": 0.18307147920131683,
      "learning_rate": 1.694120328567296e-06,
      "loss": 0.0289,
      "step": 220500
    },
    {
      "epoch": 7.73519408113889,
      "grad_norm": 0.23225538432598114,
      "learning_rate": 1.6722041535534888e-06,
      "loss": 0.0293,
      "step": 220600
    },
    {
      "epoch": 7.738700515445843,
      "grad_norm": 0.08829476684331894,
      "learning_rate": 1.6502879785396817e-06,
      "loss": 0.0288,
      "step": 220700
    },
    {
      "epoch": 7.742206949752797,
      "grad_norm": 0.5526010394096375,
      "learning_rate": 1.6283718035258743e-06,
      "loss": 0.0297,
      "step": 220800
    },
    {
      "epoch": 7.74571338405975,
      "grad_norm": 0.2329462468624115,
      "learning_rate": 1.6064556285120672e-06,
      "loss": 0.0281,
      "step": 220900
    },
    {
      "epoch": 7.7492198183667025,
      "grad_norm": 0.40496164560317993,
      "learning_rate": 1.58453945349826e-06,
      "loss": 0.0277,
      "step": 221000
    },
    {
      "epoch": 7.752726252673656,
      "grad_norm": 0.14878828823566437,
      "learning_rate": 1.5626232784844527e-06,
      "loss": 0.0274,
      "step": 221100
    },
    {
      "epoch": 7.756232686980609,
      "grad_norm": 0.19139288365840912,
      "learning_rate": 1.5407071034706456e-06,
      "loss": 0.0288,
      "step": 221200
    },
    {
      "epoch": 7.759739121287563,
      "grad_norm": 0.1573885977268219,
      "learning_rate": 1.5187909284568382e-06,
      "loss": 0.0283,
      "step": 221300
    },
    {
      "epoch": 7.763245555594516,
      "grad_norm": 0.12975770235061646,
      "learning_rate": 1.4968747534430313e-06,
      "loss": 0.0315,
      "step": 221400
    },
    {
      "epoch": 7.766751989901469,
      "grad_norm": 0.14712947607040405,
      "learning_rate": 1.474958578429224e-06,
      "loss": 0.0319,
      "step": 221500
    },
    {
      "epoch": 7.770258424208422,
      "grad_norm": 0.11649120599031448,
      "learning_rate": 1.4530424034154168e-06,
      "loss": 0.0252,
      "step": 221600
    },
    {
      "epoch": 7.773764858515376,
      "grad_norm": 0.17722588777542114,
      "learning_rate": 1.4313453901517477e-06,
      "loss": 0.0276,
      "step": 221700
    },
    {
      "epoch": 7.777271292822329,
      "grad_norm": 0.09068816900253296,
      "learning_rate": 1.4094292151379404e-06,
      "loss": 0.0282,
      "step": 221800
    },
    {
      "epoch": 7.780777727129283,
      "grad_norm": 0.3248215615749359,
      "learning_rate": 1.3875130401241335e-06,
      "loss": 0.0274,
      "step": 221900
    },
    {
      "epoch": 7.7842841614362355,
      "grad_norm": 0.11085711419582367,
      "learning_rate": 1.365596865110326e-06,
      "loss": 0.0262,
      "step": 222000
    },
    {
      "epoch": 7.787790595743189,
      "grad_norm": 0.17468370497226715,
      "learning_rate": 1.343680690096519e-06,
      "loss": 0.028,
      "step": 222100
    },
    {
      "epoch": 7.791297030050142,
      "grad_norm": 0.28325942158699036,
      "learning_rate": 1.3217645150827116e-06,
      "loss": 0.0305,
      "step": 222200
    },
    {
      "epoch": 7.794803464357095,
      "grad_norm": 0.16426095366477966,
      "learning_rate": 1.2998483400689045e-06,
      "loss": 0.0267,
      "step": 222300
    },
    {
      "epoch": 7.798309898664049,
      "grad_norm": 0.11650517582893372,
      "learning_rate": 1.2779321650550974e-06,
      "loss": 0.0295,
      "step": 222400
    },
    {
      "epoch": 7.8018163329710015,
      "grad_norm": 0.24306543171405792,
      "learning_rate": 1.25601599004129e-06,
      "loss": 0.0271,
      "step": 222500
    },
    {
      "epoch": 7.805322767277955,
      "grad_norm": 0.11520390957593918,
      "learning_rate": 1.234099815027483e-06,
      "loss": 0.0274,
      "step": 222600
    },
    {
      "epoch": 7.808829201584908,
      "grad_norm": 0.16694307327270508,
      "learning_rate": 1.2121836400136757e-06,
      "loss": 0.0289,
      "step": 222700
    },
    {
      "epoch": 7.812335635891862,
      "grad_norm": 0.13405653834342957,
      "learning_rate": 1.1902674649998686e-06,
      "loss": 0.0274,
      "step": 222800
    },
    {
      "epoch": 7.815842070198815,
      "grad_norm": 0.10708312690258026,
      "learning_rate": 1.1683512899860615e-06,
      "loss": 0.0278,
      "step": 222900
    },
    {
      "epoch": 7.8193485045057685,
      "grad_norm": 0.7354673147201538,
      "learning_rate": 1.1464351149722541e-06,
      "loss": 0.0284,
      "step": 223000
    },
    {
      "epoch": 7.822854938812721,
      "grad_norm": 0.08518125861883163,
      "learning_rate": 1.124518939958447e-06,
      "loss": 0.0232,
      "step": 223100
    },
    {
      "epoch": 7.826361373119674,
      "grad_norm": 0.03678550943732262,
      "learning_rate": 1.1026027649446396e-06,
      "loss": 0.0295,
      "step": 223200
    },
    {
      "epoch": 7.829867807426628,
      "grad_norm": 0.11574152857065201,
      "learning_rate": 1.0806865899308327e-06,
      "loss": 0.0251,
      "step": 223300
    },
    {
      "epoch": 7.833374241733581,
      "grad_norm": 0.19697074592113495,
      "learning_rate": 1.0587704149170254e-06,
      "loss": 0.0273,
      "step": 223400
    },
    {
      "epoch": 7.8368806760405345,
      "grad_norm": 0.15501268208026886,
      "learning_rate": 1.0368542399032182e-06,
      "loss": 0.0286,
      "step": 223500
    },
    {
      "epoch": 7.840387110347487,
      "grad_norm": 0.2058575302362442,
      "learning_rate": 1.014938064889411e-06,
      "loss": 0.0291,
      "step": 223600
    },
    {
      "epoch": 7.843893544654441,
      "grad_norm": 0.13320204615592957,
      "learning_rate": 9.930218898756037e-07,
      "loss": 0.0241,
      "step": 223700
    },
    {
      "epoch": 7.847399978961394,
      "grad_norm": 0.12965470552444458,
      "learning_rate": 9.711057148617966e-07,
      "loss": 0.0295,
      "step": 223800
    },
    {
      "epoch": 7.850906413268348,
      "grad_norm": 0.1349811851978302,
      "learning_rate": 9.491895398479894e-07,
      "loss": 0.0283,
      "step": 223900
    },
    {
      "epoch": 7.854412847575301,
      "grad_norm": 0.2870485484600067,
      "learning_rate": 9.272733648341823e-07,
      "loss": 0.0274,
      "step": 224000
    },
    {
      "epoch": 7.857919281882254,
      "grad_norm": 0.3982533812522888,
      "learning_rate": 9.053571898203751e-07,
      "loss": 0.0326,
      "step": 224100
    },
    {
      "epoch": 7.861425716189207,
      "grad_norm": 0.2570808529853821,
      "learning_rate": 8.834410148065679e-07,
      "loss": 0.0292,
      "step": 224200
    },
    {
      "epoch": 7.864932150496161,
      "grad_norm": 0.1446608304977417,
      "learning_rate": 8.615248397927607e-07,
      "loss": 0.0269,
      "step": 224300
    },
    {
      "epoch": 7.868438584803114,
      "grad_norm": 0.09497727453708649,
      "learning_rate": 8.396086647789535e-07,
      "loss": 0.027,
      "step": 224400
    },
    {
      "epoch": 7.871945019110067,
      "grad_norm": 0.16441655158996582,
      "learning_rate": 8.179116515152845e-07,
      "loss": 0.0292,
      "step": 224500
    },
    {
      "epoch": 7.87545145341702,
      "grad_norm": 0.5007656812667847,
      "learning_rate": 7.959954765014773e-07,
      "loss": 0.0309,
      "step": 224600
    },
    {
      "epoch": 7.878957887723973,
      "grad_norm": 0.09022806584835052,
      "learning_rate": 7.7407930148767e-07,
      "loss": 0.0277,
      "step": 224700
    },
    {
      "epoch": 7.882464322030927,
      "grad_norm": 0.2563498914241791,
      "learning_rate": 7.521631264738628e-07,
      "loss": 0.0259,
      "step": 224800
    },
    {
      "epoch": 7.88597075633788,
      "grad_norm": 0.21179690957069397,
      "learning_rate": 7.302469514600555e-07,
      "loss": 0.0285,
      "step": 224900
    },
    {
      "epoch": 7.8894771906448335,
      "grad_norm": 0.072447769343853,
      "learning_rate": 7.083307764462485e-07,
      "loss": 0.0277,
      "step": 225000
    },
    {
      "epoch": 7.892983624951786,
      "grad_norm": 0.3007144629955292,
      "learning_rate": 6.864146014324413e-07,
      "loss": 0.0267,
      "step": 225100
    },
    {
      "epoch": 7.89649005925874,
      "grad_norm": 0.21686281263828278,
      "learning_rate": 6.64498426418634e-07,
      "loss": 0.0302,
      "step": 225200
    },
    {
      "epoch": 7.899996493565693,
      "grad_norm": 0.08532179147005081,
      "learning_rate": 6.425822514048268e-07,
      "loss": 0.0276,
      "step": 225300
    },
    {
      "epoch": 7.903502927872646,
      "grad_norm": 0.12725429236888885,
      "learning_rate": 6.206660763910196e-07,
      "loss": 0.0267,
      "step": 225400
    },
    {
      "epoch": 7.9070093621796,
      "grad_norm": 0.2541080415248871,
      "learning_rate": 5.987499013772125e-07,
      "loss": 0.0271,
      "step": 225500
    },
    {
      "epoch": 7.9105157964865525,
      "grad_norm": 0.13450591266155243,
      "learning_rate": 5.768337263634053e-07,
      "loss": 0.029,
      "step": 225600
    },
    {
      "epoch": 7.914022230793506,
      "grad_norm": 0.137848898768425,
      "learning_rate": 5.549175513495981e-07,
      "loss": 0.0294,
      "step": 225700
    },
    {
      "epoch": 7.917528665100459,
      "grad_norm": 0.1513673961162567,
      "learning_rate": 5.330013763357909e-07,
      "loss": 0.0287,
      "step": 225800
    },
    {
      "epoch": 7.921035099407413,
      "grad_norm": 0.2871623933315277,
      "learning_rate": 5.110852013219837e-07,
      "loss": 0.0299,
      "step": 225900
    },
    {
      "epoch": 7.924541533714366,
      "grad_norm": 0.34194454550743103,
      "learning_rate": 4.891690263081765e-07,
      "loss": 0.0288,
      "step": 226000
    },
    {
      "epoch": 7.928047968021319,
      "grad_norm": 0.251874715089798,
      "learning_rate": 4.6725285129436933e-07,
      "loss": 0.0289,
      "step": 226100
    },
    {
      "epoch": 7.931554402328272,
      "grad_norm": 0.21673588454723358,
      "learning_rate": 4.4533667628056214e-07,
      "loss": 0.0295,
      "step": 226200
    },
    {
      "epoch": 7.935060836635226,
      "grad_norm": 0.16065065562725067,
      "learning_rate": 4.234205012667549e-07,
      "loss": 0.0292,
      "step": 226300
    },
    {
      "epoch": 7.938567270942179,
      "grad_norm": 0.1777377426624298,
      "learning_rate": 4.0150432625294777e-07,
      "loss": 0.0287,
      "step": 226400
    },
    {
      "epoch": 7.942073705249133,
      "grad_norm": 0.09359055012464523,
      "learning_rate": 3.795881512391406e-07,
      "loss": 0.0261,
      "step": 226500
    },
    {
      "epoch": 7.945580139556085,
      "grad_norm": 0.15779848396778107,
      "learning_rate": 3.5767197622533334e-07,
      "loss": 0.0243,
      "step": 226600
    },
    {
      "epoch": 7.949086573863038,
      "grad_norm": 0.16592714190483093,
      "learning_rate": 3.3575580121152615e-07,
      "loss": 0.0269,
      "step": 226700
    },
    {
      "epoch": 7.952593008169992,
      "grad_norm": 0.082403264939785,
      "learning_rate": 3.13839626197719e-07,
      "loss": 0.029,
      "step": 226800
    },
    {
      "epoch": 7.956099442476945,
      "grad_norm": 0.11393715441226959,
      "learning_rate": 2.9192345118391177e-07,
      "loss": 0.0249,
      "step": 226900
    },
    {
      "epoch": 7.959605876783899,
      "grad_norm": 0.13382276892662048,
      "learning_rate": 2.700072761701046e-07,
      "loss": 0.0287,
      "step": 227000
    },
    {
      "epoch": 7.9631123110908515,
      "grad_norm": 0.2085641771554947,
      "learning_rate": 2.480911011562974e-07,
      "loss": 0.0303,
      "step": 227100
    },
    {
      "epoch": 7.966618745397805,
      "grad_norm": 0.1506524384021759,
      "learning_rate": 2.261749261424902e-07,
      "loss": 0.0252,
      "step": 227200
    },
    {
      "epoch": 7.970125179704758,
      "grad_norm": 0.4158930480480194,
      "learning_rate": 2.04258751128683e-07,
      "loss": 0.0263,
      "step": 227300
    },
    {
      "epoch": 7.973631614011712,
      "grad_norm": 0.16707631945610046,
      "learning_rate": 1.8234257611487583e-07,
      "loss": 0.0323,
      "step": 227400
    },
    {
      "epoch": 7.977138048318665,
      "grad_norm": 0.17433670163154602,
      "learning_rate": 1.6042640110106864e-07,
      "loss": 0.0301,
      "step": 227500
    },
    {
      "epoch": 7.9806444826256175,
      "grad_norm": 0.43457767367362976,
      "learning_rate": 1.3851022608726145e-07,
      "loss": 0.0299,
      "step": 227600
    },
    {
      "epoch": 7.984150916932571,
      "grad_norm": 0.6828927993774414,
      "learning_rate": 1.1659405107345427e-07,
      "loss": 0.0278,
      "step": 227700
    },
    {
      "epoch": 7.987657351239524,
      "grad_norm": 0.19339968264102936,
      "learning_rate": 9.467787605964706e-08,
      "loss": 0.0269,
      "step": 227800
    },
    {
      "epoch": 7.991163785546478,
      "grad_norm": 0.09251785278320312,
      "learning_rate": 7.276170104583988e-08,
      "loss": 0.0286,
      "step": 227900
    },
    {
      "epoch": 7.994670219853431,
      "grad_norm": 0.3523053824901581,
      "learning_rate": 5.084552603203269e-08,
      "loss": 0.0292,
      "step": 228000
    },
    {
      "epoch": 7.9981766541603845,
      "grad_norm": 0.12806916236877441,
      "learning_rate": 2.8929351018225495e-08,
      "loss": 0.0274,
      "step": 228100
    },
    {
      "epoch": 8.0,
      "eval_accuracy_macro_0.5": 0.9874993562698364,
      "eval_accuracy_micro_0.5": 0.9874993562698364,
      "eval_accuracy_weighted_0.5": 0.9814050197601318,
      "eval_f1_macro_0.5": 0.828754186630249,
      "eval_f1_macro_0.6": 0.8216318488121033,
      "eval_f1_macro_0.7": 0.8041428923606873,
      "eval_f1_macro_0.8": 0.6962330341339111,
      "eval_f1_micro_0.5": 0.8417839407920837,
      "eval_f1_micro_0.6": 0.8357561826705933,
      "eval_f1_micro_0.7": 0.8209617733955383,
      "eval_f1_micro_0.8": 0.7902459502220154,
      "eval_f1_micro_0.9": 0.7215779423713684,
      "eval_f1_weighted_0.5": 0.8397758603096008,
      "eval_f1_weighted_0.6": 0.8318769335746765,
      "eval_f1_weighted_0.7": 0.8142581582069397,
      "eval_f1_weighted_0.8": 0.701239824295044,
      "eval_loss": 0.028058024123311043,
      "eval_runtime": 411.6481,
      "eval_samples_per_second": 138.485,
      "eval_steps_per_second": 17.311,
      "step": 228152
    }
  ],
  "logging_steps": 100,
  "max_steps": 228152,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.9562408227967693e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
