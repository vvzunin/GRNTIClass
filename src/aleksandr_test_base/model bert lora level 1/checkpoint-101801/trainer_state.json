{
  "best_metric": 0.8170711398124695,
  "best_model_checkpoint": "aleksandr_test_base/model bert lora level 1/checkpoint-101801",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 101801,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00687616035205941,
      "grad_norm": 0.2790559232234955,
      "learning_rate": 4.996131827324772e-05,
      "loss": 0.337,
      "step": 100
    },
    {
      "epoch": 0.01375232070411882,
      "grad_norm": 0.2401018738746643,
      "learning_rate": 4.9918338576856295e-05,
      "loss": 0.1414,
      "step": 200
    },
    {
      "epoch": 0.02062848105617823,
      "grad_norm": 0.23178955912590027,
      "learning_rate": 4.9875358880464876e-05,
      "loss": 0.1317,
      "step": 300
    },
    {
      "epoch": 0.02750464140823764,
      "grad_norm": 0.2571523189544678,
      "learning_rate": 4.983237918407345e-05,
      "loss": 0.1274,
      "step": 400
    },
    {
      "epoch": 0.03438080176029705,
      "grad_norm": 0.2008134126663208,
      "learning_rate": 4.978939948768202e-05,
      "loss": 0.1156,
      "step": 500
    },
    {
      "epoch": 0.04125696211235646,
      "grad_norm": 0.1713176965713501,
      "learning_rate": 4.97464197912906e-05,
      "loss": 0.1078,
      "step": 600
    },
    {
      "epoch": 0.04813312246441587,
      "grad_norm": 0.23098425567150116,
      "learning_rate": 4.970344009489917e-05,
      "loss": 0.0982,
      "step": 700
    },
    {
      "epoch": 0.05500928281647528,
      "grad_norm": 0.18672901391983032,
      "learning_rate": 4.9660460398507745e-05,
      "loss": 0.0888,
      "step": 800
    },
    {
      "epoch": 0.06188544316853469,
      "grad_norm": 0.15384753048419952,
      "learning_rate": 4.961748070211632e-05,
      "loss": 0.086,
      "step": 900
    },
    {
      "epoch": 0.0687616035205941,
      "grad_norm": 0.166092187166214,
      "learning_rate": 4.95745010057249e-05,
      "loss": 0.0806,
      "step": 1000
    },
    {
      "epoch": 0.07563776387265352,
      "grad_norm": 0.2746098041534424,
      "learning_rate": 4.9531521309333474e-05,
      "loss": 0.0774,
      "step": 1100
    },
    {
      "epoch": 0.08251392422471292,
      "grad_norm": 0.2324722409248352,
      "learning_rate": 4.948854161294205e-05,
      "loss": 0.073,
      "step": 1200
    },
    {
      "epoch": 0.08939008457677233,
      "grad_norm": 0.15009592473506927,
      "learning_rate": 4.944556191655063e-05,
      "loss": 0.075,
      "step": 1300
    },
    {
      "epoch": 0.09626624492883173,
      "grad_norm": 0.15650899708271027,
      "learning_rate": 4.94025822201592e-05,
      "loss": 0.0707,
      "step": 1400
    },
    {
      "epoch": 0.10314240528089115,
      "grad_norm": 0.16309784352779388,
      "learning_rate": 4.9359602523767776e-05,
      "loss": 0.067,
      "step": 1500
    },
    {
      "epoch": 0.11001856563295057,
      "grad_norm": 0.1942591816186905,
      "learning_rate": 4.931662282737635e-05,
      "loss": 0.0655,
      "step": 1600
    },
    {
      "epoch": 0.11689472598500997,
      "grad_norm": 0.2076319456100464,
      "learning_rate": 4.9273643130984924e-05,
      "loss": 0.0667,
      "step": 1700
    },
    {
      "epoch": 0.12377088633706938,
      "grad_norm": 0.16016905009746552,
      "learning_rate": 4.92306634345935e-05,
      "loss": 0.065,
      "step": 1800
    },
    {
      "epoch": 0.1306470466891288,
      "grad_norm": 0.23687368631362915,
      "learning_rate": 4.918768373820208e-05,
      "loss": 0.0617,
      "step": 1900
    },
    {
      "epoch": 0.1375232070411882,
      "grad_norm": 0.16015145182609558,
      "learning_rate": 4.914470404181065e-05,
      "loss": 0.0618,
      "step": 2000
    },
    {
      "epoch": 0.1443993673932476,
      "grad_norm": 0.25135520100593567,
      "learning_rate": 4.9101724345419226e-05,
      "loss": 0.0612,
      "step": 2100
    },
    {
      "epoch": 0.15127552774530703,
      "grad_norm": 0.13723228871822357,
      "learning_rate": 4.90587446490278e-05,
      "loss": 0.0572,
      "step": 2200
    },
    {
      "epoch": 0.15815168809736643,
      "grad_norm": 0.17708167433738708,
      "learning_rate": 4.901576495263638e-05,
      "loss": 0.0616,
      "step": 2300
    },
    {
      "epoch": 0.16502784844942583,
      "grad_norm": 0.15516987442970276,
      "learning_rate": 4.8972785256244955e-05,
      "loss": 0.058,
      "step": 2400
    },
    {
      "epoch": 0.17190400880148526,
      "grad_norm": 0.1666737198829651,
      "learning_rate": 4.892980555985353e-05,
      "loss": 0.0571,
      "step": 2500
    },
    {
      "epoch": 0.17878016915354467,
      "grad_norm": 0.22725056111812592,
      "learning_rate": 4.88868258634621e-05,
      "loss": 0.0602,
      "step": 2600
    },
    {
      "epoch": 0.18565632950560407,
      "grad_norm": 0.2017509639263153,
      "learning_rate": 4.8843846167070677e-05,
      "loss": 0.0584,
      "step": 2700
    },
    {
      "epoch": 0.19253248985766347,
      "grad_norm": 0.12192162126302719,
      "learning_rate": 4.880086647067925e-05,
      "loss": 0.0559,
      "step": 2800
    },
    {
      "epoch": 0.1994086502097229,
      "grad_norm": 0.20963677763938904,
      "learning_rate": 4.875788677428783e-05,
      "loss": 0.056,
      "step": 2900
    },
    {
      "epoch": 0.2062848105617823,
      "grad_norm": 0.13195613026618958,
      "learning_rate": 4.8714907077896405e-05,
      "loss": 0.057,
      "step": 3000
    },
    {
      "epoch": 0.2131609709138417,
      "grad_norm": 0.2511725127696991,
      "learning_rate": 4.867192738150498e-05,
      "loss": 0.0576,
      "step": 3100
    },
    {
      "epoch": 0.22003713126590113,
      "grad_norm": 0.1380811184644699,
      "learning_rate": 4.862894768511356e-05,
      "loss": 0.0577,
      "step": 3200
    },
    {
      "epoch": 0.22691329161796053,
      "grad_norm": 0.12292603403329849,
      "learning_rate": 4.8585967988722134e-05,
      "loss": 0.0542,
      "step": 3300
    },
    {
      "epoch": 0.23378945197001993,
      "grad_norm": 0.11024700850248337,
      "learning_rate": 4.854298829233071e-05,
      "loss": 0.0552,
      "step": 3400
    },
    {
      "epoch": 0.24066561232207936,
      "grad_norm": 0.1886621117591858,
      "learning_rate": 4.850000859593928e-05,
      "loss": 0.0544,
      "step": 3500
    },
    {
      "epoch": 0.24754177267413877,
      "grad_norm": 0.2614921033382416,
      "learning_rate": 4.8457028899547855e-05,
      "loss": 0.0538,
      "step": 3600
    },
    {
      "epoch": 0.2544179330261982,
      "grad_norm": 0.15214011073112488,
      "learning_rate": 4.841404920315643e-05,
      "loss": 0.053,
      "step": 3700
    },
    {
      "epoch": 0.2612940933782576,
      "grad_norm": 0.1798080950975418,
      "learning_rate": 4.8371069506765e-05,
      "loss": 0.0539,
      "step": 3800
    },
    {
      "epoch": 0.268170253730317,
      "grad_norm": 0.2250116467475891,
      "learning_rate": 4.8328089810373584e-05,
      "loss": 0.0549,
      "step": 3900
    },
    {
      "epoch": 0.2750464140823764,
      "grad_norm": 0.22882428765296936,
      "learning_rate": 4.828511011398216e-05,
      "loss": 0.0533,
      "step": 4000
    },
    {
      "epoch": 0.2819225744344358,
      "grad_norm": 0.16626295447349548,
      "learning_rate": 4.824213041759073e-05,
      "loss": 0.0529,
      "step": 4100
    },
    {
      "epoch": 0.2887987347864952,
      "grad_norm": 0.22051163017749786,
      "learning_rate": 4.819915072119931e-05,
      "loss": 0.0504,
      "step": 4200
    },
    {
      "epoch": 0.2956748951385546,
      "grad_norm": 0.2289120852947235,
      "learning_rate": 4.8156171024807886e-05,
      "loss": 0.0516,
      "step": 4300
    },
    {
      "epoch": 0.30255105549061406,
      "grad_norm": 0.15713217854499817,
      "learning_rate": 4.811319132841646e-05,
      "loss": 0.0491,
      "step": 4400
    },
    {
      "epoch": 0.30942721584267346,
      "grad_norm": 0.13055120408535004,
      "learning_rate": 4.8070211632025034e-05,
      "loss": 0.0515,
      "step": 4500
    },
    {
      "epoch": 0.31630337619473287,
      "grad_norm": 0.16091275215148926,
      "learning_rate": 4.802723193563361e-05,
      "loss": 0.0526,
      "step": 4600
    },
    {
      "epoch": 0.32317953654679227,
      "grad_norm": 0.20548421144485474,
      "learning_rate": 4.798425223924218e-05,
      "loss": 0.0513,
      "step": 4700
    },
    {
      "epoch": 0.33005569689885167,
      "grad_norm": 0.14797565340995789,
      "learning_rate": 4.7941272542850756e-05,
      "loss": 0.0528,
      "step": 4800
    },
    {
      "epoch": 0.33693185725091107,
      "grad_norm": 0.11182256042957306,
      "learning_rate": 4.7898292846459336e-05,
      "loss": 0.0516,
      "step": 4900
    },
    {
      "epoch": 0.34380801760297053,
      "grad_norm": 0.22932182252407074,
      "learning_rate": 4.785531315006791e-05,
      "loss": 0.0508,
      "step": 5000
    },
    {
      "epoch": 0.35068417795502993,
      "grad_norm": 0.1818227767944336,
      "learning_rate": 4.7812333453676484e-05,
      "loss": 0.0507,
      "step": 5100
    },
    {
      "epoch": 0.35756033830708933,
      "grad_norm": 0.1834561824798584,
      "learning_rate": 4.7769353757285065e-05,
      "loss": 0.0505,
      "step": 5200
    },
    {
      "epoch": 0.36443649865914873,
      "grad_norm": 0.16362829506397247,
      "learning_rate": 4.772637406089364e-05,
      "loss": 0.0505,
      "step": 5300
    },
    {
      "epoch": 0.37131265901120813,
      "grad_norm": 0.1576807200908661,
      "learning_rate": 4.768339436450221e-05,
      "loss": 0.0524,
      "step": 5400
    },
    {
      "epoch": 0.37818881936326754,
      "grad_norm": 0.2729056775569916,
      "learning_rate": 4.764041466811079e-05,
      "loss": 0.0494,
      "step": 5500
    },
    {
      "epoch": 0.38506497971532694,
      "grad_norm": 0.21044223010540009,
      "learning_rate": 4.759743497171936e-05,
      "loss": 0.0498,
      "step": 5600
    },
    {
      "epoch": 0.3919411400673864,
      "grad_norm": 0.13579827547073364,
      "learning_rate": 4.7554455275327935e-05,
      "loss": 0.0502,
      "step": 5700
    },
    {
      "epoch": 0.3988173004194458,
      "grad_norm": 0.1710270494222641,
      "learning_rate": 4.7511475578936515e-05,
      "loss": 0.0517,
      "step": 5800
    },
    {
      "epoch": 0.4056934607715052,
      "grad_norm": 0.13949525356292725,
      "learning_rate": 4.746849588254509e-05,
      "loss": 0.0519,
      "step": 5900
    },
    {
      "epoch": 0.4125696211235646,
      "grad_norm": 0.15448418259620667,
      "learning_rate": 4.742551618615366e-05,
      "loss": 0.0501,
      "step": 6000
    },
    {
      "epoch": 0.419445781475624,
      "grad_norm": 0.149039626121521,
      "learning_rate": 4.738253648976224e-05,
      "loss": 0.0475,
      "step": 6100
    },
    {
      "epoch": 0.4263219418276834,
      "grad_norm": 0.13638244569301605,
      "learning_rate": 4.733955679337082e-05,
      "loss": 0.0483,
      "step": 6200
    },
    {
      "epoch": 0.4331981021797428,
      "grad_norm": 0.18958322703838348,
      "learning_rate": 4.729657709697939e-05,
      "loss": 0.0465,
      "step": 6300
    },
    {
      "epoch": 0.44007426253180226,
      "grad_norm": 0.09494425356388092,
      "learning_rate": 4.7253597400587965e-05,
      "loss": 0.0489,
      "step": 6400
    },
    {
      "epoch": 0.44695042288386166,
      "grad_norm": 0.22077055275440216,
      "learning_rate": 4.721061770419654e-05,
      "loss": 0.0497,
      "step": 6500
    },
    {
      "epoch": 0.45382658323592107,
      "grad_norm": 0.22244565188884735,
      "learning_rate": 4.716763800780511e-05,
      "loss": 0.049,
      "step": 6600
    },
    {
      "epoch": 0.46070274358798047,
      "grad_norm": 0.11790698766708374,
      "learning_rate": 4.712465831141369e-05,
      "loss": 0.0486,
      "step": 6700
    },
    {
      "epoch": 0.46757890394003987,
      "grad_norm": 0.28374913334846497,
      "learning_rate": 4.708167861502227e-05,
      "loss": 0.0502,
      "step": 6800
    },
    {
      "epoch": 0.47445506429209927,
      "grad_norm": 0.21287228167057037,
      "learning_rate": 4.703869891863084e-05,
      "loss": 0.0476,
      "step": 6900
    },
    {
      "epoch": 0.48133122464415873,
      "grad_norm": 0.20666946470737457,
      "learning_rate": 4.6995719222239416e-05,
      "loss": 0.0477,
      "step": 7000
    },
    {
      "epoch": 0.48820738499621813,
      "grad_norm": 0.15678861737251282,
      "learning_rate": 4.6952739525847996e-05,
      "loss": 0.0464,
      "step": 7100
    },
    {
      "epoch": 0.49508354534827753,
      "grad_norm": 0.18329626321792603,
      "learning_rate": 4.690975982945657e-05,
      "loss": 0.0484,
      "step": 7200
    },
    {
      "epoch": 0.5019597057003369,
      "grad_norm": 0.16837558150291443,
      "learning_rate": 4.6866780133065144e-05,
      "loss": 0.0471,
      "step": 7300
    },
    {
      "epoch": 0.5088358660523964,
      "grad_norm": 0.21933364868164062,
      "learning_rate": 4.682380043667372e-05,
      "loss": 0.0452,
      "step": 7400
    },
    {
      "epoch": 0.5157120264044558,
      "grad_norm": 0.3432251811027527,
      "learning_rate": 4.678082074028229e-05,
      "loss": 0.0465,
      "step": 7500
    },
    {
      "epoch": 0.5225881867565152,
      "grad_norm": 0.23969361186027527,
      "learning_rate": 4.6737841043890866e-05,
      "loss": 0.0468,
      "step": 7600
    },
    {
      "epoch": 0.5294643471085746,
      "grad_norm": 0.2250785529613495,
      "learning_rate": 4.669486134749944e-05,
      "loss": 0.0487,
      "step": 7700
    },
    {
      "epoch": 0.536340507460634,
      "grad_norm": 0.1115240827202797,
      "learning_rate": 4.665188165110802e-05,
      "loss": 0.0492,
      "step": 7800
    },
    {
      "epoch": 0.5432166678126934,
      "grad_norm": 0.24778908491134644,
      "learning_rate": 4.6608901954716594e-05,
      "loss": 0.0458,
      "step": 7900
    },
    {
      "epoch": 0.5500928281647528,
      "grad_norm": 0.07712564617395401,
      "learning_rate": 4.656592225832517e-05,
      "loss": 0.0452,
      "step": 8000
    },
    {
      "epoch": 0.5569689885168122,
      "grad_norm": 0.11201747506856918,
      "learning_rate": 4.652294256193375e-05,
      "loss": 0.0448,
      "step": 8100
    },
    {
      "epoch": 0.5638451488688716,
      "grad_norm": 0.23525895178318024,
      "learning_rate": 4.647996286554232e-05,
      "loss": 0.0491,
      "step": 8200
    },
    {
      "epoch": 0.570721309220931,
      "grad_norm": 0.20013709366321564,
      "learning_rate": 4.64369831691509e-05,
      "loss": 0.048,
      "step": 8300
    },
    {
      "epoch": 0.5775974695729904,
      "grad_norm": 0.38254833221435547,
      "learning_rate": 4.639400347275947e-05,
      "loss": 0.0478,
      "step": 8400
    },
    {
      "epoch": 0.5844736299250498,
      "grad_norm": 0.1777220517396927,
      "learning_rate": 4.6351023776368045e-05,
      "loss": 0.047,
      "step": 8500
    },
    {
      "epoch": 0.5913497902771092,
      "grad_norm": 0.13887307047843933,
      "learning_rate": 4.630804407997662e-05,
      "loss": 0.0487,
      "step": 8600
    },
    {
      "epoch": 0.5982259506291687,
      "grad_norm": 0.16284151375293732,
      "learning_rate": 4.62650643835852e-05,
      "loss": 0.047,
      "step": 8700
    },
    {
      "epoch": 0.6051021109812281,
      "grad_norm": 0.2064448893070221,
      "learning_rate": 4.622208468719377e-05,
      "loss": 0.0454,
      "step": 8800
    },
    {
      "epoch": 0.6119782713332875,
      "grad_norm": 0.19786816835403442,
      "learning_rate": 4.617910499080235e-05,
      "loss": 0.0481,
      "step": 8900
    },
    {
      "epoch": 0.6188544316853469,
      "grad_norm": 0.22875207662582397,
      "learning_rate": 4.613612529441092e-05,
      "loss": 0.0439,
      "step": 9000
    },
    {
      "epoch": 0.6257305920374063,
      "grad_norm": 0.29497045278549194,
      "learning_rate": 4.60931455980195e-05,
      "loss": 0.0476,
      "step": 9100
    },
    {
      "epoch": 0.6326067523894657,
      "grad_norm": 0.22696632146835327,
      "learning_rate": 4.6050165901628076e-05,
      "loss": 0.0474,
      "step": 9200
    },
    {
      "epoch": 0.6394829127415251,
      "grad_norm": 0.12571828067302704,
      "learning_rate": 4.600718620523665e-05,
      "loss": 0.0457,
      "step": 9300
    },
    {
      "epoch": 0.6463590730935845,
      "grad_norm": 0.20738041400909424,
      "learning_rate": 4.5964206508845223e-05,
      "loss": 0.0431,
      "step": 9400
    },
    {
      "epoch": 0.6532352334456439,
      "grad_norm": 0.11790458112955093,
      "learning_rate": 4.59212268124538e-05,
      "loss": 0.0484,
      "step": 9500
    },
    {
      "epoch": 0.6601113937977033,
      "grad_norm": 0.1930720955133438,
      "learning_rate": 4.587824711606237e-05,
      "loss": 0.044,
      "step": 9600
    },
    {
      "epoch": 0.6669875541497627,
      "grad_norm": 0.15453368425369263,
      "learning_rate": 4.583526741967095e-05,
      "loss": 0.0458,
      "step": 9700
    },
    {
      "epoch": 0.6738637145018221,
      "grad_norm": 0.2000521868467331,
      "learning_rate": 4.5792287723279526e-05,
      "loss": 0.0446,
      "step": 9800
    },
    {
      "epoch": 0.6807398748538815,
      "grad_norm": 0.21329475939273834,
      "learning_rate": 4.57493080268881e-05,
      "loss": 0.0455,
      "step": 9900
    },
    {
      "epoch": 0.6876160352059411,
      "grad_norm": 0.1646937131881714,
      "learning_rate": 4.570632833049668e-05,
      "loss": 0.0454,
      "step": 10000
    },
    {
      "epoch": 0.6944921955580005,
      "grad_norm": 0.21601924300193787,
      "learning_rate": 4.5663348634105254e-05,
      "loss": 0.0462,
      "step": 10100
    },
    {
      "epoch": 0.7013683559100599,
      "grad_norm": 0.27014607191085815,
      "learning_rate": 4.562036893771383e-05,
      "loss": 0.0456,
      "step": 10200
    },
    {
      "epoch": 0.7082445162621193,
      "grad_norm": 0.14401207864284515,
      "learning_rate": 4.55773892413224e-05,
      "loss": 0.0434,
      "step": 10300
    },
    {
      "epoch": 0.7151206766141787,
      "grad_norm": 0.17662249505519867,
      "learning_rate": 4.5534409544930976e-05,
      "loss": 0.0428,
      "step": 10400
    },
    {
      "epoch": 0.7219968369662381,
      "grad_norm": 0.19474250078201294,
      "learning_rate": 4.549142984853955e-05,
      "loss": 0.0457,
      "step": 10500
    },
    {
      "epoch": 0.7288729973182975,
      "grad_norm": 0.25588759779930115,
      "learning_rate": 4.5448450152148124e-05,
      "loss": 0.0444,
      "step": 10600
    },
    {
      "epoch": 0.7357491576703569,
      "grad_norm": 0.2241983264684677,
      "learning_rate": 4.540590025272062e-05,
      "loss": 0.0423,
      "step": 10700
    },
    {
      "epoch": 0.7426253180224163,
      "grad_norm": 0.14925655722618103,
      "learning_rate": 4.5362920556329194e-05,
      "loss": 0.0449,
      "step": 10800
    },
    {
      "epoch": 0.7495014783744757,
      "grad_norm": 0.18971046805381775,
      "learning_rate": 4.531994085993777e-05,
      "loss": 0.0451,
      "step": 10900
    },
    {
      "epoch": 0.7563776387265351,
      "grad_norm": 0.2267855554819107,
      "learning_rate": 4.527696116354634e-05,
      "loss": 0.043,
      "step": 11000
    },
    {
      "epoch": 0.7632537990785945,
      "grad_norm": 0.1352309286594391,
      "learning_rate": 4.5233981467154915e-05,
      "loss": 0.042,
      "step": 11100
    },
    {
      "epoch": 0.7701299594306539,
      "grad_norm": 0.1748579740524292,
      "learning_rate": 4.519100177076349e-05,
      "loss": 0.0433,
      "step": 11200
    },
    {
      "epoch": 0.7770061197827133,
      "grad_norm": 0.16246408224105835,
      "learning_rate": 4.514802207437207e-05,
      "loss": 0.0443,
      "step": 11300
    },
    {
      "epoch": 0.7838822801347728,
      "grad_norm": 0.23050665855407715,
      "learning_rate": 4.5105042377980644e-05,
      "loss": 0.0446,
      "step": 11400
    },
    {
      "epoch": 0.7907584404868322,
      "grad_norm": 0.1972157061100006,
      "learning_rate": 4.506206268158922e-05,
      "loss": 0.0424,
      "step": 11500
    },
    {
      "epoch": 0.7976346008388916,
      "grad_norm": 0.2073179930448532,
      "learning_rate": 4.50190829851978e-05,
      "loss": 0.0443,
      "step": 11600
    },
    {
      "epoch": 0.804510761190951,
      "grad_norm": 0.2743304669857025,
      "learning_rate": 4.497610328880637e-05,
      "loss": 0.0466,
      "step": 11700
    },
    {
      "epoch": 0.8113869215430104,
      "grad_norm": 0.10400901734828949,
      "learning_rate": 4.4933123592414946e-05,
      "loss": 0.0417,
      "step": 11800
    },
    {
      "epoch": 0.8182630818950698,
      "grad_norm": 0.186038538813591,
      "learning_rate": 4.489014389602352e-05,
      "loss": 0.044,
      "step": 11900
    },
    {
      "epoch": 0.8251392422471292,
      "grad_norm": 0.23457716405391693,
      "learning_rate": 4.4847164199632094e-05,
      "loss": 0.0456,
      "step": 12000
    },
    {
      "epoch": 0.8320154025991886,
      "grad_norm": 0.1593772917985916,
      "learning_rate": 4.480418450324067e-05,
      "loss": 0.0435,
      "step": 12100
    },
    {
      "epoch": 0.838891562951248,
      "grad_norm": 0.16532981395721436,
      "learning_rate": 4.476120480684924e-05,
      "loss": 0.0439,
      "step": 12200
    },
    {
      "epoch": 0.8457677233033074,
      "grad_norm": 0.14794430136680603,
      "learning_rate": 4.471822511045782e-05,
      "loss": 0.0405,
      "step": 12300
    },
    {
      "epoch": 0.8526438836553668,
      "grad_norm": 0.17681492865085602,
      "learning_rate": 4.4675245414066397e-05,
      "loss": 0.041,
      "step": 12400
    },
    {
      "epoch": 0.8595200440074262,
      "grad_norm": 0.17439009249210358,
      "learning_rate": 4.463226571767497e-05,
      "loss": 0.0438,
      "step": 12500
    },
    {
      "epoch": 0.8663962043594856,
      "grad_norm": 0.16084575653076172,
      "learning_rate": 4.458928602128355e-05,
      "loss": 0.0434,
      "step": 12600
    },
    {
      "epoch": 0.8732723647115451,
      "grad_norm": 0.10826137661933899,
      "learning_rate": 4.4546306324892125e-05,
      "loss": 0.0448,
      "step": 12700
    },
    {
      "epoch": 0.8801485250636045,
      "grad_norm": 0.17075727880001068,
      "learning_rate": 4.45033266285007e-05,
      "loss": 0.0463,
      "step": 12800
    },
    {
      "epoch": 0.8870246854156639,
      "grad_norm": 0.23610955476760864,
      "learning_rate": 4.446034693210927e-05,
      "loss": 0.0458,
      "step": 12900
    },
    {
      "epoch": 0.8939008457677233,
      "grad_norm": 0.18193304538726807,
      "learning_rate": 4.441736723571785e-05,
      "loss": 0.0445,
      "step": 13000
    },
    {
      "epoch": 0.9007770061197827,
      "grad_norm": 0.17780233919620514,
      "learning_rate": 4.437438753932642e-05,
      "loss": 0.0435,
      "step": 13100
    },
    {
      "epoch": 0.9076531664718421,
      "grad_norm": 0.18695449829101562,
      "learning_rate": 4.4331407842935e-05,
      "loss": 0.0455,
      "step": 13200
    },
    {
      "epoch": 0.9145293268239015,
      "grad_norm": 0.205387145280838,
      "learning_rate": 4.4288428146543575e-05,
      "loss": 0.0437,
      "step": 13300
    },
    {
      "epoch": 0.9214054871759609,
      "grad_norm": 0.15106332302093506,
      "learning_rate": 4.4245878247116064e-05,
      "loss": 0.039,
      "step": 13400
    },
    {
      "epoch": 0.9282816475280203,
      "grad_norm": 0.14670346677303314,
      "learning_rate": 4.4202898550724645e-05,
      "loss": 0.0437,
      "step": 13500
    },
    {
      "epoch": 0.9351578078800797,
      "grad_norm": 0.15356571972370148,
      "learning_rate": 4.415991885433321e-05,
      "loss": 0.0424,
      "step": 13600
    },
    {
      "epoch": 0.9420339682321391,
      "grad_norm": 0.1516391783952713,
      "learning_rate": 4.4116939157941786e-05,
      "loss": 0.0445,
      "step": 13700
    },
    {
      "epoch": 0.9489101285841985,
      "grad_norm": 0.16858546435832977,
      "learning_rate": 4.407395946155037e-05,
      "loss": 0.0433,
      "step": 13800
    },
    {
      "epoch": 0.9557862889362579,
      "grad_norm": 0.2171129286289215,
      "learning_rate": 4.403097976515894e-05,
      "loss": 0.0443,
      "step": 13900
    },
    {
      "epoch": 0.9626624492883175,
      "grad_norm": 0.14426392316818237,
      "learning_rate": 4.3988000068767515e-05,
      "loss": 0.0428,
      "step": 14000
    },
    {
      "epoch": 0.9695386096403769,
      "grad_norm": 0.17460305988788605,
      "learning_rate": 4.394502037237609e-05,
      "loss": 0.044,
      "step": 14100
    },
    {
      "epoch": 0.9764147699924363,
      "grad_norm": 0.1743331402540207,
      "learning_rate": 4.390204067598467e-05,
      "loss": 0.0429,
      "step": 14200
    },
    {
      "epoch": 0.9832909303444957,
      "grad_norm": 0.16972662508487701,
      "learning_rate": 4.385906097959324e-05,
      "loss": 0.0402,
      "step": 14300
    },
    {
      "epoch": 0.9901670906965551,
      "grad_norm": 0.22072450816631317,
      "learning_rate": 4.381608128320182e-05,
      "loss": 0.0392,
      "step": 14400
    },
    {
      "epoch": 0.9970432510486145,
      "grad_norm": 0.20388078689575195,
      "learning_rate": 4.37731015868104e-05,
      "loss": 0.0406,
      "step": 14500
    },
    {
      "epoch": 1.0,
      "eval_accuracy_macro_0.5": 0.9805033206939697,
      "eval_accuracy_micro_0.5": 0.9805033206939697,
      "eval_accuracy_weighted_0.5": 0.9779812693595886,
      "eval_f1_macro_0.5": 0.7316100597381592,
      "eval_f1_macro_0.6": 0.7064381837844849,
      "eval_f1_macro_0.7": 0.6627254486083984,
      "eval_f1_macro_0.8": 0.46580517292022705,
      "eval_f1_micro_0.5": 0.7350919842720032,
      "eval_f1_micro_0.6": 0.7144057154655457,
      "eval_f1_micro_0.7": 0.6767651438713074,
      "eval_f1_micro_0.8": 0.6159805059432983,
      "eval_f1_micro_0.9": 0.48976239562034607,
      "eval_f1_weighted_0.5": 0.725976288318634,
      "eval_f1_weighted_0.6": 0.6993381977081299,
      "eval_f1_weighted_0.7": 0.6541252136230469,
      "eval_f1_weighted_0.8": 0.4447149634361267,
      "eval_loss": 0.04017025977373123,
      "eval_runtime": 143.0719,
      "eval_samples_per_second": 202.954,
      "eval_steps_per_second": 25.372,
      "step": 14543
    },
    {
      "epoch": 1.0039194114006738,
      "grad_norm": 0.1211576908826828,
      "learning_rate": 4.3730121890418965e-05,
      "loss": 0.0405,
      "step": 14600
    },
    {
      "epoch": 1.0107955717527333,
      "grad_norm": 0.06243908405303955,
      "learning_rate": 4.368714219402754e-05,
      "loss": 0.0417,
      "step": 14700
    },
    {
      "epoch": 1.0176717321047928,
      "grad_norm": 0.12645064294338226,
      "learning_rate": 4.364416249763612e-05,
      "loss": 0.0405,
      "step": 14800
    },
    {
      "epoch": 1.024547892456852,
      "grad_norm": 0.15859301388263702,
      "learning_rate": 4.3601182801244693e-05,
      "loss": 0.0413,
      "step": 14900
    },
    {
      "epoch": 1.0314240528089116,
      "grad_norm": 0.259613037109375,
      "learning_rate": 4.355820310485327e-05,
      "loss": 0.0434,
      "step": 15000
    },
    {
      "epoch": 1.0383002131609709,
      "grad_norm": 0.12923774123191833,
      "learning_rate": 4.351522340846185e-05,
      "loss": 0.0439,
      "step": 15100
    },
    {
      "epoch": 1.0451763735130304,
      "grad_norm": 0.09845209866762161,
      "learning_rate": 4.347224371207042e-05,
      "loss": 0.039,
      "step": 15200
    },
    {
      "epoch": 1.0520525338650897,
      "grad_norm": 0.19922375679016113,
      "learning_rate": 4.3429264015678996e-05,
      "loss": 0.0409,
      "step": 15300
    },
    {
      "epoch": 1.0589286942171492,
      "grad_norm": 0.17663492262363434,
      "learning_rate": 4.3386714116251485e-05,
      "loss": 0.0439,
      "step": 15400
    },
    {
      "epoch": 1.0658048545692085,
      "grad_norm": 0.22946679592132568,
      "learning_rate": 4.334373441986006e-05,
      "loss": 0.0428,
      "step": 15500
    },
    {
      "epoch": 1.072681014921268,
      "grad_norm": 0.1608659029006958,
      "learning_rate": 4.330075472346863e-05,
      "loss": 0.0391,
      "step": 15600
    },
    {
      "epoch": 1.0795571752733273,
      "grad_norm": 0.15009832382202148,
      "learning_rate": 4.3257775027077213e-05,
      "loss": 0.0416,
      "step": 15700
    },
    {
      "epoch": 1.0864333356253868,
      "grad_norm": 0.23984861373901367,
      "learning_rate": 4.321479533068579e-05,
      "loss": 0.0403,
      "step": 15800
    },
    {
      "epoch": 1.0933094959774463,
      "grad_norm": 0.13192243874073029,
      "learning_rate": 4.317181563429436e-05,
      "loss": 0.0439,
      "step": 15900
    },
    {
      "epoch": 1.1001856563295056,
      "grad_norm": 0.2795294523239136,
      "learning_rate": 4.312883593790294e-05,
      "loss": 0.0396,
      "step": 16000
    },
    {
      "epoch": 1.1070618166815651,
      "grad_norm": 0.3107834458351135,
      "learning_rate": 4.3085856241511516e-05,
      "loss": 0.0396,
      "step": 16100
    },
    {
      "epoch": 1.1139379770336244,
      "grad_norm": 0.22125813364982605,
      "learning_rate": 4.304287654512009e-05,
      "loss": 0.0381,
      "step": 16200
    },
    {
      "epoch": 1.120814137385684,
      "grad_norm": 0.24820472300052643,
      "learning_rate": 4.299989684872866e-05,
      "loss": 0.0406,
      "step": 16300
    },
    {
      "epoch": 1.1276902977377432,
      "grad_norm": 0.16949234902858734,
      "learning_rate": 4.295691715233724e-05,
      "loss": 0.0396,
      "step": 16400
    },
    {
      "epoch": 1.1345664580898027,
      "grad_norm": 0.21118830144405365,
      "learning_rate": 4.291393745594581e-05,
      "loss": 0.0393,
      "step": 16500
    },
    {
      "epoch": 1.141442618441862,
      "grad_norm": 0.16090674698352814,
      "learning_rate": 4.2870957759554385e-05,
      "loss": 0.0421,
      "step": 16600
    },
    {
      "epoch": 1.1483187787939215,
      "grad_norm": 0.1694469302892685,
      "learning_rate": 4.2827978063162966e-05,
      "loss": 0.0403,
      "step": 16700
    },
    {
      "epoch": 1.1551949391459808,
      "grad_norm": 0.22885483503341675,
      "learning_rate": 4.278499836677154e-05,
      "loss": 0.0429,
      "step": 16800
    },
    {
      "epoch": 1.1620710994980403,
      "grad_norm": 0.22066707909107208,
      "learning_rate": 4.2742018670380114e-05,
      "loss": 0.0404,
      "step": 16900
    },
    {
      "epoch": 1.1689472598500996,
      "grad_norm": 0.25265005230903625,
      "learning_rate": 4.2699038973988695e-05,
      "loss": 0.0411,
      "step": 17000
    },
    {
      "epoch": 1.1758234202021591,
      "grad_norm": 0.19615909457206726,
      "learning_rate": 4.265605927759727e-05,
      "loss": 0.0397,
      "step": 17100
    },
    {
      "epoch": 1.1826995805542184,
      "grad_norm": 0.20513489842414856,
      "learning_rate": 4.261307958120584e-05,
      "loss": 0.0389,
      "step": 17200
    },
    {
      "epoch": 1.189575740906278,
      "grad_norm": 0.21760086715221405,
      "learning_rate": 4.2570099884814416e-05,
      "loss": 0.0415,
      "step": 17300
    },
    {
      "epoch": 1.1964519012583374,
      "grad_norm": 0.14436277747154236,
      "learning_rate": 4.252712018842299e-05,
      "loss": 0.0421,
      "step": 17400
    },
    {
      "epoch": 1.2033280616103967,
      "grad_norm": 0.1163032054901123,
      "learning_rate": 4.2484140492031564e-05,
      "loss": 0.0418,
      "step": 17500
    },
    {
      "epoch": 1.2102042219624563,
      "grad_norm": 0.20354437828063965,
      "learning_rate": 4.244116079564014e-05,
      "loss": 0.0416,
      "step": 17600
    },
    {
      "epoch": 1.2170803823145155,
      "grad_norm": 0.16512836515903473,
      "learning_rate": 4.239818109924872e-05,
      "loss": 0.0444,
      "step": 17700
    },
    {
      "epoch": 1.223956542666575,
      "grad_norm": 0.1353074014186859,
      "learning_rate": 4.235520140285729e-05,
      "loss": 0.0413,
      "step": 17800
    },
    {
      "epoch": 1.2308327030186343,
      "grad_norm": 0.14950893819332123,
      "learning_rate": 4.2312221706465867e-05,
      "loss": 0.0398,
      "step": 17900
    },
    {
      "epoch": 1.2377088633706939,
      "grad_norm": 0.14060084521770477,
      "learning_rate": 4.226924201007445e-05,
      "loss": 0.0404,
      "step": 18000
    },
    {
      "epoch": 1.2445850237227531,
      "grad_norm": 0.11358488351106644,
      "learning_rate": 4.222626231368302e-05,
      "loss": 0.0394,
      "step": 18100
    },
    {
      "epoch": 1.2514611840748127,
      "grad_norm": 0.34591275453567505,
      "learning_rate": 4.2183282617291595e-05,
      "loss": 0.0412,
      "step": 18200
    },
    {
      "epoch": 1.258337344426872,
      "grad_norm": 0.12948614358901978,
      "learning_rate": 4.214030292090017e-05,
      "loss": 0.0387,
      "step": 18300
    },
    {
      "epoch": 1.2652135047789315,
      "grad_norm": 0.1734899878501892,
      "learning_rate": 4.209732322450874e-05,
      "loss": 0.0387,
      "step": 18400
    },
    {
      "epoch": 1.272089665130991,
      "grad_norm": 0.16841349005699158,
      "learning_rate": 4.205477332508123e-05,
      "loss": 0.0405,
      "step": 18500
    },
    {
      "epoch": 1.2789658254830503,
      "grad_norm": 0.1721780002117157,
      "learning_rate": 4.201179362868981e-05,
      "loss": 0.0389,
      "step": 18600
    },
    {
      "epoch": 1.2858419858351096,
      "grad_norm": 0.18200474977493286,
      "learning_rate": 4.1968813932298387e-05,
      "loss": 0.038,
      "step": 18700
    },
    {
      "epoch": 1.292718146187169,
      "grad_norm": 0.17175427079200745,
      "learning_rate": 4.192583423590696e-05,
      "loss": 0.0416,
      "step": 18800
    },
    {
      "epoch": 1.2995943065392286,
      "grad_norm": 0.23312360048294067,
      "learning_rate": 4.1882854539515534e-05,
      "loss": 0.0382,
      "step": 18900
    },
    {
      "epoch": 1.3064704668912879,
      "grad_norm": 0.13758991658687592,
      "learning_rate": 4.183987484312411e-05,
      "loss": 0.0403,
      "step": 19000
    },
    {
      "epoch": 1.3133466272433474,
      "grad_norm": 0.1429460197687149,
      "learning_rate": 4.179689514673268e-05,
      "loss": 0.0392,
      "step": 19100
    },
    {
      "epoch": 1.3202227875954067,
      "grad_norm": 0.15309712290763855,
      "learning_rate": 4.175391545034126e-05,
      "loss": 0.0429,
      "step": 19200
    },
    {
      "epoch": 1.3270989479474662,
      "grad_norm": 0.2023094892501831,
      "learning_rate": 4.171093575394984e-05,
      "loss": 0.0403,
      "step": 19300
    },
    {
      "epoch": 1.3339751082995255,
      "grad_norm": 0.1699143350124359,
      "learning_rate": 4.166795605755841e-05,
      "loss": 0.0392,
      "step": 19400
    },
    {
      "epoch": 1.340851268651585,
      "grad_norm": 0.11594083905220032,
      "learning_rate": 4.1624976361166985e-05,
      "loss": 0.042,
      "step": 19500
    },
    {
      "epoch": 1.3477274290036443,
      "grad_norm": 0.22324281930923462,
      "learning_rate": 4.1581996664775565e-05,
      "loss": 0.0383,
      "step": 19600
    },
    {
      "epoch": 1.3546035893557038,
      "grad_norm": 0.2059706449508667,
      "learning_rate": 4.153901696838414e-05,
      "loss": 0.0396,
      "step": 19700
    },
    {
      "epoch": 1.361479749707763,
      "grad_norm": 0.08081506937742233,
      "learning_rate": 4.149603727199271e-05,
      "loss": 0.0397,
      "step": 19800
    },
    {
      "epoch": 1.3683559100598226,
      "grad_norm": 0.27677208185195923,
      "learning_rate": 4.145305757560129e-05,
      "loss": 0.0394,
      "step": 19900
    },
    {
      "epoch": 1.3752320704118821,
      "grad_norm": 0.15435568988323212,
      "learning_rate": 4.141007787920986e-05,
      "loss": 0.0389,
      "step": 20000
    },
    {
      "epoch": 1.3821082307639414,
      "grad_norm": 0.17480888962745667,
      "learning_rate": 4.1367098182818435e-05,
      "loss": 0.038,
      "step": 20100
    },
    {
      "epoch": 1.3889843911160007,
      "grad_norm": 0.2474110871553421,
      "learning_rate": 4.1324118486427016e-05,
      "loss": 0.0401,
      "step": 20200
    },
    {
      "epoch": 1.3958605514680602,
      "grad_norm": 0.1306232362985611,
      "learning_rate": 4.128113879003559e-05,
      "loss": 0.0392,
      "step": 20300
    },
    {
      "epoch": 1.4027367118201197,
      "grad_norm": 0.22358278930187225,
      "learning_rate": 4.123858889060808e-05,
      "loss": 0.04,
      "step": 20400
    },
    {
      "epoch": 1.409612872172179,
      "grad_norm": 0.12137819826602936,
      "learning_rate": 4.119560919421665e-05,
      "loss": 0.0392,
      "step": 20500
    },
    {
      "epoch": 1.4164890325242385,
      "grad_norm": 0.1034570187330246,
      "learning_rate": 4.1152629497825226e-05,
      "loss": 0.0385,
      "step": 20600
    },
    {
      "epoch": 1.4233651928762978,
      "grad_norm": 0.20849527418613434,
      "learning_rate": 4.11096498014338e-05,
      "loss": 0.0415,
      "step": 20700
    },
    {
      "epoch": 1.4302413532283573,
      "grad_norm": 0.141657292842865,
      "learning_rate": 4.106667010504238e-05,
      "loss": 0.0393,
      "step": 20800
    },
    {
      "epoch": 1.4371175135804166,
      "grad_norm": 0.18946091830730438,
      "learning_rate": 4.1023690408650955e-05,
      "loss": 0.0405,
      "step": 20900
    },
    {
      "epoch": 1.4439936739324761,
      "grad_norm": 0.18850469589233398,
      "learning_rate": 4.098071071225953e-05,
      "loss": 0.0428,
      "step": 21000
    },
    {
      "epoch": 1.4508698342845356,
      "grad_norm": 0.24853964149951935,
      "learning_rate": 4.093773101586811e-05,
      "loss": 0.0406,
      "step": 21100
    },
    {
      "epoch": 1.457745994636595,
      "grad_norm": 0.23918305337429047,
      "learning_rate": 4.089475131947668e-05,
      "loss": 0.0391,
      "step": 21200
    },
    {
      "epoch": 1.4646221549886542,
      "grad_norm": 0.16311131417751312,
      "learning_rate": 4.085177162308526e-05,
      "loss": 0.0393,
      "step": 21300
    },
    {
      "epoch": 1.4714983153407137,
      "grad_norm": 0.17261254787445068,
      "learning_rate": 4.080879192669383e-05,
      "loss": 0.0361,
      "step": 21400
    },
    {
      "epoch": 1.4783744756927732,
      "grad_norm": 0.1038181334733963,
      "learning_rate": 4.0765812230302405e-05,
      "loss": 0.0393,
      "step": 21500
    },
    {
      "epoch": 1.4852506360448325,
      "grad_norm": 0.18708163499832153,
      "learning_rate": 4.072283253391098e-05,
      "loss": 0.0388,
      "step": 21600
    },
    {
      "epoch": 1.492126796396892,
      "grad_norm": 0.2424459159374237,
      "learning_rate": 4.067985283751955e-05,
      "loss": 0.0396,
      "step": 21700
    },
    {
      "epoch": 1.4990029567489513,
      "grad_norm": 0.10587311536073685,
      "learning_rate": 4.0636873141128134e-05,
      "loss": 0.0382,
      "step": 21800
    },
    {
      "epoch": 1.5058791171010109,
      "grad_norm": 0.1027398481965065,
      "learning_rate": 4.059389344473671e-05,
      "loss": 0.0361,
      "step": 21900
    },
    {
      "epoch": 1.5127552774530701,
      "grad_norm": 0.25136321783065796,
      "learning_rate": 4.055091374834528e-05,
      "loss": 0.0391,
      "step": 22000
    },
    {
      "epoch": 1.5196314378051297,
      "grad_norm": 0.17662136256694794,
      "learning_rate": 4.050793405195386e-05,
      "loss": 0.0389,
      "step": 22100
    },
    {
      "epoch": 1.5265075981571892,
      "grad_norm": 0.17324040830135345,
      "learning_rate": 4.0464954355562436e-05,
      "loss": 0.0378,
      "step": 22200
    },
    {
      "epoch": 1.5333837585092485,
      "grad_norm": 0.23189763724803925,
      "learning_rate": 4.042197465917101e-05,
      "loss": 0.0366,
      "step": 22300
    },
    {
      "epoch": 1.5402599188613078,
      "grad_norm": 0.1862328052520752,
      "learning_rate": 4.0378994962779584e-05,
      "loss": 0.0419,
      "step": 22400
    },
    {
      "epoch": 1.5471360792133673,
      "grad_norm": 0.27628451585769653,
      "learning_rate": 4.033601526638816e-05,
      "loss": 0.0373,
      "step": 22500
    },
    {
      "epoch": 1.5540122395654268,
      "grad_norm": 0.22922028601169586,
      "learning_rate": 4.029303556999673e-05,
      "loss": 0.0384,
      "step": 22600
    },
    {
      "epoch": 1.560888399917486,
      "grad_norm": 0.16939227283000946,
      "learning_rate": 4.025005587360531e-05,
      "loss": 0.0396,
      "step": 22700
    },
    {
      "epoch": 1.5677645602695454,
      "grad_norm": 0.22237902879714966,
      "learning_rate": 4.0207076177213886e-05,
      "loss": 0.0388,
      "step": 22800
    },
    {
      "epoch": 1.5746407206216049,
      "grad_norm": 0.18543435633182526,
      "learning_rate": 4.016409648082246e-05,
      "loss": 0.0395,
      "step": 22900
    },
    {
      "epoch": 1.5815168809736644,
      "grad_norm": 0.1494571566581726,
      "learning_rate": 4.0121116784431034e-05,
      "loss": 0.0385,
      "step": 23000
    },
    {
      "epoch": 1.5883930413257237,
      "grad_norm": 0.15902912616729736,
      "learning_rate": 4.0078137088039615e-05,
      "loss": 0.0366,
      "step": 23100
    },
    {
      "epoch": 1.595269201677783,
      "grad_norm": 0.16116318106651306,
      "learning_rate": 4.003515739164819e-05,
      "loss": 0.0353,
      "step": 23200
    },
    {
      "epoch": 1.6021453620298427,
      "grad_norm": 0.23663155734539032,
      "learning_rate": 3.999217769525676e-05,
      "loss": 0.0375,
      "step": 23300
    },
    {
      "epoch": 1.609021522381902,
      "grad_norm": 0.09886743128299713,
      "learning_rate": 3.9949197998865337e-05,
      "loss": 0.0372,
      "step": 23400
    },
    {
      "epoch": 1.6158976827339613,
      "grad_norm": 0.22848689556121826,
      "learning_rate": 3.990621830247391e-05,
      "loss": 0.0405,
      "step": 23500
    },
    {
      "epoch": 1.6227738430860208,
      "grad_norm": 0.2112652212381363,
      "learning_rate": 3.9863238606082484e-05,
      "loss": 0.0378,
      "step": 23600
    },
    {
      "epoch": 1.6296500034380803,
      "grad_norm": 0.2251802384853363,
      "learning_rate": 3.9820258909691065e-05,
      "loss": 0.0387,
      "step": 23700
    },
    {
      "epoch": 1.6365261637901396,
      "grad_norm": 0.1787601262331009,
      "learning_rate": 3.977727921329964e-05,
      "loss": 0.0376,
      "step": 23800
    },
    {
      "epoch": 1.643402324142199,
      "grad_norm": 0.12341461330652237,
      "learning_rate": 3.973429951690821e-05,
      "loss": 0.0408,
      "step": 23900
    },
    {
      "epoch": 1.6502784844942584,
      "grad_norm": 0.15336981415748596,
      "learning_rate": 3.9691319820516794e-05,
      "loss": 0.0383,
      "step": 24000
    },
    {
      "epoch": 1.657154644846318,
      "grad_norm": 0.20326033234596252,
      "learning_rate": 3.964834012412537e-05,
      "loss": 0.0386,
      "step": 24100
    },
    {
      "epoch": 1.6640308051983772,
      "grad_norm": 0.13799165189266205,
      "learning_rate": 3.960536042773394e-05,
      "loss": 0.038,
      "step": 24200
    },
    {
      "epoch": 1.6709069655504365,
      "grad_norm": 0.19867922365665436,
      "learning_rate": 3.9562380731342515e-05,
      "loss": 0.0374,
      "step": 24300
    },
    {
      "epoch": 1.677783125902496,
      "grad_norm": 0.19593197107315063,
      "learning_rate": 3.951940103495109e-05,
      "loss": 0.0386,
      "step": 24400
    },
    {
      "epoch": 1.6846592862545555,
      "grad_norm": 0.19332249462604523,
      "learning_rate": 3.947685113552358e-05,
      "loss": 0.0366,
      "step": 24500
    },
    {
      "epoch": 1.6915354466066148,
      "grad_norm": 0.3572232127189636,
      "learning_rate": 3.9434301236096074e-05,
      "loss": 0.0378,
      "step": 24600
    },
    {
      "epoch": 1.6984116069586743,
      "grad_norm": 0.18048320710659027,
      "learning_rate": 3.939132153970465e-05,
      "loss": 0.0384,
      "step": 24700
    },
    {
      "epoch": 1.7052877673107338,
      "grad_norm": 0.19029052555561066,
      "learning_rate": 3.934834184331322e-05,
      "loss": 0.0396,
      "step": 24800
    },
    {
      "epoch": 1.7121639276627931,
      "grad_norm": 0.15873488783836365,
      "learning_rate": 3.9305362146921796e-05,
      "loss": 0.0391,
      "step": 24900
    },
    {
      "epoch": 1.7190400880148524,
      "grad_norm": 0.143522247672081,
      "learning_rate": 3.926238245053037e-05,
      "loss": 0.0373,
      "step": 25000
    },
    {
      "epoch": 1.725916248366912,
      "grad_norm": 0.22456234693527222,
      "learning_rate": 3.9219402754138944e-05,
      "loss": 0.0387,
      "step": 25100
    },
    {
      "epoch": 1.7327924087189714,
      "grad_norm": 0.07615450769662857,
      "learning_rate": 3.9176423057747524e-05,
      "loss": 0.0385,
      "step": 25200
    },
    {
      "epoch": 1.7396685690710307,
      "grad_norm": 0.11074142158031464,
      "learning_rate": 3.91334433613561e-05,
      "loss": 0.0348,
      "step": 25300
    },
    {
      "epoch": 1.74654472942309,
      "grad_norm": 0.42549481987953186,
      "learning_rate": 3.909046366496467e-05,
      "loss": 0.0368,
      "step": 25400
    },
    {
      "epoch": 1.7534208897751495,
      "grad_norm": 0.15128418803215027,
      "learning_rate": 3.9047483968573246e-05,
      "loss": 0.0377,
      "step": 25500
    },
    {
      "epoch": 1.760297050127209,
      "grad_norm": 0.14642268419265747,
      "learning_rate": 3.900450427218183e-05,
      "loss": 0.0386,
      "step": 25600
    },
    {
      "epoch": 1.7671732104792683,
      "grad_norm": 0.16916657984256744,
      "learning_rate": 3.89615245757904e-05,
      "loss": 0.0368,
      "step": 25700
    },
    {
      "epoch": 1.7740493708313276,
      "grad_norm": 0.2251366674900055,
      "learning_rate": 3.8918544879398975e-05,
      "loss": 0.0397,
      "step": 25800
    },
    {
      "epoch": 1.7809255311833871,
      "grad_norm": 0.2357281595468521,
      "learning_rate": 3.887556518300755e-05,
      "loss": 0.0384,
      "step": 25900
    },
    {
      "epoch": 1.7878016915354467,
      "grad_norm": 0.1695404052734375,
      "learning_rate": 3.883258548661612e-05,
      "loss": 0.0353,
      "step": 26000
    },
    {
      "epoch": 1.794677851887506,
      "grad_norm": 0.1660076528787613,
      "learning_rate": 3.8789605790224696e-05,
      "loss": 0.0363,
      "step": 26100
    },
    {
      "epoch": 1.8015540122395655,
      "grad_norm": 0.23119722306728363,
      "learning_rate": 3.874662609383328e-05,
      "loss": 0.0374,
      "step": 26200
    },
    {
      "epoch": 1.808430172591625,
      "grad_norm": 0.1744428426027298,
      "learning_rate": 3.870364639744185e-05,
      "loss": 0.0378,
      "step": 26300
    },
    {
      "epoch": 1.8153063329436843,
      "grad_norm": 0.28014838695526123,
      "learning_rate": 3.8660666701050425e-05,
      "loss": 0.0382,
      "step": 26400
    },
    {
      "epoch": 1.8221824932957436,
      "grad_norm": 0.163198322057724,
      "learning_rate": 3.8617687004659005e-05,
      "loss": 0.0409,
      "step": 26500
    },
    {
      "epoch": 1.829058653647803,
      "grad_norm": 0.24628540873527527,
      "learning_rate": 3.857470730826758e-05,
      "loss": 0.0399,
      "step": 26600
    },
    {
      "epoch": 1.8359348139998626,
      "grad_norm": 0.2257494479417801,
      "learning_rate": 3.853172761187615e-05,
      "loss": 0.0384,
      "step": 26700
    },
    {
      "epoch": 1.8428109743519219,
      "grad_norm": 0.3071775436401367,
      "learning_rate": 3.848874791548473e-05,
      "loss": 0.0367,
      "step": 26800
    },
    {
      "epoch": 1.8496871347039812,
      "grad_norm": 0.22593346238136292,
      "learning_rate": 3.8446198016057216e-05,
      "loss": 0.0381,
      "step": 26900
    },
    {
      "epoch": 1.8565632950560407,
      "grad_norm": 0.28784218430519104,
      "learning_rate": 3.840321831966579e-05,
      "loss": 0.0362,
      "step": 27000
    },
    {
      "epoch": 1.8634394554081002,
      "grad_norm": 0.1699904054403305,
      "learning_rate": 3.836023862327437e-05,
      "loss": 0.0363,
      "step": 27100
    },
    {
      "epoch": 1.8703156157601595,
      "grad_norm": 0.2100963443517685,
      "learning_rate": 3.8317258926882945e-05,
      "loss": 0.0377,
      "step": 27200
    },
    {
      "epoch": 1.877191776112219,
      "grad_norm": 0.16142921149730682,
      "learning_rate": 3.827427923049152e-05,
      "loss": 0.0375,
      "step": 27300
    },
    {
      "epoch": 1.8840679364642785,
      "grad_norm": 0.14652198553085327,
      "learning_rate": 3.823129953410009e-05,
      "loss": 0.0385,
      "step": 27400
    },
    {
      "epoch": 1.8909440968163378,
      "grad_norm": 0.1388692557811737,
      "learning_rate": 3.8188319837708667e-05,
      "loss": 0.0376,
      "step": 27500
    },
    {
      "epoch": 1.897820257168397,
      "grad_norm": 0.30976325273513794,
      "learning_rate": 3.814534014131724e-05,
      "loss": 0.0379,
      "step": 27600
    },
    {
      "epoch": 1.9046964175204566,
      "grad_norm": 0.17200632393360138,
      "learning_rate": 3.8102360444925814e-05,
      "loss": 0.0395,
      "step": 27700
    },
    {
      "epoch": 1.911572577872516,
      "grad_norm": 0.1632431298494339,
      "learning_rate": 3.8059380748534395e-05,
      "loss": 0.0371,
      "step": 27800
    },
    {
      "epoch": 1.9184487382245754,
      "grad_norm": 0.13935399055480957,
      "learning_rate": 3.801640105214297e-05,
      "loss": 0.0395,
      "step": 27900
    },
    {
      "epoch": 1.9253248985766347,
      "grad_norm": 0.21520206332206726,
      "learning_rate": 3.797342135575154e-05,
      "loss": 0.0379,
      "step": 28000
    },
    {
      "epoch": 1.9322010589286942,
      "grad_norm": 0.21598374843597412,
      "learning_rate": 3.7930441659360124e-05,
      "loss": 0.0353,
      "step": 28100
    },
    {
      "epoch": 1.9390772192807537,
      "grad_norm": 0.19737817347049713,
      "learning_rate": 3.78874619629687e-05,
      "loss": 0.0415,
      "step": 28200
    },
    {
      "epoch": 1.945953379632813,
      "grad_norm": 0.21828541159629822,
      "learning_rate": 3.784448226657727e-05,
      "loss": 0.0357,
      "step": 28300
    },
    {
      "epoch": 1.9528295399848723,
      "grad_norm": 0.1225532814860344,
      "learning_rate": 3.780193236714976e-05,
      "loss": 0.0371,
      "step": 28400
    },
    {
      "epoch": 1.9597057003369318,
      "grad_norm": 0.15251053869724274,
      "learning_rate": 3.7758952670758334e-05,
      "loss": 0.0373,
      "step": 28500
    },
    {
      "epoch": 1.9665818606889913,
      "grad_norm": 0.20325081050395966,
      "learning_rate": 3.771597297436691e-05,
      "loss": 0.0374,
      "step": 28600
    },
    {
      "epoch": 1.9734580210410506,
      "grad_norm": 0.1256670206785202,
      "learning_rate": 3.767299327797549e-05,
      "loss": 0.0341,
      "step": 28700
    },
    {
      "epoch": 1.9803341813931101,
      "grad_norm": 0.15708161890506744,
      "learning_rate": 3.763001358158406e-05,
      "loss": 0.0393,
      "step": 28800
    },
    {
      "epoch": 1.9872103417451696,
      "grad_norm": 0.21522848308086395,
      "learning_rate": 3.758703388519264e-05,
      "loss": 0.0382,
      "step": 28900
    },
    {
      "epoch": 1.994086502097229,
      "grad_norm": 0.25244465470314026,
      "learning_rate": 3.754405418880122e-05,
      "loss": 0.0389,
      "step": 29000
    },
    {
      "epoch": 2.0,
      "eval_accuracy_macro_0.5": 0.9830291867256165,
      "eval_accuracy_micro_0.5": 0.9830291867256165,
      "eval_accuracy_weighted_0.5": 0.9807491898536682,
      "eval_f1_macro_0.5": 0.7717244625091553,
      "eval_f1_macro_0.6": 0.7528699636459351,
      "eval_f1_macro_0.7": 0.7199262380599976,
      "eval_f1_macro_0.8": 0.5587631464004517,
      "eval_f1_micro_0.5": 0.7743837237358093,
      "eval_f1_micro_0.6": 0.7602657079696655,
      "eval_f1_micro_0.7": 0.7334853410720825,
      "eval_f1_micro_0.8": 0.6863937377929688,
      "eval_f1_micro_0.9": 0.5876787900924683,
      "eval_f1_weighted_0.5": 0.767867386341095,
      "eval_f1_weighted_0.6": 0.7493019700050354,
      "eval_f1_weighted_0.7": 0.7165389657020569,
      "eval_f1_weighted_0.8": 0.5516320466995239,
      "eval_loss": 0.03501210734248161,
      "eval_runtime": 220.7968,
      "eval_samples_per_second": 131.51,
      "eval_steps_per_second": 16.44,
      "step": 29086
    },
    {
      "epoch": 2.000962662449288,
      "grad_norm": 0.25376731157302856,
      "learning_rate": 3.7501074492409785e-05,
      "loss": 0.0372,
      "step": 29100
    },
    {
      "epoch": 2.0078388228013475,
      "grad_norm": 0.22077688574790955,
      "learning_rate": 3.745809479601836e-05,
      "loss": 0.0353,
      "step": 29200
    },
    {
      "epoch": 2.0147149831534072,
      "grad_norm": 0.1738530546426773,
      "learning_rate": 3.741511509962694e-05,
      "loss": 0.037,
      "step": 29300
    },
    {
      "epoch": 2.0215911435054665,
      "grad_norm": 0.13306927680969238,
      "learning_rate": 3.737213540323551e-05,
      "loss": 0.0375,
      "step": 29400
    },
    {
      "epoch": 2.028467303857526,
      "grad_norm": 0.33744388818740845,
      "learning_rate": 3.732915570684409e-05,
      "loss": 0.0371,
      "step": 29500
    },
    {
      "epoch": 2.0353434642095856,
      "grad_norm": 0.11267402023077011,
      "learning_rate": 3.728617601045266e-05,
      "loss": 0.0346,
      "step": 29600
    },
    {
      "epoch": 2.042219624561645,
      "grad_norm": 0.1525447964668274,
      "learning_rate": 3.724319631406124e-05,
      "loss": 0.0346,
      "step": 29700
    },
    {
      "epoch": 2.049095784913704,
      "grad_norm": 0.16138394176959991,
      "learning_rate": 3.7200216617669816e-05,
      "loss": 0.0365,
      "step": 29800
    },
    {
      "epoch": 2.0559719452657634,
      "grad_norm": 0.184360072016716,
      "learning_rate": 3.715723692127839e-05,
      "loss": 0.0374,
      "step": 29900
    },
    {
      "epoch": 2.062848105617823,
      "grad_norm": 0.17059336602687836,
      "learning_rate": 3.711425722488697e-05,
      "loss": 0.0353,
      "step": 30000
    },
    {
      "epoch": 2.0697242659698825,
      "grad_norm": 0.1746644675731659,
      "learning_rate": 3.707127752849554e-05,
      "loss": 0.0355,
      "step": 30100
    },
    {
      "epoch": 2.0766004263219418,
      "grad_norm": 0.14260417222976685,
      "learning_rate": 3.702829783210411e-05,
      "loss": 0.0371,
      "step": 30200
    },
    {
      "epoch": 2.083476586674001,
      "grad_norm": 0.1277778446674347,
      "learning_rate": 3.698531813571269e-05,
      "loss": 0.0341,
      "step": 30300
    },
    {
      "epoch": 2.0903527470260608,
      "grad_norm": 0.2412661910057068,
      "learning_rate": 3.694276823628518e-05,
      "loss": 0.0362,
      "step": 30400
    },
    {
      "epoch": 2.09722890737812,
      "grad_norm": 0.19763921201229095,
      "learning_rate": 3.6899788539893755e-05,
      "loss": 0.0386,
      "step": 30500
    },
    {
      "epoch": 2.1041050677301794,
      "grad_norm": 0.28639551997184753,
      "learning_rate": 3.6856808843502335e-05,
      "loss": 0.0361,
      "step": 30600
    },
    {
      "epoch": 2.110981228082239,
      "grad_norm": 0.3761874735355377,
      "learning_rate": 3.681382914711091e-05,
      "loss": 0.0397,
      "step": 30700
    },
    {
      "epoch": 2.1178573884342984,
      "grad_norm": 0.15433737635612488,
      "learning_rate": 3.677084945071948e-05,
      "loss": 0.0383,
      "step": 30800
    },
    {
      "epoch": 2.1247335487863577,
      "grad_norm": 0.20786476135253906,
      "learning_rate": 3.672786975432806e-05,
      "loss": 0.0353,
      "step": 30900
    },
    {
      "epoch": 2.131609709138417,
      "grad_norm": 0.13714224100112915,
      "learning_rate": 3.668489005793663e-05,
      "loss": 0.0363,
      "step": 31000
    },
    {
      "epoch": 2.1384858694904767,
      "grad_norm": 0.12469799816608429,
      "learning_rate": 3.6641910361545205e-05,
      "loss": 0.0384,
      "step": 31100
    },
    {
      "epoch": 2.145362029842536,
      "grad_norm": 0.17343582212924957,
      "learning_rate": 3.6598930665153786e-05,
      "loss": 0.0361,
      "step": 31200
    },
    {
      "epoch": 2.1522381901945953,
      "grad_norm": 0.17625577747821808,
      "learning_rate": 3.655595096876236e-05,
      "loss": 0.0351,
      "step": 31300
    },
    {
      "epoch": 2.1591143505466546,
      "grad_norm": 0.27415189146995544,
      "learning_rate": 3.6512971272370934e-05,
      "loss": 0.0357,
      "step": 31400
    },
    {
      "epoch": 2.1659905108987143,
      "grad_norm": 0.18147188425064087,
      "learning_rate": 3.646999157597951e-05,
      "loss": 0.033,
      "step": 31500
    },
    {
      "epoch": 2.1728666712507736,
      "grad_norm": 0.1575530469417572,
      "learning_rate": 3.642701187958809e-05,
      "loss": 0.0371,
      "step": 31600
    },
    {
      "epoch": 2.179742831602833,
      "grad_norm": 0.142089381814003,
      "learning_rate": 3.638403218319666e-05,
      "loss": 0.0361,
      "step": 31700
    },
    {
      "epoch": 2.1866189919548926,
      "grad_norm": 0.0944652408361435,
      "learning_rate": 3.6341052486805236e-05,
      "loss": 0.0311,
      "step": 31800
    },
    {
      "epoch": 2.193495152306952,
      "grad_norm": 0.1349986493587494,
      "learning_rate": 3.629807279041381e-05,
      "loss": 0.0348,
      "step": 31900
    },
    {
      "epoch": 2.200371312659011,
      "grad_norm": 0.07734943181276321,
      "learning_rate": 3.6255093094022384e-05,
      "loss": 0.034,
      "step": 32000
    },
    {
      "epoch": 2.2072474730110705,
      "grad_norm": 0.19226080179214478,
      "learning_rate": 3.621211339763096e-05,
      "loss": 0.0357,
      "step": 32100
    },
    {
      "epoch": 2.2141236333631302,
      "grad_norm": 0.28863224387168884,
      "learning_rate": 3.616913370123954e-05,
      "loss": 0.0386,
      "step": 32200
    },
    {
      "epoch": 2.2209997937151895,
      "grad_norm": 0.15920424461364746,
      "learning_rate": 3.612615400484811e-05,
      "loss": 0.0346,
      "step": 32300
    },
    {
      "epoch": 2.227875954067249,
      "grad_norm": 0.1273525357246399,
      "learning_rate": 3.6083174308456686e-05,
      "loss": 0.033,
      "step": 32400
    },
    {
      "epoch": 2.234752114419308,
      "grad_norm": 0.13501334190368652,
      "learning_rate": 3.604019461206527e-05,
      "loss": 0.0364,
      "step": 32500
    },
    {
      "epoch": 2.241628274771368,
      "grad_norm": 0.33685895800590515,
      "learning_rate": 3.599721491567384e-05,
      "loss": 0.0346,
      "step": 32600
    },
    {
      "epoch": 2.248504435123427,
      "grad_norm": 0.21051806211471558,
      "learning_rate": 3.5954235219282415e-05,
      "loss": 0.0359,
      "step": 32700
    },
    {
      "epoch": 2.2553805954754864,
      "grad_norm": 0.2003716379404068,
      "learning_rate": 3.591125552289099e-05,
      "loss": 0.0365,
      "step": 32800
    },
    {
      "epoch": 2.2622567558275457,
      "grad_norm": 0.22413121163845062,
      "learning_rate": 3.586827582649956e-05,
      "loss": 0.037,
      "step": 32900
    },
    {
      "epoch": 2.2691329161796054,
      "grad_norm": 0.17957352101802826,
      "learning_rate": 3.5825296130108136e-05,
      "loss": 0.036,
      "step": 33000
    },
    {
      "epoch": 2.2760090765316647,
      "grad_norm": 0.29910171031951904,
      "learning_rate": 3.578231643371671e-05,
      "loss": 0.0358,
      "step": 33100
    },
    {
      "epoch": 2.282885236883724,
      "grad_norm": 0.2217886596918106,
      "learning_rate": 3.573933673732529e-05,
      "loss": 0.0394,
      "step": 33200
    },
    {
      "epoch": 2.2897613972357833,
      "grad_norm": 0.20812976360321045,
      "learning_rate": 3.5696357040933865e-05,
      "loss": 0.0361,
      "step": 33300
    },
    {
      "epoch": 2.296637557587843,
      "grad_norm": 0.19030115008354187,
      "learning_rate": 3.565337734454244e-05,
      "loss": 0.0361,
      "step": 33400
    },
    {
      "epoch": 2.3035137179399023,
      "grad_norm": 0.1882031261920929,
      "learning_rate": 3.561039764815102e-05,
      "loss": 0.0367,
      "step": 33500
    },
    {
      "epoch": 2.3103898782919616,
      "grad_norm": 0.1899270862340927,
      "learning_rate": 3.5567417951759593e-05,
      "loss": 0.0372,
      "step": 33600
    },
    {
      "epoch": 2.3172660386440214,
      "grad_norm": 0.3778229057788849,
      "learning_rate": 3.552443825536817e-05,
      "loss": 0.037,
      "step": 33700
    },
    {
      "epoch": 2.3241421989960807,
      "grad_norm": 0.2006467580795288,
      "learning_rate": 3.548145855897674e-05,
      "loss": 0.0342,
      "step": 33800
    },
    {
      "epoch": 2.33101835934814,
      "grad_norm": 0.20559726655483246,
      "learning_rate": 3.5438478862585315e-05,
      "loss": 0.0358,
      "step": 33900
    },
    {
      "epoch": 2.3378945197001992,
      "grad_norm": 0.20125357806682587,
      "learning_rate": 3.539549916619389e-05,
      "loss": 0.0362,
      "step": 34000
    },
    {
      "epoch": 2.344770680052259,
      "grad_norm": 0.21222497522830963,
      "learning_rate": 3.535251946980247e-05,
      "loss": 0.0367,
      "step": 34100
    },
    {
      "epoch": 2.3516468404043183,
      "grad_norm": 0.2411710023880005,
      "learning_rate": 3.5309539773411044e-05,
      "loss": 0.0389,
      "step": 34200
    },
    {
      "epoch": 2.3585230007563776,
      "grad_norm": 0.13828176259994507,
      "learning_rate": 3.526656007701962e-05,
      "loss": 0.0356,
      "step": 34300
    },
    {
      "epoch": 2.365399161108437,
      "grad_norm": 0.2533629834651947,
      "learning_rate": 3.522358038062819e-05,
      "loss": 0.0328,
      "step": 34400
    },
    {
      "epoch": 2.3722753214604966,
      "grad_norm": 0.10623127967119217,
      "learning_rate": 3.518060068423677e-05,
      "loss": 0.0367,
      "step": 34500
    },
    {
      "epoch": 2.379151481812556,
      "grad_norm": 0.5259021520614624,
      "learning_rate": 3.5137620987845346e-05,
      "loss": 0.0355,
      "step": 34600
    },
    {
      "epoch": 2.386027642164615,
      "grad_norm": 0.19610169529914856,
      "learning_rate": 3.509464129145392e-05,
      "loss": 0.0381,
      "step": 34700
    },
    {
      "epoch": 2.392903802516675,
      "grad_norm": 0.18507711589336395,
      "learning_rate": 3.5051661595062494e-05,
      "loss": 0.0351,
      "step": 34800
    },
    {
      "epoch": 2.399779962868734,
      "grad_norm": 0.23712392151355743,
      "learning_rate": 3.500868189867107e-05,
      "loss": 0.0353,
      "step": 34900
    },
    {
      "epoch": 2.4066561232207935,
      "grad_norm": 0.2424801141023636,
      "learning_rate": 3.496570220227964e-05,
      "loss": 0.0367,
      "step": 35000
    },
    {
      "epoch": 2.4135322835728528,
      "grad_norm": 0.0926763042807579,
      "learning_rate": 3.492272250588822e-05,
      "loss": 0.0342,
      "step": 35100
    },
    {
      "epoch": 2.4204084439249125,
      "grad_norm": 0.282914936542511,
      "learning_rate": 3.4879742809496796e-05,
      "loss": 0.0356,
      "step": 35200
    },
    {
      "epoch": 2.427284604276972,
      "grad_norm": 0.16381709277629852,
      "learning_rate": 3.483676311310537e-05,
      "loss": 0.0351,
      "step": 35300
    },
    {
      "epoch": 2.434160764629031,
      "grad_norm": 0.238230362534523,
      "learning_rate": 3.479378341671395e-05,
      "loss": 0.036,
      "step": 35400
    },
    {
      "epoch": 2.4410369249810904,
      "grad_norm": 0.22536543011665344,
      "learning_rate": 3.4750803720322525e-05,
      "loss": 0.0375,
      "step": 35500
    },
    {
      "epoch": 2.44791308533315,
      "grad_norm": 0.09711812436580658,
      "learning_rate": 3.47078240239311e-05,
      "loss": 0.0376,
      "step": 35600
    },
    {
      "epoch": 2.4547892456852094,
      "grad_norm": 0.17043611407279968,
      "learning_rate": 3.466484432753967e-05,
      "loss": 0.0351,
      "step": 35700
    },
    {
      "epoch": 2.4616654060372687,
      "grad_norm": 0.1573023498058319,
      "learning_rate": 3.462186463114825e-05,
      "loss": 0.037,
      "step": 35800
    },
    {
      "epoch": 2.4685415663893284,
      "grad_norm": 0.1247650608420372,
      "learning_rate": 3.457888493475682e-05,
      "loss": 0.0344,
      "step": 35900
    },
    {
      "epoch": 2.4754177267413877,
      "grad_norm": 0.16370995342731476,
      "learning_rate": 3.4535905238365394e-05,
      "loss": 0.0328,
      "step": 36000
    },
    {
      "epoch": 2.482293887093447,
      "grad_norm": 0.3058689534664154,
      "learning_rate": 3.4492925541973975e-05,
      "loss": 0.0352,
      "step": 36100
    },
    {
      "epoch": 2.4891700474455063,
      "grad_norm": 0.30174750089645386,
      "learning_rate": 3.444994584558255e-05,
      "loss": 0.0376,
      "step": 36200
    },
    {
      "epoch": 2.496046207797566,
      "grad_norm": 0.10444602370262146,
      "learning_rate": 3.440696614919112e-05,
      "loss": 0.034,
      "step": 36300
    },
    {
      "epoch": 2.5029223681496253,
      "grad_norm": 0.17380982637405396,
      "learning_rate": 3.4363986452799704e-05,
      "loss": 0.0359,
      "step": 36400
    },
    {
      "epoch": 2.5097985285016846,
      "grad_norm": 0.16000612080097198,
      "learning_rate": 3.432100675640828e-05,
      "loss": 0.036,
      "step": 36500
    },
    {
      "epoch": 2.516674688853744,
      "grad_norm": 0.196666419506073,
      "learning_rate": 3.427802706001685e-05,
      "loss": 0.0349,
      "step": 36600
    },
    {
      "epoch": 2.5235508492058036,
      "grad_norm": 0.2552396357059479,
      "learning_rate": 3.423547716058934e-05,
      "loss": 0.0365,
      "step": 36700
    },
    {
      "epoch": 2.530427009557863,
      "grad_norm": 0.24084940552711487,
      "learning_rate": 3.4192497464197914e-05,
      "loss": 0.0351,
      "step": 36800
    },
    {
      "epoch": 2.537303169909922,
      "grad_norm": 0.2507273554801941,
      "learning_rate": 3.414951776780649e-05,
      "loss": 0.0366,
      "step": 36900
    },
    {
      "epoch": 2.544179330261982,
      "grad_norm": 0.2001381516456604,
      "learning_rate": 3.410653807141507e-05,
      "loss": 0.0349,
      "step": 37000
    },
    {
      "epoch": 2.5510554906140412,
      "grad_norm": 0.15462544560432434,
      "learning_rate": 3.406355837502364e-05,
      "loss": 0.034,
      "step": 37100
    },
    {
      "epoch": 2.5579316509661005,
      "grad_norm": 0.20196089148521423,
      "learning_rate": 3.402057867863222e-05,
      "loss": 0.0339,
      "step": 37200
    },
    {
      "epoch": 2.56480781131816,
      "grad_norm": 0.2317553162574768,
      "learning_rate": 3.397759898224079e-05,
      "loss": 0.0348,
      "step": 37300
    },
    {
      "epoch": 2.571683971670219,
      "grad_norm": 0.19310696423053741,
      "learning_rate": 3.3934619285849365e-05,
      "loss": 0.035,
      "step": 37400
    },
    {
      "epoch": 2.578560132022279,
      "grad_norm": 0.28986838459968567,
      "learning_rate": 3.389163958945794e-05,
      "loss": 0.0379,
      "step": 37500
    },
    {
      "epoch": 2.585436292374338,
      "grad_norm": 0.11573034524917603,
      "learning_rate": 3.384865989306651e-05,
      "loss": 0.0337,
      "step": 37600
    },
    {
      "epoch": 2.5923124527263974,
      "grad_norm": 0.17516374588012695,
      "learning_rate": 3.380610999363901e-05,
      "loss": 0.0366,
      "step": 37700
    },
    {
      "epoch": 2.599188613078457,
      "grad_norm": 0.10905725508928299,
      "learning_rate": 3.376313029724758e-05,
      "loss": 0.034,
      "step": 37800
    },
    {
      "epoch": 2.6060647734305165,
      "grad_norm": 0.1571771204471588,
      "learning_rate": 3.372015060085616e-05,
      "loss": 0.0336,
      "step": 37900
    },
    {
      "epoch": 2.6129409337825757,
      "grad_norm": 0.15276271104812622,
      "learning_rate": 3.367717090446473e-05,
      "loss": 0.0347,
      "step": 38000
    },
    {
      "epoch": 2.6198170941346355,
      "grad_norm": 0.12488589435815811,
      "learning_rate": 3.3634191208073304e-05,
      "loss": 0.0368,
      "step": 38100
    },
    {
      "epoch": 2.6266932544866948,
      "grad_norm": 0.34314844012260437,
      "learning_rate": 3.359121151168188e-05,
      "loss": 0.0342,
      "step": 38200
    },
    {
      "epoch": 2.633569414838754,
      "grad_norm": 0.24138614535331726,
      "learning_rate": 3.354823181529046e-05,
      "loss": 0.0373,
      "step": 38300
    },
    {
      "epoch": 2.6404455751908134,
      "grad_norm": 0.15719500184059143,
      "learning_rate": 3.350525211889903e-05,
      "loss": 0.0327,
      "step": 38400
    },
    {
      "epoch": 2.6473217355428726,
      "grad_norm": 0.24537265300750732,
      "learning_rate": 3.3462272422507606e-05,
      "loss": 0.0353,
      "step": 38500
    },
    {
      "epoch": 2.6541978958949324,
      "grad_norm": 0.18872518837451935,
      "learning_rate": 3.341929272611619e-05,
      "loss": 0.0317,
      "step": 38600
    },
    {
      "epoch": 2.6610740562469917,
      "grad_norm": 0.1520126760005951,
      "learning_rate": 3.337631302972476e-05,
      "loss": 0.0357,
      "step": 38700
    },
    {
      "epoch": 2.667950216599051,
      "grad_norm": 0.20175637304782867,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.0394,
      "step": 38800
    },
    {
      "epoch": 2.6748263769511107,
      "grad_norm": 0.10008970648050308,
      "learning_rate": 3.329035363694191e-05,
      "loss": 0.0321,
      "step": 38900
    },
    {
      "epoch": 2.68170253730317,
      "grad_norm": 0.1294713318347931,
      "learning_rate": 3.324737394055048e-05,
      "loss": 0.035,
      "step": 39000
    },
    {
      "epoch": 2.6885786976552293,
      "grad_norm": 0.23613955080509186,
      "learning_rate": 3.320439424415906e-05,
      "loss": 0.0336,
      "step": 39100
    },
    {
      "epoch": 2.6954548580072886,
      "grad_norm": 0.16468527913093567,
      "learning_rate": 3.316141454776764e-05,
      "loss": 0.0336,
      "step": 39200
    },
    {
      "epoch": 2.7023310183593483,
      "grad_norm": 0.09854892641305923,
      "learning_rate": 3.311843485137621e-05,
      "loss": 0.0331,
      "step": 39300
    },
    {
      "epoch": 2.7092071787114076,
      "grad_norm": 0.2067643254995346,
      "learning_rate": 3.3075455154984785e-05,
      "loss": 0.0353,
      "step": 39400
    },
    {
      "epoch": 2.716083339063467,
      "grad_norm": 0.26050132513046265,
      "learning_rate": 3.303247545859336e-05,
      "loss": 0.0348,
      "step": 39500
    },
    {
      "epoch": 2.722959499415526,
      "grad_norm": 0.2713414430618286,
      "learning_rate": 3.298949576220194e-05,
      "loss": 0.0357,
      "step": 39600
    },
    {
      "epoch": 2.729835659767586,
      "grad_norm": 0.17395679652690887,
      "learning_rate": 3.2946516065810514e-05,
      "loss": 0.0354,
      "step": 39700
    },
    {
      "epoch": 2.736711820119645,
      "grad_norm": 0.1885846108198166,
      "learning_rate": 3.290353636941909e-05,
      "loss": 0.0374,
      "step": 39800
    },
    {
      "epoch": 2.7435879804717045,
      "grad_norm": 0.19593361020088196,
      "learning_rate": 3.286055667302766e-05,
      "loss": 0.0345,
      "step": 39900
    },
    {
      "epoch": 2.7504641408237642,
      "grad_norm": 0.32065916061401367,
      "learning_rate": 3.2817576976636235e-05,
      "loss": 0.0331,
      "step": 40000
    },
    {
      "epoch": 2.7573403011758235,
      "grad_norm": 0.12667721509933472,
      "learning_rate": 3.277459728024481e-05,
      "loss": 0.0334,
      "step": 40100
    },
    {
      "epoch": 2.764216461527883,
      "grad_norm": 0.1844550520181656,
      "learning_rate": 3.273161758385339e-05,
      "loss": 0.0328,
      "step": 40200
    },
    {
      "epoch": 2.771092621879942,
      "grad_norm": 0.10666892677545547,
      "learning_rate": 3.2688637887461964e-05,
      "loss": 0.0351,
      "step": 40300
    },
    {
      "epoch": 2.7779687822320014,
      "grad_norm": 0.2000046968460083,
      "learning_rate": 3.264565819107054e-05,
      "loss": 0.036,
      "step": 40400
    },
    {
      "epoch": 2.784844942584061,
      "grad_norm": 0.20780161023139954,
      "learning_rate": 3.260267849467912e-05,
      "loss": 0.0365,
      "step": 40500
    },
    {
      "epoch": 2.7917211029361204,
      "grad_norm": 0.1434030830860138,
      "learning_rate": 3.255969879828769e-05,
      "loss": 0.0374,
      "step": 40600
    },
    {
      "epoch": 2.7985972632881797,
      "grad_norm": 0.20858845114707947,
      "learning_rate": 3.2516719101896266e-05,
      "loss": 0.0351,
      "step": 40700
    },
    {
      "epoch": 2.8054734236402394,
      "grad_norm": 0.16680897772312164,
      "learning_rate": 3.247373940550485e-05,
      "loss": 0.0351,
      "step": 40800
    },
    {
      "epoch": 2.8123495839922987,
      "grad_norm": 0.18218402564525604,
      "learning_rate": 3.2430759709113414e-05,
      "loss": 0.0346,
      "step": 40900
    },
    {
      "epoch": 2.819225744344358,
      "grad_norm": 0.2893509268760681,
      "learning_rate": 3.238778001272199e-05,
      "loss": 0.0331,
      "step": 41000
    },
    {
      "epoch": 2.8261019046964178,
      "grad_norm": 0.2359493523836136,
      "learning_rate": 3.234480031633056e-05,
      "loss": 0.0341,
      "step": 41100
    },
    {
      "epoch": 2.832978065048477,
      "grad_norm": 0.19465987384319305,
      "learning_rate": 3.230182061993914e-05,
      "loss": 0.0341,
      "step": 41200
    },
    {
      "epoch": 2.8398542254005363,
      "grad_norm": 0.2915020287036896,
      "learning_rate": 3.2258840923547717e-05,
      "loss": 0.0322,
      "step": 41300
    },
    {
      "epoch": 2.8467303857525956,
      "grad_norm": 0.20483511686325073,
      "learning_rate": 3.221586122715629e-05,
      "loss": 0.0334,
      "step": 41400
    },
    {
      "epoch": 2.853606546104655,
      "grad_norm": 0.25236037373542786,
      "learning_rate": 3.217288153076487e-05,
      "loss": 0.033,
      "step": 41500
    },
    {
      "epoch": 2.8604827064567147,
      "grad_norm": 0.18455956876277924,
      "learning_rate": 3.2129901834373445e-05,
      "loss": 0.0348,
      "step": 41600
    },
    {
      "epoch": 2.867358866808774,
      "grad_norm": 0.1952521950006485,
      "learning_rate": 3.208735193494593e-05,
      "loss": 0.0335,
      "step": 41700
    },
    {
      "epoch": 2.8742350271608332,
      "grad_norm": 0.08723444491624832,
      "learning_rate": 3.204437223855451e-05,
      "loss": 0.0328,
      "step": 41800
    },
    {
      "epoch": 2.881111187512893,
      "grad_norm": 0.17433768510818481,
      "learning_rate": 3.200139254216308e-05,
      "loss": 0.0347,
      "step": 41900
    },
    {
      "epoch": 2.8879873478649523,
      "grad_norm": 0.32983213663101196,
      "learning_rate": 3.1958412845771656e-05,
      "loss": 0.0365,
      "step": 42000
    },
    {
      "epoch": 2.8948635082170115,
      "grad_norm": 0.15331952273845673,
      "learning_rate": 3.1915433149380237e-05,
      "loss": 0.0357,
      "step": 42100
    },
    {
      "epoch": 2.9017396685690713,
      "grad_norm": 0.2701913118362427,
      "learning_rate": 3.187245345298881e-05,
      "loss": 0.0332,
      "step": 42200
    },
    {
      "epoch": 2.9086158289211306,
      "grad_norm": 0.21971146762371063,
      "learning_rate": 3.1829473756597384e-05,
      "loss": 0.0333,
      "step": 42300
    },
    {
      "epoch": 2.91549198927319,
      "grad_norm": 0.19738583266735077,
      "learning_rate": 3.1786494060205965e-05,
      "loss": 0.0318,
      "step": 42400
    },
    {
      "epoch": 2.922368149625249,
      "grad_norm": 0.18824121356010437,
      "learning_rate": 3.174351436381454e-05,
      "loss": 0.0348,
      "step": 42500
    },
    {
      "epoch": 2.9292443099773084,
      "grad_norm": 0.25784817337989807,
      "learning_rate": 3.170053466742311e-05,
      "loss": 0.0342,
      "step": 42600
    },
    {
      "epoch": 2.936120470329368,
      "grad_norm": 0.1138901561498642,
      "learning_rate": 3.165755497103169e-05,
      "loss": 0.0363,
      "step": 42700
    },
    {
      "epoch": 2.9429966306814275,
      "grad_norm": 0.23317107558250427,
      "learning_rate": 3.161457527464026e-05,
      "loss": 0.0344,
      "step": 42800
    },
    {
      "epoch": 2.9498727910334868,
      "grad_norm": 0.16801607608795166,
      "learning_rate": 3.1571595578248835e-05,
      "loss": 0.0336,
      "step": 42900
    },
    {
      "epoch": 2.9567489513855465,
      "grad_norm": 0.1821897327899933,
      "learning_rate": 3.152861588185741e-05,
      "loss": 0.0365,
      "step": 43000
    },
    {
      "epoch": 2.963625111737606,
      "grad_norm": 0.13405419886112213,
      "learning_rate": 3.148563618546599e-05,
      "loss": 0.0331,
      "step": 43100
    },
    {
      "epoch": 2.970501272089665,
      "grad_norm": 0.16650894284248352,
      "learning_rate": 3.144265648907456e-05,
      "loss": 0.0338,
      "step": 43200
    },
    {
      "epoch": 2.977377432441725,
      "grad_norm": 0.2137993425130844,
      "learning_rate": 3.139967679268314e-05,
      "loss": 0.0327,
      "step": 43300
    },
    {
      "epoch": 2.984253592793784,
      "grad_norm": 0.1872905045747757,
      "learning_rate": 3.135669709629172e-05,
      "loss": 0.0339,
      "step": 43400
    },
    {
      "epoch": 2.9911297531458434,
      "grad_norm": 0.23793795704841614,
      "learning_rate": 3.131371739990029e-05,
      "loss": 0.0349,
      "step": 43500
    },
    {
      "epoch": 2.9980059134979027,
      "grad_norm": 0.18844322860240936,
      "learning_rate": 3.1270737703508866e-05,
      "loss": 0.0334,
      "step": 43600
    },
    {
      "epoch": 3.0,
      "eval_accuracy_macro_0.5": 0.9841054677963257,
      "eval_accuracy_micro_0.5": 0.9841054081916809,
      "eval_accuracy_weighted_0.5": 0.9820083379745483,
      "eval_f1_macro_0.5": 0.7925924062728882,
      "eval_f1_macro_0.6": 0.7790593504905701,
      "eval_f1_macro_0.7": 0.7533221244812012,
      "eval_f1_macro_0.8": 0.610953152179718,
      "eval_f1_micro_0.5": 0.7915131449699402,
      "eval_f1_micro_0.6": 0.7793314456939697,
      "eval_f1_micro_0.7": 0.7567812204360962,
      "eval_f1_micro_0.8": 0.7155768275260925,
      "eval_f1_micro_0.9": 0.6276344656944275,
      "eval_f1_weighted_0.5": 0.7865802645683289,
      "eval_f1_weighted_0.6": 0.7706094980239868,
      "eval_f1_weighted_0.7": 0.7428575754165649,
      "eval_f1_weighted_0.8": 0.5927618741989136,
      "eval_loss": 0.03301936760544777,
      "eval_runtime": 142.383,
      "eval_samples_per_second": 203.936,
      "eval_steps_per_second": 25.495,
      "step": 43629
    },
    {
      "epoch": 3.004882073849962,
      "grad_norm": 0.20736463367938995,
      "learning_rate": 3.122775800711744e-05,
      "loss": 0.0336,
      "step": 43700
    },
    {
      "epoch": 3.0117582342020217,
      "grad_norm": 0.20112141966819763,
      "learning_rate": 3.1184778310726013e-05,
      "loss": 0.0323,
      "step": 43800
    },
    {
      "epoch": 3.018634394554081,
      "grad_norm": 0.2337404191493988,
      "learning_rate": 3.114179861433459e-05,
      "loss": 0.0328,
      "step": 43900
    },
    {
      "epoch": 3.0255105549061403,
      "grad_norm": 0.32872849702835083,
      "learning_rate": 3.109881891794317e-05,
      "loss": 0.037,
      "step": 44000
    },
    {
      "epoch": 3.0323867152582,
      "grad_norm": 0.22381344437599182,
      "learning_rate": 3.105583922155174e-05,
      "loss": 0.032,
      "step": 44100
    },
    {
      "epoch": 3.0392628756102593,
      "grad_norm": 0.17441628873348236,
      "learning_rate": 3.1012859525160316e-05,
      "loss": 0.0319,
      "step": 44200
    },
    {
      "epoch": 3.0461390359623186,
      "grad_norm": 0.23292620480060577,
      "learning_rate": 3.0970309625732805e-05,
      "loss": 0.0357,
      "step": 44300
    },
    {
      "epoch": 3.053015196314378,
      "grad_norm": 0.156993567943573,
      "learning_rate": 3.092732992934138e-05,
      "loss": 0.0335,
      "step": 44400
    },
    {
      "epoch": 3.0598913566664376,
      "grad_norm": 0.14955465495586395,
      "learning_rate": 3.088435023294995e-05,
      "loss": 0.0351,
      "step": 44500
    },
    {
      "epoch": 3.066767517018497,
      "grad_norm": 0.09661777317523956,
      "learning_rate": 3.0841370536558533e-05,
      "loss": 0.0324,
      "step": 44600
    },
    {
      "epoch": 3.073643677370556,
      "grad_norm": 0.28306934237480164,
      "learning_rate": 3.079839084016711e-05,
      "loss": 0.0349,
      "step": 44700
    },
    {
      "epoch": 3.0805198377226155,
      "grad_norm": 0.15123744308948517,
      "learning_rate": 3.075541114377568e-05,
      "loss": 0.0357,
      "step": 44800
    },
    {
      "epoch": 3.0873959980746752,
      "grad_norm": 0.13504476845264435,
      "learning_rate": 3.0712431447384255e-05,
      "loss": 0.0341,
      "step": 44900
    },
    {
      "epoch": 3.0942721584267345,
      "grad_norm": 0.12260066717863083,
      "learning_rate": 3.0669451750992836e-05,
      "loss": 0.0367,
      "step": 45000
    },
    {
      "epoch": 3.101148318778794,
      "grad_norm": 0.1464122235774994,
      "learning_rate": 3.062647205460141e-05,
      "loss": 0.0325,
      "step": 45100
    },
    {
      "epoch": 3.1080244791308536,
      "grad_norm": 0.23631106317043304,
      "learning_rate": 3.0583492358209984e-05,
      "loss": 0.034,
      "step": 45200
    },
    {
      "epoch": 3.114900639482913,
      "grad_norm": 0.26840129494667053,
      "learning_rate": 3.054051266181856e-05,
      "loss": 0.0342,
      "step": 45300
    },
    {
      "epoch": 3.121776799834972,
      "grad_norm": 0.20822197198867798,
      "learning_rate": 3.0497532965427135e-05,
      "loss": 0.0357,
      "step": 45400
    },
    {
      "epoch": 3.1286529601870314,
      "grad_norm": 0.1433156281709671,
      "learning_rate": 3.045455326903571e-05,
      "loss": 0.033,
      "step": 45500
    },
    {
      "epoch": 3.135529120539091,
      "grad_norm": 0.1635715514421463,
      "learning_rate": 3.0411573572644286e-05,
      "loss": 0.0333,
      "step": 45600
    },
    {
      "epoch": 3.1424052808911505,
      "grad_norm": 0.11735421419143677,
      "learning_rate": 3.036859387625286e-05,
      "loss": 0.0325,
      "step": 45700
    },
    {
      "epoch": 3.1492814412432097,
      "grad_norm": 0.21242208778858185,
      "learning_rate": 3.0325614179861434e-05,
      "loss": 0.0328,
      "step": 45800
    },
    {
      "epoch": 3.156157601595269,
      "grad_norm": 0.23060478270053864,
      "learning_rate": 3.028263448347001e-05,
      "loss": 0.0341,
      "step": 45900
    },
    {
      "epoch": 3.1630337619473288,
      "grad_norm": 0.1631050854921341,
      "learning_rate": 3.0239654787078585e-05,
      "loss": 0.0343,
      "step": 46000
    },
    {
      "epoch": 3.169909922299388,
      "grad_norm": 0.12161607295274734,
      "learning_rate": 3.019667509068716e-05,
      "loss": 0.0333,
      "step": 46100
    },
    {
      "epoch": 3.1767860826514474,
      "grad_norm": 0.2506178021430969,
      "learning_rate": 3.0153695394295733e-05,
      "loss": 0.0302,
      "step": 46200
    },
    {
      "epoch": 3.1836622430035066,
      "grad_norm": 0.18172112107276917,
      "learning_rate": 3.0110715697904314e-05,
      "loss": 0.0341,
      "step": 46300
    },
    {
      "epoch": 3.1905384033555664,
      "grad_norm": 0.30999764800071716,
      "learning_rate": 3.0067736001512888e-05,
      "loss": 0.0316,
      "step": 46400
    },
    {
      "epoch": 3.1974145637076257,
      "grad_norm": 0.19297723472118378,
      "learning_rate": 3.002475630512146e-05,
      "loss": 0.0333,
      "step": 46500
    },
    {
      "epoch": 3.204290724059685,
      "grad_norm": 0.14481759071350098,
      "learning_rate": 2.9982206405693954e-05,
      "loss": 0.0356,
      "step": 46600
    },
    {
      "epoch": 3.2111668844117442,
      "grad_norm": 0.15349805355072021,
      "learning_rate": 2.9939226709302524e-05,
      "loss": 0.0337,
      "step": 46700
    },
    {
      "epoch": 3.218043044763804,
      "grad_norm": 0.17850226163864136,
      "learning_rate": 2.9896247012911105e-05,
      "loss": 0.0329,
      "step": 46800
    },
    {
      "epoch": 3.2249192051158633,
      "grad_norm": 0.1982061266899109,
      "learning_rate": 2.985326731651968e-05,
      "loss": 0.0347,
      "step": 46900
    },
    {
      "epoch": 3.2317953654679226,
      "grad_norm": 0.1781494915485382,
      "learning_rate": 2.9810287620128253e-05,
      "loss": 0.0343,
      "step": 47000
    },
    {
      "epoch": 3.2386715258199823,
      "grad_norm": 0.16163955628871918,
      "learning_rate": 2.9767307923736827e-05,
      "loss": 0.033,
      "step": 47100
    },
    {
      "epoch": 3.2455476861720416,
      "grad_norm": 0.09977182745933533,
      "learning_rate": 2.9724328227345404e-05,
      "loss": 0.0334,
      "step": 47200
    },
    {
      "epoch": 3.252423846524101,
      "grad_norm": 0.22340208292007446,
      "learning_rate": 2.9681348530953978e-05,
      "loss": 0.0351,
      "step": 47300
    },
    {
      "epoch": 3.25930000687616,
      "grad_norm": 0.23023270070552826,
      "learning_rate": 2.9638368834562552e-05,
      "loss": 0.0314,
      "step": 47400
    },
    {
      "epoch": 3.26617616722822,
      "grad_norm": 0.16721881926059723,
      "learning_rate": 2.9595389138171133e-05,
      "loss": 0.0311,
      "step": 47500
    },
    {
      "epoch": 3.273052327580279,
      "grad_norm": 0.23813505470752716,
      "learning_rate": 2.9552409441779703e-05,
      "loss": 0.0344,
      "step": 47600
    },
    {
      "epoch": 3.2799284879323385,
      "grad_norm": 0.24755361676216125,
      "learning_rate": 2.9509429745388277e-05,
      "loss": 0.0322,
      "step": 47700
    },
    {
      "epoch": 3.286804648284398,
      "grad_norm": 0.17528855800628662,
      "learning_rate": 2.9466450048996858e-05,
      "loss": 0.0328,
      "step": 47800
    },
    {
      "epoch": 3.2936808086364575,
      "grad_norm": 0.19585563242435455,
      "learning_rate": 2.942347035260543e-05,
      "loss": 0.0327,
      "step": 47900
    },
    {
      "epoch": 3.300556968988517,
      "grad_norm": 0.13466663658618927,
      "learning_rate": 2.9380490656214006e-05,
      "loss": 0.0345,
      "step": 48000
    },
    {
      "epoch": 3.307433129340576,
      "grad_norm": 0.13336734473705292,
      "learning_rate": 2.9337510959822583e-05,
      "loss": 0.0352,
      "step": 48100
    },
    {
      "epoch": 3.314309289692636,
      "grad_norm": 0.257802277803421,
      "learning_rate": 2.9294531263431157e-05,
      "loss": 0.0329,
      "step": 48200
    },
    {
      "epoch": 3.321185450044695,
      "grad_norm": 0.20587962865829468,
      "learning_rate": 2.925155156703973e-05,
      "loss": 0.0319,
      "step": 48300
    },
    {
      "epoch": 3.3280616103967544,
      "grad_norm": 0.1306670606136322,
      "learning_rate": 2.9208571870648305e-05,
      "loss": 0.0321,
      "step": 48400
    },
    {
      "epoch": 3.3349377707488137,
      "grad_norm": 0.18778233230113983,
      "learning_rate": 2.9165592174256885e-05,
      "loss": 0.0346,
      "step": 48500
    },
    {
      "epoch": 3.3418139311008734,
      "grad_norm": 0.16323229670524597,
      "learning_rate": 2.912304227482937e-05,
      "loss": 0.0339,
      "step": 48600
    },
    {
      "epoch": 3.3486900914529327,
      "grad_norm": 0.13733159005641937,
      "learning_rate": 2.9080062578437948e-05,
      "loss": 0.0343,
      "step": 48700
    },
    {
      "epoch": 3.355566251804992,
      "grad_norm": 0.18325118720531464,
      "learning_rate": 2.9037082882046522e-05,
      "loss": 0.0335,
      "step": 48800
    },
    {
      "epoch": 3.3624424121570513,
      "grad_norm": 0.1062791720032692,
      "learning_rate": 2.8994103185655096e-05,
      "loss": 0.0318,
      "step": 48900
    },
    {
      "epoch": 3.369318572509111,
      "grad_norm": 0.04460230842232704,
      "learning_rate": 2.895112348926367e-05,
      "loss": 0.0347,
      "step": 49000
    },
    {
      "epoch": 3.3761947328611703,
      "grad_norm": 0.1472174972295761,
      "learning_rate": 2.890814379287225e-05,
      "loss": 0.0327,
      "step": 49100
    },
    {
      "epoch": 3.3830708932132296,
      "grad_norm": 0.04701418802142143,
      "learning_rate": 2.8865164096480825e-05,
      "loss": 0.0302,
      "step": 49200
    },
    {
      "epoch": 3.3899470535652894,
      "grad_norm": 0.15303274989128113,
      "learning_rate": 2.88221844000894e-05,
      "loss": 0.0324,
      "step": 49300
    },
    {
      "epoch": 3.3968232139173486,
      "grad_norm": 0.11615757644176483,
      "learning_rate": 2.8779204703697976e-05,
      "loss": 0.0339,
      "step": 49400
    },
    {
      "epoch": 3.403699374269408,
      "grad_norm": 0.15677402913570404,
      "learning_rate": 2.873622500730655e-05,
      "loss": 0.0341,
      "step": 49500
    },
    {
      "epoch": 3.4105755346214672,
      "grad_norm": 0.22325702011585236,
      "learning_rate": 2.8693245310915124e-05,
      "loss": 0.0322,
      "step": 49600
    },
    {
      "epoch": 3.417451694973527,
      "grad_norm": 0.12632475793361664,
      "learning_rate": 2.86502656145237e-05,
      "loss": 0.0324,
      "step": 49700
    },
    {
      "epoch": 3.4243278553255863,
      "grad_norm": 0.39955082535743713,
      "learning_rate": 2.8607285918132275e-05,
      "loss": 0.0342,
      "step": 49800
    },
    {
      "epoch": 3.4312040156776455,
      "grad_norm": 0.14368776977062225,
      "learning_rate": 2.856430622174085e-05,
      "loss": 0.0312,
      "step": 49900
    },
    {
      "epoch": 3.438080176029705,
      "grad_norm": 0.11981195956468582,
      "learning_rate": 2.852132652534943e-05,
      "loss": 0.0326,
      "step": 50000
    },
    {
      "epoch": 3.4449563363817646,
      "grad_norm": 0.16203221678733826,
      "learning_rate": 2.8478346828958003e-05,
      "loss": 0.032,
      "step": 50100
    },
    {
      "epoch": 3.451832496733824,
      "grad_norm": 0.24660652875900269,
      "learning_rate": 2.8435367132566577e-05,
      "loss": 0.032,
      "step": 50200
    },
    {
      "epoch": 3.458708657085883,
      "grad_norm": 0.2075076401233673,
      "learning_rate": 2.839238743617515e-05,
      "loss": 0.0336,
      "step": 50300
    },
    {
      "epoch": 3.465584817437943,
      "grad_norm": 0.107024647295475,
      "learning_rate": 2.834940773978373e-05,
      "loss": 0.0329,
      "step": 50400
    },
    {
      "epoch": 3.472460977790002,
      "grad_norm": 0.21219758689403534,
      "learning_rate": 2.8306428043392302e-05,
      "loss": 0.0324,
      "step": 50500
    },
    {
      "epoch": 3.4793371381420615,
      "grad_norm": 0.262593537569046,
      "learning_rate": 2.8263448347000876e-05,
      "loss": 0.0334,
      "step": 50600
    },
    {
      "epoch": 3.4862132984941208,
      "grad_norm": 0.2604126036167145,
      "learning_rate": 2.8220468650609454e-05,
      "loss": 0.0363,
      "step": 50700
    },
    {
      "epoch": 3.49308945884618,
      "grad_norm": 0.21506555378437042,
      "learning_rate": 2.8177488954218028e-05,
      "loss": 0.033,
      "step": 50800
    },
    {
      "epoch": 3.49996561919824,
      "grad_norm": 0.18372952938079834,
      "learning_rate": 2.81345092578266e-05,
      "loss": 0.035,
      "step": 50900
    },
    {
      "epoch": 3.506841779550299,
      "grad_norm": 0.17317919433116913,
      "learning_rate": 2.8091529561435182e-05,
      "loss": 0.0325,
      "step": 51000
    },
    {
      "epoch": 3.5137179399023584,
      "grad_norm": 0.16373446583747864,
      "learning_rate": 2.8048979662007668e-05,
      "loss": 0.0334,
      "step": 51100
    },
    {
      "epoch": 3.520594100254418,
      "grad_norm": 0.25655901432037354,
      "learning_rate": 2.800599996561624e-05,
      "loss": 0.0323,
      "step": 51200
    },
    {
      "epoch": 3.5274702606064774,
      "grad_norm": 0.21585741639137268,
      "learning_rate": 2.7963020269224822e-05,
      "loss": 0.0349,
      "step": 51300
    },
    {
      "epoch": 3.5343464209585367,
      "grad_norm": 0.15668149292469025,
      "learning_rate": 2.7920040572833396e-05,
      "loss": 0.0307,
      "step": 51400
    },
    {
      "epoch": 3.5412225813105964,
      "grad_norm": 0.3766596019268036,
      "learning_rate": 2.7877060876441967e-05,
      "loss": 0.0321,
      "step": 51500
    },
    {
      "epoch": 3.5480987416626557,
      "grad_norm": 0.24137811362743378,
      "learning_rate": 2.7834081180050547e-05,
      "loss": 0.0351,
      "step": 51600
    },
    {
      "epoch": 3.554974902014715,
      "grad_norm": 0.26106971502304077,
      "learning_rate": 2.779110148365912e-05,
      "loss": 0.0356,
      "step": 51700
    },
    {
      "epoch": 3.5618510623667743,
      "grad_norm": 0.2590523958206177,
      "learning_rate": 2.7748121787267695e-05,
      "loss": 0.0333,
      "step": 51800
    },
    {
      "epoch": 3.5687272227188336,
      "grad_norm": 0.2490329146385193,
      "learning_rate": 2.7705142090876273e-05,
      "loss": 0.0346,
      "step": 51900
    },
    {
      "epoch": 3.5756033830708933,
      "grad_norm": 0.17311030626296997,
      "learning_rate": 2.7662162394484847e-05,
      "loss": 0.0323,
      "step": 52000
    },
    {
      "epoch": 3.5824795434229526,
      "grad_norm": 0.08671100437641144,
      "learning_rate": 2.761918269809342e-05,
      "loss": 0.0343,
      "step": 52100
    },
    {
      "epoch": 3.589355703775012,
      "grad_norm": 0.2748132348060608,
      "learning_rate": 2.7576203001701994e-05,
      "loss": 0.0351,
      "step": 52200
    },
    {
      "epoch": 3.5962318641270716,
      "grad_norm": 0.19368873536586761,
      "learning_rate": 2.7533223305310575e-05,
      "loss": 0.0333,
      "step": 52300
    },
    {
      "epoch": 3.603108024479131,
      "grad_norm": 0.16758762300014496,
      "learning_rate": 2.749024360891915e-05,
      "loss": 0.0322,
      "step": 52400
    },
    {
      "epoch": 3.60998418483119,
      "grad_norm": 0.14304542541503906,
      "learning_rate": 2.744726391252772e-05,
      "loss": 0.0336,
      "step": 52500
    },
    {
      "epoch": 3.61686034518325,
      "grad_norm": 0.22953912615776062,
      "learning_rate": 2.74042842161363e-05,
      "loss": 0.0342,
      "step": 52600
    },
    {
      "epoch": 3.6237365055353092,
      "grad_norm": 0.3698440492153168,
      "learning_rate": 2.7361304519744874e-05,
      "loss": 0.0302,
      "step": 52700
    },
    {
      "epoch": 3.6306126658873685,
      "grad_norm": 0.1851377934217453,
      "learning_rate": 2.7318324823353448e-05,
      "loss": 0.0331,
      "step": 52800
    },
    {
      "epoch": 3.637488826239428,
      "grad_norm": 0.23144316673278809,
      "learning_rate": 2.7275345126962025e-05,
      "loss": 0.031,
      "step": 52900
    },
    {
      "epoch": 3.644364986591487,
      "grad_norm": 0.19517984986305237,
      "learning_rate": 2.72323654305706e-05,
      "loss": 0.0335,
      "step": 53000
    },
    {
      "epoch": 3.651241146943547,
      "grad_norm": 0.0897124707698822,
      "learning_rate": 2.7189385734179173e-05,
      "loss": 0.0319,
      "step": 53100
    },
    {
      "epoch": 3.658117307295606,
      "grad_norm": 0.22601653635501862,
      "learning_rate": 2.7146406037787754e-05,
      "loss": 0.0314,
      "step": 53200
    },
    {
      "epoch": 3.6649934676476654,
      "grad_norm": 0.3680126667022705,
      "learning_rate": 2.7103426341396328e-05,
      "loss": 0.0333,
      "step": 53300
    },
    {
      "epoch": 3.671869627999725,
      "grad_norm": 0.2630920708179474,
      "learning_rate": 2.7060446645004898e-05,
      "loss": 0.0319,
      "step": 53400
    },
    {
      "epoch": 3.6787457883517845,
      "grad_norm": 0.26366445422172546,
      "learning_rate": 2.701746694861348e-05,
      "loss": 0.0324,
      "step": 53500
    },
    {
      "epoch": 3.6856219487038437,
      "grad_norm": 0.18668238818645477,
      "learning_rate": 2.6974487252222053e-05,
      "loss": 0.0321,
      "step": 53600
    },
    {
      "epoch": 3.692498109055903,
      "grad_norm": 0.09218652546405792,
      "learning_rate": 2.6931507555830627e-05,
      "loss": 0.0312,
      "step": 53700
    },
    {
      "epoch": 3.6993742694079623,
      "grad_norm": 0.1428777277469635,
      "learning_rate": 2.68885278594392e-05,
      "loss": 0.0321,
      "step": 53800
    },
    {
      "epoch": 3.706250429760022,
      "grad_norm": 0.1507500410079956,
      "learning_rate": 2.6845548163047778e-05,
      "loss": 0.0332,
      "step": 53900
    },
    {
      "epoch": 3.7131265901120813,
      "grad_norm": 0.38734689354896545,
      "learning_rate": 2.6802568466656352e-05,
      "loss": 0.0348,
      "step": 54000
    },
    {
      "epoch": 3.7200027504641406,
      "grad_norm": 0.14520646631717682,
      "learning_rate": 2.6759588770264926e-05,
      "loss": 0.0334,
      "step": 54100
    },
    {
      "epoch": 3.7268789108162004,
      "grad_norm": 0.31372612714767456,
      "learning_rate": 2.6716609073873506e-05,
      "loss": 0.0321,
      "step": 54200
    },
    {
      "epoch": 3.7337550711682597,
      "grad_norm": 0.24666139483451843,
      "learning_rate": 2.667362937748208e-05,
      "loss": 0.0313,
      "step": 54300
    },
    {
      "epoch": 3.740631231520319,
      "grad_norm": 0.14651940762996674,
      "learning_rate": 2.663064968109065e-05,
      "loss": 0.0321,
      "step": 54400
    },
    {
      "epoch": 3.7475073918723787,
      "grad_norm": 0.24201375246047974,
      "learning_rate": 2.658766998469923e-05,
      "loss": 0.0348,
      "step": 54500
    },
    {
      "epoch": 3.754383552224438,
      "grad_norm": 0.13092094659805298,
      "learning_rate": 2.6544690288307805e-05,
      "loss": 0.0314,
      "step": 54600
    },
    {
      "epoch": 3.7612597125764973,
      "grad_norm": 0.08907976746559143,
      "learning_rate": 2.650171059191638e-05,
      "loss": 0.0335,
      "step": 54700
    },
    {
      "epoch": 3.7681358729285566,
      "grad_norm": 0.21099036931991577,
      "learning_rate": 2.6458730895524957e-05,
      "loss": 0.0333,
      "step": 54800
    },
    {
      "epoch": 3.775012033280616,
      "grad_norm": 0.21500714123249054,
      "learning_rate": 2.641575119913353e-05,
      "loss": 0.0298,
      "step": 54900
    },
    {
      "epoch": 3.7818881936326756,
      "grad_norm": 0.10262203961610794,
      "learning_rate": 2.6372771502742105e-05,
      "loss": 0.0304,
      "step": 55000
    },
    {
      "epoch": 3.788764353984735,
      "grad_norm": 0.23751258850097656,
      "learning_rate": 2.6330221603314597e-05,
      "loss": 0.0325,
      "step": 55100
    },
    {
      "epoch": 3.795640514336794,
      "grad_norm": 0.13354803621768951,
      "learning_rate": 2.628724190692317e-05,
      "loss": 0.0323,
      "step": 55200
    },
    {
      "epoch": 3.802516674688854,
      "grad_norm": 0.2205328792333603,
      "learning_rate": 2.6244692007495657e-05,
      "loss": 0.0321,
      "step": 55300
    },
    {
      "epoch": 3.809392835040913,
      "grad_norm": 0.1481083780527115,
      "learning_rate": 2.6201712311104237e-05,
      "loss": 0.033,
      "step": 55400
    },
    {
      "epoch": 3.8162689953929725,
      "grad_norm": 0.18403558433055878,
      "learning_rate": 2.615873261471281e-05,
      "loss": 0.0329,
      "step": 55500
    },
    {
      "epoch": 3.823145155745032,
      "grad_norm": 0.23557423055171967,
      "learning_rate": 2.6115752918321385e-05,
      "loss": 0.036,
      "step": 55600
    },
    {
      "epoch": 3.8300213160970915,
      "grad_norm": 0.21145451068878174,
      "learning_rate": 2.6072773221929962e-05,
      "loss": 0.0315,
      "step": 55700
    },
    {
      "epoch": 3.836897476449151,
      "grad_norm": 0.16977845132350922,
      "learning_rate": 2.6029793525538536e-05,
      "loss": 0.0297,
      "step": 55800
    },
    {
      "epoch": 3.84377363680121,
      "grad_norm": 0.2043103724718094,
      "learning_rate": 2.598681382914711e-05,
      "loss": 0.0301,
      "step": 55900
    },
    {
      "epoch": 3.8506497971532694,
      "grad_norm": 0.14878976345062256,
      "learning_rate": 2.594383413275569e-05,
      "loss": 0.0317,
      "step": 56000
    },
    {
      "epoch": 3.857525957505329,
      "grad_norm": 0.26035600900650024,
      "learning_rate": 2.5900854436364265e-05,
      "loss": 0.033,
      "step": 56100
    },
    {
      "epoch": 3.8644021178573884,
      "grad_norm": 0.13841253519058228,
      "learning_rate": 2.585787473997284e-05,
      "loss": 0.034,
      "step": 56200
    },
    {
      "epoch": 3.8712782782094477,
      "grad_norm": 0.19309170544147491,
      "learning_rate": 2.581489504358141e-05,
      "loss": 0.034,
      "step": 56300
    },
    {
      "epoch": 3.8781544385615074,
      "grad_norm": 0.14743083715438843,
      "learning_rate": 2.577191534718999e-05,
      "loss": 0.0311,
      "step": 56400
    },
    {
      "epoch": 3.8850305989135667,
      "grad_norm": 0.269646555185318,
      "learning_rate": 2.5728935650798564e-05,
      "loss": 0.0299,
      "step": 56500
    },
    {
      "epoch": 3.891906759265626,
      "grad_norm": 0.3967782258987427,
      "learning_rate": 2.5685955954407138e-05,
      "loss": 0.0335,
      "step": 56600
    },
    {
      "epoch": 3.8987829196176857,
      "grad_norm": 0.18492235243320465,
      "learning_rate": 2.5642976258015715e-05,
      "loss": 0.0332,
      "step": 56700
    },
    {
      "epoch": 3.905659079969745,
      "grad_norm": 0.11630256474018097,
      "learning_rate": 2.559999656162429e-05,
      "loss": 0.0349,
      "step": 56800
    },
    {
      "epoch": 3.9125352403218043,
      "grad_norm": 0.25556039810180664,
      "learning_rate": 2.5557016865232863e-05,
      "loss": 0.0343,
      "step": 56900
    },
    {
      "epoch": 3.9194114006738636,
      "grad_norm": 0.17090289294719696,
      "learning_rate": 2.5514037168841444e-05,
      "loss": 0.0313,
      "step": 57000
    },
    {
      "epoch": 3.926287561025923,
      "grad_norm": 0.2752477526664734,
      "learning_rate": 2.5471057472450017e-05,
      "loss": 0.033,
      "step": 57100
    },
    {
      "epoch": 3.9331637213779826,
      "grad_norm": 0.19683685898780823,
      "learning_rate": 2.542807777605859e-05,
      "loss": 0.0333,
      "step": 57200
    },
    {
      "epoch": 3.940039881730042,
      "grad_norm": 0.14863228797912598,
      "learning_rate": 2.538509807966717e-05,
      "loss": 0.0299,
      "step": 57300
    },
    {
      "epoch": 3.9469160420821012,
      "grad_norm": 0.15708427131175995,
      "learning_rate": 2.5342118383275743e-05,
      "loss": 0.0315,
      "step": 57400
    },
    {
      "epoch": 3.953792202434161,
      "grad_norm": 0.22700749337673187,
      "learning_rate": 2.5299138686884316e-05,
      "loss": 0.0312,
      "step": 57500
    },
    {
      "epoch": 3.9606683627862203,
      "grad_norm": 0.16813920438289642,
      "learning_rate": 2.525615899049289e-05,
      "loss": 0.0311,
      "step": 57600
    },
    {
      "epoch": 3.9675445231382795,
      "grad_norm": 0.14644530415534973,
      "learning_rate": 2.5213179294101468e-05,
      "loss": 0.031,
      "step": 57700
    },
    {
      "epoch": 3.974420683490339,
      "grad_norm": 0.1863006204366684,
      "learning_rate": 2.517019959771004e-05,
      "loss": 0.0329,
      "step": 57800
    },
    {
      "epoch": 3.9812968438423986,
      "grad_norm": 0.21191787719726562,
      "learning_rate": 2.5127219901318616e-05,
      "loss": 0.0314,
      "step": 57900
    },
    {
      "epoch": 3.988173004194458,
      "grad_norm": 0.17701132595539093,
      "learning_rate": 2.5084240204927196e-05,
      "loss": 0.0316,
      "step": 58000
    },
    {
      "epoch": 3.995049164546517,
      "grad_norm": 0.3225429058074951,
      "learning_rate": 2.504126050853577e-05,
      "loss": 0.0343,
      "step": 58100
    },
    {
      "epoch": 4.0,
      "eval_accuracy_macro_0.5": 0.9849804043769836,
      "eval_accuracy_micro_0.5": 0.9849803447723389,
      "eval_accuracy_weighted_0.5": 0.9829810857772827,
      "eval_f1_macro_0.5": 0.8061310648918152,
      "eval_f1_macro_0.6": 0.7938873171806335,
      "eval_f1_macro_0.7": 0.7713889479637146,
      "eval_f1_macro_0.8": 0.6431826949119568,
      "eval_f1_micro_0.5": 0.8048330545425415,
      "eval_f1_micro_0.6": 0.7938823699951172,
      "eval_f1_micro_0.7": 0.7739951610565186,
      "eval_f1_micro_0.8": 0.7376089692115784,
      "eval_f1_micro_0.9": 0.6587755680084229,
      "eval_f1_weighted_0.5": 0.8012440204620361,
      "eval_f1_weighted_0.6": 0.7872519493103027,
      "eval_f1_weighted_0.7": 0.7631397843360901,
      "eval_f1_weighted_0.8": 0.6297383904457092,
      "eval_loss": 0.031169401481747627,
      "eval_runtime": 213.8173,
      "eval_samples_per_second": 135.803,
      "eval_steps_per_second": 16.977,
      "step": 58172
    },
    {
      "epoch": 4.001925324898576,
      "grad_norm": 0.16917496919631958,
      "learning_rate": 2.4998280812144344e-05,
      "loss": 0.033,
      "step": 58200
    },
    {
      "epoch": 4.008801485250636,
      "grad_norm": 0.13393302261829376,
      "learning_rate": 2.4955301115752918e-05,
      "loss": 0.0314,
      "step": 58300
    },
    {
      "epoch": 4.015677645602695,
      "grad_norm": 0.16662967205047607,
      "learning_rate": 2.4912321419361495e-05,
      "loss": 0.0326,
      "step": 58400
    },
    {
      "epoch": 4.022553805954755,
      "grad_norm": 0.1424182951450348,
      "learning_rate": 2.4869341722970073e-05,
      "loss": 0.0348,
      "step": 58500
    },
    {
      "epoch": 4.0294299663068145,
      "grad_norm": 0.176738902926445,
      "learning_rate": 2.4826362026578646e-05,
      "loss": 0.0299,
      "step": 58600
    },
    {
      "epoch": 4.036306126658873,
      "grad_norm": 0.0785309225320816,
      "learning_rate": 2.478338233018722e-05,
      "loss": 0.0294,
      "step": 58700
    },
    {
      "epoch": 4.043182287010933,
      "grad_norm": 0.1505972295999527,
      "learning_rate": 2.4740402633795794e-05,
      "loss": 0.0317,
      "step": 58800
    },
    {
      "epoch": 4.050058447362993,
      "grad_norm": 0.06572575122117996,
      "learning_rate": 2.469742293740437e-05,
      "loss": 0.0311,
      "step": 58900
    },
    {
      "epoch": 4.056934607715052,
      "grad_norm": 0.24856983125209808,
      "learning_rate": 2.465444324101295e-05,
      "loss": 0.0323,
      "step": 59000
    },
    {
      "epoch": 4.063810768067111,
      "grad_norm": 0.12767456471920013,
      "learning_rate": 2.4611463544621523e-05,
      "loss": 0.0315,
      "step": 59100
    },
    {
      "epoch": 4.070686928419171,
      "grad_norm": 0.1889764368534088,
      "learning_rate": 2.4568483848230097e-05,
      "loss": 0.0324,
      "step": 59200
    },
    {
      "epoch": 4.07756308877123,
      "grad_norm": 0.20488609373569489,
      "learning_rate": 2.452593394880259e-05,
      "loss": 0.031,
      "step": 59300
    },
    {
      "epoch": 4.08443924912329,
      "grad_norm": 0.11588489264249802,
      "learning_rate": 2.448295425241116e-05,
      "loss": 0.0326,
      "step": 59400
    },
    {
      "epoch": 4.0913154094753486,
      "grad_norm": 0.16471947729587555,
      "learning_rate": 2.4439974556019737e-05,
      "loss": 0.0298,
      "step": 59500
    },
    {
      "epoch": 4.098191569827408,
      "grad_norm": 0.22330200672149658,
      "learning_rate": 2.4396994859628314e-05,
      "loss": 0.0335,
      "step": 59600
    },
    {
      "epoch": 4.105067730179468,
      "grad_norm": 0.21441812813282013,
      "learning_rate": 2.4354015163236888e-05,
      "loss": 0.0303,
      "step": 59700
    },
    {
      "epoch": 4.111943890531527,
      "grad_norm": 0.27787595987319946,
      "learning_rate": 2.4311035466845462e-05,
      "loss": 0.0343,
      "step": 59800
    },
    {
      "epoch": 4.118820050883587,
      "grad_norm": 0.1922026127576828,
      "learning_rate": 2.4268055770454036e-05,
      "loss": 0.0339,
      "step": 59900
    },
    {
      "epoch": 4.125696211235646,
      "grad_norm": 0.16843867301940918,
      "learning_rate": 2.4225076074062613e-05,
      "loss": 0.0306,
      "step": 60000
    },
    {
      "epoch": 4.132572371587705,
      "grad_norm": 0.17493654787540436,
      "learning_rate": 2.418209637767119e-05,
      "loss": 0.0308,
      "step": 60100
    },
    {
      "epoch": 4.139448531939765,
      "grad_norm": 0.2804456353187561,
      "learning_rate": 2.4139116681279764e-05,
      "loss": 0.0304,
      "step": 60200
    },
    {
      "epoch": 4.146324692291825,
      "grad_norm": 0.14189913868904114,
      "learning_rate": 2.409613698488834e-05,
      "loss": 0.0318,
      "step": 60300
    },
    {
      "epoch": 4.1532008526438835,
      "grad_norm": 0.2904681861400604,
      "learning_rate": 2.4053157288496916e-05,
      "loss": 0.0331,
      "step": 60400
    },
    {
      "epoch": 4.160077012995943,
      "grad_norm": 0.17504067718982697,
      "learning_rate": 2.401017759210549e-05,
      "loss": 0.0315,
      "step": 60500
    },
    {
      "epoch": 4.166953173348002,
      "grad_norm": 0.21169821918010712,
      "learning_rate": 2.3967197895714067e-05,
      "loss": 0.0317,
      "step": 60600
    },
    {
      "epoch": 4.173829333700062,
      "grad_norm": 0.22313639521598816,
      "learning_rate": 2.3924647996286556e-05,
      "loss": 0.0286,
      "step": 60700
    },
    {
      "epoch": 4.1807054940521216,
      "grad_norm": 0.2274644374847412,
      "learning_rate": 2.388166829989513e-05,
      "loss": 0.0307,
      "step": 60800
    },
    {
      "epoch": 4.18758165440418,
      "grad_norm": 0.2334878295660019,
      "learning_rate": 2.3838688603503707e-05,
      "loss": 0.0326,
      "step": 60900
    },
    {
      "epoch": 4.19445781475624,
      "grad_norm": 0.07295013964176178,
      "learning_rate": 2.379570890711228e-05,
      "loss": 0.0314,
      "step": 61000
    },
    {
      "epoch": 4.2013339751083,
      "grad_norm": 0.17798934876918793,
      "learning_rate": 2.3752729210720855e-05,
      "loss": 0.0302,
      "step": 61100
    },
    {
      "epoch": 4.208210135460359,
      "grad_norm": 0.1429332196712494,
      "learning_rate": 2.3709749514329432e-05,
      "loss": 0.0309,
      "step": 61200
    },
    {
      "epoch": 4.2150862958124184,
      "grad_norm": 0.116190604865551,
      "learning_rate": 2.3666769817938006e-05,
      "loss": 0.0301,
      "step": 61300
    },
    {
      "epoch": 4.221962456164478,
      "grad_norm": 0.10992677509784698,
      "learning_rate": 2.3623790121546584e-05,
      "loss": 0.0311,
      "step": 61400
    },
    {
      "epoch": 4.228838616516537,
      "grad_norm": 0.2701460123062134,
      "learning_rate": 2.3580810425155157e-05,
      "loss": 0.0298,
      "step": 61500
    },
    {
      "epoch": 4.235714776868597,
      "grad_norm": 0.10417109727859497,
      "learning_rate": 2.353783072876373e-05,
      "loss": 0.0344,
      "step": 61600
    },
    {
      "epoch": 4.242590937220656,
      "grad_norm": 0.1401890367269516,
      "learning_rate": 2.349485103237231e-05,
      "loss": 0.0325,
      "step": 61700
    },
    {
      "epoch": 4.249467097572715,
      "grad_norm": 0.21214868128299713,
      "learning_rate": 2.3451871335980886e-05,
      "loss": 0.0325,
      "step": 61800
    },
    {
      "epoch": 4.256343257924775,
      "grad_norm": 0.2582785189151764,
      "learning_rate": 2.340889163958946e-05,
      "loss": 0.0314,
      "step": 61900
    },
    {
      "epoch": 4.263219418276834,
      "grad_norm": 0.14513689279556274,
      "learning_rate": 2.3365911943198034e-05,
      "loss": 0.035,
      "step": 62000
    },
    {
      "epoch": 4.270095578628894,
      "grad_norm": 0.15309424698352814,
      "learning_rate": 2.3322932246806608e-05,
      "loss": 0.0312,
      "step": 62100
    },
    {
      "epoch": 4.276971738980953,
      "grad_norm": 0.1842838078737259,
      "learning_rate": 2.3279952550415185e-05,
      "loss": 0.0308,
      "step": 62200
    },
    {
      "epoch": 4.283847899333012,
      "grad_norm": 0.20540502667427063,
      "learning_rate": 2.3236972854023762e-05,
      "loss": 0.0314,
      "step": 62300
    },
    {
      "epoch": 4.290724059685072,
      "grad_norm": 0.22670358419418335,
      "learning_rate": 2.3193993157632336e-05,
      "loss": 0.0309,
      "step": 62400
    },
    {
      "epoch": 4.297600220037131,
      "grad_norm": 0.1936054676771164,
      "learning_rate": 2.315101346124091e-05,
      "loss": 0.0287,
      "step": 62500
    },
    {
      "epoch": 4.304476380389191,
      "grad_norm": 0.1610274761915207,
      "learning_rate": 2.3108033764849484e-05,
      "loss": 0.0318,
      "step": 62600
    },
    {
      "epoch": 4.31135254074125,
      "grad_norm": 0.2684950828552246,
      "learning_rate": 2.306505406845806e-05,
      "loss": 0.0313,
      "step": 62700
    },
    {
      "epoch": 4.318228701093309,
      "grad_norm": 0.16781094670295715,
      "learning_rate": 2.302207437206664e-05,
      "loss": 0.0316,
      "step": 62800
    },
    {
      "epoch": 4.325104861445369,
      "grad_norm": 0.18428421020507812,
      "learning_rate": 2.2979094675675213e-05,
      "loss": 0.0304,
      "step": 62900
    },
    {
      "epoch": 4.331981021797429,
      "grad_norm": 0.17107093334197998,
      "learning_rate": 2.2936114979283786e-05,
      "loss": 0.0329,
      "step": 63000
    },
    {
      "epoch": 4.3388571821494875,
      "grad_norm": 0.15171965956687927,
      "learning_rate": 2.2893135282892364e-05,
      "loss": 0.0321,
      "step": 63100
    },
    {
      "epoch": 4.345733342501547,
      "grad_norm": 0.29303690791130066,
      "learning_rate": 2.2850155586500938e-05,
      "loss": 0.0315,
      "step": 63200
    },
    {
      "epoch": 4.352609502853607,
      "grad_norm": 0.24757340550422668,
      "learning_rate": 2.2807175890109515e-05,
      "loss": 0.029,
      "step": 63300
    },
    {
      "epoch": 4.359485663205666,
      "grad_norm": 0.1350608766078949,
      "learning_rate": 2.276419619371809e-05,
      "loss": 0.0307,
      "step": 63400
    },
    {
      "epoch": 4.3663618235577255,
      "grad_norm": 0.28739234805107117,
      "learning_rate": 2.2721216497326663e-05,
      "loss": 0.0323,
      "step": 63500
    },
    {
      "epoch": 4.373237983909785,
      "grad_norm": 0.2034694254398346,
      "learning_rate": 2.267823680093524e-05,
      "loss": 0.0329,
      "step": 63600
    },
    {
      "epoch": 4.380114144261844,
      "grad_norm": 0.19809956848621368,
      "learning_rate": 2.2635257104543814e-05,
      "loss": 0.0348,
      "step": 63700
    },
    {
      "epoch": 4.386990304613904,
      "grad_norm": 0.2503798007965088,
      "learning_rate": 2.259227740815239e-05,
      "loss": 0.0314,
      "step": 63800
    },
    {
      "epoch": 4.393866464965963,
      "grad_norm": 0.12584054470062256,
      "learning_rate": 2.2549297711760965e-05,
      "loss": 0.0316,
      "step": 63900
    },
    {
      "epoch": 4.400742625318022,
      "grad_norm": 0.2628295123577118,
      "learning_rate": 2.250631801536954e-05,
      "loss": 0.0298,
      "step": 64000
    },
    {
      "epoch": 4.407618785670082,
      "grad_norm": 0.19064579904079437,
      "learning_rate": 2.2463338318978116e-05,
      "loss": 0.0304,
      "step": 64100
    },
    {
      "epoch": 4.414494946022141,
      "grad_norm": 0.17578695714473724,
      "learning_rate": 2.242035862258669e-05,
      "loss": 0.0321,
      "step": 64200
    },
    {
      "epoch": 4.421371106374201,
      "grad_norm": 0.14937067031860352,
      "learning_rate": 2.2377378926195268e-05,
      "loss": 0.0338,
      "step": 64300
    },
    {
      "epoch": 4.4282472667262605,
      "grad_norm": 0.2399439513683319,
      "learning_rate": 2.233439922980384e-05,
      "loss": 0.0303,
      "step": 64400
    },
    {
      "epoch": 4.435123427078319,
      "grad_norm": 0.28489354252815247,
      "learning_rate": 2.2291419533412415e-05,
      "loss": 0.0315,
      "step": 64500
    },
    {
      "epoch": 4.441999587430379,
      "grad_norm": 0.09512194246053696,
      "learning_rate": 2.2248439837020993e-05,
      "loss": 0.0314,
      "step": 64600
    },
    {
      "epoch": 4.448875747782438,
      "grad_norm": 0.23684625327587128,
      "learning_rate": 2.2205460140629567e-05,
      "loss": 0.0309,
      "step": 64700
    },
    {
      "epoch": 4.455751908134498,
      "grad_norm": 0.24202625453472137,
      "learning_rate": 2.2162480444238144e-05,
      "loss": 0.031,
      "step": 64800
    },
    {
      "epoch": 4.462628068486557,
      "grad_norm": 0.21244366466999054,
      "learning_rate": 2.2119500747846718e-05,
      "loss": 0.0302,
      "step": 64900
    },
    {
      "epoch": 4.469504228838616,
      "grad_norm": 0.24718131124973297,
      "learning_rate": 2.2076521051455292e-05,
      "loss": 0.0301,
      "step": 65000
    },
    {
      "epoch": 4.476380389190676,
      "grad_norm": 0.16546885669231415,
      "learning_rate": 2.203354135506387e-05,
      "loss": 0.032,
      "step": 65100
    },
    {
      "epoch": 4.483256549542736,
      "grad_norm": 0.10057126730680466,
      "learning_rate": 2.1990561658672446e-05,
      "loss": 0.0329,
      "step": 65200
    },
    {
      "epoch": 4.4901327098947945,
      "grad_norm": 0.13766081631183624,
      "learning_rate": 2.194758196228102e-05,
      "loss": 0.0333,
      "step": 65300
    },
    {
      "epoch": 4.497008870246854,
      "grad_norm": 0.2540419399738312,
      "learning_rate": 2.1904602265889594e-05,
      "loss": 0.0325,
      "step": 65400
    },
    {
      "epoch": 4.503885030598914,
      "grad_norm": 0.20892661809921265,
      "learning_rate": 2.1862052366462087e-05,
      "loss": 0.0303,
      "step": 65500
    },
    {
      "epoch": 4.510761190950973,
      "grad_norm": 0.2001819759607315,
      "learning_rate": 2.1819072670070657e-05,
      "loss": 0.0299,
      "step": 65600
    },
    {
      "epoch": 4.517637351303033,
      "grad_norm": 0.21371479332447052,
      "learning_rate": 2.1776092973679234e-05,
      "loss": 0.0322,
      "step": 65700
    },
    {
      "epoch": 4.524513511655091,
      "grad_norm": 0.26790547370910645,
      "learning_rate": 2.1733113277287812e-05,
      "loss": 0.0303,
      "step": 65800
    },
    {
      "epoch": 4.531389672007151,
      "grad_norm": 0.13551141321659088,
      "learning_rate": 2.1690133580896386e-05,
      "loss": 0.0285,
      "step": 65900
    },
    {
      "epoch": 4.538265832359211,
      "grad_norm": 0.284640371799469,
      "learning_rate": 2.1647153884504963e-05,
      "loss": 0.0274,
      "step": 66000
    },
    {
      "epoch": 4.54514199271127,
      "grad_norm": 0.1996925324201584,
      "learning_rate": 2.1604174188113533e-05,
      "loss": 0.0322,
      "step": 66100
    },
    {
      "epoch": 4.5520181530633295,
      "grad_norm": 0.27377763390541077,
      "learning_rate": 2.156119449172211e-05,
      "loss": 0.032,
      "step": 66200
    },
    {
      "epoch": 4.558894313415389,
      "grad_norm": 0.269591748714447,
      "learning_rate": 2.15186445922946e-05,
      "loss": 0.033,
      "step": 66300
    },
    {
      "epoch": 4.565770473767448,
      "grad_norm": 0.2813657522201538,
      "learning_rate": 2.1475664895903177e-05,
      "loss": 0.0314,
      "step": 66400
    },
    {
      "epoch": 4.572646634119508,
      "grad_norm": 0.20754921436309814,
      "learning_rate": 2.143268519951175e-05,
      "loss": 0.0306,
      "step": 66500
    },
    {
      "epoch": 4.579522794471567,
      "grad_norm": 0.19974584877490997,
      "learning_rate": 2.138970550312033e-05,
      "loss": 0.028,
      "step": 66600
    },
    {
      "epoch": 4.586398954823626,
      "grad_norm": 0.21273326873779297,
      "learning_rate": 2.1346725806728902e-05,
      "loss": 0.0303,
      "step": 66700
    },
    {
      "epoch": 4.593275115175686,
      "grad_norm": 0.18111546337604523,
      "learning_rate": 2.1303746110337476e-05,
      "loss": 0.031,
      "step": 66800
    },
    {
      "epoch": 4.600151275527745,
      "grad_norm": 0.2740494906902313,
      "learning_rate": 2.1260766413946053e-05,
      "loss": 0.0294,
      "step": 66900
    },
    {
      "epoch": 4.607027435879805,
      "grad_norm": 0.3600190579891205,
      "learning_rate": 2.1217786717554627e-05,
      "loss": 0.0307,
      "step": 67000
    },
    {
      "epoch": 4.613903596231864,
      "grad_norm": 0.19336925446987152,
      "learning_rate": 2.1174807021163205e-05,
      "loss": 0.0314,
      "step": 67100
    },
    {
      "epoch": 4.620779756583923,
      "grad_norm": 0.18270958960056305,
      "learning_rate": 2.113182732477178e-05,
      "loss": 0.0317,
      "step": 67200
    },
    {
      "epoch": 4.627655916935983,
      "grad_norm": 0.29839152097702026,
      "learning_rate": 2.1088847628380353e-05,
      "loss": 0.0315,
      "step": 67300
    },
    {
      "epoch": 4.634532077288043,
      "grad_norm": 0.3248174786567688,
      "learning_rate": 2.104586793198893e-05,
      "loss": 0.0326,
      "step": 67400
    },
    {
      "epoch": 4.641408237640102,
      "grad_norm": 0.2370034158229828,
      "learning_rate": 2.1002888235597504e-05,
      "loss": 0.0304,
      "step": 67500
    },
    {
      "epoch": 4.648284397992161,
      "grad_norm": 0.1453716903924942,
      "learning_rate": 2.095990853920608e-05,
      "loss": 0.0294,
      "step": 67600
    },
    {
      "epoch": 4.655160558344221,
      "grad_norm": 0.2154453992843628,
      "learning_rate": 2.0916928842814655e-05,
      "loss": 0.0292,
      "step": 67700
    },
    {
      "epoch": 4.66203671869628,
      "grad_norm": 0.148027241230011,
      "learning_rate": 2.087394914642323e-05,
      "loss": 0.0319,
      "step": 67800
    },
    {
      "epoch": 4.66891287904834,
      "grad_norm": 0.2726984918117523,
      "learning_rate": 2.0830969450031806e-05,
      "loss": 0.0312,
      "step": 67900
    },
    {
      "epoch": 4.6757890394003985,
      "grad_norm": 0.20440372824668884,
      "learning_rate": 2.078798975364038e-05,
      "loss": 0.0331,
      "step": 68000
    },
    {
      "epoch": 4.682665199752458,
      "grad_norm": 0.18411949276924133,
      "learning_rate": 2.0745010057248957e-05,
      "loss": 0.0322,
      "step": 68100
    },
    {
      "epoch": 4.689541360104518,
      "grad_norm": 0.09764920175075531,
      "learning_rate": 2.070203036085753e-05,
      "loss": 0.0296,
      "step": 68200
    },
    {
      "epoch": 4.696417520456577,
      "grad_norm": 0.09971467405557632,
      "learning_rate": 2.0659050664466105e-05,
      "loss": 0.032,
      "step": 68300
    },
    {
      "epoch": 4.7032936808086365,
      "grad_norm": 0.20855869352817535,
      "learning_rate": 2.0616070968074682e-05,
      "loss": 0.0317,
      "step": 68400
    },
    {
      "epoch": 4.710169841160695,
      "grad_norm": 0.12166180461645126,
      "learning_rate": 2.057309127168326e-05,
      "loss": 0.0314,
      "step": 68500
    },
    {
      "epoch": 4.717046001512755,
      "grad_norm": 0.26471197605133057,
      "learning_rate": 2.0530111575291834e-05,
      "loss": 0.0307,
      "step": 68600
    },
    {
      "epoch": 4.723922161864815,
      "grad_norm": 0.3393588960170746,
      "learning_rate": 2.0487131878900408e-05,
      "loss": 0.0319,
      "step": 68700
    },
    {
      "epoch": 4.730798322216874,
      "grad_norm": 0.17556601762771606,
      "learning_rate": 2.044415218250898e-05,
      "loss": 0.0288,
      "step": 68800
    },
    {
      "epoch": 4.737674482568933,
      "grad_norm": 0.087809257209301,
      "learning_rate": 2.040117248611756e-05,
      "loss": 0.029,
      "step": 68900
    },
    {
      "epoch": 4.744550642920993,
      "grad_norm": 0.1370573192834854,
      "learning_rate": 2.0358192789726136e-05,
      "loss": 0.0306,
      "step": 69000
    },
    {
      "epoch": 4.751426803273052,
      "grad_norm": 0.15281252562999725,
      "learning_rate": 2.031521309333471e-05,
      "loss": 0.0306,
      "step": 69100
    },
    {
      "epoch": 4.758302963625112,
      "grad_norm": 0.17270004749298096,
      "learning_rate": 2.0272233396943284e-05,
      "loss": 0.0306,
      "step": 69200
    },
    {
      "epoch": 4.7651791239771715,
      "grad_norm": 0.35825762152671814,
      "learning_rate": 2.0229253700551858e-05,
      "loss": 0.0318,
      "step": 69300
    },
    {
      "epoch": 4.77205528432923,
      "grad_norm": 0.18219947814941406,
      "learning_rate": 2.0186274004160435e-05,
      "loss": 0.0309,
      "step": 69400
    },
    {
      "epoch": 4.77893144468129,
      "grad_norm": 0.13741900026798248,
      "learning_rate": 2.0143294307769012e-05,
      "loss": 0.0333,
      "step": 69500
    },
    {
      "epoch": 4.78580760503335,
      "grad_norm": 0.17244413495063782,
      "learning_rate": 2.0100314611377586e-05,
      "loss": 0.0313,
      "step": 69600
    },
    {
      "epoch": 4.792683765385409,
      "grad_norm": 0.11440400034189224,
      "learning_rate": 2.005733491498616e-05,
      "loss": 0.0319,
      "step": 69700
    },
    {
      "epoch": 4.799559925737468,
      "grad_norm": 0.46745625138282776,
      "learning_rate": 2.0014355218594738e-05,
      "loss": 0.0303,
      "step": 69800
    },
    {
      "epoch": 4.806436086089528,
      "grad_norm": 0.12517192959785461,
      "learning_rate": 1.997137552220331e-05,
      "loss": 0.032,
      "step": 69900
    },
    {
      "epoch": 4.813312246441587,
      "grad_norm": 0.14459146559238434,
      "learning_rate": 1.992839582581189e-05,
      "loss": 0.0311,
      "step": 70000
    },
    {
      "epoch": 4.820188406793647,
      "grad_norm": 0.13068537414073944,
      "learning_rate": 1.9885416129420463e-05,
      "loss": 0.0324,
      "step": 70100
    },
    {
      "epoch": 4.8270645671457055,
      "grad_norm": 0.18005353212356567,
      "learning_rate": 1.9842436433029037e-05,
      "loss": 0.032,
      "step": 70200
    },
    {
      "epoch": 4.833940727497765,
      "grad_norm": 0.1737777292728424,
      "learning_rate": 1.9799456736637614e-05,
      "loss": 0.0315,
      "step": 70300
    },
    {
      "epoch": 4.840816887849825,
      "grad_norm": 0.20801830291748047,
      "learning_rate": 1.9756477040246188e-05,
      "loss": 0.0305,
      "step": 70400
    },
    {
      "epoch": 4.847693048201884,
      "grad_norm": 0.31815120577812195,
      "learning_rate": 1.9713497343854765e-05,
      "loss": 0.0343,
      "step": 70500
    },
    {
      "epoch": 4.854569208553944,
      "grad_norm": 0.1332201063632965,
      "learning_rate": 1.967051764746334e-05,
      "loss": 0.0351,
      "step": 70600
    },
    {
      "epoch": 4.861445368906002,
      "grad_norm": 0.2642078399658203,
      "learning_rate": 1.9627537951071913e-05,
      "loss": 0.0329,
      "step": 70700
    },
    {
      "epoch": 4.868321529258062,
      "grad_norm": 0.08933977037668228,
      "learning_rate": 1.958455825468049e-05,
      "loss": 0.0293,
      "step": 70800
    },
    {
      "epoch": 4.875197689610122,
      "grad_norm": 0.11141643673181534,
      "learning_rate": 1.9541578558289064e-05,
      "loss": 0.0306,
      "step": 70900
    },
    {
      "epoch": 4.882073849962181,
      "grad_norm": 0.2098076492547989,
      "learning_rate": 1.949859886189764e-05,
      "loss": 0.0346,
      "step": 71000
    },
    {
      "epoch": 4.8889500103142405,
      "grad_norm": 0.14193211495876312,
      "learning_rate": 1.9455619165506215e-05,
      "loss": 0.0317,
      "step": 71100
    },
    {
      "epoch": 4.8958261706663,
      "grad_norm": 0.15628190338611603,
      "learning_rate": 1.941263946911479e-05,
      "loss": 0.0324,
      "step": 71200
    },
    {
      "epoch": 4.902702331018359,
      "grad_norm": 0.27359655499458313,
      "learning_rate": 1.9369659772723367e-05,
      "loss": 0.0338,
      "step": 71300
    },
    {
      "epoch": 4.909578491370419,
      "grad_norm": 0.20844799280166626,
      "learning_rate": 1.932668007633194e-05,
      "loss": 0.0305,
      "step": 71400
    },
    {
      "epoch": 4.9164546517224785,
      "grad_norm": 0.15685364603996277,
      "learning_rate": 1.9283700379940518e-05,
      "loss": 0.0308,
      "step": 71500
    },
    {
      "epoch": 4.923330812074537,
      "grad_norm": 0.1668918877840042,
      "learning_rate": 1.924072068354909e-05,
      "loss": 0.033,
      "step": 71600
    },
    {
      "epoch": 4.930206972426597,
      "grad_norm": 0.2462507039308548,
      "learning_rate": 1.9197740987157666e-05,
      "loss": 0.0329,
      "step": 71700
    },
    {
      "epoch": 4.937083132778657,
      "grad_norm": 0.19116179645061493,
      "learning_rate": 1.9154761290766243e-05,
      "loss": 0.0312,
      "step": 71800
    },
    {
      "epoch": 4.943959293130716,
      "grad_norm": 0.23822252452373505,
      "learning_rate": 1.9112211391338732e-05,
      "loss": 0.0328,
      "step": 71900
    },
    {
      "epoch": 4.950835453482775,
      "grad_norm": 0.09180590510368347,
      "learning_rate": 1.9069231694947306e-05,
      "loss": 0.0301,
      "step": 72000
    },
    {
      "epoch": 4.957711613834834,
      "grad_norm": 0.1967829167842865,
      "learning_rate": 1.9026251998555883e-05,
      "loss": 0.0292,
      "step": 72100
    },
    {
      "epoch": 4.964587774186894,
      "grad_norm": 0.12953762710094452,
      "learning_rate": 1.898327230216446e-05,
      "loss": 0.0289,
      "step": 72200
    },
    {
      "epoch": 4.971463934538954,
      "grad_norm": 0.26285508275032043,
      "learning_rate": 1.8940292605773034e-05,
      "loss": 0.0318,
      "step": 72300
    },
    {
      "epoch": 4.978340094891013,
      "grad_norm": 0.2630956172943115,
      "learning_rate": 1.8897312909381608e-05,
      "loss": 0.0306,
      "step": 72400
    },
    {
      "epoch": 4.985216255243072,
      "grad_norm": 0.26660701632499695,
      "learning_rate": 1.8854333212990186e-05,
      "loss": 0.0334,
      "step": 72500
    },
    {
      "epoch": 4.992092415595132,
      "grad_norm": 0.2505269944667816,
      "learning_rate": 1.881135351659876e-05,
      "loss": 0.0295,
      "step": 72600
    },
    {
      "epoch": 4.998968575947191,
      "grad_norm": 0.11236318200826645,
      "learning_rate": 1.8768373820207337e-05,
      "loss": 0.0323,
      "step": 72700
    },
    {
      "epoch": 5.0,
      "eval_accuracy_macro_0.5": 0.9854808449745178,
      "eval_accuracy_micro_0.5": 0.985480785369873,
      "eval_accuracy_weighted_0.5": 0.983514666557312,
      "eval_f1_macro_0.5": 0.8138072490692139,
      "eval_f1_macro_0.6": 0.8039671182632446,
      "eval_f1_macro_0.7": 0.7827310562133789,
      "eval_f1_macro_0.8": 0.6585507988929749,
      "eval_f1_micro_0.5": 0.8122991323471069,
      "eval_f1_micro_0.6": 0.8036999702453613,
      "eval_f1_micro_0.7": 0.7848054766654968,
      "eval_f1_micro_0.8": 0.7495887875556946,
      "eval_f1_micro_0.9": 0.673194169998169,
      "eval_f1_weighted_0.5": 0.8090532422065735,
      "eval_f1_weighted_0.6": 0.7977768182754517,
      "eval_f1_weighted_0.7": 0.7750676274299622,
      "eval_f1_weighted_0.8": 0.6452853083610535,
      "eval_loss": 0.030179433524608612,
      "eval_runtime": 213.9494,
      "eval_samples_per_second": 135.719,
      "eval_steps_per_second": 16.967,
      "step": 72715
    },
    {
      "epoch": 5.005844736299251,
      "grad_norm": 0.1466323584318161,
      "learning_rate": 1.872539412381591e-05,
      "loss": 0.031,
      "step": 72800
    },
    {
      "epoch": 5.0127208966513095,
      "grad_norm": 0.1796158105134964,
      "learning_rate": 1.8682414427424485e-05,
      "loss": 0.0291,
      "step": 72900
    },
    {
      "epoch": 5.019597057003369,
      "grad_norm": 0.2533997595310211,
      "learning_rate": 1.8639434731033062e-05,
      "loss": 0.0305,
      "step": 73000
    },
    {
      "epoch": 5.026473217355429,
      "grad_norm": 0.2304273396730423,
      "learning_rate": 1.8596455034641636e-05,
      "loss": 0.0309,
      "step": 73100
    },
    {
      "epoch": 5.033349377707488,
      "grad_norm": 0.24899375438690186,
      "learning_rate": 1.8553475338250213e-05,
      "loss": 0.0306,
      "step": 73200
    },
    {
      "epoch": 5.0402255380595475,
      "grad_norm": 0.12853270769119263,
      "learning_rate": 1.8510495641858787e-05,
      "loss": 0.0282,
      "step": 73300
    },
    {
      "epoch": 5.047101698411607,
      "grad_norm": 0.3079895079135895,
      "learning_rate": 1.846751594546736e-05,
      "loss": 0.0308,
      "step": 73400
    },
    {
      "epoch": 5.053977858763666,
      "grad_norm": 0.18998484313488007,
      "learning_rate": 1.8424536249075938e-05,
      "loss": 0.028,
      "step": 73500
    },
    {
      "epoch": 5.060854019115726,
      "grad_norm": 0.17789803445339203,
      "learning_rate": 1.8381556552684512e-05,
      "loss": 0.0312,
      "step": 73600
    },
    {
      "epoch": 5.067730179467786,
      "grad_norm": 0.16539829969406128,
      "learning_rate": 1.833857685629309e-05,
      "loss": 0.0307,
      "step": 73700
    },
    {
      "epoch": 5.074606339819844,
      "grad_norm": 0.28093692660331726,
      "learning_rate": 1.8295597159901663e-05,
      "loss": 0.0307,
      "step": 73800
    },
    {
      "epoch": 5.081482500171904,
      "grad_norm": 0.38465842604637146,
      "learning_rate": 1.8253047260474156e-05,
      "loss": 0.0306,
      "step": 73900
    },
    {
      "epoch": 5.088358660523963,
      "grad_norm": 0.1725880354642868,
      "learning_rate": 1.8210067564082726e-05,
      "loss": 0.0306,
      "step": 74000
    },
    {
      "epoch": 5.095234820876023,
      "grad_norm": 0.15163345634937286,
      "learning_rate": 1.8167087867691304e-05,
      "loss": 0.0293,
      "step": 74100
    },
    {
      "epoch": 5.1021109812280825,
      "grad_norm": 0.14364555478096008,
      "learning_rate": 1.8124108171299878e-05,
      "loss": 0.0303,
      "step": 74200
    },
    {
      "epoch": 5.108987141580141,
      "grad_norm": 0.22528433799743652,
      "learning_rate": 1.8081128474908455e-05,
      "loss": 0.0318,
      "step": 74300
    },
    {
      "epoch": 5.115863301932201,
      "grad_norm": 0.2907697260379791,
      "learning_rate": 1.8038148778517032e-05,
      "loss": 0.0304,
      "step": 74400
    },
    {
      "epoch": 5.122739462284261,
      "grad_norm": 0.19472287595272064,
      "learning_rate": 1.7995169082125603e-05,
      "loss": 0.0305,
      "step": 74500
    },
    {
      "epoch": 5.12961562263632,
      "grad_norm": 0.20657804608345032,
      "learning_rate": 1.795218938573418e-05,
      "loss": 0.0309,
      "step": 74600
    },
    {
      "epoch": 5.136491782988379,
      "grad_norm": 0.21148580312728882,
      "learning_rate": 1.7909209689342754e-05,
      "loss": 0.0291,
      "step": 74700
    },
    {
      "epoch": 5.143367943340439,
      "grad_norm": 0.14380194246768951,
      "learning_rate": 1.786622999295133e-05,
      "loss": 0.0313,
      "step": 74800
    },
    {
      "epoch": 5.150244103692498,
      "grad_norm": 0.23163414001464844,
      "learning_rate": 1.782325029655991e-05,
      "loss": 0.0295,
      "step": 74900
    },
    {
      "epoch": 5.157120264044558,
      "grad_norm": 0.11877058446407318,
      "learning_rate": 1.778027060016848e-05,
      "loss": 0.0285,
      "step": 75000
    },
    {
      "epoch": 5.1639964243966165,
      "grad_norm": 0.2278233766555786,
      "learning_rate": 1.7737290903777056e-05,
      "loss": 0.0313,
      "step": 75100
    },
    {
      "epoch": 5.170872584748676,
      "grad_norm": 0.3303559124469757,
      "learning_rate": 1.7694311207385634e-05,
      "loss": 0.029,
      "step": 75200
    },
    {
      "epoch": 5.177748745100736,
      "grad_norm": 0.23052242398262024,
      "learning_rate": 1.7651331510994208e-05,
      "loss": 0.0289,
      "step": 75300
    },
    {
      "epoch": 5.184624905452795,
      "grad_norm": 0.21250733733177185,
      "learning_rate": 1.7608351814602785e-05,
      "loss": 0.0318,
      "step": 75400
    },
    {
      "epoch": 5.191501065804855,
      "grad_norm": 0.16713055968284607,
      "learning_rate": 1.7565372118211355e-05,
      "loss": 0.0323,
      "step": 75500
    },
    {
      "epoch": 5.198377226156914,
      "grad_norm": 0.22607921063899994,
      "learning_rate": 1.7522392421819933e-05,
      "loss": 0.0279,
      "step": 75600
    },
    {
      "epoch": 5.205253386508973,
      "grad_norm": 0.1203354075551033,
      "learning_rate": 1.747941272542851e-05,
      "loss": 0.0304,
      "step": 75700
    },
    {
      "epoch": 5.212129546861033,
      "grad_norm": 0.1821105033159256,
      "learning_rate": 1.7436433029037084e-05,
      "loss": 0.0302,
      "step": 75800
    },
    {
      "epoch": 5.219005707213093,
      "grad_norm": 0.11659138649702072,
      "learning_rate": 1.739345333264566e-05,
      "loss": 0.0297,
      "step": 75900
    },
    {
      "epoch": 5.2258818675651515,
      "grad_norm": 0.6891026496887207,
      "learning_rate": 1.735047363625423e-05,
      "loss": 0.0317,
      "step": 76000
    },
    {
      "epoch": 5.232758027917211,
      "grad_norm": 0.17266246676445007,
      "learning_rate": 1.730749393986281e-05,
      "loss": 0.0298,
      "step": 76100
    },
    {
      "epoch": 5.23963418826927,
      "grad_norm": 0.23947773873806,
      "learning_rate": 1.7264514243471386e-05,
      "loss": 0.0307,
      "step": 76200
    },
    {
      "epoch": 5.24651034862133,
      "grad_norm": 0.24238023161888123,
      "learning_rate": 1.722153454707996e-05,
      "loss": 0.0308,
      "step": 76300
    },
    {
      "epoch": 5.2533865089733895,
      "grad_norm": 0.2643726170063019,
      "learning_rate": 1.7178554850688534e-05,
      "loss": 0.0296,
      "step": 76400
    },
    {
      "epoch": 5.260262669325448,
      "grad_norm": 0.23544007539749146,
      "learning_rate": 1.713557515429711e-05,
      "loss": 0.0317,
      "step": 76500
    },
    {
      "epoch": 5.267138829677508,
      "grad_norm": 0.23769046366214752,
      "learning_rate": 1.7092595457905685e-05,
      "loss": 0.0323,
      "step": 76600
    },
    {
      "epoch": 5.274014990029568,
      "grad_norm": 0.222020223736763,
      "learning_rate": 1.7049615761514263e-05,
      "loss": 0.0288,
      "step": 76700
    },
    {
      "epoch": 5.280891150381627,
      "grad_norm": 0.2126597762107849,
      "learning_rate": 1.7006636065122837e-05,
      "loss": 0.0299,
      "step": 76800
    },
    {
      "epoch": 5.287767310733686,
      "grad_norm": 0.19546137750148773,
      "learning_rate": 1.6964086165695326e-05,
      "loss": 0.0302,
      "step": 76900
    },
    {
      "epoch": 5.294643471085745,
      "grad_norm": 0.19704875349998474,
      "learning_rate": 1.6921106469303903e-05,
      "loss": 0.0316,
      "step": 77000
    },
    {
      "epoch": 5.301519631437805,
      "grad_norm": 0.19968587160110474,
      "learning_rate": 1.6878126772912477e-05,
      "loss": 0.031,
      "step": 77100
    },
    {
      "epoch": 5.308395791789865,
      "grad_norm": 0.31826573610305786,
      "learning_rate": 1.683514707652105e-05,
      "loss": 0.0303,
      "step": 77200
    },
    {
      "epoch": 5.315271952141924,
      "grad_norm": 0.15329699218273163,
      "learning_rate": 1.6792167380129628e-05,
      "loss": 0.0316,
      "step": 77300
    },
    {
      "epoch": 5.322148112493983,
      "grad_norm": 0.1289510875940323,
      "learning_rate": 1.6749617480702117e-05,
      "loss": 0.0305,
      "step": 77400
    },
    {
      "epoch": 5.329024272846043,
      "grad_norm": 0.16514204442501068,
      "learning_rate": 1.670663778431069e-05,
      "loss": 0.0281,
      "step": 77500
    },
    {
      "epoch": 5.335900433198102,
      "grad_norm": 0.17916014790534973,
      "learning_rate": 1.6663658087919268e-05,
      "loss": 0.0325,
      "step": 77600
    },
    {
      "epoch": 5.342776593550162,
      "grad_norm": 0.1601942628622055,
      "learning_rate": 1.6620678391527846e-05,
      "loss": 0.0306,
      "step": 77700
    },
    {
      "epoch": 5.349652753902221,
      "grad_norm": 0.1747811734676361,
      "learning_rate": 1.6577698695136416e-05,
      "loss": 0.03,
      "step": 77800
    },
    {
      "epoch": 5.35652891425428,
      "grad_norm": 0.158619225025177,
      "learning_rate": 1.6534718998744993e-05,
      "loss": 0.03,
      "step": 77900
    },
    {
      "epoch": 5.36340507460634,
      "grad_norm": 0.22361241281032562,
      "learning_rate": 1.6491739302353567e-05,
      "loss": 0.0328,
      "step": 78000
    },
    {
      "epoch": 5.370281234958399,
      "grad_norm": 0.2606348991394043,
      "learning_rate": 1.6448759605962145e-05,
      "loss": 0.0309,
      "step": 78100
    },
    {
      "epoch": 5.3771573953104586,
      "grad_norm": 0.18873050808906555,
      "learning_rate": 1.6405779909570722e-05,
      "loss": 0.0305,
      "step": 78200
    },
    {
      "epoch": 5.384033555662518,
      "grad_norm": 0.12860900163650513,
      "learning_rate": 1.6362800213179292e-05,
      "loss": 0.029,
      "step": 78300
    },
    {
      "epoch": 5.390909716014577,
      "grad_norm": 0.21815280616283417,
      "learning_rate": 1.631982051678787e-05,
      "loss": 0.0321,
      "step": 78400
    },
    {
      "epoch": 5.397785876366637,
      "grad_norm": 0.12069296091794968,
      "learning_rate": 1.6276840820396447e-05,
      "loss": 0.0306,
      "step": 78500
    },
    {
      "epoch": 5.404662036718697,
      "grad_norm": 0.29012781381607056,
      "learning_rate": 1.623386112400502e-05,
      "loss": 0.0308,
      "step": 78600
    },
    {
      "epoch": 5.4115381970707555,
      "grad_norm": 0.3020051419734955,
      "learning_rate": 1.6190881427613598e-05,
      "loss": 0.0298,
      "step": 78700
    },
    {
      "epoch": 5.418414357422815,
      "grad_norm": 0.20697519183158875,
      "learning_rate": 1.614790173122217e-05,
      "loss": 0.0291,
      "step": 78800
    },
    {
      "epoch": 5.425290517774875,
      "grad_norm": 0.20342303812503815,
      "learning_rate": 1.6104922034830746e-05,
      "loss": 0.0286,
      "step": 78900
    },
    {
      "epoch": 5.432166678126934,
      "grad_norm": 0.2820718586444855,
      "learning_rate": 1.6061942338439323e-05,
      "loss": 0.0314,
      "step": 79000
    },
    {
      "epoch": 5.4390428384789935,
      "grad_norm": 0.1780959665775299,
      "learning_rate": 1.6018962642047897e-05,
      "loss": 0.0278,
      "step": 79100
    },
    {
      "epoch": 5.445918998831052,
      "grad_norm": 0.10781244933605194,
      "learning_rate": 1.5975982945656475e-05,
      "loss": 0.0303,
      "step": 79200
    },
    {
      "epoch": 5.452795159183112,
      "grad_norm": 0.14883919060230255,
      "learning_rate": 1.5933003249265045e-05,
      "loss": 0.0298,
      "step": 79300
    },
    {
      "epoch": 5.459671319535172,
      "grad_norm": 0.22283624112606049,
      "learning_rate": 1.5890023552873622e-05,
      "loss": 0.0296,
      "step": 79400
    },
    {
      "epoch": 5.466547479887231,
      "grad_norm": 0.10227109491825104,
      "learning_rate": 1.58470438564822e-05,
      "loss": 0.0304,
      "step": 79500
    },
    {
      "epoch": 5.47342364023929,
      "grad_norm": 0.21727070212364197,
      "learning_rate": 1.5804064160090774e-05,
      "loss": 0.0316,
      "step": 79600
    },
    {
      "epoch": 5.48029980059135,
      "grad_norm": 0.185194730758667,
      "learning_rate": 1.576108446369935e-05,
      "loss": 0.0302,
      "step": 79700
    },
    {
      "epoch": 5.487175960943409,
      "grad_norm": 0.11921067535877228,
      "learning_rate": 1.5718104767307925e-05,
      "loss": 0.0308,
      "step": 79800
    },
    {
      "epoch": 5.494052121295469,
      "grad_norm": 0.11299484223127365,
      "learning_rate": 1.56751250709165e-05,
      "loss": 0.0281,
      "step": 79900
    },
    {
      "epoch": 5.5009282816475285,
      "grad_norm": 0.167182058095932,
      "learning_rate": 1.5632145374525076e-05,
      "loss": 0.0278,
      "step": 80000
    },
    {
      "epoch": 5.507804441999587,
      "grad_norm": 0.23016047477722168,
      "learning_rate": 1.558916567813365e-05,
      "loss": 0.0296,
      "step": 80100
    },
    {
      "epoch": 5.514680602351647,
      "grad_norm": 0.15940111875534058,
      "learning_rate": 1.5546185981742227e-05,
      "loss": 0.0304,
      "step": 80200
    },
    {
      "epoch": 5.521556762703706,
      "grad_norm": 0.10104304552078247,
      "learning_rate": 1.55032062853508e-05,
      "loss": 0.0286,
      "step": 80300
    },
    {
      "epoch": 5.528432923055766,
      "grad_norm": 0.2086702585220337,
      "learning_rate": 1.5460226588959375e-05,
      "loss": 0.0299,
      "step": 80400
    },
    {
      "epoch": 5.535309083407825,
      "grad_norm": 0.146885946393013,
      "learning_rate": 1.5417246892567952e-05,
      "loss": 0.0301,
      "step": 80500
    },
    {
      "epoch": 5.542185243759884,
      "grad_norm": 0.2588399052619934,
      "learning_rate": 1.537426719617653e-05,
      "loss": 0.0315,
      "step": 80600
    },
    {
      "epoch": 5.549061404111944,
      "grad_norm": 0.2270495444536209,
      "learning_rate": 1.5331287499785104e-05,
      "loss": 0.028,
      "step": 80700
    },
    {
      "epoch": 5.555937564464004,
      "grad_norm": 0.22971047461032867,
      "learning_rate": 1.5288307803393677e-05,
      "loss": 0.0298,
      "step": 80800
    },
    {
      "epoch": 5.5628137248160625,
      "grad_norm": 0.2815600335597992,
      "learning_rate": 1.5245328107002251e-05,
      "loss": 0.0284,
      "step": 80900
    },
    {
      "epoch": 5.569689885168122,
      "grad_norm": 0.15011188387870789,
      "learning_rate": 1.5202348410610829e-05,
      "loss": 0.0299,
      "step": 81000
    },
    {
      "epoch": 5.576566045520181,
      "grad_norm": 0.19120167195796967,
      "learning_rate": 1.5159368714219404e-05,
      "loss": 0.0309,
      "step": 81100
    },
    {
      "epoch": 5.583442205872241,
      "grad_norm": 0.2099565863609314,
      "learning_rate": 1.5116389017827978e-05,
      "loss": 0.0296,
      "step": 81200
    },
    {
      "epoch": 5.590318366224301,
      "grad_norm": 0.15837334096431732,
      "learning_rate": 1.5073409321436554e-05,
      "loss": 0.0293,
      "step": 81300
    },
    {
      "epoch": 5.597194526576359,
      "grad_norm": 0.18532977998256683,
      "learning_rate": 1.5030429625045128e-05,
      "loss": 0.0311,
      "step": 81400
    },
    {
      "epoch": 5.604070686928419,
      "grad_norm": 0.18158046901226044,
      "learning_rate": 1.4987879725617618e-05,
      "loss": 0.0292,
      "step": 81500
    },
    {
      "epoch": 5.610946847280479,
      "grad_norm": 0.1273978054523468,
      "learning_rate": 1.4944900029226194e-05,
      "loss": 0.0316,
      "step": 81600
    },
    {
      "epoch": 5.617823007632538,
      "grad_norm": 0.1816975474357605,
      "learning_rate": 1.4901920332834771e-05,
      "loss": 0.0293,
      "step": 81700
    },
    {
      "epoch": 5.6246991679845975,
      "grad_norm": 0.08974462002515793,
      "learning_rate": 1.4858940636443344e-05,
      "loss": 0.0302,
      "step": 81800
    },
    {
      "epoch": 5.631575328336657,
      "grad_norm": 0.27112746238708496,
      "learning_rate": 1.4815960940051921e-05,
      "loss": 0.0322,
      "step": 81900
    },
    {
      "epoch": 5.638451488688716,
      "grad_norm": 0.18528375029563904,
      "learning_rate": 1.4772981243660495e-05,
      "loss": 0.0307,
      "step": 82000
    },
    {
      "epoch": 5.645327649040776,
      "grad_norm": 0.14949895441532135,
      "learning_rate": 1.473000154726907e-05,
      "loss": 0.029,
      "step": 82100
    },
    {
      "epoch": 5.6522038093928355,
      "grad_norm": 0.19363750517368317,
      "learning_rate": 1.4687021850877648e-05,
      "loss": 0.03,
      "step": 82200
    },
    {
      "epoch": 5.659079969744894,
      "grad_norm": 0.2856718897819519,
      "learning_rate": 1.464404215448622e-05,
      "loss": 0.0289,
      "step": 82300
    },
    {
      "epoch": 5.665956130096954,
      "grad_norm": 0.15768098831176758,
      "learning_rate": 1.4601062458094797e-05,
      "loss": 0.0277,
      "step": 82400
    },
    {
      "epoch": 5.672832290449013,
      "grad_norm": 0.17561648786067963,
      "learning_rate": 1.4558082761703373e-05,
      "loss": 0.0297,
      "step": 82500
    },
    {
      "epoch": 5.679708450801073,
      "grad_norm": 0.19194814562797546,
      "learning_rate": 1.4515103065311947e-05,
      "loss": 0.0315,
      "step": 82600
    },
    {
      "epoch": 5.686584611153132,
      "grad_norm": 0.23830674588680267,
      "learning_rate": 1.4472123368920524e-05,
      "loss": 0.0306,
      "step": 82700
    },
    {
      "epoch": 5.693460771505191,
      "grad_norm": 0.24770931899547577,
      "learning_rate": 1.4429143672529096e-05,
      "loss": 0.0314,
      "step": 82800
    },
    {
      "epoch": 5.700336931857251,
      "grad_norm": 0.11831691116094589,
      "learning_rate": 1.4386163976137674e-05,
      "loss": 0.0281,
      "step": 82900
    },
    {
      "epoch": 5.70721309220931,
      "grad_norm": 0.10090228915214539,
      "learning_rate": 1.4343184279746249e-05,
      "loss": 0.0302,
      "step": 83000
    },
    {
      "epoch": 5.71408925256137,
      "grad_norm": 0.12179416418075562,
      "learning_rate": 1.4300204583354823e-05,
      "loss": 0.0291,
      "step": 83100
    },
    {
      "epoch": 5.720965412913429,
      "grad_norm": 0.25602924823760986,
      "learning_rate": 1.42572248869634e-05,
      "loss": 0.0323,
      "step": 83200
    },
    {
      "epoch": 5.727841573265488,
      "grad_norm": 0.20145945250988007,
      "learning_rate": 1.4214245190571973e-05,
      "loss": 0.0299,
      "step": 83300
    },
    {
      "epoch": 5.734717733617548,
      "grad_norm": 0.23988080024719238,
      "learning_rate": 1.417126549418055e-05,
      "loss": 0.0304,
      "step": 83400
    },
    {
      "epoch": 5.741593893969608,
      "grad_norm": 0.5092716813087463,
      "learning_rate": 1.4128285797789125e-05,
      "loss": 0.0335,
      "step": 83500
    },
    {
      "epoch": 5.7484700543216665,
      "grad_norm": 0.12203693389892578,
      "learning_rate": 1.40853061013977e-05,
      "loss": 0.0306,
      "step": 83600
    },
    {
      "epoch": 5.755346214673726,
      "grad_norm": 0.3717446029186249,
      "learning_rate": 1.4042326405006275e-05,
      "loss": 0.0329,
      "step": 83700
    },
    {
      "epoch": 5.762222375025786,
      "grad_norm": 0.1217828318476677,
      "learning_rate": 1.3999346708614852e-05,
      "loss": 0.03,
      "step": 83800
    },
    {
      "epoch": 5.769098535377845,
      "grad_norm": 0.1826339215040207,
      "learning_rate": 1.3956367012223426e-05,
      "loss": 0.0297,
      "step": 83900
    },
    {
      "epoch": 5.7759746957299045,
      "grad_norm": 0.27833229303359985,
      "learning_rate": 1.3913387315832002e-05,
      "loss": 0.0315,
      "step": 84000
    },
    {
      "epoch": 5.782850856081964,
      "grad_norm": 0.2728506624698639,
      "learning_rate": 1.3870407619440576e-05,
      "loss": 0.0307,
      "step": 84100
    },
    {
      "epoch": 5.789727016434023,
      "grad_norm": 0.20281757414340973,
      "learning_rate": 1.3827857720013065e-05,
      "loss": 0.0295,
      "step": 84200
    },
    {
      "epoch": 5.796603176786083,
      "grad_norm": 0.2480853796005249,
      "learning_rate": 1.3784878023621642e-05,
      "loss": 0.0329,
      "step": 84300
    },
    {
      "epoch": 5.803479337138142,
      "grad_norm": 0.1839815080165863,
      "learning_rate": 1.3741898327230218e-05,
      "loss": 0.0316,
      "step": 84400
    },
    {
      "epoch": 5.810355497490201,
      "grad_norm": 0.23764191567897797,
      "learning_rate": 1.3698918630838792e-05,
      "loss": 0.0309,
      "step": 84500
    },
    {
      "epoch": 5.817231657842261,
      "grad_norm": 0.08027437329292297,
      "learning_rate": 1.3655938934447369e-05,
      "loss": 0.0292,
      "step": 84600
    },
    {
      "epoch": 5.82410781819432,
      "grad_norm": 0.28176915645599365,
      "learning_rate": 1.3612959238055941e-05,
      "loss": 0.0284,
      "step": 84700
    },
    {
      "epoch": 5.83098397854638,
      "grad_norm": 0.1720125824213028,
      "learning_rate": 1.3569979541664518e-05,
      "loss": 0.0301,
      "step": 84800
    },
    {
      "epoch": 5.8378601388984395,
      "grad_norm": 0.11726672947406769,
      "learning_rate": 1.3526999845273094e-05,
      "loss": 0.0304,
      "step": 84900
    },
    {
      "epoch": 5.844736299250498,
      "grad_norm": 0.17441295087337494,
      "learning_rate": 1.3484020148881668e-05,
      "loss": 0.0306,
      "step": 85000
    },
    {
      "epoch": 5.851612459602558,
      "grad_norm": 0.16568376123905182,
      "learning_rate": 1.3441040452490245e-05,
      "loss": 0.0293,
      "step": 85100
    },
    {
      "epoch": 5.858488619954617,
      "grad_norm": 0.22130520641803741,
      "learning_rate": 1.339806075609882e-05,
      "loss": 0.0276,
      "step": 85200
    },
    {
      "epoch": 5.865364780306677,
      "grad_norm": 0.143086239695549,
      "learning_rate": 1.3355081059707395e-05,
      "loss": 0.0282,
      "step": 85300
    },
    {
      "epoch": 5.872240940658736,
      "grad_norm": 0.1685277223587036,
      "learning_rate": 1.331210136331597e-05,
      "loss": 0.0304,
      "step": 85400
    },
    {
      "epoch": 5.879117101010795,
      "grad_norm": 0.2849182188510895,
      "learning_rate": 1.3269121666924544e-05,
      "loss": 0.0321,
      "step": 85500
    },
    {
      "epoch": 5.885993261362855,
      "grad_norm": 0.19279101490974426,
      "learning_rate": 1.3226141970533122e-05,
      "loss": 0.03,
      "step": 85600
    },
    {
      "epoch": 5.892869421714915,
      "grad_norm": 0.11792296171188354,
      "learning_rate": 1.3183162274141697e-05,
      "loss": 0.033,
      "step": 85700
    },
    {
      "epoch": 5.8997455820669735,
      "grad_norm": 0.17188440263271332,
      "learning_rate": 1.3140182577750271e-05,
      "loss": 0.031,
      "step": 85800
    },
    {
      "epoch": 5.906621742419033,
      "grad_norm": 0.19048228859901428,
      "learning_rate": 1.3097202881358847e-05,
      "loss": 0.0302,
      "step": 85900
    },
    {
      "epoch": 5.913497902771093,
      "grad_norm": 0.20875324308872223,
      "learning_rate": 1.305422318496742e-05,
      "loss": 0.0284,
      "step": 86000
    },
    {
      "epoch": 5.920374063123152,
      "grad_norm": 0.22383706271648407,
      "learning_rate": 1.3011243488575998e-05,
      "loss": 0.0309,
      "step": 86100
    },
    {
      "epoch": 5.927250223475212,
      "grad_norm": 0.16903965175151825,
      "learning_rate": 1.2968263792184574e-05,
      "loss": 0.0284,
      "step": 86200
    },
    {
      "epoch": 5.934126383827271,
      "grad_norm": 0.15125338733196259,
      "learning_rate": 1.2925284095793147e-05,
      "loss": 0.03,
      "step": 86300
    },
    {
      "epoch": 5.94100254417933,
      "grad_norm": 0.16188816726207733,
      "learning_rate": 1.2882304399401723e-05,
      "loss": 0.0312,
      "step": 86400
    },
    {
      "epoch": 5.94787870453139,
      "grad_norm": 0.2060128152370453,
      "learning_rate": 1.28393247030103e-05,
      "loss": 0.0298,
      "step": 86500
    },
    {
      "epoch": 5.954754864883449,
      "grad_norm": 0.2968660295009613,
      "learning_rate": 1.2796345006618873e-05,
      "loss": 0.0293,
      "step": 86600
    },
    {
      "epoch": 5.9616310252355085,
      "grad_norm": 0.12692444026470184,
      "learning_rate": 1.275336531022745e-05,
      "loss": 0.029,
      "step": 86700
    },
    {
      "epoch": 5.968507185587568,
      "grad_norm": 0.1836799830198288,
      "learning_rate": 1.2710385613836024e-05,
      "loss": 0.0313,
      "step": 86800
    },
    {
      "epoch": 5.975383345939627,
      "grad_norm": 0.2855934202671051,
      "learning_rate": 1.26674059174446e-05,
      "loss": 0.0331,
      "step": 86900
    },
    {
      "epoch": 5.982259506291687,
      "grad_norm": 0.35536110401153564,
      "learning_rate": 1.2624426221053177e-05,
      "loss": 0.0264,
      "step": 87000
    },
    {
      "epoch": 5.989135666643746,
      "grad_norm": 0.15845519304275513,
      "learning_rate": 1.2581446524661749e-05,
      "loss": 0.0321,
      "step": 87100
    },
    {
      "epoch": 5.996011826995805,
      "grad_norm": 0.10864213109016418,
      "learning_rate": 1.2538466828270326e-05,
      "loss": 0.0309,
      "step": 87200
    },
    {
      "epoch": 6.0,
      "eval_accuracy_macro_0.5": 0.9858133792877197,
      "eval_accuracy_micro_0.5": 0.9858133792877197,
      "eval_accuracy_weighted_0.5": 0.9838763475418091,
      "eval_f1_macro_0.5": 0.8174580931663513,
      "eval_f1_macro_0.6": 0.8081938028335571,
      "eval_f1_macro_0.7": 0.7873467206954956,
      "eval_f1_macro_0.8": 0.6651754379272461,
      "eval_f1_micro_0.5": 0.815295398235321,
      "eval_f1_micro_0.6": 0.8070154786109924,
      "eval_f1_micro_0.7": 0.787861168384552,
      "eval_f1_micro_0.8": 0.753933310508728,
      "eval_f1_micro_0.9": 0.6767287850379944,
      "eval_f1_weighted_0.5": 0.8123143911361694,
      "eval_f1_weighted_0.6": 0.8014873266220093,
      "eval_f1_weighted_0.7": 0.7789480686187744,
      "eval_f1_weighted_0.8": 0.6509470343589783,
      "eval_loss": 0.029181692749261856,
      "eval_runtime": 156.0951,
      "eval_samples_per_second": 186.021,
      "eval_steps_per_second": 23.255,
      "step": 87258
    },
    {
      "epoch": 6.002887987347865,
      "grad_norm": 0.20285815000534058,
      "learning_rate": 1.2495916928842815e-05,
      "loss": 0.0293,
      "step": 87300
    },
    {
      "epoch": 6.009764147699924,
      "grad_norm": 0.1753028780221939,
      "learning_rate": 1.245293723245139e-05,
      "loss": 0.0306,
      "step": 87400
    },
    {
      "epoch": 6.016640308051984,
      "grad_norm": 0.18511804938316345,
      "learning_rate": 1.2409957536059966e-05,
      "loss": 0.0295,
      "step": 87500
    },
    {
      "epoch": 6.023516468404043,
      "grad_norm": 0.5478345155715942,
      "learning_rate": 1.236697783966854e-05,
      "loss": 0.0286,
      "step": 87600
    },
    {
      "epoch": 6.030392628756102,
      "grad_norm": 0.20208702981472015,
      "learning_rate": 1.2323998143277118e-05,
      "loss": 0.0301,
      "step": 87700
    },
    {
      "epoch": 6.037268789108162,
      "grad_norm": 0.29635563492774963,
      "learning_rate": 1.2281018446885692e-05,
      "loss": 0.0273,
      "step": 87800
    },
    {
      "epoch": 6.044144949460222,
      "grad_norm": 0.34644263982772827,
      "learning_rate": 1.2238038750494267e-05,
      "loss": 0.031,
      "step": 87900
    },
    {
      "epoch": 6.051021109812281,
      "grad_norm": 0.49718135595321655,
      "learning_rate": 1.2195059054102843e-05,
      "loss": 0.0289,
      "step": 88000
    },
    {
      "epoch": 6.05789727016434,
      "grad_norm": 0.217726469039917,
      "learning_rate": 1.2152079357711418e-05,
      "loss": 0.0274,
      "step": 88100
    },
    {
      "epoch": 6.0647734305164,
      "grad_norm": 0.2898012697696686,
      "learning_rate": 1.2109099661319994e-05,
      "loss": 0.0283,
      "step": 88200
    },
    {
      "epoch": 6.071649590868459,
      "grad_norm": 0.13672418892383575,
      "learning_rate": 1.2066119964928568e-05,
      "loss": 0.0285,
      "step": 88300
    },
    {
      "epoch": 6.078525751220519,
      "grad_norm": 0.1861373633146286,
      "learning_rate": 1.2023140268537143e-05,
      "loss": 0.0296,
      "step": 88400
    },
    {
      "epoch": 6.0854019115725775,
      "grad_norm": 0.17683473229408264,
      "learning_rate": 1.1980160572145719e-05,
      "loss": 0.0337,
      "step": 88500
    },
    {
      "epoch": 6.092278071924637,
      "grad_norm": 0.27607542276382446,
      "learning_rate": 1.1937180875754295e-05,
      "loss": 0.0315,
      "step": 88600
    },
    {
      "epoch": 6.099154232276697,
      "grad_norm": 0.15096886456012726,
      "learning_rate": 1.189420117936287e-05,
      "loss": 0.029,
      "step": 88700
    },
    {
      "epoch": 6.106030392628756,
      "grad_norm": 0.27080395817756653,
      "learning_rate": 1.1851221482971444e-05,
      "loss": 0.031,
      "step": 88800
    },
    {
      "epoch": 6.1129065529808155,
      "grad_norm": 0.151654452085495,
      "learning_rate": 1.180824178658002e-05,
      "loss": 0.0289,
      "step": 88900
    },
    {
      "epoch": 6.119782713332875,
      "grad_norm": 0.31936508417129517,
      "learning_rate": 1.1765262090188595e-05,
      "loss": 0.0297,
      "step": 89000
    },
    {
      "epoch": 6.126658873684934,
      "grad_norm": 0.1335151642560959,
      "learning_rate": 1.1722282393797171e-05,
      "loss": 0.0301,
      "step": 89100
    },
    {
      "epoch": 6.133535034036994,
      "grad_norm": 0.32248884439468384,
      "learning_rate": 1.1679302697405747e-05,
      "loss": 0.0314,
      "step": 89200
    },
    {
      "epoch": 6.140411194389053,
      "grad_norm": 0.20019541680812836,
      "learning_rate": 1.163632300101432e-05,
      "loss": 0.027,
      "step": 89300
    },
    {
      "epoch": 6.147287354741112,
      "grad_norm": 0.054315339773893356,
      "learning_rate": 1.1593343304622898e-05,
      "loss": 0.0306,
      "step": 89400
    },
    {
      "epoch": 6.154163515093172,
      "grad_norm": 0.23160910606384277,
      "learning_rate": 1.1550363608231472e-05,
      "loss": 0.0285,
      "step": 89500
    },
    {
      "epoch": 6.161039675445231,
      "grad_norm": 0.1561165601015091,
      "learning_rate": 1.1507383911840047e-05,
      "loss": 0.028,
      "step": 89600
    },
    {
      "epoch": 6.167915835797291,
      "grad_norm": 0.19411474466323853,
      "learning_rate": 1.1464404215448623e-05,
      "loss": 0.029,
      "step": 89700
    },
    {
      "epoch": 6.1747919961493505,
      "grad_norm": 0.15522794425487518,
      "learning_rate": 1.1421424519057197e-05,
      "loss": 0.0312,
      "step": 89800
    },
    {
      "epoch": 6.181668156501409,
      "grad_norm": 0.18482637405395508,
      "learning_rate": 1.1378444822665774e-05,
      "loss": 0.0304,
      "step": 89900
    },
    {
      "epoch": 6.188544316853469,
      "grad_norm": 0.1399943083524704,
      "learning_rate": 1.1335894923238263e-05,
      "loss": 0.0303,
      "step": 90000
    },
    {
      "epoch": 6.195420477205529,
      "grad_norm": 0.3010653555393219,
      "learning_rate": 1.1292915226846839e-05,
      "loss": 0.0308,
      "step": 90100
    },
    {
      "epoch": 6.202296637557588,
      "grad_norm": 0.1455586701631546,
      "learning_rate": 1.1249935530455413e-05,
      "loss": 0.0308,
      "step": 90200
    },
    {
      "epoch": 6.209172797909647,
      "grad_norm": 0.21111436188220978,
      "learning_rate": 1.1206955834063988e-05,
      "loss": 0.0278,
      "step": 90300
    },
    {
      "epoch": 6.216048958261707,
      "grad_norm": 0.15890246629714966,
      "learning_rate": 1.1163976137672564e-05,
      "loss": 0.0294,
      "step": 90400
    },
    {
      "epoch": 6.222925118613766,
      "grad_norm": 0.14827175438404083,
      "learning_rate": 1.112099644128114e-05,
      "loss": 0.0313,
      "step": 90500
    },
    {
      "epoch": 6.229801278965826,
      "grad_norm": 0.17958472669124603,
      "learning_rate": 1.1078016744889715e-05,
      "loss": 0.0282,
      "step": 90600
    },
    {
      "epoch": 6.2366774393178845,
      "grad_norm": 0.2069050520658493,
      "learning_rate": 1.1035037048498289e-05,
      "loss": 0.0291,
      "step": 90700
    },
    {
      "epoch": 6.243553599669944,
      "grad_norm": 0.28643369674682617,
      "learning_rate": 1.0992057352106866e-05,
      "loss": 0.0283,
      "step": 90800
    },
    {
      "epoch": 6.250429760022004,
      "grad_norm": 0.32910680770874023,
      "learning_rate": 1.094907765571544e-05,
      "loss": 0.0294,
      "step": 90900
    },
    {
      "epoch": 6.257305920374063,
      "grad_norm": 0.24893102049827576,
      "learning_rate": 1.0906527756287931e-05,
      "loss": 0.0313,
      "step": 91000
    },
    {
      "epoch": 6.264182080726123,
      "grad_norm": 0.2063174694776535,
      "learning_rate": 1.0863548059896505e-05,
      "loss": 0.0298,
      "step": 91100
    },
    {
      "epoch": 6.271058241078182,
      "grad_norm": 0.17182675004005432,
      "learning_rate": 1.082056836350508e-05,
      "loss": 0.0315,
      "step": 91200
    },
    {
      "epoch": 6.277934401430241,
      "grad_norm": 0.19951103627681732,
      "learning_rate": 1.0777588667113656e-05,
      "loss": 0.0276,
      "step": 91300
    },
    {
      "epoch": 6.284810561782301,
      "grad_norm": 0.24783846735954285,
      "learning_rate": 1.0734608970722232e-05,
      "loss": 0.0298,
      "step": 91400
    },
    {
      "epoch": 6.29168672213436,
      "grad_norm": 0.30970433354377747,
      "learning_rate": 1.0691629274330807e-05,
      "loss": 0.0291,
      "step": 91500
    },
    {
      "epoch": 6.2985628824864195,
      "grad_norm": 0.13274812698364258,
      "learning_rate": 1.0648649577939381e-05,
      "loss": 0.0283,
      "step": 91600
    },
    {
      "epoch": 6.305439042838479,
      "grad_norm": 0.24517187476158142,
      "learning_rate": 1.0605669881547957e-05,
      "loss": 0.031,
      "step": 91700
    },
    {
      "epoch": 6.312315203190538,
      "grad_norm": 0.12522339820861816,
      "learning_rate": 1.0562690185156533e-05,
      "loss": 0.0332,
      "step": 91800
    },
    {
      "epoch": 6.319191363542598,
      "grad_norm": 0.1655510514974594,
      "learning_rate": 1.0519710488765108e-05,
      "loss": 0.0304,
      "step": 91900
    },
    {
      "epoch": 6.3260675238946575,
      "grad_norm": 0.15644291043281555,
      "learning_rate": 1.0476730792373684e-05,
      "loss": 0.0292,
      "step": 92000
    },
    {
      "epoch": 6.332943684246716,
      "grad_norm": 0.11807126551866531,
      "learning_rate": 1.0433751095982258e-05,
      "loss": 0.0281,
      "step": 92100
    },
    {
      "epoch": 6.339819844598776,
      "grad_norm": 0.1730145364999771,
      "learning_rate": 1.0390771399590833e-05,
      "loss": 0.0296,
      "step": 92200
    },
    {
      "epoch": 6.346696004950836,
      "grad_norm": 0.22870217263698578,
      "learning_rate": 1.0347791703199409e-05,
      "loss": 0.0297,
      "step": 92300
    },
    {
      "epoch": 6.353572165302895,
      "grad_norm": 0.2116888165473938,
      "learning_rate": 1.0304812006807984e-05,
      "loss": 0.0296,
      "step": 92400
    },
    {
      "epoch": 6.360448325654954,
      "grad_norm": 0.10573044419288635,
      "learning_rate": 1.026183231041656e-05,
      "loss": 0.0328,
      "step": 92500
    },
    {
      "epoch": 6.367324486007013,
      "grad_norm": 0.3493073880672455,
      "learning_rate": 1.0218852614025134e-05,
      "loss": 0.0287,
      "step": 92600
    },
    {
      "epoch": 6.374200646359073,
      "grad_norm": 0.1437552124261856,
      "learning_rate": 1.0175872917633711e-05,
      "loss": 0.0306,
      "step": 92700
    },
    {
      "epoch": 6.381076806711133,
      "grad_norm": 0.1615951657295227,
      "learning_rate": 1.0132893221242285e-05,
      "loss": 0.0283,
      "step": 92800
    },
    {
      "epoch": 6.387952967063192,
      "grad_norm": 0.5592932105064392,
      "learning_rate": 1.008991352485086e-05,
      "loss": 0.03,
      "step": 92900
    },
    {
      "epoch": 6.394829127415251,
      "grad_norm": 0.10355333983898163,
      "learning_rate": 1.0046933828459436e-05,
      "loss": 0.0297,
      "step": 93000
    },
    {
      "epoch": 6.401705287767311,
      "grad_norm": 0.18870674073696136,
      "learning_rate": 1.0003954132068012e-05,
      "loss": 0.03,
      "step": 93100
    },
    {
      "epoch": 6.40858144811937,
      "grad_norm": 0.27080535888671875,
      "learning_rate": 9.960974435676588e-06,
      "loss": 0.0296,
      "step": 93200
    },
    {
      "epoch": 6.41545760847143,
      "grad_norm": 0.21038132905960083,
      "learning_rate": 9.917994739285162e-06,
      "loss": 0.0285,
      "step": 93300
    },
    {
      "epoch": 6.4223337688234885,
      "grad_norm": 0.15612775087356567,
      "learning_rate": 9.875015042893737e-06,
      "loss": 0.0278,
      "step": 93400
    },
    {
      "epoch": 6.429209929175548,
      "grad_norm": 0.18921227753162384,
      "learning_rate": 9.832035346502313e-06,
      "loss": 0.0276,
      "step": 93500
    },
    {
      "epoch": 6.436086089527608,
      "grad_norm": 0.1578555405139923,
      "learning_rate": 9.789055650110888e-06,
      "loss": 0.0302,
      "step": 93600
    },
    {
      "epoch": 6.442962249879667,
      "grad_norm": 0.12794215977191925,
      "learning_rate": 9.746075953719464e-06,
      "loss": 0.0267,
      "step": 93700
    },
    {
      "epoch": 6.4498384102317265,
      "grad_norm": 0.12172297388315201,
      "learning_rate": 9.703096257328038e-06,
      "loss": 0.028,
      "step": 93800
    },
    {
      "epoch": 6.456714570583786,
      "grad_norm": 0.22991767525672913,
      "learning_rate": 9.660116560936613e-06,
      "loss": 0.0312,
      "step": 93900
    },
    {
      "epoch": 6.463590730935845,
      "grad_norm": 0.1580113023519516,
      "learning_rate": 9.617136864545189e-06,
      "loss": 0.0269,
      "step": 94000
    },
    {
      "epoch": 6.470466891287905,
      "grad_norm": 0.12973113358020782,
      "learning_rate": 9.574157168153765e-06,
      "loss": 0.0305,
      "step": 94100
    },
    {
      "epoch": 6.477343051639965,
      "grad_norm": 0.20997872948646545,
      "learning_rate": 9.53117747176234e-06,
      "loss": 0.0287,
      "step": 94200
    },
    {
      "epoch": 6.4842192119920234,
      "grad_norm": 0.22762593626976013,
      "learning_rate": 9.488197775370914e-06,
      "loss": 0.0278,
      "step": 94300
    },
    {
      "epoch": 6.491095372344083,
      "grad_norm": 0.0954795703291893,
      "learning_rate": 9.445218078979491e-06,
      "loss": 0.0299,
      "step": 94400
    },
    {
      "epoch": 6.497971532696143,
      "grad_norm": 0.23883292078971863,
      "learning_rate": 9.402238382588065e-06,
      "loss": 0.0299,
      "step": 94500
    },
    {
      "epoch": 6.504847693048202,
      "grad_norm": 0.2198163866996765,
      "learning_rate": 9.359258686196641e-06,
      "loss": 0.0286,
      "step": 94600
    },
    {
      "epoch": 6.5117238534002615,
      "grad_norm": 0.11667471379041672,
      "learning_rate": 9.316278989805217e-06,
      "loss": 0.0282,
      "step": 94700
    },
    {
      "epoch": 6.51860001375232,
      "grad_norm": 0.11670497059822083,
      "learning_rate": 9.273299293413792e-06,
      "loss": 0.0293,
      "step": 94800
    },
    {
      "epoch": 6.52547617410438,
      "grad_norm": 0.17539666593074799,
      "learning_rate": 9.230319597022368e-06,
      "loss": 0.0291,
      "step": 94900
    },
    {
      "epoch": 6.53235233445644,
      "grad_norm": 0.3373982906341553,
      "learning_rate": 9.187339900630942e-06,
      "loss": 0.0282,
      "step": 95000
    },
    {
      "epoch": 6.539228494808499,
      "grad_norm": 0.08529459685087204,
      "learning_rate": 9.144360204239517e-06,
      "loss": 0.0283,
      "step": 95100
    },
    {
      "epoch": 6.546104655160558,
      "grad_norm": 0.22847184538841248,
      "learning_rate": 9.101380507848093e-06,
      "loss": 0.031,
      "step": 95200
    },
    {
      "epoch": 6.552980815512618,
      "grad_norm": 0.14419959485530853,
      "learning_rate": 9.058400811456669e-06,
      "loss": 0.0291,
      "step": 95300
    },
    {
      "epoch": 6.559856975864677,
      "grad_norm": 0.22512800991535187,
      "learning_rate": 9.015421115065244e-06,
      "loss": 0.0293,
      "step": 95400
    },
    {
      "epoch": 6.566733136216737,
      "grad_norm": 0.10471703857183456,
      "learning_rate": 8.972441418673818e-06,
      "loss": 0.0286,
      "step": 95500
    },
    {
      "epoch": 6.573609296568796,
      "grad_norm": 0.1865748167037964,
      "learning_rate": 8.929461722282394e-06,
      "loss": 0.028,
      "step": 95600
    },
    {
      "epoch": 6.580485456920855,
      "grad_norm": 0.1741563230752945,
      "learning_rate": 8.88648202589097e-06,
      "loss": 0.0329,
      "step": 95700
    },
    {
      "epoch": 6.587361617272915,
      "grad_norm": 0.22315599024295807,
      "learning_rate": 8.843502329499545e-06,
      "loss": 0.0287,
      "step": 95800
    },
    {
      "epoch": 6.594237777624974,
      "grad_norm": 0.15556226670742035,
      "learning_rate": 8.800952430072034e-06,
      "loss": 0.03,
      "step": 95900
    },
    {
      "epoch": 6.601113937977034,
      "grad_norm": 0.14822176098823547,
      "learning_rate": 8.758402530644525e-06,
      "loss": 0.0268,
      "step": 96000
    },
    {
      "epoch": 6.607990098329093,
      "grad_norm": 0.29707399010658264,
      "learning_rate": 8.715422834253099e-06,
      "loss": 0.0294,
      "step": 96100
    },
    {
      "epoch": 6.614866258681152,
      "grad_norm": 0.1269306093454361,
      "learning_rate": 8.672443137861674e-06,
      "loss": 0.031,
      "step": 96200
    },
    {
      "epoch": 6.621742419033212,
      "grad_norm": 0.18862904608249664,
      "learning_rate": 8.62946344147025e-06,
      "loss": 0.029,
      "step": 96300
    },
    {
      "epoch": 6.628618579385272,
      "grad_norm": 0.2069159746170044,
      "learning_rate": 8.586483745078825e-06,
      "loss": 0.0285,
      "step": 96400
    },
    {
      "epoch": 6.6354947397373305,
      "grad_norm": 0.17488889396190643,
      "learning_rate": 8.543504048687401e-06,
      "loss": 0.0258,
      "step": 96500
    },
    {
      "epoch": 6.64237090008939,
      "grad_norm": 0.2984832525253296,
      "learning_rate": 8.500524352295975e-06,
      "loss": 0.0296,
      "step": 96600
    },
    {
      "epoch": 6.64924706044145,
      "grad_norm": 0.20457524061203003,
      "learning_rate": 8.45754465590455e-06,
      "loss": 0.0284,
      "step": 96700
    },
    {
      "epoch": 6.656123220793509,
      "grad_norm": 0.19043493270874023,
      "learning_rate": 8.414564959513128e-06,
      "loss": 0.03,
      "step": 96800
    },
    {
      "epoch": 6.662999381145569,
      "grad_norm": 0.25674566626548767,
      "learning_rate": 8.371585263121702e-06,
      "loss": 0.0311,
      "step": 96900
    },
    {
      "epoch": 6.669875541497627,
      "grad_norm": 0.2557780146598816,
      "learning_rate": 8.328605566730277e-06,
      "loss": 0.0335,
      "step": 97000
    },
    {
      "epoch": 6.676751701849687,
      "grad_norm": 0.16395635902881622,
      "learning_rate": 8.285625870338851e-06,
      "loss": 0.0296,
      "step": 97100
    },
    {
      "epoch": 6.683627862201747,
      "grad_norm": 0.11564701795578003,
      "learning_rate": 8.242646173947427e-06,
      "loss": 0.0274,
      "step": 97200
    },
    {
      "epoch": 6.690504022553806,
      "grad_norm": 0.42214420437812805,
      "learning_rate": 8.199666477556004e-06,
      "loss": 0.0314,
      "step": 97300
    },
    {
      "epoch": 6.6973801829058655,
      "grad_norm": 0.2560892403125763,
      "learning_rate": 8.156686781164578e-06,
      "loss": 0.0311,
      "step": 97400
    },
    {
      "epoch": 6.704256343257924,
      "grad_norm": 0.17544637620449066,
      "learning_rate": 8.113707084773154e-06,
      "loss": 0.029,
      "step": 97500
    },
    {
      "epoch": 6.711132503609984,
      "grad_norm": 0.2325458973646164,
      "learning_rate": 8.070727388381728e-06,
      "loss": 0.0298,
      "step": 97600
    },
    {
      "epoch": 6.718008663962044,
      "grad_norm": 0.20013245940208435,
      "learning_rate": 8.027747691990305e-06,
      "loss": 0.0298,
      "step": 97700
    },
    {
      "epoch": 6.724884824314103,
      "grad_norm": 0.2473357766866684,
      "learning_rate": 7.98476799559888e-06,
      "loss": 0.0317,
      "step": 97800
    },
    {
      "epoch": 6.731760984666162,
      "grad_norm": 0.1404712051153183,
      "learning_rate": 7.941788299207454e-06,
      "loss": 0.0307,
      "step": 97900
    },
    {
      "epoch": 6.738637145018222,
      "grad_norm": 0.2930496335029602,
      "learning_rate": 7.89880860281603e-06,
      "loss": 0.0265,
      "step": 98000
    },
    {
      "epoch": 6.745513305370281,
      "grad_norm": 0.21974636614322662,
      "learning_rate": 7.855828906424606e-06,
      "loss": 0.029,
      "step": 98100
    },
    {
      "epoch": 6.752389465722341,
      "grad_norm": 0.20698381960391998,
      "learning_rate": 7.812849210033181e-06,
      "loss": 0.0298,
      "step": 98200
    },
    {
      "epoch": 6.7592656260744,
      "grad_norm": 0.19075824320316315,
      "learning_rate": 7.769869513641755e-06,
      "loss": 0.0299,
      "step": 98300
    },
    {
      "epoch": 6.766141786426459,
      "grad_norm": 0.2363782525062561,
      "learning_rate": 7.727319614214246e-06,
      "loss": 0.0292,
      "step": 98400
    },
    {
      "epoch": 6.773017946778519,
      "grad_norm": 0.23607391119003296,
      "learning_rate": 7.684339917822821e-06,
      "loss": 0.0313,
      "step": 98500
    },
    {
      "epoch": 6.779894107130579,
      "grad_norm": 0.21127091348171234,
      "learning_rate": 7.641360221431395e-06,
      "loss": 0.0287,
      "step": 98600
    },
    {
      "epoch": 6.786770267482638,
      "grad_norm": 0.24643228948116302,
      "learning_rate": 7.598380525039972e-06,
      "loss": 0.0287,
      "step": 98700
    },
    {
      "epoch": 6.793646427834697,
      "grad_norm": 0.1297214776277542,
      "learning_rate": 7.555400828648547e-06,
      "loss": 0.0301,
      "step": 98800
    },
    {
      "epoch": 6.800522588186756,
      "grad_norm": 0.297291100025177,
      "learning_rate": 7.512421132257122e-06,
      "loss": 0.0289,
      "step": 98900
    },
    {
      "epoch": 6.807398748538816,
      "grad_norm": 0.13701553642749786,
      "learning_rate": 7.469441435865697e-06,
      "loss": 0.0279,
      "step": 99000
    },
    {
      "epoch": 6.814274908890876,
      "grad_norm": 0.23801034688949585,
      "learning_rate": 7.426461739474273e-06,
      "loss": 0.0319,
      "step": 99100
    },
    {
      "epoch": 6.8211510692429345,
      "grad_norm": 0.2910228371620178,
      "learning_rate": 7.383482043082848e-06,
      "loss": 0.0311,
      "step": 99200
    },
    {
      "epoch": 6.828027229594994,
      "grad_norm": 0.23350147902965546,
      "learning_rate": 7.340502346691423e-06,
      "loss": 0.0273,
      "step": 99300
    },
    {
      "epoch": 6.834903389947054,
      "grad_norm": 0.12245965003967285,
      "learning_rate": 7.2975226502999985e-06,
      "loss": 0.0324,
      "step": 99400
    },
    {
      "epoch": 6.841779550299113,
      "grad_norm": 0.3418813943862915,
      "learning_rate": 7.254542953908573e-06,
      "loss": 0.031,
      "step": 99500
    },
    {
      "epoch": 6.8486557106511725,
      "grad_norm": 0.23107993602752686,
      "learning_rate": 7.21156325751715e-06,
      "loss": 0.0288,
      "step": 99600
    },
    {
      "epoch": 6.855531871003231,
      "grad_norm": 0.19356077909469604,
      "learning_rate": 7.1685835611257245e-06,
      "loss": 0.0282,
      "step": 99700
    },
    {
      "epoch": 6.862408031355291,
      "grad_norm": 0.1814933568239212,
      "learning_rate": 7.125603864734299e-06,
      "loss": 0.0306,
      "step": 99800
    },
    {
      "epoch": 6.869284191707351,
      "grad_norm": 0.24142447113990784,
      "learning_rate": 7.082624168342875e-06,
      "loss": 0.0295,
      "step": 99900
    },
    {
      "epoch": 6.87616035205941,
      "grad_norm": 0.23235322535037994,
      "learning_rate": 7.039644471951451e-06,
      "loss": 0.0302,
      "step": 100000
    },
    {
      "epoch": 6.883036512411469,
      "grad_norm": 0.1863214373588562,
      "learning_rate": 6.996664775560026e-06,
      "loss": 0.0307,
      "step": 100100
    },
    {
      "epoch": 6.889912672763529,
      "grad_norm": 0.22613734006881714,
      "learning_rate": 6.953685079168601e-06,
      "loss": 0.0287,
      "step": 100200
    },
    {
      "epoch": 6.896788833115588,
      "grad_norm": 0.19603586196899414,
      "learning_rate": 6.910705382777176e-06,
      "loss": 0.0306,
      "step": 100300
    },
    {
      "epoch": 6.903664993467648,
      "grad_norm": 0.20061814785003662,
      "learning_rate": 6.867725686385752e-06,
      "loss": 0.0296,
      "step": 100400
    },
    {
      "epoch": 6.9105411538197075,
      "grad_norm": 0.21519425511360168,
      "learning_rate": 6.824745989994328e-06,
      "loss": 0.0285,
      "step": 100500
    },
    {
      "epoch": 6.917417314171766,
      "grad_norm": 0.1379079669713974,
      "learning_rate": 6.781766293602902e-06,
      "loss": 0.0271,
      "step": 100600
    },
    {
      "epoch": 6.924293474523826,
      "grad_norm": 0.1899998039007187,
      "learning_rate": 6.738786597211477e-06,
      "loss": 0.0296,
      "step": 100700
    },
    {
      "epoch": 6.931169634875886,
      "grad_norm": 0.18928192555904388,
      "learning_rate": 6.695806900820054e-06,
      "loss": 0.0301,
      "step": 100800
    },
    {
      "epoch": 6.938045795227945,
      "grad_norm": 0.22988368570804596,
      "learning_rate": 6.652827204428628e-06,
      "loss": 0.0295,
      "step": 100900
    },
    {
      "epoch": 6.944921955580004,
      "grad_norm": 0.23845691978931427,
      "learning_rate": 6.609847508037203e-06,
      "loss": 0.0302,
      "step": 101000
    },
    {
      "epoch": 6.951798115932063,
      "grad_norm": 0.12434447556734085,
      "learning_rate": 6.566867811645779e-06,
      "loss": 0.0278,
      "step": 101100
    },
    {
      "epoch": 6.958674276284123,
      "grad_norm": 0.10864312946796417,
      "learning_rate": 6.5238881152543535e-06,
      "loss": 0.0302,
      "step": 101200
    },
    {
      "epoch": 6.965550436636183,
      "grad_norm": 0.1713927537202835,
      "learning_rate": 6.48090841886293e-06,
      "loss": 0.0278,
      "step": 101300
    },
    {
      "epoch": 6.9724265969882415,
      "grad_norm": 0.22363905608654022,
      "learning_rate": 6.437928722471505e-06,
      "loss": 0.0298,
      "step": 101400
    },
    {
      "epoch": 6.979302757340301,
      "grad_norm": 0.21237359941005707,
      "learning_rate": 6.3949490260800795e-06,
      "loss": 0.0321,
      "step": 101500
    },
    {
      "epoch": 6.98617891769236,
      "grad_norm": 0.2849198579788208,
      "learning_rate": 6.351969329688655e-06,
      "loss": 0.0274,
      "step": 101600
    },
    {
      "epoch": 6.99305507804442,
      "grad_norm": 0.38567134737968445,
      "learning_rate": 6.3089896332972315e-06,
      "loss": 0.0303,
      "step": 101700
    },
    {
      "epoch": 6.99993123839648,
      "grad_norm": 0.2174232453107834,
      "learning_rate": 6.266009936905806e-06,
      "loss": 0.0257,
      "step": 101800
    },
    {
      "epoch": 7.0,
      "eval_accuracy_macro_0.5": 0.9861125946044922,
      "eval_accuracy_micro_0.5": 0.9861125349998474,
      "eval_accuracy_weighted_0.5": 0.9841763377189636,
      "eval_f1_macro_0.5": 0.8225758075714111,
      "eval_f1_macro_0.6": 0.8117625713348389,
      "eval_f1_macro_0.7": 0.7917379140853882,
      "eval_f1_macro_0.8": 0.6733739376068115,
      "eval_f1_micro_0.5": 0.8199475407600403,
      "eval_f1_micro_0.6": 0.8108100295066833,
      "eval_f1_micro_0.7": 0.7927508354187012,
      "eval_f1_micro_0.8": 0.758915364742279,
      "eval_f1_micro_0.9": 0.6853013038635254,
      "eval_f1_weighted_0.5": 0.8170711398124695,
      "eval_f1_weighted_0.6": 0.8055232763290405,
      "eval_f1_weighted_0.7": 0.784402072429657,
      "eval_f1_weighted_0.8": 0.6607493758201599,
      "eval_loss": 0.028748799115419388,
      "eval_runtime": 144.1339,
      "eval_samples_per_second": 201.458,
      "eval_steps_per_second": 25.185,
      "step": 101801
    }
  ],
  "logging_steps": 100,
  "max_steps": 116344,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.156744956337318e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
