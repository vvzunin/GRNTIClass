Нейронные сети (ННС) — это мощные вычислительные модели, использующие алгоритмы для решения задач, таких как классификация, регрессия и распознавание образов. Они состоят из искусственных нейронов, которые организованы в слои: входной слой, скрытые слои и выходной слой. Каждый нейрон в сети получает данные, обрабатывает их с помощью взвешенных соединений и активационной функции, и передает результат дальше.
Основной алгоритм обучения ННС — это обратное распространение ошибки (backpropagation), где используется градиентный спуск (SGD) или его улучшенные версии (Adam, RMSprop). Для улучшения качества работы сети применяются разные архитектуры, такие как сверточные нейронные сети (CNN) для обработки изображений и рекуррентные нейронные сети (RNN) для работы с последовательностями. Современные ННС могут быть очень глубокими (DNN), что позволяет достигать высокой точности в сложных задачах, таких как генерация текста или распознавание речи.
$$ E=mc^2 $$

$\varphi = 2 \cdot 6$
[[Математический анализ]]
## Утверждение:
Для всякой системы вложенных отрезков
$$[a_1, b_1]\supset[a_2, b_2]\supset\dots[a_n, b_n]\supset\dots$$
существует хотя бы одна точка $c$, принадлежащая всем отрезкам данной системы.
Если, кроме того, длина отрезков системы стремится к 0:
$$\lim_{n \to \infty}({b_n - a_n}) = 0$$
то $c$ - единственная общая точка всех отрезков данной системы.
## Замечание
Отрезки в формулировке теоремы нельзя заменить на открытые интервалы. Например, $$\bigcap\limits_{n=1} ^{\infty} (0, \frac{1}{n}) = \varnothing$$
